Miko Pawlikowski  0:09  
Hello and welcome to Conf 42 cast Episode Two space birds love cyber bugs. My name is Miko Pawlikowski and today with me Liran Haimovitch, the CTO and co founder at Rookout. also frequently speaker Rookout empowers engineers to solve customer issues five times faster by making debugging easy and accessible in any environment. See what Rookout can do for you at www.rookout.com Hello, Liran. Great to have you here today.

Liran Haimovitch  0:41  
Hey, Mikolaj great being here as well.

Unknown Speaker  0:43  
Can you tell me what's the deal with Rookout? Where the name came from? Is it from the song you know, rook out? You were there at the beginning? Right?

Liran Haimovitch  0:50  
Yeah, I was there from the very beginning. The name actually comes from the name of the bird rook, which is a very clever Raven, that's good at solving puzzles, you can actually throw some food in a glass of water and it's going to use stones and stuff to get the low water levels up. And it can you actually use tools such as a small tree branches. And essentially Rookout is about having a very smart bird on your hand that allows you to instantly extract any piece of data you want from your application so that you can see what's going on.

Miko Pawlikowski  1:21  
Yeah, so kind of eagleeye plus a smart bird. Okay, makes sense. You know, I always have a lot of respect for people who jump into building a company from scratch. That's quite a challenge and very risky. Was there, like any moment that made you think, okay, yeah, this is worth doing. Let's just jump into that. And do it was there like in a single moment, or you just knew you kind of needed to do that. 

Liran Haimovitch  1:44  
So we were exploring the realm of cyber security, and DevOps and dev tooling, we met with so many engineering leaders, and so many individual contributors, every single time this problem came up, it's my code, it's running somewhere remote, and I just couldn't get it. And we found people try to spend so much time and effort solving it, but kind of solving it backwards, I guess, whether it's about getting your ci CD pipeline to be ever fast enough that you can just add logs on the fly. But it's never fast enough about trying to replicate your production environment locally, whether it's through a fancy orchestration, Turing's database, migration, tooling, service, virtualization, tunings. And not only are you spending so much time and effort on that, again, it's never accurate enough, we met some companies that would spend two or three days doing database migrations, every time a customer reported a bug, just to be able to observe it and see what's going on. This pain was so universal, we knew we had to do something about it.

Miko Pawlikowski  2:49  
Yeah, I can feel the pain already in there remotely from here. And you just knew, okay, we need to fix that. And you went for it.

Liran Haimovitch  2:57  
Yeah, I just felt like we had a new angle on it a fresh perspective. And we figure that at the end of the day, while we traditionally use log lines to monitor production, the act of updating those log lines of updating those metrics, was very cumbersome. It was releasing a new version and deploying it with everything that comes as part of the process. And that's a very big process, a very big risk, very big change we're doing. And the end of the day, all we're trying to do is change a single line of code, sometimes even flip a single bit in memory. And we're spending hours doing that. And we figured there had to be another way. And so we kind of take into our cybersecurity mindset and skill set and our experience and kind of build something that allows you to do it on the fly that updates the application for you on the fly to collect any piece of data you need. So without having to spend any time or effort doing it yourself.

Miko Pawlikowski  3:49  
Yeah, we'll dig deeper into that in a second. But tell me, what's your favourite and least favourite bit about working in a startup? And especially how did all of that dynamic get affected by the biggest pandemic and delivery memory,

Liran Haimovitch  4:04  
I love the experience of creating of making stuff that wasn't there. And in many ways, building a startup is the ultimate experience of that. It's not just about building the product. It's about building the company. It's about building the culture. It's about hiring the people in training them. A company is kind of a living, breathing thing. In a way. It's more than some of its power. It's all the people, all the product, all the customers and seeing it all come together knowing you're the big part in making it happen. I think that's my favourite part. my least favourite part. I would say it's about uncertainty. Especially if you think about it. When you create a startup, you literally create a business that's going bankrupt every day. because by definition, you're spending more than you're earning. And you're constantly relying on the next injection of cash coming down somewhere down the road. So we'd love to sell you a lot of personal rescuers death A lot of pressure. Think about it, how would you want to be the CEO or a C level executive in a company that's literally going bankrupt every day? Yeah,

Miko Pawlikowski  5:09  
I can definitely relate to that. And also, that actually makes me think I was watching this critical slack video the other day. And it really stuck with me that they were talking about the breathing process and how the energy is being released, you know, and the basically, bottom line is that we're constantly dying. And with every breath, we reset the timer for like, 10 minutes. And that's how we live our lives. That's kind of basically what you describe here with the start of except that the oxygen is replaced with money, right?

Liran Haimovitch  5:35  
Definitely. So I'm not sure how many people would be comfortable with this thought of every breath are taking is literally bringing them step closer to death. It got deep.

Miko Pawlikowski  5:44  
So one last random question before we jump into the record, if you could have an animal at all as a pet, would it be a rook?

Liran Haimovitch  5:51  
I think that's a good question. I actually have a dog right now, that dog really love chasing after ravens and crows and stuff. So if I had a rook and that dog side by side, it might get messy.

Miko Pawlikowski  6:04  
Although it's probably better than having a cat and a bird, you gave a talk recently had come 42 about understandability. Could you talk a little bit about how that's different from observability. The other buzzword that we keep using these days, and you know, what's the common things are and how it differs in how we apply

Liran Haimovitch  6:24  
observability. It's been around for a while now, over five years. And it stems from the need of ESeries ops to know what's going on in the system. Essentially, they deploy system eight contains some code, some configuration, you deploy it somewhere, hopefully in the cloud, and then you have to know how it's doing. I mean, you can't see into the servers themselves that are remote, there are potentially many of them. And you're trying to figure out, is my system working properly? And there are many definitions of that. But there tend to be somewhat strict. How many requests Am I serving per second? What's my latency? What's my error rate? And then how can I break that down throughout the customer experience with different API's, if I'm in a micro service environment, I probably want to see this breakdown per micro service and see the interactions and it's kind of getting the big picture. And knowing what's going on. That's the essence of observability understandability, in a way, goes a step deeper and goes a bit different route. understandability is about how well do I understand the system, not only how it's doing, but also what it's supposed to be doing, what it was originally meant to be doing and what it's doing now, and kind of saw and so forth, truly understand the system, we don't get that luxury of just seeing it from a bird's eye view. And now everything is alright, in general, we often have to answer deeper questions. And that's kind of what software engineers do on the on a daily basis. How is that feature working? Why is this customer getting a five and the other customer is getting three why for that customer, the screen is blue, and for the other customer, it's green. And it's not just about knowing that everything is good, that customer is supposed to be getting blue in that customer is supposed to be getting green. It's also about understanding the algorithms behind it. Understanding the flows, understanding the configurations. And unfortunately, this means that you constantly have to get new questions, whether you're resolving a bug, or trying to design a new feature, or just adopting an existing features. The questions keep changing on a daily, even sometimes even hourly basis. And so the data you need to answer those questions is always shifting as well. By the way, it's about the source code itself, the input and the output of the systems, the configuration and state of the system, various dependencies you might be interested in, maybe even more importantly, how they all play together. Okay,

Miko Pawlikowski  8:52  
so it's not just the school of thought is that the methodology is the best set of tools. Is that a T shirt? Which one? Is it really the understandability?

Liran Haimovitch  9:03  
It's a bit of everything I would say, especially as t shirt. But I think it's first and foremost about school of thought about knowing that. I mean, one example I like the most is the fact that when we got our basic computer science training within the university or anywhere else, you had those simple exercises, or no salt data structure redefined in a POSIX content. And those are the kinds of exercises that each of us got through after a few hours on that first computer science training. And now we expect all of ourselves to be able to do it in a matter of minutes quite often. And yet, when we get those tasks in the context of large, complex environments, they often end up taking weeks and often That's the difference. The difference between plugging those two lines of code into a huge system. It's all about knowing when to plug them and what to plug and that's about understandability So it's not just about being able to do things, it's about understanding the scope or sending out

Miko Pawlikowski  10:06  
all comes together acts a lot of science. Yeah. So basically observability is cool, you can see things, but then the next step would call it now understandability kind of level up. So you touched on a lot of things that people typically have problems with, like you mentioned, a time that it takes to get feedback. Is that what people hate the most about debugging, like from your customers experiences? Is that like the number one challenge? Or is that something that you or other people hate even more than that,

Liran Haimovitch  10:35  
it's often that feeling of helplessness that gets around when you're kind of stuck. And obviously, sometimes you get a bug. And then you're like, Oh, I know that. I made a mistake. And I forgot a.or a slash, or I need to redact one. And that's kind of brings us back to understandability. You know, the code so well, that once somebody tells you the symptom of the bug, you instantly know where in the code you made a mistake and how you need to fix it. And that's where your inability is very good. But quite often, it's not that easy. I would say more often than not, whether it's because you're missing logs, or missing metrics, or you're you don't have access to the customer data, or you don't have full the full picture of of what's actually going on, and what are the environment the code is operating in. And all of the sudden, you're kind of stuck, and you feel helpless. And this feeling is often aggravated when it's a customer that reported the bug, especially if it's an important customer, or something that has a big impact on the company. And now everybody in the company is looking at you whether it's the tech lead, or the engineering lead the solution engineer, and definitely the marketing and sales departments. And everybody's kind of staring at you and saying, Here's to fix the bug. And you're like, I have no idea what's going on.

Miko Pawlikowski  11:47  
That's a terrible feeling, especially when it's like a race condition that's very rare and only produce itself once or twice, and you have real trouble reproducing them,

Liran Haimovitch  11:57  
we recently found a couple of memory leaks within the V eight engine itself. And when put under extreme pressure. And that was so frustrating, we literally spent weeks handling those memory leaks only to find them within the aviator engine itself, which was pretty crazy.

Miko Pawlikowski  12:16  
That's also you know, we use so much open source technology and so many dependencies that it's sometimes really hard work a lot with Kubernetes. And most of the time, when you did find something that really looks like a bag, if you looked up now, there's probably someone who ran into that already. But there was this boat like lishi, the other week when we were trying to track it down. And eventually we found a ticker that was put in by someone a year ago, and only updated like a few days when someone actually managed to reproduce like race condition when a connection was being closed. I think

Liran Haimovitch  12:48  
your point around open source is another great example of where logging doesn't work well enough. Because when it's your code, and you want to add a log line, then that's quite easy. Go to the code, you edit the line, you rebuild, redeploy. But what happens when you want to adjust one load line to an open source project to an open source project, all you have to do is edit the code, but then you have to create the entire build process in packaging process and dependency process on your machine, there is a huge difference between being able to read the source code for an open source project, and being able to build it efficiently into your own build process and into your dependency management process. And that's the difference between you know, 10 seconds to type the line. And potentially there is a fork of setting up the development environment. And that's another great use case for rowcount. Because when you can instantly set a breakpoint, just like a traditional debugger, you can debug anything, it doesn't matter if it's your code, or if something else debugging is easier than anything in many cases. Yeah.

Miko Pawlikowski  13:49  
And especially now when everything's now cloud native and micro services and everything, you have all this processes running remotely, and you have to get to them. So I feel like at this stage, the suspense is unbearable. So tell us how does rook out work under the hood.

Liran Haimovitch  14:04  
So under the hood, we offer five as the case one for the JVM one for the dotnet runtime, one for the Python runtime for the node runtime and for the Ruby runtimes. And each of those is the cases built to be different and yet very closely related. And what we do is we essentially map out the code in memory, we map out the class objects, the functions and all that and we find a memory representation of that code. And we allow you to edit it. So when you go and say go into main dot java in line 14 and want to see what's happening there, we find in memory which function main dot java at line 40 is and then we recompile that function with additional instrumentation code that extracts data on the fly. So that the next time This function is called and line fault is hit, you are going to get to see what's going on inside of it. Okay,

Miko Pawlikowski  14:56  
so let's say I have a Java application, your SDK as some kind of Java agent, it starts and then I guess it modifies my classes on the fly with your extra debugging code, right? how safe is that? very safe, very safe.

Liran Haimovitch  15:11  
Like everything else we're doing. It's about trusting our infrastructure, whether it's the Java virtual machine itself, you could ask how safe is that, you know, taking Java bytecode, that stored in zip files and running it in memory that has its own set of challenges. And the thing is, it took out, we take great pride at our walk. And that's what we focus on doing that in the most secure and possible way. I know there have been some alternatives that kind of allow you to do it yourself approach where you can use various instrumentation libraries to do it yourself. And obviously, there is a lot that can go wrong, we narrow it down, we do a very specific set of data collection that's heavily tested on our end, as well as we add a lot of policy based safeties. On top of that, we have rate limiting and hit limiting, we have sandbox control that ensures you don't modify the application, you just collect data from it on the fly, and the correctness will be impacted. And so we ensure that both the code will remain valid, on the one hand, and on the other hand, we ensure that the applications overall performance and correctness won't be modified, because we tightly control what's going to be executed.

Miko Pawlikowski  16:23  
So it sounds to me a little bit like debugger light kind of thing that not everything's wide open, but you have like this specific set of things that you want to look at. And you basically expose a debugger like kind of interface, step two, right way of thinking about that,

Liran Haimovitch  16:40  
I think that's a great way to look at it, we strive to bring the experience of the debugger, also the experience of a profiler to every environment. And obviously, some trade offs have to be made, you can stop the application, because if you're going to start a production application, or a service mesh application, things aren't going to go too well. We simulate, we provide you a very close experience. We collect the data, we show you snapshots of various data controls and security controls in place to ensure you can use it in a production environment. And kind of try to bring you the best of both worlds. This is as close as you can get to running a debugger in production

Miko Pawlikowski  17:16  
culture. And the SDK that you mentioned, doesn't mean that you need to build your application with them, or does all of that happen at the startup? Kind of enrichment without you actually having to instrument the code? It's

Liran Haimovitch  17:29  
a bit of both it depends on the runtime itself. Some runtimes can be we support instrumentation runtimes. For some of them, you have to compile a scene. But either way, it's a 10 minute installation process. And you're good to go. Gotcha.

Miko Pawlikowski  17:42  
I was just thinking, I have this massive bag, I spent two weeks on it. And I gave up, I need to root. I need to root out Okay, so I go and then do I need to like recompile my thing? Or do I just like attach some kind of sidecar that will do the instrumentation on the fly.

Liran Haimovitch  17:59  
So it's not a sidecar. But it's a quick package, you just add it, you can get it up and running in under 10 minutes and find about 10 times faster than you would otherwise. Hey,

Miko Pawlikowski  18:08  
no, wait, you said five times faster on your website. And now it's there? Which one is it?

Liran Haimovitch  18:14  
So you know, it depends on which marketing person you speak to that type of thing. Okay, we're seeing customers report anything from five to 10 times faster. So it's more about how conservative we are with specific data.

Miko Pawlikowski  18:27  
And in terms of performance, you said that trying to give the best of the both worlds and I'm guessing with the limiting and just trying to put as little study instrumentation as possible, do you have any benchmarks that we could look at to see, you know, this is 1% overhead is all good, are we gonna have to trust out with them. So

Liran Haimovitch  18:43  
we do have benchmarks we can provide, not everything is public, but we'll be happy to provide as a rule of thumb, I can say that a single breakpoint is under one millisecond for most runtimes. And it's often a lot under one millisecond latency. And on top of that, we have various mechanisms such as heat limiting or rate limiting, so even if you set a breakpoint in a very hot loop, it just gonna move into sampling mode automatically disable based on various policies you can configure.

Miko Pawlikowski  19:10  
So you went with this active approach into you know, building this custom solution for all the different runtimes and I know that a lot of the industry right now is trying to leverage BPF to get things that the Linux kernel mode, do you also do any of that you know, at the kind of Cisco level or is that too coarse grain? So that is not necessarily useful to your users. So

Liran Haimovitch  19:32  
the answer is a bit of both I guess for now, we are focusing on the application core on the code itself, we are looking at dynamic instrumenting other components in the future such as ebpf, such as logging such as our stuff, but even if you look at ebp f which is very interesting technology that rowing there are various integrations, I think node is a built in ebpf engine and things are changing very rapidly. Very interesting. There is a whole lot of Focus is about being able to easily and dynamically collect data and instrument. So wherever we go, we try to say it's not our focus to collect you the same data day in day out. There are many companies that do that APM logging, and graters and so on. And they're doing a great job, what we focus on his being able to collect just data you need with as little overhead as possible, and being able to move it very, very fast, so that you can change your mind in a matter of seconds on what you want to collect. And we don't want technology to hold you back what technology to empower you. And this actually goes beyond debugging. It goes into collecting analytics, collecting metrics, any piece of data you want from your software should be available within seconds, rather than prioritising new features

Miko Pawlikowski  20:49  
and getting lots of for consumer makes sense, different use case. And just the question. So you started with about four years ago, right? Something like that, which kind of correlates with Kubernetes becoming a thing? Is all of that, because Kubernetes made it so hard to debug things that you have to do solutions like that, or is that just a coincidence that this happened roughly at the same time. So

Liran Haimovitch  21:12  
it's an interesting coincidence. On the one hand, we have customers from all around, whether they're the most cutting edge cloud native, even some serverless. On the other hand, we have a lot of customers, and we're still rolling in data centres with vertical scaling servers, Java application servers, and none of that. I would say we just mapped it a few months ago. And we were very surprised to see that most of our customers are very deep into Kubernetes. I'm not sure if they're, it's because the pain is so much bigger in Kubernetes. And especially in service mesh environments, where you just can't set up decent development environments for your engineers, or is it just a coincidence that those companies are more agile, and more interested in adopting new technology? No, I

Miko Pawlikowski  21:54  
was kind of half joking. Kubernetes has some advantages also makes things a bit more complex either later to explore. Okay, one more question. I noticed that you have a solid open source footprints on GitHub, are you an open source company, kind of open source company? Is there anything you recommend sticking out on GitHub?

Liran Haimovitch  22:15  
We're not an open source company, or at least not for now, it's always been a debate for us a kind of how do we build the product in a way that's both useful? From an open source perspective? It's still sustainable from a commercial perspective. And it's a tricky question. So we've been struggling with. At the meantime, we've tried to out to open source as much as we can. We've open source various tools we've built internally, for instance, we've built a tool called Git enforcer, that allows you to enforce and automate various best practices over GitHub pull requests, and so on. Actually, over the past couple of years, we've seen GitHub implement some of those features since then, which is pretty cool. Back in there when we originally wrote it three years ago, but much of it was lacking. So let's say a developer opens a pull request. And with they don't have a ticket to merge it yet, because it just saw about as they were walking, they can just add a comment to the pull request and automatically get the JIRA ticket for it so they can manage it. and all kinds of other equal opportunities. So that's available is an open source project. We've also open sourced some of our research around integrating air with browsers and stuff. And we are hoping to release some more of our co IB into open source this year.

Miko Pawlikowski  23:28  
Awesome. That was really cool. I'm looking forward to trying out all of those things running. I just want to close up with one question I think most of our audience might find useful. If you were to pick one single highest return on investment thing that you did for your tech career, what would it be? And would you recommend other people do that too,

Liran Haimovitch  23:50  
my career's been, I would say, pretty unorthodox, or at least compared to many people. In a way, I think that's the important thing I took is being independent and being able a belief in yourself and your ability to learn. Just knowing that you can pick up any topic you want, whether it's along the way with rock out, I grew my knowledge from Python. from basic to expert, I learned Java, I've learned JavaScript, and I've learned Ruby. I've also upgraded my Java, C sharp knowledge, and all of that pretty much on my own. I think the important thing about software engineering is learning to learn. It's about knowing how to learn a picking up new technologies, picking up new languages, and expanding the capabilities. And of course, wherever you're working with our smart colleagues around you, you definitely need to build on that learn from them. But at the same time, it's important to both learn to learn and to build your capacity for learning, as well as gaining a deeper understanding of every technology you pick up because you would see those themes returning different languages, different runtimes. They have a lot in common and the more you Deeply you understand one, the easier it's going to be to understand the next. So always learning always being inquisitive makes a huge difference in your ability to pick up new skills and technologies and be a great engineer. Awesome.

Miko Pawlikowski  25:13  
I like that building the tree branch by branch. You never know where the next branch might go. Thank you for that. leerin If you want to check out Lee, Ron's company once again, www.ruco.com thanks so much for coming. I'll see you next time. Thank you, everybody.

Transcribed by https://otter.ai
