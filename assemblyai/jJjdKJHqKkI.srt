1
00:00:34,610 --> 00:00:38,454
Hello everyone and welcome to this talk called your lambdas in

2
00:00:38,492 --> 00:00:41,670
Rust. So before getting started,

3
00:00:41,740 --> 00:00:44,886
I'd like to share the slides with you because I'm going to be showing you

4
00:00:44,908 --> 00:00:48,342
some code examples. I'm going to be giving you a bunch of different links so

5
00:00:48,396 --> 00:00:51,754
if there is something that might interest used to you will have the slides

6
00:00:51,802 --> 00:00:55,406
ready for later. And as you scan the QR code or go to

7
00:00:55,428 --> 00:00:59,054
that link you see there, I'm going to introduce myself. So hello again

8
00:00:59,092 --> 00:01:03,114
everyone. My name is Luciano and I am can AWS Serverless

9
00:01:03,162 --> 00:01:07,390
Hero, a certified solution architect and also a Microsoft MVP.

10
00:01:07,550 --> 00:01:11,486
I work for a company called fourtheorem. More on that in a minute.

11
00:01:11,598 --> 00:01:15,042
As a senior architect, and you might have seen me

12
00:01:15,096 --> 00:01:18,226
in the node js field because I'm the co author of this

13
00:01:18,248 --> 00:01:21,542
book called Node JS Design Patterns. If you have read this book,

14
00:01:21,596 --> 00:01:24,774
not relevant for this talk, but I'd be really curious to know what you think

15
00:01:24,812 --> 00:01:28,194
about that. So definitely feel free to connect with me and let's

16
00:01:28,242 --> 00:01:31,560
chat after this talk. I'd love to talk with all of you.

17
00:01:32,570 --> 00:01:36,586
So, about fourtheorem. We are a consulting company. We are

18
00:01:36,768 --> 00:01:40,422
especially focused on serverless, on AWS.

19
00:01:40,486 --> 00:01:43,934
We are also AWS consulting partners and we spend

20
00:01:43,972 --> 00:01:47,146
a lot of time helping customers doing cloud migration.

21
00:01:47,258 --> 00:01:50,702
We train their teams, we help them to get started with the cloud.

22
00:01:50,836 --> 00:01:54,378
We have been building a few interesting high performance serverless applications

23
00:01:54,474 --> 00:01:57,586
and we also helped a few companies to cut down cost of their

24
00:01:57,608 --> 00:02:00,834
own cloud expenditure. If all this stuff is something that

25
00:02:00,872 --> 00:02:04,370
interests you, feel free to connect with me or send an email to the address

26
00:02:04,440 --> 00:02:07,838
you see there. And we are also hiring. So if that's something you

27
00:02:07,864 --> 00:02:11,026
want to discuss again, let's have a quick chat and I'd

28
00:02:11,058 --> 00:02:14,834
love to know more about you. We are very committed

29
00:02:14,882 --> 00:02:17,666
to content creation. We create a lot of articles,

30
00:02:17,698 --> 00:02:21,414
but we are also very keen in publishing weekly

31
00:02:21,462 --> 00:02:25,510
episodes of our podcast. This is just one of our episodes,

32
00:02:25,590 --> 00:02:29,398
so if you are into AWS, you might want to check, but our podcast

33
00:02:29,494 --> 00:02:32,700
and let us know what you think about that.

34
00:02:33,090 --> 00:02:36,734
So enough presentation, let's get into the talk.

35
00:02:36,852 --> 00:02:40,714
And the agenda for today is I'm going to be trying to explain what serverless

36
00:02:40,762 --> 00:02:43,946
is and what are the main benefits. In my opinion.

37
00:02:44,138 --> 00:02:48,354
We're going to be going through what is AWS Lambda and the pricing model.

38
00:02:48,552 --> 00:02:51,938
We are going to be discussing why rust, why it's so cool,

39
00:02:52,104 --> 00:02:55,294
and we're going to look at specific tool called cargo lambdas

40
00:02:55,342 --> 00:02:58,478
and I'm going to be showing you some examples. Then we are going to be

41
00:02:58,504 --> 00:03:01,830
discussing how to use cargo lambda with another tool called Sam.

42
00:03:02,170 --> 00:03:05,286
And finally, we're going to be looking at some lambda tuning and

43
00:03:05,308 --> 00:03:08,454
some closing does and questions that you might have.

44
00:03:08,652 --> 00:03:11,830
So let's start with serverless. What is serverless?

45
00:03:11,910 --> 00:03:15,274
It's always very, very hard to describe what serverless is. So I

46
00:03:15,312 --> 00:03:18,986
took a different approach, a more modern approach, I dare to

47
00:03:19,008 --> 00:03:22,902
say, and I asked Chat GPT, what the hell is serverless?

48
00:03:23,046 --> 00:03:26,110
And I was actually surprised that it gave me a quite good answer.

49
00:03:26,180 --> 00:03:29,438
It's a bit long, so I'm going to try to focus on the main points.

50
00:03:29,604 --> 00:03:33,418
So one of the main points is that it says that it's a cloud computing

51
00:03:33,434 --> 00:03:37,374
model where the cloud provider manages the infrastructure and automatically allocates

52
00:03:37,422 --> 00:03:41,086
computing resources to execute code in response to events

53
00:03:41,118 --> 00:03:45,054
or requests. Another good point is that there are no servers to

54
00:03:45,112 --> 00:03:48,326
manage or provision. And another one is that

55
00:03:48,348 --> 00:03:51,782
developers only pay for the actual usage of their application,

56
00:03:51,916 --> 00:03:55,366
not for the infrastructure. And finally, examples of

57
00:03:55,388 --> 00:03:58,370
serverless services include AWS lambdas.

58
00:03:58,450 --> 00:04:01,610
So when we talk about AWS Lambda is the most

59
00:04:01,680 --> 00:04:05,786
common serverless service. Okay, if we want to summarize all

60
00:04:05,808 --> 00:04:09,606
of that in a nutshell, serverless is a way of running applications

61
00:04:09,638 --> 00:04:12,746
in the cloud. And of course there are servers, we just don't

62
00:04:12,778 --> 00:04:16,014
need to manage them as developers, and you pay for

63
00:04:16,052 --> 00:04:19,738
what you use. And finally, you have small units

64
00:04:19,834 --> 00:04:23,474
of compute which are generally called functions or functions as a service,

65
00:04:23,592 --> 00:04:27,342
and those are triggered by events. So there is an event driven

66
00:04:27,406 --> 00:04:30,974
model that is kind of the default way of building serverless

67
00:04:31,022 --> 00:04:34,974
applications. Now, serverless brings

68
00:04:35,022 --> 00:04:38,834
some benefits, in my opinion. The first one, and probably

69
00:04:38,872 --> 00:04:42,326
the most important one, is that generally because you don't have to think so

70
00:04:42,348 --> 00:04:45,606
much about servers, how to provision them, how to size them,

71
00:04:45,628 --> 00:04:49,654
how to keep them up to date, how to install security patches

72
00:04:49,702 --> 00:04:53,290
or whatever, you can focus a lot more on the business

73
00:04:53,360 --> 00:04:57,290
logic. And this is generally because I think still serverless today

74
00:04:57,360 --> 00:05:00,554
is not yet perfect, meaning that there is

75
00:05:00,592 --> 00:05:04,794
still a little bit of learning curve, there is still a little bit of infrastructure

76
00:05:04,842 --> 00:05:08,254
as code that you need to write, and you

77
00:05:08,292 --> 00:05:12,122
don't get to focus as much on the business logic as I wish serverless

78
00:05:12,186 --> 00:05:15,534
would let me do. But I think this is kind of the general principle

79
00:05:15,582 --> 00:05:18,994
of serverless, and it's going to be getting better and better.

80
00:05:19,112 --> 00:05:23,246
So as a kind of generic concept, we can say that the ideal

81
00:05:23,358 --> 00:05:26,934
serverless implementation will let you focus more and more

82
00:05:26,972 --> 00:05:31,110
on business logic rather than everything else around the infrastructure.

83
00:05:33,050 --> 00:05:36,546
In my opinion, serverless increase team agility.

84
00:05:36,738 --> 00:05:40,518
And by that I mean that there is a learning curve

85
00:05:40,614 --> 00:05:44,006
initially. So once you get over that learning curve,

86
00:05:44,118 --> 00:05:47,610
teams generally can be much more independent. They can ship

87
00:05:49,230 --> 00:05:53,262
with a very good frequency. You can easily change things around because

88
00:05:53,316 --> 00:05:57,038
the units of compute are smaller. So it's easier to swap one function

89
00:05:57,204 --> 00:06:00,702
and rewrite it entirely, or change the language, or try

90
00:06:00,756 --> 00:06:04,990
different things. Or maybe you want to test a new idea.

91
00:06:05,060 --> 00:06:08,814
You can just ship a new serverless project. You don't need to rely on existing

92
00:06:08,862 --> 00:06:12,354
infrastructure. So in general, the serverless approach gives you

93
00:06:12,392 --> 00:06:15,714
many, many opportunities to ship things fast and try

94
00:06:15,752 --> 00:06:18,982
new things. And if things don't work out, you can try

95
00:06:19,036 --> 00:06:22,486
new things again without having too much at stake that

96
00:06:22,508 --> 00:06:25,974
you cannot change anymore. And the other point

97
00:06:26,012 --> 00:06:29,590
is that you get automatic scalability, and this is kind of

98
00:06:29,660 --> 00:06:33,398
true, meaning that server scales quite well. You don't

99
00:06:33,414 --> 00:06:37,082
really need to think too much about if you

100
00:06:37,136 --> 00:06:40,566
have a sudden spike of usage, how do you scale

101
00:06:40,598 --> 00:06:43,450
your servers? All of that happens automatically.

102
00:06:43,610 --> 00:06:47,626
But I, but there a sorta, because there are still some boundaries

103
00:06:47,658 --> 00:06:51,486
that you need to understand. Of course, serverless, different cloud providers will

104
00:06:51,508 --> 00:06:55,026
have different limits or quotas, and it's important to

105
00:06:55,048 --> 00:06:58,594
understand how these limits or quota work because they will affect how

106
00:06:58,632 --> 00:07:02,258
much you can actually scale. So there is a quite good

107
00:07:02,344 --> 00:07:06,226
default level of scalability that works out of the box and

108
00:07:06,248 --> 00:07:09,654
you don't have to think too much about that. But if you really are

109
00:07:09,692 --> 00:07:12,806
a heavy user of the cloud, and you might have like

110
00:07:12,988 --> 00:07:15,666
thousands or hundreds, thousands of invocations,

111
00:07:15,858 --> 00:07:18,842
there will be limits there that you need to understand and you need to figure

112
00:07:18,896 --> 00:07:22,726
out how to overcome those limits. And it might not be very trivial.

113
00:07:22,838 --> 00:07:26,362
So in a way, serverless scales much

114
00:07:26,416 --> 00:07:30,246
easier than more traditional deployments. But still, it doesn't

115
00:07:30,278 --> 00:07:35,422
scale indefinitely. AWS we would like to think so

116
00:07:35,556 --> 00:07:38,766
all over. I will say that serverless is not

117
00:07:38,788 --> 00:07:42,606
a universal solution. It is a great solution and it can work well in

118
00:07:42,628 --> 00:07:46,586
many situations. But you need to appreciate what are the trade offs,

119
00:07:46,618 --> 00:07:50,322
the pros and cons, and take a judgment call and decide whether

120
00:07:50,376 --> 00:07:53,714
you want to use serverless or not. But for the sake of this

121
00:07:53,752 --> 00:07:56,866
talk, we're going to be assuming that serverless is a great use case.

122
00:07:56,968 --> 00:08:00,306
So we're going to be seeing more about how does

123
00:08:00,328 --> 00:08:02,834
it work and how we can use it, how we can use it with rust

124
00:08:02,882 --> 00:08:06,470
and what are the advantages of all of that. Now let's focus

125
00:08:06,540 --> 00:08:10,134
a little bit more on AWS lambda. AWS lambdas is the

126
00:08:10,172 --> 00:08:14,150
fuzz function as a service offering that you get in AWS,

127
00:08:14,310 --> 00:08:17,850
and it's basically a unit of compute that looks like a function.

128
00:08:17,920 --> 00:08:21,806
You write a function with some inputs and some outputs, and this function can

129
00:08:21,828 --> 00:08:25,642
be triggered automatically by AWS when specific events

130
00:08:25,706 --> 00:08:29,482
occur, and you have to define which events your lambda

131
00:08:29,546 --> 00:08:32,926
is going to be triggered by. And some examples can be an

132
00:08:32,948 --> 00:08:37,086
HTTP request. For instance, if you use an API gateway or a new file

133
00:08:37,118 --> 00:08:40,846
in S three, so somebody is creating a new file, maybe a user is uploading

134
00:08:40,878 --> 00:08:44,398
something and you want to do some processing, you can trigger a lambdas

135
00:08:44,494 --> 00:08:47,810
starting from that new file appearing in an s three packet.

136
00:08:48,710 --> 00:08:51,686
It could be a job in a queue. So you could implement a pool of

137
00:08:51,708 --> 00:08:55,426
worker by just using lambdas, and they will keep pulling jobs

138
00:08:55,458 --> 00:08:58,618
from a queue and execute on those jobs as soon as there

139
00:08:58,624 --> 00:09:02,442
are new jobs available. Or you can create

140
00:09:02,576 --> 00:09:06,218
complicated flows by using a tool like step function

141
00:09:06,304 --> 00:09:09,770
where basically you are orchestrating an entire flow and calling different

142
00:09:09,840 --> 00:09:13,718
lambdas. And every one of these lambdas can be responsible for

143
00:09:13,744 --> 00:09:17,406
a particular step of that flow. Or you can even run a

144
00:09:17,428 --> 00:09:21,070
lambda on a schedule. Maybe you want to trigger a backup, or you want to

145
00:09:21,220 --> 00:09:24,526
ping a specific web page, maybe to

146
00:09:24,548 --> 00:09:28,354
check if there are updates. You can create a schedule and you can trigger that

147
00:09:28,392 --> 00:09:32,370
lambdas, for instance, every hour, or every day, or every weekend.

148
00:09:32,790 --> 00:09:36,430
And finally, you can also invoke lambdas manually. So, for instance,

149
00:09:36,590 --> 00:09:40,050
if you want to just create a workflow and you want to trigger it manually,

150
00:09:40,130 --> 00:09:43,814
you can just create a lambdas and trigger that whenever you feel the need for

151
00:09:43,852 --> 00:09:47,446
that. Now let's look a little bit more at what is the

152
00:09:47,548 --> 00:09:51,222
cost that the cost model, the pricing

153
00:09:51,286 --> 00:09:54,966
model that you get with AWS lambda. So the cost model is generally

154
00:09:54,998 --> 00:09:58,426
a function of allocated memory multiplied by time,

155
00:09:58,608 --> 00:10:02,122
which basically means that when you

156
00:10:02,256 --> 00:10:05,610
define a lambdas, you need to allocate a certain amount of memory,

157
00:10:05,690 --> 00:10:09,294
and then when you execute a lambda, it's going to execute for a certain amount

158
00:10:09,332 --> 00:10:12,906
of time, and you are basically paying a value that is proportional

159
00:10:12,938 --> 00:10:16,242
to the memory multiplied to the amount of milliseconds that your function

160
00:10:16,296 --> 00:10:19,746
has been running. Let's actually see an example to understand this

161
00:10:19,768 --> 00:10:23,682
a little bit better. If we allocate 512

162
00:10:23,736 --> 00:10:27,080
megabytes of memory for a given function,

163
00:10:27,690 --> 00:10:31,382
I don't remember exactly which region, but one of the regions will

164
00:10:31,436 --> 00:10:32,520
have this price,

165
00:10:33,610 --> 00:10:37,778
$83 per millisecond.

166
00:10:37,874 --> 00:10:41,146
So if we execute this lambda for 15 minutes, which by the

167
00:10:41,168 --> 00:10:45,420
way, is the maximum amount of time that a lambda can be executed for,

168
00:10:45,790 --> 00:10:49,270
the final cost is going to be multiplying

169
00:10:49,350 --> 00:10:53,760
that unit per that amount of ram by

170
00:10:54,450 --> 00:10:58,046
the number of milliseconds that exist in 50 minutes and we end up

171
00:10:58,068 --> 00:11:03,582
with $7.

172
00:11:03,716 --> 00:11:06,866
And I had ruined the joke there. But yeah,

173
00:11:06,968 --> 00:11:10,722
basically you can see how running a lambda for 15

174
00:11:10,776 --> 00:11:13,060
minutes will cost you less than a cent.

175
00:11:15,750 --> 00:11:19,270
Now what about cpu? Because so far the unit there

176
00:11:19,340 --> 00:11:22,722
is only memory and time. What about cpu?

177
00:11:22,786 --> 00:11:26,694
Cpu actually is something that we cannot directly configure. It's something that

178
00:11:26,732 --> 00:11:30,342
gets automatically configured proportional to the amount of memory

179
00:11:30,406 --> 00:11:34,330
that we allocate. So there is a table here that explained that

180
00:11:34,400 --> 00:11:38,314
a little bit better. Basically, if we take an amount

181
00:11:38,352 --> 00:11:42,190
of memory that goes in between 128 and something around

182
00:11:42,260 --> 00:11:45,242
3000, you get two virtual cpus.

183
00:11:45,386 --> 00:11:48,766
And then the more memory you give, the more

184
00:11:48,868 --> 00:11:52,410
virtual cpus, you get up to six virtual cpus.

185
00:11:52,570 --> 00:11:55,874
So this is actually very important. We will talk a little bit more about

186
00:11:55,912 --> 00:11:59,634
this later because you can see how you

187
00:11:59,672 --> 00:12:02,958
don't directly control cpu, but you control memory.

188
00:12:03,054 --> 00:12:06,750
So sometimes if you want more cpu, you just need to increase memory,

189
00:12:06,910 --> 00:12:10,798
but you cannot change the two dimensions independently.

190
00:12:10,974 --> 00:12:13,734
Now I'm going to be showing you a very quick example of what it looks

191
00:12:13,772 --> 00:12:16,998
like to write a lambda in Node JS, just to understand what is the kind

192
00:12:17,004 --> 00:12:19,240
of interface that you have to deal with.

193
00:12:19,930 --> 00:12:23,466
Now, when you write a lambda, you generally call that a

194
00:12:23,488 --> 00:12:26,934
handler function, which is basically the function that gets invoked,

195
00:12:26,982 --> 00:12:30,782
the function that represents your business logic that needs to respond to an event.

196
00:12:30,916 --> 00:12:34,686
So this function is basically just a

197
00:12:34,708 --> 00:12:38,750
function, in this case in node Js, that accepts can argument called

198
00:12:38,820 --> 00:12:42,702
event, which is effectively an object that describes the event

199
00:12:42,756 --> 00:12:46,238
that triggered the execution. There is also a context object

200
00:12:46,324 --> 00:12:49,746
which gives you more information about the lambdas, how much memory is

201
00:12:49,768 --> 00:12:53,442
available, how long this lambdas has been running, and it's something that you can use

202
00:12:53,496 --> 00:12:56,994
if you need to read more about, know more about

203
00:12:57,032 --> 00:13:00,486
the context of execution. Now generally inside this

204
00:13:00,508 --> 00:13:03,174
kind of function you will do a number of different things,

205
00:13:03,292 --> 00:13:06,614
but most likely you will want to fetch some data from the event and

206
00:13:06,652 --> 00:13:09,522
use it as input to your execution.

207
00:13:09,666 --> 00:13:12,874
Then you will have some kind of business logic. And finally, when you

208
00:13:12,912 --> 00:13:16,186
complete your business logic, you will have some kind of result that you might want

209
00:13:16,208 --> 00:13:20,058
to return to the caller of this lambdas function. And if we

210
00:13:20,064 --> 00:13:24,206
want to see a more specific example, let's say that in this particular event we

211
00:13:24,228 --> 00:13:28,350
have a field called URL. So we can take this field and do

212
00:13:28,420 --> 00:13:32,346
a fetch request to this URL. So we actually do an HTTP request.

213
00:13:32,458 --> 00:13:35,982
We get the response of that HTTP request, and then the result

214
00:13:36,036 --> 00:13:39,554
of our lambda function is effectively the status code. So in a way

215
00:13:39,592 --> 00:13:43,554
we might have implemented here a very simple elt check that can be used

216
00:13:43,592 --> 00:13:46,770
to see what's the status of an HTTP endpoint.

217
00:13:47,990 --> 00:13:51,382
Now, what kind of languages are supported? I showed you an example

218
00:13:51,436 --> 00:13:54,946
of node JS, and that's one of the runtimes

219
00:13:54,978 --> 00:13:58,594
that are supported. But there are a lot more that are supported. There is Python,

220
00:13:58,642 --> 00:14:02,458
there is Java net, go Ruby, and you

221
00:14:02,464 --> 00:14:05,734
can even write your own custom ones. So if you want to write a runtime

222
00:14:05,782 --> 00:14:09,226
for Lisp or for Erlang or for elixir, you can

223
00:14:09,248 --> 00:14:12,910
definitely do that. It takes a little bit of effort, but you can do that.

224
00:14:13,060 --> 00:14:16,286
But you might have noticed here that there is

225
00:14:16,308 --> 00:14:19,994
no rust there. So what's going on with rust?

226
00:14:20,122 --> 00:14:23,502
I'm here to talk about writing

227
00:14:23,566 --> 00:14:26,130
lambdas in rust, and there is no rust runtime.

228
00:14:26,630 --> 00:14:29,646
Now of course you can get rust,

229
00:14:29,758 --> 00:14:33,566
and that happens by doing a custom runtime written

230
00:14:33,598 --> 00:14:37,574
in rust. And here there is a topic that

231
00:14:37,612 --> 00:14:41,126
we might discuss, because when you use node js or

232
00:14:41,148 --> 00:14:44,274
Python or Java, you can select specific versions

233
00:14:44,322 --> 00:14:48,134
of node js, Python or Java. But basically AWS is

234
00:14:48,172 --> 00:14:51,898
responsible for patching security and making sure that you are always using a

235
00:14:51,904 --> 00:14:55,590
runtime that is secure enough for that particular version.

236
00:14:55,750 --> 00:14:58,090
When you write your own custom runtimes,

237
00:14:59,070 --> 00:15:02,522
that's something that doesn't really happen. You are more in charge

238
00:15:02,586 --> 00:15:06,202
of the whole runtime. So there is an argument

239
00:15:06,266 --> 00:15:09,470
there where I wish that AWS will provide

240
00:15:09,540 --> 00:15:12,910
a better way for you to write Rust lambdas. But as of today,

241
00:15:12,980 --> 00:15:16,462
actually you are not alone. AWS gives you a lot of tooling,

242
00:15:16,606 --> 00:15:20,194
and actually there is a very good libraries there

243
00:15:20,232 --> 00:15:23,230
that is called AWS lambda rust runtime.

244
00:15:23,390 --> 00:15:26,710
And this is basically how you create a custom

245
00:15:26,780 --> 00:15:30,562
runtime, totally written in rust. And then in this runtime

246
00:15:30,626 --> 00:15:34,006
you can also embed your own functions. So in

247
00:15:34,028 --> 00:15:37,554
a way you are creating together a runtime

248
00:15:37,602 --> 00:15:41,318
that also contains your function code and that can have different pros

249
00:15:41,334 --> 00:15:45,242
and cons. We already discussed the con, which is basically you don't really get

250
00:15:45,296 --> 00:15:49,194
a lot of security updates. It's on you to recompile the entire runtime and

251
00:15:49,232 --> 00:15:52,886
ship a new version of that lambdas. But as a consequence

252
00:15:52,918 --> 00:15:56,714
of that you also get better performance, because in one process you have the runtime

253
00:15:56,762 --> 00:16:00,282
and you have your lambda code, so there is less message passing.

254
00:16:00,426 --> 00:16:04,094
And also rust is the team

255
00:16:04,132 --> 00:16:07,854
that is building this rust runtime is also building a lot of tooling,

256
00:16:07,982 --> 00:16:12,290
like middlewares or the ability to run generic services AWS

257
00:16:12,360 --> 00:16:16,082
lambdas, you can even embed web frameworks into your own lambdas.

258
00:16:16,226 --> 00:16:19,494
So just because you have more direct control,

259
00:16:19,692 --> 00:16:23,480
and your code and the runtime are more tied together.

260
00:16:23,850 --> 00:16:27,474
You can do a lot more manipulation of the environment

261
00:16:27,602 --> 00:16:30,090
as opposed to what you can do with other languages.

262
00:16:30,910 --> 00:16:34,742
So let's see how using this AWS

263
00:16:34,806 --> 00:16:38,426
lambda restaurant time looks like. So you have

264
00:16:38,448 --> 00:16:41,974
to write song code that looks like this. So this is kind of an lo

265
00:16:42,032 --> 00:16:45,262
word, lambdas, and there are actually two main

266
00:16:45,316 --> 00:16:48,878
parts here. The first part is this function here,

267
00:16:49,044 --> 00:16:52,586
where this basically is our generic lambda

268
00:16:52,618 --> 00:16:55,986
Android. We get an event, we can do something with this event,

269
00:16:56,168 --> 00:16:58,930
and eventually we return a response.

270
00:16:59,750 --> 00:17:03,426
Then there is another part here, which is the main function.

271
00:17:03,528 --> 00:17:06,722
And inside the main function we have this lambda runtime

272
00:17:06,786 --> 00:17:10,054
run. And this is basically the part that is using the

273
00:17:10,092 --> 00:17:14,530
lambda runtime library that we saw before from the GitHub repository

274
00:17:14,690 --> 00:17:18,166
to initialize a lambdas runtime that

275
00:17:18,188 --> 00:17:21,434
is able to call your specific lambdas function

276
00:17:21,552 --> 00:17:24,746
code. So you can see here today how in

277
00:17:24,768 --> 00:17:28,614
the same binary, at the end of the day, we will have the runtime,

278
00:17:28,662 --> 00:17:31,674
but also the lambda code. And of course,

279
00:17:31,712 --> 00:17:35,374
this comes with a little bit of extra boilerplate, because we need to make sure

280
00:17:35,412 --> 00:17:39,534
we initialize with this main function,

281
00:17:39,732 --> 00:17:43,778
the code that is able to run the runtime and use our lambda function

282
00:17:43,864 --> 00:17:46,930
as the only function available in that runtime.

283
00:17:49,670 --> 00:17:52,430
Okay, now the next question is, why rust,

284
00:17:52,510 --> 00:17:56,254
though? Why is rust so interesting in the context

285
00:17:56,302 --> 00:18:00,470
of AWS Lambda and serverless in a more general sense?

286
00:18:00,620 --> 00:18:03,894
So let's talk a little bit more about rust as

287
00:18:03,932 --> 00:18:07,826
a language. It is a relatively new language. The first version

288
00:18:07,858 --> 00:18:11,338
was released in 2015. It is a

289
00:18:11,344 --> 00:18:15,078
compiled language, so that kind of puts

290
00:18:15,094 --> 00:18:18,266
it in the same bucket as go or C or C Plus plus,

291
00:18:18,368 --> 00:18:21,546
where you can not just interpret scripts, but you actually have

292
00:18:21,568 --> 00:18:24,400
to compile your code before you can execute it.

293
00:18:25,410 --> 00:18:29,306
It is a language that is focused on performance and memory safety.

294
00:18:29,498 --> 00:18:33,054
These are the two main qualities that people will refer to when they think

295
00:18:33,092 --> 00:18:36,706
about rust. But it's also a language that interesting

296
00:18:36,808 --> 00:18:40,354
enough, and this is a little bit as opposed to C

297
00:18:40,392 --> 00:18:44,322
or C Plus. Plus is trying to give very good high

298
00:18:44,376 --> 00:18:48,126
level constructs. For instance, you have things like iterators that are

299
00:18:48,168 --> 00:18:51,990
built in, in the language, and generally you will have a lot of

300
00:18:52,060 --> 00:18:55,846
high level functions, while at the same time being a compiled language and

301
00:18:55,868 --> 00:18:59,746
a system programming language. When you want to do very low level stuff,

302
00:18:59,868 --> 00:19:03,482
you can kind of drill down and get to the level where you can do

303
00:19:03,536 --> 00:19:04,940
very low level things.

304
00:19:06,350 --> 00:19:10,106
So in a way, it is a great general purpose language because

305
00:19:10,128 --> 00:19:13,882
you can write high level software. For instance, a web server

306
00:19:13,946 --> 00:19:17,614
but you can also write operative systems with it. So you get a very good

307
00:19:17,652 --> 00:19:21,086
degree of possibilities by just adopting rust as

308
00:19:21,108 --> 00:19:24,254
a programming language. And another thing that I really like

309
00:19:24,372 --> 00:19:28,418
is that there is a very modern tool chain. For instance, we'll be talking more

310
00:19:28,504 --> 00:19:32,414
about cargo, which is a tool that allows you to install dependencies,

311
00:19:32,542 --> 00:19:36,114
and this is built in in the language, which is something that doesn't happen so

312
00:19:36,152 --> 00:19:40,310
often with lower level programming languages or system programming languages.

313
00:19:41,290 --> 00:19:44,726
And in general, there is a great ecosystem. I was surprised for

314
00:19:44,748 --> 00:19:48,086
a language that is still relatively new to try to

315
00:19:48,188 --> 00:19:51,658
code a bunch of different applications. And every time I

316
00:19:51,664 --> 00:19:55,542
needed a library, I was able to find even more than one library.

317
00:19:55,606 --> 00:19:58,826
And every one of those libraries generally has very good

318
00:19:58,848 --> 00:20:02,294
documentation, good examples, good testing, and is generally

319
00:20:02,342 --> 00:20:05,726
well maintained. So I have to say that I'm quite impressed by

320
00:20:05,748 --> 00:20:09,406
the level of maturity of the tool can and the ecosystem as a

321
00:20:09,428 --> 00:20:13,554
whole by just considering that the language is still relatively new

322
00:20:13,672 --> 00:20:17,506
and not so popularly adopted by

323
00:20:17,608 --> 00:20:20,914
many, many companies. And the final point, last but

324
00:20:20,952 --> 00:20:24,706
not least, rust as can. Awesome mascot, and I'm glad to

325
00:20:24,728 --> 00:20:26,440
have it here as well.

326
00:20:29,930 --> 00:20:32,930
Okay, moving on, let's talk about cargo.

327
00:20:33,010 --> 00:20:36,274
I mentioned already that cargo is a built in package

328
00:20:36,322 --> 00:20:39,838
manager. So in a way it's like NPM, but for Rust,

329
00:20:39,954 --> 00:20:43,302
you can use it to, say cargo, add a specific library,

330
00:20:43,366 --> 00:20:46,938
and it's going to make sure to download and make the library available

331
00:20:47,104 --> 00:20:50,426
into your project. But it also does a

332
00:20:50,448 --> 00:20:53,854
lot more than that, because it has a lot of subcommands that

333
00:20:53,892 --> 00:20:57,310
can be used for scaffolding a new project, or a library for running

334
00:20:57,380 --> 00:21:01,182
tests, for running benchmarks. And it is also something

335
00:21:01,236 --> 00:21:04,486
that can be extended with third party commands. For instance,

336
00:21:04,538 --> 00:21:08,286
there are third party commands that allows you to do snapshot testing,

337
00:21:08,398 --> 00:21:12,210
to do fuzzy testing, to do all sorts of different

338
00:21:12,280 --> 00:21:15,650
things that you might need for specific projects.

339
00:21:17,530 --> 00:21:21,254
Now, the next point is, why do we care about rust in the context of

340
00:21:21,292 --> 00:21:24,950
lambda? We already saw that it's not as easy

341
00:21:25,020 --> 00:21:28,462
as with other languages to do lambdas in rust.

342
00:21:28,546 --> 00:21:31,994
So why should we go through that trouble? Is it really worth

343
00:21:32,032 --> 00:21:35,820
it? What are the benefits? And the main benefit is that

344
00:21:36,590 --> 00:21:40,322
if we combine the performance characteristics of rust

345
00:21:40,406 --> 00:21:43,726
with also the ability of being a language that allows you to

346
00:21:43,748 --> 00:21:47,246
be very efficient memory wise, those are pretty

347
00:21:47,268 --> 00:21:50,782
much the two dimensions that basically on

348
00:21:50,836 --> 00:21:55,062
which we calculate cost for execution of lambda functions.

349
00:21:55,146 --> 00:21:58,820
So if we can be very efficient with performance, and we can also

350
00:22:00,550 --> 00:22:04,306
be very efficient in terms of memory, we can probably save a lot of

351
00:22:04,328 --> 00:22:08,114
money, as opposed to running the same kind of application in lambda

352
00:22:08,162 --> 00:22:12,434
with different languages that might not be AWS performance and might consume

353
00:22:12,482 --> 00:22:15,782
a lot more memory to run. The other

354
00:22:15,836 --> 00:22:19,586
thing is that it is a language that focuses a lot on multi

355
00:22:19,618 --> 00:22:23,050
thread safety, so we could be able to write very good

356
00:22:23,120 --> 00:22:27,014
multi threaded versions of the code that we have in a lambda

357
00:22:27,062 --> 00:22:30,894
written in another language, which is something that can allow us to be even more

358
00:22:30,932 --> 00:22:34,240
performant and therefore save even more cost.

359
00:22:35,330 --> 00:22:38,622
And finally, and this is more of a personal take,

360
00:22:38,756 --> 00:22:41,998
there are no null types and there is a great

361
00:22:42,084 --> 00:22:45,474
system to deal with errors, which I think naturally once

362
00:22:45,512 --> 00:22:49,810
you start to learn how to use rust as a language and appreciate the concepts

363
00:22:50,150 --> 00:22:54,818
and the libraries that rust gives you to deal with the

364
00:22:54,824 --> 00:22:58,710
eventuality that you might have a value or not have it, or the

365
00:22:58,780 --> 00:23:02,630
way of dealing with errors, I think you will end up writing code

366
00:23:02,700 --> 00:23:05,826
that is generally more well structured, well tested,

367
00:23:05,858 --> 00:23:09,446
and it covers for more edge cases. So you might end up with fewer

368
00:23:09,478 --> 00:23:12,250
bugs than what you would have with other languages.

369
00:23:12,830 --> 00:23:16,300
And one last point is that

370
00:23:16,910 --> 00:23:21,034
I have seen, and this is something that I don't have strong evidence,

371
00:23:21,082 --> 00:23:24,346
but just by doing some measurements with my own lambdas,

372
00:23:24,458 --> 00:23:28,590
that you generally get very good cold started

373
00:23:28,660 --> 00:23:32,462
times and your lambdas will run very quickly. So again,

374
00:23:32,516 --> 00:23:36,486
this is just another opinion point that reinforces the fact that with rust

375
00:23:36,538 --> 00:23:40,082
you might be saving a lot of money, especially if you have lambdas that gets

376
00:23:40,136 --> 00:23:43,442
executed thousands of times or hundreds of thousands of times

377
00:23:43,496 --> 00:23:47,078
per day. It might be really worth considering to rewrite that particular

378
00:23:47,164 --> 00:23:50,566
lambda in Rust. Now let's start to look

379
00:23:50,588 --> 00:23:54,294
at the tooling. We have this tool called cargo lambdas, which is

380
00:23:54,332 --> 00:23:57,686
relatively new and it's built by AWS or somebody at

381
00:23:57,708 --> 00:24:01,834
AWS. And basically what it does is a third party command for

382
00:24:01,872 --> 00:24:05,066
cargo. So extends the set of tools that are available by

383
00:24:05,088 --> 00:24:08,662
default in cargo, just to make it easier for you to auto

384
00:24:08,726 --> 00:24:11,150
test and deploy lambdas in Rust.

385
00:24:11,970 --> 00:24:15,754
And one of the most interesting features is that it can cross compile

386
00:24:15,802 --> 00:24:20,746
for Linux. IRM, which is lambdas

387
00:24:20,778 --> 00:24:24,190
will run in Linux, but you have a choice between x 86 or

388
00:24:24,260 --> 00:24:27,854
IRM, and generally going for IRM it is cheaper

389
00:24:27,902 --> 00:24:31,394
and it might be even faster. So again, another reason to pick that

390
00:24:31,432 --> 00:24:34,898
one if you are caring about cost. But it is always a

391
00:24:34,904 --> 00:24:38,262
little bit annoying to compile for Linux IRM if you work with

392
00:24:38,316 --> 00:24:41,826
other systems or with other processors, and with cargo

393
00:24:41,858 --> 00:24:45,282
lambdas, you get this built in cross compilation.

394
00:24:45,346 --> 00:24:49,218
So you can just use Windows, Mac or Linux in whatever

395
00:24:49,404 --> 00:24:52,650
architecture, and you should be able to compile without problems.

396
00:24:52,720 --> 00:24:55,994
For Linux IRM and so far I've been using it

397
00:24:56,032 --> 00:24:59,430
on Mac and I didn't have any problem of compilation,

398
00:24:59,510 --> 00:25:02,250
so definitely works well on Mac.

399
00:25:03,310 --> 00:25:06,702
Now, what are the main commands that cargo lambda gives you?

400
00:25:06,756 --> 00:25:09,918
It gives you cargo lambda new, which is something you can use to scaffold a

401
00:25:09,924 --> 00:25:13,150
new project. Then it gives you cargo lambdas watch,

402
00:25:13,300 --> 00:25:17,250
which is a command that you can run to keep watching

403
00:25:17,320 --> 00:25:21,570
your code for new changes and keep a development environment hot.

404
00:25:21,640 --> 00:25:25,106
So basically creates kind of a lambda emulator which

405
00:25:25,128 --> 00:25:28,754
allows you to test your lambda, but that emulator is automatically restarted

406
00:25:28,802 --> 00:25:32,994
every time you do a code change. So you don't need to worry about stopping,

407
00:25:33,122 --> 00:25:36,934
recompiling and rerunning the lambda every

408
00:25:36,972 --> 00:25:40,706
time you do a change. And there is another command called

409
00:25:40,748 --> 00:25:44,106
cargo lambda invoke which basically allows you to simulate an

410
00:25:44,128 --> 00:25:47,354
event coming into the lambda and triggering it

411
00:25:47,392 --> 00:25:50,714
so you can see what is the effect of a specific event and test your

412
00:25:50,752 --> 00:25:54,222
code that way. And finally you have cargo lambda build

413
00:25:54,276 --> 00:25:58,074
to build the lambda for production and cargo lambda deploy to release

414
00:25:58,122 --> 00:26:01,486
it to AWS. Now I want

415
00:26:01,508 --> 00:26:04,906
to show you a very quick demo of cargo lambda.

416
00:26:05,018 --> 00:26:08,402
So I have created the environment, so what we can do is

417
00:26:08,456 --> 00:26:12,338
cargolanda new conf

418
00:26:12,424 --> 00:26:15,778
42. I actually spelled conf

419
00:26:15,864 --> 00:26:19,174
43, but I think we'll go with that. So is

420
00:26:19,212 --> 00:26:22,390
this function an HTTP function I'm going to go for no, now,

421
00:26:22,460 --> 00:26:26,722
because I want to showcase you that you can pick different kind of events

422
00:26:26,866 --> 00:26:30,722
and the runtime is actually giving

423
00:26:30,796 --> 00:26:34,534
you types for all the different kind of events that you have in AWS.

424
00:26:34,662 --> 00:26:38,266
So this tool is basically able to scaffold your code

425
00:26:38,368 --> 00:26:41,866
with the event type that you need already selected for you.

426
00:26:41,968 --> 00:26:46,122
So for the sake of this example, I want to go with sqs

427
00:26:46,266 --> 00:26:49,326
just because I think this is a common enough use case, and one of the

428
00:26:49,348 --> 00:26:53,026
use cases where you might benefit the most by writing your lambda in

429
00:26:53,048 --> 00:26:56,690
rust. And it did something

430
00:26:56,760 --> 00:27:00,594
we don't really know yet. So we just know that here a new folder was

431
00:27:00,632 --> 00:27:04,740
created called 43. Sorry typo, but whatever

432
00:27:06,550 --> 00:27:10,246
and what we do, we can just open visual studio code and

433
00:27:10,268 --> 00:27:13,686
see what kind of code we have inside there. So let

434
00:27:13,708 --> 00:27:17,414
me make this a little bit bigger. So basically what

435
00:27:17,452 --> 00:27:21,286
it did, it created a cargo terminal, which is like the packet JSon

436
00:27:21,318 --> 00:27:24,682
of Rust. And this already includes all the

437
00:27:24,736 --> 00:27:28,390
dependencies that we might need to write a lambdas. So it contains

438
00:27:28,470 --> 00:27:32,218
lambda events, which is a library that gives us all the types of all

439
00:27:32,224 --> 00:27:35,966
the different kind of events. It contains the lambdas runtime and

440
00:27:35,988 --> 00:27:39,114
then it contains Tokyo, which is something needed for the lambdas runtime.

441
00:27:39,162 --> 00:27:43,210
This is just an async runtime for rust and some tracing utilities

442
00:27:43,290 --> 00:27:46,786
which are very convenient for logging and tracing. Now if

443
00:27:46,808 --> 00:27:50,146
we look at the code that was created for us, you can see that we

444
00:27:50,168 --> 00:27:53,646
have all the boilerplate already done, and this boilerplate

445
00:27:53,678 --> 00:27:58,146
is actually doing some initialization of the tracing stack

446
00:27:58,178 --> 00:28:01,750
for us. So this is basically initializing a logger that we can use,

447
00:28:01,900 --> 00:28:06,086
and then it's creating our skeleton for the lambda function

448
00:28:06,188 --> 00:28:09,578
itself. So the lambdas handler with the type of event

449
00:28:09,664 --> 00:28:13,370
that we selected. So let's write some simple

450
00:28:13,440 --> 00:28:17,434
code just to make something useful. Let's remember that

451
00:28:17,472 --> 00:28:20,970
this is a lambda that is going to be invoked when

452
00:28:21,040 --> 00:28:23,994
SQS events happen. So you generally have a queue,

453
00:28:24,042 --> 00:28:26,986
you're going to be submitting a bunch of jobs to this queue,

454
00:28:27,098 --> 00:28:31,338
and then you probably have an integration where new jobs appearing

455
00:28:31,354 --> 00:28:34,994
in this queue will trigger this lambda, which is then responsible for

456
00:28:35,032 --> 00:28:38,386
processing those kind of jobs. So the

457
00:28:38,408 --> 00:28:42,846
first thing that you generally do is you want to separate

458
00:28:42,878 --> 00:28:46,626
the event from the context. And basically the way

459
00:28:46,648 --> 00:28:50,210
you do that is by doing calling this event into parts.

460
00:28:50,290 --> 00:28:53,974
And you can see here that now we have direct access to the SQS event

461
00:28:54,092 --> 00:28:57,282
and the context. We are not going to need the context.

462
00:28:57,346 --> 00:29:00,486
So I'm just going to use an underscore here to avoid warnings.

463
00:29:00,598 --> 00:29:04,342
And now what we might want to do is in sqs

464
00:29:04,406 --> 00:29:07,658
you might be having multiple records per event.

465
00:29:07,824 --> 00:29:11,114
So what we can do is basically say for

466
00:29:11,312 --> 00:29:15,626
record in records, and I think I like what copilot

467
00:29:15,658 --> 00:29:19,374
is giving me, so I'm going to go with this. So for every record in

468
00:29:19,492 --> 00:29:23,074
the list of records that are available in this event, we want to write

469
00:29:23,112 --> 00:29:28,030
some tracing information. And basically tracing

470
00:29:28,110 --> 00:29:32,686
what allows us to do is allows

471
00:29:32,718 --> 00:29:36,374
us to specify a bunch of values that

472
00:29:36,412 --> 00:29:39,746
will be logged as structured logs. So here we can define

473
00:29:39,778 --> 00:29:43,270
the new event is new or something like job

474
00:29:43,420 --> 00:29:49,050
started maybe. And we can say record

475
00:29:49,200 --> 00:29:52,906
message id and we don't need to say

476
00:29:53,008 --> 00:29:56,460
a string, I believe. And then

477
00:29:57,950 --> 00:30:02,206
is it message id? Actually I

478
00:30:02,228 --> 00:30:06,014
think we have message id. And then yeah,

479
00:30:06,052 --> 00:30:09,946
we can read also the body. So we can say body is equal

480
00:30:09,978 --> 00:30:11,680
to record body.

481
00:30:13,030 --> 00:30:16,546
Now this is an

482
00:30:16,568 --> 00:30:20,226
option string. So we might want to do unwrap just to see the

483
00:30:20,248 --> 00:30:21,220
clean value.

484
00:30:26,710 --> 00:30:29,958
And this basically means that this is one of

485
00:30:29,964 --> 00:30:33,670
the utilities that I mentioned before. So because the message id

486
00:30:33,740 --> 00:30:35,640
might be there or might not be there,

487
00:30:36,810 --> 00:30:40,690
this cannot be null basically. So we are forced to deal with this

488
00:30:40,780 --> 00:30:44,874
option, which basically means this value can exist or not.

489
00:30:44,992 --> 00:30:48,506
And rust is forcing us to deal with the fact that we need

490
00:30:48,528 --> 00:30:51,690
to tell rust what to do when the message is not there.

491
00:30:51,760 --> 00:30:55,454
So what a wrap or default does is basically saying if

492
00:30:55,492 --> 00:30:59,054
there is a value, take it as job id. Otherwise use

493
00:30:59,092 --> 00:31:02,990
the default value for strings, which is just going to be can empty string.

494
00:31:03,410 --> 00:31:07,474
So what we are doing here, we're just printing a log line for

495
00:31:07,512 --> 00:31:11,362
every single job. And this log line contains the job

496
00:31:11,416 --> 00:31:15,170
id and the content of that job. So the body of that message

497
00:31:15,240 --> 00:31:18,450
in sqs. Now we can also return something

498
00:31:18,520 --> 00:31:22,086
here. This is just the unit type, which means we don't really have nothing to

499
00:31:22,108 --> 00:31:25,830
return. It's just an empty table. But let's just say that we want to return

500
00:31:25,900 --> 00:31:29,482
a string for now. And what we can return

501
00:31:29,616 --> 00:31:34,620
is we could say let message count

502
00:31:34,990 --> 00:31:38,694
equal event records length.

503
00:31:38,822 --> 00:31:42,286
And here what we can do is say this is

504
00:31:42,308 --> 00:31:46,494
the number of messages processed and we can just

505
00:31:46,692 --> 00:31:50,286
return this. Now this function is probably good enough for

506
00:31:50,308 --> 00:31:52,698
us to see if something works.

507
00:31:52,884 --> 00:31:56,674
So how do we test it? We can test it locally and

508
00:31:56,712 --> 00:32:00,100
we can say cargo lambda watch.

509
00:32:02,070 --> 00:32:06,306
And this is the one that starts the development server.

510
00:32:06,418 --> 00:32:10,786
So what we can do now is to say cargo

511
00:32:10,978 --> 00:32:15,000
lambdas invoke, but we will need some

512
00:32:15,370 --> 00:32:18,886
message. So the first thing that we do is we just invoke it

513
00:32:18,908 --> 00:32:22,458
with an empty message. And this is probably going to fail because we

514
00:32:22,464 --> 00:32:25,754
are going to be trying to cast this particular message to

515
00:32:25,792 --> 00:32:28,940
an SQS type of event. So let's see what happens.

516
00:32:29,550 --> 00:32:33,326
And actually it didn't fail. Actually no.

517
00:32:33,348 --> 00:32:36,400
It is compiling first. Let's see if it fails or not.

518
00:32:45,670 --> 00:32:49,842
It's okay. It did fail because it wasn't able to deserialize

519
00:32:49,906 --> 00:32:54,002
the message into the specific type that we were expecting.

520
00:32:54,146 --> 00:32:57,242
So how do we do this?

521
00:32:57,296 --> 00:33:00,906
I have prepared here a piece of JSON that represents an

522
00:33:00,928 --> 00:33:04,678
SQS event. So what we can do is PB

523
00:33:04,774 --> 00:33:07,782
paste into event JSON.

524
00:33:07,926 --> 00:33:11,630
So at this point what we can do is

525
00:33:11,700 --> 00:33:15,630
cargo lambda invoked data file

526
00:33:16,530 --> 00:33:20,510
and here we can specify event JSOn.

527
00:33:23,750 --> 00:33:28,114
What did I do wrong? Okay, I probably

528
00:33:28,232 --> 00:33:32,274
have very bad

529
00:33:32,392 --> 00:33:42,782
json there, so let me do it.

530
00:33:42,856 --> 00:33:45,960
Let's have a quick look at this event here.

531
00:33:46,570 --> 00:33:50,282
So we have an event Json. Oh yeah, I have

532
00:33:50,336 --> 00:33:53,834
bogus quotes because I'm copy pasting this

533
00:33:53,872 --> 00:33:57,180
from the web and it didn't like it.

534
00:33:59,070 --> 00:34:02,894
Okay, is this a good Json now? Looks like it is.

535
00:34:03,012 --> 00:34:07,578
So let's try again. And we want to run cargo

536
00:34:07,594 --> 00:34:10,510
lambda invoke data file event JSon.

537
00:34:11,250 --> 00:34:14,366
Okay, it's saying two message processed. So you can see

538
00:34:14,388 --> 00:34:17,646
here, this is the response that we received from the lambdas.

539
00:34:17,758 --> 00:34:21,314
But if we look at the emulator here, we can see that the lambda did

540
00:34:21,352 --> 00:34:24,734
log indeed two lines. Two event name,

541
00:34:24,792 --> 00:34:28,678
job started, event name, job started, job id.

542
00:34:28,844 --> 00:34:32,214
And then the body is test message one and

543
00:34:32,252 --> 00:34:35,542
test message two. So this kind of works.

544
00:34:35,596 --> 00:34:39,642
And you can see how, interestingly enough, the tracing utility also

545
00:34:39,696 --> 00:34:43,114
gives us a request id. It also integrates with x

546
00:34:43,152 --> 00:34:47,302
ray and gives us tracing. So this is actually a really powerful

547
00:34:47,366 --> 00:34:51,274
default there, which is something that you might want to have for production

548
00:34:51,322 --> 00:34:55,562
applications. Now the next thing that we want to do is cargo

549
00:34:55,706 --> 00:34:58,510
lambda build release.

550
00:34:58,930 --> 00:35:03,230
This is going to build a release version. So a more optimized version

551
00:35:03,570 --> 00:35:07,362
and a more stripped down version of our lambdas code

552
00:35:07,496 --> 00:35:09,810
which is going to be ready for deployment.

553
00:35:12,790 --> 00:35:16,754
So once this finishes to build, what we can do is cargo

554
00:35:16,802 --> 00:35:19,640
lambda deploy, I believe.

555
00:35:20,730 --> 00:35:25,174
I guess we're going to figure it out and

556
00:35:25,212 --> 00:35:29,386
then we are going to see that we

557
00:35:29,408 --> 00:35:32,220
can run the same function on AWS itself.

558
00:35:33,790 --> 00:35:36,090
So cargo lambdas,

559
00:35:37,310 --> 00:35:41,194
let's see, help we have cargo lambdas

560
00:35:41,242 --> 00:35:42,110
deploy.

561
00:35:47,010 --> 00:35:50,334
Now what this is doing is actually zipping our

562
00:35:50,372 --> 00:35:54,302
lambda code and calling the specific APIs

563
00:35:54,366 --> 00:35:58,020
in AWS that will make this lambda available in my account.

564
00:35:59,830 --> 00:36:03,474
And it's also doing a bunch of stuff because lambda will also

565
00:36:03,592 --> 00:36:06,706
need role, will lead log groups. So it's doing all of these

566
00:36:06,728 --> 00:36:10,534
things for us. So this is the arm, so the unique identifier of our

567
00:36:10,572 --> 00:36:13,590
new lambda. So if we go to my lambda account,

568
00:36:13,740 --> 00:36:16,658
which hopefully you can read if we refresh,

569
00:36:16,834 --> 00:36:20,710
we should see that we have a new function called comfort tree.

570
00:36:21,390 --> 00:36:25,098
While this loads, I'm going to copy that json here

571
00:36:25,184 --> 00:36:28,746
and we can invoke this lambda manually with this particular

572
00:36:28,848 --> 00:36:33,418
json. So if we go here in test, we can input

573
00:36:33,594 --> 00:36:38,734
this example JSon. And if we test the

574
00:36:38,772 --> 00:36:41,998
lambda was invoked in my account and we should see the same result.

575
00:36:42,084 --> 00:36:45,166
Two message processes is the output of the lambdas.

576
00:36:45,278 --> 00:36:48,626
While here we can see all the logs and we can see

577
00:36:48,648 --> 00:36:52,514
that we have the two logs in a very similar way as

578
00:36:52,552 --> 00:36:54,530
what we tested locally.

579
00:36:56,090 --> 00:37:00,694
Now back to the slides we

580
00:37:00,732 --> 00:37:04,786
saw so far that we were able to create a lambdas and ship

581
00:37:04,818 --> 00:37:08,566
it. So what's next? You probably just don't want

582
00:37:08,588 --> 00:37:11,914
to deal only with lambdas. When you're creating a project you will have a lot

583
00:37:11,952 --> 00:37:15,370
more infrastructure. So there is a specific tool that you can use

584
00:37:15,440 --> 00:37:19,658
that is called Sam serverless application model that can help you there.

585
00:37:19,824 --> 00:37:23,182
And sum is basically a yaml based infrastructure as code tool

586
00:37:23,236 --> 00:37:26,686
that allows you to build serverless applications in

587
00:37:26,708 --> 00:37:30,046
an easier way. And it's great again when you

588
00:37:30,068 --> 00:37:33,854
have to go beyond just one lambda, just to give you some

589
00:37:33,892 --> 00:37:37,646
examples. For instance, you need to provision multiple lambdas, not just one lambdas

590
00:37:37,678 --> 00:37:41,614
with it, but you might have a complex project that requires multiple lambdas.

591
00:37:41,742 --> 00:37:45,586
And for instance, you might also need to provision other pieces of infrastructure

592
00:37:45,618 --> 00:37:49,330
like s, three buckets, permissions, dynamodB tables

593
00:37:49,410 --> 00:37:52,630
and so on. And sum basically

594
00:37:52,700 --> 00:37:56,454
supports everything that is natively supported by cloudformation, which is

595
00:37:56,492 --> 00:37:59,846
the default tool in AWS to do infrastructure as code.

596
00:37:59,948 --> 00:38:03,226
But it gives you a slightly simpler abstraction, so it gives you

597
00:38:03,248 --> 00:38:06,538
slightly more concise code. And there are a

598
00:38:06,544 --> 00:38:10,246
lot of shortcuts that you can use, and some will take care of generating

599
00:38:10,358 --> 00:38:13,040
the equivalent cloud formation code.

600
00:38:14,130 --> 00:38:17,194
So the deployments actually happen through cloudformation.

601
00:38:17,242 --> 00:38:21,294
So some create cloudformation code and then that cloudformation code

602
00:38:21,332 --> 00:38:25,262
is deployed. So you get all the same benefits that you get with cloudformation.

603
00:38:25,326 --> 00:38:28,340
For instance, rollbacks, change sets and so on.

604
00:38:29,190 --> 00:38:32,274
And if you want to see how a template looks like,

605
00:38:32,392 --> 00:38:35,646
it's pretty much like a cloudformation template with just a few

606
00:38:35,688 --> 00:38:39,074
differences. For instance, you have that transform AWS

607
00:38:39,122 --> 00:38:43,014
serverless, which is basically telling AWS that when this

608
00:38:43,052 --> 00:38:46,918
template is trying to be deployed, it needs to be transformed to basically

609
00:38:47,004 --> 00:38:50,774
apply all the shortcuts that we have with some and convert it to

610
00:38:50,812 --> 00:38:54,362
a complete cloud formation template. And then here

611
00:38:54,416 --> 00:38:57,594
what we see is that we have defined a function and we also

612
00:38:57,632 --> 00:39:01,754
define an s strip bucket, and then we are referencing that strip bucket

613
00:39:01,882 --> 00:39:05,134
to trigger that lambda function. Every time that there is a new

614
00:39:05,172 --> 00:39:09,562
file on that bucket, and in this case sam

615
00:39:09,626 --> 00:39:13,290
or cloudformation, they are going to understand that there is a dependency

616
00:39:13,370 --> 00:39:16,450
between that bucket and the lambda trigger event.

617
00:39:16,600 --> 00:39:20,398
So the bucket is going to be created before the lambda

618
00:39:20,414 --> 00:39:24,226
trigger event is created, while the lambdas itself and the bucket can

619
00:39:24,248 --> 00:39:27,998
be created in parallel. So that's the beauty of infrastructure

620
00:39:28,014 --> 00:39:31,366
AWS code, that you don't have to think exactly about the order of things or

621
00:39:31,388 --> 00:39:34,578
what are the dependencies. You can just express those dependencies

622
00:39:34,674 --> 00:39:37,974
in a declarative way, and then the tool is going to take care of

623
00:39:38,012 --> 00:39:41,322
deploying the new infrastructure or future changes

624
00:39:41,376 --> 00:39:44,714
that you might be doing to this infrastructure, and just make sure you

625
00:39:44,752 --> 00:39:48,810
end up with the state that you are describing in your template.

626
00:39:50,670 --> 00:39:54,342
Okay, then why do we like AWS

627
00:39:54,406 --> 00:39:57,850
sum? So AWS sum is another tool by AWS, and no surprises.

628
00:39:57,930 --> 00:40:01,434
It works with cargo lambda. It is still experimental.

629
00:40:01,482 --> 00:40:05,466
Cargo lambda is still very new. The rust runtime is still relatively

630
00:40:05,498 --> 00:40:08,962
new. Sam has been around for a few years, but is always

631
00:40:09,016 --> 00:40:12,226
adding more and more features. And it only makes sense that Sam is

632
00:40:12,248 --> 00:40:15,986
trying to support the rust ecosystem. So as of today,

633
00:40:16,088 --> 00:40:19,782
if you use the latest version of Sam and you enable the

634
00:40:19,836 --> 00:40:23,618
experimental features, you are able to use sum with cargo lambda.

635
00:40:23,714 --> 00:40:27,094
And the advantage is that you can use infrastructure as code with the full

636
00:40:27,132 --> 00:40:30,422
power of sum, but you can build and run your rust

637
00:40:30,486 --> 00:40:34,730
lambdas with cargo lambdas, which can give you all that nice emulator,

638
00:40:35,310 --> 00:40:39,126
and it can also build and cross compile lambdas

639
00:40:39,238 --> 00:40:41,370
for Linux and IRM.

640
00:40:42,510 --> 00:40:46,094
Now another note is this is something I haven't tried yet, but it looks

641
00:40:46,132 --> 00:40:49,278
like cargo lambda also works with CDK. So if

642
00:40:49,284 --> 00:40:52,654
you prefer to use CDK to define infrastructure as code, you should be able

643
00:40:52,692 --> 00:40:56,462
to use CDK together with cargo lambda. Check out that repository

644
00:40:56,526 --> 00:40:59,566
if you want to try it out. And if you're

645
00:40:59,598 --> 00:41:02,914
curious to see a more complete example that involves Sam and

646
00:41:02,952 --> 00:41:06,100
cargo lambda, I recently built this particular application,

647
00:41:06,630 --> 00:41:10,150
and this application basically allows me to see

648
00:41:10,220 --> 00:41:14,386
if there are earthquakes close to my family. I am originally from Sicily,

649
00:41:14,498 --> 00:41:18,074
close to the Mount Aetna, and it's an area where there are

650
00:41:18,192 --> 00:41:22,282
often earthquakes and they might be even violent ones.

651
00:41:22,416 --> 00:41:26,300
So with this tool I can basically be notified as soon as

652
00:41:26,750 --> 00:41:30,634
a decent enough earthquake happens, and I can immediately reach

653
00:41:30,672 --> 00:41:33,854
out to my family to see if they are okay. So the way that I

654
00:41:33,892 --> 00:41:37,274
built this tool is basically a lambda that is triggered

655
00:41:37,322 --> 00:41:40,414
every hour. This lambda will call a specific API that

656
00:41:40,452 --> 00:41:43,634
gives me information about earthquakes in Italy and in other

657
00:41:43,672 --> 00:41:46,834
areas around Italy. And then this

658
00:41:46,872 --> 00:41:50,434
lambdas has a number of filters that basically will

659
00:41:50,472 --> 00:41:54,034
make sure that if there are recent earthquakes, they are

660
00:41:54,072 --> 00:41:57,974
happening close enough to the area of interest that I care

661
00:41:58,012 --> 00:42:02,002
about. And the magnitude of that earthquake goes above

662
00:42:02,066 --> 00:42:05,206
a certain threshold. If all of that happens, there is an

663
00:42:05,228 --> 00:42:08,426
event that is created on Eventbridge, and there is a rule in

664
00:42:08,448 --> 00:42:12,646
eventbridge that logs this particular event, but also sends

665
00:42:12,678 --> 00:42:17,014
the message to an SNS topic. So I can use an email subscription

666
00:42:17,062 --> 00:42:20,954
to also receive an email. Now again, this is just an example

667
00:42:21,072 --> 00:42:24,734
and it's working and quite complete. So you can check

668
00:42:24,772 --> 00:42:28,942
out the repository and see how I implemented it. Of course, feel free

669
00:42:29,076 --> 00:42:32,926
to submit prs or take this and change it and deploy it to your

670
00:42:32,948 --> 00:42:36,386
own account. And now I

671
00:42:36,408 --> 00:42:39,282
have another couple of points before we finish this talk,

672
00:42:39,416 --> 00:42:43,282
because with lambda and Rust, we are trying

673
00:42:43,336 --> 00:42:46,898
to maybe put a little bit more effort into learning a

674
00:42:46,904 --> 00:42:50,454
new language and writing code that is more optimized. What else can

675
00:42:50,492 --> 00:42:54,102
we do to actually optimize that lambda and make sure that we are

676
00:42:54,156 --> 00:42:57,430
exploiting all the potentials that we can actually exploit.

677
00:42:57,930 --> 00:43:01,494
And there is a very interesting thing

678
00:43:01,532 --> 00:43:04,838
that we need to think about, because remember when I told you that you don't

679
00:43:04,854 --> 00:43:08,998
pick the cpu, you just pick the memory, and the cpu grows proportional

680
00:43:09,014 --> 00:43:12,414
to the amount of memory. So one idea that you might have is

681
00:43:12,452 --> 00:43:15,626
that if I get more cpu,

682
00:43:15,818 --> 00:43:19,742
maybe I can be significantly faster. That even if I am paying

683
00:43:19,796 --> 00:43:23,758
more because I'm allocating more memory, I am so much faster that

684
00:43:23,844 --> 00:43:27,358
it still comes off as cheaper to go with more memory

685
00:43:27,454 --> 00:43:31,330
and therefore more cpu, rather than just trying to save everything

686
00:43:31,400 --> 00:43:34,834
on memory. And then maybe it takes a long time to process your

687
00:43:34,872 --> 00:43:37,878
lambda. So basically the question is,

688
00:43:37,964 --> 00:43:41,474
where do we find the sweet spot? And it is actually not a non trivial

689
00:43:41,522 --> 00:43:45,446
problem. It's not something you can kind of define in

690
00:43:45,468 --> 00:43:48,578
advance. Generally, the best way of finding the sweet

691
00:43:48,674 --> 00:43:51,942
spot is by trying different configurations for your lambda

692
00:43:52,006 --> 00:43:55,258
and actually seeing the numbers and then deciding, looking at

693
00:43:55,264 --> 00:43:57,610
the numbers, what is the best configuration.

694
00:43:58,510 --> 00:44:02,234
And there is a really good tool called AWS lambda power tuning

695
00:44:02,362 --> 00:44:05,422
that you can use, and it's basically a step function that

696
00:44:05,476 --> 00:44:09,326
can trigger your lambdas using a bunch of different configurations in

697
00:44:09,348 --> 00:44:12,506
terms of memory. And then it collects

698
00:44:12,538 --> 00:44:16,274
a bunch of data and it will show you graphs that can help

699
00:44:16,312 --> 00:44:19,694
you to decide which configuration is the best. For instance,

700
00:44:19,742 --> 00:44:23,074
in this graph you can see that this lambda was executed with

701
00:44:23,112 --> 00:44:27,126
different combinations of memory, 128, 156 and

702
00:44:27,148 --> 00:44:30,518
so on. And we can see here at about

703
00:44:30,684 --> 00:44:34,146
1024 that this is probably the sweet spot,

704
00:44:34,258 --> 00:44:38,060
because the execution time doesn't change

705
00:44:40,350 --> 00:44:44,362
the execution time. There is the red

706
00:44:44,416 --> 00:44:48,298
line, so it goes down dramatically while

707
00:44:48,464 --> 00:44:50,926
the execution cost, which is the blue line,

708
00:44:51,108 --> 00:44:55,374
is starting to pick up. So basically we are seeing that

709
00:44:55,492 --> 00:45:00,170
if we compare the same execution

710
00:45:00,250 --> 00:45:04,194
cost, we can reduce the amount of time. So this

711
00:45:04,232 --> 00:45:07,666
is probably the sweet spot there, and you can check

712
00:45:07,688 --> 00:45:11,614
out the repository. There are more examples that tell you also how to interpret

713
00:45:11,662 --> 00:45:14,774
this particular diagram. And in

714
00:45:14,812 --> 00:45:18,360
any way you can test different functions and figure out

715
00:45:19,290 --> 00:45:22,680
which configuration perform best for your particular function.

716
00:45:23,850 --> 00:45:27,542
Now, I want to answer a couple of questions

717
00:45:27,596 --> 00:45:31,274
that you might have at this point, just to finish this talk. How easy

718
00:45:31,312 --> 00:45:34,922
it is to learn rust if you don't know rust today, is it worth going

719
00:45:34,976 --> 00:45:38,970
through the trouble of learning rust just to try to optimize a few lambdas?

720
00:45:39,470 --> 00:45:42,742
Well, I'm not going to say that learning rust

721
00:45:42,806 --> 00:45:46,606
is easy. I think there is a bit of a learning curve there that

722
00:45:46,628 --> 00:45:49,994
you definitely need to go through, and it might take a little bit of effort,

723
00:45:50,122 --> 00:45:53,914
especially if you're coming from languages such as Javascript

724
00:45:53,962 --> 00:45:57,630
or Python that are higher level interpreted programming languages,

725
00:45:57,790 --> 00:46:01,762
where you don't have to worry too much about memory or memory safety because

726
00:46:01,816 --> 00:46:05,214
the language will take care of all that stuff for you. In rust,

727
00:46:05,262 --> 00:46:08,806
you need to learn a bunch of new concepts that are actually things that you

728
00:46:08,828 --> 00:46:12,706
generally don't have to worry about when you program in higher level interpreted

729
00:46:12,738 --> 00:46:16,166
programming languages. So definitely it's not easy,

730
00:46:16,268 --> 00:46:19,722
but is it worth it? My personal answer

731
00:46:19,776 --> 00:46:23,654
is yes. I've personally been through this journey of learning rust

732
00:46:23,782 --> 00:46:27,626
for the last probably three years or three years and

733
00:46:27,648 --> 00:46:30,810
a half. Of course, I've done that in my own spare time.

734
00:46:30,880 --> 00:46:34,142
So probably if you invest more of your own time

735
00:46:34,196 --> 00:46:37,422
into learning it, you can be proficient in much less

736
00:46:37,476 --> 00:46:40,926
time. Also today there are a lot of very good resources to

737
00:46:40,948 --> 00:46:44,126
get started, and therefore you might

738
00:46:44,148 --> 00:46:48,050
be able to become proficient with rust much quicker than I did.

739
00:46:48,200 --> 00:46:51,714
And I would say that it's definitely worth it, because now I

740
00:46:51,752 --> 00:46:55,442
think coming from higher level programming languages, I understand a lot

741
00:46:55,496 --> 00:46:58,646
more of how programming languages in general work,

742
00:46:58,748 --> 00:47:02,182
how memory works, how I can optimize things better,

743
00:47:02,236 --> 00:47:06,086
and I think this is also affecting the way I write code in Python or

744
00:47:06,108 --> 00:47:09,926
node JS. So I think learning rust on

745
00:47:09,948 --> 00:47:13,386
its own, it's a good investment, and I think we'll be seeing rust more

746
00:47:13,408 --> 00:47:16,554
and more in the future. So it can be also a good investment for your

747
00:47:16,592 --> 00:47:20,230
career in general. So as a summary

748
00:47:20,310 --> 00:47:23,646
before we wrap this up, I think serverless is just a

749
00:47:23,668 --> 00:47:26,538
great way of building applications.

750
00:47:26,714 --> 00:47:29,934
Rust is also a great language and a great ecosystem to build

751
00:47:29,972 --> 00:47:34,006
applications. So if you combine the two, I think we have a powerful combination

752
00:47:34,058 --> 00:47:38,194
there, and you can use sum and cargo lambda together

753
00:47:38,312 --> 00:47:42,066
to have a great developer experience. Sum gives you a lot of control on

754
00:47:42,088 --> 00:47:45,638
the infrastructure side, while cargo lambda gives you a lot of control

755
00:47:45,724 --> 00:47:49,618
on the rust compilation,

756
00:47:49,714 --> 00:47:52,998
testing and execution. So combining the two together,

757
00:47:53,084 --> 00:47:56,886
you can deploy infrastructure that leverages rust when

758
00:47:56,908 --> 00:47:58,310
it comes to compute.

759
00:47:59,530 --> 00:48:03,418
And finally, learning rust is not necessarily easy, but in

760
00:48:03,424 --> 00:48:07,018
my opinion, it's definitely worth it. So try it a little bit, spend a

761
00:48:07,024 --> 00:48:10,314
little bit of time, find people to learn it with, and I think

762
00:48:10,352 --> 00:48:13,578
it's going to become a fun journey that eventually is going to give you a

763
00:48:13,584 --> 00:48:16,250
lot of satisfaction and a lot of good opportunities.

764
00:48:16,670 --> 00:48:20,374
So that's all I have for today. Thank you very much for listening

765
00:48:20,422 --> 00:48:23,794
to this talk. If you want to grab the slides, there is the link again,

766
00:48:23,912 --> 00:48:26,942
and if you want to check out my book and give me some feedback,

767
00:48:27,006 --> 00:48:30,194
please do. There is a link there. Reach out to me and let me know

768
00:48:30,232 --> 00:48:32,226
what you think. Thank you very much.

