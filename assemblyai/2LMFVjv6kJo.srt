1
00:00:41,090 --> 00:00:45,046
Hi. Imagine a scenario. You wake up 08:55 a.m.

2
00:00:45,068 --> 00:00:48,374
Your alarm goes off. You roll out of bed, walk over to your

3
00:00:48,412 --> 00:00:51,534
desk. This is now your office. Since we're all working from

4
00:00:51,572 --> 00:00:55,066
home during the pandemic, you open up your laptop and you see there's a meeting

5
00:00:55,098 --> 00:00:58,682
scheduled at 09:00 a.m. With your CTO. Of course, that meeting wasn't

6
00:00:58,746 --> 00:01:02,186
in existence yesterday and the evening, but that's how your CTO

7
00:01:02,218 --> 00:01:06,542
rolls. So you quickly fix yourself up, make yourself look presentable,

8
00:01:06,606 --> 00:01:09,838
brush your teeth, and dial into the Zoom meeting. Now your CTO

9
00:01:09,854 --> 00:01:12,594
is going a mile per second, babbling about something,

10
00:01:12,712 --> 00:01:16,014
and eventually your CTO gets to the point. I read an article

11
00:01:16,062 --> 00:01:19,738
that said all successful companies need to be multi cloud. Get us multicloud

12
00:01:19,774 --> 00:01:23,106
by the end of the half. And then your CTO hangs up. Now you're

13
00:01:23,138 --> 00:01:26,406
staring at that prompt in Zoom that says your meeting has ended and

14
00:01:26,428 --> 00:01:29,910
you're pretty angry. Half of you angry because you haven't had your coffee yet,

15
00:01:29,980 --> 00:01:33,258
and the other half of you angry because you had this giant project dropped in

16
00:01:33,264 --> 00:01:36,906
your lap. Multicloud and cloud migration is just not easy.

17
00:01:37,088 --> 00:01:40,730
The reason it's not easy is because of this concept called vendor lock in.

18
00:01:40,800 --> 00:01:44,014
As you use a cloud provider, you start using more and more

19
00:01:44,052 --> 00:01:47,694
services that they provide. So imagine you start to use s three for

20
00:01:47,732 --> 00:01:51,306
storage. You start to use kinesis for streaming,

21
00:01:51,418 --> 00:01:54,814
et cetera. And these services make your life and software easy to

22
00:01:54,852 --> 00:01:58,178
build. But the more you use these services, these more you

23
00:01:58,184 --> 00:02:01,394
get stuck with that vendor. You get locked in with that vendor because

24
00:02:01,432 --> 00:02:05,122
they are more or less proprietary to that vendor. So now you have this

25
00:02:05,176 --> 00:02:08,546
herculean task to break through vendor lockin so

26
00:02:08,568 --> 00:02:11,926
that you could go multi cloud. But then you wonder, is these a way

27
00:02:11,948 --> 00:02:15,334
to say screw? The harder way we're doing this, the smarter way?

28
00:02:15,532 --> 00:02:19,170
Hi, I'm Larry Finn, these author of Cloud Sidecar,

29
00:02:19,250 --> 00:02:22,954
and I'm going to talk to you about how cloud sidecar can help you

30
00:02:22,992 --> 00:02:26,234
take your existing or even new software and make it

31
00:02:26,272 --> 00:02:29,482
work on multiple clouds or to switch clouds. Now,

32
00:02:29,536 --> 00:02:33,422
beyond that silly story about your CTO saying you have to go multi cloud,

33
00:02:33,556 --> 00:02:37,006
there are a variety of reasons to actually go multi cloud in this

34
00:02:37,028 --> 00:02:40,874
infographic. From the information, it shows the rising costs

35
00:02:41,002 --> 00:02:44,910
of cloud bills, specifically AWS bills. For some notable companies,

36
00:02:45,060 --> 00:02:48,594
being able to go multi cloud or to switch clouds is

37
00:02:48,632 --> 00:02:52,002
a way that you could actually optimize your bills and try to keep

38
00:02:52,056 --> 00:02:55,570
your bills lower, maybe pit some clouds against each other.

39
00:02:55,720 --> 00:02:59,118
We've all been there where your app or your website is just

40
00:02:59,144 --> 00:03:02,966
running slow. So you go to your cloud provider status page and it says

41
00:03:03,068 --> 00:03:06,342
everything is AOK. But then you realize half the Internet isn't working,

42
00:03:06,396 --> 00:03:09,914
so everything is not AOK. Your cloud provider is clearly on

43
00:03:09,952 --> 00:03:13,174
fire. Now if you were multicloud, you could easily

44
00:03:13,222 --> 00:03:16,950
fail over to another cloud and have no interruptions.

45
00:03:17,030 --> 00:03:20,590
I'm going to be honest here, it's probably best first step

46
00:03:20,660 --> 00:03:23,882
to be redundant within multiple data centers or regions

47
00:03:23,946 --> 00:03:27,578
within a single cloud become redundancy to multiple clouds.

48
00:03:27,674 --> 00:03:31,770
But being multicloud is an exceptional level of redundancy.

49
00:03:31,930 --> 00:03:35,582
Some clouds just provide better services than others. So one cloud

50
00:03:35,636 --> 00:03:39,202
might be great at storage, another cloud might be great at big data,

51
00:03:39,256 --> 00:03:43,106
and a third cloud might be great at machine learning. Wouldn't it be amazing if

52
00:03:43,128 --> 00:03:46,406
you could pick and choose the features of each cloud, mix them

53
00:03:46,428 --> 00:03:49,494
together and make your product the best it possibly can be?

54
00:03:49,612 --> 00:03:53,446
And finally, cloud providers are not just single companies

55
00:03:53,548 --> 00:03:56,994
that provide cloud services. They're actually these giant

56
00:03:57,042 --> 00:04:00,342
corporations that do a lot of things. So Amazon

57
00:04:00,406 --> 00:04:03,814
is a huge retailer, Google is the largest

58
00:04:03,862 --> 00:04:07,290
ad tech company and Microsoft apparently these put

59
00:04:07,360 --> 00:04:11,114
trackers in vaccines. Now you might be working with

60
00:04:11,152 --> 00:04:14,222
companies that might not feel comfortable to be working

61
00:04:14,276 --> 00:04:18,206
with these cloud providers. So imagine you are a b to b company.

62
00:04:18,308 --> 00:04:22,206
You're hosted on Google Cloud, you do something with data and

63
00:04:22,308 --> 00:04:25,886
a prospective company is an ad tech and doesn't

64
00:04:25,918 --> 00:04:29,602
want to use you because you are on Google Cloud. Actually going

65
00:04:29,656 --> 00:04:33,346
multi cloud or switching clouds is a two piece problem.

66
00:04:33,448 --> 00:04:36,434
There's the infrastructure problem and the software problem.

67
00:04:36,632 --> 00:04:40,102
I'm not going to really go into the infrastructure problem, that's not my strong

68
00:04:40,156 --> 00:04:43,622
point. And it's mostly a solves problem. You can use infrastructure as code,

69
00:04:43,676 --> 00:04:47,238
like terraform, and be able to build your infrastructure on a

70
00:04:47,244 --> 00:04:51,046
different cloud, or use kubernetes and just pick up all your infrastructure and

71
00:04:51,068 --> 00:04:54,730
just move it to a new cloud. But what I'm going to talk about is

72
00:04:54,880 --> 00:04:58,234
how do you handle your software? How do you make that multi cloud or

73
00:04:58,272 --> 00:05:02,266
enable it to switch clouds? Imagine you have a piece of software that works on

74
00:05:02,288 --> 00:05:05,774
AWS and you want it to work on GCP. AWS is

75
00:05:05,812 --> 00:05:09,358
Amazon and GCP is Google. So it's a simple python application.

76
00:05:09,524 --> 00:05:13,418
You uses these boto library, which is the Python Amazon library,

77
00:05:13,514 --> 00:05:17,166
and you're connecting to s three for storage and sqs for queues.

78
00:05:17,278 --> 00:05:20,770
Now how do you make this work on GCP? Well, you would have to build

79
00:05:20,840 --> 00:05:24,226
a storage abstraction library or some sort

80
00:05:24,248 --> 00:05:27,538
of library layer that sits on top of

81
00:05:27,624 --> 00:05:30,722
both boto library and the Google Cloud storage library.

82
00:05:30,866 --> 00:05:34,050
And your code would interact with this storage abstraction library.

83
00:05:34,130 --> 00:05:37,862
And underneath the hood it would switch between boto to go to Amazon or Google

84
00:05:37,916 --> 00:05:41,290
Cloud storage to go to gcs, which is the Google

85
00:05:41,360 --> 00:05:44,742
storage. Now your abstraction would have to be a single interface

86
00:05:44,806 --> 00:05:48,058
that supports functionality in both clouds, and you have

87
00:05:48,064 --> 00:05:51,618
to do a similar thing for q abstraction library. You would have to wrap

88
00:05:51,654 --> 00:05:54,862
around the boto library and wrap around Google Cloud

89
00:05:54,916 --> 00:05:58,606
pubself library. Now imagine you have that cto that

90
00:05:58,628 --> 00:06:02,286
create cto that decided that your company should be polyglot so

91
00:06:02,308 --> 00:06:05,506
that any engineer can choose any language they want. Because what's the

92
00:06:05,528 --> 00:06:09,230
harm in that? So now your system has some python,

93
00:06:09,310 --> 00:06:13,518
some golang, some scala, some node js, some Java,

94
00:06:13,614 --> 00:06:16,242
maybe some esoteric languages like, I don't know,

95
00:06:16,296 --> 00:06:20,434
clojure, Erlang, Haskell, whatever, not knocking any of these languages,

96
00:06:20,482 --> 00:06:24,006
but that's a lot of languages to support. Now you're also using a lot of

97
00:06:24,028 --> 00:06:27,834
cloud services. So you use s three for storage, sqs for

98
00:06:27,872 --> 00:06:30,746
queues, kinesis for streaming data,

99
00:06:30,928 --> 00:06:34,586
dynamodb for document store, and redshift for

100
00:06:34,608 --> 00:06:37,674
big data. So you have these n languages and

101
00:06:37,712 --> 00:06:40,794
these m services. So now you have to

102
00:06:40,832 --> 00:06:44,234
build those wrappers of n times m. Like each language

103
00:06:44,282 --> 00:06:47,438
has to have wrappers for each of these services. And that's a lot

104
00:06:47,444 --> 00:06:51,262
of libraries and code to write. Imagine also you're a pretty big company,

105
00:06:51,316 --> 00:06:55,018
you've invested in microservices. So in this example there's 1500

106
00:06:55,044 --> 00:06:59,170
plus microservices. So now not only do you have to

107
00:06:59,320 --> 00:07:02,770
change all those codes in different languages for different services,

108
00:07:02,920 --> 00:07:06,606
you have to do it in 1500 plus applications which might be

109
00:07:06,648 --> 00:07:09,798
using cloud services in vastly different ways,

110
00:07:09,884 --> 00:07:13,954
might be accessing and using different libraries. You might not be a very dry

111
00:07:14,002 --> 00:07:17,622
company, so this could be a deploy nightmare and

112
00:07:17,756 --> 00:07:20,970
cloud be really complicated to roll out. So this is where cloud

113
00:07:21,040 --> 00:07:24,726
sidecar can help. You can help solve these problems. Now imagine

114
00:07:24,758 --> 00:07:28,026
you have that python application that uses the Boto library to

115
00:07:28,048 --> 00:07:31,482
talk to AWS. What cloud sidecar does is it gets

116
00:07:31,536 --> 00:07:35,258
deployed next to your application in the sidecar design pattern.

117
00:07:35,354 --> 00:07:38,894
A sidecar design pattern just means an application that sits next to your

118
00:07:38,932 --> 00:07:42,126
application and helps your application. These is a well

119
00:07:42,148 --> 00:07:45,626
known design pattern. You have it in zookeeper

120
00:07:45,738 --> 00:07:49,614
console, any service, mesh like

121
00:07:49,652 --> 00:07:53,410
Linkard. So you have cloud sidecar sitting next to your application.

122
00:07:53,560 --> 00:07:57,190
Your application talks to cloud sidecar instead of the cloud

123
00:07:57,260 --> 00:08:00,626
itself. So you tell it to talk to cloud Sidecar,

124
00:08:00,738 --> 00:08:03,654
it thinks it's talking to Amazon. In this example,

125
00:08:03,852 --> 00:08:07,574
cloud Sidecar translates all the requests. The API requests to

126
00:08:07,612 --> 00:08:11,034
Google Cloud gets the responses from Google Cloud and

127
00:08:11,072 --> 00:08:14,614
translates it back to Amazon. So your Python application doesn't

128
00:08:14,662 --> 00:08:17,926
change at all. Thinks it's still talking to Amazon, but it indeed

129
00:08:17,958 --> 00:08:21,814
is talking to Google Cloud now, because this is transforming API

130
00:08:21,862 --> 00:08:25,354
requests. Cloud Sidecar can support any language

131
00:08:25,482 --> 00:08:29,066
as long as it has like a cloud library. And also in theory

132
00:08:29,098 --> 00:08:33,258
it could support any cloud because it's just translating between API requests,

133
00:08:33,354 --> 00:08:37,026
getting a bit into the nitty gritty of how the software actually works.

134
00:08:37,128 --> 00:08:40,030
Imagine you have your application with the cloud library,

135
00:08:40,110 --> 00:08:43,774
whatever it happens to be, and you could deploy cloud sidecar

136
00:08:43,822 --> 00:08:47,198
on this machine. Let's say you're using like an EC two machine,

137
00:08:47,294 --> 00:08:51,190
you deploy it next to it and you configure application to connect to

138
00:08:51,260 --> 00:08:54,482
localhost via the cloud library. Or if you're using Kubernetes,

139
00:08:54,546 --> 00:08:58,278
there's a sidecar design pattern built into Kubernetes and you deploy it that way.

140
00:08:58,364 --> 00:09:02,186
Now cloud sidecar is running, and it exposes an HTTP router to handle these

141
00:09:02,208 --> 00:09:05,930
API requests, and a configuration to drive which

142
00:09:06,000 --> 00:09:09,386
different types of APIs are supported and which ports they're on.

143
00:09:09,488 --> 00:09:13,434
So we can have s three or an s three interface exposed

144
00:09:13,482 --> 00:09:17,374
on a specific port that your applications connects on. And when

145
00:09:17,412 --> 00:09:21,210
your application connects on that port, it gets routed to the correct handler.

146
00:09:21,290 --> 00:09:24,574
So for example, it'll get routed to the s these

147
00:09:24,612 --> 00:09:28,178
handler on port 3450. Now once your request goes to

148
00:09:28,184 --> 00:09:32,366
the s three handler, it will convert the request from AWS,

149
00:09:32,478 --> 00:09:36,126
and it might just send it directly to s three AWS and just be passed

150
00:09:36,158 --> 00:09:39,622
through. Or it might interpret the request converting it to Google

151
00:09:39,676 --> 00:09:43,254
Cloud storage, get the response back from Google Cloud storage and

152
00:09:43,292 --> 00:09:46,902
send everything back, making it look like it came from s three.

153
00:09:47,036 --> 00:09:50,474
So your application thinks, for all intents and purposes, it's talking to

154
00:09:50,512 --> 00:09:53,814
s three. Or in this example, SQS or kinesis.

155
00:09:53,942 --> 00:09:57,718
Cloud sidecar is written in Golang, and there's several good reasons

156
00:09:57,734 --> 00:10:01,402
for this. This is a sidecar which runs next to your application.

157
00:10:01,456 --> 00:10:04,846
So you want a very minimal footprint, very small memory and

158
00:10:04,868 --> 00:10:08,634
cpu footprint. And Golang is great for this. It's not like JVM,

159
00:10:08,682 --> 00:10:12,254
which will eat all the memory on your machine. Go is also a very

160
00:10:12,292 --> 00:10:15,602
simple language which is great for an open source project where

161
00:10:15,656 --> 00:10:18,770
people can easily dive into it, contribute code,

162
00:10:18,840 --> 00:10:22,194
modify code, et cetera, and there's a lot

163
00:10:22,232 --> 00:10:26,050
of open source libraries that it can use and take advantage of.

164
00:10:26,120 --> 00:10:29,414
And finally, go is a very performant language. It has

165
00:10:29,452 --> 00:10:33,126
a very nice concurrency system and it also

166
00:10:33,148 --> 00:10:36,774
has a lot of low level constructs. Now it might not be as performant as

167
00:10:36,812 --> 00:10:40,754
languages like Rust or C Plus plus, but because of the simplicity

168
00:10:40,802 --> 00:10:44,282
of the language, go wins out

169
00:10:44,336 --> 00:10:48,426
over those languages. For this project I'm going to show you a demo application

170
00:10:48,528 --> 00:10:52,234
that kind of will wrap this around into a little more of a

171
00:10:52,272 --> 00:10:55,882
concrete example. So imagine you run a image conversion

172
00:10:55,946 --> 00:10:59,354
website, we've all been there, where you have a png

173
00:10:59,402 --> 00:11:03,114
file and for some reason you need a jpg file. So you google png

174
00:11:03,162 --> 00:11:06,846
to jpg conversion, find a website, click upload, upload your

175
00:11:06,868 --> 00:11:10,306
png and you get a link to the jpg and you're happy. So you're running

176
00:11:10,328 --> 00:11:13,906
this website and it's actually doing great. It's a great website, makes good

177
00:11:13,928 --> 00:11:17,026
money on ads, but AWS is charging you more

178
00:11:17,048 --> 00:11:19,954
and more and more for their s three services and you look into it and

179
00:11:19,992 --> 00:11:23,526
Google cloud storage is way cheaper. So you wonder how can I pick up

180
00:11:23,548 --> 00:11:26,966
my system and move it to google Cloud? So let's look at the architecture you

181
00:11:26,988 --> 00:11:30,662
have. You have this scala application using the play framework,

182
00:11:30,726 --> 00:11:34,102
which is the front end framework, and uses interact

183
00:11:34,166 --> 00:11:37,750
with it. They click upload and it will upload a png

184
00:11:37,830 --> 00:11:41,254
to s three and then it will put a message on Sqs

185
00:11:41,302 --> 00:11:44,986
with that your s three URL. Now on the other end you have a python

186
00:11:45,018 --> 00:11:48,574
worker that's listening to Sqs for these messages, converts these

187
00:11:48,612 --> 00:11:52,650
image from Png to Jpg using some open source library

188
00:11:52,730 --> 00:11:56,570
and then uploads the result into s three, which then the UI displays.

189
00:11:56,650 --> 00:12:00,306
It's actually a great architecture because you can scale up the workers as

190
00:12:00,328 --> 00:12:03,186
much as you want and you could scale up the front end as much as

191
00:12:03,208 --> 00:12:06,470
you want. S three and sqs can handle a lot of load.

192
00:12:06,890 --> 00:12:10,566
So I've actually pre recorded the demo, which this whole

193
00:12:10,588 --> 00:12:13,814
thing is prerecorded, but demo I'm going to actually

194
00:12:13,852 --> 00:12:17,480
show you is this image uploading system

195
00:12:18,090 --> 00:12:21,750
using cloud sidecar to handle multiple clouds. This is the UI

196
00:12:21,830 --> 00:12:25,674
I'm going to dive into the scala code here. It's just a simple controller where

197
00:12:25,712 --> 00:12:29,334
I inject two modules. I created an s three module and an SQS

198
00:12:29,382 --> 00:12:33,030
module. Now the s three module uses the standard AWS

199
00:12:33,110 --> 00:12:36,942
Java library and it just sells it to connect

200
00:12:36,996 --> 00:12:40,138
to localhost on a certain port. And now when I interact

201
00:12:40,154 --> 00:12:43,386
with s three, I interact with it the way I always do in Java.

202
00:12:43,498 --> 00:12:46,910
Similarly, here I am using the SQS library

203
00:12:47,070 --> 00:12:50,834
and just connecting to localhost on a different port. Now in the worker I'm using

204
00:12:50,872 --> 00:12:54,546
boto, three similar sqs, s three, and I'm just

205
00:12:54,568 --> 00:12:58,274
passing it an endpoint URL, whatever port I want to use,

206
00:12:58,392 --> 00:13:01,734
I'm going to start up the worker, just running one worker because what

207
00:13:01,772 --> 00:13:05,106
I scale. So I'm going to show you my s three bucket. Show you there's

208
00:13:05,138 --> 00:13:08,214
nothing these right now I'm going to show you my GCS bucket. Nothing there.

209
00:13:08,252 --> 00:13:11,514
Right now there's nothing up my sleeves. I'm not even wearing sleeves, but that's not

210
00:13:11,552 --> 00:13:14,858
important. So now I'm going to upload an image to my application.

211
00:13:15,024 --> 00:13:18,922
Everything's running and cloud sidecar is running, pointing to AWS. So what happens

212
00:13:18,976 --> 00:13:22,346
is my play application is going to upload to s three, worker picks off

213
00:13:22,368 --> 00:13:25,886
a message from sqs and uploads to s three, and then I'm going

214
00:13:25,908 --> 00:13:29,198
to actually see this in my UI as a resultant image. Now if

215
00:13:29,204 --> 00:13:32,938
we look at the Amazon bucket, we see the JPG and the PNG, the source

216
00:13:32,954 --> 00:13:36,718
and destination, and on Google Cloud we see nothing. So now I'm

217
00:13:36,734 --> 00:13:40,814
going to restart cloud sidecar with a different configuration.

218
00:13:40,942 --> 00:13:44,706
This one will point to gcs. Typically you don't even need to

219
00:13:44,808 --> 00:13:48,046
restart cloud sidecar, it dynamically loads configs, but it's

220
00:13:48,078 --> 00:13:51,890
easier for the demo. As you'll note, I didn't actually restart my worker or my

221
00:13:51,960 --> 00:13:55,142
skull app. So now I'm going to upload a new image. It's going to actually

222
00:13:55,196 --> 00:13:58,198
go to GCS. A message is going to go to pub sub, the worker is

223
00:13:58,204 --> 00:14:01,546
going to read off pub sub, convert it and upload to gcS. And then we

224
00:14:01,568 --> 00:14:05,146
will see the image here. New image. And as you can

225
00:14:05,168 --> 00:14:08,950
see, the source and destination image are now in gcs

226
00:14:09,030 --> 00:14:12,666
and they're not in s three. Really cool stuff.

227
00:14:12,768 --> 00:14:15,994
Now that you've seen the demo, what are all the features of cloud sidecar

228
00:14:16,042 --> 00:14:19,566
and how can you actually use this at your company or your site?

229
00:14:19,748 --> 00:14:23,594
Right now we have two editions, the community edition and the enterprise edition.

230
00:14:23,722 --> 00:14:27,502
Community is completely open source, the enterprise is open core,

231
00:14:27,646 --> 00:14:30,914
but this might all just merge into open source. It's just things

232
00:14:30,952 --> 00:14:34,258
we're playing with. So as I mentioned before, both of

233
00:14:34,264 --> 00:14:37,586
these support any language, any programming language that you're using,

234
00:14:37,688 --> 00:14:41,238
and they both support AWS to GCP conversion. As these main thing,

235
00:14:41,324 --> 00:14:44,614
I've been adding GCP to AWS conversion a little bit

236
00:14:44,652 --> 00:14:47,906
by little bit, but no other clouds yet. For file storage

237
00:14:47,938 --> 00:14:51,302
they both support s three to gcs, and for file storage they also

238
00:14:51,356 --> 00:14:55,610
both support gcs to s three. For queues we support sqs to pub sub

239
00:14:55,680 --> 00:14:58,938
and for breaking data we support kinesis to pub sub. And I'll go into what

240
00:14:58,944 --> 00:15:02,634
these queues and streaming data solutions actually are like. Cloud Sidecar also

241
00:15:02,672 --> 00:15:06,330
supports customizable plugins. So imagine if we didn't support sqs.

242
00:15:06,410 --> 00:15:10,350
You could write a plugin to support sqs and just drop it in and

243
00:15:10,420 --> 00:15:14,106
cloud sidecar will pick it up. You don't even need to recompile cloud sidecar.

244
00:15:14,218 --> 00:15:17,554
We also support customizable middleware. So if you want to write

245
00:15:17,592 --> 00:15:20,974
some sort of logging, middleware, metrics, encryption, et cetera,

246
00:15:21,022 --> 00:15:23,938
you could write that really easy and drop it in and configure it. Now in

247
00:15:23,944 --> 00:15:27,702
the enterprise versions we support a few more functionalities. We support key value,

248
00:15:27,756 --> 00:15:31,734
which is DynamoDb to datastore or bigtable. We support

249
00:15:31,852 --> 00:15:36,050
big data, so we support redshift to bigquery, SQL conversions.

250
00:15:36,130 --> 00:15:39,846
And also for big data we support customizable stores, procedure style

251
00:15:39,878 --> 00:15:43,098
plugins. So basically, if you've used a

252
00:15:43,104 --> 00:15:46,694
lot of databases, SQL doesn't always convert to the most optimized

253
00:15:46,742 --> 00:15:50,230
SQL and different dialects. These, you could write your own plugins

254
00:15:50,390 --> 00:15:53,798
that look like stored procedures, call them from queries,

255
00:15:53,894 --> 00:15:57,866
and then have cloud Sidecar call that plugin which generates

256
00:15:57,898 --> 00:16:01,178
a different query based on your end destination

257
00:16:01,274 --> 00:16:04,426
so you can make it as optimized as you want. We also support metrics,

258
00:16:04,458 --> 00:16:08,066
integration, statsd and datadog because, well, that's the big dog.

259
00:16:08,248 --> 00:16:11,506
For s three to gcs, we support list one and list two.

260
00:16:11,528 --> 00:16:14,866
The two types of listing ACL head get put,

261
00:16:14,968 --> 00:16:18,302
multipart upload, delete, multidelete, and copy. Now,

262
00:16:18,376 --> 00:16:21,814
I've kind of glossed over something, but these different services in different

263
00:16:21,852 --> 00:16:25,266
clouds, while they're super similar, there are small caveats of how they're

264
00:16:25,298 --> 00:16:28,566
different. And one important one for s three to GCS is

265
00:16:28,588 --> 00:16:32,134
s three supports something called multipart upload, which GCS does

266
00:16:32,172 --> 00:16:35,798
not support. So what's multipart upload? Imagine you have this really large file,

267
00:16:35,814 --> 00:16:38,986
let's say ten gigabyte file, and you want to upload it. Now, uploading a ten

268
00:16:39,008 --> 00:16:42,314
gigabyte file is going to take a long time, and then you might get

269
00:16:42,352 --> 00:16:45,326
interrupted and it's a pain in the bum. So with s three, what you could

270
00:16:45,348 --> 00:16:49,274
do is say, I want to create a big file upload at this destination URL,

271
00:16:49,322 --> 00:16:52,846
and s three will say, cool, you just need to upload all the parts to

272
00:16:52,868 --> 00:16:56,106
this URL and tell me when you're done. So what you do on your client

273
00:16:56,138 --> 00:16:59,698
side is you split up this ten gigabyte file into 1gb chunks, and then you

274
00:16:59,704 --> 00:17:02,994
could upload them in parallel or however. And once they're all

275
00:17:03,032 --> 00:17:06,414
done, you tell s three I'm done. It merges those chunks

276
00:17:06,462 --> 00:17:10,034
together and puts it at the destination. GCS does not have multipart

277
00:17:10,082 --> 00:17:13,942
upload, but it has something called combine, which will combine some amount

278
00:17:13,996 --> 00:17:17,122
of elements already uploaded to gcs.

279
00:17:17,186 --> 00:17:20,450
So underneath the hood we use that to mimic multipart upload.

280
00:17:20,530 --> 00:17:23,990
Now, there's other caveats with the s three API that I've discovered

281
00:17:24,150 --> 00:17:27,318
along with GCS. I could talk about it at length. I won't

282
00:17:27,334 --> 00:17:30,166
bore you, but if you're ever interested, just hit me up and we could chat

283
00:17:30,198 --> 00:17:34,154
about it. For GCs s three, which is in beta feature we just recently added,

284
00:17:34,202 --> 00:17:37,930
we support list, ACl, get put, resumable upload,

285
00:17:38,010 --> 00:17:41,406
combine, delete and copy. Similar to the s,

286
00:17:41,428 --> 00:17:44,974
these gcs incompatibilities, resumable upload

287
00:17:45,022 --> 00:17:48,654
and combine are not natively supported in s three, so we mimic

288
00:17:48,702 --> 00:17:52,354
them using some of the existing functionality in s

289
00:17:52,392 --> 00:17:56,046
three. Great. So going on to queues and streams,

290
00:17:56,238 --> 00:18:00,146
I want to explain the different queue offerings of the clouds and then what

291
00:18:00,168 --> 00:18:03,714
we offer on top of them. So on the far left you have sqs,

292
00:18:03,762 --> 00:18:06,966
the simple queue, which is the simplest one. Basically you create a

293
00:18:06,988 --> 00:18:10,762
queue, you post messages to it, and then workers can listen to these queue and

294
00:18:10,816 --> 00:18:14,410
workers will alternate who actually gets the message. So it's great for

295
00:18:14,480 --> 00:18:17,958
worker pools. On the other end of the spectrum is kinesis,

296
00:18:18,054 --> 00:18:21,286
where you'll create topics, drop messages into that topic,

297
00:18:21,318 --> 00:18:25,066
and they just flow through. And whoever's consuming these messages,

298
00:18:25,178 --> 00:18:28,686
they keep track of the offset of the message they last read, and then they

299
00:18:28,708 --> 00:18:32,158
just keep reading messages after that offset. Kinesis is a

300
00:18:32,164 --> 00:18:35,486
lot more similar to Kafka, if you're used to Kafka.

301
00:18:35,598 --> 00:18:39,602
So SQs and kinesis are both AWs. Somewhere in the middle is pub sub,

302
00:18:39,656 --> 00:18:43,362
which is these GCP offering, Google cloud offering. And this is

303
00:18:43,416 --> 00:18:47,214
sort of like RabbitMQ if you've ever used it. You post messages

304
00:18:47,262 --> 00:18:50,534
to the pub sub topic and you can actually create an arbitrary amount

305
00:18:50,572 --> 00:18:54,002
of queues attached to the topic, which will start accumulating

306
00:18:54,066 --> 00:18:57,314
messages once they're published to the topic. And then the queues

307
00:18:57,362 --> 00:19:00,934
kind of works like sqs, where you could have workers attached to them and they'll

308
00:19:00,982 --> 00:19:04,570
retrieve messages in some alternating manner. They don't have any

309
00:19:04,640 --> 00:19:08,234
offsets or whatever. So for message queue we support

310
00:19:08,272 --> 00:19:11,630
sqs to pub sub, and these functionality we support list,

311
00:19:11,700 --> 00:19:14,618
create, purge, delete, send, send, batch, receive,

312
00:19:14,714 --> 00:19:18,346
delete, message and delete message batch for kinesis

313
00:19:18,378 --> 00:19:21,930
to pub sub we support getrecords, get shard, iterator,

314
00:19:22,010 --> 00:19:25,854
describe, publish, create stream and delete stream. Now for

315
00:19:25,892 --> 00:19:29,250
NoSQL, which is mostly a document store key value store,

316
00:19:29,320 --> 00:19:32,994
we support DynamoDB to Datastore. Just so you know, I'm not

317
00:19:33,032 --> 00:19:37,106
even sure if it's still called Datastore. They might call it Firestore because Datastore

318
00:19:37,138 --> 00:19:40,518
took over firebase. All this crazy Google cloud stuff.

319
00:19:40,684 --> 00:19:44,066
But the functionality we support are getitem query,

320
00:19:44,178 --> 00:19:47,542
scan, put item, update item and delete item. Now,

321
00:19:47,596 --> 00:19:51,546
interesting caveats here between DynamoDB and Datastore. DynamoDB has

322
00:19:51,568 --> 00:19:55,354
the concept of query and scan, which both search for

323
00:19:55,392 --> 00:19:58,730
items or filter for items, but use different methods for it.

324
00:19:58,800 --> 00:20:02,398
Datastore does not have that. So these two function calls end up being

325
00:20:02,404 --> 00:20:05,966
the equivalent in datastore of one function call.

326
00:20:06,068 --> 00:20:09,674
And also Dynamodb has like a pretty complicated JSon

327
00:20:09,722 --> 00:20:13,406
nested filtering updating system. Datastore does

328
00:20:13,428 --> 00:20:16,898
not have such a system. It's a simpler language, so we try

329
00:20:16,904 --> 00:20:20,030
to convert it as best as possible. We're constantly improving

330
00:20:20,190 --> 00:20:23,746
this functionality of cloud sidecar. So for big

331
00:20:23,768 --> 00:20:27,338
data, this is kind of an outlier where all the other systems

332
00:20:27,374 --> 00:20:31,442
I spoke about have a simple pretty much rest API. Maybe there's

333
00:20:31,506 --> 00:20:35,494
XML. If it's s three, that's how old s three actually is. But for

334
00:20:35,532 --> 00:20:39,510
big data on AWS we use redshift,

335
00:20:39,590 --> 00:20:42,698
which is actually somewhat related to postgres and has a

336
00:20:42,704 --> 00:20:46,454
postgres interface. So for cloud sidecar we actually expose

337
00:20:46,502 --> 00:20:50,506
a postgres interface for big data. So your application is

338
00:20:50,528 --> 00:20:54,026
not even a cloud library you uses, you might be using however you connect to

339
00:20:54,048 --> 00:20:57,598
a database. So it might be JDBC or whatever you use to connect to a

340
00:20:57,604 --> 00:21:00,714
postgres database, you point it to connect to cloud sidecar

341
00:21:00,762 --> 00:21:04,794
instead of redshift. Cloud sidecar of course is using this config to

342
00:21:04,852 --> 00:21:08,962
realize if you actually want to connect to AWS as a destination or Google

343
00:21:09,016 --> 00:21:12,498
Cloud Bigquery's destination. If it's redshift, it just kind

344
00:21:12,504 --> 00:21:16,226
of proxies the queries through to redshift and proxies the response back

345
00:21:16,248 --> 00:21:20,146
to you. If it's bigquery, it will consume the SQL,

346
00:21:20,258 --> 00:21:24,054
interpret it and converting it to a bigquery SQL and then

347
00:21:24,252 --> 00:21:28,146
respond with parse the response and return it as if it was a postgres

348
00:21:28,178 --> 00:21:31,962
or redshift response. Now, if you actually use our special

349
00:21:32,096 --> 00:21:35,706
stored procedure plugins, there's special commands in your SQL to

350
00:21:35,728 --> 00:21:39,882
call those stored procedure plugins. And if we see that we'll call your code and

351
00:21:39,936 --> 00:21:42,966
pass to what the destination is trying to actually trigger.

352
00:21:43,078 --> 00:21:46,494
And in your code you could say, hey, if this is called with certain

353
00:21:46,532 --> 00:21:50,126
parameters, redshift is my destination, create a SQL query like

354
00:21:50,148 --> 00:21:53,854
this. But if bigquery is my destination, create a SQL query like

355
00:21:53,892 --> 00:21:57,406
that. And this is all dynamic and really you could optimize

356
00:21:57,438 --> 00:22:01,810
it as much as you want. So for our general SQL conversion

357
00:22:02,150 --> 00:22:04,986
in big data, we support, insert, select, delete,

358
00:22:05,038 --> 00:22:08,434
unload, which is basically to export data, copy,

359
00:22:08,482 --> 00:22:12,514
which is basically to import data, rename table, create table and drop

360
00:22:12,562 --> 00:22:16,530
table. Great. So I've told you some arbitrary

361
00:22:16,690 --> 00:22:20,450
example demo of how this could work in these real world and all our functionalities,

362
00:22:20,530 --> 00:22:24,330
but who's actually using this cloud sidecar is mostly a side project

363
00:22:24,400 --> 00:22:28,726
of mine, but my day job has been at a company called ActioniQ or AIQ.

364
00:22:28,838 --> 00:22:32,426
And we're what's known as a CDP, a customer data platform.

365
00:22:32,608 --> 00:22:36,094
So maybe you could interpret it from a picture. What a customer data

366
00:22:36,132 --> 00:22:39,374
platform does is it works with large companies, sucks up

367
00:22:39,412 --> 00:22:42,934
all this large company's data from various data sources,

368
00:22:43,082 --> 00:22:46,674
internalizes it, makes it usable, makes it so that

369
00:22:46,712 --> 00:22:50,754
this data can actually be built into user audiences and

370
00:22:50,792 --> 00:22:54,900
then those audiences can be exported into external systems like email,

371
00:22:55,430 --> 00:22:59,298
advertisements, et cetera. So let me give you a concrete example.

372
00:22:59,464 --> 00:23:03,574
Action Xu has Michael Kors as a customer, and Michael Kors has

373
00:23:03,692 --> 00:23:07,282
data about online orders, online clicks,

374
00:23:07,346 --> 00:23:11,166
online returns, in store purchases, in store returns,

375
00:23:11,218 --> 00:23:15,254
et cetera. These might be stored in various data stores. Action IQ

376
00:23:15,302 --> 00:23:18,966
sucks all that data in. And these we have a really nice uses interface

377
00:23:18,998 --> 00:23:22,834
that lets marketers working at Michael Kors to build segments

378
00:23:22,902 --> 00:23:26,138
or audiences of customers based on some criteria.

379
00:23:26,234 --> 00:23:30,142
So they might want to find out who paid over $3,000

380
00:23:30,196 --> 00:23:33,646
in shoes last year, but has not bought shoes this year. So they

381
00:23:33,668 --> 00:23:37,522
could quickly put that into our system, drag and drop see account in really

382
00:23:37,576 --> 00:23:41,346
quick time, realize that this is like a nice audience size to target. Probably could

383
00:23:41,368 --> 00:23:45,234
get us some good sales and then they could send those customers a

384
00:23:45,272 --> 00:23:48,626
coupon via email and then a cool dance video via

385
00:23:48,658 --> 00:23:51,794
TikTok. Because everyone likes dance videos or TikTok.

386
00:23:51,842 --> 00:23:55,542
I don't know. I don't use TikTok. So Action IQ has typically been

387
00:23:55,596 --> 00:23:58,946
on Amazon, but we started getting approached or approaching

388
00:23:58,978 --> 00:24:02,990
customers. That said, they do not want to be on Amazon for multiple reasons.

389
00:24:03,090 --> 00:24:06,746
They would prefer to be on Google Cloud. So we went under

390
00:24:06,848 --> 00:24:10,282
taking a project to go multi cloud with Google Cloud as our second

391
00:24:10,336 --> 00:24:13,726
cloud provider. Of course we did the infrastructure, which I'm not going to get into,

392
00:24:13,828 --> 00:24:17,114
but we were able to leverage my project cloud sidecar,

393
00:24:17,242 --> 00:24:20,382
to make our software work on both Google Cloud

394
00:24:20,436 --> 00:24:23,966
and AWS with very little code change. Since we

395
00:24:23,988 --> 00:24:27,854
are a big data company, we use a lot of the AWS

396
00:24:27,902 --> 00:24:31,970
services to really make it so that we can move data very simply.

397
00:24:32,310 --> 00:24:35,998
So being able to just deploy cloud sidecar with our

398
00:24:36,024 --> 00:24:40,022
application meant that we were able to save a lot of time making

399
00:24:40,076 --> 00:24:43,606
code changes, et cetera. And we actually were able to

400
00:24:43,628 --> 00:24:46,018
release multicloud before our deadline,

401
00:24:46,194 --> 00:24:49,494
which is shocking to me because I've never released before

402
00:24:49,532 --> 00:24:53,082
deadline and made our customer very happy. We've been using

403
00:24:53,136 --> 00:24:56,362
cloud Sidecar in production for many months to years

404
00:24:56,416 --> 00:25:00,202
now. Of course we found bugs and we fixed them and big help

405
00:25:00,256 --> 00:25:04,234
in us going multi cloud and making that customer successful.

406
00:25:04,362 --> 00:25:08,394
Great. So I've told you everything about cloud Sidecar. You heard my spiel.

407
00:25:08,522 --> 00:25:12,238
Please try it out. Go cloud sidecar.com for more information.

408
00:25:12,404 --> 00:25:16,746
We have a link to our GitHub@GitHub.com slash cloud Sidecar.

409
00:25:16,858 --> 00:25:20,274
Try it, download it, play around with know you cloud,

410
00:25:20,312 --> 00:25:23,650
contribute to it. Our open source project. You could create issues,

411
00:25:23,800 --> 00:25:27,886
all that good stuff. Also, if you're interested in the enterprise offering,

412
00:25:27,918 --> 00:25:31,254
if you're like a big company, feel free to reach out to me

413
00:25:31,292 --> 00:25:35,206
through the website or email me at Larry Cloud sidecar.com.

414
00:25:35,308 --> 00:25:39,158
I'm also always free to talk about multicloud or anything

415
00:25:39,244 --> 00:25:42,230
really, so hit me up. I'm always around.

416
00:25:42,380 --> 00:25:46,146
Got nothing else going on during the pandemic. If you want to see the image

417
00:25:46,178 --> 00:25:50,302
uploader, that code is real. You could go to GitHub Lawrence Finn Cloud

418
00:25:50,356 --> 00:25:53,818
Sidecar Image demo and if you want to just follow me on Twitter.

419
00:25:53,914 --> 00:25:57,566
I'm at Lawrence Finn have three followers. One is my mom and one

420
00:25:57,588 --> 00:26:00,698
is my cat. So I don't know, maybe there's another follower out there. And I'm

421
00:26:00,714 --> 00:26:02,860
also on LinkedIn. If you haven't used that.

