1
00:00:00,410 --> 00:00:06,126
Jamaica make up real

2
00:00:06,148 --> 00:00:10,618
time feedback into the behavior of your distributed systems and observing

3
00:00:10,714 --> 00:00:14,538
changes. Exceptions errors in real time allows

4
00:00:14,554 --> 00:00:17,914
you to not only experiment with confidence but respond

5
00:00:18,042 --> 00:00:20,480
instantly to get things working again.

6
00:00:24,610 --> 00:01:05,360
Close hello,

7
00:01:06,210 --> 00:01:09,650
my name is Alpersanavji and I will talk

8
00:01:09,720 --> 00:01:14,114
about distributed transactions in service. Meshes mesh today let

9
00:01:14,152 --> 00:01:16,290
me introduce myself in the beginning,

10
00:01:17,590 --> 00:01:21,750
as I mentioned, I'm Alparsonavji and I'm working as a software developer at

11
00:01:21,820 --> 00:01:25,186
Zapata Computing and I'm

12
00:01:25,218 --> 00:01:28,674
currently working with the platform team. We are dealing with the cloud native

13
00:01:28,722 --> 00:01:32,686
issues. We are building the backend

14
00:01:32,738 --> 00:01:36,314
applications for the quantum engine for

15
00:01:36,352 --> 00:01:39,878
the quantum computing team and you can always

16
00:01:39,984 --> 00:01:45,840
access me, you can always reach me using my email which is alpersonalgy@gmail.com.

17
00:01:49,170 --> 00:01:53,666
Let's start our talk with imagining a large

18
00:01:53,768 --> 00:01:57,394
ecommerce business. Imagine that this

19
00:01:57,512 --> 00:02:01,314
ecommerce business has thousands of transactions per

20
00:02:01,352 --> 00:02:05,322
day and there are multiple variety of goods

21
00:02:05,406 --> 00:02:07,880
exist in the business.

22
00:02:08,250 --> 00:02:11,542
There are multiple locations and time zones that people are

23
00:02:11,596 --> 00:02:15,526
using. Our business, our websites, maybe we

24
00:02:15,548 --> 00:02:19,098
have multiple websites. And also imagine that you

25
00:02:19,104 --> 00:02:23,146
are a developer in this company and you have more

26
00:02:23,168 --> 00:02:27,402
than hundreds of colleagues, technical colleagues working

27
00:02:27,456 --> 00:02:31,310
on the applications and also DevOps.

28
00:02:31,730 --> 00:02:34,830
And you have multiple specialized teams.

29
00:02:35,570 --> 00:02:38,906
So these specialized

30
00:02:38,938 --> 00:02:42,334
teams are also working in different locations and remote work. We can say

31
00:02:42,372 --> 00:02:46,898
that this is the modern enterprise company

32
00:02:46,984 --> 00:02:51,182
structure. So one day your CTO

33
00:02:51,246 --> 00:02:54,674
or your executives come to you and ask this

34
00:02:54,712 --> 00:02:58,886
question, if it

35
00:02:58,908 --> 00:03:03,122
will be in your hands, how do you set up our software architecture

36
00:03:03,186 --> 00:03:05,880
from scratch? Which approach will we use?

37
00:03:06,970 --> 00:03:10,902
Will you use a monolith or we use a microservices

38
00:03:10,966 --> 00:03:14,362
approach. So when we are talking

39
00:03:14,416 --> 00:03:17,642
about monolith and microservices, this is not just a

40
00:03:17,696 --> 00:03:21,326
simple approach. There are multiple then different approaches that you

41
00:03:21,348 --> 00:03:24,842
can think when we call these approaches.

42
00:03:24,986 --> 00:03:29,086
But just we know that monolith is really

43
00:03:29,188 --> 00:03:32,682
difficult for these kind of enterprises and

44
00:03:32,756 --> 00:03:36,706
we will most likely eventually come to

45
00:03:36,728 --> 00:03:39,650
a point that we will use Microservices approach.

46
00:03:40,390 --> 00:03:43,470
So eventually you choose Microsoft's architecture,

47
00:03:43,550 --> 00:03:46,520
but the problems just start with there.

48
00:03:47,690 --> 00:03:51,922
Firstly, you will have multiple different technologies

49
00:03:52,066 --> 00:03:55,922
running on different environments

50
00:03:56,066 --> 00:03:59,782
and you need to make them run stable

51
00:03:59,846 --> 00:04:03,466
and reliably without having any

52
00:04:03,488 --> 00:04:07,066
issues. So you might have front end services,

53
00:04:07,248 --> 00:04:10,734
you might have back end services that are talking to each other.

54
00:04:10,852 --> 00:04:12,190
There will be clients,

55
00:04:13,250 --> 00:04:16,414
external clients that are accessing to your front end

56
00:04:16,452 --> 00:04:19,854
services most likely. And there might

57
00:04:19,892 --> 00:04:23,626
be some message brokers that

58
00:04:23,668 --> 00:04:27,266
is used to communicate these services. And there

59
00:04:27,288 --> 00:04:31,006
will be most likely some multiple different system of records,

60
00:04:31,118 --> 00:04:35,018
third party libraries and so on. So you need to deal with lots

61
00:04:35,054 --> 00:04:38,840
of problems. First we need to understand

62
00:04:40,250 --> 00:04:42,310
where we set up our microservices,

63
00:04:43,690 --> 00:04:47,590
our microservices, as you know, in the modern

64
00:04:48,490 --> 00:04:52,106
ecosystems, application ecosystems, they are most

65
00:04:52,128 --> 00:04:56,022
likely in a containerized environment

66
00:04:56,086 --> 00:05:00,098
which we most likely will be using Docker for container,

67
00:05:00,134 --> 00:05:03,882
as a container engine, and there as the container orchestration

68
00:05:03,946 --> 00:05:06,190
tool, we will be most likely using kubernetes.

69
00:05:07,970 --> 00:05:12,526
And as the number of Microsoft increase, then you

70
00:05:12,548 --> 00:05:16,106
will need new tools. And you know that the number of Microsofts

71
00:05:16,138 --> 00:05:19,954
will increase eventually in time because you will need new features and

72
00:05:19,992 --> 00:05:23,314
also you will need some scalability. You will

73
00:05:23,352 --> 00:05:27,714
end up with some scalability issues. So the number will increase.

74
00:05:27,842 --> 00:05:31,926
And with these new tools, actually you will need new tools because you

75
00:05:31,948 --> 00:05:35,718
will need more ease of maintenance on your application

76
00:05:35,804 --> 00:05:39,062
environment. So these new tools

77
00:05:39,126 --> 00:05:42,426
will include some kind of service meshes. So what's the

78
00:05:42,448 --> 00:05:46,250
service meshes? This service mesh is

79
00:05:46,400 --> 00:05:52,526
an infrastructure layer application and it

80
00:05:52,548 --> 00:05:56,362
runs in the infrastructure layer and enables the security secure communication

81
00:05:56,426 --> 00:06:01,034
in the infrastructurities amongst

82
00:06:01,082 --> 00:06:04,366
services. So we can say that it is handing

83
00:06:04,398 --> 00:06:08,302
over the east to west communication among

84
00:06:08,366 --> 00:06:13,090
services. And by taking over this communication

85
00:06:14,790 --> 00:06:19,682
you can control the whole interaction

86
00:06:19,746 --> 00:06:22,120
between these services. For example,

87
00:06:23,290 --> 00:06:26,486
by taking over the communication you can

88
00:06:26,508 --> 00:06:29,722
manage the traffic posts, you can manage the security,

89
00:06:29,856 --> 00:06:34,694
and also you can provide some observability to your developers

90
00:06:34,742 --> 00:06:38,186
and users. Currently there

91
00:06:38,208 --> 00:06:42,238
are multiple service mesh products, but the top three is

92
00:06:42,324 --> 00:06:46,174
istio, console and Linkerd. The most popular one is the istio which

93
00:06:46,212 --> 00:06:48,270
we will also use on our demonstrations,

94
00:06:49,650 --> 00:06:53,282
but Linkerd and console are also used. There are also some

95
00:06:53,336 --> 00:06:57,442
other applications that the implementations of service

96
00:06:57,496 --> 00:07:01,010
mesh okay, we set up

97
00:07:01,080 --> 00:07:04,660
our service mesh and we tried to solve some issues,

98
00:07:07,850 --> 00:07:11,666
but since you have multiple services and multiple

99
00:07:11,698 --> 00:07:15,554
system of records, you will most likely end up with dual

100
00:07:15,602 --> 00:07:19,370
write problems which we will mention in a few seconds.

101
00:07:20,990 --> 00:07:25,642
This means that you will need to access multiple system

102
00:07:25,696 --> 00:07:29,434
of records at the same time and you will

103
00:07:29,472 --> 00:07:33,166
need transaction operations. So since you

104
00:07:33,188 --> 00:07:37,630
are running in a distributed environment, prepare yourself to distribute transactions.

105
00:07:38,450 --> 00:07:41,790
Let's talk about the dual write problem in the beginning.

106
00:07:42,470 --> 00:07:45,582
So this represents

107
00:07:45,646 --> 00:07:49,294
a really small part of our large ecommerce

108
00:07:49,342 --> 00:07:52,962
business. Imagine that there's a front end service

109
00:07:53,096 --> 00:07:57,726
that accept the request from the user and starts

110
00:07:57,758 --> 00:08:01,126
a transaction transaction. This transaction can

111
00:08:01,148 --> 00:08:04,838
be something like purchasing a good

112
00:08:04,924 --> 00:08:07,974
from your website and most

113
00:08:08,012 --> 00:08:11,754
likely you will be accessing multiple serves at the same time

114
00:08:11,792 --> 00:08:15,478
and you will need to run them in the same transaction boundary.

115
00:08:15,654 --> 00:08:19,130
For instance, you might need to access user service,

116
00:08:19,280 --> 00:08:22,734
product, service and banking service at the same time. And these might

117
00:08:22,772 --> 00:08:27,194
be accessing to separate

118
00:08:27,242 --> 00:08:30,286
databases, different databases for instance like this user D to

119
00:08:30,308 --> 00:08:32,830
be banking DB or product DB.

120
00:08:34,310 --> 00:08:37,906
And if the banking service, for instance, if one

121
00:08:37,928 --> 00:08:40,814
of our services crashes,

122
00:08:40,942 --> 00:08:44,398
imagine that we cannot access the banking service in this transaction.

123
00:08:44,494 --> 00:08:48,390
We need to roll back our updates on the product

124
00:08:48,460 --> 00:08:52,434
service and user service. So let's

125
00:08:52,482 --> 00:08:56,726
demonstrate this problem and we

126
00:08:56,748 --> 00:09:00,566
will try to understand more. So firstly,

127
00:09:00,678 --> 00:09:07,098
we will have similar

128
00:09:07,184 --> 00:09:09,450
environments in our demonstration.

129
00:09:14,310 --> 00:09:17,794
So let's first see our

130
00:09:17,992 --> 00:09:21,266
application. Yeah, we will have multiple services, we will

131
00:09:21,288 --> 00:09:25,426
have the user service and we

132
00:09:25,448 --> 00:09:29,030
will have deployment for the user service. Another deployment for the product

133
00:09:29,100 --> 00:09:33,000
service, another deployment for the banking service.

134
00:09:33,530 --> 00:09:37,206
And the one that will serve as

135
00:09:37,228 --> 00:09:40,538
the front end service will be the ecommerce service. And as you

136
00:09:40,544 --> 00:09:44,410
can see here, this ecommerce rule will know about the other three

137
00:09:44,480 --> 00:09:48,554
services so it can communicate through

138
00:09:48,672 --> 00:09:52,430
to these microservices. So let's apply

139
00:09:52,500 --> 00:09:59,978
this one's.

140
00:10:00,154 --> 00:10:05,534
Our deployments is being applied as

141
00:10:05,572 --> 00:10:09,502
we have source by the way. Meanwhile these

142
00:10:09,556 --> 00:10:13,090
source are created. I also need to mention

143
00:10:13,240 --> 00:10:17,110
we have already installed istio

144
00:10:17,850 --> 00:10:21,382
in our environment. So let's see get

145
00:10:21,516 --> 00:10:25,590
services istio

146
00:10:25,930 --> 00:10:29,306
system. So you can see that

147
00:10:29,328 --> 00:10:32,730
there are multiple sources running for the istio.

148
00:10:33,710 --> 00:10:37,462
So when we check the pods

149
00:10:37,526 --> 00:10:41,322
existing in the default namespace, you will see our

150
00:10:41,376 --> 00:10:44,750
pods are now running and you will see that there will be

151
00:10:44,820 --> 00:10:48,446
two ready containers in each pod. One of them

152
00:10:48,468 --> 00:10:51,714
will be the actual pod for the application and the second one

153
00:10:51,752 --> 00:10:54,782
will be the sidecar,

154
00:10:54,926 --> 00:10:59,010
the proxy sidecar for the istio service mesh.

155
00:11:00,150 --> 00:11:04,014
So our service are running, our pods are running. Let's check the

156
00:11:04,072 --> 00:11:07,522
services to get the external IP

157
00:11:07,586 --> 00:11:11,640
for the front end service. This is the external IP that we'll be using

158
00:11:12,490 --> 00:11:16,354
and we have also our kiali

159
00:11:16,482 --> 00:11:18,940
frontend to see the running services.

160
00:11:19,550 --> 00:11:23,210
This is the tools that come out of the box

161
00:11:23,280 --> 00:11:26,666
with istio service mesh. So you can see that the

162
00:11:26,688 --> 00:11:30,526
default Kubernetes service and also the other services that

163
00:11:30,548 --> 00:11:34,282
we are running are all here. So let's

164
00:11:34,346 --> 00:11:38,094
try to access our front

165
00:11:38,132 --> 00:11:41,698
end which will be running on the

166
00:11:41,704 --> 00:11:43,300
881 port.

167
00:11:46,070 --> 00:11:49,442
Yes, this is the simple front

168
00:11:49,496 --> 00:11:52,686
end for our ecommerce.

169
00:11:52,878 --> 00:11:56,434
You can see that there's only a single product and there are multiple

170
00:11:56,482 --> 00:12:00,070
information, there are multiple info about the product

171
00:12:00,140 --> 00:12:04,438
and also the user and the store itself. So we get

172
00:12:04,604 --> 00:12:08,138
these product information,

173
00:12:08,304 --> 00:12:11,738
the price, the stock and other information from the

174
00:12:11,744 --> 00:12:15,354
product service and we have a available user credits

175
00:12:15,472 --> 00:12:18,966
here which is 10,000 pounds. You can

176
00:12:19,008 --> 00:12:22,334
imagine this one as some kind of

177
00:12:22,452 --> 00:12:26,634
available credits to the user which might be already applied

178
00:12:26,682 --> 00:12:30,366
by a voucher or

179
00:12:30,388 --> 00:12:34,098
something like that. So we will be using these

180
00:12:34,184 --> 00:12:37,586
credits and this will be also accessing to the

181
00:12:37,608 --> 00:12:41,486
user service. So let's try to add this basket

182
00:12:41,518 --> 00:12:45,174
and try to buy this product.

183
00:12:45,372 --> 00:12:48,742
So in this place,

184
00:12:48,796 --> 00:12:53,238
in this area, we will specify how many products

185
00:12:53,324 --> 00:12:56,886
that we are buying. Let's think that it will be. Let's imagine that it

186
00:12:56,908 --> 00:13:00,074
will be three. And you can see that this

187
00:13:00,112 --> 00:13:03,674
part will be deducted from your bank account. It means that

188
00:13:03,712 --> 00:13:07,126
in our application this amount will be deducted

189
00:13:07,158 --> 00:13:10,654
from the banking service. From the banking service.

190
00:13:10,852 --> 00:13:14,702
So we are trying to access banking service and

191
00:13:14,756 --> 00:13:18,654
this part will be deducted from your available user credits.

192
00:13:18,772 --> 00:13:23,220
So let's say that we will get 3000

193
00:13:23,830 --> 00:13:27,714
from our available user credits and the

194
00:13:27,752 --> 00:13:31,154
remaining 10,500 pounds from

195
00:13:31,192 --> 00:13:34,934
the bank account. When I click

196
00:13:35,132 --> 00:13:39,430
on buy now, this application intentionally

197
00:13:40,810 --> 00:13:44,226
throws an error on the banking

198
00:13:44,258 --> 00:13:48,002
service. So we will see an error

199
00:13:48,066 --> 00:13:52,426
here. But what we expect is actually in the dual write problem that

200
00:13:52,448 --> 00:13:56,266
we are trying to demonstrate. Since we have an issue on

201
00:13:56,288 --> 00:14:00,014
the banking service, we don't need to

202
00:14:00,052 --> 00:14:03,498
change the product, the quantity, the stock

203
00:14:03,674 --> 00:14:07,774
of the products since we haven't purchased these ones. And also

204
00:14:07,972 --> 00:14:11,726
we shouldn't see any issues with the available user

205
00:14:11,758 --> 00:14:16,030
credits. But since we don't have any transactional operation

206
00:14:16,110 --> 00:14:19,010
right now, we will have some problems.

207
00:14:19,160 --> 00:14:22,834
Let's click on buy now. Yes, we have

208
00:14:22,872 --> 00:14:26,534
seen the internal server error here. So let's go back to our

209
00:14:26,572 --> 00:14:30,630
main page. And now you can see that the product stock is now

210
00:14:30,700 --> 00:14:34,594
seven, which was ten in the beginning.

211
00:14:34,722 --> 00:14:38,730
Now we have three quantities

212
00:14:39,470 --> 00:14:43,542
left lost during the transaction.

213
00:14:43,686 --> 00:14:47,226
And also we can see that the current available user credit is

214
00:14:47,248 --> 00:14:50,874
7000, which should be 10,000. Because we haven't completed

215
00:14:50,922 --> 00:14:55,182
the transaction. We had issues on the banking service. So this is the

216
00:14:55,316 --> 00:14:58,654
representation of the demonstrations of the dual right

217
00:14:58,692 --> 00:15:03,422
problem. So what

218
00:15:03,476 --> 00:15:08,174
we need to do to figure out this problem. There are multiple approaches

219
00:15:08,222 --> 00:15:11,554
that you can use, but the most popular ones are the two phase commit and

220
00:15:11,592 --> 00:15:15,410
distributed sagas. We will start with the two phase commit.

221
00:15:16,630 --> 00:15:20,166
This two phase commit is actually very similar to

222
00:15:20,188 --> 00:15:24,466
the local transactions. It is trying to approach the local transaction

223
00:15:24,498 --> 00:15:28,410
approach to the distributed environment.

224
00:15:28,830 --> 00:15:32,378
You will have a coordinator and there will be two phases as

225
00:15:32,464 --> 00:15:36,410
mentioned in the name. The first phase will be the

226
00:15:36,480 --> 00:15:40,000
prepare phase. When the user try to

227
00:15:40,370 --> 00:15:43,790
start a transaction, the front end service

228
00:15:43,860 --> 00:15:47,680
will communicate to coordinator and the coordinator will

229
00:15:48,210 --> 00:15:52,174
start the first phase, the prepare phase. It will communicate to

230
00:15:52,212 --> 00:15:55,858
all of the services and ask for the changes to

231
00:15:55,864 --> 00:15:59,618
be ready. So they will make the changes ready

232
00:15:59,704 --> 00:16:03,458
and then they communicate back to the coordinator and say that yes,

233
00:16:03,544 --> 00:16:07,062
we are ready for the second phase. If any of the services

234
00:16:07,196 --> 00:16:10,760
fail in the first phase, then the coordinator will

235
00:16:11,370 --> 00:16:15,654
roll back the transaction by communicating again to the

236
00:16:15,692 --> 00:16:20,970
remaining services. But if every service says

237
00:16:21,040 --> 00:16:24,854
that we are ready for the commit phase, then the coordinator

238
00:16:24,902 --> 00:16:28,282
will fail. The coordinator will commit the transaction. Yeah,

239
00:16:28,336 --> 00:16:33,434
as we mentioned, for instance, when we banking service says

240
00:16:33,472 --> 00:16:36,766
that it is not ready, I cannot commit, there is a problem on my

241
00:16:36,788 --> 00:16:40,542
side. Then the coordinator will call to user service and product service

242
00:16:40,596 --> 00:16:42,260
to roll back their changes.

243
00:16:43,830 --> 00:16:47,074
The advantages of the two phase commit is that the

244
00:16:47,112 --> 00:16:53,506
strong data comes consistency. So you

245
00:16:53,528 --> 00:16:56,934
will have the consistent data at all

246
00:16:56,972 --> 00:17:00,294
times. And also you will have the read

247
00:17:00,332 --> 00:17:03,814
write isolation because you will

248
00:17:03,852 --> 00:17:06,520
not have any stale reads or something like that.

249
00:17:07,150 --> 00:17:10,986
But the negatives or the disadvantages of the two

250
00:17:11,008 --> 00:17:15,174
phase committee is that it is a blocking

251
00:17:15,222 --> 00:17:17,500
approach. So when it is running,

252
00:17:19,330 --> 00:17:22,030
when you started transaction,

253
00:17:23,010 --> 00:17:26,480
you won't be accessing the same

254
00:17:27,730 --> 00:17:30,400
records at the same time.

255
00:17:31,330 --> 00:17:34,930
So it will be running blocking, which is a really big negative

256
00:17:35,670 --> 00:17:39,090
in a distributed environment. Another thing is that your

257
00:17:39,160 --> 00:17:42,914
data sources should be xa compatible and you might

258
00:17:42,952 --> 00:17:46,098
have some scalability issues because of the coordinator.

259
00:17:46,194 --> 00:17:49,942
And also, again, since the coordinator is some kind of single

260
00:17:49,996 --> 00:17:54,002
point of failure, you need to handle the failures on the coordinator

261
00:17:54,146 --> 00:17:56,950
and figure out a solution.

262
00:17:58,350 --> 00:18:01,590
So the other approach is the distributed sagas,

263
00:18:01,750 --> 00:18:05,370
the distributed sagas that we will use also in our demonstration.

264
00:18:05,950 --> 00:18:09,454
So this is a more suitable approach for

265
00:18:09,492 --> 00:18:13,050
distributed environments because, you know, in the distributed environments,

266
00:18:13,210 --> 00:18:17,902
the applications are responsible for their own running

267
00:18:18,036 --> 00:18:21,858
without discussing any, without having to know

268
00:18:21,944 --> 00:18:25,426
of the others. So they are isolated from in some kind

269
00:18:25,448 --> 00:18:29,794
of terms. So again,

270
00:18:29,832 --> 00:18:33,570
in the distributed sagas, we can say that every service is

271
00:18:33,640 --> 00:18:37,414
responsible with its own transaction, and if it

272
00:18:37,452 --> 00:18:40,530
fails to perform the transaction, the operation,

273
00:18:40,610 --> 00:18:44,162
then it lets other know about its failure,

274
00:18:44,226 --> 00:18:47,834
and the other microservices will take care

275
00:18:47,872 --> 00:18:50,060
of the rest by themselves.

276
00:18:50,510 --> 00:18:55,498
Imagine that we have the

277
00:18:55,584 --> 00:18:58,794
same scenario. The user access the front end

278
00:18:58,832 --> 00:19:02,174
service and front end service will call, the application will

279
00:19:02,212 --> 00:19:05,920
start a transaction by just calling the services.

280
00:19:06,370 --> 00:19:10,222
The user service will start the transaction itself, the product service will

281
00:19:10,276 --> 00:19:13,860
start a transaction for itself, and the banking service will do so.

282
00:19:14,550 --> 00:19:18,034
And let's imagine that the banking service will fail again.

283
00:19:18,152 --> 00:19:21,794
When it fails, it will just call the

284
00:19:21,832 --> 00:19:25,334
compensation actions of the other services. So it will call the product service,

285
00:19:25,372 --> 00:19:29,922
and it will call the user service using their compensation calls.

286
00:19:30,066 --> 00:19:32,390
What's the compensation call? Actually?

287
00:19:32,460 --> 00:19:36,670
Compensation action. We can say that it is semantically undoes the action.

288
00:19:36,770 --> 00:19:41,274
So you need to develop another

289
00:19:41,472 --> 00:19:45,190
logic to undo the action.

290
00:19:45,350 --> 00:19:49,600
It might be kind of deleting a record from the database or

291
00:19:50,130 --> 00:19:53,214
changing the parameters or something like that.

292
00:19:53,412 --> 00:19:57,018
So it is not a proper rollback,

293
00:19:57,114 --> 00:20:00,430
but changing, semantically,

294
00:20:01,350 --> 00:20:05,490
changing the updates, rollbacking the updates.

295
00:20:06,390 --> 00:20:10,690
So this figure actually

296
00:20:10,840 --> 00:20:15,042
represents the saga better because

297
00:20:15,096 --> 00:20:18,946
it is just a serial

298
00:20:19,058 --> 00:20:22,374
run of multiple services. Imagine that you are

299
00:20:22,412 --> 00:20:25,654
becoming a trip, and when you are booking a trip, you need to first plan

300
00:20:25,692 --> 00:20:28,594
the meeting, then book the flights, then book the hotel,

301
00:20:28,642 --> 00:20:32,138
and then book the transport. And again,

302
00:20:32,224 --> 00:20:35,574
imagine that when you are using these operations,

303
00:20:35,702 --> 00:20:39,334
you plan the meeting successfully, then you book the flight successfully,

304
00:20:39,382 --> 00:20:42,714
but you had an issue with the when booking the hotel.

305
00:20:42,842 --> 00:20:46,814
So the hotel booking will cancel itself

306
00:20:46,932 --> 00:20:51,070
and then call the cancellation call

307
00:20:51,140 --> 00:20:54,786
of the book flight. So the book flights will be canceled and then

308
00:20:54,888 --> 00:20:58,354
the book flights will cancel the plan meeting by

309
00:20:58,392 --> 00:21:01,506
calling this compensation action. So this

310
00:21:01,528 --> 00:21:04,866
is the simple representation of

311
00:21:04,888 --> 00:21:08,614
the distributed sagas. We also need to mention about

312
00:21:08,652 --> 00:21:12,034
two approaches. There are two basic

313
00:21:12,082 --> 00:21:15,462
approaches on the distributed sagas. The first one is the orchestration, and the second

314
00:21:15,516 --> 00:21:18,822
one is the choreography approach. In the orchestration

315
00:21:18,886 --> 00:21:22,470
approach, there will be orchestrator

316
00:21:22,550 --> 00:21:27,770
to actually orchestrate manage the

317
00:21:27,840 --> 00:21:31,406
transaction itself. It's not the same thing in

318
00:21:31,428 --> 00:21:34,874
the two phase commit, the coordinator in this two phase commit,

319
00:21:35,002 --> 00:21:38,506
it just helps

320
00:21:38,618 --> 00:21:42,058
the distribute applications to communicate them,

321
00:21:42,244 --> 00:21:45,490
each of them. In the choreography approach,

322
00:21:45,990 --> 00:21:49,266
all of the services are responsible for

323
00:21:49,288 --> 00:21:53,166
their own, and they most likely use kind of event source

324
00:21:53,198 --> 00:21:56,440
or something like that to communicate each other.

325
00:21:57,850 --> 00:22:01,606
Yeah. The advantages of this sagas are, as you

326
00:22:01,628 --> 00:22:05,270
know, it is running asynchronous

327
00:22:05,610 --> 00:22:08,754
and it doesn't need a homogeneous environment.

328
00:22:08,802 --> 00:22:11,994
It can run with heterogeneous distributed components. And also

329
00:22:12,032 --> 00:22:14,330
we don't need any xa transactions,

330
00:22:15,790 --> 00:22:19,326
we don't need any xa specific thing. And also it is

331
00:22:19,348 --> 00:22:22,560
scalable because all of the

332
00:22:23,650 --> 00:22:28,506
applications, all of the services are running their own transaction

333
00:22:28,698 --> 00:22:32,070
or responsible from their own transaction.

334
00:22:32,250 --> 00:22:35,534
The disadvantages of the distributed sagas is the eventual

335
00:22:35,582 --> 00:22:39,410
consistency. There is no strong consistency in distributed sagas

336
00:22:40,390 --> 00:22:44,466
because at some time you

337
00:22:44,488 --> 00:22:47,522
can have some sale rates. For instance,

338
00:22:47,586 --> 00:22:50,786
imagine that when you have the issue with the banking

339
00:22:50,818 --> 00:22:54,582
service, when it has the failure, then you might be

340
00:22:54,716 --> 00:22:59,050
reaching the same related records in the user database

341
00:23:00,110 --> 00:23:04,038
from a different application, and you will be the updated

342
00:23:04,134 --> 00:23:07,706
information at the exact that time. So there

343
00:23:07,728 --> 00:23:10,090
will be also no write read isolation.

344
00:23:12,190 --> 00:23:15,486
Another issue with the distribution sagas is you need to develop

345
00:23:15,588 --> 00:23:19,006
a separate compensation function. You need to

346
00:23:19,028 --> 00:23:22,398
provide a separate logic for that one. There's no simple rollback,

347
00:23:22,494 --> 00:23:26,450
and you also need to handle the compensation failures.

348
00:23:27,990 --> 00:23:31,054
So let's talk about our solution.

349
00:23:31,182 --> 00:23:35,422
So we need to first discuss about, we need to talk about Istio,

350
00:23:35,566 --> 00:23:39,126
the architecture of Istio. As we mentioned

351
00:23:39,228 --> 00:23:42,578
in the beginning, the Istio

352
00:23:42,674 --> 00:23:46,574
actually is a service mesh that handles

353
00:23:46,642 --> 00:23:49,290
the service to service communication.

354
00:23:50,510 --> 00:23:53,738
So you can see that there are multiple pods in

355
00:23:53,744 --> 00:23:58,122
this system and there are two planes that we can mention.

356
00:23:58,256 --> 00:24:02,154
The first one is the control plane that runs the istio's

357
00:24:02,202 --> 00:24:05,534
own applications. And also in the

358
00:24:05,572 --> 00:24:09,166
data plane your applications will be

359
00:24:09,188 --> 00:24:13,114
running. And in the data plane on each pod

360
00:24:13,162 --> 00:24:17,454
there will be a proxy. Istio uses envy proxy to communicate,

361
00:24:17,502 --> 00:24:20,782
to hand over the communication.

362
00:24:20,926 --> 00:24:24,310
And here you can see that the ingress traffic comes into the

363
00:24:24,380 --> 00:24:27,734
applications and the proxy hands

364
00:24:27,772 --> 00:24:30,870
over that one and you can again

365
00:24:30,940 --> 00:24:34,534
see that there is no direct communication between service a

366
00:24:34,572 --> 00:24:37,858
to service b. It will be only happens

367
00:24:38,044 --> 00:24:41,306
through the proxies. So the east to

368
00:24:41,328 --> 00:24:44,826
west communication will be always happened between the

369
00:24:44,848 --> 00:24:48,730
proxies. Another feature that we'll be using

370
00:24:48,800 --> 00:24:51,482
is, will be the envoy proxy filter chains.

371
00:24:51,626 --> 00:24:55,310
This is a really useful feature of envoy that you can

372
00:24:55,380 --> 00:24:59,630
enhance or you can block the data communication.

373
00:25:00,290 --> 00:25:03,874
For instance, you can have some HTTP filters that you can

374
00:25:04,072 --> 00:25:08,260
add more information, some header, update the headers or

375
00:25:09,270 --> 00:25:12,514
change the data itself using these

376
00:25:12,552 --> 00:25:16,262
filters. Or you can even block or you can cut

377
00:25:16,316 --> 00:25:19,400
the circuit using these filters at any time.

378
00:25:21,530 --> 00:25:25,506
Our solution can be demonstrated

379
00:25:25,538 --> 00:25:28,762
like this. Again, we will have user service

380
00:25:28,816 --> 00:25:31,994
and product, service and banking services. In these pods we will

381
00:25:32,032 --> 00:25:36,518
have the envoy proxies provided by the istio

382
00:25:36,614 --> 00:25:40,266
service mesh. We will attach a filter

383
00:25:40,458 --> 00:25:44,298
to these envoy proxies and these filters

384
00:25:44,394 --> 00:25:47,966
will be communicating to our own application which will be

385
00:25:47,988 --> 00:25:49,440
calling propeller app.

386
00:25:50,850 --> 00:25:54,254
These filters will be providing information

387
00:25:54,372 --> 00:25:57,762
about the transaction and this propeller app will

388
00:25:57,816 --> 00:26:01,454
just store the transaction information on a hazelcast

389
00:26:01,502 --> 00:26:05,190
cluster. So let's see

390
00:26:05,260 --> 00:26:09,240
in action. Our application is still running

391
00:26:09,850 --> 00:26:12,914
and we can also see the Kiali console.

392
00:26:12,962 --> 00:26:16,514
Yeah, you can see that this is the

393
00:26:16,572 --> 00:26:20,394
previous run of our demonstration. So the ecommerce service,

394
00:26:20,512 --> 00:26:24,810
we access the ecommerce service and ecommerce service access to

395
00:26:24,880 --> 00:26:27,770
user, product and banking services accordingly.

396
00:26:28,850 --> 00:26:32,800
So here we will first create a

397
00:26:34,610 --> 00:26:37,854
hazardous cluster. This hazardous cluster will

398
00:26:37,892 --> 00:26:41,406
have three replicas and we will

399
00:26:41,428 --> 00:26:44,946
be accessing this hazardous cluster using a hazardous cluster service.

400
00:26:45,128 --> 00:26:48,786
And our propeller application will again have three

401
00:26:48,808 --> 00:26:53,598
replicas and it will be just storing

402
00:26:53,614 --> 00:26:57,990
the data of the transaction data in the hazardous cluster.

403
00:26:58,410 --> 00:27:01,958
So first let's start, let's apply the

404
00:27:02,044 --> 00:27:06,082
deployment, the configuration for the hazardous

405
00:27:06,146 --> 00:27:06,950
cluster.

406
00:27:14,870 --> 00:27:18,422
Okay, our hazardous cluster is being created and

407
00:27:18,476 --> 00:27:22,520
let's apply the propolar app

408
00:27:23,790 --> 00:27:27,670
configuration. Yeah, they are all being created.

409
00:27:27,830 --> 00:27:33,162
Let's check the services or

410
00:27:33,216 --> 00:27:34,300
pods first.

411
00:27:36,450 --> 00:27:40,234
They're all running. Yes, all of them are nearly

412
00:27:40,282 --> 00:27:44,400
running. The last instance of the proper rep

413
00:27:44,770 --> 00:27:47,694
is also ready. Let's check one last time.

414
00:27:47,812 --> 00:27:52,722
Everything is running and you can see two

415
00:27:52,776 --> 00:27:56,674
containers in each pod. One of them is the actual pod. The second one

416
00:27:56,712 --> 00:27:59,410
will be the envoy proxy.

417
00:28:00,310 --> 00:28:03,798
So what will we also do is as we also mentioned

418
00:28:03,884 --> 00:28:07,174
in the diagram, we will apply a

419
00:28:07,212 --> 00:28:11,062
filter to envy proxy. So let's first apply

420
00:28:11,116 --> 00:28:14,422
it and then discuss about details.

421
00:28:14,486 --> 00:28:18,566
It will be propeller filter yaml yeah it's

422
00:28:18,598 --> 00:28:22,614
created. So let's

423
00:28:22,662 --> 00:28:25,690
discuss about the propeller filter.

424
00:28:26,050 --> 00:28:29,950
This is the part that the transaction,

425
00:28:31,010 --> 00:28:34,958
the saga will be running on. So this is

426
00:28:35,044 --> 00:28:38,234
the kind of envoy filter. And this envoy

427
00:28:38,282 --> 00:28:42,660
filter is a custom resource provided by the istio and

428
00:28:45,430 --> 00:28:49,060
it's an HTTP filter. It is running at the HTTP level

429
00:28:49,510 --> 00:28:53,730
and it is inserted before the operation.

430
00:28:53,890 --> 00:28:57,430
So it will be running before the operation for each operation

431
00:28:58,330 --> 00:29:02,178
on the pods. So it's

432
00:29:02,194 --> 00:29:05,862
a Loa filter. You can have multiple options here,

433
00:29:05,996 --> 00:29:09,702
but I will be using LoA to implement

434
00:29:09,766 --> 00:29:13,820
this filter. So there are

435
00:29:14,510 --> 00:29:17,950
two functions, two main functions. One will be

436
00:29:18,020 --> 00:29:21,162
running on each request.

437
00:29:21,226 --> 00:29:25,934
The second one will be running on each response into

438
00:29:25,972 --> 00:29:29,698
the pod. So what will be on the request is

439
00:29:29,864 --> 00:29:33,986
we will just get the transaction id from the

440
00:29:34,008 --> 00:29:37,346
headers. And from this header we will

441
00:29:37,368 --> 00:29:40,580
get this transaction id and send it to the

442
00:29:41,690 --> 00:29:45,686
propeller app, which you can see here, there's a

443
00:29:45,708 --> 00:29:49,062
put key and value, just an entry. And here

444
00:29:49,116 --> 00:29:53,190
is the address of our internal address of our internal

445
00:29:53,770 --> 00:29:58,714
domain of the propeller app. The second function

446
00:29:58,832 --> 00:30:03,082
is actually on

447
00:30:03,136 --> 00:30:06,730
response function. On each response we will

448
00:30:06,800 --> 00:30:10,846
check the status of the HTTP status of the

449
00:30:10,868 --> 00:30:14,382
response. So if there's a failure on

450
00:30:14,436 --> 00:30:18,126
the response, if it is a failure, then we will say that we

451
00:30:18,148 --> 00:30:21,538
will call the compensation actions. How we will do that,

452
00:30:21,624 --> 00:30:25,426
we will get the transaction id again from the header and we

453
00:30:25,448 --> 00:30:29,714
will communicate the propeller app to

454
00:30:29,752 --> 00:30:33,202
get the information about the information about the

455
00:30:33,336 --> 00:30:37,014
current transaction. We will get the transaction information

456
00:30:37,132 --> 00:30:40,914
and for each endpoint we will call the compensate

457
00:30:40,962 --> 00:30:43,918
actions for this transaction.

458
00:30:44,114 --> 00:30:47,594
And so the compensation actions will be called.

459
00:30:47,792 --> 00:30:51,226
So again we will go and check our

460
00:30:51,408 --> 00:30:52,890
envoy filters.

461
00:30:56,590 --> 00:30:59,850
Yeah, this filter is applied.

462
00:30:59,930 --> 00:31:04,558
So let's try to demonstrate our demo

463
00:31:04,644 --> 00:31:08,334
again. So again, we have the

464
00:31:08,372 --> 00:31:12,322
same application as you most likely notice that

465
00:31:12,376 --> 00:31:15,714
we haven't redeployed our application. We have

466
00:31:15,752 --> 00:31:19,154
just applied filter. So let's try to.

467
00:31:19,192 --> 00:31:22,950
Again, you need to see that our current

468
00:31:23,020 --> 00:31:26,502
product stock is seven and available user credit is

469
00:31:26,556 --> 00:31:30,274
7000. So let's try to purchase

470
00:31:30,322 --> 00:31:34,026
this product again. For instance, this time I

471
00:31:34,048 --> 00:31:36,780
will get four of these products.

472
00:31:40,190 --> 00:31:43,594
Anyway, let's continue with this one and talk about it later.

473
00:31:43,712 --> 00:31:47,566
And also let's get the 5000

474
00:31:47,668 --> 00:31:50,480
from our user credits.

475
00:31:51,410 --> 00:31:54,014
So when I click on buy now,

476
00:31:54,212 --> 00:31:57,466
if the distribute

477
00:31:57,498 --> 00:32:01,554
stagger works then the product

478
00:32:01,752 --> 00:32:05,358
stock and the available user credits shouldn't be changed.

479
00:32:05,454 --> 00:32:09,202
It means that the product stock will stay at seven and

480
00:32:09,256 --> 00:32:12,742
the amount from the available user credits should be

481
00:32:12,796 --> 00:32:16,182
stay at 7000. Let's click on buy

482
00:32:16,236 --> 00:32:19,826
now. Yeah, we have the internal

483
00:32:19,858 --> 00:32:23,126
server error and when we go back yes, we can

484
00:32:23,148 --> 00:32:26,954
see that the distributed saga worked because we have

485
00:32:26,992 --> 00:32:30,506
rolled back the updates on the available user credits and

486
00:32:30,528 --> 00:32:34,842
we have rolled back the product stocked on the product

487
00:32:34,896 --> 00:32:38,366
service. And also we

488
00:32:38,388 --> 00:32:43,626
can check here, there's a detailed representation

489
00:32:43,738 --> 00:32:47,166
of the operation. You can see that the product

490
00:32:47,268 --> 00:32:50,530
propeller app is communicating to Helzikes cluster.

491
00:32:51,590 --> 00:32:55,042
The banking services failed. It is still not

492
00:32:55,096 --> 00:32:58,370
properly updated because we will see that the banking service

493
00:32:58,440 --> 00:33:02,422
will be communicating to proppler app and then this banking service

494
00:33:02,476 --> 00:33:06,630
will be also communicating to product service and user service in a few seconds.

495
00:33:07,690 --> 00:33:12,262
But let's continue what

496
00:33:12,316 --> 00:33:15,098
happens. Let's try to discuss what happens.

497
00:33:15,264 --> 00:33:22,762
So the banking service app return

498
00:33:22,816 --> 00:33:26,346
that HTTP 500 response and on the

499
00:33:26,368 --> 00:33:30,574
my proxy we

500
00:33:30,772 --> 00:33:34,878
intercept that response and then we check that

501
00:33:34,964 --> 00:33:39,470
since it is at 500 then we access

502
00:33:39,540 --> 00:33:43,850
the propul wrap, get the details of the transaction

503
00:33:43,930 --> 00:33:47,394
from the hazelcast cluster and then with

504
00:33:47,432 --> 00:33:51,338
the information that taken from the cluster

505
00:33:51,534 --> 00:33:54,854
we call the compensation actions on each service

506
00:33:54,972 --> 00:33:57,638
on which will be the product and user services.

507
00:33:57,804 --> 00:34:01,826
So the compensation actions worked and then we roll

508
00:34:01,858 --> 00:34:05,686
back the transaction. We can again. Yes, here is

509
00:34:05,708 --> 00:34:09,442
the updated version of the it's a pretty complicated

510
00:34:09,506 --> 00:34:13,350
one, but you can see that ecommerce service contacted to

511
00:34:13,420 --> 00:34:17,198
the profiler app and then it contacted the banking service.

512
00:34:17,364 --> 00:34:20,746
Sorry, the banking service contact the proposed app and then banking

513
00:34:20,778 --> 00:34:24,426
service get the call to compensation actions of the user

514
00:34:24,458 --> 00:34:25,840
service and product service.

515
00:34:28,450 --> 00:34:32,734
Yeah, this is the end of my talk and

516
00:34:32,852 --> 00:34:36,300
I hope you enjoyed it. Just I need to say that.

