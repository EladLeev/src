1
00:00:38,850 --> 00:00:42,434
Hello, my name is Misuthrukal. I'm a quality assurance automation engineer

2
00:00:42,482 --> 00:00:46,230
and in this session I want to talk about the importance of quality

3
00:00:46,300 --> 00:00:49,586
assurance in DevOps principles. We know that DevOps

4
00:00:49,618 --> 00:00:53,518
is trying to bring development activities and operations together

5
00:00:53,604 --> 00:00:57,210
or close to each other as much as possible. And quality assurance

6
00:00:57,290 --> 00:01:01,230
is an important touchstone in this discipline. I'm starting with a beautiful

7
00:01:01,300 --> 00:01:05,230
breed scene, which is not a coincidence because quality assurance

8
00:01:05,310 --> 00:01:09,342
is trying to find ways or channels between different parties

9
00:01:09,486 --> 00:01:13,106
and make the delivery or the transportation possible

10
00:01:13,208 --> 00:01:16,274
between these parties or the stakeholders. So what

11
00:01:16,312 --> 00:01:20,470
we will talk about in detail is, as we just briefly started,

12
00:01:20,620 --> 00:01:23,926
we will talk about the importance of the role or the

13
00:01:23,948 --> 00:01:27,462
place of quality assurance in DevOps. And then we will start talking

14
00:01:27,516 --> 00:01:30,826
about the problems or the challenges that we want to

15
00:01:30,848 --> 00:01:34,358
cope with, or in other words, the achievements or the targets

16
00:01:34,374 --> 00:01:38,810
that we want to hit and aligned with these problems or challenges or

17
00:01:38,880 --> 00:01:42,154
the achievements or the targets. We will talk about several

18
00:01:42,202 --> 00:01:45,294
metrics or dimensions of

19
00:01:45,332 --> 00:01:49,102
quality and I want to focus at least two

20
00:01:49,156 --> 00:01:52,506
fundamental categories, which are the speed and the

21
00:01:52,548 --> 00:01:55,694
reliability or the health of our quality assurance activities.

22
00:01:55,822 --> 00:01:59,726
And eventually we will talk about monitoring activities and aligned

23
00:01:59,758 --> 00:02:03,630
with this monitoring, how well we can fit ourselves

24
00:02:03,790 --> 00:02:07,174
into the product or the project goals, and how well

25
00:02:07,212 --> 00:02:10,818
we can fit in the bigger picture, right? Because as quality assurance

26
00:02:10,914 --> 00:02:14,738
we want to contribute to the product or the project goals.

27
00:02:14,834 --> 00:02:19,038
So how well we can align in this wider

28
00:02:19,234 --> 00:02:22,506
product or the project goal set and how well

29
00:02:22,528 --> 00:02:26,186
we can fit in the bigger picture. Starting from

30
00:02:26,208 --> 00:02:29,626
the role or the importance of quality assurance, let's first of

31
00:02:29,648 --> 00:02:33,210
all consider what we want to do from a wider perspective.

32
00:02:33,370 --> 00:02:36,766
We try to provide the best solution to our customers,

33
00:02:36,868 --> 00:02:39,818
right? But what is the definition of best solution?

34
00:02:39,914 --> 00:02:43,202
So this is the role of Kuala assurance. We try to

35
00:02:43,256 --> 00:02:46,866
ensure we are developing a set of functionalities which

36
00:02:46,888 --> 00:02:50,850
will meet customer expectancies. So sometimes we

37
00:02:50,920 --> 00:02:54,530
try to communicate directly with the end users or maybe the product

38
00:02:54,600 --> 00:02:58,326
owners or the product managers to understand what the

39
00:02:58,348 --> 00:03:02,194
users or the customers need or what they are expecting

40
00:03:02,242 --> 00:03:05,846
from this product. And sometimes we are trying to communicate with

41
00:03:05,868 --> 00:03:09,082
the development teams to understand in what ways they

42
00:03:09,136 --> 00:03:12,918
implemented these features or the functionalities.

43
00:03:13,094 --> 00:03:16,586
So this is why the communication skills are very important

44
00:03:16,688 --> 00:03:20,490
for quality assurance members, because we communicate with

45
00:03:20,560 --> 00:03:24,014
lots of different parties or stakeholders and sometimes we

46
00:03:24,052 --> 00:03:27,390
try to bring all of them together on the same page.

47
00:03:27,540 --> 00:03:31,642
And thinking from the modern project management methodologies,

48
00:03:31,786 --> 00:03:35,058
we know that we are trying to reduce the delivery time

49
00:03:35,144 --> 00:03:39,694
and increase the frequency of deliveries or the deployments.

50
00:03:39,822 --> 00:03:43,874
Because speed is very important. We are competing in time and

51
00:03:43,912 --> 00:03:47,158
in modern project management ways we try to do

52
00:03:47,244 --> 00:03:50,882
the continuous deliveries or the continuous integration activities.

53
00:03:51,026 --> 00:03:54,918
So in this perspective, quality assurance is very important because

54
00:03:55,004 --> 00:03:58,566
whenever we have a neat release candidate, we have to ensure

55
00:03:58,598 --> 00:04:02,406
the quality, not only the accuracy of the functionalities, but also lots

56
00:04:02,438 --> 00:04:05,546
of different quality aspects. We have to ensure, for example,

57
00:04:05,648 --> 00:04:09,702
performance, usability, maintainability, several abilities

58
00:04:09,766 --> 00:04:13,150
of quality dimensions, right? We have to check so

59
00:04:13,220 --> 00:04:17,566
with a proper and health quality assurance process this

60
00:04:17,588 --> 00:04:21,354
is possible. Otherwise there would be some risks whenever

61
00:04:21,402 --> 00:04:25,678
we do not perform the quality assurance activities. Whenever we have a new release candidate,

62
00:04:25,774 --> 00:04:29,618
there will be some potential risks or vulnerabilities and

63
00:04:29,704 --> 00:04:33,074
this would be possible only with a good, or maybe with

64
00:04:33,112 --> 00:04:37,000
an automated quality assurance process set

65
00:04:37,370 --> 00:04:40,754
and aligned with this perspective. Of course, in a scenario

66
00:04:40,802 --> 00:04:44,278
where the quality assurance teams or members are not involved in

67
00:04:44,364 --> 00:04:47,650
the whole development processes, we can understand that

68
00:04:47,740 --> 00:04:51,626
there would be some risks because all the quality

69
00:04:51,808 --> 00:04:54,646
goals or dimensions would not be covered.

70
00:04:54,758 --> 00:04:58,294
And whenever the new candidate or the features

71
00:04:58,342 --> 00:05:01,802
or the implementation would be merged into the production

72
00:05:01,866 --> 00:05:05,520
environment, there would be some risks which would be

73
00:05:06,050 --> 00:05:09,818
resulting in some critical consequences. In the later stages,

74
00:05:09,914 --> 00:05:14,114
we will discuss why this is important to find the

75
00:05:14,152 --> 00:05:18,002
vulnerabilities or the potential risks as early as possible

76
00:05:18,136 --> 00:05:21,426
in the next slides. But first of all,

77
00:05:21,448 --> 00:05:24,994
let's try to understand what kind of problems or challenges we have,

78
00:05:25,112 --> 00:05:28,534
because doing the problem definition in the first place

79
00:05:28,572 --> 00:05:32,578
is important. In this way we can understand in what ways we can contribute

80
00:05:32,674 --> 00:05:36,578
or bring value by understanding the challenges that we want to cope

81
00:05:36,594 --> 00:05:39,734
with. So nowadays the products that we are testing

82
00:05:39,782 --> 00:05:43,366
are really complex and complicated, right? Because they are deployed

83
00:05:43,398 --> 00:05:46,986
in different platforms or execution environments, which means they

84
00:05:47,008 --> 00:05:50,586
have several integrations and interfaces as well, because they

85
00:05:50,608 --> 00:05:54,634
are communicating to different applications as well. There is a large network

86
00:05:54,682 --> 00:05:58,442
of applications and we want to do our verification and validation

87
00:05:58,506 --> 00:06:01,998
activities in this comprehensive scope with different

88
00:06:02,084 --> 00:06:06,322
constraints and limitations. Because there is the time

89
00:06:06,456 --> 00:06:10,226
constraints, there is limited budget, limited resources, there are

90
00:06:10,248 --> 00:06:13,474
some different constraints as well. So thinking about all

91
00:06:13,512 --> 00:06:17,106
these problems and constraints and limitations, we can derive

92
00:06:17,138 --> 00:06:20,342
some different quality metrics to understand how

93
00:06:20,396 --> 00:06:23,542
well we are proceeding with our achievements or

94
00:06:23,596 --> 00:06:26,706
targets. And of course they should be aligned

95
00:06:26,738 --> 00:06:30,338
with the bigger perspective, the product metrics.

96
00:06:30,434 --> 00:06:34,134
So we can start with think and Dora metrics, which formulates

97
00:06:34,182 --> 00:06:37,914
a good set of product metrics. First of all, we can think

98
00:06:37,952 --> 00:06:41,298
of the speed of delivery and the quality of delivery.

99
00:06:41,414 --> 00:06:44,974
We want to provide a good set of functionalities which will

100
00:06:45,012 --> 00:06:48,606
cover the customer expectancies, but we want to do that with a

101
00:06:48,628 --> 00:06:51,882
good speed, ideally the continuous integration,

102
00:06:51,946 --> 00:06:55,378
right? As fast as possible. On the other hand,

103
00:06:55,464 --> 00:06:59,330
there should be a good quality. We should talk about several quality

104
00:06:59,400 --> 00:07:03,342
aspects, not only the accuracy of the functionalities, but also that the performance,

105
00:07:03,406 --> 00:07:07,890
usability and several quality aspects. So our quality metrics

106
00:07:08,050 --> 00:07:12,082
can be categorized in two fundamental groups, the speed

107
00:07:12,226 --> 00:07:16,182
and the reliability, or the quality of

108
00:07:16,236 --> 00:07:20,010
our features or functionalities. So we will discuss these

109
00:07:20,080 --> 00:07:23,370
two categories in detail. And let's start

110
00:07:23,440 --> 00:07:27,830
with the first one, the speed of our delivery.

111
00:07:27,910 --> 00:07:31,578
So there are several aspects or parameters that will affect the speed

112
00:07:31,594 --> 00:07:35,166
of our deliveries. First of all, the direct parameter, which is

113
00:07:35,188 --> 00:07:38,954
the execution of test cases, right? Because it is directly affecting

114
00:07:39,002 --> 00:07:42,526
our pipelines or delivery time. If the

115
00:07:42,548 --> 00:07:46,002
execution of the test cases are slow, which means they are taking

116
00:07:46,056 --> 00:07:50,194
too much time. Of course, after some time, everyone will

117
00:07:50,232 --> 00:07:53,746
start complaining about the test cases. They will say that whenever we

118
00:07:53,768 --> 00:07:57,482
have a new release candidate, of course we want to execute our test cases.

119
00:07:57,566 --> 00:08:00,886
But if execution is taking too much time, they will say that

120
00:08:00,908 --> 00:08:04,246
they are slowing down the pipelines. So execution of

121
00:08:04,268 --> 00:08:07,814
test cases is directly affecting the delivery time. So what

122
00:08:07,852 --> 00:08:11,850
we can do is we can do a time analysis and try to understand

123
00:08:11,920 --> 00:08:15,546
the slowly running test cases, and we can try to understand

124
00:08:15,648 --> 00:08:18,986
the points where it's slowing down the

125
00:08:19,008 --> 00:08:22,650
execution and trying to get rid of the unnecessary weights

126
00:08:22,730 --> 00:08:25,886
or dummy weights in our test cases. Along with

127
00:08:25,908 --> 00:08:29,806
that, on top of the analysis, what we can do is we can

128
00:08:29,828 --> 00:08:33,714
parallelize our test executions. We can divide our

129
00:08:33,752 --> 00:08:37,666
whole set into some subsets, and we can make our

130
00:08:37,688 --> 00:08:40,260
test cases independent from each other.

131
00:08:41,350 --> 00:08:45,242
In this way, we can enable the parallelization of test cases,

132
00:08:45,326 --> 00:08:49,238
and it will already decrease the total duration of our

133
00:08:49,324 --> 00:08:53,330
test execution. On the other hand, even the reliability

134
00:08:53,410 --> 00:08:56,518
is affecting our test execution time.

135
00:08:56,604 --> 00:09:00,710
Maybe it's not a direct parameter, but eventually

136
00:09:00,870 --> 00:09:04,186
how flaky our test cases will be

137
00:09:04,288 --> 00:09:07,466
affecting our test execution time. Because if we have some

138
00:09:07,488 --> 00:09:10,818
flaky tests, which means one time passing and one times failing,

139
00:09:10,934 --> 00:09:15,150
then eventually it means we will need some retries to

140
00:09:15,220 --> 00:09:19,614
retry the failing test cases to understand if they are still failing or

141
00:09:19,732 --> 00:09:23,510
they will start passing. So this means the retries

142
00:09:23,610 --> 00:09:26,946
will increase the total execution duration and it

143
00:09:26,968 --> 00:09:30,466
will affect the speed of our delivery. So in terms of

144
00:09:30,488 --> 00:09:33,618
reliability, we can discuss different conditions. For example,

145
00:09:33,704 --> 00:09:37,986
if our features are properly implemented,

146
00:09:38,098 --> 00:09:41,334
they are implemented as desired. But if our test

147
00:09:41,372 --> 00:09:44,626
case are failing, then it means it's a false alarm,

148
00:09:44,658 --> 00:09:48,278
right? Because our test case is failing. But normally the feature is

149
00:09:48,364 --> 00:09:52,074
implemented as expected. So this is not a real

150
00:09:52,112 --> 00:09:54,906
bug, this is a false alarm. So in this case,

151
00:09:55,008 --> 00:09:58,358
we have to retry our test case, and we have to get rid

152
00:09:58,374 --> 00:10:01,686
of this flaky test case, the false alarm.

153
00:10:01,798 --> 00:10:05,498
On the other hand, if our test case is just passing

154
00:10:05,594 --> 00:10:08,766
whenever there is an unexpected situation in the

155
00:10:08,788 --> 00:10:12,762
feature, in the implementation of the feature, it means there is a silent horror

156
00:10:12,826 --> 00:10:16,938
in our test cases. There is a potential risk

157
00:10:17,034 --> 00:10:20,626
vulnerability. But our test case is just passing, they are

158
00:10:20,648 --> 00:10:24,018
not capable of finding the issue. This is a silent horror case.

159
00:10:24,104 --> 00:10:27,462
So which means we will maybe just let the

160
00:10:27,596 --> 00:10:31,014
issue go in production and we will have some

161
00:10:31,052 --> 00:10:34,710
extra cost in the later stages. These are the reliability issues

162
00:10:34,860 --> 00:10:38,778
and which we don't want to have in our test

163
00:10:38,864 --> 00:10:42,330
execution environments or the test frameworks. But why

164
00:10:42,400 --> 00:10:45,642
do we have some reliable issues? Why we would

165
00:10:45,696 --> 00:10:49,254
have even the false alarms or the silent horror

166
00:10:49,302 --> 00:10:53,262
cases in our test environments or test frameworks? Because we

167
00:10:53,316 --> 00:10:56,814
might have several test smells, as we

168
00:10:56,852 --> 00:11:00,350
may have several smells in our product code.

169
00:11:00,500 --> 00:11:03,982
We can have different test smells in our test automation

170
00:11:04,046 --> 00:11:08,146
framework as well. There are several kinds of test smells, like some

171
00:11:08,168 --> 00:11:12,302
of them are related to test coverage, or some of them are related

172
00:11:12,366 --> 00:11:16,274
to different maintainability aspects of our test code.

173
00:11:16,392 --> 00:11:20,306
But we can get rid of all these kind of test smells to reduce

174
00:11:20,338 --> 00:11:23,894
the reliable issues in our test automation framework and

175
00:11:23,932 --> 00:11:27,970
to reduce these test smells. Of course we need some

176
00:11:28,060 --> 00:11:32,122
strong quality gates. Whenever we have some new test

177
00:11:32,176 --> 00:11:35,754
implementation, we have to check all the code quality even

178
00:11:35,792 --> 00:11:39,050
in our test code. And if we have some issues,

179
00:11:39,200 --> 00:11:42,606
then we have

180
00:11:42,628 --> 00:11:46,538
to stop that, and we don't want them to let go in production

181
00:11:46,634 --> 00:11:49,914
because otherwise there will be some critical consequences.

182
00:11:50,042 --> 00:11:53,454
Maybe there will be some silent horror cases, or maybe there

183
00:11:53,492 --> 00:11:57,894
will be some false alarms stemming from this kind of testimony.

184
00:11:57,962 --> 00:12:01,682
So if we have some quality gates, which can be either

185
00:12:01,736 --> 00:12:04,814
static code analysis or doing the code

186
00:12:04,952 --> 00:12:08,150
review activities, the peer review activities. But by

187
00:12:08,220 --> 00:12:11,720
enabling these kind of quality gates, we can already

188
00:12:12,410 --> 00:12:15,782
find the vulnerabilities even in the test code and

189
00:12:15,836 --> 00:12:19,554
stop them before merging into our test automation

190
00:12:19,602 --> 00:12:22,806
frameworks. So the execution speed of test cases

191
00:12:22,838 --> 00:12:26,474
is already affecting the delivery, but also the reliability of the test

192
00:12:26,512 --> 00:12:30,662
cases. Because whenever we have a failing test, we have to stop the pipeline

193
00:12:30,726 --> 00:12:34,094
and try to understand if the failure is a real bug or

194
00:12:34,132 --> 00:12:37,694
a false alarm. And even the maintainability of our test

195
00:12:37,732 --> 00:12:41,166
cases is affecting the delivery speed. Because whenever we have

196
00:12:41,188 --> 00:12:45,150
a false alarm, which means whenever we have an issue in the test itself,

197
00:12:45,300 --> 00:12:48,690
we have to fix the issue in our test code. And until

198
00:12:48,760 --> 00:12:51,746
we fix and we make the test passing again,

199
00:12:51,848 --> 00:12:55,762
we have to stop the pipeline. And whenever we make the test pass

200
00:12:55,816 --> 00:13:00,002
again, then we can continue with the delivery. So this means how easily

201
00:13:00,066 --> 00:13:03,238
we can fix the issue in the test or

202
00:13:03,324 --> 00:13:08,294
how easily we can maintain our test is

203
00:13:08,332 --> 00:13:12,234
a parameter that really affects the delivery speed. So how

204
00:13:12,272 --> 00:13:15,706
we can improve the maintainability a very well known example is the

205
00:13:15,728 --> 00:13:19,926
UI automation, right? Whenever the layout of the page is changing,

206
00:13:20,038 --> 00:13:24,046
then of course the selectors or the locators of our

207
00:13:24,148 --> 00:13:27,166
elements on the web page should be updated in the test code.

208
00:13:27,268 --> 00:13:31,102
And if we follow good coding practices or

209
00:13:31,156 --> 00:13:34,346
some patterns that will contribute to maintainability,

210
00:13:34,458 --> 00:13:37,566
then we can easily update, for example by excluding

211
00:13:37,598 --> 00:13:41,614
the locators from the test classes or the spec files, then we can easily

212
00:13:41,662 --> 00:13:45,194
do that. By following these kind of good practices

213
00:13:45,342 --> 00:13:48,786
or different approaches, we can try to improve

214
00:13:48,818 --> 00:13:52,786
the maintainability because otherwise it will be slowing

215
00:13:52,818 --> 00:13:56,534
down our pipelines to fix the issues in our test code.

216
00:13:56,652 --> 00:14:00,314
One more good practice to improve the maintainability is removing the

217
00:14:00,352 --> 00:14:03,866
duplication or avoiding the duplication. Because whenever we

218
00:14:03,888 --> 00:14:06,970
have repeated core or duplicated code in test spec

219
00:14:07,040 --> 00:14:09,994
files, then whenever we need an update or fix,

220
00:14:10,112 --> 00:14:14,334
then we have to go to all relevant piece of code

221
00:14:14,452 --> 00:14:18,366
and we have to fix in all of them. But if we have only one

222
00:14:18,468 --> 00:14:21,738
source of truth, for example a dedicated

223
00:14:21,834 --> 00:14:25,506
class file where the implementation is done, then we can go

224
00:14:25,528 --> 00:14:28,882
to the relevant part and fix the issue in

225
00:14:28,936 --> 00:14:32,898
only one source of truth. These kind of different

226
00:14:32,984 --> 00:14:36,214
approaches or good coding practices will help us to

227
00:14:36,252 --> 00:14:39,686
improve the maintenance. So summing up the first part in

228
00:14:39,708 --> 00:14:43,222
terms of the speed, of course we can improve our

229
00:14:43,276 --> 00:14:47,470
execution speed by enabling or embracing the parallelization

230
00:14:47,650 --> 00:14:50,986
or improving the reliability of test.

231
00:14:51,088 --> 00:14:55,414
By removing the test mass or even improving the maintainability

232
00:14:55,542 --> 00:14:58,646
will contribute the delivery of the speed.

233
00:14:58,838 --> 00:15:02,434
Now let's investigate the second aspect of the quality assurance activities,

234
00:15:02,502 --> 00:15:06,254
which is effective testing. How capable or how good our test

235
00:15:06,292 --> 00:15:10,206
cases are to find the issues in the early stages because we might

236
00:15:10,228 --> 00:15:13,790
have test cases running very fast or we might have 100%

237
00:15:13,860 --> 00:15:17,806
coverage metrics, but still we might have some escape bugs

238
00:15:17,838 --> 00:15:21,838
or escaped issues which were not found in our testing activities

239
00:15:21,934 --> 00:15:25,842
but just reported from the production environments. But what might

240
00:15:25,896 --> 00:15:29,414
we be missing or overlooking? What might be the reasons for having

241
00:15:29,452 --> 00:15:33,014
these escaped bugs? Because normally we try to cover all the test

242
00:15:33,052 --> 00:15:35,842
cases or all the features with test cases,

243
00:15:35,906 --> 00:15:39,334
but still we might have these kind of issues. So we have to

244
00:15:39,372 --> 00:15:42,954
go back to verification and validation distinction. Sometimes we

245
00:15:42,992 --> 00:15:47,382
just talk to the development teams and try to understand what is being implemented,

246
00:15:47,526 --> 00:15:51,206
but this is not the only thing that we have to ensure. Right on top

247
00:15:51,248 --> 00:15:54,890
of that, we have to understand if the implementations

248
00:15:54,970 --> 00:15:58,478
were already aligned with the requirements in the first place. This is

249
00:15:58,484 --> 00:16:02,142
the distinction between verification and validation. What is being

250
00:16:02,196 --> 00:16:06,194
implemented and what was supposed to be implemented. So this

251
00:16:06,232 --> 00:16:09,730
is aligned with the customer perspective and customer focus.

252
00:16:09,880 --> 00:16:13,742
So we have to understand what was expected or required

253
00:16:13,806 --> 00:16:17,134
by the customers and what are we delivering or providing

254
00:16:17,182 --> 00:16:20,466
as a solution to them. So to try to improve

255
00:16:20,498 --> 00:16:24,390
this mindset, we can ensure that we are running the correct

256
00:16:24,460 --> 00:16:28,834
scope. We have to update our test cases whenever we have a new implementation

257
00:16:28,962 --> 00:16:32,202
or whenever even we have a new refactoring on the code

258
00:16:32,256 --> 00:16:35,914
base. Then we can try to check if our test cases are

259
00:16:35,952 --> 00:16:39,658
up to date, or if we are running any or

260
00:16:39,744 --> 00:16:43,646
if we are running any coverage issues. But not only the test steps or

261
00:16:43,668 --> 00:16:47,870
the test context, but also the execution environment is very important

262
00:16:48,020 --> 00:16:51,440
because sometimes, for example, let's suppose we have a

263
00:16:51,890 --> 00:16:55,762
data upload feature. So this might be

264
00:16:55,816 --> 00:16:59,646
running with different data types or data ranges.

265
00:16:59,758 --> 00:17:03,742
So not only running with certain data types like integer

266
00:17:03,806 --> 00:17:07,186
values or string values, but also running with double values

267
00:17:07,218 --> 00:17:10,930
is also important. Or not only with positive values,

268
00:17:11,010 --> 00:17:15,506
but also negative values are also important. So supporting

269
00:17:15,538 --> 00:17:19,690
the test steps with the relevant test data or running

270
00:17:19,760 --> 00:17:23,590
in the correct or supposed potential execution

271
00:17:23,670 --> 00:17:27,514
environments is very important because sometimes different users are running

272
00:17:27,632 --> 00:17:31,582
on different browsers, with different devices, or with

273
00:17:31,636 --> 00:17:35,838
different operating systems. So not only running

274
00:17:35,924 --> 00:17:39,146
the correct test steps on a certain environment,

275
00:17:39,258 --> 00:17:42,902
but also running on different potential execution

276
00:17:42,986 --> 00:17:46,514
environments is also very important. So one

277
00:17:46,552 --> 00:17:50,580
more thing that we might try to follow to improve our

278
00:17:50,950 --> 00:17:54,290
test coverage is trying to embrace different test design

279
00:17:54,360 --> 00:17:58,494
techniques. There are some different techniques like equivalence partitioning

280
00:17:58,622 --> 00:18:01,090
or boundary value analysis,

281
00:18:01,530 --> 00:18:05,302
not to overlook some corner cases or boundary values or

282
00:18:05,356 --> 00:18:06,950
different data ranges.

283
00:18:08,190 --> 00:18:12,122
To avoid these kind of issues, embracing different test

284
00:18:12,176 --> 00:18:15,354
design techniques can be a good approach or a

285
00:18:15,392 --> 00:18:19,274
good test design pattern. But also

286
00:18:19,312 --> 00:18:22,534
there is one more thing that we can adapt in our quality assurance activities,

287
00:18:22,582 --> 00:18:26,158
which is the personnel based testing. By thinking of different

288
00:18:26,244 --> 00:18:30,618
personas or different characteristics, we can come up with different scenarios,

289
00:18:30,714 --> 00:18:34,654
for example, thinking of different users from different regions

290
00:18:34,782 --> 00:18:38,574
or different ages, or with different characteristics,

291
00:18:38,622 --> 00:18:42,846
with different activities or motivations or frustrations,

292
00:18:42,958 --> 00:18:46,982
we can think of different use cases or different

293
00:18:47,036 --> 00:18:51,382
scenarios. So in this case we try to avoid having or

294
00:18:51,516 --> 00:18:55,126
overlooking some different scenarios. For example, aligned with

295
00:18:55,148 --> 00:18:58,378
this, we can come up with, for example,

296
00:18:58,464 --> 00:19:02,374
for different people, maybe the accessibility

297
00:19:02,502 --> 00:19:05,626
or the performance is more important than

298
00:19:05,728 --> 00:19:09,546
other aspects, or for other users maybe the

299
00:19:09,568 --> 00:19:13,242
usability or the user friendliness of the interfaces

300
00:19:13,306 --> 00:19:17,166
is more important. So in this way we can try to cover all

301
00:19:17,188 --> 00:19:21,130
the aspects of the quality, not only the functionality,

302
00:19:21,210 --> 00:19:24,590
but also all the non functional aspects would be covered

303
00:19:24,670 --> 00:19:28,914
by thinking from different perspectives and trying to understand

304
00:19:29,112 --> 00:19:33,042
all kinds of or types of different use flows in

305
00:19:33,096 --> 00:19:36,722
our product or on our feature.

306
00:19:36,786 --> 00:19:39,974
Lets we try to discuss the

307
00:19:40,012 --> 00:19:43,990
quality assurance improvements that we can do to contribute or bring value

308
00:19:44,060 --> 00:19:47,414
to the product perspective. Right? We try to provide

309
00:19:47,532 --> 00:19:51,014
or support the deliveries from two different fundamental

310
00:19:51,062 --> 00:19:54,554
aspects, which is the speed and quality, because we want to have

311
00:19:54,592 --> 00:19:58,154
a fast and high quality delivery and we try

312
00:19:58,192 --> 00:20:01,514
to support it from the quality assurance perspective. But how

313
00:20:01,552 --> 00:20:05,134
can we ensure that we are proceeding in the correct direction? Of course

314
00:20:05,172 --> 00:20:09,098
we can utilize monitoring activities and we can collect several metrics

315
00:20:09,194 --> 00:20:13,562
to understand how well we are proceeding in these dimensions

316
00:20:13,626 --> 00:20:17,202
or the aspects of quality. And we can talk about

317
00:20:17,256 --> 00:20:21,122
several different metrics. But one of the first metrics set

318
00:20:21,176 --> 00:20:24,706
from the quality perspective is the issues or the bugs that

319
00:20:24,728 --> 00:20:28,774
we have because it will directly give an idea about how quality

320
00:20:28,892 --> 00:20:32,502
how level of quality we have in our products

321
00:20:32,636 --> 00:20:36,226
or the feature sets. So we can show different distribution

322
00:20:36,258 --> 00:20:40,342
of bugs across their severity levels or across the component

323
00:20:40,406 --> 00:20:44,122
on which they were found or the module on which

324
00:20:44,176 --> 00:20:47,866
the bugs were found. But apart from those, I want to

325
00:20:47,888 --> 00:20:51,534
highlight the importance of having the post mortems which

326
00:20:51,572 --> 00:20:55,294
is kind of trying to understand or trying to interpret them,

327
00:20:55,412 --> 00:20:59,082
trying to talk to them, because bugs have several meaningful

328
00:20:59,146 --> 00:21:02,654
or valuable information. Understand. And if we try

329
00:21:02,692 --> 00:21:06,446
to understand what they are trying to tell us, then we can collect

330
00:21:06,478 --> 00:21:10,238
some insights and we can try to reveal some weaknesses

331
00:21:10,334 --> 00:21:14,354
in our processes and the product. And we can try to introduce some

332
00:21:14,392 --> 00:21:18,598
new initiatives and improvements for the future activities. Because quality

333
00:21:18,684 --> 00:21:22,374
assurance is not only finding the bugs, this is already good enough,

334
00:21:22,492 --> 00:21:26,194
but also trying to avoid them in the future activities.

335
00:21:26,322 --> 00:21:29,818
If we try to interpret the previously created bugs, then we

336
00:21:29,824 --> 00:21:33,354
can try to understand what kind of weaknesses we had in

337
00:21:33,392 --> 00:21:36,746
our past activities. And by trying to improve them,

338
00:21:36,848 --> 00:21:40,234
trying to create some new initiatives, we can try

339
00:21:40,272 --> 00:21:44,170
to avoid them in the first place in our future activities

340
00:21:44,250 --> 00:21:47,466
as well. So not only the bugs of course, we can call several

341
00:21:47,498 --> 00:21:51,674
other metrics as well. So what we can do is we can transform

342
00:21:51,722 --> 00:21:55,454
them into some visual graphs or charts and monitoring

343
00:21:55,502 --> 00:21:58,786
dashboards. Because sometimes interpreting the raw data is

344
00:21:58,808 --> 00:22:02,350
not easy. But if we have some visuals then we can easily

345
00:22:02,430 --> 00:22:05,746
understand what is going on in our environments and what kind

346
00:22:05,768 --> 00:22:08,854
of trends or charts we have. And we can

347
00:22:08,892 --> 00:22:12,406
try to collect some insights about the health of

348
00:22:12,428 --> 00:22:16,534
our processes and the product and the processes and try to

349
00:22:16,572 --> 00:22:19,720
improve them for the future activities as well.

350
00:22:20,090 --> 00:22:23,574
So to sum up, we tried to discuss the role or the importance

351
00:22:23,622 --> 00:22:27,418
of quality assurance in DevOps practices. We discussed the problems or the

352
00:22:27,424 --> 00:22:31,706
challenges we have and we discussed the ways to contribute

353
00:22:31,818 --> 00:22:35,662
to our product goals from quality assurance perspective. For example,

354
00:22:35,716 --> 00:22:38,890
we discussed how we can support fast delivery

355
00:22:38,970 --> 00:22:42,622
in terms of the execution speed. We try to improve the test

356
00:22:42,676 --> 00:22:46,354
execution duration or test execution time, and we try to

357
00:22:46,392 --> 00:22:49,986
reduce the number of false alarms because whenever we have them we have

358
00:22:50,008 --> 00:22:53,438
to stop the pipelines. Or whenever we stop the pipeline,

359
00:22:53,534 --> 00:22:57,842
we try to fix the issues in the test code. So we discuss the importance

360
00:22:57,906 --> 00:23:01,558
of improving the maintainability of test code because

361
00:23:01,724 --> 00:23:05,254
that would directly affect the time where we stop our

362
00:23:05,292 --> 00:23:09,194
pipelines. On the other hand, we discussed ways to support the

363
00:23:09,232 --> 00:23:12,602
quality of our deliveries whenever we have some reliability issues

364
00:23:12,656 --> 00:23:15,830
or coverage issues. We might have some escape bugs,

365
00:23:15,910 --> 00:23:19,322
but we discussed ways to embrace different test

366
00:23:19,376 --> 00:23:23,134
design techniques, or embracing different Persona based test

367
00:23:23,332 --> 00:23:27,342
techniques or different approaches to improve our

368
00:23:27,396 --> 00:23:31,374
coverage and the reliability of test framework or test environment or test

369
00:23:31,412 --> 00:23:34,954
set to avoid those kind of issues. And eventually,

370
00:23:35,002 --> 00:23:38,426
we discussed importance of continuous monitoring

371
00:23:38,538 --> 00:23:42,330
to continuously get some insights about potential

372
00:23:42,410 --> 00:23:46,246
improvements that we can embrace in our processes and

373
00:23:46,348 --> 00:23:50,226
the quality of our products. So thanks a lot for listening

374
00:23:50,258 --> 00:23:53,654
to me and if you have any questions or feedback, I would be more than

375
00:23:53,692 --> 00:23:55,540
glad to try to answer them.

