1
00:00:22,010 --> 00:00:25,074
Hi everyone. My name is Melissa McGregor,

2
00:00:25,162 --> 00:00:29,266
and I'm a developer advocate at iterative AI.

3
00:00:29,378 --> 00:00:33,174
But I specifically work on DVC, which is

4
00:00:33,292 --> 00:00:36,662
a data version control like open

5
00:00:36,716 --> 00:00:40,182
source tool you can use to, well,

6
00:00:40,236 --> 00:00:44,070
version control your machine learning projects. But today

7
00:00:44,140 --> 00:00:47,634
I'm going to talk to you about convolutional neural networks

8
00:00:47,682 --> 00:00:51,150
in action. If you have any questions at any point,

9
00:00:51,220 --> 00:00:54,538
feel free to reach out to me personally on Twitter

10
00:00:54,634 --> 00:00:58,142
at flipped coding, or you can reach out to the whole team

11
00:00:58,276 --> 00:01:01,406
on twitter@dvc.org but

12
00:01:01,508 --> 00:01:05,234
just so you have a little background about me, I have my

13
00:01:05,272 --> 00:01:08,398
master's in mechanical and aerospace engineering.

14
00:01:08,494 --> 00:01:12,158
Then I did some machine learning work in robotics,

15
00:01:12,254 --> 00:01:16,294
where I was able to work on this cool autonomous car that

16
00:01:16,412 --> 00:01:19,826
interfaced with pedestrians and passengers.

17
00:01:19,938 --> 00:01:22,710
And from there I've done things on front end,

18
00:01:22,780 --> 00:01:25,698
back end, DevOps, database,

19
00:01:25,794 --> 00:01:29,014
admin stuff. I've just kind of been all over the place in

20
00:01:29,052 --> 00:01:32,730
tech. But convolutional neural networks are actually

21
00:01:32,800 --> 00:01:36,486
something that I work with a lot on my personal projects,

22
00:01:36,598 --> 00:01:40,026
which probably says a lot about what I do with my free time.

23
00:01:40,128 --> 00:01:44,046
But I wanted to talk about them with you all so that you

24
00:01:44,068 --> 00:01:47,530
can see how they're actually used in action.

25
00:01:47,690 --> 00:01:51,198
So just a quick overview of what we'll be talking about today.

26
00:01:51,364 --> 00:01:55,266
I'll give a quick background on neural networks in general.

27
00:01:55,448 --> 00:01:59,134
Then we'll go over some basics of cnns,

28
00:01:59,262 --> 00:02:02,814
and I'll touch on a few use cases for cnns,

29
00:02:02,942 --> 00:02:06,482
and we'll actually make one. Well, I'll walk

30
00:02:06,536 --> 00:02:10,546
through the code that you would use to make a CNN in Python.

31
00:02:10,658 --> 00:02:13,874
And we'll run just one quick training experiment

32
00:02:13,922 --> 00:02:17,494
with DBC so we can look at how well our

33
00:02:17,532 --> 00:02:20,874
model actually is. And finally, I'll wrap up with

34
00:02:20,912 --> 00:02:24,602
just a few key takeaways, some stuff that I really

35
00:02:24,656 --> 00:02:28,186
hope helps you after this is over. So to

36
00:02:28,208 --> 00:02:31,706
get started, little background on neural networks.

37
00:02:31,898 --> 00:02:35,902
These are basically just algorithms that can be used to make

38
00:02:35,956 --> 00:02:39,886
predictions. So they're made of these

39
00:02:40,068 --> 00:02:43,386
multiple layers of nodes. And this is

40
00:02:43,428 --> 00:02:46,562
what one node looks like. So the goal of

41
00:02:46,616 --> 00:02:49,694
a neural network is to take advantage of deep

42
00:02:49,742 --> 00:02:53,106
learning to try and imitate the

43
00:02:53,128 --> 00:02:56,470
way our brain works. So each node can be

44
00:02:56,620 --> 00:03:00,470
like a node in your brain or a neuron or something.

45
00:03:00,620 --> 00:03:03,666
You give it a certain number of inputs,

46
00:03:03,778 --> 00:03:07,442
and these a value is assigned to how important those

47
00:03:07,516 --> 00:03:10,854
inputs are to the problem you're trying to solve.

48
00:03:10,982 --> 00:03:14,666
Then some crazy math happens, and you go through an

49
00:03:14,688 --> 00:03:18,406
activation function to finally get your output

50
00:03:18,518 --> 00:03:22,030
or your prediction or whatever it is you're looking

51
00:03:22,100 --> 00:03:26,122
for. Now let's talk about some basics of CNNs.

52
00:03:26,266 --> 00:03:30,442
So convolutional neural networks, network has convolutions.

53
00:03:30,586 --> 00:03:33,938
And these are just math. So it's a

54
00:03:33,944 --> 00:03:37,214
linear operation that uses

55
00:03:37,342 --> 00:03:41,006
multiplication on set weights with inputs.

56
00:03:41,118 --> 00:03:44,814
But basically that means the filter is smaller

57
00:03:44,862 --> 00:03:48,854
than the input data. So you take the

58
00:03:48,892 --> 00:03:52,230
multiplication between youll filter

59
00:03:52,730 --> 00:03:56,434
and the filter itself, like the filter

60
00:03:56,482 --> 00:04:00,150
patch. So the little part of the image that your

61
00:04:00,220 --> 00:04:04,026
CNN is going over, you take the filter patch and the

62
00:04:04,048 --> 00:04:07,466
filter and you get the dot product. But here's a

63
00:04:07,488 --> 00:04:11,422
picture to show what that looks like a little bit better. So these

64
00:04:11,476 --> 00:04:15,258
squares that you see in orange or yellow,

65
00:04:15,354 --> 00:04:19,386
I'm not sure which color that is. But the squares

66
00:04:19,418 --> 00:04:23,298
that youll see in there are actually the

67
00:04:23,464 --> 00:04:26,994
filter sized patch of the image. And the

68
00:04:27,032 --> 00:04:30,370
filter itself is this three by three

69
00:04:30,440 --> 00:04:34,274
matrix that is over that image. And as

70
00:04:34,312 --> 00:04:37,670
we perform these convolutions, you go across,

71
00:04:37,740 --> 00:04:41,426
youll image in a step called a stride.

72
00:04:41,538 --> 00:04:44,774
So if you have a stride length of one,

73
00:04:44,892 --> 00:04:48,214
you would just can from this three x three

74
00:04:48,252 --> 00:04:52,362
section, and then you'd shift the whole three by three matrix over

75
00:04:52,416 --> 00:04:55,674
to these next set of three squares until you

76
00:04:55,712 --> 00:04:59,306
run out. And then you drop down to the next row and youll

77
00:04:59,408 --> 00:05:03,166
repeat until youll have scanned these whole image with

78
00:05:03,188 --> 00:05:07,194
that filter. So when you do have your convolved

79
00:05:07,242 --> 00:05:11,274
feature at the end, basically this is just a smaller

80
00:05:11,322 --> 00:05:14,546
representation of what that image is.

81
00:05:14,648 --> 00:05:18,386
So usually we're using convolutions to pick out

82
00:05:18,488 --> 00:05:23,026
the features in these photo like edges or maybe

83
00:05:23,128 --> 00:05:26,822
large landscape features, things that

84
00:05:26,956 --> 00:05:31,094
are really big and help define the

85
00:05:31,132 --> 00:05:34,578
overall image. Basically, because with CNNs,

86
00:05:34,674 --> 00:05:38,618
the gap that they fill in is that when you have just

87
00:05:38,704 --> 00:05:42,758
a regular neural network or you're using some kind of other algorithm

88
00:05:42,854 --> 00:05:46,522
to classify images, they might

89
00:05:46,576 --> 00:05:50,698
take that image and make it into this one dimensional thing,

90
00:05:50,864 --> 00:05:54,574
which if you take an image and make it 1d,

91
00:05:54,692 --> 00:05:57,738
it takes a lot away from the context.

92
00:05:57,914 --> 00:06:01,166
So you need to have at least two dimensions with

93
00:06:01,188 --> 00:06:05,950
your images so that you get that spatial and temporal

94
00:06:06,030 --> 00:06:09,758
perspective of what's actually happening in these image.

95
00:06:09,854 --> 00:06:13,250
And when we use convolutions, it helps us

96
00:06:13,400 --> 00:06:17,794
both take advantage of a lot of the preprocessing

97
00:06:17,842 --> 00:06:21,318
that we get with CNNS. And it helps us

98
00:06:21,404 --> 00:06:25,074
get through our data faster because it takes these image

99
00:06:25,122 --> 00:06:28,682
and it squeezes it down into the features that

100
00:06:28,736 --> 00:06:33,050
really matter. That's what we're doing with our convolutions. So something

101
00:06:33,120 --> 00:06:37,046
else that's a major part of CNN's

102
00:06:37,158 --> 00:06:40,922
is the max pooling layer or multiple layers,

103
00:06:40,986 --> 00:06:43,422
if that's what your model needs.

104
00:06:43,556 --> 00:06:47,482
But max pooling is actually how we decrease

105
00:06:47,626 --> 00:06:51,246
our computational load that we need to process all

106
00:06:51,268 --> 00:06:55,342
of our data. So the way that this works, it returns

107
00:06:55,406 --> 00:06:58,706
the max value from the portion of

108
00:06:58,728 --> 00:07:02,034
the image covered by the kernel. So if I

109
00:07:02,072 --> 00:07:05,958
go back to this, the filter that's over

110
00:07:06,044 --> 00:07:10,354
our orange area is the kernel. So our kernel

111
00:07:10,482 --> 00:07:14,882
is three, because we have this three by three chunk

112
00:07:14,946 --> 00:07:19,114
out of this element. And what this is saying is that

113
00:07:19,232 --> 00:07:23,450
it returns the largest value from that

114
00:07:23,520 --> 00:07:26,986
kernel. So with this one, this might not be

115
00:07:27,008 --> 00:07:30,942
the best example. This is a picture for something else, but this would

116
00:07:30,996 --> 00:07:34,762
return a one here just because that would be the largest

117
00:07:34,826 --> 00:07:38,234
number in this filter size patch.

118
00:07:38,362 --> 00:07:41,802
So that's what's meant by max pooling.

119
00:07:41,946 --> 00:07:45,822
And when it's choosing this maximum

120
00:07:45,886 --> 00:07:50,286
value from the kernel, this helps act as a noise suppressant,

121
00:07:50,398 --> 00:07:53,982
so that max value represents some really bold

122
00:07:54,046 --> 00:07:57,222
feature in an image. For example, that might

123
00:07:57,276 --> 00:08:01,206
be a large these, that really cases up

124
00:08:01,308 --> 00:08:04,934
a good chunk of an image. Or it could be something

125
00:08:05,052 --> 00:08:08,506
like a person that's standing in

126
00:08:08,528 --> 00:08:12,442
these foreground of an image it's going through and

127
00:08:12,496 --> 00:08:16,234
picking. But the most important features in each of

128
00:08:16,272 --> 00:08:19,434
those kernels as we go through the

129
00:08:19,472 --> 00:08:23,210
image with our convolution scan.

130
00:08:23,370 --> 00:08:26,654
So there are a lot of different types of CNNs. It just

131
00:08:26,692 --> 00:08:30,586
depends on the model you need and the problem you're trying to tackle.

132
00:08:30,698 --> 00:08:34,894
And 1D CNNs are usually used on time series

133
00:08:34,942 --> 00:08:37,950
data. Like I mentioned a little bit earlier,

134
00:08:38,110 --> 00:08:42,062
1D isn't the greatest to process images

135
00:08:42,206 --> 00:08:46,446
just because you lose a lot of context of what's happening in an image.

136
00:08:46,558 --> 00:08:49,606
But if you have some kind of time series data,

137
00:08:49,708 --> 00:08:53,446
like maybe, I don't know why you would be interested in

138
00:08:53,468 --> 00:08:56,770
the weather changing in a way that you would need a CNN,

139
00:08:56,850 --> 00:09:01,114
but I'm sure there's an application for it. So anything that

140
00:09:01,152 --> 00:09:04,310
is time dependent, one CNNs

141
00:09:04,470 --> 00:09:08,326
will probably do a good job. And then two CNNs,

142
00:09:08,358 --> 00:09:12,030
which is what we've been talking about the most. These are used

143
00:09:12,100 --> 00:09:15,520
with image labeling, classification problems.

144
00:09:16,210 --> 00:09:19,966
It's kind of like the standard when we're trying

145
00:09:19,988 --> 00:09:23,442
to classify images now and then there

146
00:09:23,496 --> 00:09:27,586
are three dimensional CNNs. This is getting

147
00:09:27,688 --> 00:09:31,554
into some more high tech imagery. So you'll see

148
00:09:31,592 --> 00:09:35,634
these a lot in healthcare with things like ct scans

149
00:09:35,682 --> 00:09:39,478
and mris. Youll probably see it in some kind of

150
00:09:39,644 --> 00:09:42,998
crazy advanced scientific labs where they're doing

151
00:09:43,084 --> 00:09:45,766
stuff with electric fields, maybe.

152
00:09:45,948 --> 00:09:49,394
Not sure. Whatever it is that they use to make

153
00:09:49,452 --> 00:09:52,874
three d images, you might be able to process it

154
00:09:52,912 --> 00:09:56,890
with a 3d CNN, and you've seen what a 2d

155
00:09:56,960 --> 00:10:01,194
CNN looks like. When you're scanning through with the convolutions and

156
00:10:01,232 --> 00:10:04,974
doing your maxpooling. But a 3d CNN would

157
00:10:05,012 --> 00:10:08,842
look like a cube, and you would scan through different chunks

158
00:10:08,906 --> 00:10:12,534
of that cube and do your convolutions and your max

159
00:10:12,602 --> 00:10:16,162
pooling to get the most important features out of it.

160
00:10:16,216 --> 00:10:19,682
So that's how they use 3d CNNs for things

161
00:10:19,736 --> 00:10:23,662
like tumor detection or weird

162
00:10:23,806 --> 00:10:27,720
tissue issues. Tissue issues,

163
00:10:28,570 --> 00:10:32,130
sorry. But that is a real practical

164
00:10:32,210 --> 00:10:35,378
use for convolutional neural sets.

165
00:10:35,554 --> 00:10:39,498
And just so we're clear, there's a few differences between

166
00:10:39,584 --> 00:10:43,354
convolutional neural nets and regular ones. But a big one

167
00:10:43,392 --> 00:10:46,822
is that CNN save time on pre processing

168
00:10:46,886 --> 00:10:50,702
data. So when they're scanning through the

169
00:10:50,756 --> 00:10:54,106
image and looking at the kernels,

170
00:10:54,218 --> 00:10:57,374
it's actually doing some feature extraction for us.

171
00:10:57,492 --> 00:11:01,994
So you don't have to have a predefined

172
00:11:02,122 --> 00:11:04,802
set of features that you're looking for.

173
00:11:04,936 --> 00:11:08,290
CNNs do this discovery as they're going

174
00:11:08,360 --> 00:11:12,194
along. And I just spoke a little bit ahead of my

175
00:11:12,232 --> 00:11:15,894
second bullet point, but that's okay. But like I was saying,

176
00:11:16,012 --> 00:11:20,642
CNNs, they figure out the important characteristics

177
00:11:20,786 --> 00:11:24,918
as they go through that convolutional part

178
00:11:25,084 --> 00:11:28,650
of the process. But there is

179
00:11:28,720 --> 00:11:32,042
one thing where neural nets do shine a little bit

180
00:11:32,096 --> 00:11:36,170
more than CNNs, and that's when you don't have super

181
00:11:36,240 --> 00:11:39,974
large data sets. So typically anything

182
00:11:40,112 --> 00:11:44,090
under, I think it was 10,000 images.

183
00:11:44,170 --> 00:11:48,378
You might not get the best accuracy with cnns.

184
00:11:48,474 --> 00:11:52,158
So convolutional neural nets do need a

185
00:11:52,164 --> 00:11:56,446
lot more data than regular neural nets to be super effective.

186
00:11:56,638 --> 00:12:00,206
So here's a few use cases for CNNs.

187
00:12:00,398 --> 00:12:04,270
Maybe you want to recognize different handwriting,

188
00:12:04,430 --> 00:12:08,214
which kind of segues into the MNIsT example that

189
00:12:08,252 --> 00:12:11,634
we'll be going through shortly. Or maybe you're

190
00:12:11,682 --> 00:12:14,806
working on something like an autonomous car.

191
00:12:14,908 --> 00:12:18,650
Or maybe you're trying to get a computer to

192
00:12:18,720 --> 00:12:22,166
identify certain parts as they pass a camera.

193
00:12:22,358 --> 00:12:26,566
This is one of those times you would consider a convolutional,

194
00:12:26,758 --> 00:12:30,214
convolutional neural networks net. And you

195
00:12:30,272 --> 00:12:34,266
might also use this to help prevent bank fraud.

196
00:12:34,378 --> 00:12:38,990
So reading the digits on checks is actually a really important thing.

197
00:12:39,140 --> 00:12:42,550
If you've ever deposited a check in an ATM

198
00:12:42,650 --> 00:12:46,002
or on a mobile app, there's probably been some

199
00:12:46,056 --> 00:12:49,714
kind of CNN behind that. And again,

200
00:12:49,912 --> 00:12:53,442
post offices have a lot of mail that these

201
00:12:53,496 --> 00:12:57,110
handle throughout the day, so they need some help

202
00:12:57,180 --> 00:13:00,610
when things are going down. Conveyor belts, I imagine.

203
00:13:00,770 --> 00:13:04,166
So youll know, it needs to make sure that the

204
00:13:04,188 --> 00:13:07,414
zip codes make sense and addresses make

205
00:13:07,452 --> 00:13:10,858
sense for handwritten letters or even

206
00:13:11,024 --> 00:13:14,486
labels that have been printed off still need to be processed.

207
00:13:14,598 --> 00:13:18,266
And this is where CNNs really shine. So now for

208
00:13:18,288 --> 00:13:22,538
the fun part. I tested this literally

209
00:13:22,714 --> 00:13:26,478
1 minute before I started this talk.

210
00:13:26,644 --> 00:13:29,646
So this live demo should work,

211
00:13:29,748 --> 00:13:33,220
but we'll see how things go. Let me

212
00:13:33,590 --> 00:13:36,350
go ahead and switch screens.

213
00:13:36,510 --> 00:13:40,738
Okay, so you can see my instance of vs code.

214
00:13:40,904 --> 00:13:43,746
And I want to make sure to emphasize right now,

215
00:13:43,848 --> 00:13:47,494
you don't have to use visual studio code to

216
00:13:47,532 --> 00:13:51,654
do any of the things that I'm doing. You can use whatever ide you

217
00:13:51,692 --> 00:13:55,878
prefer. Nothing I'm doing is vs code specific.

218
00:13:56,044 --> 00:13:59,562
You can even run all of these commands that I'm about to run

219
00:13:59,616 --> 00:14:02,746
in a regular old console, but I just

220
00:14:02,768 --> 00:14:06,860
like vs code anyways. I have these example

221
00:14:07,950 --> 00:14:12,074
convolutional neural net setup for a MNiSt

222
00:14:12,122 --> 00:14:15,550
example, but I also have it inside

223
00:14:15,620 --> 00:14:19,342
of a DVC pipeline because this is how I like to track

224
00:14:19,396 --> 00:14:23,410
my experiments, to see what models or

225
00:14:23,480 --> 00:14:27,762
what code changes, what hyperparameter values or

226
00:14:27,816 --> 00:14:31,170
what data sets really make a big difference when I'm training

227
00:14:31,240 --> 00:14:35,474
my model, it just makes it easier to track stuff. But let's

228
00:14:35,522 --> 00:14:39,254
break down this convolutional neural net. So to

229
00:14:39,292 --> 00:14:43,046
start with, I'm just using Pytorch, and this

230
00:14:43,068 --> 00:14:47,390
is all built in. So this torch neural net module,

231
00:14:47,570 --> 00:14:51,302
all of these convolution max pool linear

232
00:14:51,366 --> 00:14:54,698
things, this relu activation function,

233
00:14:54,784 --> 00:14:59,158
all of this is just part of Pytorch. But what we're doing initially

234
00:14:59,254 --> 00:15:02,778
is creating the neural

235
00:15:02,794 --> 00:15:06,126
net itself. So up here, this is where you'll have

236
00:15:06,148 --> 00:15:09,582
to know something about your data. So the data set

237
00:15:09,636 --> 00:15:12,974
that I'm working with, I know that I have one

238
00:15:13,092 --> 00:15:16,862
in channel for my image. Like you might have multiple

239
00:15:16,926 --> 00:15:20,846
channels for your images if you're working with rgb

240
00:15:20,958 --> 00:15:24,142
images, like colored images.

241
00:15:24,286 --> 00:15:27,078
But if you're working with something that's black and white,

242
00:15:27,164 --> 00:15:30,582
you probably can get away with just having one channel in.

243
00:15:30,716 --> 00:15:33,814
And then we'll have eight channels going out,

244
00:15:33,932 --> 00:15:37,522
and we have a kernel

245
00:15:37,586 --> 00:15:41,286
size of three. So the reason we have eight channels

246
00:15:41,318 --> 00:15:45,270
going, but is just because I know these size of my images,

247
00:15:45,430 --> 00:15:49,126
and this is about how much we'll

248
00:15:49,158 --> 00:15:53,210
be able to scan over and get from our convolution.

249
00:15:53,370 --> 00:15:57,198
And then we've added this padding because we only have

250
00:15:57,284 --> 00:16:00,922
eight, we want to make sure that we're capturing the edges

251
00:16:01,066 --> 00:16:04,930
of the image in case there's some important information there.

252
00:16:05,080 --> 00:16:08,750
So that's how we made our first convolution.

253
00:16:08,910 --> 00:16:12,610
Next we have our max pool layer. And then

254
00:16:12,680 --> 00:16:16,310
this is where we'll go through that kernel size and

255
00:16:16,380 --> 00:16:19,766
make sure we have the max value for

256
00:16:19,868 --> 00:16:23,650
each kernel size patch.

257
00:16:23,810 --> 00:16:27,410
So this is where we get our noise suppression.

258
00:16:27,570 --> 00:16:31,322
This is how we make sure we're pulling out the more

259
00:16:31,376 --> 00:16:34,874
important features of our image. And then we have our

260
00:16:34,912 --> 00:16:38,682
next convolution. So you can have as many layers of

261
00:16:38,736 --> 00:16:42,302
convolutions and max pools as you need.

262
00:16:42,436 --> 00:16:46,606
You can throw in some batches if you need. They can get really

263
00:16:46,708 --> 00:16:50,250
intense if you're working with some crazy images,

264
00:16:50,410 --> 00:16:54,426
which it doesn't take much. So don't

265
00:16:54,458 --> 00:16:58,106
be afraid to play around with multiple layers of convolutions

266
00:16:58,138 --> 00:17:01,426
and max pools. But one thing to keep in

267
00:17:01,448 --> 00:17:05,674
mind is that the input for the next convolutional

268
00:17:05,742 --> 00:17:09,606
layer matches what the but was for

269
00:17:09,628 --> 00:17:13,714
the previous layer. So in this case, you see we're

270
00:17:13,762 --> 00:17:17,298
getting more defined

271
00:17:17,394 --> 00:17:21,382
on the image area that we're going over. So now we've

272
00:17:21,446 --> 00:17:24,922
started with eight channels coming in and

273
00:17:24,976 --> 00:17:28,230
we're going to go over 16 predictions.

274
00:17:28,310 --> 00:17:31,834
So we're trying to get more definition and

275
00:17:31,952 --> 00:17:35,066
figure out what those important features are. But we'll

276
00:17:35,098 --> 00:17:38,446
keep the same kernel size. We'll do the padding just

277
00:17:38,468 --> 00:17:41,854
to make sure we're not losing anything. And then we just have

278
00:17:41,892 --> 00:17:45,474
a few linearization layers at the end just

279
00:17:45,512 --> 00:17:48,770
to normalize some things. And last,

280
00:17:48,920 --> 00:17:52,546
we have our forward network. And this

281
00:17:52,568 --> 00:17:55,886
is how we really get the features and build

282
00:17:55,928 --> 00:17:59,590
the model. So we have activation layer for

283
00:17:59,660 --> 00:18:03,206
this first one, and that's just a way of getting a

284
00:18:03,228 --> 00:18:06,594
positive value or a zero if there isn't

285
00:18:06,642 --> 00:18:10,550
a positive value. And youll see relu activation

286
00:18:10,630 --> 00:18:14,598
used pretty much standardly in neural networks

287
00:18:14,774 --> 00:18:19,238
just because it gives you that impulse

288
00:18:19,414 --> 00:18:22,526
value, it's either positive or zero, so you

289
00:18:22,548 --> 00:18:26,026
don't have to filter out as much stuff. But we're

290
00:18:26,138 --> 00:18:29,706
doing the activation function, we're handling the maxpooling

291
00:18:29,738 --> 00:18:33,186
on the image, we're going through activation for

292
00:18:33,208 --> 00:18:36,530
the next convolution, we're doing some more stuff,

293
00:18:36,680 --> 00:18:39,620
and then finally we return the model.

294
00:18:40,070 --> 00:18:44,254
So that is how you make convolutional neural

295
00:18:44,302 --> 00:18:47,586
networks net in Python using Pytorch.

296
00:18:47,698 --> 00:18:51,254
And a lot of it really is just dependent on how well you

297
00:18:51,292 --> 00:18:55,138
know your data. So if you're a little bit confused

298
00:18:55,234 --> 00:18:59,446
about what numbers you should use for your convolutional

299
00:18:59,478 --> 00:19:03,894
layers or your max pool, take a look at these pytorch docs

300
00:19:03,942 --> 00:19:07,930
and then just play around with them. Pretty much all of

301
00:19:08,000 --> 00:19:11,770
model making and machine learning is just experimenting

302
00:19:11,850 --> 00:19:15,534
with different values. And that's why I like

303
00:19:15,572 --> 00:19:18,000
DVC. So for example,

304
00:19:19,650 --> 00:19:23,380
I'm just going to run an experiment to show you what it looks like

305
00:19:26,870 --> 00:19:30,386
I told you, I tested this not too long ago,

306
00:19:30,488 --> 00:19:33,940
like literal minute before,

307
00:19:34,390 --> 00:19:38,466
and okay, it's not broken, but haven't

308
00:19:38,498 --> 00:19:42,134
made any changes. So let's say I didn't know how

309
00:19:42,172 --> 00:19:45,446
many out channels to have, and I'm going

310
00:19:45,468 --> 00:19:49,146
to put nine here just to see what happens. So when

311
00:19:49,168 --> 00:19:52,646
I run this experiment, DVC detects

312
00:19:52,678 --> 00:19:56,230
the change and it runs this training stage.

313
00:19:56,390 --> 00:19:59,958
But you'll notice that we have

314
00:20:00,064 --> 00:20:04,190
can error for this because I changed from eight to nine.

315
00:20:04,340 --> 00:20:08,558
And it'll show you what the expected is for

316
00:20:08,644 --> 00:20:12,462
whatever our given image is. And we just change

317
00:20:12,516 --> 00:20:16,434
these back. Maybe we change these kernel size and I

318
00:20:16,472 --> 00:20:20,094
try to run that again. Let's see. No, that didn't

319
00:20:20,142 --> 00:20:22,500
work. So we'll change that back.

320
00:20:23,350 --> 00:20:26,822
Let's change something down here. Let's say we want

321
00:20:26,956 --> 00:20:30,360
ten instead of 16. Wonder if that'll work.

322
00:20:30,810 --> 00:20:34,198
No, but the good thing about

323
00:20:34,284 --> 00:20:37,754
DVC is that if any of those

324
00:20:37,792 --> 00:20:41,242
code changes were to have run, maybe let's try

325
00:20:41,296 --> 00:20:45,162
changing this to 64, see what

326
00:20:45,216 --> 00:20:48,138
happens. Did that run? No.

327
00:20:48,304 --> 00:20:51,786
Good. So you see, you really have to know the data you're

328
00:20:51,818 --> 00:20:55,246
working with to get the right values. But let

329
00:20:55,268 --> 00:20:58,720
me just try one more thing and see if that works.

330
00:20:59,490 --> 00:21:03,090
All right. These is exactly what it's like

331
00:21:03,240 --> 00:21:07,540
sometimes when you're training a model. But basically

332
00:21:08,070 --> 00:21:12,142
I'm going to come change a hyperparameter,

333
00:21:12,286 --> 00:21:16,134
going to change my learning rate, just to show you all what it's like

334
00:21:16,172 --> 00:21:20,294
to run an experiment, because this is something else you might change if

335
00:21:20,332 --> 00:21:24,134
you're working with convolutional neural networks net or a lot

336
00:21:24,172 --> 00:21:26,360
of other machine learning problems.

337
00:21:27,130 --> 00:21:30,922
So I changed that learning rate because I'm trying to figure

338
00:21:30,976 --> 00:21:35,340
out the best model for my MNIS data sets.

339
00:21:35,710 --> 00:21:38,860
And I'm going to do this a lot.

340
00:21:39,310 --> 00:21:43,086
It's a common problem in machine learning to just do this,

341
00:21:43,268 --> 00:21:47,066
changing values, changing code, maybe adding

342
00:21:47,098 --> 00:21:50,414
new data to your training set and seeing how that

343
00:21:50,452 --> 00:21:53,874
affects your model. So in this case, youll can see we

344
00:21:53,912 --> 00:21:57,854
have some epics that are running, we have our loss,

345
00:21:57,982 --> 00:22:01,246
we see how accurate it is, and that's

346
00:22:01,278 --> 00:22:04,878
with this learning rate. So I'm going to stop these training

347
00:22:04,984 --> 00:22:09,240
run and just show you our table real quick.

348
00:22:09,850 --> 00:22:13,414
So, yeah, if you look up

349
00:22:13,452 --> 00:22:17,930
here, you'll see my last run with this

350
00:22:18,000 --> 00:22:19,100
training rate.

351
00:22:21,950 --> 00:22:25,274
Yeah, it's not as great as we

352
00:22:25,312 --> 00:22:29,340
would want it to be, but 83% accuracy isn't that bad.

353
00:22:30,530 --> 00:22:34,446
But now that you've seen kind of how

354
00:22:34,628 --> 00:22:37,930
we make a CNN, how we run, can experiment,

355
00:22:38,090 --> 00:22:41,614
I'm going to switch back over to the

356
00:22:41,652 --> 00:22:44,946
slides and we can go ahead and finish up.

357
00:22:45,128 --> 00:22:48,802
So a few things I hope that youll take away from this.

358
00:22:48,936 --> 00:22:52,578
Make sure that you compare a few different algorithms before

359
00:22:52,664 --> 00:22:55,220
you decide what's best for your application.

360
00:22:55,750 --> 00:22:59,442
So a CNN might be great for most images,

361
00:22:59,506 --> 00:23:03,574
but maybe you find something else that works better for your data set.

362
00:23:03,692 --> 00:23:07,126
It's okay to play around with different things to find what

363
00:23:07,148 --> 00:23:10,714
gives you the best and then take advantage of

364
00:23:10,752 --> 00:23:14,154
what's already out there. You don't have to write everything from

365
00:23:14,192 --> 00:23:18,230
scratch to prove that you're just this great ML

366
00:23:18,310 --> 00:23:22,158
engineer. It's fine. We already know that you're great.

367
00:23:22,324 --> 00:23:25,726
Just take it easy. You don't have to do the

368
00:23:25,748 --> 00:23:29,194
hard math stuff anymore. Use those existing

369
00:23:29,242 --> 00:23:33,158
libraries like Pytorch and maybe even tensorflow

370
00:23:33,194 --> 00:23:37,282
if you want to take the time to learn that. And then when you have

371
00:23:37,336 --> 00:23:39,940
a problem, especially in machine learning,

372
00:23:40,310 --> 00:23:44,270
try breaking it down into multiple steps.

373
00:23:44,430 --> 00:23:47,974
So that's something that a tool like DVC can

374
00:23:48,012 --> 00:23:52,114
really help with is just you're able to reproduce

375
00:23:52,162 --> 00:23:55,654
every experiment you run. So if you're looking at your

376
00:23:55,692 --> 00:23:59,074
model and you're trying to figure out what value you changed

377
00:23:59,202 --> 00:24:02,120
to make it this good,

378
00:24:03,050 --> 00:24:06,838
then you'll have a record of the exact changes

379
00:24:06,924 --> 00:24:09,710
you made to make such a great model.

380
00:24:09,900 --> 00:24:13,006
But that's all I have for you today. I hope you

381
00:24:13,028 --> 00:24:16,750
were able to learn a lot about cnns. And again,

382
00:24:16,820 --> 00:24:20,334
if you have any questions for me, feel free to reach out

383
00:24:20,372 --> 00:24:23,260
on Twitter at flipped coding. Thank you.

