1
00:00:00,410 --> 00:00:06,174
Jamaica real

2
00:00:06,212 --> 00:00:09,934
time feedback into the behavior of your distributed systems and

3
00:00:09,972 --> 00:00:13,614
observing changes exceptions errors in real

4
00:00:13,652 --> 00:00:17,914
time allows you to not only experiment with confidence, but respond

5
00:00:18,042 --> 00:00:20,480
instantly to get things working again.

6
00:00:24,610 --> 00:00:47,130
Close hello

7
00:00:47,200 --> 00:00:50,842
everyone and welcome to my talk lira disrupting full tech search

8
00:00:50,896 --> 00:00:54,506
industry with javascript before we start, I always like to introduce

9
00:00:54,538 --> 00:00:57,678
myself very briefly. I am Michele. I work as

10
00:00:57,684 --> 00:01:01,514
a staff engineer at Nearform. I'm a Google developer expert and a Microsoft

11
00:01:01,562 --> 00:01:05,806
MVP. I want to start by saying that I love elasticsearch.

12
00:01:05,918 --> 00:01:09,474
When I think of full text search engines, I always think

13
00:01:09,512 --> 00:01:13,742
of my favorite open source project ever, which is elastic.

14
00:01:13,886 --> 00:01:17,254
In the past I had the opportunity to work a lot on elasticsearch or

15
00:01:17,292 --> 00:01:21,206
with elasticsearch, of course on projects and products. And I

16
00:01:21,228 --> 00:01:25,318
got to say, I also tried working with solar. I tried working

17
00:01:25,404 --> 00:01:29,462
directly with Lucine. So the library underneath elasticsearch

18
00:01:29,526 --> 00:01:32,986
itself, but also underneath solar. But I got to say,

19
00:01:33,008 --> 00:01:36,646
every single time I come back to elasticsearch because it's

20
00:01:36,678 --> 00:01:40,742
just an amazing open source project and I truly,

21
00:01:40,806 --> 00:01:44,526
truly love it. In the past, of course, I've been contributing to

22
00:01:44,548 --> 00:01:48,958
open source a lot. And I've been working a bit on UnomI, which is a

23
00:01:49,124 --> 00:01:52,826
CDP, a customer data platform from Apache that

24
00:01:52,868 --> 00:01:57,742
uses elasticsearch as a leader database in the whole overall architecture.

25
00:01:57,886 --> 00:02:01,714
And I was amazed by the fact that every day we

26
00:02:01,752 --> 00:02:04,926
could just throw millions of data to Unomi,

27
00:02:04,958 --> 00:02:09,314
and elasticsearch would work just fine. And the performances

28
00:02:09,362 --> 00:02:13,142
in search couldn't be that much affected by the amount of data

29
00:02:13,196 --> 00:02:16,914
we just insert into the database. And this is true.

30
00:02:16,962 --> 00:02:21,320
Amazing. And one question I always wondered was

31
00:02:22,830 --> 00:02:27,190
how is it possible that Lucine, and of course then solar or elasticsearch

32
00:02:27,270 --> 00:02:30,570
can be that fast? And when we think about

33
00:02:30,720 --> 00:02:34,266
performances, when we think about how elasticsearch, how Lucine

34
00:02:34,298 --> 00:02:37,838
works, we have to make a distinction. Of course, we already anticipated that

35
00:02:37,924 --> 00:02:41,806
a couple of seconds ago, but yeah, Lucine is

36
00:02:41,828 --> 00:02:44,990
the actual full text search library, which is written in Java.

37
00:02:45,070 --> 00:02:49,474
And elasticsearch is not just a

38
00:02:49,512 --> 00:02:53,218
search engine itself because it uses Lucine, but it's also a

39
00:02:53,224 --> 00:02:56,034
restful server. It is a distributed system.

40
00:02:56,232 --> 00:02:59,618
It adds sharding on top of the overall distributed

41
00:02:59,634 --> 00:03:02,934
system so that if you have a lot of data, you can shard data

42
00:03:02,972 --> 00:03:07,042
amongst multiple nodes. It takes care of data consistency monitoring,

43
00:03:07,106 --> 00:03:10,778
cluster management, a lot of stuff.

44
00:03:10,944 --> 00:03:14,874
And as I already said, I love elasticsearch and I

45
00:03:14,912 --> 00:03:18,314
wanted to start recreating it from scratch. Not because

46
00:03:18,352 --> 00:03:21,374
I didn't like it, but because I wanted to learn more.

47
00:03:21,492 --> 00:03:25,150
And quoting one of the best of all time,

48
00:03:25,300 --> 00:03:28,398
Richard Feynman what I cannot create, I do not understand.

49
00:03:28,484 --> 00:03:32,918
So that's my life motto. This is something that truly

50
00:03:33,034 --> 00:03:36,754
explains the way I do learn stuff. So yeah,

51
00:03:36,792 --> 00:03:40,500
I wanted to create something in order to understand how that works,

52
00:03:41,350 --> 00:03:44,366
of course. Again, I love elastic,

53
00:03:44,478 --> 00:03:47,986
but I also had some problems with it. It's not the easiest

54
00:03:48,018 --> 00:03:51,526
software to deploy and set up, let's be honest with that.

55
00:03:51,628 --> 00:03:54,914
It's quite hard to upgrade, it has a big memory

56
00:03:54,962 --> 00:03:57,958
footprint, cpu consumption is not great,

57
00:03:58,044 --> 00:04:01,366
and it's really, really costly. So if you go on the cloud version, it has

58
00:04:01,388 --> 00:04:05,162
a cost. If you want to maintain it on your own, on your cloud

59
00:04:05,216 --> 00:04:08,554
provider, provider of choice, it also has a cost, of course.

60
00:04:08,672 --> 00:04:12,794
So at the end of the day, I find it to be a very

61
00:04:12,832 --> 00:04:16,494
good product. Has no competition in my opinion right now,

62
00:04:16,692 --> 00:04:19,598
but has some problems. Let's be honest about that.

63
00:04:19,764 --> 00:04:22,846
Before I continue, I want to say that all the problems that I found,

64
00:04:22,948 --> 00:04:26,842
maybe it was all my fault, maybe I was too inexpert and elasticsearch

65
00:04:26,906 --> 00:04:30,274
was a bit too much for me. We all know that making simple software is

66
00:04:30,312 --> 00:04:34,194
hard. We can give it a try. But I want this to be

67
00:04:34,232 --> 00:04:37,670
clear from the start, I love elasticsearch and I started

68
00:04:37,740 --> 00:04:41,574
recreating something similar just because I wanted to learn more, not because I wanted to

69
00:04:41,612 --> 00:04:45,000
replace in first place the whole system.

70
00:04:45,530 --> 00:04:49,066
So I set myself a goal. I wanted to give a talk on how

71
00:04:49,088 --> 00:04:52,490
full text search engines work. That's also for another nice reason.

72
00:04:52,640 --> 00:04:55,740
If I don't have a goal, I'm not able to

73
00:04:56,510 --> 00:05:00,090
understand how stuff works and basically study.

74
00:05:00,160 --> 00:05:04,030
I need a motivation. So that was my motivation. And yeah,

75
00:05:04,100 --> 00:05:07,482
I started learning more about full tech search algorithms,

76
00:05:07,546 --> 00:05:11,280
data structures, whatever. And yeah,

77
00:05:12,290 --> 00:05:15,646
I started going down the rabbit hole. So that was me the

78
00:05:15,668 --> 00:05:19,074
first few hours reading the theory behind full tech search. It's not

79
00:05:19,112 --> 00:05:22,354
easy, let's be honest about that. The hard truth is that

80
00:05:22,392 --> 00:05:25,634
I needed to study a lot of algorithms in data structures. I have

81
00:05:25,672 --> 00:05:28,758
no degree, so I didn't have any place in my mind where I

82
00:05:28,764 --> 00:05:32,482
could say like, okay, I remember I discussed this during a university

83
00:05:32,546 --> 00:05:36,194
lecture, I can reach out to that. I don't know, professor,

84
00:05:36,242 --> 00:05:39,974
for example, for learning something, asking questions, I started literally

85
00:05:40,022 --> 00:05:42,954
from scratch. And that can be kind of a problem for us.

86
00:05:42,992 --> 00:05:45,818
I thought developers, as I am,

87
00:05:45,984 --> 00:05:48,620
but was very interesting anyway.

88
00:05:49,710 --> 00:05:52,702
And of course after you start implementing stuff,

89
00:05:52,756 --> 00:05:56,014
after you start at least learning how stuff

90
00:05:56,052 --> 00:05:59,786
works, you need to implement it. And of course when you start implement

91
00:05:59,898 --> 00:06:03,906
something, you have to choose a programming language to implement your

92
00:06:03,928 --> 00:06:06,994
algorithms and your data structures. And of course I

93
00:06:07,032 --> 00:06:10,734
wanted to be a cool guy. Cool guy uses

94
00:06:10,782 --> 00:06:13,620
cool programming languages. So of course, oh no,

95
00:06:13,990 --> 00:06:17,398
Haskell, of course.

96
00:06:17,484 --> 00:06:20,774
I started working with Rust, and I

97
00:06:20,812 --> 00:06:24,374
gotta say, I've been working with Haskell for quite a long time,

98
00:06:24,492 --> 00:06:27,960
so I thought that rust could have been a nice option,

99
00:06:29,070 --> 00:06:32,554
easiest option, possibly. I was terribly wrong.

100
00:06:32,672 --> 00:06:36,390
It's not an easy programming language. It's super cool. Of course, cool guys uses

101
00:06:36,470 --> 00:06:39,754
rust all the time, it just wasn't for

102
00:06:39,792 --> 00:06:43,406
me. So I decided to implement everything from scratch in

103
00:06:43,428 --> 00:06:46,686
Golang. And also Golang is not super easy in my

104
00:06:46,708 --> 00:06:50,750
opinion. I mean, when compared to other program languages such as typescript or

105
00:06:50,900 --> 00:06:54,706
Ruby, for example, these are another kind

106
00:06:54,728 --> 00:06:59,140
of program language. So I started feeling a bit frustrated about that because

107
00:06:59,510 --> 00:07:03,006
I want to make stuff done, but I didn't

108
00:07:03,038 --> 00:07:06,114
have enough knowledge of those program languages to get stuff done,

109
00:07:06,152 --> 00:07:09,938
of course. And then I remembered a quote from

110
00:07:10,024 --> 00:07:13,766
Jeff Oatwood, the co founder of Stack Overflow, as known as

111
00:07:13,788 --> 00:07:17,934
the Otwood load, that says an application that can be written in JavaScript

112
00:07:18,002 --> 00:07:20,490
will eventually be written in JavaScript.

113
00:07:20,910 --> 00:07:24,406
And yeah, why not? JavaScript is the king

114
00:07:24,438 --> 00:07:28,602
of programming languages, right? So I decided to start implementing stuff

115
00:07:28,656 --> 00:07:32,334
with JavaScript, and that was kind of surprising to me. I started

116
00:07:32,372 --> 00:07:36,430
implementing stuff with rust. All the data structures that are required

117
00:07:37,170 --> 00:07:41,034
to work on search engines

118
00:07:41,162 --> 00:07:44,538
started with rust. Re implementing everything in Golang was quite

119
00:07:44,564 --> 00:07:48,446
optimized actually, because I've spent a lot of time on stack

120
00:07:48,478 --> 00:07:52,146
overflow, of course asking for code reviews to more expert people. So I

121
00:07:52,168 --> 00:07:55,586
was pretty confident in the performances. But I got to

122
00:07:55,608 --> 00:07:59,142
say, even though JavaScript couldn't outperform those languages, it was

123
00:07:59,276 --> 00:08:03,366
very close. And we will see how close we are

124
00:08:03,548 --> 00:08:07,126
in the next slides. That brings me to the next question. There is no

125
00:08:07,148 --> 00:08:10,938
slow programming language, but just bad algorithms in data structure design,

126
00:08:11,024 --> 00:08:14,314
which basically means that maybe my algorithms, of course, I ask for

127
00:08:14,352 --> 00:08:17,834
code reviews, I ask for many things and help,

128
00:08:18,032 --> 00:08:22,122
but maybe they weren't so well optimized. So rust

129
00:08:22,186 --> 00:08:25,600
cannot make your shitty code be better.

130
00:08:27,490 --> 00:08:31,662
But I have more experience in JavaScript, so my JavaScript code is written better

131
00:08:31,716 --> 00:08:35,346
than my rust code, of course, and performs not better. But we

132
00:08:35,368 --> 00:08:38,130
are pretty close, and that's a good point in my opinion,

133
00:08:38,710 --> 00:08:41,794
to understand. That's a lesson that I had to bring home.

134
00:08:41,912 --> 00:08:45,846
So basically, after spending a couple of months

135
00:08:46,028 --> 00:08:49,782
working on that search engine, I gave

136
00:08:49,836 --> 00:08:54,242
my talk at we are developers in Berlin on August,

137
00:08:54,306 --> 00:08:58,518
I guess. And yeah, this is how lira

138
00:08:58,614 --> 00:09:02,826
was born. So lira nowadays it's can open source project

139
00:09:03,008 --> 00:09:06,998
that of course, it's a full text search engine written in typescript.

140
00:09:07,174 --> 00:09:10,846
And one nice thing about lira that I'd like

141
00:09:10,868 --> 00:09:15,018
to highlight is that targets every single JavaScript runtime.

142
00:09:15,114 --> 00:09:18,174
So it's not a problem.

143
00:09:18,212 --> 00:09:22,378
If you want to run like JavaScript on, let's say node js,

144
00:09:22,474 --> 00:09:26,430
on Dino, on can, on Cloudflare workers, on react native,

145
00:09:26,510 --> 00:09:29,134
it's not a problem, we don't have any kind of dependency.

146
00:09:29,262 --> 00:09:33,038
We test everything on every single runtime, and we implemented

147
00:09:33,134 --> 00:09:37,014
everything from scratch with backward compatibility in

148
00:09:37,052 --> 00:09:40,790
every single runtime in mind, as well as performances, of course.

149
00:09:40,860 --> 00:09:44,354
So we implemented everything from scratch. We implemented prefix,

150
00:09:44,402 --> 00:09:47,650
true, inverted indexes, b trees, tree maps,

151
00:09:47,730 --> 00:09:52,374
we implementing the stamped algorithm, stopwords support

152
00:09:52,412 --> 00:09:55,766
for custom stopwords, we introduced support for multiple

153
00:09:55,798 --> 00:09:59,814
languages, everything from scratch so that you can use lira wherever

154
00:09:59,862 --> 00:10:03,310
you want on your favorite runtime. And when I say

155
00:10:03,380 --> 00:10:07,166
runtimes, I refer to the fact that you can run, let's say

156
00:10:07,268 --> 00:10:11,338
lira on cloudflare workers or netrify functions.

157
00:10:11,354 --> 00:10:15,486
So you can target edge computing, you can run it on browsers, on can

158
00:10:15,598 --> 00:10:19,902
lambda functions, on AWS lambda edge dino

159
00:10:19,966 --> 00:10:23,778
react native node js, you can literally run it wherever you want.

160
00:10:23,864 --> 00:10:27,010
And talking specifically about edge computing,

161
00:10:27,350 --> 00:10:30,646
it wasn't super easy for us to

162
00:10:30,668 --> 00:10:34,006
get there. I remember I was in a conference in Berlin a couple of

163
00:10:34,028 --> 00:10:38,166
months ago, and I was there with a colleague of mine and I

164
00:10:38,188 --> 00:10:41,946
said, you know what, it would be cool to

165
00:10:41,968 --> 00:10:45,146
run lira on the edge, right? He told me,

166
00:10:45,168 --> 00:10:48,410
okay, yeah, hold my beer, that's all he said.

167
00:10:48,480 --> 00:10:52,160
And the day after we've been able to ship a

168
00:10:52,850 --> 00:10:56,986
very basic version of the very first full text search engine capable

169
00:10:57,018 --> 00:11:00,480
of running on edge networks. And let me show you how we did it.

170
00:11:00,930 --> 00:11:04,980
So talking about Lira, how it works, we basically have

171
00:11:07,750 --> 00:11:11,074
a collection of functions actually, which are for example, create,

172
00:11:11,192 --> 00:11:15,150
insert, remove and search. So create creates a new lira instance,

173
00:11:15,310 --> 00:11:18,898
insert inserts new data into the existing instance.

174
00:11:18,994 --> 00:11:22,706
Remove removes data and search of course performs a search operation. But let's

175
00:11:22,738 --> 00:11:25,570
start from the beginning. It's not schemaless,

176
00:11:25,650 --> 00:11:29,286
so it's not really like elasticsearch in

177
00:11:29,308 --> 00:11:33,366
that sense, which is totally schemaless, but you have to define the types

178
00:11:33,398 --> 00:11:37,146
for the stuff that you are going to input into the database itself.

179
00:11:37,248 --> 00:11:41,014
So in that example we just create a schema containing author,

180
00:11:41,062 --> 00:11:44,606
which is a string, and quote, which is another string. Then we

181
00:11:44,628 --> 00:11:48,234
want to insert stuff. So as you can see there, we basically pass the DB,

182
00:11:48,282 --> 00:11:52,762
so we mutate the original DB instance by inserting

183
00:11:52,826 --> 00:11:56,546
new stuff. This is a synchronous operation, as you can

184
00:11:56,568 --> 00:12:01,010
see there. So we also provide an insert batch method which is asynchronous

185
00:12:01,350 --> 00:12:04,866
and prevents the event loop from blocking. So that's pretty important just

186
00:12:04,888 --> 00:12:08,758
for you to know. And once we insert stuff,

187
00:12:08,844 --> 00:12:12,598
we can eventually start searching for data. So in

188
00:12:12,604 --> 00:12:15,874
that example, we pass DB, so inside that database,

189
00:12:15,922 --> 00:12:19,878
because we might have multiple databases, why not inside

190
00:12:19,964 --> 00:12:23,770
that database, search for the term, let's say if

191
00:12:23,840 --> 00:12:27,174
on all the properties. So search it on quote and author.

192
00:12:27,222 --> 00:12:30,730
But you can also choose to search on quote only on author only.

193
00:12:30,880 --> 00:12:33,518
And you will see that elapsed. It's 99.

194
00:12:33,604 --> 00:12:37,262
We'll get back later. Count is two and

195
00:12:37,316 --> 00:12:40,714
two results. So these are the results. This is the API

196
00:12:40,762 --> 00:12:44,110
for searching data. But now you may be wondering, what is 99?

197
00:12:44,180 --> 00:12:47,090
It's records. Milliseconds.

198
00:12:47,590 --> 00:12:50,738
No, it's actually microseconds. And you might be thinking,

199
00:12:50,904 --> 00:12:54,302
wow, okay, you only inserted like four documents.

200
00:12:54,366 --> 00:12:58,166
Of course, it's fast. Yes, this is true. But we also made

201
00:12:58,188 --> 00:13:02,454
some benchmarks. So we took 1

202
00:13:02,492 --> 00:13:06,002
million entries, which are actually 1 million movie titles

203
00:13:06,066 --> 00:13:10,010
from the international movie database. We inserted everything inside

204
00:13:10,080 --> 00:13:13,766
lira and we performed different searches. So for example, we searched

205
00:13:13,798 --> 00:13:17,626
for believe inside of all the indexes and

206
00:13:17,728 --> 00:13:20,882
on average it took 41 microseconds,

207
00:13:20,966 --> 00:13:25,134
so millionth of a second to

208
00:13:25,172 --> 00:13:28,954
get all the results. And if you go like in criminal

209
00:13:29,002 --> 00:13:32,926
minds, for example, it takes 187 microseconds. But as you can see,

210
00:13:32,948 --> 00:13:36,802
criminal minds has two different terms, so it performs two different

211
00:13:36,856 --> 00:13:40,338
searches, then intersects all the documents containing both terms.

212
00:13:40,424 --> 00:13:43,922
So there is a lot to do in that case. But it's so

213
00:13:43,976 --> 00:13:47,506
damn fast. And again, there's no slow programming language out

214
00:13:47,528 --> 00:13:51,494
there. There is just bad algorithm and data structure design. So that's something

215
00:13:51,532 --> 00:13:55,254
to keep in mind after we get there. We also wanted to give support from

216
00:13:55,292 --> 00:13:58,914
multiple languages because of course English is default,

217
00:13:58,962 --> 00:14:02,426
but I'm italian, so I might want to index italian data.

218
00:14:02,608 --> 00:14:05,994
And when indexing data, we also want to make

219
00:14:06,032 --> 00:14:09,418
our search engine smart. So let me give

220
00:14:09,424 --> 00:14:13,446
you an example. We perform stemming operations

221
00:14:13,558 --> 00:14:16,686
and stopwords removals. For example, if we

222
00:14:16,708 --> 00:14:20,266
have sentences

223
00:14:20,378 --> 00:14:24,126
containing commonly used words such as articles

224
00:14:24,158 --> 00:14:26,830
like a v, et cetera,

225
00:14:26,990 --> 00:14:30,114
and other similar words, we just remove them because they have

226
00:14:30,152 --> 00:14:33,826
no sense. And if we have words like lucky, for example,

227
00:14:34,008 --> 00:14:37,730
we stem it to luck, so that if you search luck,

228
00:14:37,810 --> 00:14:41,986
you will find exactly that word, or luckiest,

229
00:14:42,098 --> 00:14:45,042
you will find all the documents containing luck,

230
00:14:45,106 --> 00:14:49,042
lucky, of course you can also say, okay, give me the exact result.

231
00:14:49,116 --> 00:14:53,340
So luckiest, not luck or lucky, so you can filter out

232
00:14:53,950 --> 00:14:58,140
results that you don't want. But we also give you an interface for

233
00:14:58,590 --> 00:15:02,178
smart searches, and we do that using a stemming algorithm

234
00:15:02,214 --> 00:15:05,406
that right now it's supporting in 23 different languages. So that's an

235
00:15:05,428 --> 00:15:09,470
example of how it works. We basically expose a true shakeable

236
00:15:10,450 --> 00:15:13,440
italian stemmer. In that example you can see on the screen,

237
00:15:13,830 --> 00:15:17,746
so you choose the language and the tokenizer. So the

238
00:15:17,768 --> 00:15:21,406
tokenizer, sorry, the stemmer, it's part of the tokenizer

239
00:15:21,438 --> 00:15:25,266
process right now, will be the italian stemmer. Of course, writing in

240
00:15:25,288 --> 00:15:28,482
stemmers, it's not easy because every single language has different rules.

241
00:15:28,546 --> 00:15:32,518
So you can't stem italian words like english words,

242
00:15:32,604 --> 00:15:37,634
for example. We will see more example going on. So lucky

243
00:15:37,762 --> 00:15:41,574
gets stemmed to luck. But the same rules can't apply for Italian,

244
00:15:41,622 --> 00:15:44,742
for example, or Germany, or German, or Russian,

245
00:15:44,806 --> 00:15:48,614
or, I don't know, Swedish, Turkish, et cetera. So we relied

246
00:15:48,662 --> 00:15:52,746
on snowball. So snowball, it's a project created

247
00:15:52,778 --> 00:15:56,858
by Martin Porter, which is the author of the Porter Stemmer,

248
00:15:56,954 --> 00:16:00,126
which is possibly one of the most beautiful stemming algorithms out

249
00:16:00,148 --> 00:16:03,766
there. Super brilliant, and it's totally open source.

250
00:16:03,818 --> 00:16:07,154
So not only the stemming algorithm itself which is

251
00:16:07,192 --> 00:16:10,978
written in c, but can be compiled down to Javascript or

252
00:16:11,064 --> 00:16:14,642
imported into Golang, rust, wherever, but it also gives you

253
00:16:14,776 --> 00:16:18,386
idea on how to create your own stemmer. So in that example,

254
00:16:18,488 --> 00:16:21,398
as you can see here, we have like, I don't know, step zero,

255
00:16:21,484 --> 00:16:24,274
search for the longest among the suffixes.

256
00:16:24,402 --> 00:16:28,426
If we find that suffix, we just remove it. Then next step, search for

257
00:16:28,448 --> 00:16:31,770
the longest amongst following suffixes.

258
00:16:32,510 --> 00:16:36,582
And whenever we find one of those suffixes, we perform a given operation

259
00:16:36,646 --> 00:16:39,802
following the algorithm description. So it's really easy

260
00:16:39,856 --> 00:16:44,494
and convenient to follow these

261
00:16:44,612 --> 00:16:47,754
instructions to create more and more stemmers.

262
00:16:47,802 --> 00:16:51,374
There are battle tested, accurate and

263
00:16:51,412 --> 00:16:54,394
also widely used also inside other projects.

264
00:16:54,442 --> 00:16:58,526
I'm not sure that elasticsearch for example uses this stemmer algorithm,

265
00:16:58,638 --> 00:17:02,194
but I wouldn't be surprised. Let's say that I know that a lot of search

266
00:17:02,232 --> 00:17:05,966
engines out there are using the exact same algorithm, so the results are pretty

267
00:17:06,008 --> 00:17:10,246
accurate in every other, let's say, competitor we

268
00:17:10,268 --> 00:17:13,574
can find for lira. So just for giving an

269
00:17:13,612 --> 00:17:16,642
example, this is how stemming algorithm networks in English,

270
00:17:16,706 --> 00:17:20,502
so we have like consign, which gets stem to consign,

271
00:17:20,646 --> 00:17:24,650
but then we have the past form, so consigned in the past

272
00:17:24,800 --> 00:17:27,290
gets stemmed to consign, again,

273
00:17:27,440 --> 00:17:30,666
consigning gets stamped again to

274
00:17:30,688 --> 00:17:34,414
consign. So this is how it works. And of course I'm italian, I could write

275
00:17:34,452 --> 00:17:37,914
can italian stemmer. And these are the tests,

276
00:17:37,962 --> 00:17:41,422
for example, that I had to perform. I know nothing about

277
00:17:41,476 --> 00:17:45,346
German, but I'd love to, but I don't know how

278
00:17:45,368 --> 00:17:49,278
to speak it or how to write it. So following the porter's terminal

279
00:17:49,294 --> 00:17:53,506
algorithm description, it was possible to

280
00:17:53,528 --> 00:17:56,806
do that. And of course if you want to have fun, you can

281
00:17:56,828 --> 00:18:00,390
create your own stemming algorithm. So in that example,

282
00:18:00,540 --> 00:18:04,214
stemming function is nothing more than a function giving you

283
00:18:04,252 --> 00:18:08,026
a word and expecting a new word in return. So in that

284
00:18:08,048 --> 00:18:11,590
example we are just appending ish

285
00:18:11,750 --> 00:18:15,274
ish to the word. So that if you

286
00:18:15,312 --> 00:18:19,046
really want to have fun or you don't like the stemming

287
00:18:19,078 --> 00:18:22,606
algorithm, you can bring your own, which is really really convenient because there

288
00:18:22,628 --> 00:18:26,474
are many out there and you can just import a library

289
00:18:26,602 --> 00:18:29,998
and use it as you prefer. So we did also the

290
00:18:30,004 --> 00:18:33,694
same for custom stopwords. So for example, common stop

291
00:18:33,732 --> 00:18:37,280
words are, I don't know, a d

292
00:18:38,050 --> 00:18:41,598
me, you, these are all stopwords.

293
00:18:41,614 --> 00:18:44,994
That doesn't carry a lot of meaning to the search if we think

294
00:18:45,032 --> 00:18:48,642
of overall meaning for the search

295
00:18:48,696 --> 00:18:52,086
query and results. So basically,

296
00:18:52,188 --> 00:18:55,414
given the language that you support, for example,

297
00:18:55,452 --> 00:18:59,522
in that case we don't specify a given language, so it's English by default.

298
00:18:59,666 --> 00:19:03,242
We give you the list of english stopwords and you can filter them out,

299
00:19:03,296 --> 00:19:06,282
you can append new stuff, or you can bring your own stop words.

300
00:19:06,336 --> 00:19:11,150
So it's all up to you. So it's highly customizable.

301
00:19:11,650 --> 00:19:15,566
Lira had some project goals, of course, we wanted to

302
00:19:15,588 --> 00:19:19,194
run on any JavaScript

303
00:19:19,242 --> 00:19:22,398
runtime. We wanted it to be as small as possible,

304
00:19:22,484 --> 00:19:25,390
as fast as possible, and easy to maintain and deploy.

305
00:19:25,890 --> 00:19:29,090
And I gotta say, we had some great achievement.

306
00:19:29,430 --> 00:19:33,170
It works on every single JavaScript runtimes. It has a small

307
00:19:33,240 --> 00:19:36,840
modular core, as you can see, you can always interact with the core, so that,

308
00:19:38,490 --> 00:19:42,246
I don't know, for example, we have a hug system, so you can interact with

309
00:19:42,428 --> 00:19:45,926
all the processes to customize the experience as you

310
00:19:45,948 --> 00:19:49,000
wish. It's pretty fast,

311
00:19:49,450 --> 00:19:53,382
can be deployed literally everywhere, serialized data in different formats.

312
00:19:53,446 --> 00:19:57,222
So we will see what that means in just a second and has a powerful

313
00:19:57,286 --> 00:20:00,746
plugin system. Speaking of which, at a certain point you

314
00:20:00,768 --> 00:20:04,634
have the data, you want to deploy the data, you may want to persist

315
00:20:04,682 --> 00:20:07,834
the data somewhere so you don't have to index

316
00:20:07,882 --> 00:20:09,840
everything from scratch every single time.

317
00:20:10,610 --> 00:20:14,302
So we created a plugin which is called plugin data

318
00:20:14,356 --> 00:20:17,666
persistence. It's an official plugin and basically allows you

319
00:20:17,688 --> 00:20:21,394
to export the index from one lira instance and re import it

320
00:20:21,432 --> 00:20:24,994
somewhere else. And this is pretty important, let me show you why. So let's say

321
00:20:25,032 --> 00:20:28,646
we have this lira instance, we have

322
00:20:28,668 --> 00:20:31,426
a schema. We insert data into the original instance.

323
00:20:31,538 --> 00:20:35,110
Then we import the persist to file function

324
00:20:35,180 --> 00:20:38,914
which is runtime specific. This only works on can and node JS.

325
00:20:38,962 --> 00:20:42,518
As for now, if there's anyone wanting to implement this on Dino,

326
00:20:42,614 --> 00:20:46,566
I'd be super happy to help of course. And persist

327
00:20:46,598 --> 00:20:50,426
to file will return the file path where you persist the data. It's an

328
00:20:50,448 --> 00:20:54,286
absolute path, so you pass the original instance that we just created. So this

329
00:20:54,308 --> 00:20:58,074
one for reference, we choose the format binary

330
00:20:58,122 --> 00:21:02,790
by default. So message pack, but you can also choose DPAC or JSON

331
00:21:02,970 --> 00:21:06,258
serialization and an output file. So in

332
00:21:06,264 --> 00:21:10,002
that case quotes MSP, which is message pack

333
00:21:10,056 --> 00:21:15,102
of course. So we are basically taking Lira

334
00:21:15,166 --> 00:21:18,834
index, we are serializing it and saving it to disk in a binary

335
00:21:18,882 --> 00:21:23,186
format. Then we can use the restore from file from another totally

336
00:21:23,218 --> 00:21:27,734
different machine or service and we read it in

337
00:21:27,772 --> 00:21:31,880
memory. So restored instance constant in that case will be

338
00:21:33,130 --> 00:21:37,146
an in memory index for lira. So as you can see,

339
00:21:37,328 --> 00:21:39,846
we choose the file quotes MSP,

340
00:21:40,038 --> 00:21:43,290
the one we just created, and we can now immediately

341
00:21:43,370 --> 00:21:46,350
perform search on restored databases.

342
00:21:47,090 --> 00:21:50,606
That brings us to a lot of target architectures. Let me give you

343
00:21:50,628 --> 00:21:55,006
a couple of examples. We have the offline search architecture

344
00:21:55,038 --> 00:21:58,226
for example. So let's say we have a mobile app on

345
00:21:58,248 --> 00:22:01,742
react native which is totally supported from lira.

346
00:22:01,886 --> 00:22:06,014
So we perform search and whenever the connection

347
00:22:06,142 --> 00:22:09,574
is not established to the server, we can also

348
00:22:09,612 --> 00:22:12,886
rely on a local backup for the data. So we can fall back to

349
00:22:12,908 --> 00:22:16,566
the local DB that let's say every five minutes asks the

350
00:22:16,588 --> 00:22:20,170
server for new data. So if there's new data, we serialize that new data,

351
00:22:20,240 --> 00:22:23,478
we send it to the local database on our applications.

352
00:22:23,574 --> 00:22:27,494
And whenever the Internet connection

353
00:22:27,542 --> 00:22:31,166
fails, we will always be able to fall back to in

354
00:22:31,188 --> 00:22:34,510
memory database, be it, I don't know,

355
00:22:34,660 --> 00:22:38,286
sqlite or any database you like to use on your

356
00:22:38,308 --> 00:22:42,240
mobile applications. But that's not just it.

357
00:22:42,690 --> 00:22:45,778
We may want to have a kind of a CI process

358
00:22:45,944 --> 00:22:50,194
for lira so that you build your database every

359
00:22:50,232 --> 00:22:53,922
five minutes, let's say, or every minute, every three minutes you

360
00:22:53,976 --> 00:22:58,034
choose and you deposit your serialized

361
00:22:58,082 --> 00:23:02,102
index on s three. For example, it triggers a simple

362
00:23:02,156 --> 00:23:06,054
notification service SNS, which will

363
00:23:06,092 --> 00:23:09,386
deployed some lambdas containing the in memory index so

364
00:23:09,408 --> 00:23:13,094
that you can query the data directly on AWS

365
00:23:13,142 --> 00:23:16,454
lambda. And every time you put some new index

366
00:23:16,502 --> 00:23:20,326
inside s three, you will be able to basically redeploy

367
00:23:20,358 --> 00:23:23,520
lambdas and perform search operations on new data.

368
00:23:24,050 --> 00:23:27,194
So with that target architecture, for example, you have to forget

369
00:23:27,242 --> 00:23:30,474
about cluster management deployed data consistency because it's

370
00:23:30,522 --> 00:23:34,626
all managed by AWS in that case, so you

371
00:23:34,648 --> 00:23:38,370
only have to take care about performing search operations.

372
00:23:39,670 --> 00:23:42,894
Or if you're lazy like me, you can deploy

373
00:23:42,942 --> 00:23:46,566
everywhere using nebula. So I couldn't prepare a real

374
00:23:46,668 --> 00:23:49,800
live demo, but let me show you, what does that mean?

375
00:23:50,490 --> 00:23:52,680
So this is an example.

376
00:23:53,770 --> 00:23:57,350
We installed nebula, which is the build system. Oops, sorry.

377
00:23:57,500 --> 00:24:00,902
We installed nebula, which is the build system for

378
00:24:00,956 --> 00:24:04,506
lira. It's the official one, it's still in beta, but it's working pretty fine.

379
00:24:04,608 --> 00:24:07,866
So as you can see, we basically install it from NPM. And when

380
00:24:07,888 --> 00:24:11,680
we look inside our folder right now in that demo,

381
00:24:12,210 --> 00:24:16,506
we have two files, data JSon and Lira Yaml.

382
00:24:16,698 --> 00:24:21,146
So let's see what's inside those files. If we can lira

383
00:24:21,258 --> 00:24:25,726
YML, we will see that we have a schema, which is a normal

384
00:24:25,758 --> 00:24:30,158
schema definition for lira. We already saw that sharding automatic

385
00:24:30,254 --> 00:24:33,586
or we don't want sharding, I don't know, that's up to

386
00:24:33,608 --> 00:24:37,634
you. An output file. So in that case, bundle JS.

387
00:24:37,682 --> 00:24:41,714
So it will generate a lira application containing

388
00:24:41,762 --> 00:24:45,218
the data inside the bundle JS file.

389
00:24:45,394 --> 00:24:48,662
The kind of data that we have in that kind is of type JSON,

390
00:24:48,726 --> 00:24:51,770
and it comes from the data JSON file.

391
00:24:52,510 --> 00:24:55,930
You could also use type JavaScript

392
00:24:57,710 --> 00:25:01,574
and as a source use, let's say Foo JS, which exports

393
00:25:01,622 --> 00:25:05,050
default, can asynchronous function, so that you can call a database,

394
00:25:05,130 --> 00:25:08,414
get the data, and get the data from there, basically. So you can

395
00:25:08,452 --> 00:25:11,946
interact with the database, but that's up to you. Let's use JSON, that it's

396
00:25:11,978 --> 00:25:15,758
easier. And the target in that case is cloudflare workers.

397
00:25:15,934 --> 00:25:19,650
And we can configure, for example the cloudflare worker name,

398
00:25:19,720 --> 00:25:23,330
in that case Pockydex, because we are going to deploy Pockydex

399
00:25:24,790 --> 00:25:28,146
if we want to run tests, true or false. In that case, we want to

400
00:25:28,168 --> 00:25:31,494
run tests. If we go see the data that we have

401
00:25:31,532 --> 00:25:34,786
inside data JSON, as you can see here, it follows

402
00:25:34,818 --> 00:25:37,694
the schema definition. So we have a lot of pokemons,

403
00:25:37,762 --> 00:25:41,926
and that's really it. We can now run nebula

404
00:25:41,958 --> 00:25:45,594
bundle or nebula D, which stands for

405
00:25:45,632 --> 00:25:48,886
deploy, so it will bundle and deploy.

406
00:25:48,998 --> 00:25:51,390
And as you can see, in just 5 seconds,

407
00:25:52,290 --> 00:25:55,610
we've been able to deploy everything to cloudflare workers.

408
00:25:55,690 --> 00:25:59,082
So if we make a search with the CRL for Pica,

409
00:25:59,146 --> 00:26:02,446
for example, we will get a response and we

410
00:26:02,468 --> 00:26:05,554
are running on can edge network, in that case,

411
00:26:05,592 --> 00:26:09,538
cloudflare workers. So congratulations. In like

412
00:26:09,624 --> 00:26:13,486
5 seconds, we just deployed the very first full text search engines

413
00:26:13,518 --> 00:26:17,294
capable of running on an edge network lira.

414
00:26:17,422 --> 00:26:20,774
It's free and open source and I will be

415
00:26:20,812 --> 00:26:24,470
there if any one of you needs some help setting up it,

416
00:26:24,540 --> 00:26:27,926
creating a target architecture. This is a service I can

417
00:26:28,108 --> 00:26:32,018
kind of help you with. So if you need something, I'd like

418
00:26:32,044 --> 00:26:35,402
to hear from you. I'd like to hear your feedbacks on Lira. If you have

419
00:26:35,456 --> 00:26:39,674
any kind of questions, please feel free to reach out to me directly at

420
00:26:39,712 --> 00:26:43,102
Michele Rivacode on Twitter. But we also have

421
00:26:43,236 --> 00:26:46,526
a slack channel where you can find help from a community,

422
00:26:46,628 --> 00:26:51,680
from me, from my colleagues working on Lira. So please join lirasearch slack.com.

423
00:26:52,050 --> 00:26:55,762
This is where we make lira happen. And before I end

424
00:26:55,816 --> 00:26:59,346
my speech, I'd like to thank Nearform. We are

425
00:26:59,368 --> 00:27:03,534
a professional service company specializing

426
00:27:03,582 --> 00:27:07,006
node JS DevOps react native. We maintain

427
00:27:07,038 --> 00:27:11,042
a lot of open source software. We are responsible for the maintenance

428
00:27:11,106 --> 00:27:14,946
of almost 8% of all the NPI modules used globally,

429
00:27:15,058 --> 00:27:18,194
which gets downloaded like 1 billion times per month, which is totally

430
00:27:18,242 --> 00:27:21,714
crazy. And we are hiring so worldwide

431
00:27:21,762 --> 00:27:25,378
for remote. If you are interested, please feel free to reach out. And I'd

432
00:27:25,394 --> 00:27:29,366
like to thank Nearform for letting me working on lira and presenting this to

433
00:27:29,388 --> 00:27:32,686
you today. So thank you so much. Thank you all for

434
00:27:32,708 --> 00:27:36,206
following this talk. And this is where you can find me, mainly on

435
00:27:36,228 --> 00:27:39,694
Twitter because this is where I live most. Thank again has

436
00:27:39,732 --> 00:27:42,654
been a pleasure. I hope to see you all very, very soon.

