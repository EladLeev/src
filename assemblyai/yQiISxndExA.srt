1
00:00:27,890 --> 00:00:31,318
Hi there. In this session we're going to talk about

2
00:00:31,404 --> 00:00:35,042
cloud native chaos engineering and how to do it at scale.

3
00:00:35,186 --> 00:00:38,946
I am Uma Mukkara, CEO at Chaos native and I'm

4
00:00:38,978 --> 00:00:42,914
also a maintainer of Litmus Chaos CNCF sandbox

5
00:00:42,962 --> 00:00:46,338
project. I live in Bangalore with my two boys and my wife.

6
00:00:46,434 --> 00:00:49,902
I've been doing a lot of entrepreneurial stuff

7
00:00:49,996 --> 00:00:52,986
in the last decade, starting with Cloud Byte,

8
00:00:53,098 --> 00:00:56,634
which is a storage startup for service providers.

9
00:00:56,762 --> 00:01:00,218
Then I later on started Openebs and myadata,

10
00:01:00,314 --> 00:01:04,270
where I also started a project called Litmus

11
00:01:04,430 --> 00:01:08,206
for Cloud Native Chaos Engineering, which is also a CNCF

12
00:01:08,238 --> 00:01:11,874
project. Recently we spun off from my data to

13
00:01:11,912 --> 00:01:15,618
completely focus on litmus chaos and

14
00:01:15,704 --> 00:01:19,590
cloud native chaos engineering. I'm happy to be here

15
00:01:19,740 --> 00:01:23,314
talking about what is cloud native chaos engineering at this Chaos

16
00:01:23,362 --> 00:01:27,046
engineering conference of Conf 42. Let's talk

17
00:01:27,068 --> 00:01:30,838
a little bit about reliability. What is reliability?

18
00:01:31,014 --> 00:01:35,290
It's about achieving resilience for operations using

19
00:01:35,440 --> 00:01:40,734
chaos engineering. That's a regular definition that

20
00:01:40,772 --> 00:01:44,174
we've been hearing about reliability. And what

21
00:01:44,212 --> 00:01:47,694
about cloud native? Cloud native usually is

22
00:01:47,732 --> 00:01:51,278
associated with containerization, where you

23
00:01:51,444 --> 00:01:55,870
change or rearchitect your applications for using microservices

24
00:01:55,950 --> 00:02:00,110
architecture. And you also apply the advancements

25
00:02:00,190 --> 00:02:04,082
of CACD, where you get your

26
00:02:04,216 --> 00:02:08,374
code tested pretty well using these

27
00:02:08,412 --> 00:02:12,134
advancements. And also you try to make use of

28
00:02:12,252 --> 00:02:16,466
all the declarative nature of these services or applications

29
00:02:16,578 --> 00:02:20,330
and apply githubs to manage them at scale. So in effect,

30
00:02:20,480 --> 00:02:23,802
cloud native is nothing but microservices are

31
00:02:23,856 --> 00:02:27,526
being delivered faster. Your applications,

32
00:02:27,718 --> 00:02:31,774
which are now multiple microservices sre being

33
00:02:31,812 --> 00:02:35,422
delivered faster, that's the net effect of

34
00:02:35,476 --> 00:02:39,786
cloud native ecosystem. What about reliability?

35
00:02:39,898 --> 00:02:43,202
In cloud native we talked about what is cloud

36
00:02:43,256 --> 00:02:46,500
native and what is reliability. How do you apply these together?

37
00:02:47,110 --> 00:02:51,214
Well, it's applying chaos engineering

38
00:02:51,262 --> 00:02:55,066
to achieve resilience in operations in the cloud native

39
00:02:55,118 --> 00:02:58,770
ecosystem, and you still get faster

40
00:02:58,930 --> 00:03:02,230
application delivery. So in essence,

41
00:03:02,570 --> 00:03:06,262
it's about applying chaos engineering for

42
00:03:06,316 --> 00:03:09,986
the resilience of cloud native applications. And that's

43
00:03:10,018 --> 00:03:13,706
what we're going to talk about in this session. Why is it different, what it

44
00:03:13,728 --> 00:03:16,906
is? And how do you do that? Before we jump in,

45
00:03:17,008 --> 00:03:20,330
let's talk a little bit about traditional chaos engineering.

46
00:03:21,570 --> 00:03:25,690
Traditional chaos engineering is all about avoiding

47
00:03:25,770 --> 00:03:29,306
expensive downtimes. We all know that these downtimes

48
00:03:29,338 --> 00:03:32,978
are not easy to deal with. They will usually

49
00:03:33,064 --> 00:03:38,590
result in expensive losses.

50
00:03:38,750 --> 00:03:42,850
And what you do as part of practising

51
00:03:43,590 --> 00:03:47,074
chaos engineering is you don't wait for failure

52
00:03:47,122 --> 00:03:51,090
to occur. You keep testing in production, you keep introducing

53
00:03:51,170 --> 00:03:54,854
faults in production, and then see if your services can hold

54
00:03:54,892 --> 00:03:58,234
up. If not, you tune the system and these you

55
00:03:58,272 --> 00:04:01,450
learn, right? So that's the feedback loop that

56
00:04:01,600 --> 00:04:05,594
we keep talking about in chaos engineering and

57
00:04:05,632 --> 00:04:08,410
the general state of chaos engineering till recently,

58
00:04:08,830 --> 00:04:12,320
I would say till 2019 or 20,

59
00:04:12,690 --> 00:04:16,362
is we all understood. What is chaos engineering?

60
00:04:16,426 --> 00:04:20,330
It's supposed to be a standard, and it has been limited to experts

61
00:04:20,410 --> 00:04:23,858
and enthusiasts and people

62
00:04:24,024 --> 00:04:28,110
operating. Large deployments typically follow chaos engineering,

63
00:04:28,270 --> 00:04:32,094
right? And chaos engineering is generally

64
00:04:32,142 --> 00:04:36,150
started after you burn your hands with these downtime

65
00:04:36,650 --> 00:04:39,030
as part of the root cause analysis,

66
00:04:39,850 --> 00:04:43,586
you will resolve that we need to practice chaos engineering.

67
00:04:43,618 --> 00:04:47,442
So let's start doing it. That's how typically it has been done

68
00:04:47,596 --> 00:04:50,860
till recently, a year or so. Right?

69
00:04:51,230 --> 00:04:54,666
And how they've been doing is we

70
00:04:54,688 --> 00:04:58,122
all know that game days SRE, the ways that you keep using

71
00:04:58,176 --> 00:05:02,538
it and you integrate into CACD,

72
00:05:02,634 --> 00:05:06,334
but not like has a thumb rule. They're being done

73
00:05:06,452 --> 00:05:09,070
pretty rarely, not as a standard practice.

74
00:05:09,650 --> 00:05:13,362
And it is typically limited so far to

75
00:05:13,416 --> 00:05:17,406
sres. Developers limit their testing to CI

76
00:05:17,438 --> 00:05:20,866
pipelines, the regular functional testing, or a little bit of

77
00:05:20,888 --> 00:05:24,290
negative testing. It's not deep chaos testing,

78
00:05:25,050 --> 00:05:29,334
and also the measurement of results is

79
00:05:29,372 --> 00:05:33,894
also not standardized or there are no tools exist to do that.

80
00:05:34,092 --> 00:05:38,234
And observability is also done through whatever

81
00:05:38,352 --> 00:05:42,118
the tools that were available and manual operations,

82
00:05:42,214 --> 00:05:45,770
manual scripting, all that stuff. So overall,

83
00:05:46,430 --> 00:05:50,082
so far, chaos engineering is well understood

84
00:05:50,246 --> 00:05:54,080
why part of it, and many

85
00:05:54,450 --> 00:05:58,666
large companies who are operating large data centers and applications

86
00:05:58,698 --> 00:06:02,730
have been doing it, and it is

87
00:06:02,900 --> 00:06:06,238
still about manually planning it and manually

88
00:06:06,334 --> 00:06:09,700
executing it. And there are no

89
00:06:10,390 --> 00:06:13,854
certain defined ways of doing chaos

90
00:06:13,902 --> 00:06:17,910
engineering where people with common

91
00:06:17,980 --> 00:06:21,798
knowledge of operations can go ahead and then practice it.

92
00:06:21,964 --> 00:06:24,946
So that's the state of affairs,

93
00:06:25,058 --> 00:06:29,110
in my opinion, of chaos engineering till recently.

94
00:06:29,270 --> 00:06:33,354
Before we go into cloud native and chaos engineering, let's see

95
00:06:33,472 --> 00:06:37,194
the state of affairs of cloud native and chaos engineering itself

96
00:06:37,312 --> 00:06:41,402
with respect to crossing the chasm Kubernetes

97
00:06:41,466 --> 00:06:45,354
is pretty well adopted now, and it is believed

98
00:06:45,402 --> 00:06:47,280
to be in the mainstream market,

99
00:06:48,610 --> 00:06:51,918
whereas chaos engineering is believed to be still

100
00:06:52,004 --> 00:06:55,250
in its early days in these cloud native ecosystem.

101
00:06:55,830 --> 00:06:59,502
And that's probably I'm going to touch upon

102
00:06:59,646 --> 00:07:02,642
why is it so important? Right?

103
00:07:02,696 --> 00:07:05,794
So why can't you go ahead and then practice

104
00:07:05,842 --> 00:07:09,538
chaos engineering the regular way in cloud native ecosystem?

105
00:07:09,714 --> 00:07:13,170
Right? So what is chaos engineering

106
00:07:13,250 --> 00:07:16,502
done in cloud native environment is

107
00:07:16,556 --> 00:07:20,010
called? It's called as cloud native chaos engineering.

108
00:07:20,830 --> 00:07:24,854
Why should there be any difference in practicing

109
00:07:24,902 --> 00:07:27,770
of chaos engineering in the cloud native ecosystem?

110
00:07:29,710 --> 00:07:33,774
I would say primarily there are two reasons why we should look

111
00:07:33,812 --> 00:07:35,950
at chaos engineering differently.

112
00:07:36,930 --> 00:07:40,686
One is more dynamism the other is the

113
00:07:40,708 --> 00:07:44,046
way DevOps has changed with respect

114
00:07:44,078 --> 00:07:46,210
to infrastructure provisioning.

115
00:07:47,270 --> 00:07:50,158
So let's talk a little bit about dynamism,

116
00:07:50,334 --> 00:07:53,358
right? So it started with containerization,

117
00:07:53,534 --> 00:07:56,200
where an application is broken into,

118
00:07:56,730 --> 00:07:59,894
split into multiple microservices. So instead of

119
00:07:59,932 --> 00:08:04,354
dealing with one large application, you have multiple smaller

120
00:08:04,482 --> 00:08:06,520
microservices to deal with.

121
00:08:07,390 --> 00:08:10,486
And they are actually being tested

122
00:08:10,598 --> 00:08:14,454
with pretty nicely done CACD pipelines.

123
00:08:14,582 --> 00:08:18,218
And the goal here is to deliver them faster. So there are

124
00:08:18,224 --> 00:08:21,098
a lot of advancements in CI and CD.

125
00:08:21,194 --> 00:08:24,750
New tools are available and they're being made easier.

126
00:08:25,250 --> 00:08:28,862
And the net effect of that is instead

127
00:08:28,916 --> 00:08:32,410
of typical releases happening in 90

128
00:08:32,500 --> 00:08:36,126
days or 180 days of large systems,

129
00:08:36,318 --> 00:08:39,122
you get these almost every week,

130
00:08:39,256 --> 00:08:42,254
right? You have multiple microservices.

131
00:08:42,382 --> 00:08:45,894
Something or other is being changed all the

132
00:08:45,932 --> 00:08:49,320
time, at least once in a week in very large system.

133
00:08:50,250 --> 00:08:54,114
Look at this cloud native ecosystem, the dynamism.

134
00:08:54,242 --> 00:08:57,526
There are so many players working together under the

135
00:08:57,548 --> 00:09:01,210
leadership of CNCF, and it is working very, very well.

136
00:09:01,280 --> 00:09:05,514
There are a lot of coordination is going on. And the

137
00:09:05,552 --> 00:09:08,842
net effect of all these is you are

138
00:09:08,896 --> 00:09:12,254
getting very dynamic changes all

139
00:09:12,292 --> 00:09:16,142
the time into your system. If you sre in

140
00:09:16,196 --> 00:09:17,950
cloud native ecosystem,

141
00:09:18,850 --> 00:09:22,154
right? And then imagine doing chaos

142
00:09:22,202 --> 00:09:24,820
engineering in that system,

143
00:09:26,150 --> 00:09:30,398
you also have to be very dynamic in terms of doing chaos engineering.

144
00:09:30,574 --> 00:09:34,750
And the other one is DevOps being changed.

145
00:09:34,830 --> 00:09:38,418
And it's not about left shift

146
00:09:38,594 --> 00:09:42,502
containerization coming faster, it's about

147
00:09:42,556 --> 00:09:46,998
infrastructure provisioning. So how

148
00:09:47,084 --> 00:09:50,890
infrastructure provisioning has changed, first of all, it is now 100%

149
00:09:50,960 --> 00:09:54,950
declarative. Everybody provides an API, a declarative

150
00:09:55,030 --> 00:09:59,034
API where developers can go ahead and write the

151
00:09:59,072 --> 00:10:02,926
declarative code or syntax to

152
00:10:02,948 --> 00:10:06,446
get the infrastructure they want. They're not waiting for anyone to

153
00:10:06,468 --> 00:10:09,742
provision the infrastructure for them, they're doing it themselves.

154
00:10:09,876 --> 00:10:13,342
Right. And by following

155
00:10:13,406 --> 00:10:16,430
the practice of Gitops, which is on these raise,

156
00:10:16,590 --> 00:10:20,462
developers are going ahead and getting the infrastructure

157
00:10:20,526 --> 00:10:23,474
through APIs that they want, right?

158
00:10:23,672 --> 00:10:26,920
So it is happening already.

159
00:10:27,290 --> 00:10:31,906
And because the infrastructure is getting provisioned

160
00:10:31,938 --> 00:10:35,750
left and right, it also means that the system

161
00:10:35,900 --> 00:10:39,562
could be less resilient, because the faults can

162
00:10:39,616 --> 00:10:43,514
happen very much

163
00:10:43,712 --> 00:10:47,178
in the infrastructure and typically they do happen in the

164
00:10:47,184 --> 00:10:51,034
infrastructure. So your applications are coming faster

165
00:10:51,162 --> 00:10:55,002
into production in terms of microservices updates.

166
00:10:55,146 --> 00:10:59,642
And developers are also provisioning these infrastructure underneath,

167
00:10:59,706 --> 00:11:03,970
changing the infrastructure underneath that these applications run upon

168
00:11:04,310 --> 00:11:07,746
frequently. So both of these things together

169
00:11:07,928 --> 00:11:11,086
will cause a problem for resilience,

170
00:11:11,198 --> 00:11:15,394
right? And that's what chaos

171
00:11:15,442 --> 00:11:19,240
engineering in cloud native has to be aware of.

172
00:11:20,090 --> 00:11:23,602
So in summary, there's more dynamism

173
00:11:23,746 --> 00:11:26,838
and there's more infrastructure changes. So you need to

174
00:11:26,844 --> 00:11:30,150
be doing cloud native chaos engineering.

175
00:11:30,310 --> 00:11:33,834
So how do you do this differently in

176
00:11:33,872 --> 00:11:37,322
cloud native ecosystem? So I have

177
00:11:37,376 --> 00:11:41,454
come up with certain general principles of

178
00:11:41,492 --> 00:11:45,246
practicing chaos engineering. Or how do

179
00:11:45,268 --> 00:11:47,870
you do with set of principles?

180
00:11:48,530 --> 00:11:52,720
I'm setting up around five of them these.

181
00:11:53,350 --> 00:11:56,706
Till recently in my blogs I've written four.

182
00:11:56,888 --> 00:12:00,846
But recently I've observed open observability

183
00:12:00,958 --> 00:12:04,990
is a big deal. So you have to have

184
00:12:05,080 --> 00:12:08,434
a common layer of observability to do chaos

185
00:12:08,482 --> 00:12:11,878
engineering in cloud native ecosystem. I'll talk about that.

186
00:12:11,964 --> 00:12:16,806
But first of all, it has to be open source. And by

187
00:12:16,988 --> 00:12:20,914
having this infrastructure or architecture

188
00:12:21,042 --> 00:12:24,170
for chaos engineering in open source, you sre getting

189
00:12:24,240 --> 00:12:27,286
a more reliable stack

190
00:12:27,398 --> 00:12:31,326
for doing chaos engineering. Kubernetes and the entire CNSafe is an

191
00:12:31,348 --> 00:12:35,390
example of that. All these projects are well cooked,

192
00:12:36,050 --> 00:12:40,270
well architected, well designed and well reviewed.

193
00:12:41,170 --> 00:12:44,722
And chaos experiments, which in my opinion will become

194
00:12:44,776 --> 00:12:49,410
a commodity at some point. They have to be community collaborated

195
00:12:49,830 --> 00:12:52,882
so that there are no false alarms coming out.

196
00:12:53,016 --> 00:12:58,002
Right. And you need not spend a lot of time writing

197
00:12:58,146 --> 00:13:02,006
the most common chaos experiments so they can

198
00:13:02,028 --> 00:13:05,638
be hosted somewhere and they should be available

199
00:13:05,724 --> 00:13:09,606
for most commonly required

200
00:13:09,718 --> 00:13:13,382
chaos operations. And chaos

201
00:13:13,446 --> 00:13:16,858
itself has to be managed at scale. So that means that

202
00:13:17,024 --> 00:13:21,502
the chaos experiments need to be versioned and they

203
00:13:21,636 --> 00:13:25,278
need to follow a lifecycle of their own. So you

204
00:13:25,284 --> 00:13:30,126
need to have open API and the

205
00:13:30,148 --> 00:13:33,070
versioning support for chaos experiments.

206
00:13:33,670 --> 00:13:37,634
And how do you do this at scale? The challenge is

207
00:13:37,672 --> 00:13:41,278
always about doing anything at scale is a challenge,

208
00:13:41,374 --> 00:13:44,986
right? So the same thing applies to chaos

209
00:13:45,038 --> 00:13:48,726
engineering in cloud native ecosystems also. So when

210
00:13:48,748 --> 00:13:52,354
you're doing it at big scale, you need to automate

211
00:13:52,402 --> 00:13:56,802
everything. And the right way to do it is using Gitops.

212
00:13:56,866 --> 00:14:00,774
So the entire chaos engineering construction

213
00:14:00,822 --> 00:14:04,470
has to be declarative and has to be supported

214
00:14:04,550 --> 00:14:08,406
by the well known tools like Argo CD

215
00:14:08,438 --> 00:14:12,302
or flux or spinner cut and so forth. And open

216
00:14:12,356 --> 00:14:15,534
observability is an important thing. As I mentioned a little

217
00:14:15,572 --> 00:14:18,974
while ago, observability is a key

218
00:14:19,012 --> 00:14:22,186
thing, especially when you introduce

219
00:14:22,218 --> 00:14:25,618
a fault, and you need to be

220
00:14:25,624 --> 00:14:29,554
able to go and debug whether a certain change in behavior is

221
00:14:29,592 --> 00:14:33,186
because of the fault that I introduced or is it

222
00:14:33,208 --> 00:14:37,314
because of something else that happened coincidentally. So these

223
00:14:37,352 --> 00:14:40,982
are the principles of cloud native chaos engineering. You need to

224
00:14:41,036 --> 00:14:44,646
have an eye on it. You need not follow all of them all the time,

225
00:14:44,748 --> 00:14:48,140
but it's good to have all of them

226
00:14:48,830 --> 00:14:51,130
being followed, in my opinion.

227
00:14:51,870 --> 00:14:55,674
So I want to introduce Litmus project,

228
00:14:55,872 --> 00:15:00,306
which is actually built based on these principles.

229
00:15:00,438 --> 00:15:03,870
And we've been building it for about three years

230
00:15:03,940 --> 00:15:07,742
now. And I'm happy

231
00:15:07,796 --> 00:15:11,502
to say that we sre almost there with all of them,

232
00:15:11,636 --> 00:15:15,314
and especially the first three of them have been

233
00:15:15,432 --> 00:15:18,926
there for more than a year now. And we are releasing Litmus

234
00:15:18,958 --> 00:15:23,170
20 very soon with githubs and open observability

235
00:15:23,830 --> 00:15:27,734
features. So basically you

236
00:15:27,772 --> 00:15:31,138
got all these cloud native chaos engineering principles

237
00:15:31,234 --> 00:15:34,040
well adhered by the Litmus project.

238
00:15:34,490 --> 00:15:38,040
Let's look at Litmus a little bit more detail.

239
00:15:39,150 --> 00:15:42,602
It's a platform for doing, it's a complete tool

240
00:15:42,656 --> 00:15:46,186
set for doing cloud native chaos engineering. And it

241
00:15:46,208 --> 00:15:49,980
comes with a simple helm chart where

242
00:15:52,990 --> 00:15:56,974
you will be installing and doing chaos workflows. I'll touch upon it,

243
00:15:57,092 --> 00:16:02,682
but basically it all starts with a simple Kubernetes

244
00:16:02,746 --> 00:16:06,286
application called Litmus. And using helm

245
00:16:06,318 --> 00:16:10,126
you can install it. And you already have all these experiments

246
00:16:10,238 --> 00:16:13,742
that are needed to do your chaos workflows in a public hub.

247
00:16:13,886 --> 00:16:17,922
And you will end up having your own private hub

248
00:16:17,986 --> 00:16:21,894
for coordination of the new experiments that you write or

249
00:16:21,932 --> 00:16:25,414
tuned ones with your team through

250
00:16:25,452 --> 00:16:29,350
a private hub. So once you install litmus

251
00:16:29,510 --> 00:16:33,562
through the helm chart, you will have something

252
00:16:33,616 --> 00:16:37,466
called litmus portal. It's a centralized place where all your

253
00:16:37,488 --> 00:16:41,978
chaos engineering efforts are coordinated

254
00:16:42,154 --> 00:16:45,834
and you will be pulling in the experiments

255
00:16:45,882 --> 00:16:49,658
or referring to the experiments on public or private hubs.

256
00:16:49,834 --> 00:16:52,590
And you can run chaos workflows anywhere,

257
00:16:53,270 --> 00:16:56,482
either any Kubernetes cloud or

258
00:16:56,536 --> 00:17:00,162
any kubernetes on Prem. And it is not limited only

259
00:17:00,216 --> 00:17:04,642
to kubernetes. You can run these chaos experiments from

260
00:17:04,696 --> 00:17:08,226
litmus portal, from these

261
00:17:08,248 --> 00:17:11,738
kubernetes ecosystem, but the targets can be non

262
00:17:11,774 --> 00:17:15,730
kubernetes as well. And then if you're doing it at scale,

263
00:17:15,890 --> 00:17:20,182
you better do it through Gitops. So Litmus

264
00:17:20,246 --> 00:17:23,910
provides an option whether you want to store all your configuration

265
00:17:24,070 --> 00:17:28,042
in the local database or in a git. And then

266
00:17:28,096 --> 00:17:32,254
once you store them in git, you can

267
00:17:32,292 --> 00:17:35,982
automatically do easier integration with

268
00:17:36,036 --> 00:17:39,306
any of these CD tools. So let's

269
00:17:39,338 --> 00:17:43,086
go and look at in a little bit more detail. You have central Litmus

270
00:17:43,118 --> 00:17:46,514
portal and all you do is you can pick up

271
00:17:46,552 --> 00:17:50,146
a predefined chaos workflow, or you can create a

272
00:17:50,168 --> 00:17:53,730
chaos workflow and you run it against

273
00:17:53,800 --> 00:17:57,942
a target, and the target is

274
00:17:57,996 --> 00:18:01,586
where the chaos operator will be spun and the experiments

275
00:18:01,618 --> 00:18:05,558
will be run. So you can have multiple targets connected to the

276
00:18:05,564 --> 00:18:09,082
same portal. So you don't install litmus again and again. You install

277
00:18:09,136 --> 00:18:13,034
Litmus once per your enterprise or a team,

278
00:18:13,152 --> 00:18:16,758
and these you're good to go. You have rbacs

279
00:18:16,774 --> 00:18:20,526
and everything in Litmus portal. And then once these experiments are

280
00:18:20,548 --> 00:18:25,450
run, the metrics are exported back to Prometheus,

281
00:18:25,610 --> 00:18:29,502
the observability system and the analytics sre

282
00:18:29,556 --> 00:18:32,914
pushed back into the portal. Out of

283
00:18:32,952 --> 00:18:35,938
all this, the previous one I talked about,

284
00:18:36,104 --> 00:18:39,426
workflow is a key element. It's one

285
00:18:39,448 --> 00:18:42,690
of the innovations that happened

286
00:18:42,840 --> 00:18:46,486
in the last six months within the litmus team.

287
00:18:46,668 --> 00:18:50,322
So I want to talk a little bit about litmus chaos

288
00:18:50,386 --> 00:18:53,880
workflow, what it is. So it is basically

289
00:18:54,250 --> 00:18:58,326
argo workflow consisting of multiple

290
00:18:58,518 --> 00:19:02,454
chaos experiments, and you can arrange them in sequence

291
00:19:02,502 --> 00:19:06,570
or in parallel, or a combination of them and

292
00:19:06,720 --> 00:19:11,194
they get run. And litmus chaos workflow also consists

293
00:19:11,242 --> 00:19:13,950
of consolidated results and status.

294
00:19:14,690 --> 00:19:19,022
So that is one workflow. So that is a unit of

295
00:19:19,076 --> 00:19:22,586
execution or management for

296
00:19:22,628 --> 00:19:26,178
you within Litmus. And using

297
00:19:26,264 --> 00:19:29,730
workflow, keeping all the configuration, the complex

298
00:19:30,630 --> 00:19:35,294
workflow in a declarative manner, we sre saying chaos

299
00:19:35,342 --> 00:19:39,240
engineering and githubs can be put together

300
00:19:39,850 --> 00:19:44,066
using this declarative nature. And argo workflow

301
00:19:44,178 --> 00:19:48,154
is a pretty stable. In fact, it is in

302
00:19:48,192 --> 00:19:52,502
incubation stage within CNCF,

303
00:19:52,566 --> 00:19:55,686
a very widely used tool. So I'm

304
00:19:55,718 --> 00:20:00,146
pretty sure you will have great experience using argon litmus

305
00:20:00,198 --> 00:20:03,914
together. So if you want to go a little bit deep dive,

306
00:20:03,962 --> 00:20:06,480
how does the chaos workflow work?

307
00:20:07,650 --> 00:20:11,530
So basically your experiments are in Chaos hub.

308
00:20:11,690 --> 00:20:14,754
The chaos workflow refers to the

309
00:20:14,792 --> 00:20:19,074
experiments on this hub, and you

310
00:20:19,112 --> 00:20:22,722
always keep them in a hub, either public hub, you can refer

311
00:20:22,776 --> 00:20:26,526
to them and then tune them through Yaml file. Or if you are changing

312
00:20:26,558 --> 00:20:29,766
some of these experiments, you can keep these in a private, or if you are

313
00:20:29,788 --> 00:20:33,474
creating new one using the sdks, you can keep them in private hub.

314
00:20:33,522 --> 00:20:36,806
But ultimately a workflow refers to an

315
00:20:36,828 --> 00:20:41,862
experiment within a hub somewhere. So if

316
00:20:41,916 --> 00:20:46,358
you want to kick start this workflow

317
00:20:46,454 --> 00:20:50,058
and you create the workflow, push it. So somebody

318
00:20:50,144 --> 00:20:53,846
recognizes that these is a change, either manually executed

319
00:20:53,878 --> 00:20:58,606
or through GitHub. Finally, chaos engine is

320
00:20:58,628 --> 00:21:01,914
the one that's responsible for kickstarting. So chaos

321
00:21:01,962 --> 00:21:05,954
operator will be watching for the change in chaos engine and

322
00:21:06,072 --> 00:21:09,300
then the experiments will be run and

323
00:21:09,670 --> 00:21:13,438
exporter litmus chaos exporter will take the results

324
00:21:13,534 --> 00:21:17,370
metrics and push it back into Prometheus. The chaos results

325
00:21:17,390 --> 00:21:21,346
CRD will be created, and the result of the chaos experiments

326
00:21:21,458 --> 00:21:25,960
in this case will be pushed back into these litmus for

327
00:21:26,410 --> 00:21:30,482
analysis and debugging or monitoring purposes.

328
00:21:30,626 --> 00:21:34,200
So that's how a chaos workflow happened. And then these

329
00:21:34,590 --> 00:21:38,406
workflows, many of them are available as a predefined workflows.

330
00:21:38,438 --> 00:21:41,502
You just need to configure them, attune them.

331
00:21:41,556 --> 00:21:45,182
And these, you are good to go. And these

332
00:21:45,236 --> 00:21:49,306
chaos workflows can be run against multiple targets, and it's

333
00:21:49,338 --> 00:21:52,974
basically a multi cloud chaos

334
00:21:53,022 --> 00:21:57,060
engineering ecosystem here that we are talking about

335
00:21:58,230 --> 00:22:01,774
in terms of experiments list. Litmus provides

336
00:22:01,822 --> 00:22:05,342
a lot of experiments of all types,

337
00:22:05,486 --> 00:22:09,282
a few more or in the works, Ivo chaos and DNS chaos,

338
00:22:09,346 --> 00:22:12,598
all that stuff. But you got

339
00:22:12,684 --> 00:22:16,440
pretty much everything that you need to start

340
00:22:17,210 --> 00:22:21,246
today. And another thing that lateness

341
00:22:21,298 --> 00:22:25,382
provides is how to define

342
00:22:25,446 --> 00:22:29,270
your hypothesis using probes.

343
00:22:29,350 --> 00:22:33,166
You can define the steady state hypothesis in

344
00:22:33,188 --> 00:22:36,814
a declarative way using probes, and using

345
00:22:36,852 --> 00:22:40,718
probes and annotations, you will be able to mark

346
00:22:40,884 --> 00:22:44,722
what was the chaos duration on

347
00:22:44,776 --> 00:22:48,274
any regular grafanographs, for example.

348
00:22:48,472 --> 00:22:52,686
It also provides a good deal of analytics litmus

349
00:22:52,718 --> 00:22:57,014
portal about comparing resilience within

350
00:22:57,052 --> 00:23:00,694
the workflows that are run at the same time

351
00:23:00,732 --> 00:23:04,694
or at different times, all that stuff. So you have great

352
00:23:04,732 --> 00:23:08,474
beginnings of the observability that is built in, rather than depending on

353
00:23:08,512 --> 00:23:10,170
some external tools.

354
00:23:11,230 --> 00:23:14,650
And chaos interleaving is an important concept.

355
00:23:14,990 --> 00:23:17,930
How about CI in pipelines, right?

356
00:23:18,000 --> 00:23:21,386
So there is a lot of advancements, lot of interest in CI.

357
00:23:21,498 --> 00:23:26,058
So what we have done is we have created Litmus

358
00:23:26,154 --> 00:23:28,746
CI library, Chaos library.

359
00:23:28,938 --> 00:23:32,550
And you can go ahead and create a chaos stage

360
00:23:32,730 --> 00:23:36,562
and use this library through

361
00:23:36,616 --> 00:23:41,342
this existing tools. So for example, if you're using GitLab,

362
00:23:41,486 --> 00:23:45,146
you can create a remote

363
00:23:45,198 --> 00:23:49,670
template for chaos that uses this wrapper

364
00:23:50,170 --> 00:23:54,274
of CI library wrapper, and then your remote template

365
00:23:54,322 --> 00:23:57,582
is ready. You don't need to really worry about execution

366
00:23:57,666 --> 00:24:00,762
of the underlying chaos workflow. It all happens

367
00:24:00,816 --> 00:24:04,586
automatically. So, so far we have done for

368
00:24:04,688 --> 00:24:08,390
GitLab and GitHub actions and Spinnaker,

369
00:24:08,470 --> 00:24:11,680
and most recently for Captain project.

370
00:24:12,130 --> 00:24:15,790
So these are the integrations that are available today,

371
00:24:15,860 --> 00:24:19,678
and many more may be coming pretty soon or later

372
00:24:19,764 --> 00:24:25,202
in this year. Litmus is known for being

373
00:24:25,256 --> 00:24:28,754
very strong for doing chaos engineering on

374
00:24:28,792 --> 00:24:32,606
kubernetes. But how about non Kubernetes? Does litmus

375
00:24:32,638 --> 00:24:36,342
support chaos engineering for non Kubernetes? The answer

376
00:24:36,396 --> 00:24:40,354
is yes. The experiment management and monitoring

377
00:24:40,402 --> 00:24:43,974
everything remains on kubernetes. And you

378
00:24:44,012 --> 00:24:47,734
can still execute experiments on these

379
00:24:47,772 --> 00:24:50,934
target, such as various different clouds,

380
00:24:50,982 --> 00:24:54,470
or your own vmware on Prem,

381
00:24:54,550 --> 00:24:57,530
or OpenStack on Prem, et cetera.

382
00:24:58,030 --> 00:25:01,950
So how it works is your experiments runs

383
00:25:03,010 --> 00:25:07,822
all the way till the last leg within

384
00:25:07,876 --> 00:25:12,650
kubernetes, but the actual chaos

385
00:25:12,810 --> 00:25:16,930
will be executed on the target by using the network access

386
00:25:17,000 --> 00:25:21,314
control APIs. So you need to write that logic of how

387
00:25:21,352 --> 00:25:24,814
do you kill that? And rest of the chaos engineering

388
00:25:24,862 --> 00:25:28,086
control plane will stay on kubernetes. And we

389
00:25:28,108 --> 00:25:31,926
do have some experiments like

390
00:25:32,108 --> 00:25:36,306
EC two terminate or EBS detach, GPD detach,

391
00:25:36,418 --> 00:25:41,014
and many more are the coming. So later this year I'm

392
00:25:41,062 --> 00:25:44,822
pretty sure we'll have many more such examples

393
00:25:44,886 --> 00:25:48,406
of doing chaos for non

394
00:25:48,438 --> 00:25:52,606
Kubernetes resources. So that's how it happens.

395
00:25:52,788 --> 00:25:56,414
As long as you have an API to reach that resource on the other

396
00:25:56,452 --> 00:26:00,254
side, you will be able to kill that

397
00:26:00,292 --> 00:26:02,110
resource using that API.

398
00:26:03,270 --> 00:26:06,670
So other one that I want to touch upon

399
00:26:06,830 --> 00:26:10,814
is what about CNCF projects and Litmus?

400
00:26:10,862 --> 00:26:14,386
What are the integrations that are available? And we

401
00:26:14,408 --> 00:26:17,934
have recently integrated both with these workflow and we've tested

402
00:26:17,982 --> 00:26:22,040
very well with Argo CD and certified it. We have also

403
00:26:22,890 --> 00:26:26,742
done close integration with captain by working through their

404
00:26:26,796 --> 00:26:29,498
team. A fantastic team, I would say.

405
00:26:29,664 --> 00:26:34,746
And of course, we've been the Open EBS team

406
00:26:34,848 --> 00:26:39,414
and Openebs is the one that started litmus

407
00:26:39,542 --> 00:26:43,974
integration to begin with. A lot of community members use chaos

408
00:26:44,022 --> 00:26:47,370
testing with open EBS and we SRE certified

409
00:26:47,450 --> 00:26:51,294
for other runtimes like Cryo and container D. That's where

410
00:26:51,332 --> 00:26:54,978
so far we got and we have in our short

411
00:26:55,064 --> 00:26:59,070
or medium roadmap to do some good integrations with the flux

412
00:26:59,230 --> 00:27:03,406
crossplane and ytest the database

413
00:27:03,518 --> 00:27:06,710
and for security open policy agent.

414
00:27:06,860 --> 00:27:10,134
So these are the projects that we have in mind to do

415
00:27:10,252 --> 00:27:14,040
some kind of integration along with

416
00:27:14,890 --> 00:27:18,330
usage of these projects.

417
00:27:18,990 --> 00:27:23,286
Here is the quick summary of the Litmus roadmap.

418
00:27:23,398 --> 00:27:27,260
I think I talked through most of it. You can just

419
00:27:28,590 --> 00:27:31,694
take a look at this in this recording. You can pause and take a look

420
00:27:31,732 --> 00:27:35,520
at this roadmap in detail if you want.

421
00:27:37,170 --> 00:27:40,634
Let's talk what we do at chaos

422
00:27:40,682 --> 00:27:43,954
native and more details about

423
00:27:44,072 --> 00:27:48,050
what chaos native can do for chaos engineering,

424
00:27:48,470 --> 00:27:51,746
both for cloud native and

425
00:27:51,768 --> 00:27:55,254
non cloud native environments. So the idea

426
00:27:55,292 --> 00:27:59,366
of v spinning off from my data is

427
00:27:59,548 --> 00:28:03,190
to provide more resources to the success

428
00:28:03,260 --> 00:28:07,046
of Litmus project and to accelerate the

429
00:28:07,068 --> 00:28:10,982
adoption of litmus by enterprise users.

430
00:28:11,126 --> 00:28:14,454
A lot of users, the enterprise

431
00:28:14,502 --> 00:28:18,170
big users have been using Litmus and they've been approaching

432
00:28:18,670 --> 00:28:22,302
if the litmus team can support. And of course, we've been using

433
00:28:22,356 --> 00:28:25,422
that from being part of my

434
00:28:25,476 --> 00:28:29,102
data. But now we felt it's time to go

435
00:28:29,156 --> 00:28:32,910
and put more focus, create more resources

436
00:28:33,510 --> 00:28:37,426
around Litmus. So that's how the company has been

437
00:28:37,608 --> 00:28:42,018
launched a few days ago. And how are we going to do

438
00:28:42,104 --> 00:28:46,082
that? Acceleration of enterprise adoption of Litmus

439
00:28:46,226 --> 00:28:49,858
is really by building a stronger community around Litmus.

440
00:28:50,034 --> 00:28:53,462
So community is very, very important and

441
00:28:53,596 --> 00:28:57,394
we want to encourage and demonstrate the

442
00:28:57,452 --> 00:29:01,402
open governance nature of litmus. So we will be putting

443
00:29:01,456 --> 00:29:05,418
more resources to work with more community members,

444
00:29:05,584 --> 00:29:08,922
large companies, in the cloud native ecosystem and

445
00:29:08,976 --> 00:29:12,510
work together to build a stronger community and the

446
00:29:12,580 --> 00:29:16,126
adoption increases. I just talked about the

447
00:29:16,148 --> 00:29:19,786
plans to integrate litmus with other CNCA projects,

448
00:29:19,898 --> 00:29:23,106
so all that requires more resources which

449
00:29:23,128 --> 00:29:27,730
we are now going to be able to allocate.

450
00:29:28,070 --> 00:29:32,130
So apart from enterprise support, we sre also thinking

451
00:29:32,200 --> 00:29:35,666
of doing CD tools integrations with

452
00:29:35,768 --> 00:29:38,906
many more of them and Katis

453
00:29:38,958 --> 00:29:43,154
distribution, testing and making sure that chaos

454
00:29:43,202 --> 00:29:46,370
engineering is done very easily in the air gapped environments.

455
00:29:46,450 --> 00:29:49,578
Also, and some of the customers are asking

456
00:29:49,664 --> 00:29:52,710
for managed services around chaos engineering.

457
00:29:52,870 --> 00:29:56,074
And we also have plans to launch chaos as

458
00:29:56,112 --> 00:29:59,562
a service at some point of time for

459
00:29:59,616 --> 00:30:03,342
making chaos easy for developers. So that's about

460
00:30:03,476 --> 00:30:06,974
this session where we talked about cloud

461
00:30:07,012 --> 00:30:10,558
native chaos engineering and the need for it. How do

462
00:30:10,564 --> 00:30:14,334
you do that? And I'm encouraging you

463
00:30:14,372 --> 00:30:17,806
to go ahead and give Litmus a try. And if you

464
00:30:17,828 --> 00:30:21,358
have any questions or need support,

465
00:30:21,524 --> 00:30:24,994
come back to the Litmus channel on Kubernetes Slack.

466
00:30:25,162 --> 00:30:28,806
With that, I hope you sre going to have a

467
00:30:28,828 --> 00:30:32,534
great conference on Conf 42 and have

468
00:30:32,572 --> 00:30:34,740
a fantastic day or evening. Thank you.

