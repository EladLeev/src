1
00:00:19,930 --> 00:00:23,562
Hi everyone, my name is Hussain and I'm a cloud engineer.

2
00:00:23,626 --> 00:00:26,726
In this session we will talk about how to build a software as a service

3
00:00:26,828 --> 00:00:30,710
including infrastructure management, payment system, these kind of scenarios.

4
00:00:31,610 --> 00:00:35,622
Let's take a look at scenario first here.

5
00:00:35,676 --> 00:00:39,366
In this outline you may need to do a configuration in your project.

6
00:00:39,468 --> 00:00:42,938
We will see it how to do a logging, proper logging in

7
00:00:42,944 --> 00:00:46,358
your application. How to generate artifacts including binaries,

8
00:00:46,454 --> 00:00:50,720
docker images how to do some kind of static code check in your project.

9
00:00:51,330 --> 00:00:54,874
How to include your project artifact

10
00:00:54,922 --> 00:00:57,630
generation into a pipeline, CI pipeline.

11
00:00:58,290 --> 00:01:01,966
We will check how to do infrastructure as code management and at

12
00:01:01,988 --> 00:01:05,250
the end we will see the payment system, how we can integrate with the payment

13
00:01:05,320 --> 00:01:09,362
system. Let's say that you are building a

14
00:01:09,496 --> 00:01:12,674
project go project. You can just start with go code in it,

15
00:01:12,712 --> 00:01:16,094
right? You provide your repo URL

16
00:01:16,142 --> 00:01:18,982
which is for example GitHub URL. Then that's it.

17
00:01:19,036 --> 00:01:22,278
Your project will be synchronized to GitHub. You can push it

18
00:01:22,284 --> 00:01:26,040
to removed, you can pull it again. So this will be your modular project.

19
00:01:27,370 --> 00:01:30,806
When it comes to configuration I just wanted to suggest a

20
00:01:30,908 --> 00:01:34,586
project which is called conf. There is of

21
00:01:34,608 --> 00:01:38,102
course a couple of other projects about this configuration management

22
00:01:38,166 --> 00:01:41,978
but this is the simplest one that I use. Quf. On the

23
00:01:42,064 --> 00:01:45,934
left hand side when you take a look at there is a YAML configuration and

24
00:01:45,972 --> 00:01:49,486
on the right hand side there is a Golang struct. So if

25
00:01:49,508 --> 00:01:52,894
you use you can simply unmarshall your YAML configuration into

26
00:01:52,932 --> 00:01:56,606
a Golang struct. In Golang struct there

27
00:01:56,628 --> 00:02:00,334
are two sections as we have in the YaML configuration f and db.

28
00:02:00,382 --> 00:02:03,698
On the right hand side there is an app and DB. Under DB there are

29
00:02:03,704 --> 00:02:07,780
a couple of fields and under app there are port section which is 3000.

30
00:02:08,550 --> 00:02:11,846
In the Golang strugg you can even use a receiver function.

31
00:02:11,948 --> 00:02:15,206
There's DSN for example in database connection we will

32
00:02:15,228 --> 00:02:18,874
be using DSM for postgres connection. You can

33
00:02:18,912 --> 00:02:22,774
use this kind of best practices to use in your configuration

34
00:02:22,822 --> 00:02:25,962
system. Most probably you have heard about

35
00:02:26,016 --> 00:02:29,658
twelve factor app. In one of its rules there

36
00:02:29,664 --> 00:02:33,610
is a section which is do your configuration over environment variables.

37
00:02:33,690 --> 00:02:37,166
Here I am exporting a couple of environment variables but why?

38
00:02:37,268 --> 00:02:40,462
What are they? For example app underscore port

39
00:02:40,516 --> 00:02:44,098
is equal to 3000. Here underscore means the indentation in

40
00:02:44,104 --> 00:02:48,158
the yaml. In Yaml we had app indent

41
00:02:48,254 --> 00:02:51,922
there is a child port here, app underscore port.

42
00:02:52,056 --> 00:02:55,394
So you can set this one through environment variable and it

43
00:02:55,432 --> 00:02:59,030
will be again can be unmarshalled to a goal length track,

44
00:02:59,100 --> 00:03:02,882
same using environment variable is the best practice in the cloud environment

45
00:03:02,946 --> 00:03:07,154
because you have a workload, for example pod you can just parts environment

46
00:03:07,202 --> 00:03:09,450
variables like this notation.

47
00:03:11,230 --> 00:03:15,274
After configuration you may start to think about logging. Here I am

48
00:03:15,312 --> 00:03:19,366
using Zep and in Zep as you can see I initialize

49
00:03:19,478 --> 00:03:23,054
logging here and then there's a deferred function because

50
00:03:23,172 --> 00:03:26,750
this kind of performance well performant libraries, they are

51
00:03:26,820 --> 00:03:30,942
buffering the logs. They are not writing logs to some kind of destination like

52
00:03:30,996 --> 00:03:34,994
system output right away they are buffering them and they write to

53
00:03:35,032 --> 00:03:39,234
console in batch. Here let's say that if there is a problem as

54
00:03:39,272 --> 00:03:42,754
a final step there before the exiting, it will just

55
00:03:42,792 --> 00:03:46,226
flushes all the logs from the buffer. It is a

56
00:03:46,248 --> 00:03:49,814
good usage. In order to log something you

57
00:03:49,852 --> 00:03:53,442
just provide a sentence and then you can provide a couple of context item.

58
00:03:53,506 --> 00:03:56,898
For example in our quiz application if there is a problem while fetching

59
00:03:56,914 --> 00:04:00,780
the quiz questions you can say that oh, there is a problem but

60
00:04:01,230 --> 00:04:04,966
in which session for which customer you can provide key value pairs

61
00:04:04,998 --> 00:04:08,474
here. This part is important especially if you are sending your

62
00:04:08,512 --> 00:04:12,478
logs to a logging backend. If you have lots of applications then

63
00:04:12,644 --> 00:04:15,994
by using these fields you can easily filter out the log statements

64
00:04:16,042 --> 00:04:19,674
in the logging backend like elasticsearch or Graylock.

65
00:04:19,722 --> 00:04:23,214
These kind of tools assume

66
00:04:23,262 --> 00:04:27,438
that we built our application, but how to generate artifacts?

67
00:04:27,534 --> 00:04:31,010
Artifacts means here binary executables or docker images

68
00:04:32,070 --> 00:04:36,238
go releaser helps you to build cross platform artifacts,

69
00:04:36,334 --> 00:04:40,294
windows, Linux, whatever you need Mac and also helps you to

70
00:04:40,332 --> 00:04:43,942
release something. Release not only means release to GitHub, for example,

71
00:04:44,076 --> 00:04:48,214
it can also announce some new release versions into discord,

72
00:04:48,342 --> 00:04:51,180
slack notification, these kind of things.

73
00:04:52,350 --> 00:04:55,862
You can simply create a Goreleaser yaml file

74
00:04:56,006 --> 00:05:00,070
and run this function. Go releaser build or release

75
00:05:00,230 --> 00:05:04,010
clean to delete this folder after operation

76
00:05:04,090 --> 00:05:07,662
finished here in the Yaml file I defined a build

77
00:05:07,716 --> 00:05:11,598
section. Under build section there are a couple of builds you

78
00:05:11,604 --> 00:05:15,146
need to provide the id because there is a cross reference inside the yaml

79
00:05:15,178 --> 00:05:19,060
file. Id is queezor API. Main is

80
00:05:20,550 --> 00:05:23,950
when you say go build you need to provide a main file

81
00:05:24,030 --> 00:05:28,114
which is the endpoint. This entry point contains

82
00:05:28,162 --> 00:05:32,102
a main package and main function right here. Since I have

83
00:05:32,156 --> 00:05:35,880
a couple of modules in this project, I am providing my

84
00:05:36,810 --> 00:05:40,234
quizzer API endpoint and as an output I am saying

85
00:05:40,272 --> 00:05:44,234
that binary name will be quizzer API. This execution will

86
00:05:44,272 --> 00:05:48,154
be for Linux and AmD 64 for

87
00:05:48,192 --> 00:05:51,966
Docker section. Here I am saying dockers and

88
00:05:52,148 --> 00:05:56,186
in same way like we have in the executable generation,

89
00:05:56,298 --> 00:05:59,854
we provide an Id. I am saying that this docker image will

90
00:05:59,892 --> 00:06:03,498
be for Linux and AmD 64. I am

91
00:06:03,524 --> 00:06:08,222
providing ids because these binaries will be used to generate docker images.

92
00:06:08,366 --> 00:06:11,470
Image templates is used for generating docker image.

93
00:06:11,630 --> 00:06:15,262
Basically tag which we say docker tag

94
00:06:15,326 --> 00:06:19,602
you mean here tag

95
00:06:19,666 --> 00:06:22,390
is coming from git context,

96
00:06:24,170 --> 00:06:28,102
git context and it is dynamic. For example

97
00:06:28,156 --> 00:06:32,618
whenever you push docker image into this

98
00:06:32,704 --> 00:06:36,266
repository, you will see this current tag will be used here

99
00:06:36,368 --> 00:06:40,458
to generate docker image names

100
00:06:40,554 --> 00:06:44,346
for build flag template. Basically in my docker

101
00:06:44,378 --> 00:06:47,114
image I am providing a couple of parameters,

102
00:06:47,242 --> 00:06:50,320
for example module name, these kind of things.

103
00:06:51,010 --> 00:06:54,146
I can also use these build arguments here. In my case

104
00:06:54,168 --> 00:06:57,714
there is a module key. I am also using label which we will

105
00:06:57,752 --> 00:07:02,194
see it soon in the example extra files means

106
00:07:02,312 --> 00:07:06,366
this part is important because while goryleaser builds

107
00:07:06,398 --> 00:07:10,434
something, for example docker image in the docker context there are only two files,

108
00:07:10,482 --> 00:07:14,534
docker file and the artifact binary executable. So I need

109
00:07:14,572 --> 00:07:18,054
also config this yaml. In my current project these

110
00:07:18,092 --> 00:07:21,334
extra files is used to include also this file into docker

111
00:07:21,382 --> 00:07:24,634
context. Skip push false is used

112
00:07:24,672 --> 00:07:28,266
for just push this one into docker registry which I

113
00:07:28,288 --> 00:07:32,142
will be providing in the GitHub action. What about

114
00:07:32,196 --> 00:07:35,834
quality check? In quality check we will be using Golang CI

115
00:07:35,962 --> 00:07:36,670
lint.

116
00:07:39,090 --> 00:07:44,974
Golang CI lint is used for maintaining

117
00:07:45,022 --> 00:07:49,266
all the linters. There are lots of linters as

118
00:07:49,288 --> 00:07:52,994
an open source project this Goling CI lint just manage them

119
00:07:53,032 --> 00:07:57,314
to run. It is very easy. It runs

120
00:07:57,362 --> 00:08:01,174
them according to your configuration. Again you simply create

121
00:08:01,212 --> 00:08:05,480
a goaling CI yaml file and run Golink CI lint run.

122
00:08:07,610 --> 00:08:10,886
There are a couple of lots of linters but let me

123
00:08:10,908 --> 00:08:14,758
give you a couple of examples. For example, if you expose a structure

124
00:08:14,774 --> 00:08:18,518
outside but didn't provide in a comment so there will be an error.

125
00:08:18,694 --> 00:08:22,158
For the list of full reference you can just take a look at

126
00:08:22,244 --> 00:08:23,790
linters in the URL.

127
00:08:26,770 --> 00:08:29,578
We provided lots of executions these operations,

128
00:08:29,674 --> 00:08:32,682
but again we can run them locally.

129
00:08:32,826 --> 00:08:36,354
What about if we are working with team? So whenever you push something

130
00:08:36,392 --> 00:08:39,986
to remote they will be all test verified right here we

131
00:08:40,008 --> 00:08:43,842
can use GitHub actions. In GitHub actions we can verify test build

132
00:08:43,896 --> 00:08:48,178
artifacts. Whatever you are doing in CI system you can do that in GitHub actions

133
00:08:48,274 --> 00:08:51,734
easily. Just an example here I am saying

134
00:08:51,772 --> 00:08:55,586
that whenever you pull push something to repository

135
00:08:55,618 --> 00:08:59,266
or create a pull request, an action will be triggered.

136
00:08:59,458 --> 00:09:03,574
In this action Ubuntu machine will be used as you can see in runson

137
00:09:03,702 --> 00:09:07,370
and in order to run these actions I will need a content

138
00:09:07,440 --> 00:09:12,070
read and package write. Package write is for generating docker images and attached repository

139
00:09:12,150 --> 00:09:15,790
and also creating releases. Of course content read

140
00:09:15,860 --> 00:09:19,354
means I need to read contents like git content or release

141
00:09:19,402 --> 00:09:22,766
content, right? Because I need to know if there is a tag or not these

142
00:09:22,788 --> 00:09:26,274
kind of things. In the step sections I

143
00:09:26,312 --> 00:09:30,626
check out the code base. I set up goal because

144
00:09:30,648 --> 00:09:33,890
I will need it. In the goal release I do some linter check

145
00:09:33,960 --> 00:09:37,038
by using goaling CI linter there is an action for that.

146
00:09:37,064 --> 00:09:40,390
You don't need to do nothing manually.

147
00:09:41,050 --> 00:09:44,294
I am using camel because this is an emulator. So if you are doing

148
00:09:44,332 --> 00:09:47,270
a docker build operation you can use this emulator.

149
00:09:48,430 --> 00:09:52,330
I need to log in to my GitHub container registry right here.

150
00:09:52,400 --> 00:09:55,510
The registry URL is GitHub container registry IO.

151
00:09:55,670 --> 00:09:59,626
The username is repository owner which

152
00:09:59,648 --> 00:10:03,322
is my username in GitHub. And also there is a GitHub token

153
00:10:03,386 --> 00:10:06,782
because I need to log into here first and then

154
00:10:06,836 --> 00:10:10,686
as a final set is Gore releaser. In Gore laser there is an

155
00:10:10,708 --> 00:10:15,106
action for that. Of course as a parameter I am saying that release clean

156
00:10:15,208 --> 00:10:18,334
so it will build everything and release

157
00:10:18,382 --> 00:10:21,986
to GitHub. There will be a NIV release, there will

158
00:10:22,008 --> 00:10:26,606
be a NIv docker package and

159
00:10:26,648 --> 00:10:30,134
the final output will be something like this quizzer. On the right

160
00:10:30,172 --> 00:10:33,730
hand side there will be a release and again in the packages section

161
00:10:33,810 --> 00:10:36,710
you will see Queezer API.

162
00:10:39,210 --> 00:10:42,122
What is next? We build lots of things.

163
00:10:42,176 --> 00:10:45,606
So where do we ship them? If there is a docker image,

164
00:10:45,638 --> 00:10:48,566
most probably we will ship it to a containerized environment,

165
00:10:48,678 --> 00:10:52,042
maybe kubernetes, right? So who will manage kubernetes?

166
00:10:52,186 --> 00:10:55,598
We will manage it by using terraform and in our case it

167
00:10:55,604 --> 00:10:58,846
will be terraform cloud. We will see

168
00:10:58,868 --> 00:11:02,622
an example soon. So you build

169
00:11:02,676 --> 00:11:05,586
a software as a service project. But why?

170
00:11:05,688 --> 00:11:11,666
Because you like to develop tools and you

171
00:11:11,688 --> 00:11:14,674
want to earn money out of that, right? Because you need to earn money and

172
00:11:14,712 --> 00:11:18,310
then put another investment on top of your product.

173
00:11:18,460 --> 00:11:22,374
Here. In order to charge your customer, first you need to understand your

174
00:11:22,412 --> 00:11:25,846
customer and then you need to track your usage. Here we

175
00:11:25,868 --> 00:11:29,530
will be using stripe and in stripe there is

176
00:11:29,680 --> 00:11:32,906
three important models in

177
00:11:32,928 --> 00:11:36,438
stripe, let's say the domain model. The first one is subscription.

178
00:11:36,534 --> 00:11:39,942
You let your customers to subscribe

179
00:11:40,006 --> 00:11:43,806
a plan. So you simply define your plan. In stripe you

180
00:11:43,828 --> 00:11:47,566
can define your plan in order to subscribe your

181
00:11:47,588 --> 00:11:51,134
customers. You can come up with a UI. There will be a link

182
00:11:51,252 --> 00:11:55,042
and these links will be redirected to stripe checkout page.

183
00:11:55,176 --> 00:11:59,166
Again, checkout subscription plans, they are all managed

184
00:11:59,198 --> 00:12:03,330
in stripe. You can do that because in stripe there is a no code notation

185
00:12:04,310 --> 00:12:07,638
subscription item is let's say that there is a plans, right?

186
00:12:07,724 --> 00:12:11,730
Under this plan there can be some kind of line items

187
00:12:11,810 --> 00:12:15,682
like cost per storage,

188
00:12:15,826 --> 00:12:19,770
cost per request count, these kind of things.

189
00:12:19,920 --> 00:12:23,910
And we will be using this in our calculation

190
00:12:24,070 --> 00:12:27,530
metric. Billing means this is called usage record.

191
00:12:27,680 --> 00:12:31,126
You need to track your customer and send them periodically stripe.

192
00:12:31,158 --> 00:12:34,798
So this is the only part you need to handle on your own.

193
00:12:34,964 --> 00:12:38,286
Let's say that there is a cron job and in

194
00:12:38,308 --> 00:12:41,754
this cron job you simply calculate the usage.

195
00:12:41,802 --> 00:12:45,842
For example, in our case in quiz application, question count per

196
00:12:45,896 --> 00:12:49,214
hour. For example, each hour you periodically etc.

197
00:12:49,262 --> 00:12:52,814
The question count per customer and you send them to stripe.

198
00:12:52,862 --> 00:12:56,422
So at the end of the billing period, stripe knows how

199
00:12:56,476 --> 00:13:00,166
to calculate the total amount per customer and

200
00:13:00,188 --> 00:13:03,880
then multiply it by unit price within their plan.

201
00:13:04,330 --> 00:13:07,926
And then it will charge the customer and then it will notify the

202
00:13:07,948 --> 00:13:11,290
customer. That's it. You do nothing if you use stripe,

203
00:13:11,630 --> 00:13:15,274
almost nothing. Of course the first step

204
00:13:15,312 --> 00:13:18,650
is subscribe your customer. As I said, there will be a link

205
00:13:18,720 --> 00:13:22,254
click on it, check out session, they will select plan, they will

206
00:13:22,292 --> 00:13:26,058
provide their payment method. Everything happens on the stripe servers,

207
00:13:26,154 --> 00:13:29,310
not on your servers, and your customer

208
00:13:29,380 --> 00:13:32,862
will be subscribed to a specific plan. After that.

209
00:13:32,996 --> 00:13:36,114
Since you know the customer plan, how do you know

210
00:13:36,152 --> 00:13:39,538
customer plan? You know because in GitHub site there is a

211
00:13:39,544 --> 00:13:42,386
webhook system. Whenever somebody subcontracts a plan,

212
00:13:42,488 --> 00:13:45,926
you can be automatically notified. So I am notified and

213
00:13:45,948 --> 00:13:49,218
then I know in which customer belongs

214
00:13:49,234 --> 00:13:53,362
to which plan. And then periodically,

215
00:13:53,426 --> 00:13:57,106
each hour I am calculating the usage. For example here quantity

216
00:13:57,218 --> 00:14:00,794
is two for these hours. Two questions. For example,

217
00:14:00,912 --> 00:14:04,342
I am sending this to stripe and as you can see the action

218
00:14:04,406 --> 00:14:08,042
is increment. So increment means I send

219
00:14:08,096 --> 00:14:11,722
2257. So they will be all

220
00:14:11,776 --> 00:14:14,858
incremented on the stripe side. At the end of billing period,

221
00:14:14,954 --> 00:14:18,974
stripe will get the final amount and multiply it by unit price.

222
00:14:19,172 --> 00:14:23,166
Again, to sum up, the only thing you need to do is just calculate

223
00:14:23,198 --> 00:14:26,706
your pricing. I mean the customer usage. Send it to

224
00:14:26,728 --> 00:14:30,606
stripe. That's it. It is only amount. All the remaining

225
00:14:30,638 --> 00:14:35,150
parts will be handled by stripe itself deployment.

226
00:14:35,230 --> 00:14:38,574
So here Argocd really deserves a separate session

227
00:14:38,622 --> 00:14:41,874
for the entire ArgoCD concept.

228
00:14:41,922 --> 00:14:45,222
But here I just wanted to focus on one of its

229
00:14:45,276 --> 00:14:48,634
custom resource, which is application. Here I am saying

230
00:14:48,672 --> 00:14:52,166
that just create an argo application with name quizzer

231
00:14:52,198 --> 00:14:56,266
API and in the spec you see this application

232
00:14:56,368 --> 00:15:00,406
will be under default project and the source

233
00:15:00,438 --> 00:15:04,574
will be a helm chart. Let's say that you

234
00:15:04,612 --> 00:15:07,914
already have a CI system. It builds everything and it generates

235
00:15:07,962 --> 00:15:11,546
helm chart. Put it to GitHub pages, right? You already have a helm

236
00:15:11,578 --> 00:15:15,182
chart here. I am saying that this application is responsible

237
00:15:15,246 --> 00:15:18,622
for deploying a helm chart. Here is the repo URL,

238
00:15:18,686 --> 00:15:22,738
here is the version, here is the release name. Just deploy this.

239
00:15:22,904 --> 00:15:27,202
Deploy where it is defined in the destination section.

240
00:15:27,346 --> 00:15:31,234
It is the current Kubernetes cluster. So wherever you deploy

241
00:15:31,282 --> 00:15:35,142
this argo CD, it will deploy this helm chart into

242
00:15:35,276 --> 00:15:39,046
existing Kubernetes cluster and in namespace

243
00:15:39,078 --> 00:15:39,660
dev.

244
00:15:41,950 --> 00:15:45,398
Okay, let's assume that we deploy our application helm

245
00:15:45,414 --> 00:15:49,302
chart. What about confidential data for example postgres database

246
00:15:49,366 --> 00:15:52,986
password and stripe

247
00:15:53,018 --> 00:15:55,230
key for example for the integration.

248
00:15:57,410 --> 00:16:00,762
For example, do you like to create secrets manually in Kubernetes

249
00:16:00,826 --> 00:16:04,834
environment? Most probably no, right? But there will be a manual operation and

250
00:16:04,872 --> 00:16:08,466
there will be lack of synchronization. Here there is a project which is

251
00:16:08,488 --> 00:16:12,274
called external secret. In external secret you simply synchronize your

252
00:16:12,312 --> 00:16:16,740
secret and

253
00:16:17,270 --> 00:16:20,786
secret from the secret providers and your Kubernetes

254
00:16:20,818 --> 00:16:24,002
secrets. When you take a look at their pages,

255
00:16:24,066 --> 00:16:27,566
you will see something like this in AWS GCP vault,

256
00:16:27,618 --> 00:16:31,194
there are lots of secret providers. You can

257
00:16:31,232 --> 00:16:34,470
maintain your secrets in vault AWS or GCP

258
00:16:34,550 --> 00:16:38,474
and secret manager external secret help

259
00:16:38,512 --> 00:16:42,274
you to create secrets in your Kubernetes environment

260
00:16:42,342 --> 00:16:45,914
by using these secret manager providers. So assume

261
00:16:45,962 --> 00:16:49,582
that you put something into vault or remove something from vault or change

262
00:16:49,636 --> 00:16:53,850
something from vault, they will be synchronized to your Kubernetes secrets.

263
00:16:54,010 --> 00:16:57,198
This is very cool, right? So you don't need to maintain secrets

264
00:16:57,214 --> 00:17:00,686
manually. Public access. You deployed

265
00:17:00,718 --> 00:17:04,706
lots of things in the Kubernetes environment. They are already. But how do

266
00:17:04,728 --> 00:17:06,680
you expose them to the outside?

267
00:17:08,170 --> 00:17:11,638
Of course you expose them to outside by using Kubernetes service,

268
00:17:11,724 --> 00:17:15,490
maybe ingress controller, that's fine. But they expose,

269
00:17:15,650 --> 00:17:18,994
for example in GKE they expose ingress load balancer.

270
00:17:19,042 --> 00:17:22,506
Right? But do you like to provide that IP address to your customers?

271
00:17:22,688 --> 00:17:25,786
No. Right. Then that's why you need to

272
00:17:25,808 --> 00:17:29,306
create some kind of DNS entry for that. Assume that

273
00:17:29,328 --> 00:17:32,926
we are using Cloudflare. They have terraform provider and you

274
00:17:32,948 --> 00:17:36,826
can just create a Cloudflare record. It is a resource.

275
00:17:37,018 --> 00:17:40,590
And in order to create a Cloudflare record,

276
00:17:40,740 --> 00:17:44,334
this is a DNS record. I am saying that just

277
00:17:44,372 --> 00:17:47,534
create this record under this zone id. It is a Cloudflare

278
00:17:47,582 --> 00:17:50,926
specific thing. Let's say that you created a domain there and there is a zone

279
00:17:50,958 --> 00:17:54,194
id for each domain. You need to provide that information here.

280
00:17:54,232 --> 00:17:57,894
Otherwise it cannot know in which domain. I need to add this

281
00:17:57,932 --> 00:18:01,798
entry if my website

282
00:18:01,884 --> 00:18:05,426
name under Cloudflare is Queezer

283
00:18:05,538 --> 00:18:09,426
IO. When I add this entry, it will be something like terraform,

284
00:18:09,538 --> 00:18:13,018
queezer IO and it will point to this specific IP address

285
00:18:13,104 --> 00:18:16,726
because it is an a record. A record means name to IP

286
00:18:16,758 --> 00:18:17,340
address.

287
00:18:19,550 --> 00:18:23,246
Okay, now my quiz application is up and running. I can

288
00:18:23,268 --> 00:18:26,426
access it by using a fully

289
00:18:26,458 --> 00:18:29,694
qualified DNS name. Now when

290
00:18:29,732 --> 00:18:33,346
I open the application in the browser, I see oh this page is

291
00:18:33,448 --> 00:18:36,882
insecure. Where is my secret? You can use

292
00:18:36,936 --> 00:18:40,526
sort manager if you are using Kubernetes environment, sort manager helps

293
00:18:40,558 --> 00:18:43,182
you to integrate your resource,

294
00:18:43,326 --> 00:18:47,370
especially for example certificate manager management

295
00:18:47,470 --> 00:18:50,994
with the third parties. Basically you can see lots of configurations

296
00:18:51,042 --> 00:18:54,918
in sort manager web page. But I want to focus on one thing here

297
00:18:55,084 --> 00:18:58,690
again like with external secret like Argo CD,

298
00:18:58,770 --> 00:19:03,702
you need to deploy the external sort

299
00:19:03,756 --> 00:19:07,146
manager. Yeah, just helm shard. Once you deploy it

300
00:19:07,248 --> 00:19:10,506
there will be a couple of custom resources available

301
00:19:10,608 --> 00:19:13,918
and issuer and cluster issues are one of them. Here I

302
00:19:13,924 --> 00:19:18,058
am saying that just create an issue for me which is named example issuer

303
00:19:18,154 --> 00:19:21,178
and this will be integrated with the Cloudflare.

304
00:19:21,354 --> 00:19:25,026
So I already have domain names in Cloudflare and Cloudflare will

305
00:19:25,048 --> 00:19:28,654
know that oh there is a TLS in my Kubernetes environment.

306
00:19:28,702 --> 00:19:32,638
So there will be an HTTPs request up until Cloudflare.

307
00:19:32,734 --> 00:19:36,818
While Cloudflare connecting to my resource which is quizzer API,

308
00:19:36,914 --> 00:19:40,834
it is using ingress resource, it will also connect Cloudflare

309
00:19:40,882 --> 00:19:43,826
also connect to an endpoint which is TLS,

310
00:19:43,938 --> 00:19:47,506
right. And this will be using a let's

311
00:19:47,538 --> 00:19:51,530
encrypt. You know let's encrypt is an open source free system

312
00:19:51,600 --> 00:19:54,698
that you can generate your certificates periodically, right?

313
00:19:54,864 --> 00:19:58,006
So I have an issuer, it can be also cluster issuer.

314
00:19:58,038 --> 00:20:02,014
It is a system in my ingress record

315
00:20:02,132 --> 00:20:05,642
when I provided this automation sort manager cluster issuer

316
00:20:05,706 --> 00:20:09,214
example issues, you see this ingress will

317
00:20:09,252 --> 00:20:12,714
be automatically, you know,

318
00:20:12,772 --> 00:20:16,706
when you add an ingress record, ingress controller just refreshes it

319
00:20:16,888 --> 00:20:20,642
Nginx configuration. So there will be a TLS section under

320
00:20:20,696 --> 00:20:23,986
this configuration. So Cloudflare will

321
00:20:24,008 --> 00:20:27,350
be connected to TLS endpoint on this part.

322
00:20:27,420 --> 00:20:31,798
So everything is HTTPs. You see from bottom

323
00:20:31,964 --> 00:20:35,014
from Golang project up until to a

324
00:20:35,052 --> 00:20:38,666
production environment we can have this kind of system.

325
00:20:38,768 --> 00:20:42,934
So very summarized notation

326
00:20:42,982 --> 00:20:46,940
of building a software as a service product.

327
00:20:47,710 --> 00:20:48,940
What is next?

328
00:20:50,930 --> 00:20:55,120
Let's take a look at an example in the code base here

329
00:20:55,890 --> 00:21:00,042
I build a project which is called Quizzer. In Quizzer

330
00:21:00,106 --> 00:21:04,874
I want to start from CMD folder. In CMD means CMD

331
00:21:04,922 --> 00:21:08,274
is the entry point folder and here in the entry point there

332
00:21:08,312 --> 00:21:11,762
can be multiple or single, whatever you prefer under

333
00:21:11,816 --> 00:21:16,946
API for example, there is a main main in

334
00:21:16,968 --> 00:21:20,022
main co. As you can see it is a main package. There is a main

335
00:21:20,076 --> 00:21:22,920
function right here.

336
00:21:24,010 --> 00:21:27,406
If I am trying to wrap something, for example logger

337
00:21:27,458 --> 00:21:31,820
library, I use a notation, package notation which is technology

338
00:21:32,750 --> 00:21:36,694
x. Since this is a logger, I am saying logger

339
00:21:36,742 --> 00:21:40,700
x. So under internal I have a logging logger x.

340
00:21:41,710 --> 00:21:44,826
When I say new, basically it returns a

341
00:21:44,848 --> 00:21:48,106
zeplogger. So basically it returns zep new production,

342
00:21:48,218 --> 00:21:52,014
right. If there is a problem, it will

343
00:21:52,052 --> 00:21:55,298
do a log fatal f. That means it will exit one,

344
00:21:55,384 --> 00:21:59,038
right? And it will print a log. And after that I am initializing

345
00:21:59,054 --> 00:22:03,470
one configuration. Let's check what happens there. In initializing

346
00:22:03,550 --> 00:22:07,780
there is a struct here config Db app. It contains all the thing.

347
00:22:08,250 --> 00:22:12,550
And in the init function you see I am initializing the quant

348
00:22:13,210 --> 00:22:16,360
which I mentioned before.

349
00:22:17,610 --> 00:22:21,546
And also I am using Yaml Parser here there is a

350
00:22:21,568 --> 00:22:24,666
default config file which is config yaml. And if

351
00:22:24,688 --> 00:22:28,106
you provide a config yaml environment variable config location, I will

352
00:22:28,128 --> 00:22:31,370
also use that. You can override the location of config file.

353
00:22:32,030 --> 00:22:36,574
Here I am saying that could you please load the configuration for

354
00:22:36,612 --> 00:22:40,154
me? It will load the configuration. Let's say that there is a byte array,

355
00:22:40,202 --> 00:22:44,222
byte or slice of bytes. And here basically I am saying that

356
00:22:44,276 --> 00:22:47,662
unmarshall this byte of array into the config.

357
00:22:47,726 --> 00:22:51,534
That's it. So it will return config. Now I will have a config

358
00:22:51,582 --> 00:22:55,330
struck and all the fields are already pre populated.

359
00:22:55,670 --> 00:22:59,400
I can use this config in any other places in my application

360
00:22:59,930 --> 00:23:03,266
if there is a problem. Of course it will do a log fatal and fail

361
00:23:03,298 --> 00:23:06,360
to initialize config. What else?

362
00:23:06,730 --> 00:23:10,102
Now I will try to connect to a database.

363
00:23:10,166 --> 00:23:14,220
Here I am using gorm. I will show you an example entity there.

364
00:23:14,590 --> 00:23:18,874
Here gorm is orm library for go

365
00:23:19,072 --> 00:23:22,726
and it has different drivers support like postgres,

366
00:23:22,758 --> 00:23:25,962
mySql, etc. Here I am saying

367
00:23:26,016 --> 00:23:29,646
that as you can see DBDSM there is a connection URL here.

368
00:23:29,748 --> 00:23:33,406
Could you please connect to postgres and it connects to

369
00:23:33,428 --> 00:23:36,946
postgres database and I will show you the entity. Let me show

370
00:23:36,968 --> 00:23:40,610
you entities here under domain. There is a for example question

371
00:23:40,680 --> 00:23:45,790
entity here. In question entity there

372
00:23:45,800 --> 00:23:49,400
is a field description and also there is a gorm model.

373
00:23:50,170 --> 00:23:53,090
This contains id created, updated,

374
00:23:53,170 --> 00:23:57,046
deleted. This is coming from gorm orm library. So you don't need

375
00:23:57,068 --> 00:24:00,522
to put Id created this kind of common

376
00:24:00,576 --> 00:24:02,970
fields all the time for all entities.

377
00:24:04,350 --> 00:24:07,622
While we are running our application basically in the repository

378
00:24:07,686 --> 00:24:11,174
section. Again by using gorm

379
00:24:11,222 --> 00:24:14,254
I am using auto migrate and I am providing my

380
00:24:14,292 --> 00:24:18,174
struct as a reference. When you do that it just do

381
00:24:18,212 --> 00:24:21,534
some kind of reflection. It gets all the fields and it

382
00:24:21,572 --> 00:24:24,734
creates a table out of that fields. Let me show you the column

383
00:24:24,782 --> 00:24:30,946
structure for that. When I run this application I

384
00:24:30,968 --> 00:24:33,780
need to check if I have this application running or not.

385
00:24:36,810 --> 00:24:40,966
Okay. That database is not run. Okay anyways

386
00:24:40,998 --> 00:24:43,980
I will show you that later.

387
00:24:45,230 --> 00:24:49,046
So basically there will be a database table that

388
00:24:49,088 --> 00:24:52,414
only contains a description field as a custom and

389
00:24:52,452 --> 00:24:55,962
there is also id created, updated and deleted

390
00:24:56,026 --> 00:25:00,000
section. Let's continue with the main file here.

391
00:25:00,690 --> 00:25:04,226
Also of course there is defer here. I need to close my

392
00:25:04,248 --> 00:25:07,570
db connection before exiting something. And I am using

393
00:25:07,640 --> 00:25:11,054
fiber for rest endpoint. This is a very lightweight

394
00:25:11,102 --> 00:25:14,146
and good well performance library for go. You can

395
00:25:14,168 --> 00:25:17,442
use fiber for that. And here I am registering

396
00:25:17,506 --> 00:25:21,062
an endpoint metrics endpoint and I'm using prom,

397
00:25:21,116 --> 00:25:24,834
HTTP. You know Prometheus is very well known library for monitoring

398
00:25:24,882 --> 00:25:28,746
systems. It is for metrics for the application. If you

399
00:25:28,768 --> 00:25:33,020
do that it will basically expose some kind of metrics to the outside.

400
00:25:35,470 --> 00:25:39,286
And finally I am initializing the question repository

401
00:25:39,398 --> 00:25:42,778
and as a parameter I provide date, database and locker.

402
00:25:42,954 --> 00:25:46,922
I have one more endpoint questions and it returns

403
00:25:46,986 --> 00:25:50,494
list of questions to me and this application will be run on

404
00:25:50,532 --> 00:25:54,260
port 30,000 and

405
00:25:58,710 --> 00:26:01,540
okay I think I managed to run.

406
00:26:02,310 --> 00:26:06,790
Okay the application is running right now. Let me show you the database.

407
00:26:07,450 --> 00:26:09,880
I will scroll this one like this.

408
00:26:12,810 --> 00:26:16,750
Okay, here there is a public tables,

409
00:26:16,850 --> 00:26:20,282
entities columns. As you can see we have

410
00:26:20,336 --> 00:26:23,340
description and we have deleted updated created Id.

411
00:26:23,790 --> 00:26:28,326
Very simple. Okay, so let's

412
00:26:28,358 --> 00:26:33,422
move on. I can also have collector main here.

413
00:26:33,556 --> 00:26:37,470
This is another endpoint I just wanted to show you. You can

414
00:26:37,540 --> 00:26:41,006
add lots of entry points into your application. And in

415
00:26:41,028 --> 00:26:44,766
Dockerfile let me show you the docker file. Because Gory laser uses

416
00:26:44,798 --> 00:26:48,498
this docker file. There is an argument which is module and inside

417
00:26:48,584 --> 00:26:52,370
module I am copying this module. This module is used for

418
00:26:52,440 --> 00:26:56,246
binary executable. So if it is quizzer API it

419
00:26:56,268 --> 00:26:59,650
will be quizzer API. If it is a cron job it will be another enterpoint.

420
00:26:59,730 --> 00:27:04,594
And I am also copying the config

421
00:27:04,642 --> 00:27:08,374
disk file here. And of course I am providing config location

422
00:27:08,422 --> 00:27:11,862
or config Yaml and running the binary executable.

423
00:27:11,926 --> 00:27:15,446
So who passes this argument? Who passes this argument?

424
00:27:15,558 --> 00:27:19,194
It is passed on Golang releaser. As you can see

425
00:27:19,232 --> 00:27:22,786
here, build angular module is equal to queer

426
00:27:22,838 --> 00:27:25,838
API. If I had another build section here,

427
00:27:25,924 --> 00:27:29,722
I can provide for example payment collector or usage

428
00:27:29,786 --> 00:27:33,666
calculator, these kind of things. So for

429
00:27:33,688 --> 00:27:37,586
the configuration I think that's it. So when

430
00:27:37,608 --> 00:27:41,490
I push my changes into remote, let me

431
00:27:41,560 --> 00:27:44,614
show you what happens at that time because I want to

432
00:27:44,652 --> 00:27:48,280
show you a couple of

433
00:27:48,650 --> 00:27:49,750
examples.

434
00:27:52,890 --> 00:27:58,966
Tab quizzer in

435
00:27:58,988 --> 00:28:02,262
Quizzer you see for example I created a pull request

436
00:28:02,326 --> 00:28:05,882
change not count. For example, as you can see here

437
00:28:06,016 --> 00:28:09,306
I have CI build green and also there is a terraform part,

438
00:28:09,328 --> 00:28:12,926
I will show you that one. Also in Queezor you will see

439
00:28:12,948 --> 00:28:16,762
there is a release and there is a package. When I check the package

440
00:28:16,826 --> 00:28:23,006
part, you will see it. Now there

441
00:28:23,028 --> 00:28:26,978
is a version Queezor API and I can simply do a docker pull

442
00:28:27,064 --> 00:28:31,060
on this part, right. And what else?

443
00:28:31,750 --> 00:28:35,286
As I said, there is a terraform integration here in

444
00:28:35,308 --> 00:28:39,858
terraform, basically in terraform cloud I created a workspace

445
00:28:39,954 --> 00:28:44,066
and in workspace I just connected this workspace with my repository.

446
00:28:44,178 --> 00:28:47,926
And in my repository I said that there is

447
00:28:47,948 --> 00:28:52,250
an IEX folder here and there is a main file. So basically

448
00:28:52,400 --> 00:28:55,606
I am creating a container cluster, I am creating a node

449
00:28:55,638 --> 00:28:59,870
pool under it and that's it. It simply creates a Kubernetes cluster.

450
00:29:00,210 --> 00:29:03,886
So let's click on this terraform cloud

451
00:29:03,988 --> 00:29:07,886
link because it only does a plan section. When I click on

452
00:29:07,908 --> 00:29:12,080
it, it will redirect me to the terraform cloud page.

453
00:29:12,850 --> 00:29:14,500
Let me go through it.

454
00:29:15,590 --> 00:29:19,346
Okay. As you can see the plan is finished. Inside the

455
00:29:19,368 --> 00:29:22,894
plan you see one to create, one to change, one to destroy.

456
00:29:22,942 --> 00:29:25,780
You can see the changes here. If it is okay,

457
00:29:27,590 --> 00:29:31,074
you can just apply this plan. Once you

458
00:29:31,112 --> 00:29:34,210
apply it, let me show you also Google

459
00:29:34,280 --> 00:29:38,250
Cloud console what it creates

460
00:29:52,660 --> 00:29:53,410
engine.

461
00:29:57,860 --> 00:30:01,692
Okay, as you can see there is a queer Kubernetes

462
00:30:01,756 --> 00:30:06,056
cluster and it created everything. So um,

463
00:30:06,158 --> 00:30:09,416
including infrastructure, everything. If I have

464
00:30:09,518 --> 00:30:12,936
them in my code base I

465
00:30:12,958 --> 00:30:16,872
can easily sync everything to my production with single

466
00:30:16,926 --> 00:30:20,936
push or single tag. So that was it. Hope it

467
00:30:20,958 --> 00:30:27,256
was a valuable session for you and thank

468
00:30:27,278 --> 00:30:28,468
you for listening.

