1
00:01:28,530 --> 00:01:32,034
Hello and welcome. Today's talk is titled Pushing

2
00:01:32,082 --> 00:01:36,054
Code. Don't forget to flag your canaries. Thanks for joining in.

3
00:01:36,172 --> 00:01:38,994
In this talk we'll cover a variety of topics.

4
00:01:39,042 --> 00:01:42,138
We'll go into reliability, how it's

5
00:01:42,234 --> 00:01:46,026
most importantly about the user. Why do we do canary releases

6
00:01:46,058 --> 00:01:49,674
in the first place? When is it safe to expand those canary

7
00:01:49,722 --> 00:01:53,118
releases and also dive into feature flagging

8
00:01:53,214 --> 00:01:56,850
various features and then also

9
00:01:56,920 --> 00:02:00,462
understand how our users rely on our services and then identify

10
00:02:00,526 --> 00:02:04,002
the ideal groups in youll users base

11
00:02:04,136 --> 00:02:07,606
to target. And at these end we'll have

12
00:02:07,628 --> 00:02:11,014
a quick question and answer session. Let's get started

13
00:02:11,052 --> 00:02:14,406
with reliability. Reliability is feature number one.

14
00:02:14,588 --> 00:02:17,954
Without reliability, nothing else matters.

15
00:02:18,082 --> 00:02:21,290
It doesn't matter what shiny new feature you put into your

16
00:02:21,360 --> 00:02:24,934
application. If your application is not reliable, the customer won't

17
00:02:24,982 --> 00:02:28,234
care. Now, reliability might mean

18
00:02:28,272 --> 00:02:31,450
a few different things to your team. Phased on these,

19
00:02:31,520 --> 00:02:35,502
you are in the maturity of your application or service and also

20
00:02:35,556 --> 00:02:39,594
scale and growth of users adoption let's say you're a startup

21
00:02:39,722 --> 00:02:43,198
you're just worried about let's get the features out. Let's not focus too much

22
00:02:43,204 --> 00:02:46,654
on reliability or the other bells and whistles because

23
00:02:46,692 --> 00:02:49,858
we want to get the feature out, because if we don't get it out,

24
00:02:49,944 --> 00:02:53,726
we'll get beaten by competitors. So you're really focused on delivering features

25
00:02:53,758 --> 00:02:57,480
as fast as possible and delivering value to your customers as fast as possible.

26
00:02:57,850 --> 00:03:01,206
And then at some point reliability starts. As you get

27
00:03:01,228 --> 00:03:05,014
more customers, reliability starts becoming more and more important because

28
00:03:05,052 --> 00:03:08,760
now you've got customers paying for your product and

29
00:03:09,210 --> 00:03:12,586
maybe they're complaining something's not working and that

30
00:03:12,608 --> 00:03:16,458
is these reliability of youll application. Your reliability is suffering because you move fast,

31
00:03:16,624 --> 00:03:20,218
which you had to do, but now you're at a point where you need

32
00:03:20,224 --> 00:03:23,886
to address those concerns so your customers don't leave. And as you

33
00:03:23,908 --> 00:03:27,886
grow into a bigger company, that reliability becomes more and more important. You see

34
00:03:27,988 --> 00:03:31,162
a lot of companies become very stagnant

35
00:03:31,226 --> 00:03:35,134
sometimes as far as releasing products because they've built such a

36
00:03:35,172 --> 00:03:38,354
massive platform. These their customers are relying on that. It's really

37
00:03:38,392 --> 00:03:42,222
hard for the company to release new versions or new features

38
00:03:42,366 --> 00:03:45,670
without going through a whole suite of testing. That takes a long

39
00:03:45,740 --> 00:03:51,030
time. And that's the other extreme of where

40
00:03:51,180 --> 00:03:55,314
reliability takes over and innovation drops

41
00:03:55,362 --> 00:03:59,002
off. The state of DevOps report sponsored by Google states

42
00:03:59,056 --> 00:04:03,178
that reliability is a combination of measures which

43
00:04:03,344 --> 00:04:06,940
include availability, which is one of the most important.

44
00:04:07,390 --> 00:04:11,258
Availability can be tracked with four golden signals,

45
00:04:11,354 --> 00:04:15,258
latency, traffic saturation and errors.

46
00:04:15,354 --> 00:04:18,654
If your users can't easily access the service or

47
00:04:18,692 --> 00:04:22,506
if it's unbearably slow, or if there's errors popping

48
00:04:22,538 --> 00:04:26,306
up everywhere, then it's not reliable. We've all been

49
00:04:26,328 --> 00:04:29,730
there. We've all used a SaaS product or any other product

50
00:04:29,880 --> 00:04:33,586
where you're sitting there waiting for the loading spinner to end and just

51
00:04:33,608 --> 00:04:37,158
keeps going in an infinite loop. Or you click tab and you see a

52
00:04:37,164 --> 00:04:41,842
loading skeleton which initial

53
00:04:41,986 --> 00:04:46,034
glance is like, oh, it looks a little better. That's why the loading skeletons

54
00:04:46,082 --> 00:04:48,994
were invented or implemented,

55
00:04:49,122 --> 00:04:52,838
because it gives the user perception of speed. But in fact you're

56
00:04:52,854 --> 00:04:56,234
still waiting. So we've all been there, we've all seen it,

57
00:04:56,272 --> 00:04:59,722
we know exactly how annoyed we get. And at that point all

58
00:04:59,776 --> 00:05:03,434
the bells and the whistles, all the nice shiny new features don't really better because

59
00:05:03,472 --> 00:05:06,766
we're so annoyed at the one feature we wanted to use at that time and

60
00:05:06,788 --> 00:05:10,426
it's not working. Our internal SRE expert, Kurt Anderson,

61
00:05:10,458 --> 00:05:14,494
who did 70 years as part of LinkedIn's SRE team, says reliability

62
00:05:14,542 --> 00:05:18,174
is a team sport. It's a constant balancing act between pushing

63
00:05:18,222 --> 00:05:22,098
new code to production and monitoring your services to make

64
00:05:22,104 --> 00:05:26,338
sure these performance as expected within the threshold

65
00:05:26,434 --> 00:05:31,506
that you have set for resources and just overall healthy.

66
00:05:31,618 --> 00:05:35,046
The practice of SRE is about bridging the gap between

67
00:05:35,148 --> 00:05:38,700
the dev side of things and the operational side of things,

68
00:05:39,230 --> 00:05:42,682
so that innovation can keep going

69
00:05:42,816 --> 00:05:46,666
at a fast pace while also maintaining the reliability of

70
00:05:46,688 --> 00:05:50,550
your application. Oftentimes it feels like innovation

71
00:05:50,710 --> 00:05:54,206
goes super fast and then reliability falls off. And these other

72
00:05:54,228 --> 00:05:57,614
times reliability takes over and is the

73
00:05:57,652 --> 00:06:01,006
number one priority and then innovation drops off.

74
00:06:01,108 --> 00:06:04,798
And that's where I talked about. Different states of companies tend

75
00:06:04,814 --> 00:06:08,690
to have different extremes sometimes, but really the perfect

76
00:06:08,760 --> 00:06:11,842
experience is having a balance between them.

77
00:06:11,896 --> 00:06:15,462
Where innovation is fast but also reliability is high. That's the perfect

78
00:06:15,516 --> 00:06:19,014
balance. That's the perfect experience for youll customer and for

79
00:06:19,212 --> 00:06:22,230
your development teams and your operational teams.

80
00:06:23,210 --> 00:06:27,170
Sre lives between the dev and ops

81
00:06:27,330 --> 00:06:31,306
and our job is to smooth it out as much as possible. We want to

82
00:06:31,328 --> 00:06:35,546
connect dev and ops so that they can keep going at

83
00:06:35,568 --> 00:06:39,142
equal pace without causing too much friction.

84
00:06:39,286 --> 00:06:42,426
And we have to think about, as an

85
00:06:42,448 --> 00:06:46,062
engineering team, we have to think about what is planned work, what's unplanned work.

86
00:06:46,116 --> 00:06:48,810
When something goes wrong in production,

87
00:06:48,890 --> 00:06:52,314
yes, you release something really fast. Something went wrong in production

88
00:06:52,442 --> 00:06:55,866
that causes unplanned work for your teams as well. So it's not just impacting

89
00:06:55,898 --> 00:06:59,346
the customers, also impacting internal engineering teams as

90
00:06:59,368 --> 00:07:03,090
well. In our topic today, we'll go over how you want to continue

91
00:07:03,160 --> 00:07:07,938
release and innovate while meeting your customers expectations of reliability

92
00:07:08,114 --> 00:07:11,574
and their needs for new features at the same time.

93
00:07:11,772 --> 00:07:14,866
To do that, you have to adopt an iterative release

94
00:07:14,898 --> 00:07:17,910
process using canaries and feature plays.

95
00:07:18,750 --> 00:07:22,780
Before we do that though, let's take a simple example.

96
00:07:24,270 --> 00:07:28,186
Now, I've got an ecommerce application that a

97
00:07:28,208 --> 00:07:31,546
customer can log in, search and buy things.

98
00:07:31,728 --> 00:07:35,118
And I've got a simple user journey here. The user is logging in.

99
00:07:35,284 --> 00:07:39,022
How likely the login is to succeed is extremely important to the success

100
00:07:39,076 --> 00:07:42,298
of your application. It does pertain to reliability. If the user

101
00:07:42,314 --> 00:07:45,438
can't even get through the front door, what users is your product? What uses are

102
00:07:45,444 --> 00:07:48,834
the shiny new features? They're of no use at all.

103
00:07:49,032 --> 00:07:52,386
Now, let's say the customer was able to log in and now they're searching for

104
00:07:52,408 --> 00:07:56,286
a product. How fast those search results come back is extremely

105
00:07:56,318 --> 00:07:59,606
important. Obviously not as important as getting into the

106
00:07:59,628 --> 00:08:03,526
front door in the first place, but fairly important

107
00:08:03,628 --> 00:08:06,854
because it annoys the user when something is slow. We talked

108
00:08:06,892 --> 00:08:10,422
about this just a couple of slides ago. We've been there.

109
00:08:10,476 --> 00:08:13,898
You're using a product even if you're not buying something. You're trying to use a

110
00:08:13,904 --> 00:08:18,378
product and it's slow. It annoys you, right? It gives you a bad experience

111
00:08:18,464 --> 00:08:22,686
with that product and you'll hold that negative experience until it

112
00:08:22,708 --> 00:08:26,046
gets resolved somehow. Now, customer found the

113
00:08:26,068 --> 00:08:28,906
product they're looking for. They want to add it to these parts.

114
00:08:29,098 --> 00:08:32,110
If it gets successfully added to the cart, awesome.

115
00:08:32,260 --> 00:08:35,460
If it doesn't or it takes a long time to do so,

116
00:08:35,910 --> 00:08:39,138
that's a problem because the customer

117
00:08:39,224 --> 00:08:42,626
wasn't able to do what they came to your application to

118
00:08:42,648 --> 00:08:46,510
do. And if they're paying you money, maybe a membership fee

119
00:08:46,590 --> 00:08:50,054
or monthly fee, whatever they're paying

120
00:08:50,092 --> 00:08:53,558
you, they're paying you to do what they came here to do.

121
00:08:53,644 --> 00:08:56,534
And if they can't do it, they're not going to be happy.

122
00:08:56,732 --> 00:08:58,860
All these three things put together,

123
00:08:59,710 --> 00:09:02,762
obviously this is a simplified example, but these

124
00:09:02,816 --> 00:09:05,946
three things put together encompass how happy a

125
00:09:05,968 --> 00:09:08,220
customer is going to be with your product.

126
00:09:08,670 --> 00:09:12,038
Now in this example, we talked about

127
00:09:12,064 --> 00:09:16,058
latency as one of the big metrics,

128
00:09:16,154 --> 00:09:19,886
and that would be the SLI, the service level indicator that

129
00:09:19,908 --> 00:09:23,554
we want to use. If we were measuring this and these service level objective could

130
00:09:23,592 --> 00:09:28,482
be, I want this latency to be below

131
00:09:28,536 --> 00:09:31,986
a certain threshold over 30 seconds. That would

132
00:09:32,008 --> 00:09:35,326
be how you measure, and slo

133
00:09:35,358 --> 00:09:39,154
would be what you want to measure and optimize because you're

134
00:09:39,202 --> 00:09:42,626
probably always going to get one or two responses and occasionally

135
00:09:42,658 --> 00:09:45,750
that are slow. But what really matters to the overall experience

136
00:09:45,820 --> 00:09:49,414
of your customer is how slow is

137
00:09:49,452 --> 00:09:52,746
it over a period of time? If it's just slow for one

138
00:09:52,768 --> 00:09:56,230
call and then it gets super, super fast, customer probably won't

139
00:09:56,390 --> 00:10:00,778
be affected too much and they won't mind too much. But if it's consistently slow,

140
00:10:00,954 --> 00:10:04,750
then we have a problem. And youll can measure that using slos and slots.

141
00:10:05,570 --> 00:10:07,550
Blameless. Blameless plug.

142
00:10:09,250 --> 00:10:12,350
Now, let's talk about canarying. What is canarying? Well,

143
00:10:12,420 --> 00:10:16,094
the term canary comes from an old mining tactic

144
00:10:16,142 --> 00:10:19,822
where miners would release canaries into tunnels to measure toxic gases.

145
00:10:19,966 --> 00:10:23,746
If the canary survived, that means the tunnel was safe. If they

146
00:10:23,768 --> 00:10:27,558
didn't, well, not so safe. How do we relate that

147
00:10:27,564 --> 00:10:31,366
to software development? In software development, canary means releasing to

148
00:10:31,548 --> 00:10:35,314
a set of users over time until you've rolled out a feature

149
00:10:35,362 --> 00:10:38,714
to all customers. Why do we do this? Well, one,

150
00:10:38,832 --> 00:10:42,486
there's less impacted liability. As I said, you're releases to a subset

151
00:10:42,518 --> 00:10:46,106
of users iteratively so you could roll it out to one

152
00:10:46,128 --> 00:10:49,722
set of customers, monitor, make sure

153
00:10:49,856 --> 00:10:53,162
things are looking okay in your metrics, tools, et cetera.

154
00:10:53,306 --> 00:10:57,146
And if they don't, you could stop the rollout or even roll

155
00:10:57,178 --> 00:11:00,606
back the rollout without impacting all of your customers, right?

156
00:11:00,628 --> 00:11:04,174
So therefore, you're more reliable to all the other

157
00:11:04,212 --> 00:11:07,822
customers. And two, continuous feedback from

158
00:11:07,876 --> 00:11:10,658
various users that you're rolling out to. If you roll out the first set of

159
00:11:10,664 --> 00:11:13,460
customers and they tell you, this sucks, these can't even use it.

160
00:11:13,830 --> 00:11:17,122
It's not even the workflow that they want. Maybe you pause,

161
00:11:17,266 --> 00:11:20,806
go back, revisit the design, and don't roll out the feature to

162
00:11:20,828 --> 00:11:24,600
everybody else because maybe you never know.

163
00:11:25,610 --> 00:11:29,106
And then three smooth operations, right, you're releasing

164
00:11:29,138 --> 00:11:33,254
to less users. Therefore, the surface area of incidents has decreased dramatically.

165
00:11:33,382 --> 00:11:36,826
And if you don't encounter incidents with these set

166
00:11:36,848 --> 00:11:39,350
of users you release to, then you can roll out to another set of users,

167
00:11:39,430 --> 00:11:42,606
keep doing the same thing, monitor, and then roll out to the other set of

168
00:11:42,628 --> 00:11:46,570
customers, hopefully reducing the incidents as much as possible and causing less strain

169
00:11:46,730 --> 00:11:50,202
on internal engineering teams.

170
00:11:50,346 --> 00:11:53,934
Let's talk about software development lifecycle for a bit. You might

171
00:11:53,972 --> 00:11:56,846
think, okay, well, you've got these iterative releases,

172
00:11:56,958 --> 00:12:00,238
canary releases. How does that affect my lifecycle?

173
00:12:00,334 --> 00:12:03,682
Well, the short answer is it doesn't. You're still going to be building

174
00:12:03,736 --> 00:12:06,118
your application, testing it,

175
00:12:06,284 --> 00:12:09,446
deploying it, monitoring, and then

176
00:12:09,468 --> 00:12:12,934
if you find any issues, you'll be fixing them, reviewing the fix,

177
00:12:13,052 --> 00:12:16,246
learning from it, and then repeating the process over

178
00:12:16,268 --> 00:12:20,330
and over again. The difference here, and I've got sort of two different

179
00:12:20,400 --> 00:12:24,214
use cases being demonstrated here the difference in canary releases

180
00:12:24,262 --> 00:12:27,580
is that the deploy step is really

181
00:12:27,950 --> 00:12:31,638
broken up into multiple steps, right. You're releasing

182
00:12:31,734 --> 00:12:35,390
it to first set of customers doing the monitor, fix, review, learn,

183
00:12:35,460 --> 00:12:39,198
build, cycle again after you release the first set of customers and

184
00:12:39,204 --> 00:12:42,926
then the same feature rolling out to the next set of customers and

185
00:12:42,948 --> 00:12:46,718
then repeating the process. So really you take every feature and repeat

186
00:12:46,734 --> 00:12:50,658
this process multiple times for every set of customers. So it's the

187
00:12:50,664 --> 00:12:53,906
same process, you're just doing it in a more iterative way over and

188
00:12:53,928 --> 00:12:58,066
over again. And the fact that you're breaking it out and

189
00:12:58,088 --> 00:13:01,506
it's the fact that you're releasing it to small system users, meaning that your monitoring

190
00:13:01,538 --> 00:13:05,014
and fixes are less urgent because you, youll turn

191
00:13:05,052 --> 00:13:08,274
off the feature too. You've got feature flags, so you could turn off the feature

192
00:13:08,322 --> 00:13:12,106
as well if it was a major issue that the feature introduced. And these,

193
00:13:12,128 --> 00:13:14,634
the other part I want to showcase these is feature A and feature B.

194
00:13:14,672 --> 00:13:18,522
So not only are you releasing two subsets of users over time,

195
00:13:18,576 --> 00:13:21,886
for feature A, you're going to offset feature B, release it,

196
00:13:21,908 --> 00:13:25,934
and these do the same process as feature B independently. How does

197
00:13:25,972 --> 00:13:29,422
that work in a timeline or chronological fashion? Well,

198
00:13:29,556 --> 00:13:33,106
here is a good example. This is the

199
00:13:33,128 --> 00:13:36,754
same chart, essentially this is the same thing as

200
00:13:36,792 --> 00:13:40,370
this, but more chronological and

201
00:13:40,440 --> 00:13:43,874
more visually, I guess, easy to understand. So these

202
00:13:43,912 --> 00:13:48,294
we've got feature A and feature B just like the last diagram. And then

203
00:13:48,492 --> 00:13:52,134
let's just say 123456. Those numbers

204
00:13:52,252 --> 00:13:56,242
represent sprints and then the y axis here represents

205
00:13:56,306 --> 00:14:00,290
customers and the x axis is chronological and number of features.

206
00:14:00,450 --> 00:14:03,658
So let's say feature a is done and we're ready to roll it out to

207
00:14:03,664 --> 00:14:07,414
the first set of customers, we roll it out to 25% of customers. In sprint

208
00:14:07,462 --> 00:14:11,494
one, we do whats process monitor,

209
00:14:11,622 --> 00:14:15,086
fix any issues, get feedback. And once we're ready and we

210
00:14:15,108 --> 00:14:18,666
feel comfortable in sprint two, maybe we'll

211
00:14:18,698 --> 00:14:22,318
roll it out to 25% more customers. And then in sprint three,

212
00:14:22,404 --> 00:14:25,918
we'll roll it out to 25% more customers. And maybe in

213
00:14:25,924 --> 00:14:28,926
sprint three, this is a time where we're about to reach a general availability.

214
00:14:29,038 --> 00:14:33,234
Maybe it's time to button up our documentation, make sure it's all up to date.

215
00:14:33,432 --> 00:14:37,186
And these in sprint four, we'll roll it out to all the

216
00:14:37,208 --> 00:14:40,614
customers. Now going back to start a sprint three,

217
00:14:40,652 --> 00:14:44,082
you can see feature B was done and feature B was also ready to release.

218
00:14:44,146 --> 00:14:47,382
So in feature B we repeated the same process, but now

219
00:14:47,436 --> 00:14:50,846
feature B in Sprint three is only released 25% of customers, whereas feature

220
00:14:50,898 --> 00:14:54,486
A is released to 75% of customers. And hopefully feature

221
00:14:54,518 --> 00:14:58,394
A and feature B are decoupled enough so that if something happened and only

222
00:14:58,432 --> 00:15:01,902
went wrong with feature A in sprint one, two or three, you could

223
00:15:01,956 --> 00:15:05,502
pause feature A, continue releasing feature B because

224
00:15:05,556 --> 00:15:09,674
they're feature toggled right and continue the canary approach with feature

225
00:15:09,722 --> 00:15:12,986
B. While feature a is sort of paused and you're working

226
00:15:13,028 --> 00:15:16,718
on fixing the issues, this allows you to unblock your pipeline.

227
00:15:16,814 --> 00:15:20,130
Don't have to do major git wrangling, which,

228
00:15:20,280 --> 00:15:23,230
let's be honest, in some cases is unavoidable.

229
00:15:23,390 --> 00:15:26,478
But hopefully you've decoupled the features enough that you don't

230
00:15:26,494 --> 00:15:29,846
have to do that git wrangling. And you can make the

231
00:15:29,868 --> 00:15:33,506
process easier for your engineers, your developers don't have to rush. Make sure they're

232
00:15:33,538 --> 00:15:37,026
reverting, make sure they're not losing code, make sure they're not having merge

233
00:15:37,058 --> 00:15:40,326
conflicts. All that good stuff that comes with

234
00:15:40,428 --> 00:15:43,606
messing around with git histories and making git merge

235
00:15:43,638 --> 00:15:46,986
commits and reverts. Now feature flags we talked about

236
00:15:47,008 --> 00:15:49,890
a little bit with feature a, feature B in the last couple of slides,

237
00:15:49,990 --> 00:15:53,966
but what do they do for us? They allow us

238
00:15:53,988 --> 00:15:57,550
to inform timing, stability and the go forward

239
00:15:57,620 --> 00:16:00,698
strategy. So you can proactively monitor

240
00:16:00,874 --> 00:16:04,106
what got pushed because you can see when the feature

241
00:16:04,138 --> 00:16:08,222
flag was enabled and then who it got pushed to because you can obviously specify

242
00:16:08,286 --> 00:16:11,218
which customers you enabled the feature flag for.

243
00:16:11,384 --> 00:16:14,846
And that's how we would do canary, you would say feature flag a enabled

244
00:16:14,878 --> 00:16:18,514
for customer A and B, and then feature flag a in

245
00:16:18,552 --> 00:16:22,086
two weeks gets enabled for customer C, customer D and so

246
00:16:22,108 --> 00:16:25,318
on and so forth. You know exactly when you did those changes and then you

247
00:16:25,324 --> 00:16:28,962
can watch for incidents before you continue to push. For example, in the diagram

248
00:16:29,026 --> 00:16:32,694
I've got here on the left from sumo logic, you can see the icon

249
00:16:32,742 --> 00:16:36,006
for the feature flag. You can see it around April 1 the feature

250
00:16:36,038 --> 00:16:40,086
flag was turned on and you can see there's a spike in

251
00:16:40,128 --> 00:16:42,942
Prometheus memory usage. The pink line,

252
00:16:42,996 --> 00:16:46,970
the blue line both spiked and the orange line sort of spiked

253
00:16:47,050 --> 00:16:51,086
there. What happened? Well, if we didn't have

254
00:16:51,188 --> 00:16:55,840
feature flags, we may not necessarily know when

255
00:16:56,230 --> 00:17:00,350
something was rolled out. You could obviously go to your releases

256
00:17:00,510 --> 00:17:03,538
and correlate that. But it's so much easier when you have something whats you can

257
00:17:03,544 --> 00:17:06,974
explicitly turn on and more importantly explicitly

258
00:17:07,022 --> 00:17:10,374
turn off if you saw issues. So if we saw this spike, we could

259
00:17:10,412 --> 00:17:13,670
potentially turn it off. So we turned off a feature flag maybe,

260
00:17:13,740 --> 00:17:17,686
and these it goes back down. And then once everything is stable and

261
00:17:17,708 --> 00:17:21,190
you fix the any issues you've identified, you roll out to other users.

262
00:17:21,770 --> 00:17:25,286
And in all this slot the test for a rollback strategy,

263
00:17:25,318 --> 00:17:28,250
because in worst case scenario you have to roll back the code to make sure

264
00:17:28,320 --> 00:17:31,120
you have a strategy in place. If you do need to do that,

265
00:17:31,650 --> 00:17:35,486
let's take a simple case study regarding a

266
00:17:35,508 --> 00:17:38,830
project that we internally canary called Comsflow.

267
00:17:39,570 --> 00:17:43,666
Comsflow is a communications flow tool

268
00:17:43,768 --> 00:17:48,670
whats allows the users to customize

269
00:17:48,750 --> 00:17:52,450
message templates and messages and who

270
00:17:52,520 --> 00:17:56,514
they want to send those messages to based on certain events. In the blameless platform,

271
00:17:56,712 --> 00:18:00,262
for example, you could have incident status changes trigger an event.

272
00:18:00,316 --> 00:18:03,714
Incident severity changes or retrospective state changes trigger

273
00:18:03,762 --> 00:18:07,186
a blameless event, which would trigger a message that has variables

274
00:18:07,218 --> 00:18:09,606
in it to SMS,

275
00:18:09,718 --> 00:18:13,542
email, Slack, Microsoft Teams, or status page recipients.

276
00:18:13,686 --> 00:18:17,366
And those recipients could be internal or external. You could directly

277
00:18:17,398 --> 00:18:20,698
post to a customer status parts you've got. You could directly post

278
00:18:20,784 --> 00:18:23,358
to a public page if you wanted to.

279
00:18:23,524 --> 00:18:27,102
Now, in this product, you can see

280
00:18:27,156 --> 00:18:30,974
there's different areas that could be feature flagged individually. For example, we could take

281
00:18:31,012 --> 00:18:34,958
incident status, incident severity, post mortem state.

282
00:18:35,044 --> 00:18:39,070
Those could all be separate features. Maybe we only release incident status

283
00:18:39,230 --> 00:18:42,926
and that was the only thing that was complete at the time. Maybe we releases

284
00:18:42,958 --> 00:18:46,734
that first as a feature flag, and then maybe blameless

285
00:18:46,782 --> 00:18:50,350
event and reminders are separated as well. Maybe we

286
00:18:50,360 --> 00:18:53,366
only want to do events at the moment. We don't want to enable reminders or

287
00:18:53,388 --> 00:18:56,674
they're not done yet, the development isn't complete, we'll just keep that features flag

288
00:18:56,722 --> 00:19:00,118
off. And then in the message template we've got these variables that I

289
00:19:00,124 --> 00:19:03,530
mentioned. We could turn off variables because like I said, it could

290
00:19:03,600 --> 00:19:07,226
not be done, or you want to minimize the release scope. And then even

291
00:19:07,248 --> 00:19:10,778
the recipients could be controlled based feature flags. So anything

292
00:19:10,864 --> 00:19:15,434
could be feature flagged here pretty much, but it really depends on your organization,

293
00:19:15,562 --> 00:19:18,926
your team, and how granular you want to be. As far

294
00:19:18,948 --> 00:19:22,682
as feature flagging, here's a rough overview

295
00:19:22,746 --> 00:19:26,562
and plan that we had about how we rolled out comms flow. For example,

296
00:19:26,616 --> 00:19:30,178
we had the first iteration in early December. We had a certain set of

297
00:19:30,184 --> 00:19:33,906
features built for comprise flow, and at

298
00:19:33,928 --> 00:19:37,990
the bottom we had some customer accounts that we decided

299
00:19:38,490 --> 00:19:42,134
were asking for a feature and wanted

300
00:19:42,172 --> 00:19:45,446
to use it, et cetera. We just determined who those were and rolled out

301
00:19:45,468 --> 00:19:48,214
iteratively using a canary approach to those customers,

302
00:19:48,412 --> 00:19:51,546
and then we let them play with it for all of

303
00:19:51,568 --> 00:19:54,758
December. And then in Canary we came out with the next set of features

304
00:19:54,774 --> 00:19:57,514
which were individually feature toggled as well.

305
00:19:57,632 --> 00:20:01,470
And then we decided, okay, all the customers can have this feature because

306
00:20:01,540 --> 00:20:04,990
we felt comfortable and confident based on our previous releases.

307
00:20:05,330 --> 00:20:08,800
What do we learn in this process? Well, a couple of things.

308
00:20:09,330 --> 00:20:13,440
Production readiness. As we rolled out two customers

309
00:20:14,710 --> 00:20:18,174
iteratively in a subset manner using a canary

310
00:20:18,222 --> 00:20:21,682
approach, we were able to get feedback from these customers. We were able to

311
00:20:21,736 --> 00:20:25,026
monitor our metrics and make sure nothing were

312
00:20:25,048 --> 00:20:28,326
breaking. So that gives us more confidence as far as how ready this application is

313
00:20:28,348 --> 00:20:32,262
for production. Obviously we do production readiness testing before

314
00:20:32,316 --> 00:20:35,650
we release to any customer as well. But just getting that feedback

315
00:20:35,730 --> 00:20:39,494
or getting that visibility into customers using

316
00:20:39,532 --> 00:20:42,694
it and our logs looking okay and our services are healthy

317
00:20:42,742 --> 00:20:45,898
gives us even more confidence that yes, when we roll this out,

318
00:20:46,064 --> 00:20:49,866
this will work and it won't break and cause headaches. And these,

319
00:20:49,888 --> 00:20:53,290
these other thing is much more agile roadmap. We were able to

320
00:20:53,440 --> 00:20:57,086
break up all the features and different features so that people could still develop and

321
00:20:57,108 --> 00:21:00,606
keep developing without worrying about overriding somebody's change or

322
00:21:00,628 --> 00:21:04,398
merging something. Whats couldn't go out to production because we had feature plays in place

323
00:21:04,564 --> 00:21:08,142
and a couple of other things. Ownership and code cleanup.

324
00:21:08,206 --> 00:21:12,078
Well, ownership, what does that mean? Well, we had a lot of features,

325
00:21:12,174 --> 00:21:15,954
created a bunch of feature flags. One thing, in some

326
00:21:16,072 --> 00:21:19,506
cases we dropped the ball as far as who whats the owner,

327
00:21:19,698 --> 00:21:23,250
who whats responsible for enabling the feature flag? Is the product manager,

328
00:21:23,330 --> 00:21:27,042
is the engineering manager, is the engineer who's responsible

329
00:21:27,106 --> 00:21:30,358
for enabling the feature flag. That wasn't super clear for some of

330
00:21:30,364 --> 00:21:33,002
the features that we rolled out. And so we had features that we rolled out

331
00:21:33,056 --> 00:21:36,774
at one point that weren't enabled for customers and we thought they were released

332
00:21:36,902 --> 00:21:40,054
and then we had to go back and enable them. So lesson learned.

333
00:21:40,182 --> 00:21:43,846
And we obviously learned from that and working towards making

334
00:21:43,888 --> 00:21:47,486
it better and have a process for it now. But keep that in mind as

335
00:21:47,508 --> 00:21:51,374
you're adding feature plays throughout your code base. And then since

336
00:21:51,412 --> 00:21:54,906
you're adding feature flags throughout your code base, code cleanup becomes

337
00:21:54,938 --> 00:21:58,786
an issue as well. Let's say you've gone through the canary process. You've enabled the

338
00:21:58,808 --> 00:22:01,906
features for x number of customers over time.

339
00:22:02,088 --> 00:22:05,330
Now you've got to go back and clean up that code

340
00:22:05,480 --> 00:22:09,058
because otherwise you're going to have really bad code where you

341
00:22:09,064 --> 00:22:13,254
have a bunch of if statements checking for certain features, et cetera, and those

342
00:22:13,292 --> 00:22:16,198
aren't really useful anymore because you've already enabled it for everybody. So you want to

343
00:22:16,204 --> 00:22:19,430
go back and take those out. That's an important aspect from a development experience

344
00:22:19,500 --> 00:22:23,314
perspective. Now let's talk about how we went about

345
00:22:23,372 --> 00:22:27,146
building the right canary user groups, right the

346
00:22:27,168 --> 00:22:30,710
first users group that is the most important, in my opinion,

347
00:22:30,790 --> 00:22:34,510
as far as releasing feature to is the ones that are already using a specific

348
00:22:34,580 --> 00:22:38,334
product area where you're adding a features, you don't want to impact their

349
00:22:38,372 --> 00:22:42,426
workflow. If you're releasing a feature and you're impacting their workflow,

350
00:22:42,458 --> 00:22:46,010
you want them to test it out. You want them to like, hey, first of

351
00:22:46,020 --> 00:22:49,326
all, let them know, hey, we're releasing

352
00:22:49,358 --> 00:22:52,866
this new feature. Kind of want you to take a look at it and let

353
00:22:52,888 --> 00:22:56,258
us know what you think. And these, maybe they've asked for these specific feature in

354
00:22:56,264 --> 00:23:00,306
the first place. So you obviously want their feedback right off the bat without releases

355
00:23:00,338 --> 00:23:03,382
to everybody else. And the great thing is you can tell

356
00:23:03,436 --> 00:23:07,346
customers, look, we're releasing this feature and they'll

357
00:23:07,378 --> 00:23:10,986
trust you because they'll see that you have

358
00:23:11,008 --> 00:23:14,826
a plan. You're not just rolling things out willy nilly and that

359
00:23:14,848 --> 00:23:18,266
you're actually innovating. These. There's another set of

360
00:23:18,288 --> 00:23:21,718
users that are less active, right? They're not currently using the product area. They didn't

361
00:23:21,734 --> 00:23:25,166
really ask for it. Do they even care about the feature? Are these the right

362
00:23:25,268 --> 00:23:28,560
group for canary testing? Probably not.

363
00:23:29,250 --> 00:23:33,214
And there's a vocal set of users who will give you specific feedback even

364
00:23:33,252 --> 00:23:37,066
if you don't ask for it. Sometimes it's valuable to get that opinion,

365
00:23:37,098 --> 00:23:40,366
but you also don't want to have a bunch of noise as far as feedback

366
00:23:40,398 --> 00:23:43,794
is concerned. You want to make sure you target these users that are the super

367
00:23:43,832 --> 00:23:47,342
users of your product or of that features specifically,

368
00:23:47,486 --> 00:23:51,398
because you want to know when customers actually using it,

369
00:23:51,564 --> 00:23:54,662
how do they use it, how does it impact these workflow? Does it improve something

370
00:23:54,716 --> 00:23:57,622
for them or did it make things worse? You want to know from the power

371
00:23:57,676 --> 00:24:00,842
users, you don't want to know necessarily from someone who likes giving

372
00:24:00,896 --> 00:24:04,186
feedback, wants to give feedback and doesn't really use

373
00:24:04,208 --> 00:24:07,594
the feature heavily, though we all, we may even

374
00:24:07,632 --> 00:24:11,466
be some of those vocal users ourselves. But as

375
00:24:11,488 --> 00:24:14,734
far as canary testing, the best group to target is the ones that

376
00:24:14,772 --> 00:24:18,506
are already using youll product area or have specifically

377
00:24:18,538 --> 00:24:22,206
asked for a feature set. The harness blog had

378
00:24:22,228 --> 00:24:25,834
a quote that says a Canary deployment is the lowest risk

379
00:24:25,882 --> 00:24:29,474
prone compared to all these deployment strategies because of the level

380
00:24:29,512 --> 00:24:32,834
of control. And I would agree you're releasing to a small

381
00:24:32,872 --> 00:24:36,466
set of users, not everybody. And so you control who's

382
00:24:36,498 --> 00:24:42,614
getting the experience that you've decided. And you also control when

383
00:24:42,652 --> 00:24:46,726
you can roll it back as well, right? If something goes wrong, you can

384
00:24:46,748 --> 00:24:49,718
roll it back. If things look good, then you roll out the next set of

385
00:24:49,724 --> 00:24:53,446
customers, so you have that control within your hands. And features plays just

386
00:24:53,468 --> 00:24:56,870
make that even easier by being able to turn it off really easily.

387
00:24:57,210 --> 00:25:01,374
And that's all for today. Please let me know if youll have any questions.

388
00:25:01,572 --> 00:25:05,614
Please feel free to send feedback to my email hamad@blameless.com and

389
00:25:05,652 --> 00:25:07,820
I'll be available for any questions. Thank you.

