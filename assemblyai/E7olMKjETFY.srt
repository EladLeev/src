1
00:00:23,930 --> 00:00:27,442
Hi everyone, welcome. Come to the session on unleashing the power of chaos

2
00:00:27,506 --> 00:00:29,750
engineering in CD pipelines.

3
00:00:30,490 --> 00:00:34,006
I'm Sarthak and with me is Saranya. We both

4
00:00:34,028 --> 00:00:37,366
are senior software developers at harness and also maintainer of

5
00:00:37,388 --> 00:00:41,106
Litmus Chaos which is an open source tool that allows

6
00:00:41,138 --> 00:00:44,514
you to practice chaos engineering. We have attached our LinkedIn

7
00:00:44,562 --> 00:00:48,134
and Twitter profiles just in case you want to reach out to us after

8
00:00:48,172 --> 00:00:51,582
this session. So agenda I'll be

9
00:00:51,636 --> 00:00:55,342
talking about Kios in CD pipelines. I know it is something

10
00:00:55,396 --> 00:00:59,210
that not many organizations practice and is new for many SREs

11
00:00:59,290 --> 00:01:02,974
and DevOps engineers. There are organizations who

12
00:01:03,012 --> 00:01:06,686
don't even practice Kios engineering as standalone task

13
00:01:06,798 --> 00:01:09,940
and they're surely missing out on a lot because of this.

14
00:01:10,470 --> 00:01:13,874
I'll also share some interesting stats that I've copied from

15
00:01:13,912 --> 00:01:17,074
Google which may get you thinking, followed by

16
00:01:17,112 --> 00:01:20,854
which I'll tell you why Kios is important and how

17
00:01:20,892 --> 00:01:24,246
it can help you make a better product. And at

18
00:01:24,268 --> 00:01:27,554
the end Sarania will show a demo on what are the strategies

19
00:01:27,602 --> 00:01:31,770
that we follow and how we do it at harness to make our product

20
00:01:31,840 --> 00:01:35,402
resilient. I hope the agenda is interesting enough

21
00:01:35,456 --> 00:01:38,778
to keep you with us till the end. All right,

22
00:01:38,864 --> 00:01:42,038
let's get started. So I know

23
00:01:42,064 --> 00:01:45,690
this is the honest reaction of DevOps engineers and SREs

24
00:01:45,770 --> 00:01:49,294
who are peacefully running their CD pipelines. I know

25
00:01:49,332 --> 00:01:52,926
you guys have done a great job building a deployment pipeline for

26
00:01:52,948 --> 00:01:56,306
your application, but trust me, adding a chaos step is

27
00:01:56,328 --> 00:01:59,906
worth it and I bet you guys will be convinced by the end of

28
00:01:59,928 --> 00:02:04,274
this talk. So chaos in CD pipelines in simple terms,

29
00:02:04,472 --> 00:02:08,262
means adding disciplined chaos in your pipeline and check

30
00:02:08,316 --> 00:02:11,986
how the system reacts to these disruptions. So the goal

31
00:02:12,018 --> 00:02:15,490
is to ensure that the CD pipelines remains stable,

32
00:02:15,650 --> 00:02:19,274
reliable and capable of delivering software smoothly even

33
00:02:19,312 --> 00:02:22,410
if unexpected challenges arises.

34
00:02:23,070 --> 00:02:26,438
Let's see some interesting stats here. So downtimes

35
00:02:26,454 --> 00:02:30,166
are expensive the Gartner it key metrics data

36
00:02:30,288 --> 00:02:33,982
report states that average cost of downtime is around

37
00:02:34,036 --> 00:02:37,326
five point six k dollars per minute, which is

38
00:02:37,348 --> 00:02:41,326
a lot. Not only the cost, but customer impact as

39
00:02:41,348 --> 00:02:45,182
well. So poor system reliability and unexpected failures

40
00:02:45,246 --> 00:02:48,610
can lead to a decline in customer satisfaction and loyalty.

41
00:02:49,190 --> 00:02:52,946
According to Zendesk, 39% of customers will

42
00:02:53,048 --> 00:02:56,502
avoid using a product or service after a bad experience

43
00:02:56,636 --> 00:03:00,706
for obvious reasons. So now the question is how to improve

44
00:03:00,738 --> 00:03:04,120
these numbers. And the answer is quite simple,

45
00:03:04,890 --> 00:03:08,406
make your system resilient and improve MTTR. That is

46
00:03:08,428 --> 00:03:11,734
the mean time to repair. So now chaos engineering

47
00:03:11,782 --> 00:03:14,986
can help you achieve this and injecting chaos in

48
00:03:15,008 --> 00:03:17,820
your CD pipelines can help you automate the process.

49
00:03:19,890 --> 00:03:23,406
Let's see why chaos step in deployment pipeline and how is it

50
00:03:23,428 --> 00:03:27,070
useful. So the first one is early issue detection.

51
00:03:27,490 --> 00:03:31,322
Chaos engineering involves intentionally injecting controlled

52
00:03:31,386 --> 00:03:35,182
disruptions into the systems. So this process allows

53
00:03:35,246 --> 00:03:38,882
teams to identify weakness and vulnerabilities before

54
00:03:38,936 --> 00:03:42,514
the system reaches the production environment. So by identifying and

55
00:03:42,552 --> 00:03:45,870
addressing issues, early teams can prevent

56
00:03:45,950 --> 00:03:49,666
these problems from causing any significant outages or failures in

57
00:03:49,688 --> 00:03:53,266
the live production systems and avoid

58
00:03:53,298 --> 00:03:56,726
its impact on the users. So let's say for an

59
00:03:56,748 --> 00:04:00,186
example, suppose a chaos experiment reveals that a

60
00:04:00,208 --> 00:04:03,834
certain component of the system becomes unresponsive under

61
00:04:03,872 --> 00:04:07,050
high load conditions. So injecting this early,

62
00:04:07,200 --> 00:04:11,302
let's say, in QA, will allow the team to optimize the component

63
00:04:11,446 --> 00:04:15,086
before it impacts the end user. And this is a very

64
00:04:15,108 --> 00:04:18,842
common situation. Next, we have enhanced resilience,

65
00:04:18,986 --> 00:04:22,446
let's say improved resilience. So anyone who

66
00:04:22,468 --> 00:04:26,018
has read about chaos engineering, so anyone who

67
00:04:26,024 --> 00:04:29,362
has read about chaos engineering must know that this is the primary aim of

68
00:04:29,416 --> 00:04:33,010
chaos engineering, that is, to make the systems more resilient.

69
00:04:33,430 --> 00:04:37,206
Chaos experiments are designed to test how well a

70
00:04:37,228 --> 00:04:41,026
system can adapt to unexpected conditions, and it continues

71
00:04:41,058 --> 00:04:44,854
to function without causing any major failures. So by

72
00:04:44,892 --> 00:04:48,950
deliberately introducing chaos and monitoring system behavior,

73
00:04:49,110 --> 00:04:52,326
teams can implement strategies that enhance the system's

74
00:04:52,358 --> 00:04:55,786
overall resilience. So let's say, for an example,

75
00:04:55,968 --> 00:04:59,446
if a chaos experiment simulates a sudden increase in traffic

76
00:04:59,558 --> 00:05:03,338
or server failure, the team can use the insights gained

77
00:05:03,354 --> 00:05:07,006
to implement auto scaling mechanisms or some other solutions to

78
00:05:07,028 --> 00:05:11,290
tackle this. Then we have improved incident response.

79
00:05:11,450 --> 00:05:14,942
So by intentionally introducing chaos in your CD pipeline,

80
00:05:15,086 --> 00:05:18,500
you create controlled scenarios where things can go wrong.

81
00:05:18,950 --> 00:05:22,446
So this will provide an opportunity to identify weakness in your system's

82
00:05:22,478 --> 00:05:26,390
response mechanism, identify the and identify

83
00:05:26,970 --> 00:05:30,294
incident handling procedures. So let's say for an

84
00:05:30,332 --> 00:05:34,098
example, consider a scenario where you simulate a sudden

85
00:05:34,194 --> 00:05:37,894
surge in user traffic during the ko step. So this

86
00:05:37,932 --> 00:05:42,054
allows your team to assess how well the system can handle unexpected

87
00:05:42,102 --> 00:05:46,166
spikes and how quickly can it scale resources to maintain

88
00:05:46,198 --> 00:05:50,278
performance. So any issues discovered during this scale scenario

89
00:05:50,374 --> 00:05:54,330
can be addressed which will lead to an improved incident response.

90
00:05:54,410 --> 00:05:57,710
When similar situation occur in a real world scenario,

91
00:05:58,210 --> 00:06:01,566
then we have continuous validation. For me,

92
00:06:01,668 --> 00:06:05,158
this is the most important thing. Adding Ko

93
00:06:05,194 --> 00:06:08,514
step in the CD pipeline ensures continuous validation of your

94
00:06:08,552 --> 00:06:11,010
system's resilience and reliability.

95
00:06:11,750 --> 00:06:15,274
So regularly testing the system to controlled chaos

96
00:06:15,422 --> 00:06:19,510
will help in validating that it can withstand unexpected

97
00:06:19,930 --> 00:06:23,334
events and disruptions throughout its life cycles, not only

98
00:06:23,372 --> 00:06:26,706
once, but throughout its lifecycle. So practicing

99
00:06:26,738 --> 00:06:30,790
chaos engineering once or twice and thinking your application is resilient

100
00:06:31,290 --> 00:06:34,586
is like hitting the gym on a new year and thinking that you will be

101
00:06:34,608 --> 00:06:37,914
fit for the rest of the year. You know, that's not

102
00:06:37,952 --> 00:06:41,562
how it works. So continuous validation ensures

103
00:06:41,626 --> 00:06:44,986
that you don't just test for resilience once and forget

104
00:06:45,018 --> 00:06:48,494
about it. Instead, you regularly subject your system to

105
00:06:48,532 --> 00:06:52,030
different chaos scenarios, and you validate that your system

106
00:06:52,100 --> 00:06:55,010
adapts and responds well to these challenges.

107
00:06:55,750 --> 00:06:59,246
So it's like giving your system a regular workout to ensure

108
00:06:59,358 --> 00:07:03,218
it stays in top shape, reducing the risk of unexpected failures when

109
00:07:03,224 --> 00:07:06,850
it matters the most. So when you deliver your product

110
00:07:06,920 --> 00:07:10,566
to the customer, you are confident that we have done all

111
00:07:10,588 --> 00:07:14,466
the amount of testing, and it's not going to cause any disruptions,

112
00:07:14,578 --> 00:07:18,406
and it will be a very smooth experience for the customers. Then we

113
00:07:18,428 --> 00:07:20,570
have increased adoption of chaos.

114
00:07:21,230 --> 00:07:25,158
So even though chaos is not a new term anymore in the industry,

115
00:07:25,334 --> 00:07:28,614
and I'm pretty sure that whoever is seeing this session

116
00:07:28,662 --> 00:07:32,346
is very well aware of what chaos engineering is now, which was

117
00:07:32,368 --> 00:07:35,120
not the case maybe three or four years back.

118
00:07:35,890 --> 00:07:39,082
So even though chaos is not a very new term in the industry,

119
00:07:39,226 --> 00:07:42,766
but there are teams and organizations that are reluctant to

120
00:07:42,788 --> 00:07:46,334
use it in their systems. Adding and automating

121
00:07:46,382 --> 00:07:50,446
chaos through CD pipelines and testing out with simple chaos experiments

122
00:07:50,558 --> 00:07:54,046
will help them gain confidence and allow them to adopt

123
00:07:54,078 --> 00:07:57,140
two chaos engineering practices. So,

124
00:07:57,670 --> 00:08:01,194
by gradually injecting chaos scenarios into the CD pipeline

125
00:08:01,342 --> 00:08:04,322
and noticing the positive impact on system reliability,

126
00:08:04,466 --> 00:08:08,294
the team becomes more comfortable and confident in adopting chaos

127
00:08:08,342 --> 00:08:12,314
engineering practices. So this increased acceptance will

128
00:08:12,352 --> 00:08:16,182
lead to a culture where chaos is seen as a means of continuous

129
00:08:16,246 --> 00:08:18,730
improvement rather than a potential risk.

130
00:08:19,310 --> 00:08:22,414
I know this fear is still there in the market that chaos can

131
00:08:22,452 --> 00:08:27,546
cause disruptions, and our system may not be healthy

132
00:08:27,578 --> 00:08:31,610
enough to handle all these things, and we don't have to do chaos testing

133
00:08:31,690 --> 00:08:34,994
in our system, but it's not like

134
00:08:35,032 --> 00:08:38,942
that. So, just to start off with, you can start with some simple chaos

135
00:08:39,006 --> 00:08:42,786
experiments, integrate it in your CD pipelines, and you will

136
00:08:42,808 --> 00:08:46,614
see the results. So that's how it works.

137
00:08:46,812 --> 00:08:53,414
So these are the five important reasons which

138
00:08:53,452 --> 00:08:57,270
you can get benefit from if you integrate chaos in your CD pipelines,

139
00:08:57,870 --> 00:09:01,260
right? So just a meme here.

140
00:09:01,790 --> 00:09:05,530
No developer were hurt in making this meme.

141
00:09:06,030 --> 00:09:08,220
It's just a meme to lighten up things.

142
00:09:09,630 --> 00:09:12,794
So, enough of theory now. Let's get

143
00:09:12,832 --> 00:09:16,298
to the demo. Time for the demo. Hope the demo gods

144
00:09:16,394 --> 00:09:20,142
is with us. Over to you, Saranya. Thanks,

145
00:09:20,196 --> 00:09:24,274
Arthur. And hey, everyone, this is Saranya, and I'm going to give a

146
00:09:24,472 --> 00:09:28,594
brief demo or more of it. I'm going to explain how

147
00:09:28,792 --> 00:09:33,026
we can add chaos as pipelines as

148
00:09:33,048 --> 00:09:36,566
a step in. CD pipelines so in the

149
00:09:36,588 --> 00:09:39,080
name of the demo gods, let's get started.

150
00:09:41,050 --> 00:09:44,360
So before going to the pipeline itself, I'm going to

151
00:09:46,010 --> 00:09:49,338
explain the environment. So this is the application that we

152
00:09:49,344 --> 00:09:52,294
are going to that is being deployed.

153
00:09:52,342 --> 00:09:55,786
And as

154
00:09:55,808 --> 00:09:59,740
you can see, this is an online booty cat shopping application, demo application,

155
00:10:00,690 --> 00:10:03,978
which has a microservice based architecture. It has various

156
00:10:04,074 --> 00:10:08,234
microservices such as cart

157
00:10:08,282 --> 00:10:12,110
service, checkout service, and a currency converter service.

158
00:10:12,180 --> 00:10:15,314
So multiple services are there. So basically you

159
00:10:15,352 --> 00:10:18,898
can do a very basic functionality of online

160
00:10:18,984 --> 00:10:22,658
shopping. So you can change the quantity, add it

161
00:10:22,664 --> 00:10:25,960
to the cart, and you can place an order.

162
00:10:27,450 --> 00:10:32,966
So this is the application that we are going to deploy. And here,

163
00:10:33,068 --> 00:10:37,014
let me show you CD pipelines. So this is the pipeline that we have

164
00:10:37,052 --> 00:10:40,794
created. And the first step is

165
00:10:40,912 --> 00:10:44,102
obviously the deployment step. This is the rollout deployment,

166
00:10:44,246 --> 00:10:47,654
and next step is the observed deployment

167
00:10:47,702 --> 00:10:51,322
step. So in this step we generally

168
00:10:51,466 --> 00:10:56,126
observe the application, how it behaves, like if

169
00:10:56,148 --> 00:11:00,426
it's healthy or not. If it's not, then we can simply roll

170
00:11:00,458 --> 00:11:04,100
it back, otherwise it will go further with the cure step.

171
00:11:04,470 --> 00:11:08,002
So for the demo purpose, I have just

172
00:11:08,056 --> 00:11:14,066
added sleep of ten minutes, 10 seconds, and you

173
00:11:14,088 --> 00:11:17,954
can add your own commands as per your own requirements. So that's

174
00:11:18,002 --> 00:11:20,920
that then, coming to the chaos step.

175
00:11:21,610 --> 00:11:25,090
So here I have added

176
00:11:25,170 --> 00:11:28,234
this, so as chaos experimentation step.

177
00:11:28,352 --> 00:11:31,702
So we have added this booty cat cpu hog experiment.

178
00:11:31,766 --> 00:11:35,306
So what it does, it generally puts a

179
00:11:35,328 --> 00:11:39,254
load on cpu in the target

180
00:11:39,302 --> 00:11:41,790
cluster where the application is deployed.

181
00:11:43,090 --> 00:11:45,920
And this is the expected resilience course.

182
00:11:46,530 --> 00:11:49,726
I'll come back to this in a while. And this is

183
00:11:49,748 --> 00:11:53,486
the chaos infrastructure detail that the target infrastructure, where the application has

184
00:11:53,508 --> 00:11:56,974
been deployed, and the namespace and default is pod

185
00:11:57,022 --> 00:12:00,782
cpu hog. So, coming to the expected resilience

186
00:12:00,846 --> 00:12:04,114
score. So let me give

187
00:12:04,152 --> 00:12:07,666
you a quick refresher on how chaos engineering is generally

188
00:12:07,698 --> 00:12:11,240
carried out. So the very first step of the chaos engineering is,

189
00:12:11,770 --> 00:12:14,662
first of all, we have to identify the steady state,

190
00:12:14,716 --> 00:12:18,426
continuous, the steady state hypothesis. That means how the

191
00:12:18,448 --> 00:12:21,478
application behaves when it is healthy.

192
00:12:21,574 --> 00:12:25,386
So first you need to identify that, and then we introduce a

193
00:12:25,408 --> 00:12:29,146
fault, and then we check if the

194
00:12:29,168 --> 00:12:33,002
slos are met or not. If yes, then the application is resilient.

195
00:12:33,066 --> 00:12:37,200
Otherwise the weakness is found and we have to

196
00:12:37,650 --> 00:12:41,022
improve upon that and then run

197
00:12:41,076 --> 00:12:46,994
this complete cycle again and again in

198
00:12:47,032 --> 00:12:49,940
connection to this first step. That is the steady state,

199
00:12:51,990 --> 00:12:56,354
the steady state hypothesis. We have this expected

200
00:12:56,402 --> 00:12:59,554
resilience code. That means what is the minimum resilience

201
00:12:59,602 --> 00:13:03,400
code that we expect the application to have,

202
00:13:03,770 --> 00:13:07,374
so that the cure step is considered as successful.

203
00:13:07,522 --> 00:13:10,330
So you can give it any number.

204
00:13:10,400 --> 00:13:14,986
But to give an idea on how

205
00:13:15,008 --> 00:13:18,394
we can decide upon this number, if you click on here,

206
00:13:18,512 --> 00:13:21,738
you can see as these are all previously run experiments,

207
00:13:21,754 --> 00:13:25,246
you can get an idea of

208
00:13:25,268 --> 00:13:29,022
the expected score from this last resilience score. For this,

209
00:13:29,076 --> 00:13:32,560
let's say it's 100 and for lambda function

210
00:13:33,430 --> 00:13:36,770
timeouts. So for this experiment it's 50%.

211
00:13:36,840 --> 00:13:40,926
So according to these last run, last resilience

212
00:13:40,958 --> 00:13:44,546
for values, we can decide and then we

213
00:13:44,568 --> 00:13:48,306
can improvise based on like after multiple runs,

214
00:13:48,418 --> 00:13:51,814
we'll obviously get an idea what value to set

215
00:13:51,852 --> 00:13:56,040
there. So yeah, that's that.

216
00:13:56,570 --> 00:14:00,220
And then coming to this particular

217
00:14:01,550 --> 00:14:04,986
step, the diagram that Sarthak Jain

218
00:14:05,008 --> 00:14:08,300
already mentioned, you must be wondering, where is the rollback step?

219
00:14:09,950 --> 00:14:13,790
We have this cure step, but where is the rollback step?

220
00:14:13,940 --> 00:14:17,246
So if you click on

221
00:14:17,268 --> 00:14:20,586
this particular cure step, and if we go to this advanced

222
00:14:20,618 --> 00:14:23,940
section here, we have this failure strategy. That means

223
00:14:24,390 --> 00:14:28,462
what strategy to adopt when this particular step fails.

224
00:14:28,526 --> 00:14:31,694
So in this particular pipeline,

225
00:14:31,742 --> 00:14:35,778
we have chosen the rollback stage. So in case the step fails,

226
00:14:35,874 --> 00:14:40,418
it will basically simply roll it back to the healthy

227
00:14:40,514 --> 00:14:44,838
deployment. So if I

228
00:14:44,924 --> 00:14:48,794
come here, this is a different pipeline where I will

229
00:14:48,832 --> 00:14:51,180
be able to show how to add.

230
00:14:54,590 --> 00:14:58,054
This is the cure step. And if I go to advanced section, in the failure

231
00:14:58,102 --> 00:15:01,760
strategy here, you can see we have this rollback stage and

232
00:15:05,490 --> 00:15:08,954
we can also have other options as a failure

233
00:15:09,002 --> 00:15:13,070
strategy that is like manual intervention. If you want to do a manual intervention

234
00:15:15,110 --> 00:15:18,260
after post, like there's a timeout after that,

235
00:15:18,790 --> 00:15:22,500
some of these market success or ignore it, something like that

236
00:15:23,990 --> 00:15:27,554
will happen as per your own requirement. So in QA

237
00:15:27,602 --> 00:15:31,480
you can simply ignore or

238
00:15:32,890 --> 00:15:36,962
abort or mark it as success. But in prod environment

239
00:15:37,106 --> 00:15:40,998
it is advisable to roll it back to a safer

240
00:15:41,174 --> 00:15:44,842
deployment. So here also you have

241
00:15:44,896 --> 00:15:47,820
other options like mark as access,

242
00:15:48,270 --> 00:15:51,020
retry and all other things are there.

243
00:15:51,390 --> 00:15:54,958
So in addition to this, I wanted to also,

244
00:15:55,124 --> 00:15:59,566
just wanted to let you know that here

245
00:15:59,748 --> 00:16:03,230
you can also add other steps

246
00:16:03,750 --> 00:16:07,634
in parallel or in serial, so you can add a cure if

247
00:16:07,672 --> 00:16:11,410
I click here. So you can also add any other step

248
00:16:11,480 --> 00:16:14,020
or a cure step in general.

249
00:16:15,030 --> 00:16:19,122
So you can choose an experiment and choose

250
00:16:19,176 --> 00:16:22,646
the expected resilience score and add it here like

251
00:16:22,668 --> 00:16:26,626
this. So coming back to our original

252
00:16:26,738 --> 00:16:29,722
demo pipeline, so as here,

253
00:16:29,776 --> 00:16:33,482
you can see I think we are clear about

254
00:16:33,536 --> 00:16:38,438
this particular pipeline, and due

255
00:16:38,454 --> 00:16:41,774
to time constraint, I won't be able to run it because it will take quite

256
00:16:41,812 --> 00:16:45,120
some time, but I will be able to explain

257
00:16:46,130 --> 00:16:50,270
the failure and success cases

258
00:16:51,170 --> 00:16:55,246
from the execution already executing executed

259
00:16:55,278 --> 00:16:59,060
pipelines. So we have run it multiple times.

260
00:16:59,430 --> 00:17:03,330
So let me first go to this failed pipeline.

261
00:17:03,910 --> 00:17:07,686
Yeah, so here you can see this Kio step has been

262
00:17:07,708 --> 00:17:11,138
failures because the expected resilience score

263
00:17:11,234 --> 00:17:15,766
here is 90. But the resilience score we got after the

264
00:17:15,948 --> 00:17:20,186
execution is 66. That's why this particular step failed. And as

265
00:17:20,208 --> 00:17:23,686
a result of that, the rollback step got triggered.

266
00:17:23,718 --> 00:17:27,626
Because I already showed you that we have chosen the rollback strategy as

267
00:17:27,648 --> 00:17:31,446
a rollback, as a failure strategy. So rollback

268
00:17:31,638 --> 00:17:35,566
step got triggered and posted. A health check

269
00:17:35,748 --> 00:17:40,350
to ensure the deployment is healthy has also been executed.

270
00:17:40,770 --> 00:17:44,802
So this is what happens in case the

271
00:17:44,936 --> 00:17:48,882
cure step gets failed. And other

272
00:17:48,936 --> 00:17:52,834
than that, let's go to the success one

273
00:17:52,952 --> 00:17:56,614
here if I. Yeah, so here

274
00:17:56,652 --> 00:17:59,746
you can see this pipeline chaos been successful.

275
00:17:59,778 --> 00:18:03,186
Pipelines execution has been successful because the expected resilience score

276
00:18:03,218 --> 00:18:06,902
is 90, whereas the actual resilience score is 100.

277
00:18:07,036 --> 00:18:11,466
But if you want to see this particular chaos execution step in

278
00:18:11,488 --> 00:18:16,646
detail, you can just click here. And this brings

279
00:18:16,678 --> 00:18:20,606
us to the chaos execution step. Here you can

280
00:18:20,628 --> 00:18:24,414
see the steps that like

281
00:18:24,452 --> 00:18:29,486
first of all that is the install cure step. Then the actual

282
00:18:29,588 --> 00:18:32,766
fault execution here you can see all the

283
00:18:32,948 --> 00:18:36,174
required probes here. First one is

284
00:18:36,212 --> 00:18:40,358
the card service availability check, then booty

285
00:18:40,394 --> 00:18:43,506
website latency check, and the pod status check. So all

286
00:18:43,528 --> 00:18:46,920
these probes have been passed, resulting in the score of 100%.

287
00:18:47,770 --> 00:18:51,446
And if you wish to see the logs, logs are also available

288
00:18:51,548 --> 00:18:55,222
here and fault configuration can also be found

289
00:18:55,276 --> 00:18:58,666
out here. So this is how you can see the

290
00:18:58,688 --> 00:19:03,260
chaos experimentation in detail. And before

291
00:19:04,270 --> 00:19:07,674
wrapping this up, I have two more things to share if

292
00:19:07,712 --> 00:19:11,214
I go back. So the

293
00:19:11,252 --> 00:19:14,142
demo I showed, like whatever I explained here,

294
00:19:14,276 --> 00:19:18,026
this can be easily done with natively using the harness

295
00:19:18,138 --> 00:19:22,362
kiosk and harness CD pipelines. But if you want to integrate

296
00:19:22,426 --> 00:19:25,410
kyostep externally,

297
00:19:26,070 --> 00:19:29,522
the APIs are already available which can be used.

298
00:19:29,576 --> 00:19:33,598
So for example, we have integrated it with GitLab.

299
00:19:33,694 --> 00:19:37,560
Here you can see the same step, the deploy step, the ko step, and then

300
00:19:38,330 --> 00:19:42,582
in this case it's failed. So the rollback happened. So similar thing

301
00:19:42,636 --> 00:19:46,326
can be done using GitLab as well. So if you

302
00:19:46,348 --> 00:19:50,742
click here, you can get all the details of this particular step, like the logs

303
00:19:50,886 --> 00:19:54,394
here, you can find out why it's failures and all. So this can also

304
00:19:54,432 --> 00:19:58,106
be done by using the aps that are

305
00:19:58,128 --> 00:20:02,014
available. And one

306
00:20:02,052 --> 00:20:05,806
last thing is if I go

307
00:20:05,828 --> 00:20:07,150
to the pipeline,

308
00:20:09,810 --> 00:20:13,682
in this case, whatever I showed, I am able

309
00:20:13,736 --> 00:20:16,798
to trigger the pipeline manually.

310
00:20:16,974 --> 00:20:19,940
But this can also be done,

311
00:20:20,470 --> 00:20:24,254
it can be triggered automatically based upon

312
00:20:24,302 --> 00:20:27,746
some webhook, based upon some continuous that can

313
00:20:27,768 --> 00:20:31,414
be done using the webhooks. So here you can see it

314
00:20:31,452 --> 00:20:34,914
got triggered by one such webhook, that is card service deploy

315
00:20:34,962 --> 00:20:39,110
changes. So in this case, in case there is some changes in the deployment,

316
00:20:39,270 --> 00:20:42,650
the pipeline will automatically get triggered and you can see

317
00:20:42,800 --> 00:20:46,682
the details execution. So in this case it got

318
00:20:46,736 --> 00:20:51,194
passed. Instead of manual intervention,

319
00:20:51,242 --> 00:20:54,122
it can also be triggered using the webhooks.

320
00:20:54,266 --> 00:20:55,760
So yeah,

321
00:20:58,130 --> 00:21:01,920
that's how you can integrate chaos as a CD step.

322
00:21:02,930 --> 00:21:06,814
As a CD pipelines step. And I hope we have

323
00:21:06,852 --> 00:21:10,814
convinced you enough to add one more chaos step

324
00:21:10,852 --> 00:21:14,640
into your pipelines and ensure the continuous resilience of your application.

325
00:21:15,290 --> 00:21:19,286
And with this, I would like to thank you for

326
00:21:19,388 --> 00:21:20,420
watching us till the end.

