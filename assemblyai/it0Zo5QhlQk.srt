1
00:00:27,650 --> 00:00:30,918
Hello everyone, my name is Mitrivinik and I'm a developer advocate on the

2
00:00:30,924 --> 00:00:34,386
Facebook open source team. Today we'll talk about concurrency in Java,

3
00:00:34,418 --> 00:00:37,746
and I'll try to use some of the Facebook open source projects in Android

4
00:00:37,778 --> 00:00:41,266
space to showcase lessons that we will learn today in this talk. So let's

5
00:00:41,298 --> 00:00:44,754
get started. Thank you everyone for joining. As I mentioned, my name is Mitrivinik.

6
00:00:44,802 --> 00:00:48,546
You can read all my other content on my Twitter account, Dmitry Vinnik,

7
00:00:48,578 --> 00:00:52,030
and on my website that depth. So without further ado, let's get started.

8
00:00:52,100 --> 00:00:55,326
What are our goals for today? The goals are fairly straightforward. We'll talk about

9
00:00:55,348 --> 00:00:58,682
concurrency in its forms. We'll discuss misconceptions in concurrency

10
00:00:58,746 --> 00:01:02,382
and also workflows, how and why they used in Java. So the

11
00:01:02,436 --> 00:01:05,966
big question to ask is why concurrency? Why do we even need

12
00:01:05,988 --> 00:01:09,650
to talk about it? Motivations are fairly straightforward, I'm sure you've heard of them.

13
00:01:09,720 --> 00:01:12,706
It's the fact that we all have multi core machines these days,

14
00:01:12,808 --> 00:01:16,814
the abundance of microservices, it's been around for ages

15
00:01:16,862 --> 00:01:20,258
now. And also the cloud computing services like AWS,

16
00:01:20,354 --> 00:01:24,262
Azure and Google Cloud. So all those services obviously provide you with

17
00:01:24,316 --> 00:01:27,798
as many resources as you'd like, and the concurrency just goes along with it so

18
00:01:27,804 --> 00:01:31,562
you can utilize more. So what's the conclusion know after me bringing up those

19
00:01:31,696 --> 00:01:34,182
motivation factors? So the conclusion is fairly straightforward.

20
00:01:34,246 --> 00:01:37,462
Concurrency is a new reality. Concurrency is the reality.

21
00:01:37,526 --> 00:01:40,378
It's not something you have to adopt anymore, it's already here.

22
00:01:40,464 --> 00:01:44,350
So what's in it for us though? Yes, it's great that the world is ready

23
00:01:44,420 --> 00:01:48,730
and that's how people operate. But why would you need to adopt concurrency?

24
00:01:48,810 --> 00:01:52,126
And the benefits again, just three of them that I'd like to mention. The fact

25
00:01:52,148 --> 00:01:55,846
that there is no idling of resources, the fact that you have multicore

26
00:01:55,898 --> 00:01:59,982
machines but you don't use those resources is kind of wasteful. It improves

27
00:02:00,126 --> 00:02:03,694
user experience. You don't have those freezing

28
00:02:03,742 --> 00:02:07,522
threats, the frozen UI while you're waiting on something to load. You can't ever

29
00:02:07,576 --> 00:02:10,662
close the pop up, you don't want to have that. That's why we have different

30
00:02:10,716 --> 00:02:14,342
threads running in parallel. And the fact that it really forces you to think about

31
00:02:14,396 --> 00:02:18,034
abstractions, because as long as you have a fairly safe abstractions

32
00:02:18,082 --> 00:02:21,646
in your code, you can actually utilize multithreading fairly easily.

33
00:02:21,698 --> 00:02:25,866
But unfortunately it's not just good parts when it comes to concurrency, otherwise there

34
00:02:25,888 --> 00:02:29,526
wouldn't be a need for this talk whatsoever. There are complexities. The fact that thread

35
00:02:29,558 --> 00:02:33,690
safety has to be considered, the race conditions the liveness.

36
00:02:33,850 --> 00:02:37,054
When do you remove the thread from the pool? When do you

37
00:02:37,092 --> 00:02:40,862
reuse it? Performance it's not just a gives add another

38
00:02:40,916 --> 00:02:44,414
thread to your machine and your service and have an improvement two

39
00:02:44,452 --> 00:02:47,726
x or ten x just by adding a couple of threads. It doesn't

40
00:02:47,758 --> 00:02:51,774
work like that. And also really you have to consider about other stages

41
00:02:51,822 --> 00:02:54,830
of software development lifecycle. How do you test concurrency?

42
00:02:54,910 --> 00:02:58,034
That's a big issue of its own, but even though it's complex,

43
00:02:58,162 --> 00:03:01,974
it's actually beneficial. As I mentioned, the motivations and

44
00:03:02,012 --> 00:03:05,702
benefits, and I would even call it beautiful. Concurrency is beautiful.

45
00:03:05,836 --> 00:03:09,398
It reminds me of the fact that concurrency very much like

46
00:03:09,484 --> 00:03:12,774
sharks. When we hear about sharks, we worry about them,

47
00:03:12,812 --> 00:03:16,282
how dangerous they are, but really it's the fact that we don't really know about

48
00:03:16,336 --> 00:03:19,674
them well enough. The same goes for concurrency. As long as you're not aware of

49
00:03:19,712 --> 00:03:23,562
how to use it, how it can improve your workflow. Try to avoid,

50
00:03:23,706 --> 00:03:27,114
you know, concurrency in sharks when I've read the Brian Goitz

51
00:03:27,162 --> 00:03:30,462
Java concurrency in practice, at first it know

52
00:03:30,596 --> 00:03:34,046
scary to me, it's so complex. But as I was reading more and more,

53
00:03:34,068 --> 00:03:38,186
I realized that concurrency is extremely useful and the book

54
00:03:38,228 --> 00:03:41,822
again made an impression on me. The same goes for this book by Jean Marie

55
00:03:41,886 --> 00:03:45,378
the Chark Fear and beauty these same kind of concept there. I would want to

56
00:03:45,464 --> 00:03:48,622
try to use this talk for you to remove these fear in

57
00:03:48,696 --> 00:03:51,670
avoiding concurrency and begin to admire it like I did.

58
00:03:51,740 --> 00:03:55,206
And this journey from fear to admiration is what

59
00:03:55,228 --> 00:03:59,286
will create our agenda. We'll begin by talking about single threading in

60
00:03:59,308 --> 00:04:02,378
Java. Then we'll discuss multi threads concurrency in

61
00:04:02,384 --> 00:04:05,654
Java, and ultimately we'll finish by discussing workflows.

62
00:04:05,702 --> 00:04:08,662
But as I mentioned, we'll begin by talking about single threads.

63
00:04:08,726 --> 00:04:11,626
So another important question to ask do I even care?

64
00:04:11,728 --> 00:04:15,706
I've given you a couple of motivation factors benefits also complexities.

65
00:04:15,818 --> 00:04:19,546
Still, I might have not convinced you right. You might be asking yourself or telling

66
00:04:19,578 --> 00:04:23,306
yourself that my app is single threaded. I don't even need to make it more

67
00:04:23,428 --> 00:04:27,086
performant. It might be too complex to think about concurrency.

68
00:04:27,198 --> 00:04:31,182
And that's why, regardless of whether you'd like to adopt concurrency

69
00:04:31,246 --> 00:04:35,106
itself, I always push people to consider implementing design for

70
00:04:35,128 --> 00:04:38,622
concurrency. It's the fact that you stop programming by coincidence.

71
00:04:38,766 --> 00:04:42,262
You don't just write software and assume it will work. You design

72
00:04:42,316 --> 00:04:45,446
by contract. You know what to expect from your code. You try to

73
00:04:45,468 --> 00:04:48,866
avoid temporal coupling, which is basically when depending

74
00:04:48,898 --> 00:04:52,218
on these order of operations, you actually modify the state of

75
00:04:52,224 --> 00:04:55,382
the object. Imagine that you use the HTTP request

76
00:04:55,446 --> 00:04:59,114
and depending on whether you've made a post or get call

77
00:04:59,152 --> 00:05:02,698
on it, you would expect the response to be inside of the object.

78
00:05:02,784 --> 00:05:06,558
That's a good example of what temporary coupling is. So you need to really

79
00:05:06,644 --> 00:05:09,838
work on making it immutable and atomic as possible.

80
00:05:09,924 --> 00:05:13,354
So, meaning regardless of how many threads interact with it, one thread

81
00:05:13,402 --> 00:05:17,026
can change the object for another thread, it will use its own copy or

82
00:05:17,048 --> 00:05:20,818
utilize other techniques again to sync for concurrency first.

83
00:05:20,904 --> 00:05:24,402
And that's where I'd like to talk about multithreading a bit more.

84
00:05:24,456 --> 00:05:28,326
And just regardless of Java, you use something else. It's just the

85
00:05:28,348 --> 00:05:32,226
conceptual idea of multithreading. So multithreading, what forms

86
00:05:32,258 --> 00:05:35,602
can it take? There are so many different ideas and forms,

87
00:05:35,666 --> 00:05:39,814
and that's why I'd like to discuss concurrency form, parallel form, and asynchronous

88
00:05:39,862 --> 00:05:43,514
forms. And again, I'll begin with the most commonly used

89
00:05:43,552 --> 00:05:47,126
concurrent form. So concurrent form implies that it's working with multiple

90
00:05:47,158 --> 00:05:50,342
tasks, but it doesn't physically require multiple cores,

91
00:05:50,406 --> 00:05:53,886
but at the same time it's logically simultaneous tasks. What it

92
00:05:53,908 --> 00:05:57,146
means is that if you had an old machine and you didn't have multiple cores

93
00:05:57,178 --> 00:06:00,798
like my Mac laptop would, you would have a

94
00:06:00,804 --> 00:06:04,826
perception that tasks completed parallel from one another. But in reality it's

95
00:06:04,858 --> 00:06:08,658
actually just switch resources around. So is it too abstract? It might be

96
00:06:08,664 --> 00:06:12,338
too abstract. Just to see the diagram. I'd like to just show you some example.

97
00:06:12,504 --> 00:06:16,206
And I like to try to think of developing

98
00:06:16,238 --> 00:06:18,998
an app. And what do you need to develop an app? You need coffee and

99
00:06:19,004 --> 00:06:22,726
you need the laptop, right? And so when it comes to that, imagine you have

100
00:06:22,748 --> 00:06:26,118
a single thread, a person named John, and John just

101
00:06:26,204 --> 00:06:30,006
needs to code and drink coffee. Code and drink coffee. And even

102
00:06:30,028 --> 00:06:33,334
though it's just a single person, he ultimately completed two tasks.

103
00:06:33,382 --> 00:06:36,906
So two simultaneous tasks. He drank his cup of coffee, but he

104
00:06:36,928 --> 00:06:40,982
also completed the app. So it seemed like it's simultaneous. Logically simultaneous

105
00:06:41,046 --> 00:06:44,398
tasks, but there's only one genre, right? So he had to use

106
00:06:44,484 --> 00:06:48,622
his resources and switch it around. So ultimately he finished two tasks. Parallel form

107
00:06:48,676 --> 00:06:52,282
is a bit more complex. What it means is that it still have multiple

108
00:06:52,346 --> 00:06:55,890
tasks, multiple subtasks, some people think of it.

109
00:06:55,960 --> 00:06:59,646
In other words, imagine you have a complex mathematical

110
00:06:59,838 --> 00:07:03,950
algorithm running, and so what you do, you split it in multiple subtasks

111
00:07:04,030 --> 00:07:07,526
that ultimately do their own part of the equation. Then they come together

112
00:07:07,628 --> 00:07:10,646
and do the summation, or do the

113
00:07:10,668 --> 00:07:15,186
addition, do subtraction, whatever necessary. It's physically simultaneous.

114
00:07:15,218 --> 00:07:18,710
So it does require multiple cpus, which again we have enough

115
00:07:18,780 --> 00:07:22,762
these days for the most part, let's try to apply it. Developing an app.

116
00:07:22,816 --> 00:07:26,634
And here we actually have Jenny. And Jenny, she's not just

117
00:07:26,672 --> 00:07:30,218
a single person, you can things of it, she's ambidextrous, she has

118
00:07:30,304 --> 00:07:33,130
ability to use both hands at the same time.

119
00:07:33,200 --> 00:07:36,730
So in things case you can think of Jenny as two people, two threads,

120
00:07:36,810 --> 00:07:39,722
because using one hand she can keep drinking coffee,

121
00:07:39,786 --> 00:07:43,754
finishing that one task, but with another she can just keep coding. So you ultimately

122
00:07:43,802 --> 00:07:47,298
have this physically simultaneous process, completing two

123
00:07:47,384 --> 00:07:51,134
subtasks and ultimately having an app. And it brings us to asynchronous

124
00:07:51,182 --> 00:07:55,026
formers of multithreading. So when it comes to asynchronous, it's really an

125
00:07:55,048 --> 00:07:58,726
idea of fire and forget. It's non blocking tasks and

126
00:07:58,748 --> 00:08:02,742
they do require multiple of, you know, you go to withdraw money

127
00:08:02,796 --> 00:08:06,578
from ATM and while your main operation is to withdraw

128
00:08:06,594 --> 00:08:10,374
the money asynchronously, it might fire a logging

129
00:08:10,422 --> 00:08:14,550
operation somewhere. So the people who manage ATM

130
00:08:14,630 --> 00:08:18,006
know that the transaction happened of some sort, some metadata.

131
00:08:18,038 --> 00:08:21,450
Right. And that separate task that doesn't affect the main

132
00:08:21,520 --> 00:08:25,246
process of withdrawing the money has been triggered. And that's where asynchronous come

133
00:08:25,268 --> 00:08:29,054
and play. It's fire and forget. So let's think again. Developing an app, we have

134
00:08:29,092 --> 00:08:32,606
coffee, we have laptop, but the big question to ask is, where did

135
00:08:32,628 --> 00:08:35,826
the coffee come from? Right? Who does that? Who makes it for you?

136
00:08:35,928 --> 00:08:40,030
And this is where coffee machine or our great friend Henry

137
00:08:40,110 --> 00:08:43,486
comes into play. And Henry is so amazing, he just keeps

138
00:08:43,518 --> 00:08:46,834
bringing you coffee while you work on your app. In this

139
00:08:46,872 --> 00:08:50,562
case, John is the person who's not an ambidexter developer.

140
00:08:50,626 --> 00:08:54,694
He develops an app, but also drinking coffee at the same time. Parallel to

141
00:08:54,732 --> 00:08:58,598
his work, Henry just keeps making coffee, bringing it over without

142
00:08:58,684 --> 00:09:02,250
actually stopping John. So it's been quite abstract so far.

143
00:09:02,320 --> 00:09:05,478
Let's actually look at concurrency in Java. So without further ado,

144
00:09:05,574 --> 00:09:08,874
let's get started with concurrency in Java in particular.

145
00:09:08,992 --> 00:09:12,446
First there were runnable and threads. That's probably where most of

146
00:09:12,468 --> 00:09:16,010
the concern, avoidance of concurrency

147
00:09:16,090 --> 00:09:20,458
happened for majority of beginner Java developers or even senior Java developers.

148
00:09:20,554 --> 00:09:24,758
And so when it comes to runnable and threads, these didn't take any input,

149
00:09:24,874 --> 00:09:27,726
they didn't produce any output, and they gave you no exceptions.

150
00:09:27,918 --> 00:09:31,826
An example I have here some pseudocode where you have a

151
00:09:31,848 --> 00:09:35,182
process of drinking coffee. It's a simple run operation

152
00:09:35,246 --> 00:09:38,674
that you have to override and implement in one way or another.

153
00:09:38,792 --> 00:09:42,626
But really when you trigger it, you have very little control over runnable

154
00:09:42,658 --> 00:09:46,498
itself. I'll give you a quick demo with fresco to just showcase runnable and threads

155
00:09:46,514 --> 00:09:50,438
and how they're used. Fresco is a great image management library on Android.

156
00:09:50,534 --> 00:09:53,814
Imagine you're on a slow network and you can't

157
00:09:53,862 --> 00:09:57,146
show image completely in a high resolution right away.

158
00:09:57,248 --> 00:10:00,838
And so what Fresco would do is it will show a placeholder

159
00:10:00,934 --> 00:10:04,846
and slowly improve the quality of the image, will handle caching and

160
00:10:04,868 --> 00:10:07,966
other complex things for you. That's what fresco is. And to use

161
00:10:07,988 --> 00:10:12,414
fresco, it's fairly straightforward. You would gave to add

162
00:10:12,452 --> 00:10:15,630
a create functionality, you initialize the fresco,

163
00:10:15,790 --> 00:10:19,474
then you cold add to your layout a simple

164
00:10:19,672 --> 00:10:23,218
drawy view as an example. And then what

165
00:10:23,224 --> 00:10:26,802
you would do is that you will just show the image fairly straightforward, but then

166
00:10:26,856 --> 00:10:30,962
it will actually handle caching. As I mentioned, a placeholder

167
00:10:31,026 --> 00:10:34,806
image for you. So now let's take a look at small example of runnable and

168
00:10:34,828 --> 00:10:38,578
threads with fresco. Imagine if I had a simple adapter

169
00:10:38,754 --> 00:10:42,474
for fresco image handling. I cold use something called run on

170
00:10:42,512 --> 00:10:45,782
UI threads that's common to activities in Android

171
00:10:45,846 --> 00:10:49,306
and I would supply runnable to it and will handle in the run

172
00:10:49,408 --> 00:10:52,910
refreshment of the UI whenever data on the screen would change.

173
00:10:52,980 --> 00:10:56,990
That's what runnable are and they still heavily used even today.

174
00:10:57,060 --> 00:11:00,442
While concurrency, as I will show in this talk, has improved

175
00:11:00,506 --> 00:11:04,838
significantly in the past couple of years, so fortunately, after threads

176
00:11:04,874 --> 00:11:08,974
and runnable, GDK five was released and GDK five introduced concurrency

177
00:11:09,102 --> 00:11:12,450
API, concurrency API had multiple

178
00:11:12,950 --> 00:11:16,706
ways to improve your experience, developer experience when

179
00:11:16,728 --> 00:11:20,438
it comes to concurrency. One of the big additions were thread local

180
00:11:20,524 --> 00:11:23,814
atomic operations, thread safe collections, and a lot more other

181
00:11:23,852 --> 00:11:27,190
things. So let's take a look at thread local. What the heck that is.

182
00:11:27,260 --> 00:11:30,598
Thread local is a great way to confine resources.

183
00:11:30,694 --> 00:11:34,618
It allows you to request or initialize different

184
00:11:34,704 --> 00:11:38,474
instance of the source of a resource, like for instance simple date

185
00:11:38,512 --> 00:11:42,246
formatter, depending on the threads that access the thread local. That being

186
00:11:42,288 --> 00:11:45,802
said, it still doesn't come for free. There are some opportunities

187
00:11:45,946 --> 00:11:49,626
for memory leaks and the fact that you should be still avoiding global

188
00:11:49,658 --> 00:11:53,214
fields like thread locals that really kind of

189
00:11:53,332 --> 00:11:57,186
allow you to do that. Atomic operations are also great addition to

190
00:11:57,208 --> 00:12:00,734
the concurrency. What it does is it helps you with compound

191
00:12:00,782 --> 00:12:04,610
operations, the inline incrementation that you might have seen before,

192
00:12:04,680 --> 00:12:08,326
especially with for loops like I plus plus, it's actually a

193
00:12:08,348 --> 00:12:11,670
compound operation in the parallel flow,

194
00:12:12,410 --> 00:12:15,734
it would have to retrieve a value, add another value and add

195
00:12:15,772 --> 00:12:19,382
them up. It's three different operations together and if you were just to

196
00:12:19,436 --> 00:12:22,874
plainly access and do those kind of addition, it will lead you

197
00:12:22,912 --> 00:12:26,182
to potentially having race condition there. That's why atomic operation

198
00:12:26,246 --> 00:12:29,866
are great for that. They will make sure that incrementation, subtraction or

199
00:12:29,888 --> 00:12:33,706
even more complex atomic reference to a website. An example that

200
00:12:33,728 --> 00:12:37,038
I have here will be handled for you, so it allows you to have a

201
00:12:37,044 --> 00:12:40,654
speed and also it gave compare and swap operation that handled for

202
00:12:40,692 --> 00:12:43,998
you in the background and threads collections with collections

203
00:12:44,014 --> 00:12:47,918
in general, adding values to it and retrieving values

204
00:12:47,934 --> 00:12:51,810
from the collection are complex for different threads. That's why

205
00:12:51,880 --> 00:12:55,874
with threads safe collections like concurrent hashmap, you have again a

206
00:12:55,912 --> 00:12:59,846
great handle on compound operations. Getting a value, changing it

207
00:12:59,868 --> 00:13:02,898
and then putting it back in the collection. It's not that straightforward.

208
00:13:02,994 --> 00:13:06,546
And here you have a configurable concurrency in action.

209
00:13:06,658 --> 00:13:10,326
You can control how big the collection can be, the density number of

210
00:13:10,348 --> 00:13:13,798
threads that you think might be accessing this collection. And you don't

211
00:13:13,814 --> 00:13:17,526
have to create this synchronized block that really just blocks

212
00:13:17,558 --> 00:13:21,498
your threads and you lose so much when it comes to concurrency. That's why

213
00:13:21,584 --> 00:13:25,022
just plainly using this collection saves you so much time.

214
00:13:25,076 --> 00:13:28,714
And I'll give you a quick demo with Spectrum, another Facebook open source

215
00:13:28,762 --> 00:13:31,918
project. Just showcase how one of these collections can be used.

216
00:13:32,004 --> 00:13:35,562
Spectrum is another open source library from Facebook that focuses

217
00:13:35,626 --> 00:13:39,006
on Android and actually other platforms as well. But in this example I'll

218
00:13:39,038 --> 00:13:42,382
use spectrum for Android. What spectrum does is it handles

219
00:13:42,446 --> 00:13:46,130
transcoding of images for you. In other words, it will handle

220
00:13:46,790 --> 00:13:50,614
in this scenario complex image uploads for you, making sure

221
00:13:50,652 --> 00:13:53,926
that resolution is actually kept as high as possible with

222
00:13:53,948 --> 00:13:57,206
a small size as possible. So to use spectrum you

223
00:13:57,228 --> 00:14:01,740
would have to simply add initializer to oncreate function

224
00:14:02,110 --> 00:14:05,418
and then you cold have to specify what kind of plugins you will use.

225
00:14:05,504 --> 00:14:09,254
Basically what images. In this example you will use like GPEG,

226
00:14:09,302 --> 00:14:13,166
PNG, et cetera. And in our case if you

227
00:14:13,188 --> 00:14:16,858
wanted to use it you would just invoke spectrum to transcode

228
00:14:16,954 --> 00:14:20,298
input file output and then produce output stream,

229
00:14:20,394 --> 00:14:23,774
specify GPaC as output and

230
00:14:23,812 --> 00:14:27,314
so on. So you will see documentation for spectrum is quite extensive and

231
00:14:27,352 --> 00:14:31,166
I cold say great, but if I were to apply concurrency API

232
00:14:31,278 --> 00:14:34,980
for spectrum, you would see that I would return

233
00:14:35,610 --> 00:14:38,898
concurrent hash map that I showed in my slides.

234
00:14:38,994 --> 00:14:43,058
I would have imagine I wanted to process duplicate images,

235
00:14:43,154 --> 00:14:46,806
but I don't want to just upload photos to my

236
00:14:46,908 --> 00:14:50,358
app. Instead I want to just have a

237
00:14:50,364 --> 00:14:54,090
quick lookup on my map. But because I have a concurrent application

238
00:14:54,240 --> 00:14:57,226
I want to make sure I don't have a race condition and the only thing

239
00:14:57,248 --> 00:15:01,494
I would have to do is my already initialized transcoded images map.

240
00:15:01,542 --> 00:15:04,890
I would look up by name or an id for the image,

241
00:15:04,970 --> 00:15:08,666
and if it's not there yet, I'll add it to the list. Otherwise I'll

242
00:15:08,698 --> 00:15:12,478
just retrieve it and use for my purposes. So again,

243
00:15:12,564 --> 00:15:16,046
quick look at what concurrent hashmap

244
00:15:16,078 --> 00:15:19,762
can do for you. So we talked about concurrency really briefly. I'd like to

245
00:15:19,816 --> 00:15:23,502
now jump into workflows and not just workflows in Java.

246
00:15:23,566 --> 00:15:26,626
And that's where a big question to ask where do we start when we

247
00:15:26,648 --> 00:15:30,050
talk about workflows? And it's important to start at other languages,

248
00:15:30,130 --> 00:15:33,830
at other implementations of that. Promises in Javascript might have been

249
00:15:33,900 --> 00:15:37,346
the first time I myself personally heard of workflows. And we'll

250
00:15:37,378 --> 00:15:40,658
talk at future and callable executive framework and it will bring

251
00:15:40,684 --> 00:15:44,518
us to completeable future. So promises in Javascript you don't

252
00:15:44,534 --> 00:15:47,782
have to think long for how to scare a web developer.

253
00:15:47,846 --> 00:15:51,398
You just have to bring up the callback hell that people had to encounter.

254
00:15:51,494 --> 00:15:54,926
When you call an operation, then you wait for it to complete, then you have

255
00:15:54,948 --> 00:15:58,394
to handle on success, on failure, try to even catch exceptions.

256
00:15:58,442 --> 00:16:01,854
It's been really complicated in the past. Fortunately with creation of

257
00:16:01,892 --> 00:16:04,858
promises now, it's very much like chaining of operation.

258
00:16:04,954 --> 00:16:08,466
You call a task, you call an operation, and then depending on how it

259
00:16:08,488 --> 00:16:12,670
works, you either handle success or a failure, or ultimately

260
00:16:12,750 --> 00:16:16,638
an exception. And as you can see in this example on the screen things pseudocode,

261
00:16:16,734 --> 00:16:20,262
you can see how much shorter and actually maintainable this code

262
00:16:20,316 --> 00:16:24,022
becomes when it comes to Java. Future and callable are very important.

263
00:16:24,156 --> 00:16:27,974
What runnable is for a threads. Basically this powerhorse, these thing

264
00:16:28,012 --> 00:16:30,986
that does the work. Callable is what does work for future.

265
00:16:31,088 --> 00:16:35,046
Callable is really a big improvement. Step forward from runnables.

266
00:16:35,158 --> 00:16:38,586
It doesn't still take any input, but it produces an output and

267
00:16:38,608 --> 00:16:42,458
has an exception that you have to handle. In this example, imagine that you have

268
00:16:42,464 --> 00:16:45,886
a process that sometime in the future someone has to fix a bug. That's what

269
00:16:45,908 --> 00:16:49,114
filing a bug is, right? You expect it to be fixed ideally.

270
00:16:49,162 --> 00:16:52,986
So imagine you have to override a call operation.

271
00:16:53,098 --> 00:16:56,610
It will throw an exception, someone will fix a bug, and then depending on success

272
00:16:56,680 --> 00:17:00,466
or failure, you will handle it appropriately, but also you

273
00:17:00,488 --> 00:17:03,486
have to handle an exception. But the future, again, it's similar to threads,

274
00:17:03,518 --> 00:17:06,498
but using callables. It's something that's completed in the future.

275
00:17:06,584 --> 00:17:10,034
That's what the name comes from. Executive framework is what it relies

276
00:17:10,082 --> 00:17:13,718
on, and I'll talk in depth about what executive framework is in the

277
00:17:13,724 --> 00:17:17,186
later slides. So executive service, just imagine that it's

278
00:17:17,218 --> 00:17:20,534
a thing that we are aware of. You have an operation completed to

279
00:17:20,572 --> 00:17:24,090
do. We have plenty of to dos in our code base, so we have something

280
00:17:24,160 --> 00:17:27,446
that someone will fix in the future. So you have a completed

281
00:17:27,478 --> 00:17:31,078
to do written and then you have a future that you invoke

282
00:17:31,174 --> 00:17:34,926
on these executor service and you say code to be written and

283
00:17:34,948 --> 00:17:38,042
you wait for that code to be written. That's what future will produce.

284
00:17:38,106 --> 00:17:41,950
Actual code as you can see in this pseudocode future sounds great though,

285
00:17:42,020 --> 00:17:45,854
but how do we use it? That's where executive framework is essential.

286
00:17:45,982 --> 00:17:49,502
Executive framework really helps with things like threads management

287
00:17:49,566 --> 00:17:52,994
and implements this declarative model. Things that you don't have to

288
00:17:53,032 --> 00:17:56,690
think about how something works, but it just works. So you focus

289
00:17:56,760 --> 00:18:00,214
on the task that you're trying to complete, rather than focusing on how

290
00:18:00,252 --> 00:18:03,954
that task is done. That's these executive framework. What these executive framework

291
00:18:04,002 --> 00:18:07,586
does for you, it handles that threat management for you. It really relies

292
00:18:07,618 --> 00:18:11,046
on these threads pool. That's what behind the scene executive framework is

293
00:18:11,068 --> 00:18:14,726
all about. Threads pool is really what does the threads management

294
00:18:14,838 --> 00:18:18,250
and threads configuration. Here is an example of actual

295
00:18:18,320 --> 00:18:21,706
constructor that thread pool executor looks like in

296
00:18:21,728 --> 00:18:25,226
the Java itself. It has so many arguments

297
00:18:25,258 --> 00:18:28,478
and you wouldn't want to initialize it on your own unless you're building a custom

298
00:18:28,564 --> 00:18:31,742
executor framework. Executor service. That's why

299
00:18:31,876 --> 00:18:35,422
regardless of that many arguments, we have factories. And factories

300
00:18:35,486 --> 00:18:39,314
are amazing. I can't talk about executor service without talking

301
00:18:39,352 --> 00:18:42,914
about factories. Executor factories, there are plenty of them.

302
00:18:42,952 --> 00:18:46,222
There's a single thread pool, great for just experiments.

303
00:18:46,286 --> 00:18:50,038
Cached thread pool, something that you would use for small operations like

304
00:18:50,124 --> 00:18:53,794
you're trying to crawl. Web page you have multiple threads that scroll

305
00:18:53,842 --> 00:18:56,806
different pages. That's where cache thread pool will come into play.

306
00:18:56,908 --> 00:19:00,598
Thick thread pool, you know exactly how many threads you'd like to utilize.

307
00:19:00,694 --> 00:19:04,534
It's great for some, again, complex and resource heavy mathematical

308
00:19:04,582 --> 00:19:08,198
calculations. Scheduled threat pool, think of it like Kronos

309
00:19:08,294 --> 00:19:12,154
or just constantly monitoring service that you might like to trigger and work.

310
00:19:12,192 --> 00:19:15,358
Stealing pool is actually how strings in Java work.

311
00:19:15,444 --> 00:19:19,278
They just throw around resources. Utilize whatever pool already has.

312
00:19:19,364 --> 00:19:22,846
Great thing that you don't really have to worry about too much on your

313
00:19:22,868 --> 00:19:26,274
own. Just rely on the ones that I've just mentioned prior though.

314
00:19:26,312 --> 00:19:29,666
Executor and thread pools. It ultimately produce this thing that

315
00:19:29,688 --> 00:19:32,818
I've mentioned before. Executor service. Executor service

316
00:19:32,904 --> 00:19:36,270
is what allows you to have these asynchronous tasks, these futures,

317
00:19:36,350 --> 00:19:39,558
but ultimately it's threads pools. In this example, as I mentioned before,

318
00:19:39,644 --> 00:19:43,266
you'd like to crawl website. You have a crawler service that relies

319
00:19:43,298 --> 00:19:46,358
on the factory forecast threads, cache, thread pool, have a

320
00:19:46,364 --> 00:19:49,794
list of URLs you'd like to crawl and you just submit

321
00:19:49,842 --> 00:19:53,066
those operations to executor. It launches them as soon as

322
00:19:53,088 --> 00:19:57,014
you invoke submit and you can just collect those future pages and ultimately

323
00:19:57,062 --> 00:20:00,954
wait for them to complete. I'll give you a quick demo with Fresco as

324
00:20:00,992 --> 00:20:04,366
an example of how to use executor service. So let's give it

325
00:20:04,388 --> 00:20:07,386
a go. Another quick look at Fresco and how it can be used with futures

326
00:20:07,418 --> 00:20:10,666
and executable services. In this case, I have an image

327
00:20:10,698 --> 00:20:13,738
pipeline, something that fresco relies quite heavily.

328
00:20:13,834 --> 00:20:17,554
It has a great implementation for something called data sources and its

329
00:20:17,592 --> 00:20:21,154
own executors. The only thing you have to know is it's just

330
00:20:21,192 --> 00:20:25,102
how it handles images. And so if I were to subscribe

331
00:20:25,246 --> 00:20:29,890
to a certain data source, the only thing I would really need is the bitmaps

332
00:20:29,970 --> 00:20:33,766
and executor, in this case color thread executor that

333
00:20:33,788 --> 00:20:37,286
I would retrieve instance of. That's how it's actually used

334
00:20:37,388 --> 00:20:40,822
in fresco. Good production ready example.

335
00:20:40,956 --> 00:20:44,458
The important question to ask are we done? Mean, you know, the title of

336
00:20:44,464 --> 00:20:48,314
this talk is completeable futures. So you can guess we'll talk about something other

337
00:20:48,352 --> 00:20:51,534
than future because it's not perfect. Future pitfalls. Some of them

338
00:20:51,572 --> 00:20:54,858
are blocking operations. There is no result chaining, so it's

339
00:20:54,874 --> 00:20:58,394
not real promises a future combination combining multiple

340
00:20:58,442 --> 00:21:01,866
futures that's running in parallel and exception handling is fairly

341
00:21:01,898 --> 00:21:05,410
complex when dealing with futures themselves. So blocking result

342
00:21:05,480 --> 00:21:09,250
retrieval, what does it mean? So when you call a gap on the future

343
00:21:09,320 --> 00:21:13,326
itself, it blocks the process, right. And you actually have to handle

344
00:21:13,438 --> 00:21:17,166
interrupted exceptions and things of that sort. So there are some ways to handle

345
00:21:17,198 --> 00:21:20,674
it, but ultimately you're losing on a lot of benefits of asynchronous.

346
00:21:20,722 --> 00:21:24,162
And also you have to be careful and always use the timeouts. You don't necessarily

347
00:21:24,226 --> 00:21:27,858
have just a continuous block with no end whatsoever.

348
00:21:27,954 --> 00:21:31,258
That's why you call get with a timeout of some sort. There is no future

349
00:21:31,344 --> 00:21:34,794
chaining. You can't wait for future to complete and just

350
00:21:34,912 --> 00:21:38,474
keep writing like a stream style code. You have to make a

351
00:21:38,512 --> 00:21:42,134
call for it, wait for tasks to complete, and only then handle

352
00:21:42,182 --> 00:21:45,150
it some one way or another. For instance, you have a kanban board,

353
00:21:45,220 --> 00:21:48,286
you have a developer that writes these code, have to wait for that

354
00:21:48,308 --> 00:21:51,454
code to complete and only these you can test it, which kind of makes

355
00:21:51,492 --> 00:21:55,386
sense. But if you will write it as the two separate blocks, it becomes

356
00:21:55,418 --> 00:21:59,186
kind of harder to maintain because you context switch. That's why future chaining are

357
00:21:59,208 --> 00:22:02,626
so important. Exception handling. Another thing I want to just bring up, it is

358
00:22:02,648 --> 00:22:06,238
complex. Multiple exceptions to handle, interrupted exceptions,

359
00:22:06,334 --> 00:22:09,846
executor for exceptions, timeout exceptions. Lots of things when you're

360
00:22:09,868 --> 00:22:13,858
dealing with futures and you gave to handle them completely different depending

361
00:22:13,874 --> 00:22:17,554
on what exception you're dealing with. So there are many issues, but no worries,

362
00:22:17,602 --> 00:22:21,174
right? We have completeable future to help us. That's why this talk is called completeable

363
00:22:21,222 --> 00:22:24,918
future, and that's where we'll discuss that in length.

364
00:22:25,014 --> 00:22:28,282
So, completeable future, it basically gets you everything that future has,

365
00:22:28,336 --> 00:22:31,786
but now has additional interface implementation, which is

366
00:22:31,808 --> 00:22:35,770
completion stage. It allows you to transform, compose, chain, and combine

367
00:22:35,850 --> 00:22:39,338
basically everything that future had issues with. Completeable future allows

368
00:22:39,354 --> 00:22:42,954
you to handle those pitfalls I've mentioned before with future, we're handling

369
00:22:43,002 --> 00:22:46,674
them with completeable future transformation and chaining. It allows you to have

370
00:22:46,712 --> 00:22:50,546
workflows. It relies on something called fork joint pool that I

371
00:22:50,568 --> 00:22:53,842
brought up earlier really briefly, but basically the way you write it,

372
00:22:53,896 --> 00:22:57,154
you can supply a sync, basically retrigger a operation like

373
00:22:57,192 --> 00:23:00,966
developer wants coffee, so a person has to brew it while that

374
00:23:00,988 --> 00:23:04,678
being is happening. Developer can just keep doing their thing so it doesn't have

375
00:23:04,684 --> 00:23:08,054
to stop the person from working while that's happening. As soon as

376
00:23:08,092 --> 00:23:11,706
coffee is done, you can invoke, then apply, basically drink the coffee when

377
00:23:11,728 --> 00:23:15,578
it's ready. That's done. You can have more complex operations like

378
00:23:15,744 --> 00:23:18,838
you can have a separate pool just to handle that operation.

379
00:23:18,934 --> 00:23:22,454
But it's just for folks who have a more intense concurrency

380
00:23:22,502 --> 00:23:25,754
that models in place. Controllable futures

381
00:23:25,802 --> 00:23:29,406
you can now control when the operation is done. So in this case you can

382
00:23:29,428 --> 00:23:33,406
control when these future is completed. If it's not yet done, you can say give

383
00:23:33,428 --> 00:23:37,550
me whatever and specify default value, or you can forcefully complete

384
00:23:37,620 --> 00:23:40,914
it through another thread even if you'd like. In this case, I complete

385
00:23:41,032 --> 00:23:44,642
latte making, which is give me an espresso, give me whatever you've done so far.

386
00:23:44,696 --> 00:23:47,970
If you're not yet done, and I'll take that and I'll go with that,

387
00:23:48,040 --> 00:23:51,334
you can have multiple futures controlled, right? You have all off

388
00:23:51,372 --> 00:23:54,502
or any off operation with completeable future here.

389
00:23:54,556 --> 00:23:58,166
It's perfect for. Let's say you try and run a web driver test for

390
00:23:58,188 --> 00:24:01,446
multiple browsers, Firefox, Chrome and ie, and the only thing

391
00:24:01,468 --> 00:24:05,126
you really have to invoke is all off and just run those asynchronous threads

392
00:24:05,158 --> 00:24:08,586
in whatever way, shape or form you'd like. And then just wait for

393
00:24:08,608 --> 00:24:12,234
those to be done. You can see how many processes are still working.

394
00:24:12,352 --> 00:24:15,630
You can control them even more fine grain if you'd like,

395
00:24:15,700 --> 00:24:19,374
but just amount of control it gives you is outstanding. You can also

396
00:24:19,412 --> 00:24:22,686
combine your tasks, right? You can collect your results. You can run them

397
00:24:22,708 --> 00:24:26,270
either synchronously or synchronously. Imagine you have two teams asking

398
00:24:26,340 --> 00:24:29,634
you for APIs before you work on it. You don't want to just

399
00:24:29,672 --> 00:24:33,442
rush. You want to make sure you have these requests properly filed and only

400
00:24:33,496 --> 00:24:36,962
then you will put them on your kanban board or whatever you use. And so

401
00:24:37,016 --> 00:24:40,994
you'll wait for those teams to complete these operations, which is filing

402
00:24:41,042 --> 00:24:45,062
those requests and only these, you'll begin working on them. That's where then

403
00:24:45,116 --> 00:24:48,542
combined operation come into place. It's just that powerful

404
00:24:48,626 --> 00:24:52,278
but also exception handling. As I mentioned being very complex

405
00:24:52,374 --> 00:24:56,198
with futures. Here you have a very much try catch

406
00:24:56,294 --> 00:24:59,690
finally flow but using completeable future. In this case,

407
00:24:59,760 --> 00:25:03,546
if an exception is thrown, you have exceptionally call to make and

408
00:25:03,568 --> 00:25:07,054
this is these if exception happened, it will go there, handle it

409
00:25:07,092 --> 00:25:10,794
whatever way you want. You can fail it completely, you can propagate the exception,

410
00:25:10,842 --> 00:25:15,214
you can just return some value or you can handle it. It's finally basically

411
00:25:15,332 --> 00:25:18,594
in that case, if the exception happened, it will go on its own if

412
00:25:18,632 --> 00:25:21,938
statement. If not, you can proceed in whatever shape form

413
00:25:22,024 --> 00:25:25,566
you'd like. Great. The paradigm that you don't have to switch

414
00:25:25,598 --> 00:25:29,158
from your regular coding, non concurrent coding with a completeable future.

415
00:25:29,244 --> 00:25:32,850
Just outstanding. And to give you a quick demo, I'll use Litho,

416
00:25:32,930 --> 00:25:36,914
another open source project from Facebook to showcase completeable future really briefly.

417
00:25:36,962 --> 00:25:40,842
So another example of Facebook open source library that I'll like to showcase really

418
00:25:40,896 --> 00:25:44,374
quickly is Litho. Litho is a great declarative framework

419
00:25:44,422 --> 00:25:47,674
for UI and Android. What it does is helps you to

420
00:25:47,792 --> 00:25:51,750
easily and quickly create uis for Android applications.

421
00:25:51,830 --> 00:25:55,374
In this example, the only thing you would need to do to have lethal working

422
00:25:55,412 --> 00:25:59,598
for you, you would need to initialize as so loader and then

423
00:25:59,764 --> 00:26:02,974
you would have components. It's heavily inspired by

424
00:26:03,012 --> 00:26:06,434
react. As you can guess, that's where components come from. And in this

425
00:26:06,472 --> 00:26:10,290
case I just show you how text component might

426
00:26:10,440 --> 00:26:14,094
show up on the UI for Android. We have a great tutorial

427
00:26:14,142 --> 00:26:18,374
on the Litho website as well, fblisso.com and

428
00:26:18,412 --> 00:26:22,546
so to give you an example of how it's used with completeable future, how Litho

429
00:26:22,578 --> 00:26:25,558
can utilize completeable futures. Imagine that I,

430
00:26:25,644 --> 00:26:29,574
for some reason, whatever reason might be want to randomly change the

431
00:26:29,612 --> 00:26:32,634
text on the component and so what I would do is that I would

432
00:26:32,672 --> 00:26:36,566
use completeable future run async, which basically triggers

433
00:26:36,598 --> 00:26:41,030
operation that I don't care for. Result really, it produces void

434
00:26:41,110 --> 00:26:44,794
as its return. And what I would do, I would retrieve

435
00:26:44,842 --> 00:26:48,446
a text component, change it text, and basically rebuild the

436
00:26:48,468 --> 00:26:52,346
UI. But again, I would be triggering it randomly in a separate

437
00:26:52,378 --> 00:26:56,090
thread. It might be some just funny small app that you

438
00:26:56,100 --> 00:27:00,142
might be building, and that's where computable future will come into play quite usefully.

439
00:27:00,206 --> 00:27:03,262
So I always like to end my talks with call to action.

440
00:27:03,406 --> 00:27:06,706
Try to embrace concurrency. As I mentioned before, it's already here.

441
00:27:06,728 --> 00:27:09,958
It's a reality that we all live in. Review your application. Even if

442
00:27:09,964 --> 00:27:13,474
you're not ready for concurrency, think about designing for concurrency.

443
00:27:13,522 --> 00:27:16,550
It will bring you the benefits just by itself and just continue learning.

444
00:27:16,620 --> 00:27:20,738
Concurrency is one thing, reactivity is another very popular concept

445
00:27:20,754 --> 00:27:24,182
that's been discussed for ages now. So continue learning.

446
00:27:24,236 --> 00:27:27,666
When it comes to that, don't just be afraid of a concept just because you've

447
00:27:27,698 --> 00:27:31,102
used it before, like threads and runnables. These a lot of work being done

448
00:27:31,156 --> 00:27:35,018
around that. So my name is Nietzsche Vinnie. Go to my Twitter, my blog

449
00:27:35,114 --> 00:27:38,700
LinkedIn, or just email me directly if you have any questions. Thank you so much.

