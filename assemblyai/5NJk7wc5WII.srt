1
00:00:00,410 --> 00:00:06,126
Jamaica make up real

2
00:00:06,148 --> 00:00:09,902
time feedback into the behavior of your distributed systems and

3
00:00:09,956 --> 00:00:14,046
observing changes exceptions. Errors in real time

4
00:00:14,148 --> 00:00:17,914
allows you to not only experiment with confidence, but respond

5
00:00:18,042 --> 00:00:20,480
instantly to get things working again.

6
00:00:24,610 --> 00:01:05,750
Slos sake

7
00:01:05,770 --> 00:01:09,042
you for tuning in to my talk. I am going to be

8
00:01:09,096 --> 00:01:12,626
talking about continuous reliability and how is it that

9
00:01:12,648 --> 00:01:16,278
we can get there. Let's go ahead and just jump right in.

10
00:01:16,444 --> 00:01:19,702
As we know, software is going to break.

11
00:01:19,836 --> 00:01:23,746
The world that we're building continues relying on the stability

12
00:01:23,858 --> 00:01:26,040
of this naturally brittle technology.

13
00:01:26,810 --> 00:01:30,474
The challenge that we continue facing is very

14
00:01:30,512 --> 00:01:33,690
much about making sure that our customers stay first.

15
00:01:33,840 --> 00:01:37,386
How do we continue to innovate and deliver products and

16
00:01:37,408 --> 00:01:40,714
services so that our customers are

17
00:01:40,752 --> 00:01:44,334
happy that we're minimizing that risk of failure as

18
00:01:44,372 --> 00:01:48,222
much as possible? But we actually have come a long

19
00:01:48,276 --> 00:01:51,946
way. Maybe we used to think that our technology stacks

20
00:01:51,978 --> 00:01:55,250
was very complex, but boy were we wrong.

21
00:01:55,400 --> 00:01:59,154
Our legacy systems were way more simpler than

22
00:01:59,192 --> 00:02:02,382
the systems that we have now. These complexity continues

23
00:02:02,446 --> 00:02:05,766
increasing. We started out with just a few services

24
00:02:05,868 --> 00:02:09,334
on premises. Maybe we had one service that was

25
00:02:09,372 --> 00:02:12,882
being hosted, and maybe we had one or two annual

26
00:02:12,946 --> 00:02:16,822
releases. We've gone ahead and shifted left and

27
00:02:16,876 --> 00:02:20,410
rearchitected our monoliths to be microservices.

28
00:02:20,830 --> 00:02:24,090
Now we have things hosted in the cloud that

29
00:02:24,160 --> 00:02:28,150
we don't even know that location. If it's data centers,

30
00:02:28,310 --> 00:02:32,090
we now have hundreds if not thousands of microservices

31
00:02:32,170 --> 00:02:35,626
that we have to look after. And thanks to DevOps,

32
00:02:35,658 --> 00:02:39,834
we've collaborated a lot more when we have more frequent releases

33
00:02:39,962 --> 00:02:43,066
and sometimes we even deploy on Fridays.

34
00:02:43,258 --> 00:02:46,286
We have been thinking about these complexity.

35
00:02:46,398 --> 00:02:49,534
We have been preparing for the more unexpected

36
00:02:49,582 --> 00:02:53,214
that can happen to our systems. We are at a chaos engineering

37
00:02:53,262 --> 00:02:57,030
conference, so I am not going to go ahead and cover the history

38
00:02:57,100 --> 00:03:00,918
of chaos engineering. It's been great to see this space

39
00:03:01,004 --> 00:03:05,426
continue evolving, the community getting larger and stronger,

40
00:03:05,538 --> 00:03:09,386
and for more tools to be out there to make these possible.

41
00:03:09,568 --> 00:03:13,274
It's great to find tools that allow for us to run

42
00:03:13,392 --> 00:03:16,922
simple and safe experiments without needing to do

43
00:03:16,976 --> 00:03:20,606
one of a kind configurations. But what is

44
00:03:20,628 --> 00:03:24,266
it that we're missing? We have to continue reminding

45
00:03:24,298 --> 00:03:27,450
ourselves that as our systems get more complex,

46
00:03:27,610 --> 00:03:30,990
that means that our failures are also more complex.

47
00:03:31,410 --> 00:03:34,654
Operating them at scale is even more of

48
00:03:34,692 --> 00:03:38,402
a headache. We still find ourselves doing a lot of these

49
00:03:38,456 --> 00:03:41,602
manual work. That is a lot of toil of us to find

50
00:03:41,656 --> 00:03:45,026
the site reliability engineers. We end up having to

51
00:03:45,048 --> 00:03:48,726
do a lot of remediation, a lot of looking for the

52
00:03:48,748 --> 00:03:51,698
proper dashboards and observability links,

53
00:03:51,794 --> 00:03:55,782
and we also spend a lot of time executing those runbooks or

54
00:03:55,836 --> 00:03:59,274
shell scripts to make sure that our systems come back up.

55
00:03:59,392 --> 00:04:03,446
We constantly find ourselves feeling like this little stick

56
00:04:03,478 --> 00:04:07,466
figure, this is fine. My systems are broken, but they'll come

57
00:04:07,488 --> 00:04:10,906
back up. I'll have more coffee. I won't sleep. It's going to

58
00:04:10,928 --> 00:04:14,126
be okay. Maybe we'll actually escalate and get more help.

59
00:04:14,308 --> 00:04:17,946
But we are the ones that are on call. We're the ones getting pitched

60
00:04:17,978 --> 00:04:22,378
and woken up in these middle of these night. Until when is this too much?

61
00:04:22,564 --> 00:04:26,514
Until when do we question and ask ourselves what

62
00:04:26,552 --> 00:04:29,970
can we do to make things better? How do we make things

63
00:04:30,040 --> 00:04:33,170
more automated? How do we make things more reliable?

64
00:04:34,230 --> 00:04:37,742
I say that I am going to be talking about continuous

65
00:04:37,806 --> 00:04:41,270
reliability, but how is it that we're going to get there?

66
00:04:41,420 --> 00:04:45,334
Well, I believe that with these three words, we can get there.

67
00:04:45,532 --> 00:04:49,382
When I look back at my time as an SRE and working within SRE

68
00:04:49,446 --> 00:04:52,922
communities, three things that always come to mind

69
00:04:52,976 --> 00:04:56,810
is automation, standardization, and experiments.

70
00:04:57,150 --> 00:05:00,814
We learned that automations and standardization are

71
00:05:00,852 --> 00:05:04,510
core principles to site reliability engineering. And of course

72
00:05:04,580 --> 00:05:08,334
we cannot forget experimentation. From chaos engineering to

73
00:05:08,372 --> 00:05:11,946
feature flags to canary deployments, they've all helped

74
00:05:11,978 --> 00:05:15,714
us move the needle through all these years. We know that

75
00:05:15,752 --> 00:05:19,554
automation helps our organization and our teams not burn out

76
00:05:19,592 --> 00:05:23,634
and our systems to be more reliable. And of course we

77
00:05:23,672 --> 00:05:27,394
know that defining these reliability goals, it helps

78
00:05:27,442 --> 00:05:31,414
keep us online. Well, captain allows for these things to

79
00:05:31,452 --> 00:05:34,706
come together under one roof. So let's

80
00:05:34,738 --> 00:05:38,566
go ahead and dive right in. And first I'm going to introduce myself.

81
00:05:38,748 --> 00:05:42,982
My name is Ana Margarita Medina. I am a senior chaos engineer

82
00:05:43,046 --> 00:05:46,554
at Grumlin. I've been working here for almost four years

83
00:05:46,672 --> 00:05:50,754
with the focus of empowering others to learn more about chaos engineering

84
00:05:50,822 --> 00:05:54,062
and move their journey forward. Prior to that,

85
00:05:54,116 --> 00:05:57,514
I used to be at Uber working as an SRE

86
00:05:57,642 --> 00:06:01,338
where I focused in chaos engineering and cloud infrastructure.

87
00:06:01,514 --> 00:06:05,054
Prior to that I was also a front end developer, a back

88
00:06:05,092 --> 00:06:08,770
end developer and I even did some mobile applications.

89
00:06:09,190 --> 00:06:12,402
Gotten a chance to take all my knowledge from those

90
00:06:12,456 --> 00:06:16,070
industries and try to talk about making things more reliable.

91
00:06:16,650 --> 00:06:20,598
I also sit on the advisory board for Captain project,

92
00:06:20,684 --> 00:06:24,258
which has been really cool to see this space continue growing.

93
00:06:24,434 --> 00:06:27,558
Representation is something that really matters to me.

94
00:06:27,644 --> 00:06:30,854
So shout out to all of you that are joining in from one of those

95
00:06:30,892 --> 00:06:34,086
groups. I was born and raised in Costa Rica and my parents

96
00:06:34,118 --> 00:06:37,882
are from Nicaragua and I now reside in the San Francisco Bay area.

97
00:06:38,016 --> 00:06:41,982
So shout out to all of you. Let's go ahead and

98
00:06:42,036 --> 00:06:44,960
jump right back into this captain project.

99
00:06:45,330 --> 00:06:48,922
Captain is these control plane for DevOps automation

100
00:06:48,986 --> 00:06:52,822
of cloud native applications. It uses a declarative

101
00:06:52,906 --> 00:06:56,686
approach to build scalable automation for delivery

102
00:06:56,798 --> 00:07:00,594
and the operations of these services. It can also be

103
00:07:00,632 --> 00:07:03,810
scaled to a large number of services as well.

104
00:07:03,960 --> 00:07:08,718
The cool thing about captain is that it works for cloud native applications

105
00:07:08,894 --> 00:07:11,670
and is not just exclusive to Kubernetes.

106
00:07:12,250 --> 00:07:16,034
Captain is also part of the CNCF foundation

107
00:07:16,162 --> 00:07:19,162
and it sits in as a sandsbox project.

108
00:07:19,296 --> 00:07:22,154
It's been great to watch this project grow,

109
00:07:22,272 --> 00:07:26,090
improve and for it to gather more adoption.

110
00:07:26,990 --> 00:07:31,066
One of the awesome things within captain is that it allows for

111
00:07:31,088 --> 00:07:34,478
you to have a lot of things out of the box. You're going to

112
00:07:34,484 --> 00:07:38,090
be getting observability, some dashboards and alerting

113
00:07:38,170 --> 00:07:40,670
that allow for you to have best practices.

114
00:07:41,170 --> 00:07:45,090
You also get to configure that monitoring and observability

115
00:07:45,430 --> 00:07:49,294
whether you want it as default settings or you want customizable

116
00:07:49,342 --> 00:07:53,570
dashboards, along with getting some extra

117
00:07:53,640 --> 00:07:57,730
alertings that are going to be set up based on service level objectives

118
00:07:57,810 --> 00:08:01,042
for each managed service that you have within captain.

119
00:08:01,186 --> 00:08:05,126
And it allows for you to bring under the same platform some

120
00:08:05,148 --> 00:08:08,866
of that delivery, along with operations and

121
00:08:08,908 --> 00:08:12,650
remediations for your services. So I talk but service

122
00:08:12,720 --> 00:08:15,926
level objectives and service level indicators,

123
00:08:15,958 --> 00:08:19,738
I want to make sure to cover that terminology before we talk a

124
00:08:19,744 --> 00:08:23,102
little bit more about them. That service level agreement is

125
00:08:23,156 --> 00:08:26,654
going to be that contract with your users that is going to

126
00:08:26,692 --> 00:08:30,574
include the consequences for that contract to be not met.

127
00:08:30,772 --> 00:08:34,106
And that comes down to that service level objective,

128
00:08:34,218 --> 00:08:38,114
that is that target value or the range of failures that you

129
00:08:38,152 --> 00:08:42,146
have for that service that is going to be up or not,

130
00:08:42,328 --> 00:08:45,822
and that is going to be then measured by that service level

131
00:08:45,896 --> 00:08:49,714
indicator. That is a carefully defined quantitative measure

132
00:08:49,762 --> 00:08:53,046
of some aspect of the level of the service that you are

133
00:08:53,068 --> 00:08:56,870
providing. So a perfect example is our service

134
00:08:56,940 --> 00:09:00,682
level indicator being a web request that

135
00:09:00,736 --> 00:09:04,314
is going to have latency and for it to be less

136
00:09:04,352 --> 00:09:08,154
than 500 milliseconds. So that indicator is just these latency of

137
00:09:08,192 --> 00:09:11,514
every single request for that service. When we look

138
00:09:11,552 --> 00:09:15,454
at it, we look at that service level objective that it's 95%

139
00:09:15,492 --> 00:09:20,346
of those web requests have a latency less than 500 milliseconds

140
00:09:20,458 --> 00:09:23,962
over a rolling month in that service level agreement.

141
00:09:24,026 --> 00:09:28,414
A web request that have a latency less than 500 milliseconds

142
00:09:28,462 --> 00:09:32,322
for the month. If not that customer gets that money back. So there's actually

143
00:09:32,376 --> 00:09:36,610
a consequence for things to not be done

144
00:09:36,680 --> 00:09:39,926
with reliability in mind. And of course we

145
00:09:39,948 --> 00:09:43,106
have that big idea that we care so much about reliability.

146
00:09:43,218 --> 00:09:46,726
So we actually just don't want nines of reliability. We want to go ahead and

147
00:09:46,748 --> 00:09:50,310
think that we're trying to reach 100% of web requests,

148
00:09:50,390 --> 00:09:54,010
but that perfect ideal world doesn't really work when we actually

149
00:09:54,080 --> 00:09:57,466
put it out to technologies. The amount of dependencies that we

150
00:09:57,488 --> 00:10:00,806
have really make it really hard to have five nines,

151
00:10:00,838 --> 00:10:04,446
four nines, three nines of reliability. You have to do the work.

152
00:10:04,548 --> 00:10:08,330
Captain allows for you to take these concepts known as SLOs

153
00:10:08,410 --> 00:10:11,630
and SLOs, and it allows for you to have standardization.

154
00:10:11,970 --> 00:10:16,462
We have many tools that allow for us to be declaring service level objectives,

155
00:10:16,526 --> 00:10:20,034
but we don't have them under one platform. We need to find

156
00:10:20,072 --> 00:10:23,234
a way to standardize them across the tools and

157
00:10:23,272 --> 00:10:26,798
across different stages that you have within your pipeline,

158
00:10:26,894 --> 00:10:30,038
and sometimes even just these organization on its own.

159
00:10:30,204 --> 00:10:32,934
Captain allows for you to do just that.

160
00:10:33,132 --> 00:10:37,122
If you're interested in learning more specifically about the ways that slos

161
00:10:37,186 --> 00:10:40,546
can get created and be done within captain.

162
00:10:40,658 --> 00:10:43,946
One of the contributors, Andreas Grabner, a great friend,

163
00:10:44,048 --> 00:10:47,386
has a lot of talks around this. I personally love the one he

164
00:10:47,408 --> 00:10:49,420
gave last year, the Slos conf.

165
00:10:49,950 --> 00:10:54,378
So as we keep in mind that we have a declarative environment

166
00:10:54,554 --> 00:10:57,962
that allows for us to set up service level objectives,

167
00:10:58,106 --> 00:11:01,870
that is a way that we can think about building reliability.

168
00:11:03,430 --> 00:11:07,122
With bringing slos into all of this,

169
00:11:07,176 --> 00:11:10,610
we now have service level objectives that are going

170
00:11:10,680 --> 00:11:13,794
to work within the pipelines. That means that

171
00:11:13,832 --> 00:11:17,682
developers are going to see how their code, their improvements,

172
00:11:17,746 --> 00:11:21,970
their features that they're working on are actually impacting this reliability

173
00:11:22,050 --> 00:11:25,874
metric. And this will allow for a service level objective

174
00:11:25,922 --> 00:11:29,174
to actually work as a gatekeeper. So they're

175
00:11:29,222 --> 00:11:33,194
getting a chance to see things gradually roll out to your

176
00:11:33,232 --> 00:11:36,202
dev environment, to your staging environment. They get to say,

177
00:11:36,256 --> 00:11:40,250
oh, actually, this is making the request be even

178
00:11:40,320 --> 00:11:43,614
slower. We actually don't allow for that to

179
00:11:43,652 --> 00:11:47,166
be hitting our customers. Based on the service level agreement and

180
00:11:47,188 --> 00:11:49,790
that SLO that we just recently covered,

181
00:11:50,290 --> 00:11:53,262
we now have slos, part of a platform,

182
00:11:53,396 --> 00:11:57,122
part of the CICD, a great way that I love

183
00:11:57,176 --> 00:12:00,946
calling it is this being test driven operations. A lot

184
00:12:00,968 --> 00:12:04,450
of that SRE operation work now gets to be

185
00:12:04,520 --> 00:12:07,862
defined and done in a way that we actually have

186
00:12:07,996 --> 00:12:11,830
pass and failures based on these metrics that we define.

187
00:12:12,810 --> 00:12:15,826
We have these slos built into pipelines.

188
00:12:16,018 --> 00:12:19,402
This is a way for you to then think

189
00:12:19,456 --> 00:12:22,902
about what can you do to make things better afterwards.

190
00:12:23,046 --> 00:12:26,998
And captain allows for you to define these remediation actions,

191
00:12:27,174 --> 00:12:30,686
what to execute, to reevaluate that

192
00:12:30,708 --> 00:12:32,270
service level objective,

193
00:12:36,430 --> 00:12:40,186
since those objectives must be met in every single stage for

194
00:12:40,208 --> 00:12:43,674
every deployment within captain, captain is going to be

195
00:12:43,712 --> 00:12:47,422
running tests to make sure the service level objective is not

196
00:12:47,476 --> 00:12:50,846
breached before that promotion. You're getting a chance to

197
00:12:50,868 --> 00:12:54,062
automate that delivery. You get a chance to automate that

198
00:12:54,116 --> 00:12:56,720
extra step that SRe also gets to do.

199
00:12:57,810 --> 00:13:01,474
When Dynatrace looked around these space using the

200
00:13:01,512 --> 00:13:05,394
2020 DevOps report, they saw that 63% of

201
00:13:05,432 --> 00:13:09,282
folks are building internal delivery platforms and they wanted to

202
00:13:09,336 --> 00:13:13,106
find a way that they can give back to the community. They then ran

203
00:13:13,138 --> 00:13:16,598
their own surveys and got a chance to find out that a

204
00:13:16,604 --> 00:13:20,082
lot of time was being wasted maintaining pipelines,

205
00:13:20,226 --> 00:13:24,470
doing a lot of manual tasks and doing a lot of manual remediation.

206
00:13:25,370 --> 00:13:28,938
This can totally happen. I've seen this in multiple orgs where a

207
00:13:28,944 --> 00:13:32,586
lot of these things are completely just shell scripts that folks have

208
00:13:32,608 --> 00:13:35,686
to run, or you have to send a message on slack to

209
00:13:35,728 --> 00:13:39,242
one of your friends across these.org and ask, how do you bring a database

210
00:13:39,306 --> 00:13:39,920
back?

211
00:13:43,300 --> 00:13:47,040
We first start with the pipelines. We then bring in service

212
00:13:47,110 --> 00:13:51,732
level objectives to be set up as

213
00:13:51,786 --> 00:13:55,152
quality gates that captain allows for you to define.

214
00:13:55,216 --> 00:13:58,692
So as these service level objectives are defined within

215
00:13:58,746 --> 00:14:02,724
the development stage, as they are met and

216
00:14:02,762 --> 00:14:06,724
there's not a breach in it, and breach and reliability that then gets promoted

217
00:14:06,772 --> 00:14:10,100
over to your pre production environment, your staging environment.

218
00:14:10,260 --> 00:14:13,736
And as we see that those things are reliable and it's not a

219
00:14:13,758 --> 00:14:17,212
harm to our slO, we then get to promote that

220
00:14:17,266 --> 00:14:19,340
to our production environment.

221
00:14:22,510 --> 00:14:26,314
The cool thing too is that we also get to automate the operation of

222
00:14:26,352 --> 00:14:30,094
bringing our systems back when there is an issue that breaches that

223
00:14:30,132 --> 00:14:34,362
service level objective. So it gets to execute

224
00:14:34,426 --> 00:14:38,682
one of these remediation actions that you've set up, such as toggling

225
00:14:38,746 --> 00:14:43,342
that feature flag and these. That quality gate reevaluates

226
00:14:43,406 --> 00:14:46,286
that service level objective.

227
00:14:46,478 --> 00:14:50,686
If it passes. You now have remediated

228
00:14:50,878 --> 00:14:54,194
what was going on and it closes your reported

229
00:14:54,242 --> 00:14:58,182
issue. This takes in alerts and problems within

230
00:14:58,236 --> 00:15:01,282
your observability, within your dashboards.

231
00:15:01,346 --> 00:15:04,866
This is something that you can set up with tools such as Dynatrace

232
00:15:04,898 --> 00:15:08,346
and Prometheus, of course. And I wanted to show you

233
00:15:08,448 --> 00:15:11,050
a little bit of what that looks like in action.

234
00:15:12,430 --> 00:15:15,862
One of my favorite things about captain is that it has multiple

235
00:15:15,926 --> 00:15:19,674
learning resources. The tutorials. Captain Sh has

236
00:15:19,712 --> 00:15:23,342
really cool tutorials that you can run through. I'm going to go ahead and

237
00:15:23,396 --> 00:15:26,798
follow the captain. Full tour of Dynatrace. But if

238
00:15:26,804 --> 00:15:30,174
you don't want to use Dynatrace, you can use Prometheus and

239
00:15:30,292 --> 00:15:33,902
you'll get a chance to see how you bring your own kubernetes cluster.

240
00:15:33,966 --> 00:15:37,522
You install captain and such. So let's see what this

241
00:15:37,576 --> 00:15:41,358
does. We get a chance to just install captain

242
00:15:41,454 --> 00:15:45,234
by running this command. We get to give it these use case. Today we're going

243
00:15:45,272 --> 00:15:48,774
to focus on continuous delivery since that come with those

244
00:15:48,812 --> 00:15:52,562
quality gates. And it allows for you to see how this gradually

245
00:15:52,626 --> 00:15:56,102
rolls out. We're going to onboard our own project.

246
00:15:56,236 --> 00:15:59,546
We're going to call sock shop and we're going to pass a yaml file that

247
00:15:59,568 --> 00:16:02,938
helps define it. As we start our project,

248
00:16:03,024 --> 00:16:06,694
we now see that we have defined our three stages.

249
00:16:06,822 --> 00:16:10,574
Our stages are going to be very simple. Development, staging and

250
00:16:10,612 --> 00:16:14,654
production. We have a project now we actually need

251
00:16:14,692 --> 00:16:18,606
to onboard some services. So we're going to start out by onboarding a

252
00:16:18,628 --> 00:16:21,922
cart service. We're going to pass that sharp for it.

253
00:16:21,976 --> 00:16:25,618
We're going to pass our database of carts as well.

254
00:16:25,784 --> 00:16:29,614
And we're going to trigger

255
00:16:29,662 --> 00:16:33,406
that first delivery of our application. We're going to start out

256
00:16:33,448 --> 00:16:37,366
by triggering that database and

257
00:16:37,388 --> 00:16:40,614
then triggering the delivery of these cart's application to give

258
00:16:40,652 --> 00:16:43,830
the tag for the images that you are actually deploying.

259
00:16:44,250 --> 00:16:48,074
And things are going well. We see that we did the

260
00:16:48,112 --> 00:16:51,670
delivery over to deployment, to staging

261
00:16:51,750 --> 00:16:55,580
and to production. And things are all green. Things are going well.

262
00:16:56,270 --> 00:16:58,170
The project is succeeding.

263
00:16:59,090 --> 00:17:02,842
We then go ahead and do another release.

264
00:17:02,986 --> 00:17:06,510
We're now releasing version two of our carts.

265
00:17:06,930 --> 00:17:10,190
We see that production is still running on version,

266
00:17:11,010 --> 00:17:14,606
still running on version one of our application. But as we're

267
00:17:14,638 --> 00:17:18,974
actually rolling out version two of our application, we see that it's starting to fail

268
00:17:19,102 --> 00:17:22,574
in our preprod environment and in our development environment.

269
00:17:22,702 --> 00:17:26,662
When we look over at captain, we can see that the delivery got started,

270
00:17:26,796 --> 00:17:30,422
but when it came down to that evaluation stage, it's actually

271
00:17:30,476 --> 00:17:34,630
having issues. Dynatrace is reporting maybe a breach within

272
00:17:34,700 --> 00:17:37,930
slos and it's not allowing for this to get promoted.

273
00:17:41,050 --> 00:17:44,246
This allows for us to take a deep dive into

274
00:17:44,268 --> 00:17:47,894
that evaluation. When we go see what it's looking like in

275
00:17:47,932 --> 00:17:51,466
staging, we see that the response time of

276
00:17:51,488 --> 00:17:55,210
the 95th percentile is actually being

277
00:17:55,280 --> 00:17:59,082
1052 milliseconds. This does not meet

278
00:17:59,136 --> 00:18:03,046
these criteria that we have for things to be passing. So the

279
00:18:03,088 --> 00:18:06,474
result is being failed. And this is not getting promoted

280
00:18:06,522 --> 00:18:09,774
from staging onto production. We go

281
00:18:09,812 --> 00:18:12,894
ahead and we get to now release version three

282
00:18:12,932 --> 00:18:16,274
of this application where we're thinking more, but that

283
00:18:16,312 --> 00:18:20,258
response time. So as we release that, we see that

284
00:18:20,424 --> 00:18:24,322
our dev environment has moved over to version three. We also

285
00:18:24,376 --> 00:18:27,474
see that our staging environment eventually got rolled out

286
00:18:27,512 --> 00:18:31,766
to version three. And our production has also adopted into version three.

287
00:18:31,868 --> 00:18:34,854
So this is the ideal delivery that we're doing,

288
00:18:34,892 --> 00:18:38,626
our applications, it has passed some service level objectives

289
00:18:38,738 --> 00:18:41,420
and it's able to get promoted to the next one.

290
00:18:43,470 --> 00:18:47,542
If you're wondering how some of these service level objectives are defined

291
00:18:47,606 --> 00:18:51,626
and measured within captain and how all the magic that it

292
00:18:51,648 --> 00:18:55,290
does, you get to see some examples of it. We have some service

293
00:18:55,360 --> 00:18:59,086
level in the create indicators, which is that response time in the

294
00:18:59,108 --> 00:19:02,686
95th percentile, in that 15 percentile. And of

295
00:19:02,708 --> 00:19:06,042
course we have our error rates and we have our through output.

296
00:19:06,186 --> 00:19:09,842
We get a chance to see how those now have

297
00:19:09,896 --> 00:19:13,534
service level objectives. You get to define what the criteria

298
00:19:13,582 --> 00:19:17,166
needs to be for them to pass the criteria that it takes for them

299
00:19:17,208 --> 00:19:20,822
to be on warning. And then you now

300
00:19:20,876 --> 00:19:24,694
get to get an overall score for that service based on

301
00:19:24,732 --> 00:19:28,150
these different quality gates that the application has.

302
00:19:28,300 --> 00:19:32,714
You can have some that are warning and the

303
00:19:32,752 --> 00:19:36,346
quality gate is going to give you that warning. Some of them

304
00:19:36,368 --> 00:19:40,666
are just going to fail or continue passing. The awesome part

305
00:19:40,768 --> 00:19:44,602
is that captain allows for you to define these as their own

306
00:19:44,656 --> 00:19:48,458
Yaml files. You have your Slos Yaml. You have your Sli

307
00:19:48,554 --> 00:19:52,302
Yaml that you just get to say what it is that you

308
00:19:52,356 --> 00:19:55,586
want for that indicator and objective to be.

309
00:19:55,768 --> 00:19:59,922
And now captain allows for those

310
00:19:59,976 --> 00:20:03,186
YAml files to define the platform and the way that it's going

311
00:20:03,208 --> 00:20:07,198
to work. So when we talk about continuous reliability,

312
00:20:07,374 --> 00:20:11,074
to me that gets created when we have service level objectives,

313
00:20:11,122 --> 00:20:14,834
when we have things like captain that come with quality gates

314
00:20:14,962 --> 00:20:18,850
and we bring in that experiments piece, we bring in that chaos

315
00:20:18,930 --> 00:20:22,474
engineering. Those slos are going to require for

316
00:20:22,512 --> 00:20:25,850
us to do the work of setting up indicators. And now

317
00:20:25,920 --> 00:20:30,170
we get to inject chaos within the pipelines and

318
00:20:30,320 --> 00:20:34,262
see what that experiments does. So there's multiple

319
00:20:34,326 --> 00:20:37,998
ways for one to do chaos engineering. You can go ahead

320
00:20:38,084 --> 00:20:41,786
and run this at every single stage, see what chaos engineering

321
00:20:41,818 --> 00:20:46,080
experiment does in the dev and the staging prior to leaching to

322
00:20:46,770 --> 00:20:50,718
production. Or you can also just have a chaos engineers stage.

323
00:20:50,814 --> 00:20:55,134
So you can have your development, your staging, then have a chaos engineering stage.

324
00:20:55,262 --> 00:20:59,450
And that is that last quality gate before you promote to production.

325
00:20:59,630 --> 00:21:03,250
You can also think about doing chaos engineering alongside

326
00:21:03,330 --> 00:21:06,646
performance testing. This is one of the great ways that you have

327
00:21:06,668 --> 00:21:09,958
a lot of learning that comes with chaos engineering. This is one

328
00:21:09,964 --> 00:21:13,494
of the things that we did at Uber. We did load testing and we went

329
00:21:13,532 --> 00:21:16,666
ahead and also did chaos engineering. That's a way that we

330
00:21:16,688 --> 00:21:20,486
were preparing for our Black Fridays. That was our Halloween and New Year's.

331
00:21:20,518 --> 00:21:24,278
How do we make sure that we have enough bare metal racks

332
00:21:24,374 --> 00:21:28,014
that allow for us to handle the large load of capacity that

333
00:21:28,052 --> 00:21:31,342
we have on our peak traffic days, and how do we make sure

334
00:21:31,396 --> 00:21:35,338
that all these 50 microservices that it takes to run a trip

335
00:21:35,434 --> 00:21:38,514
are actually reliable on that day that we really

336
00:21:38,632 --> 00:21:42,254
matter. So that practice, we're not just building this overnight.

337
00:21:42,302 --> 00:21:44,420
There was a lot of testing that got done.

338
00:21:45,350 --> 00:21:49,094
And when we do these type of chaos engineering within

339
00:21:49,132 --> 00:21:52,918
the pipelines, we're asking ourselves, is this service

340
00:21:53,004 --> 00:21:56,386
level objective met? Yes. Cool. We're promoting

341
00:21:56,418 --> 00:21:59,634
that over to production. That service level objective

342
00:21:59,682 --> 00:22:03,638
is not met. Did we actually identify a weakness?

343
00:22:03,814 --> 00:22:07,034
We get a chance to do multiple things with something like,

344
00:22:07,072 --> 00:22:10,746
captain, you get to have autoremediation in case you want to

345
00:22:10,768 --> 00:22:14,654
set that up, or you just have to now do

346
00:22:14,692 --> 00:22:18,000
a new release, and that fix is actually going through.

347
00:22:18,610 --> 00:22:22,046
How do we think about these experiments? We're going to

348
00:22:22,068 --> 00:22:25,614
always keep in mind quality gates. We don't even have to do

349
00:22:25,652 --> 00:22:28,954
the math or ask our team if we think that these chaos

350
00:22:29,002 --> 00:22:33,042
engineer experiment results are okay for the customer or not,

351
00:22:33,096 --> 00:22:36,590
because we went ahead and we defined slos and slis.

352
00:22:36,750 --> 00:22:40,354
When the slos are met, we're good to go. When that SLO

353
00:22:40,402 --> 00:22:44,200
is not met, we're not okay to ship over to our customers.

354
00:22:45,130 --> 00:22:49,014
The way that this all comes together, when we do that example of

355
00:22:49,052 --> 00:22:52,586
having a chaos engineering stage is going to be

356
00:22:52,688 --> 00:22:56,294
about that application rolling out to that chaos engineering

357
00:22:56,342 --> 00:23:00,390
stage. That stage now triggers chaos engineering experiment.

358
00:23:00,550 --> 00:23:03,854
It takes all that data from the application and your

359
00:23:03,892 --> 00:23:07,360
tools that you have connected to it. It then says,

360
00:23:09,330 --> 00:23:12,734
is this SLO a pass or a fail? Do we

361
00:23:12,772 --> 00:23:16,094
promote to production or not? And we

362
00:23:16,132 --> 00:23:19,378
get to see how a lot of that continuous learning

363
00:23:19,464 --> 00:23:22,754
comes about. We're going to learn by doing, we're going to

364
00:23:22,792 --> 00:23:26,594
learn by injecting failure into our systems. And of course, there's that

365
00:23:26,632 --> 00:23:30,722
continuous aspect of it where we're going to be improving and repeating

366
00:23:30,786 --> 00:23:34,274
as we do more releases of our application. The ecosystem

367
00:23:34,322 --> 00:23:37,574
of captain continues growing. There's a lot of tools that you can

368
00:23:37,612 --> 00:23:41,122
use, starting with a delivery subset of applications.

369
00:23:41,186 --> 00:23:45,078
On the test side, there's a lot of it when it comes to observability,

370
00:23:45,174 --> 00:23:48,202
you can tie in multiple tools, and of course,

371
00:23:48,256 --> 00:23:51,894
in collaboration, you can send messages over to Slack to Microsoft

372
00:23:51,942 --> 00:23:55,206
Teams. Captain also recently launched SAP.

373
00:23:55,238 --> 00:23:58,522
Your integration for you to have a little bit more freedom

374
00:23:58,586 --> 00:24:02,046
if you want to do things in a no code way. You can also

375
00:24:02,148 --> 00:24:05,626
access these webhooks that allow for things to just be plug

376
00:24:05,658 --> 00:24:09,266
and play within your own internal systems or any other service that

377
00:24:09,288 --> 00:24:12,974
you don't see in the integrations. It's a great time to be playing

378
00:24:13,022 --> 00:24:17,266
around with captain and make sure to join the captain community.

379
00:24:17,368 --> 00:24:20,482
There's a lot of learning resources within chaos

380
00:24:20,546 --> 00:24:24,534
Engineering, SRE and DevOps. You can head on over to

381
00:24:24,572 --> 00:24:28,646
Captain Sh to learn more about this project. You can follow them on

382
00:24:28,668 --> 00:24:32,226
Twitter, YouTube and LinkedIn. Go ahead and give them

383
00:24:32,268 --> 00:24:36,150
a star over GitHub and make sure to get your hands dirty.

384
00:24:36,230 --> 00:24:39,786
Head on over to tutorials Captain Sh and make

385
00:24:39,808 --> 00:24:43,930
sure to take a look. They even have one that you can do locally using

386
00:24:44,000 --> 00:24:48,394
k three s in just a few minutes and set up a local Kubernetes cluster

387
00:24:48,442 --> 00:24:52,266
and get a chance to play with this delivery pipelines. As we're

388
00:24:52,298 --> 00:24:56,218
closing out, I want to make sure that I leave with some final thoughts

389
00:24:56,394 --> 00:25:00,062
as we go through the stuff that we're building within our systems.

390
00:25:00,126 --> 00:25:03,998
We have to remember that we can't just build reliability overnight.

391
00:25:04,094 --> 00:25:07,474
That can't just be an OKR. We also have to

392
00:25:07,512 --> 00:25:11,346
remember we can't. But reliability overnight.

393
00:25:11,458 --> 00:25:15,218
You can't bring in just a new tool that's going to promise you more nines

394
00:25:15,234 --> 00:25:18,694
of reliability. Those don't exist. You actually have to do the

395
00:25:18,732 --> 00:25:22,890
work. You have to learn. You have to inject failure and learn.

396
00:25:23,040 --> 00:25:26,346
You have to be able to make sure that

397
00:25:26,368 --> 00:25:30,102
you think of ways to make your team, your systems, more robust,

398
00:25:30,166 --> 00:25:34,410
more reliable. And the way to do that is by establishing

399
00:25:34,490 --> 00:25:38,474
processes, automating them, and continuous reliability

400
00:25:38,522 --> 00:25:41,838
that those processes are being ran and that the proper

401
00:25:41,924 --> 00:25:45,034
results are being gotten. That includes

402
00:25:45,082 --> 00:25:48,574
things like experiments, those service level objectives,

403
00:25:48,702 --> 00:25:52,350
making sure that you're doing game days, that you're doing failovers,

404
00:25:52,430 --> 00:25:56,066
that you're executing those runboats so that they don't become scale for

405
00:25:56,088 --> 00:26:00,134
those days that really matter. And reliability is not can

406
00:26:00,172 --> 00:26:03,974
accident at all. You have to do the work. You have

407
00:26:04,012 --> 00:26:07,542
to make sure that you're thinking ahead and thinking about

408
00:26:07,596 --> 00:26:11,006
unexpected things that can happen to your system and do chaos

409
00:26:11,058 --> 00:26:14,986
engineering around it. You also have to continue learning.

410
00:26:15,168 --> 00:26:19,014
If you're interested in taking the next step in your learning journey,

411
00:26:19,142 --> 00:26:22,554
feel free to check out Gremlin certification. You can head on

412
00:26:22,592 --> 00:26:26,174
over to gremlin.com slash certification to learn all

413
00:26:26,212 --> 00:26:30,106
about it. There's currently two certification modules that Gremlin

414
00:26:30,138 --> 00:26:33,854
is providing. We have the practitioner level, which ends up

415
00:26:33,892 --> 00:26:37,406
being chaos engineering fundamentals, and you have

416
00:26:37,428 --> 00:26:41,022
the next level. What is that professional level where you can get

417
00:26:41,076 --> 00:26:44,782
to test your skills on advanced chaos engineering along

418
00:26:44,836 --> 00:26:48,518
with some of that Gremlin terminology. I hope you all get a

419
00:26:48,524 --> 00:26:51,894
chance to check it out. And with that, I would love to say thank

420
00:26:51,932 --> 00:26:55,366
you for tuning into my chat. If you have any questions

421
00:26:55,468 --> 00:27:00,258
about Captain Chaos, engineering Gremlin Sre DevOps,

422
00:27:00,434 --> 00:27:05,606
don't be afraid to reach out. You can reach me on my email at anna@gremlin.com

423
00:27:05,708 --> 00:27:09,426
or feel free to say hi on Twitter Anna Underscore m underscore

424
00:27:09,458 --> 00:27:10,850
Medina gracias.

