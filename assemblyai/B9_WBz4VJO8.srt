1
00:00:25,410 --> 00:00:29,670
You. Hello. Good day,

2
00:00:29,740 --> 00:00:32,806
good morning, good afternoon, good evening, wherever you

3
00:00:32,828 --> 00:00:36,838
are today. Thank you so much for staying up or for

4
00:00:36,924 --> 00:00:40,790
coming to my talk today. I'm really excited to share

5
00:00:40,860 --> 00:00:44,290
some knowledge today about security rates engineering.

6
00:00:44,370 --> 00:00:47,874
So today I'm going to be talking on these subject risk driven fault

7
00:00:47,922 --> 00:00:51,578
injection security cares engineering for the fast and furious.

8
00:00:51,674 --> 00:00:55,562
My name is Kennedy Torkura and I am a cloud security engineer

9
00:00:55,706 --> 00:00:59,102
at Mattermost. And actually I'm also

10
00:00:59,156 --> 00:01:03,306
a PhD student. I'm completing my PhD at these Hasoplatna Institute,

11
00:01:03,418 --> 00:01:07,678
and my PhD is on cloud security. And therefore

12
00:01:07,854 --> 00:01:11,874
I'm going to be sharing knowledge about part of the things that I researched on

13
00:01:11,912 --> 00:01:15,502
and some of the theorems that I proposed and also evaluated

14
00:01:15,566 --> 00:01:18,546
as part of my doctoral thesis. So,

15
00:01:18,568 --> 00:01:22,498
let us start off with definition of security chaos engineering.

16
00:01:22,594 --> 00:01:26,470
And we're going to be borrowing the definition that has been proposed by

17
00:01:26,540 --> 00:01:30,582
Aaron Reinhardt, who is also the creator of security chaos engineering.

18
00:01:30,646 --> 00:01:34,074
He defines it as the identification of

19
00:01:34,112 --> 00:01:37,702
security control failures through proactive experimentation

20
00:01:37,766 --> 00:01:40,926
to build confidence in the system's ability to

21
00:01:40,948 --> 00:01:43,738
defend against malicious conditions in production.

22
00:01:43,834 --> 00:01:47,754
So some similarities actually between definition

23
00:01:47,802 --> 00:01:51,306
of chaos engineering and that of security chaos engineering,

24
00:01:51,338 --> 00:01:54,834
but the key differences here are that we are trying

25
00:01:54,872 --> 00:01:58,958
to look at how we can identify security control failures

26
00:01:59,054 --> 00:02:02,158
and how we can defend against malicious conditions.

27
00:02:02,254 --> 00:02:04,862
So some differences. Basically,

28
00:02:05,016 --> 00:02:08,486
chaos engineering tries to address availability problems,

29
00:02:08,588 --> 00:02:11,778
and that is done by employing resiliency patterns.

30
00:02:11,874 --> 00:02:13,750
So, resiliency patterns,

31
00:02:14,490 --> 00:02:17,806
strategies like timeouts, buckheads, circuit breaker,

32
00:02:17,858 --> 00:02:22,170
are being used to inject failures and to identify

33
00:02:23,390 --> 00:02:27,274
problems that might affect the availability of

34
00:02:27,312 --> 00:02:31,434
services on the other side. On the other hand, security case engineering

35
00:02:31,482 --> 00:02:35,086
addresses availability also, and a slightly different kind

36
00:02:35,108 --> 00:02:37,662
of availability this time around.

37
00:02:37,716 --> 00:02:41,562
Availability problems that might be caused by malicious actions,

38
00:02:41,626 --> 00:02:45,250
for example, denial of service attacks. Security based

39
00:02:45,320 --> 00:02:49,650
engineering also tries to look at integrity and confidentiality,

40
00:02:49,990 --> 00:02:55,206
whatever might impact on

41
00:02:55,228 --> 00:02:57,906
integrity or confidentiality or availability,

42
00:02:58,018 --> 00:03:02,278
which are the three principles of security,

43
00:03:02,444 --> 00:03:06,214
usually we call the CIA triad. And how that is done is

44
00:03:06,252 --> 00:03:10,666
by employing the existing controls that

45
00:03:10,688 --> 00:03:14,742
we have been using in cybersecurity. For example, the preventive

46
00:03:14,806 --> 00:03:18,966
controls. We're talking about mechanisms like firewalls,

47
00:03:19,158 --> 00:03:22,470
detected controls like intrusion detection systems,

48
00:03:22,550 --> 00:03:25,810
corrective controls, for example, incident response systems.

49
00:03:25,830 --> 00:03:29,582
So, security case engineering tries to verify that

50
00:03:29,636 --> 00:03:33,214
these controls are working the way they are supposed to

51
00:03:33,252 --> 00:03:36,770
work in an environment. And if they're not

52
00:03:36,840 --> 00:03:39,954
working that way, that's going to be notified, that's going to be

53
00:03:39,992 --> 00:03:43,746
identified. And the key big picture here is

54
00:03:43,768 --> 00:03:47,554
to be able to detect security blind spots,

55
00:03:47,682 --> 00:03:51,494
spots that these systems are

56
00:03:51,532 --> 00:03:55,218
not able to see, they're not able to identify.

57
00:03:55,314 --> 00:03:59,118
So what's the importance of applying security care engineering

58
00:03:59,154 --> 00:04:03,146
in the current dispensation? Today we live in a cloud native world,

59
00:04:03,248 --> 00:04:06,534
and actually our systems are getting more and more complex.

60
00:04:06,662 --> 00:04:09,686
And according to Bruce Schneer, in an essay,

61
00:04:09,718 --> 00:04:12,350
he wrote a plea for simplicity.

62
00:04:14,050 --> 00:04:17,642
The core message in that article was that complexity

63
00:04:17,786 --> 00:04:20,842
is the worst enemy of security. And essentially,

64
00:04:20,906 --> 00:04:24,254
that is what we are seeing today. Our systems are becoming

65
00:04:24,302 --> 00:04:28,066
more and more complex, and this makes it

66
00:04:28,168 --> 00:04:31,838
harder for security to be even effective,

67
00:04:32,014 --> 00:04:35,554
because security professionals can

68
00:04:35,592 --> 00:04:38,518
only defend systems that they are able two understand.

69
00:04:38,684 --> 00:04:41,846
The more they understand the system, the better they have a

70
00:04:41,868 --> 00:04:45,490
chance of defending it, or even identifying

71
00:04:45,570 --> 00:04:49,734
when there are malicious or insecure events

72
00:04:49,782 --> 00:04:53,434
in that system. Also, another problem we see is there is an

73
00:04:53,472 --> 00:04:57,210
increases of attacks against cloud infrastructure.

74
00:04:57,790 --> 00:05:01,486
A few years back, there were already attacks, actually when

75
00:05:01,508 --> 00:05:05,102
we saw hackers penetrating the Amazon web

76
00:05:05,156 --> 00:05:07,722
services, actually the account of cecilar,

77
00:05:07,866 --> 00:05:11,402
to be able to spawn virtual machines to mine bitcoins.

78
00:05:11,466 --> 00:05:16,146
And doing this, they were able to hide their tracks in a way that their

79
00:05:16,168 --> 00:05:19,762
infiltration was not even noticed. And later on, we also

80
00:05:19,816 --> 00:05:23,774
saw other kinds of attacks. For example, the exploitation

81
00:05:23,822 --> 00:05:28,710
of s three buckets, where attackers were able to successfully

82
00:05:29,530 --> 00:05:32,886
have access, unauthorized access to s three buckets and

83
00:05:32,908 --> 00:05:35,638
exfiltrate very sensitive information.

84
00:05:35,804 --> 00:05:39,862
However, things are actually getting worse. Attackers are becoming

85
00:05:39,926 --> 00:05:43,914
much more organized. And in a recent report, the Cloud

86
00:05:43,952 --> 00:05:47,738
Native threats report that was released by the Aqua security

87
00:05:47,824 --> 00:05:51,514
team, they actually showed that these attacks are getting more

88
00:05:51,552 --> 00:05:55,230
and more complicated. They are getting more and more sophisticated

89
00:05:55,650 --> 00:05:59,326
against cloud native infrastructure. They were able to deploy a

90
00:05:59,348 --> 00:06:02,698
set of honeypots in these wild, and based on this, they are able

91
00:06:02,724 --> 00:06:06,658
to gather attacks as they happen, and they are able to analyze it.

92
00:06:06,744 --> 00:06:11,650
So there are more and more attacks coming up against

93
00:06:11,720 --> 00:06:15,006
cloud native infrastructure. Another problem we see

94
00:06:15,048 --> 00:06:18,946
is the problem of new kinds of attacks, or let's

95
00:06:18,978 --> 00:06:23,160
say new security problems.

96
00:06:23,610 --> 00:06:27,810
One of the most common one is that of misconfiguration.

97
00:06:27,890 --> 00:06:31,378
So according to Gartner, from now up

98
00:06:31,404 --> 00:06:35,066
to four years ahead, there's going to be a lot of problems that

99
00:06:35,088 --> 00:06:38,426
are caused by misconfiguration. And as you know, we've heard a

100
00:06:38,448 --> 00:06:41,722
lot about, I just mentioned about s three buckets and these,

101
00:06:41,856 --> 00:06:45,214
when the major reason why these buckets are

102
00:06:45,252 --> 00:06:48,894
being attacked is because of misconfiguration. And 99%

103
00:06:48,932 --> 00:06:52,346
of attacks against cloud infrastructure are going to be caused

104
00:06:52,378 --> 00:06:56,158
by users faults, majorly, inability to configure,

105
00:06:56,254 --> 00:06:59,634
or inability two deployed to deploy cloud assets in a way

106
00:06:59,672 --> 00:07:02,914
that they are secure. And these things are being

107
00:07:02,952 --> 00:07:06,054
caused by, essentially, I put it into two

108
00:07:06,092 --> 00:07:09,506
main reasons. There is a knowledge gap

109
00:07:09,618 --> 00:07:12,710
as regards what is expected

110
00:07:13,050 --> 00:07:16,946
from people who are using the cloud, and there's insufficient tooling

111
00:07:16,978 --> 00:07:20,906
support to help them to be able to deploy or to

112
00:07:20,928 --> 00:07:24,694
be able to deployed these infrastructure properly. And we can easily

113
00:07:24,742 --> 00:07:26,860
see this. So we have on the screen here,

114
00:07:27,630 --> 00:07:31,222
actually two policies which are access control policies

115
00:07:31,286 --> 00:07:35,280
for Amazon Web services on XM. Right here is a policy

116
00:07:35,970 --> 00:07:39,806
that actually is quite large and most

117
00:07:39,828 --> 00:07:43,258
of the time people are expected to pick up

118
00:07:43,284 --> 00:07:47,266
these policies, manage them, to edit them by themselves, by hand, actually doing

119
00:07:47,288 --> 00:07:50,994
it manually. And this is a very, very tangible example of

120
00:07:51,032 --> 00:07:54,580
working about insufficient tooling support

121
00:07:54,970 --> 00:07:58,546
for security. So also as we observe,

122
00:07:58,578 --> 00:08:01,942
there's a lot of new trends coming up that

123
00:08:01,996 --> 00:08:06,658
are actually aligned with the digital transformation agenda.

124
00:08:06,834 --> 00:08:09,938
We got DevOps, we have the CI CD pipeline,

125
00:08:10,034 --> 00:08:13,546
we have a lot

126
00:08:13,568 --> 00:08:16,826
of people are shifting their workloads to the left. They want

127
00:08:16,848 --> 00:08:19,786
to be able to be fast, they want to be able to agile, to be

128
00:08:19,808 --> 00:08:22,974
agile. They want two be able, two basically make

129
00:08:23,012 --> 00:08:29,246
use of the new trends, new technologies to

130
00:08:29,268 --> 00:08:31,680
take. It has an advantage for themselves.

131
00:08:32,870 --> 00:08:37,134
And unfortunately this is not easy for security two handle

132
00:08:37,262 --> 00:08:41,060
because the traditional model of security is like we see,

133
00:08:41,910 --> 00:08:45,186
to be able to take care of infrastructure that is more or

134
00:08:45,208 --> 00:08:48,598
less static, doesn't really change. And this is how security

135
00:08:48,684 --> 00:08:51,926
has been in the last two decades or even three

136
00:08:51,948 --> 00:08:55,506
decades. Most of our security systems are designed

137
00:08:55,538 --> 00:08:59,222
to protect those kind of systems that are static.

138
00:08:59,286 --> 00:09:02,746
And the new trends have become, they're a problem for

139
00:09:02,768 --> 00:09:06,090
security. Security is more like quite confused these days.

140
00:09:06,160 --> 00:09:10,614
You see the traditional security mechanisms

141
00:09:10,662 --> 00:09:14,206
are basically struggling to catch up with these

142
00:09:14,308 --> 00:09:18,394
recent trends. And so there is a new kid in the block,

143
00:09:18,522 --> 00:09:21,598
a new concept coming up called the cloud native security.

144
00:09:21,764 --> 00:09:25,138
And essentially cloud native security is about

145
00:09:25,304 --> 00:09:27,650
securing cloud native infrastructure,

146
00:09:29,190 --> 00:09:32,354
which kind of summarizes the new trends we're seeing these

147
00:09:32,392 --> 00:09:36,120
days. Like has I mentioned

148
00:09:36,650 --> 00:09:40,342
in the last slide, in order to sort of define what cloud

149
00:09:40,396 --> 00:09:44,326
native security is, which essentially boils down to defense in

150
00:09:44,348 --> 00:09:48,346
depth, the Kubernetes security team issued an

151
00:09:48,368 --> 00:09:51,978
article which the link is down below there.

152
00:09:52,064 --> 00:09:58,026
But essentially security in a cloud native world has

153
00:09:58,048 --> 00:10:01,514
to be set up at every

154
00:10:01,552 --> 00:10:05,274
layer of the cloud native infrastructure. So starting from the internal

155
00:10:05,322 --> 00:10:08,570
one, the inner layer, we got the code layer,

156
00:10:08,650 --> 00:10:11,898
which is these most common one to us because we've

157
00:10:11,914 --> 00:10:15,230
been writing software for many years, many decades.

158
00:10:15,310 --> 00:10:19,122
So security has two be embedded in our code using things

159
00:10:19,176 --> 00:10:22,562
like static code analysis or dynamic code

160
00:10:22,616 --> 00:10:25,594
analysis. The next layer is the container.

161
00:10:25,742 --> 00:10:29,922
So we got to be able to scan our containers to detect dependencies

162
00:10:29,986 --> 00:10:33,494
that have malicious components and

163
00:10:33,532 --> 00:10:36,806
things like that. Then the next outer layer is the

164
00:10:36,828 --> 00:10:40,758
cluster. Now we're talking about orchestrators like kubernetes,

165
00:10:40,854 --> 00:10:44,554
and there's a whole new kind

166
00:10:44,592 --> 00:10:48,234
of problems that are emanating from kubernetes. And we got to be able

167
00:10:48,272 --> 00:10:51,914
to take care of things using things like the network

168
00:10:51,962 --> 00:10:55,594
policies, or to be able to analyze when there are processes

169
00:10:55,642 --> 00:10:59,642
within the containers that are actually malicious

170
00:10:59,706 --> 00:11:03,626
or are suspicious. Now, the final layer is these cloud infrastructure,

171
00:11:03,738 --> 00:11:06,960
which is the very platform upon which

172
00:11:07,410 --> 00:11:10,750
the entire auditory layers delay upon.

173
00:11:10,830 --> 00:11:14,990
And we're going to be able to take care of this cloud infrastructure.

174
00:11:15,070 --> 00:11:18,406
We should be able to look at things like these shared security

175
00:11:18,508 --> 00:11:22,294
model, and we have good understanding of how it works,

176
00:11:22,412 --> 00:11:25,154
have a good understanding of our responsibilities,

177
00:11:25,282 --> 00:11:30,102
and understand the kind of security efforts

178
00:11:30,166 --> 00:11:34,042
that are expected from us. So this is a summary of

179
00:11:34,096 --> 00:11:37,306
what cloud native security is, but how does the

180
00:11:37,328 --> 00:11:41,006
attacker look at it? We've just talked about four layers of

181
00:11:41,108 --> 00:11:44,446
infrastructure. Unfortunately, attackers still look at

182
00:11:44,468 --> 00:11:47,914
this as one single target. So inasmuch

183
00:11:47,962 --> 00:11:51,274
as they might need to have the skills that are necessary

184
00:11:51,322 --> 00:11:55,502
for them to conducted attacks, probably they need just one toolkit

185
00:11:55,566 --> 00:11:59,358
to be able to successfully attack a cloud native infrastructure.

186
00:11:59,454 --> 00:12:03,326
And the attack surface

187
00:12:03,358 --> 00:12:07,430
is so wide that these possibilities are endless. As you see here,

188
00:12:07,580 --> 00:12:10,886
the attacker can virtually start from any part, either from

189
00:12:10,908 --> 00:12:14,662
the code or from the docker layer, or from the

190
00:12:14,716 --> 00:12:18,326
Kubernetes layer of the cluster, or even from the cloud layer,

191
00:12:18,438 --> 00:12:21,734
can virtually start from any layer and literally

192
00:12:21,862 --> 00:12:25,210
move across the other layer. And we have seen attacks,

193
00:12:25,550 --> 00:12:27,770
these kinds of kinds of attacks.

194
00:12:29,390 --> 00:12:33,546
What we still see, and the way our cloud native security platforms

195
00:12:33,578 --> 00:12:36,894
are being designed, is to take care of these layers, one after

196
00:12:36,932 --> 00:12:41,082
the other. So we got tooling support today for these core layer,

197
00:12:41,146 --> 00:12:45,054
we got tooling support for the container layer. A lot of systems

198
00:12:45,102 --> 00:12:48,882
are, security systems are designed. Two do that these days.

199
00:12:49,016 --> 00:12:52,786
We got cluster security platforms and we got of

200
00:12:52,808 --> 00:12:55,770
course, the cloud security platforms.

201
00:12:55,950 --> 00:12:59,174
And the challenge here is that most

202
00:12:59,212 --> 00:13:02,726
of these tooling support, these platforms, these security

203
00:13:02,828 --> 00:13:05,320
systems, do not talk to themselves,

204
00:13:06,090 --> 00:13:10,246
they work independently, and there is really no cross coordination

205
00:13:10,278 --> 00:13:14,454
or no cross understanding. So eventually, human operators

206
00:13:14,502 --> 00:13:18,410
are expected still to come into this loop. And these

207
00:13:18,480 --> 00:13:21,434
try to make sense of the output,

208
00:13:21,482 --> 00:13:25,578
the results, the analysis that these individual components

209
00:13:25,674 --> 00:13:29,754
are making. So essentially what is missing is for us to have a unifying

210
00:13:29,802 --> 00:13:33,710
layer, a unifying strategies that stitches these

211
00:13:33,780 --> 00:13:37,346
various components together and makes sense of it. And that

212
00:13:37,368 --> 00:13:40,738
is where security chaos engineering comes in. And I will in

213
00:13:40,744 --> 00:13:44,002
the next slides, try to explain how that works.

214
00:13:44,136 --> 00:13:47,266
So basically, security chaos engineering,

215
00:13:47,378 --> 00:13:51,334
as far as I see, is going to be a new

216
00:13:51,372 --> 00:13:55,314
way for us to be able to put together these various

217
00:13:55,362 --> 00:13:58,470
cloud security, cloud native security platforms.

218
00:13:58,550 --> 00:14:03,382
And commonly I've put in this diagram the major categories

219
00:14:03,446 --> 00:14:07,210
of cloud native security. First, we got the cloud security

220
00:14:07,280 --> 00:14:10,702
posture management, which tries to look at the control

221
00:14:10,756 --> 00:14:14,922
plane of cloud infrastructure to detected malicious

222
00:14:14,986 --> 00:14:18,622
actions, to be able to detect misconfigurations and stuff like that.

223
00:14:18,756 --> 00:14:22,298
We got the cloud workload protection platforms,

224
00:14:22,394 --> 00:14:25,086
essentially looking at workloads from kubernetes,

225
00:14:25,278 --> 00:14:28,914
doing vulnerability scanning and things like that. And we also have

226
00:14:28,952 --> 00:14:32,386
the cloud access security brokers, which are also another kind of

227
00:14:32,408 --> 00:14:36,118
security system that looks at these, tries to understand

228
00:14:36,204 --> 00:14:41,106
the interactions between on premises infrastructure owned

229
00:14:41,138 --> 00:14:44,886
by organizations, and how these

230
00:14:44,988 --> 00:14:48,730
on premises systems are interacting with a cloud platform,

231
00:14:48,880 --> 00:14:54,262
and tries to make sure that sensitive

232
00:14:54,326 --> 00:14:58,166
data is not handled in ways that exposes

233
00:14:58,198 --> 00:15:02,394
them and quite a number of things. So essentially, security rates engineering,

234
00:15:02,522 --> 00:15:06,634
as far as I see, is going to be that unifying mechanism that brings

235
00:15:06,682 --> 00:15:10,222
together these various security components to make sense

236
00:15:10,356 --> 00:15:14,414
out of them. So let us talk a little bit about riskdriven fault

237
00:15:14,462 --> 00:15:18,482
injection. And essentially, riskdriven fault injection is

238
00:15:18,536 --> 00:15:22,030
about employing security case engineering from a risk

239
00:15:22,110 --> 00:15:25,606
perspective. And why that is important is

240
00:15:25,628 --> 00:15:29,062
because firstly, we know that 100%

241
00:15:29,116 --> 00:15:32,678
security is a dream. There is no security

242
00:15:32,764 --> 00:15:35,110
system that is 100% secure.

243
00:15:36,250 --> 00:15:39,914
Problems emanate from various directions, either from within

244
00:15:40,112 --> 00:15:43,622
our employees that may make mistakes to attackers

245
00:15:43,686 --> 00:15:47,194
that evolve new ways. Two things like zero

246
00:15:47,232 --> 00:15:50,830
do vulnerabilities that might be exploited by

247
00:15:50,900 --> 00:15:54,846
some attackers. And I've also spoken with a

248
00:15:54,868 --> 00:15:58,602
couple of people who are trying to convey chaos

249
00:15:58,666 --> 00:16:02,206
engineering to these security teams. And what

250
00:16:02,228 --> 00:16:06,178
I sense is it's a bit difficult, because security

251
00:16:06,264 --> 00:16:09,614
is a hard language to explain, it is hard to measure.

252
00:16:09,662 --> 00:16:13,262
It is larger, abstract. And so we can use risk

253
00:16:13,326 --> 00:16:16,470
as a method to communicate or to drive

254
00:16:16,540 --> 00:16:20,326
chaos engineering to our security engineers to

255
00:16:20,348 --> 00:16:24,482
end our culture. And we have various kinds of methods

256
00:16:24,546 --> 00:16:28,262
for looking at risk. Quantitative risk assessments

257
00:16:28,406 --> 00:16:31,786
are really more attractive. We're going to look at

258
00:16:31,808 --> 00:16:35,670
data driven strategies. Risk helps us to measure

259
00:16:35,750 --> 00:16:39,578
security, that we can communicate this whatever

260
00:16:39,744 --> 00:16:43,102
strategy we are trying to propose in more

261
00:16:43,156 --> 00:16:46,782
clearer and more sensible ways to management, as well as two other

262
00:16:46,836 --> 00:16:50,446
teams in a company. I'm going to walk you through what we refer to

263
00:16:50,468 --> 00:16:54,686
as the security case engineering feedback

264
00:16:54,718 --> 00:17:01,874
loop, which is a method that we think is

265
00:17:01,912 --> 00:17:05,906
going to drive these implementation of security case engineering

266
00:17:06,018 --> 00:17:10,162
much better and much constructively in an organization. It consists

267
00:17:10,226 --> 00:17:13,986
of five parts, and essentially this is a feedback loop,

268
00:17:14,098 --> 00:17:17,538
and which is

269
00:17:17,724 --> 00:17:21,146
an adaptation of the MApik feedback loop that has

270
00:17:21,168 --> 00:17:24,858
been used in autonomous computing systems. And the idea

271
00:17:24,944 --> 00:17:28,170
here is how we can take security based

272
00:17:28,240 --> 00:17:31,914
engineering and push towards it, become an automated

273
00:17:32,042 --> 00:17:35,790
system that works behind the scenes and works together with

274
00:17:35,860 --> 00:17:39,038
other security systems in a

275
00:17:39,044 --> 00:17:42,174
way that hardens security and makes security much,

276
00:17:42,212 --> 00:17:45,094
much better. So the first part of this group is execute.

277
00:17:45,162 --> 00:17:48,786
And here we have to talk about what

278
00:17:48,808 --> 00:17:52,402
is the aim of the experiment. So if you want to conduct a security based

279
00:17:52,456 --> 00:17:56,558
engineering experiment, you want to be able to clearly define these aim.

280
00:17:56,654 --> 00:18:00,150
What do you want to achieve? And based on that, you're going to craft a

281
00:18:00,220 --> 00:18:03,554
suitable hypothesis which you're going to be proving,

282
00:18:03,682 --> 00:18:06,870
and then you're going to look at and define the scope,

283
00:18:07,370 --> 00:18:10,726
the intensity of the experiments

284
00:18:10,758 --> 00:18:14,282
you want to carry. It's really important to carry out some

285
00:18:14,336 --> 00:18:17,574
sort of sanity checks. You're going to be coordinating with responsible

286
00:18:17,622 --> 00:18:21,150
teams. You want to understand, you want to convey to them

287
00:18:21,220 --> 00:18:23,994
clearly what you aim to achieve.

288
00:18:24,122 --> 00:18:27,754
These are administrative aspects, these are, of course, social aspects.

289
00:18:27,802 --> 00:18:31,434
Very important. There is a human side that is largely

290
00:18:31,482 --> 00:18:34,946
overlooked. You want to be able to communicate with people and

291
00:18:34,968 --> 00:18:38,402
let them understand your mindset aim, and you want to by

292
00:18:38,456 --> 00:18:41,886
them in very important is recoverability.

293
00:18:41,998 --> 00:18:46,002
And what I mean by recoverability is if things go wrong,

294
00:18:46,136 --> 00:18:49,814
you want to be able to roll back to the state. That is good

295
00:18:49,852 --> 00:18:53,174
enough. And there are various ways of putting this

296
00:18:53,212 --> 00:18:57,774
in place. There are infrastructure as code strategies

297
00:18:57,842 --> 00:19:01,706
where an infrastructure is already in git using

298
00:19:01,808 --> 00:19:05,530
things like terraform or AWS, cloud formation,

299
00:19:05,870 --> 00:19:09,114
and there's also state management. So if things go wrong

300
00:19:09,152 --> 00:19:12,974
or if you break things, you can sort of recover and

301
00:19:13,092 --> 00:19:16,960
kind of not bring too much problems to the system.

302
00:19:17,570 --> 00:19:21,166
So I talked about you trying to have kind

303
00:19:21,188 --> 00:19:24,466
of a scope of what you want to do. We created a

304
00:19:24,488 --> 00:19:28,126
tool called cloud strike, and in cloud strike

305
00:19:28,238 --> 00:19:31,762
we has different modes of operation. So if you're going to

306
00:19:31,816 --> 00:19:35,162
launch inject security fault injection,

307
00:19:35,326 --> 00:19:38,854
or if you're going to inject security faults, they can have

308
00:19:38,892 --> 00:19:42,230
different magnitude of intensity,

309
00:19:42,890 --> 00:19:45,800
30%, 60%, 90%.

310
00:19:47,770 --> 00:19:51,830
You have to figure out how the impact is going to be in different degrees

311
00:19:51,910 --> 00:19:56,182
and decide on what degree you will use based on the maturity

312
00:19:56,326 --> 00:20:00,378
of the team or of the infrastructure. And you

313
00:20:00,384 --> 00:20:03,914
could have an attack scenario. These actually we had, and I'm going to give

314
00:20:03,952 --> 00:20:07,466
an example in the next slide where we had, we could chain various

315
00:20:07,578 --> 00:20:11,310
attacks to sort of form a scenario. So it's two simulate,

316
00:20:12,050 --> 00:20:15,202
to simulate how attackers move in real life,

317
00:20:15,256 --> 00:20:18,958
because attackers do not, they launch series of attacks

318
00:20:19,134 --> 00:20:22,834
to be able to achieve their objective. So here we have

319
00:20:22,872 --> 00:20:26,790
a table which has different attacks

320
00:20:27,290 --> 00:20:31,458
which we use in cloud strike.

321
00:20:31,634 --> 00:20:34,806
So we got the cloud resource we want to

322
00:20:34,828 --> 00:20:38,914
attack, the action that we want to take. And just a brief description.

323
00:20:39,042 --> 00:20:43,030
These first line we got the user. So we create a new random user.

324
00:20:43,190 --> 00:20:46,474
This is an action. And you could kind of, like I said,

325
00:20:46,512 --> 00:20:50,266
have a scenario where you link three or

326
00:20:50,288 --> 00:20:53,562
four or more of these various individual actions,

327
00:20:53,706 --> 00:20:58,446
and that is going to form an attack scenario. And here is an

328
00:20:58,468 --> 00:21:01,774
example of the experiments we carried out. We start with

329
00:21:01,812 --> 00:21:04,750
creating a user called bob get buckets.

330
00:21:04,830 --> 00:21:08,494
We select a random bucket from that which we got from Amazon

331
00:21:08,542 --> 00:21:15,074
Web services, and we create a malicious policy and we

332
00:21:15,112 --> 00:21:18,822
assign Bob access to the bucket using the policy.

333
00:21:18,956 --> 00:21:22,838
And in this case, we want to be able to see whether our

334
00:21:22,924 --> 00:21:26,470
security system, whatever security system we are using in the cloud,

335
00:21:26,540 --> 00:21:30,330
maybe it's cloud security posture management or something

336
00:21:30,400 --> 00:21:33,642
as simple as cloud trail. You want to see whether it's able

337
00:21:33,696 --> 00:21:37,434
to detect these activities. When you created a new

338
00:21:37,472 --> 00:21:41,238
user, was it flagged? Did the cloud security mechanisms

339
00:21:41,334 --> 00:21:45,470
detect it? How long did it take for my notification to

340
00:21:45,620 --> 00:21:48,240
reach you, for example? Also similar,

341
00:21:48,610 --> 00:21:52,462
when you create a malicious policy, are you able to detect that

342
00:21:52,516 --> 00:21:57,954
a malicious policy was created. So the

343
00:21:57,992 --> 00:22:01,986
second point on the stage of the feedback loop is monitor. So once you

344
00:22:02,008 --> 00:22:05,998
start injecting failures, you want to be able to monitor the progress.

345
00:22:06,174 --> 00:22:10,134
This is pretty important that you have sort

346
00:22:10,172 --> 00:22:13,606
of either logging system where you are able to see the logs in

347
00:22:13,628 --> 00:22:17,126
real time, or you have an observability systems and there are a lot

348
00:22:17,148 --> 00:22:19,910
of them coming up these days, or you have even tracing.

349
00:22:19,990 --> 00:22:23,722
So whatever you have that gives you clear visibility into

350
00:22:23,776 --> 00:22:27,226
the progress of the attack, because essentially you

351
00:22:27,248 --> 00:22:30,442
want to be able to stop these experiment. If things

352
00:22:30,496 --> 00:22:34,478
begin to go too bad and you want to be able to recover, as I

353
00:22:34,484 --> 00:22:37,818
said, you want to be able to have recoverability,

354
00:22:37,914 --> 00:22:41,326
which makes it possible for you to roll back to

355
00:22:41,348 --> 00:22:44,820
these good state. Of course, this is the third part.

356
00:22:45,190 --> 00:22:49,266
The third stage is about analyzing. So assuming everything,

357
00:22:49,448 --> 00:22:52,770
even if you had a failure, if you had to stop these

358
00:22:52,920 --> 00:22:57,366
experiment, it's critically important that you have to understand

359
00:22:57,468 --> 00:23:01,558
why it failed. You get some lessons from

360
00:23:01,644 --> 00:23:05,170
what happened, what went wrong, why did the experiment fail?

361
00:23:05,250 --> 00:23:08,562
So you can have another trial. And if you succeed,

362
00:23:08,626 --> 00:23:10,620
you want to be able to derive questions,

363
00:23:11,390 --> 00:23:14,506
derive answers to the questions you posed at the beginning of the

364
00:23:14,528 --> 00:23:18,666
planning stage. And essentially what we are talking about from a security

365
00:23:18,768 --> 00:23:22,174
perspective is looking at this is an example of the

366
00:23:22,212 --> 00:23:25,614
OWAsp risk rating methodology. And so since

367
00:23:25,812 --> 00:23:29,262
we are proposes a risk based methodology, it is

368
00:23:29,316 --> 00:23:33,266
pretty important for a good analysis to understand

369
00:23:33,368 --> 00:23:36,686
exactly the results you got from the experiment.

370
00:23:36,798 --> 00:23:42,066
You want to understand these kind of threat agents that

371
00:23:42,088 --> 00:23:45,058
might exploit this attack.

372
00:23:45,224 --> 00:23:48,454
You want to look at the attack vectors, the vehicles they're going to

373
00:23:48,492 --> 00:23:51,574
use to conduct such an attack. You want to

374
00:23:51,612 --> 00:23:55,510
understand exactly the problem, the vulnerability that was detected,

375
00:23:56,250 --> 00:23:59,942
because eventually you're going to have to fix that. You want to

376
00:23:59,996 --> 00:24:04,362
understand the security controls that were compromised and other

377
00:24:04,416 --> 00:24:07,994
important things. What is the technical impact of

378
00:24:08,032 --> 00:24:11,534
that attack and of course the business impact. We think if you

379
00:24:11,572 --> 00:24:14,766
are able to sort of have this clear understanding or

380
00:24:14,788 --> 00:24:17,946
this clear analysis of experimental results,

381
00:24:18,058 --> 00:24:22,974
it even makes it much easier to convey two,

382
00:24:23,012 --> 00:24:25,940
get a buy in from management, for example.

383
00:24:26,870 --> 00:24:30,846
So the fourth stage of the security case engineering feedback

384
00:24:30,878 --> 00:24:34,594
loop is about planning. So you want to plan for the next

385
00:24:34,632 --> 00:24:38,086
iteration of your experiments because the

386
00:24:38,108 --> 00:24:42,354
idea is to have a continuous

387
00:24:42,482 --> 00:24:46,658
system. So in this case you're

388
00:24:46,674 --> 00:24:50,902
going to have to create things like backlogs for vulnerability management,

389
00:24:50,966 --> 00:24:54,810
for whatever teams that are responsible to fix

390
00:24:54,880 --> 00:24:57,846
the things, the security problems that were detected.

391
00:24:58,038 --> 00:25:01,610
This might mean you're reaching out to the security operations

392
00:25:01,690 --> 00:25:05,070
teams, development teams and also

393
00:25:05,140 --> 00:25:09,306
threat modeling. I think the knowledge that is going to be gained

394
00:25:09,338 --> 00:25:12,894
from security case engineering is a knowledge that

395
00:25:12,932 --> 00:25:16,242
can be used for threat modeling or things

396
00:25:16,296 --> 00:25:19,954
like security awareness training for teams, because you

397
00:25:19,992 --> 00:25:24,350
must understand that what you have at the end of a security based engineering

398
00:25:24,510 --> 00:25:25,570
experiment,

399
00:25:28,810 --> 00:25:32,694
you've been able to understand these problems in these system, meaning that you

400
00:25:32,732 --> 00:25:35,654
have knowledge about what might happen in the future.

401
00:25:35,772 --> 00:25:39,566
And it's different from what you get from traditional systems,

402
00:25:39,618 --> 00:25:43,180
which they try to explain about what has happened

403
00:25:43,790 --> 00:25:47,130
here you are trying to explain what might happen in the future.

404
00:25:47,200 --> 00:25:50,826
So it's really, really proactive. So you want to be able to

405
00:25:51,008 --> 00:25:54,862
fix, as I said, the issues you saw and

406
00:25:54,916 --> 00:25:58,670
also construct hypothesis for the next iteration of

407
00:25:58,820 --> 00:26:02,834
experiments. So this is like the last part of it, which is very

408
00:26:02,872 --> 00:26:06,414
critical part, and talking about automation,

409
00:26:06,542 --> 00:26:10,498
we want to have a knowledge base. So every result

410
00:26:10,584 --> 00:26:14,958
that you got from the security rates engineering experiments,

411
00:26:15,054 --> 00:26:18,454
imagining that you were able to construct supports. So for us

412
00:26:18,492 --> 00:26:22,274
in our tool cloud strike, every security based engineering

413
00:26:22,322 --> 00:26:25,974
experiment had a report and that report has put into a

414
00:26:26,012 --> 00:26:30,042
sort of knowledgebase which might be just some database where you

415
00:26:30,096 --> 00:26:33,974
put in your supports. And these gives you access to greater

416
00:26:34,022 --> 00:26:37,606
possibilities. For example, you can create cloud watch rules

417
00:26:37,638 --> 00:26:41,614
to trigger alarms for specific events. You could create

418
00:26:41,652 --> 00:26:45,406
rules for your cloud security posture management system.

419
00:26:45,508 --> 00:26:49,306
You could create rates for identity and access management

420
00:26:49,498 --> 00:26:53,826
analyzer. You could also do

421
00:26:53,848 --> 00:26:57,950
a lot of things. So what we see here is nowadays

422
00:26:58,110 --> 00:27:02,420
actually the concept of SIM is actually getting

423
00:27:03,430 --> 00:27:07,254
obsolete because SIM systems are beginning to

424
00:27:07,292 --> 00:27:10,918
struggle to even manage data or to be able to analyze security

425
00:27:11,004 --> 00:27:15,078
information properly. And we see here

426
00:27:15,164 --> 00:27:19,114
that it's possible that security chaos engineering is put into the so

427
00:27:19,152 --> 00:27:22,890
called security data lake, which is more becoming,

428
00:27:23,310 --> 00:27:26,858
more and more becoming a much preferred way for putting together

429
00:27:27,024 --> 00:27:30,186
security information so that you can get some sort of

430
00:27:30,208 --> 00:27:33,546
intelligence from it. So security based engineering,

431
00:27:33,658 --> 00:27:37,502
the reports you get can be put into a security data

432
00:27:37,556 --> 00:27:41,594
leak. And where you have other resources of information like the threats intelligence

433
00:27:41,642 --> 00:27:44,740
source, you're getting a lot of information from

434
00:27:45,990 --> 00:27:50,030
threat intelligence source. The feeds that tell you about things like malicious

435
00:27:50,190 --> 00:27:53,870
ip addresses and things like that. You have the ETL

436
00:27:53,950 --> 00:27:57,490
things, all the log analytics systems,

437
00:27:57,650 --> 00:28:01,522
they push their knowledge, they push the output of the analysis

438
00:28:01,586 --> 00:28:05,702
to this place, to this central data

439
00:28:05,756 --> 00:28:09,254
leak. We see that security case

440
00:28:09,292 --> 00:28:12,726
and generated results can also eventually live in such

441
00:28:12,828 --> 00:28:16,202
a security data lake and give users much,

442
00:28:16,256 --> 00:28:20,042
much better and much more contextual information to use

443
00:28:20,096 --> 00:28:23,294
to harden their security system. We also

444
00:28:23,332 --> 00:28:27,258
like to point you to some of the papers we wrote. So these first sets

445
00:28:27,274 --> 00:28:30,606
of papers, two patterns were written where we cyber

446
00:28:30,708 --> 00:28:33,918
security engineer security case engineering methods,

447
00:28:34,014 --> 00:28:37,374
firstly to evaluate a cloud security posture

448
00:28:37,422 --> 00:28:40,990
management system to see if it functions as expected.

449
00:28:41,070 --> 00:28:45,234
And the other paper was based for

450
00:28:45,272 --> 00:28:49,000
incident response, where we were also trying to see how

451
00:28:49,930 --> 00:28:53,702
an incident response system works. If it works as

452
00:28:53,756 --> 00:28:57,254
fast, has it should work, if it's slow. And we think these are

453
00:28:57,292 --> 00:29:01,046
also very good use cases. There are also two papers we wrote

454
00:29:01,078 --> 00:29:04,678
that focus squarely on security rates engineering.

455
00:29:04,854 --> 00:29:08,700
We took a deep dive into this subject and tried to understand

456
00:29:09,810 --> 00:29:13,470
from an academic perspective as well as from a practical

457
00:29:14,690 --> 00:29:18,670
perspective, what are the connections with existing literature

458
00:29:19,090 --> 00:29:22,730
that are related to this field of fault injection.

459
00:29:22,810 --> 00:29:26,818
And we saw there is quite an existing work about

460
00:29:26,904 --> 00:29:30,494
security fault injection, more under the canopy

461
00:29:30,542 --> 00:29:33,794
of dependability. And we

462
00:29:33,832 --> 00:29:37,798
think it's kind of exciting to explore these

463
00:29:37,884 --> 00:29:42,370
related works, to have a better understanding of security based engineering.

464
00:29:42,450 --> 00:29:45,734
And last is, I want to point out the security based

465
00:29:45,772 --> 00:29:49,242
engineering book that was released actually

466
00:29:49,296 --> 00:29:52,922
last year. And we had a very good opportunity to contribute to these

467
00:29:52,976 --> 00:29:57,098
book. And if you are really interested in understanding security

468
00:29:57,184 --> 00:30:00,682
chaos engineering, I will really recommend this book to you.

469
00:30:00,736 --> 00:30:04,462
And also you can also have a look at our

470
00:30:04,516 --> 00:30:07,754
publications and you will have a much better understanding

471
00:30:07,802 --> 00:30:11,726
of this field. So this brings me to the end of my

472
00:30:11,748 --> 00:30:15,262
talk. Thank you so much for staying along

473
00:30:15,396 --> 00:30:18,974
and feel free to shoot a mail to me or to reach

474
00:30:19,012 --> 00:30:22,574
out to me in case you want to learn more about what I'm doing.

475
00:30:22,692 --> 00:30:23,822
Thank you very much.

