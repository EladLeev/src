1
00:00:23,050 --> 00:00:26,642
Hi there. Thank you for joining my session.

2
00:00:26,786 --> 00:00:30,440
Today we will talk about machine learning and security.

3
00:00:30,890 --> 00:00:35,250
So the title of my talk is hacking and securing machine learning environments

4
00:00:35,330 --> 00:00:39,714
and systems. So, to introduce myself, I joshua Arvin Lat,

5
00:00:39,842 --> 00:00:43,634
and I am the chief technology officer of Nuworks

6
00:00:43,682 --> 00:00:47,346
Interactive Labs. I'm also an AWS

7
00:00:47,378 --> 00:00:51,306
machine learning hero. And I am the author of the book Machine

8
00:00:51,338 --> 00:00:55,166
Learning with Amazon Sagemaker cookbook. So if you're interested

9
00:00:55,348 --> 00:00:59,482
in doing some hands on work on performing machine learning experiments

10
00:00:59,546 --> 00:01:02,766
and deployments in the AWS cloud, then this may

11
00:01:02,788 --> 00:01:05,986
be the book for you. So, enough about

12
00:01:06,008 --> 00:01:09,762
myself and enough about my book. Let's now go straight into

13
00:01:09,816 --> 00:01:13,330
talking about machine learning and securing. So let's start first

14
00:01:13,400 --> 00:01:15,880
with machine learning and the machine learning process.

15
00:01:16,650 --> 00:01:20,630
Let's say that we want to build and deploy

16
00:01:21,210 --> 00:01:25,126
an image classification model. It's a machine learning model where

17
00:01:25,308 --> 00:01:28,818
we pass in, let's say an image, an image

18
00:01:28,834 --> 00:01:32,522
of a cat to the code. And what you want your model

19
00:01:32,576 --> 00:01:35,674
to do is CTO check if

20
00:01:35,712 --> 00:01:38,794
that model is a cat or not a cat.

21
00:01:38,912 --> 00:01:42,558
So if it is a can, the output should be one.

22
00:01:42,724 --> 00:01:46,158
If it's not a cat, then the output would be a zero.

23
00:01:46,324 --> 00:01:50,046
So your machine learning model is able to perform

24
00:01:50,228 --> 00:01:54,034
some intelligent task that it's programmed to

25
00:01:54,072 --> 00:01:57,826
do. So there are other applications of machine learning, let's say

26
00:01:57,848 --> 00:02:01,518
sentiment analysis. Let's say you want to perform forecast,

27
00:02:01,694 --> 00:02:05,326
you want to perform some regression and classification,

28
00:02:05,518 --> 00:02:08,200
then you would be able to do that with machine learning.

29
00:02:08,890 --> 00:02:12,680
So in order to build models, you would of course, need data.

30
00:02:13,370 --> 00:02:16,774
And in order to be able to perform and build that

31
00:02:16,812 --> 00:02:20,554
model, you have to follow a process called the

32
00:02:20,592 --> 00:02:24,426
machine learning process. So you can see in the screen a

33
00:02:24,448 --> 00:02:27,740
simplified version of this process. And again,

34
00:02:28,190 --> 00:02:31,846
you would need to start with data. So most of the time,

35
00:02:31,968 --> 00:02:35,246
in order to have a model, you would need to have data in

36
00:02:35,268 --> 00:02:38,586
order to train that model, especially for supervised classification

37
00:02:38,698 --> 00:02:42,446
requirements. So here we can see that you

38
00:02:42,468 --> 00:02:45,842
start with data collection. Next, you prepare and clean

39
00:02:45,896 --> 00:02:49,758
the data, you visualize it, and then you perform feature engineering

40
00:02:49,934 --> 00:02:53,474
in order to prepare your model. In order to prepare your

41
00:02:53,512 --> 00:02:56,786
data for model training. Once your

42
00:02:56,808 --> 00:02:58,680
data is ready for a model training,

43
00:02:59,690 --> 00:03:03,782
you use certain algorithms and you

44
00:03:03,836 --> 00:03:07,662
perform and provide specific parameters

45
00:03:07,746 --> 00:03:11,818
and hyperparameters, CTO chain and tune your model. So you

46
00:03:11,824 --> 00:03:15,114
would produce a model which can then be

47
00:03:15,152 --> 00:03:18,278
used to perform predictions or inference.

48
00:03:18,454 --> 00:03:21,614
So at these point, now that you have a model, if you have

49
00:03:21,652 --> 00:03:25,338
a new data or new set of records,

50
00:03:25,434 --> 00:03:29,070
you can now use those records as input, and your model

51
00:03:29,140 --> 00:03:32,190
can be used to perform specific predictions.

52
00:03:33,650 --> 00:03:36,766
So after you have a model, you need to perform model evaluation,

53
00:03:36,878 --> 00:03:40,706
because the goal of your model is to be as accurate as possible.

54
00:03:40,888 --> 00:03:44,660
Let's say you have an image of a dog. You don't want your image to

55
00:03:45,830 --> 00:03:49,526
tell you that it's a cat. So the goal is for your model to

56
00:03:49,548 --> 00:03:52,294
make as many correct answers as possible,

57
00:03:52,492 --> 00:03:55,974
and that's the goal of model evaluation. So once you are happy

58
00:03:56,012 --> 00:04:00,022
with your model, you now deploy it. So that's the basic

59
00:04:00,086 --> 00:04:03,770
machine learning process. That's the simplified machine learning process.

60
00:04:03,920 --> 00:04:07,914
And in real life, you would encounter requirements where you

61
00:04:07,952 --> 00:04:11,594
will have to perform redeployments, meaning that

62
00:04:11,632 --> 00:04:15,246
you have an existing model in place and then given a new data,

63
00:04:15,348 --> 00:04:18,462
given a new data set or an updated data set,

64
00:04:18,516 --> 00:04:21,678
you would have to train a new model, compare it

65
00:04:21,684 --> 00:04:25,726
with the previous one, and then you can replace it and ensure

66
00:04:25,838 --> 00:04:29,250
that there's zero downtime. So, as you can see,

67
00:04:29,400 --> 00:04:33,326
this entire process involves both machine learning and engineering.

68
00:04:33,438 --> 00:04:36,762
That's why there's something called machine learning engineering,

69
00:04:36,846 --> 00:04:40,166
where you have to take care of the infrastructure, you have

70
00:04:40,188 --> 00:04:43,954
to take care of the application in order to deploy

71
00:04:44,002 --> 00:04:46,870
and host and manage your models in production.

72
00:04:48,270 --> 00:04:52,486
In order to make the lives of data scientists and machine

73
00:04:52,518 --> 00:04:55,770
learning engineers easier, a lot of machine learning

74
00:04:55,840 --> 00:05:00,054
practitioners make use of specific frameworks and

75
00:05:00,192 --> 00:05:04,160
platforms and services in order to automate certain

76
00:05:04,930 --> 00:05:08,910
parts of the work. For example, instead of building

77
00:05:08,980 --> 00:05:13,090
your own custom solution using

78
00:05:13,160 --> 00:05:15,730
custom scripts, custom formulas,

79
00:05:16,470 --> 00:05:20,702
we can basically proceed with using scripts

80
00:05:20,766 --> 00:05:24,818
or even services which can help automate the work for us. So as

81
00:05:24,824 --> 00:05:28,566
you can see in the screen, this is an example of how a service like

82
00:05:28,588 --> 00:05:32,226
Sagemaker is used to compute for certain metrics

83
00:05:32,258 --> 00:05:35,654
like the class imbalance scores, DPPL and

84
00:05:35,692 --> 00:05:39,998
treatment equality, so that we can easily analyze

85
00:05:40,034 --> 00:05:43,386
and understand our data and the model. So this is

86
00:05:43,408 --> 00:05:47,258
very helpful when it comes to dealing with requirements, when it

87
00:05:47,264 --> 00:05:50,746
comes to fairness. And you can technically use siege maker also to

88
00:05:50,768 --> 00:05:54,074
analyze models and how it behaves,

89
00:05:54,122 --> 00:05:57,534
especially when you're dealing with, let's say, neural networks. If it's hard

90
00:05:57,572 --> 00:06:01,658
to understand how your model works, maybe you can check its behavior

91
00:06:01,834 --> 00:06:05,070
through different teams and through different formulas.

92
00:06:07,250 --> 00:06:10,574
Now that we have vector understanding of the machine

93
00:06:10,622 --> 00:06:13,742
learning process and the different approaches,

94
00:06:13,806 --> 00:06:17,106
especially with the usage of services and platforms,

95
00:06:17,218 --> 00:06:21,094
let's proceed with talking about security. When thinking

96
00:06:21,132 --> 00:06:24,934
about security, usually people think of

97
00:06:24,972 --> 00:06:28,294
the best practices. People think that when they follow the best

98
00:06:28,332 --> 00:06:32,694
practices, they think that their application or their infrastructure

99
00:06:32,822 --> 00:06:36,490
would be secure. Unfortunately, this is not the case,

100
00:06:36,640 --> 00:06:40,126
because in order to know if your system is secure, you have CTO

101
00:06:40,148 --> 00:06:44,106
test it. These is very similar to testing load

102
00:06:44,138 --> 00:06:47,614
testing. If your client asks you, can your

103
00:06:47,652 --> 00:06:51,482
system support 100 clients

104
00:06:51,546 --> 00:06:55,250
or users at the same time? You cannot just say,

105
00:06:55,400 --> 00:06:58,820
yes, it can support it without actually testing it.

106
00:06:59,350 --> 00:07:02,658
So what we want to do here is if we want to test if something

107
00:07:02,744 --> 00:07:06,238
is working or not, then we literally have to

108
00:07:06,264 --> 00:07:10,278
use certain set of tools and processes to test

109
00:07:10,444 --> 00:07:13,986
and validate our own assumptions. So in the case of load

110
00:07:14,018 --> 00:07:18,166
testing, we use a load testing tool. If we're talking about

111
00:07:18,348 --> 00:07:21,446
security testing, we use the appropriate set of tools.

112
00:07:21,558 --> 00:07:25,526
We may use the security scanners, we may use certain tools

113
00:07:25,558 --> 00:07:28,826
to assess and check different vulnerabilities of

114
00:07:28,848 --> 00:07:32,446
our application and infrastructure. And that's basically part of the

115
00:07:32,468 --> 00:07:35,594
tool chain and toolkit needed to assess

116
00:07:35,642 --> 00:07:38,320
your environments. At the same time,

117
00:07:38,690 --> 00:07:42,334
it's important that we keep in mind that we are trying

118
00:07:42,372 --> 00:07:45,694
to protect our system from attackers.

119
00:07:45,822 --> 00:07:49,460
So we have to assume the role and

120
00:07:50,070 --> 00:07:54,178
mindset and approach of these hackers, as this is

121
00:07:54,264 --> 00:07:57,526
for them a game, this is for them a puzzle, and they

122
00:07:57,548 --> 00:08:00,678
will be given a set of resources to attack,

123
00:08:00,844 --> 00:08:04,946
and they will follow a certain set of protocols

124
00:08:04,978 --> 00:08:09,050
and processes in order to understand the environment and perform

125
00:08:09,120 --> 00:08:12,058
a sequence of attacks. For example,

126
00:08:12,224 --> 00:08:15,654
if they're given, let's say, five servers, the first thing that they'll

127
00:08:15,702 --> 00:08:18,746
check is what's visible to me.

128
00:08:18,848 --> 00:08:23,434
What can I easily access? Is these system configured

129
00:08:23,482 --> 00:08:26,830
properly, which systems can attack right away?

130
00:08:26,980 --> 00:08:30,030
If a hacker is able to attack a certain server,

131
00:08:31,250 --> 00:08:34,354
if that hacker is able to, let's say,

132
00:08:34,472 --> 00:08:37,986
get access by exploiting a

133
00:08:38,008 --> 00:08:41,634
certain set of vulnerabilities resources, would they be

134
00:08:41,672 --> 00:08:45,334
able to perform privilege escalation next? And so

135
00:08:45,372 --> 00:08:48,966
on. So after exploiting one

136
00:08:48,988 --> 00:08:52,194
of the vulnerabilities and having access to the servers,

137
00:08:52,242 --> 00:08:55,382
they may try to use that server to access the other

138
00:08:55,436 --> 00:08:59,242
servers in the infrastructure. So once they are

139
00:08:59,296 --> 00:09:01,820
able to reach the inner ones,

140
00:09:02,190 --> 00:09:06,278
the servers which have direct connection to the databases,

141
00:09:06,454 --> 00:09:09,450
these, that's the time these will try to extract the data.

142
00:09:09,600 --> 00:09:13,274
They might try to steal the passwords, or they might try to extract

143
00:09:13,322 --> 00:09:16,734
everything from that server and send it to

144
00:09:16,772 --> 00:09:20,382
their own machines. And that's their way. That's where they will use

145
00:09:20,436 --> 00:09:24,274
other tools to basically maybe

146
00:09:24,472 --> 00:09:27,810
get the passwords or maybe use the data

147
00:09:27,880 --> 00:09:31,794
to attack other systems. Finally, they may

148
00:09:31,832 --> 00:09:35,410
use the other servers they have already compromised to attack

149
00:09:35,480 --> 00:09:39,414
other servers as well. So again, there are a lot of things which

150
00:09:39,452 --> 00:09:42,854
can be performed by attackers. So from your

151
00:09:42,892 --> 00:09:46,166
point of view, if you want to secure something, you have to

152
00:09:46,188 --> 00:09:49,900
understand how your systems can be attacked. At the same time

153
00:09:50,430 --> 00:09:53,658
you have to assume that this will be a

154
00:09:53,664 --> 00:09:57,686
combination of attacks. Some attacks may be performed

155
00:09:57,718 --> 00:10:02,298
and directed towards the human entities,

156
00:10:02,394 --> 00:10:06,250
meaning the employees. So if an employee gets attacked,

157
00:10:06,330 --> 00:10:09,886
maybe one of your colleagues may receive an

158
00:10:09,908 --> 00:10:13,586
email, and then when that person opens a

159
00:10:13,608 --> 00:10:17,954
link in the email, then his or her machine would

160
00:10:17,992 --> 00:10:21,518
be compromised already. So that machine

161
00:10:21,614 --> 00:10:25,598
may have access on internal network, and that's where the attack may

162
00:10:25,624 --> 00:10:29,590
happen. So again, there are different areas and different

163
00:10:29,660 --> 00:10:32,914
things an attacked will do. So it's better that you are prepared

164
00:10:32,962 --> 00:10:36,854
on what's possible whenever you're trying

165
00:10:36,892 --> 00:10:38,220
to protect your system.

166
00:10:40,590 --> 00:10:43,834
So a lot of companies know this, but in real life,

167
00:10:43,872 --> 00:10:47,594
in practice, this is usually not the case, as a lot of companies

168
00:10:47,712 --> 00:10:51,526
often deprioritize security. For one thing,

169
00:10:51,648 --> 00:10:55,166
they would prioritize the short term financial objectives and the

170
00:10:55,188 --> 00:10:58,586
long term financial objectives, because there's nothing to secure

171
00:10:58,618 --> 00:11:03,370
if there's no business in the first place, right? That's how people

172
00:11:03,460 --> 00:11:06,674
think. At the same time, it's already hard

173
00:11:06,712 --> 00:11:09,154
to keep the client and the customers happy.

174
00:11:09,352 --> 00:11:12,770
So in terms of the ratio and the focus areas,

175
00:11:13,190 --> 00:11:17,046
your company may spend or may have 90% or

176
00:11:17,068 --> 00:11:20,806
95% of the entire population of the entire team

177
00:11:20,988 --> 00:11:24,790
focused on the first two or three

178
00:11:24,940 --> 00:11:28,242
objectives here, right? Short term financial objectives,

179
00:11:28,306 --> 00:11:31,654
long term financial objectives, and client and customer happiness,

180
00:11:31,782 --> 00:11:34,442
because that alone is already hard.

181
00:11:34,576 --> 00:11:38,614
So if we add more things to this list, of course that would be deprioritized,

182
00:11:38,742 --> 00:11:42,480
and that's what's happening usually to compliance, to security,

183
00:11:43,170 --> 00:11:46,158
even to the operational excellence part.

184
00:11:46,324 --> 00:11:49,934
A lot of these things get deprioritized and it's our duty to

185
00:11:49,972 --> 00:11:53,534
remind everyone how important security is. Because if

186
00:11:53,572 --> 00:11:56,750
your data gets hacked, if your systems get attacked

187
00:11:56,830 --> 00:12:00,274
and your data is stolen, then there's a big chance that

188
00:12:00,312 --> 00:12:03,554
your company might close. Because of course,

189
00:12:03,672 --> 00:12:06,934
if the passwords and the credentials are stolen and

190
00:12:06,972 --> 00:12:10,614
your customers get affects, then customers would lose trust

191
00:12:10,732 --> 00:12:14,214
in your company. So be very careful about these

192
00:12:14,252 --> 00:12:17,778
topic, because security is a complex field and

193
00:12:17,884 --> 00:12:22,010
it's super hard to secure systems.

194
00:12:23,870 --> 00:12:27,446
That said, you need to have the right mindset and the right strategies

195
00:12:27,558 --> 00:12:31,290
when securing ML systems and environments.

196
00:12:31,450 --> 00:12:36,190
So when talking about machine learning and machine learning engineering projects,

197
00:12:36,690 --> 00:12:40,222
we have to understand what's available to us,

198
00:12:40,276 --> 00:12:43,620
we have to understand what hackers would want.

199
00:12:44,470 --> 00:12:47,954
So here we can see in the screen that we

200
00:12:47,992 --> 00:12:51,646
have control of the custom implementation aspect.

201
00:12:51,758 --> 00:12:55,330
If we have custom code, if we have custom scripts, then yes,

202
00:12:55,400 --> 00:12:58,934
that's in our control, that's under our control, that's under our

203
00:12:58,972 --> 00:13:02,934
responsibility. We have to make sure that everything we put inside

204
00:13:03,132 --> 00:13:06,306
that platform or service is properly checked

205
00:13:06,338 --> 00:13:10,106
and secured. At the same time, we have to ensure that the

206
00:13:10,128 --> 00:13:14,374
service or tool that we're using is properly configured. A lot of attacks

207
00:13:14,422 --> 00:13:18,246
are performed on misconfigured servers or systems,

208
00:13:18,358 --> 00:13:21,440
so it is important that we properly secure this as well.

209
00:13:21,890 --> 00:13:24,160
So the ML service that we will use,

210
00:13:24,930 --> 00:13:29,342
or if we are not using an ML service, that's critical also,

211
00:13:29,476 --> 00:13:33,050
because the type of security strategies that we will implement

212
00:13:33,210 --> 00:13:36,546
depend whether we're using an ML service or not.

213
00:13:36,648 --> 00:13:40,386
So let's say that we're using tensorflow or

214
00:13:40,408 --> 00:13:43,602
Pytorch or Mxnet on top of a server, like an easy

215
00:13:43,656 --> 00:13:47,302
to instance. Then there we're making use of an open

216
00:13:47,356 --> 00:13:51,186
source framework to run training experiments

217
00:13:51,218 --> 00:13:54,358
and deployments inside a server we can control.

218
00:13:54,524 --> 00:13:58,354
So the hardware is managed by AWS,

219
00:13:58,482 --> 00:14:02,362
so we don't need to worry about that, because that's being taken

220
00:14:02,416 --> 00:14:05,926
care of AWS themselves, at least when you're

221
00:14:05,958 --> 00:14:09,738
running machine learning experiments on AWS. So what about the

222
00:14:09,744 --> 00:14:13,278
operating system and the applications inside

223
00:14:13,444 --> 00:14:17,262
that server? We need to take care of that, because that's under

224
00:14:17,316 --> 00:14:20,718
our control. So there's something called a shared responsibility model,

225
00:14:20,884 --> 00:14:25,002
and that model should be similar across

226
00:14:25,076 --> 00:14:28,754
all the other different cloud platforms. So make

227
00:14:28,792 --> 00:14:32,114
sure you know which ones you need to take care of. And you also

228
00:14:32,152 --> 00:14:35,506
need to make sure that the different services and tools

229
00:14:35,538 --> 00:14:37,030
are configured properly.

230
00:14:39,770 --> 00:14:43,586
So now it's time, we think like a hacker.

231
00:14:43,698 --> 00:14:47,510
All right, so let's try to do a quick simulation,

232
00:14:47,850 --> 00:14:51,894
and let's say that we have this network. So there's

233
00:14:51,942 --> 00:14:54,870
a public subnet, and then there's a private subnet.

234
00:14:54,950 --> 00:14:58,326
In the public subnet, we can have these, the web servers.

235
00:14:58,518 --> 00:15:02,650
And those web servers are accessible globally.

236
00:15:02,730 --> 00:15:06,446
So the outside world can access everything inside the green

237
00:15:06,548 --> 00:15:09,914
region and in the blue region, the private

238
00:15:09,962 --> 00:15:13,338
subnet, we have these, these database servers.

239
00:15:13,434 --> 00:15:17,406
So of course, since the data should be protected,

240
00:15:17,518 --> 00:15:20,130
those are stored inside the private subnet.

241
00:15:21,110 --> 00:15:24,738
So if you were a hacker, of course, you cannot directly attack the ones in

242
00:15:24,744 --> 00:15:28,774
the private subnet. You would probably have to look for the

243
00:15:28,812 --> 00:15:32,118
servers in the public subnet first. So, as you can see,

244
00:15:32,204 --> 00:15:35,846
we have already highlighted and put a box and tagged it

245
00:15:35,868 --> 00:15:39,174
as high risk because anyone can access that,

246
00:15:39,212 --> 00:15:42,646
including the attackers. They will try to run different scripts,

247
00:15:42,678 --> 00:15:46,234
they will use different tools to assess the security of the server and

248
00:15:46,272 --> 00:15:49,386
applications running there, and then they will perform an

249
00:15:49,408 --> 00:15:53,086
attack. If they are able to compromise that, that server will

250
00:15:53,108 --> 00:15:56,686
be used to attack the other servers. So what you need to

251
00:15:56,708 --> 00:16:00,334
do is to add multiple layers of security,

252
00:16:00,532 --> 00:16:03,426
CTO, secure the different aspects of your application,

253
00:16:03,608 --> 00:16:07,602
and you need to prioritize what's highlighted and

254
00:16:07,656 --> 00:16:10,802
tagged as high risk. So that's the reason why the green

255
00:16:10,856 --> 00:16:14,766
area, the public subnet, is tagged

256
00:16:14,878 --> 00:16:18,338
and sometimes labeled as a DMZ, a demilitarized

257
00:16:18,354 --> 00:16:22,150
zone. So you need to protect everything in that DMZ.

258
00:16:24,250 --> 00:16:28,014
So now let's try to implement the same set of concepts

259
00:16:28,162 --> 00:16:31,722
in our machine learning process and in our machine learning

260
00:16:31,776 --> 00:16:35,402
environments. So here are some

261
00:16:35,456 --> 00:16:38,966
of the applications and services and tools a machine

262
00:16:38,998 --> 00:16:42,558
learning practitioner would use. Of course, if you're a data scientist or a

263
00:16:42,564 --> 00:16:46,234
machine learning engineer, you may be using Jupyter notebooks.

264
00:16:46,362 --> 00:16:49,722
And that Jupyter notebook will be running on infrastructure

265
00:16:49,786 --> 00:16:53,630
such as servers or instances or

266
00:16:53,700 --> 00:16:56,686
virtual machines. In some cases,

267
00:16:56,718 --> 00:17:00,562
you will have an ML service to help you manage running

268
00:17:00,616 --> 00:17:03,986
these notebook instances for you. So on top of

269
00:17:04,008 --> 00:17:07,374
that Jupiter notebook, you will be running custom code and you will download

270
00:17:07,422 --> 00:17:10,938
the data sets. So in terms of like the holler

271
00:17:10,974 --> 00:17:14,486
convention here, you will see that the ones in white are the ones you

272
00:17:14,508 --> 00:17:18,170
can control. And if you're not able to manage these things

273
00:17:18,240 --> 00:17:22,214
properly, then hackers may be able to take advantage

274
00:17:22,262 --> 00:17:25,370
of that and use it to compromise your system.

275
00:17:25,520 --> 00:17:29,830
So how would that work? If your infrastructure is something that

276
00:17:29,920 --> 00:17:33,594
is valuable to hackers, maybe they can run some bitcoin

277
00:17:33,642 --> 00:17:37,566
mining stuff there. They may try to write some

278
00:17:37,588 --> 00:17:41,450
malicious code or write some malicious scripts

279
00:17:41,610 --> 00:17:45,314
inside some of the packages and dependencies that you may use.

280
00:17:45,432 --> 00:17:49,826
So when you run your scripts, suddenly the

281
00:17:49,848 --> 00:17:53,298
hacker's malicious code would run as well. And what will happen

282
00:17:53,384 --> 00:17:57,462
is your hacker would be able to run

283
00:17:57,516 --> 00:18:01,154
things inside your infrastructure, and out of nowhere,

284
00:18:01,282 --> 00:18:04,166
the entire infrastructure has been compromised already.

285
00:18:04,348 --> 00:18:07,506
So how are hackers able to do this? They are able

286
00:18:07,548 --> 00:18:11,482
to do this by adding some

287
00:18:11,536 --> 00:18:14,380
payload, which, let's say, opens a port.

288
00:18:14,750 --> 00:18:18,266
So if there's a server, maybe before the

289
00:18:18,288 --> 00:18:22,398
script is executed, let's say port 4000 is

290
00:18:22,564 --> 00:18:26,170
closed. So when you run your script,

291
00:18:26,330 --> 00:18:28,960
the malicious payload runs as well.

292
00:18:29,490 --> 00:18:32,800
And then suddenly port 4000 is open.

293
00:18:33,110 --> 00:18:36,574
So your servers, port 4000 has been opened

294
00:18:36,702 --> 00:18:40,510
by the malicious payload. Now your hacker,

295
00:18:40,670 --> 00:18:44,546
since it knows that that port is open, he will now

296
00:18:44,648 --> 00:18:46,310
connect to your server,

297
00:18:47,210 --> 00:18:50,326
and he will be able to run commands as

298
00:18:50,348 --> 00:18:54,326
if it was his or her, or her own machine or computer.

299
00:18:54,508 --> 00:18:58,274
So if your hacker wants to download scripts,

300
00:18:58,322 --> 00:19:02,810
if your hacker wants to navigate through the files, if your hacker wants to

301
00:19:02,960 --> 00:19:06,540
steal the passwords and the data, then that is now possible.

302
00:19:06,910 --> 00:19:10,614
And if the machine that you have has excessive

303
00:19:10,662 --> 00:19:14,554
permissions, then it may be able to do other things like delete

304
00:19:14,602 --> 00:19:18,174
resources. It may be able to create resources and so on.

305
00:19:18,292 --> 00:19:22,834
So be very careful because usually the cloud environments have

306
00:19:22,872 --> 00:19:26,274
something called roles, roles and

307
00:19:26,392 --> 00:19:29,842
security entities, which allow them to perform

308
00:19:29,896 --> 00:19:33,634
operations without API keys. So be very

309
00:19:33,672 --> 00:19:37,286
careful about that because hackers may be able to

310
00:19:37,308 --> 00:19:41,298
use that either for privilege escalation or for performing

311
00:19:41,394 --> 00:19:42,790
malicious actions.

312
00:19:44,570 --> 00:19:47,994
So this is one good example. So let's say that

313
00:19:48,112 --> 00:19:52,010
you decided to use a pre built

314
00:19:52,080 --> 00:19:55,770
model prepared by someone else, someone that

315
00:19:55,840 --> 00:19:58,300
is outside your company.

316
00:19:58,990 --> 00:20:02,234
So that means that instead of using your own

317
00:20:02,272 --> 00:20:05,630
data to train a model, you would be making use of a model

318
00:20:05,700 --> 00:20:09,482
trained by someone else. So that all you need to worry about is model deployment.

319
00:20:09,626 --> 00:20:12,862
So when you're writing custom scripts, you would probably use

320
00:20:12,916 --> 00:20:16,466
something like this where you use a library and then

321
00:20:16,488 --> 00:20:20,386
you use the load method or function to load a pre

322
00:20:20,408 --> 00:20:24,146
built model so that you can use that model for prediction or

323
00:20:24,168 --> 00:20:28,006
inference, right? So what if that model had

324
00:20:28,108 --> 00:20:31,926
a malicious payload or an instruction similar to

325
00:20:31,948 --> 00:20:35,718
what I discussed earlier? And then when you run the code

326
00:20:35,884 --> 00:20:39,318
which loads these model, then suddenly your

327
00:20:39,404 --> 00:20:43,466
infrastructure and your application gets compromised. So what you

328
00:20:43,488 --> 00:20:47,370
need to do is you have to review each of the libraries that you're using

329
00:20:47,520 --> 00:20:50,638
and how it impacts these securing of your system,

330
00:20:50,804 --> 00:20:54,766
especially if there are known vulnerabilities and issues

331
00:20:54,868 --> 00:20:58,462
like this. So make sure to read and look

332
00:20:58,516 --> 00:21:02,486
for the documentation sites because these are usually documented

333
00:21:02,538 --> 00:21:06,210
either here or in the issues or security section.

334
00:21:08,550 --> 00:21:12,420
So now when you're talking about machine learning and machine learning services,

335
00:21:12,870 --> 00:21:16,100
what you need to do is you need to know

336
00:21:16,570 --> 00:21:19,778
what you're trying to do and what you're trying to prepare.

337
00:21:19,874 --> 00:21:23,894
So when you're running training jobs in the cloud, you may use

338
00:21:23,932 --> 00:21:27,926
a machine learning service which converts input into

339
00:21:28,028 --> 00:21:31,370
output. And the output would be the model

340
00:21:31,440 --> 00:21:34,826
artifacts which can then be loaded later on to

341
00:21:34,848 --> 00:21:38,314
perform predictions. But before you are able CTO reach that point,

342
00:21:38,432 --> 00:21:41,766
you will need to pass in different parameters. So that

343
00:21:41,808 --> 00:21:45,120
includes the data set, that includes the custom code.

344
00:21:45,570 --> 00:21:49,566
And then in some cases you are given the opportunity to update the

345
00:21:49,588 --> 00:21:52,922
environment and prepare your own custom container image.

346
00:21:53,066 --> 00:21:56,414
So that if you were to use a library, like let's say that the transformers

347
00:21:56,462 --> 00:22:00,082
library, you would be able to use these hugging face

348
00:22:00,136 --> 00:22:03,730
stuff inside your training jobs.

349
00:22:04,230 --> 00:22:07,974
And at the same time you would have to add and provide the

350
00:22:08,012 --> 00:22:11,302
configuration parameters. So the one in the

351
00:22:11,436 --> 00:22:14,534
black box, that's something that you usually are

352
00:22:14,572 --> 00:22:17,926
not able to control and manage. So all you need to

353
00:22:17,948 --> 00:22:20,890
worry about would be the inputs and outputs.

354
00:22:21,310 --> 00:22:24,826
So in some cases you might think, hey, I'm going

355
00:22:24,848 --> 00:22:28,522
to use a custom container image, I'll just use something which has been built

356
00:22:28,576 --> 00:22:31,550
by another entity. You have to be very careful,

357
00:22:33,330 --> 00:22:36,442
because if there's a malicious process or a malicious

358
00:22:36,506 --> 00:22:40,894
application or script running inside a container from

359
00:22:40,932 --> 00:22:44,866
that container image, then if you run the training job,

360
00:22:45,048 --> 00:22:48,162
then the training job server might

361
00:22:48,216 --> 00:22:51,614
get compromised. And if the permissions

362
00:22:51,662 --> 00:22:55,150
and roles assigned to that server is a bit

363
00:22:55,240 --> 00:22:58,886
too powerful, then the malicious script may

364
00:22:58,908 --> 00:23:01,974
be able to perform actions like,

365
00:23:02,012 --> 00:23:05,462
let's say deleting different resources in your account or maybe

366
00:23:05,516 --> 00:23:09,606
creating new ones. It may be used to even perform privilege escalation

367
00:23:09,718 --> 00:23:13,206
from an account level. So be very careful because these input

368
00:23:13,238 --> 00:23:16,726
parameters are also the areas

369
00:23:16,838 --> 00:23:20,534
where your hacker might insert a payload or a malicious

370
00:23:20,582 --> 00:23:24,206
script. So when it comes to deployment, these are

371
00:23:24,228 --> 00:23:27,934
different options in different cloud platforms. And what is

372
00:23:27,972 --> 00:23:31,390
important is that the different types of attacks would also differ

373
00:23:31,540 --> 00:23:35,314
depending on where you deploy your model. So now

374
00:23:35,352 --> 00:23:39,506
that we have the model artifacts, now that we have already trained a model,

375
00:23:39,688 --> 00:23:43,314
it's now time that we build and

376
00:23:43,352 --> 00:23:46,898
deploy that model into its own inference endpoint.

377
00:23:46,994 --> 00:23:51,010
So what's an inference endpoint? An inference endpoint is simply

378
00:23:51,170 --> 00:23:54,486
maybe a web API where a model is

379
00:23:54,508 --> 00:23:58,566
hosted. So what your custom code would do if

380
00:23:58,588 --> 00:24:02,218
it's not automated yet by the ML service is your custom

381
00:24:02,304 --> 00:24:05,706
code would load the model, and then when there's a new

382
00:24:05,728 --> 00:24:09,610
request containing the input payload, the loaded model object

383
00:24:09,760 --> 00:24:13,434
would be used to perform a prediction with the input payload

384
00:24:13,482 --> 00:24:17,294
as the input, and then it would return an output back

385
00:24:17,332 --> 00:24:21,386
to the caller. So let's say that your model is an image classification

386
00:24:21,498 --> 00:24:24,890
model. If the input payload contains an image,

387
00:24:25,050 --> 00:24:28,546
these the output should either be a one or a zero. So if it's a

388
00:24:28,568 --> 00:24:32,098
cat, it's a one. If there's no can there, it's a zero.

389
00:24:32,264 --> 00:24:35,894
So that's basically the goal of your inference endpoint to

390
00:24:35,932 --> 00:24:39,554
just provide a web service accepting

391
00:24:39,602 --> 00:24:43,270
the input and securing the output as the response.

392
00:24:43,770 --> 00:24:47,320
So in some cases an ML service would provide

393
00:24:47,790 --> 00:24:51,942
more flexibility, like allowing you to introduce

394
00:24:52,086 --> 00:24:55,322
a custom container image. So if you are using certain

395
00:24:55,376 --> 00:24:59,114
libraries and packages, this is very helpful. However, you should be

396
00:24:59,152 --> 00:25:02,622
careful because similar to the previous example, you shouldn't use

397
00:25:02,676 --> 00:25:06,826
a container image provided by other entities.

398
00:25:06,938 --> 00:25:11,098
At the same time, your custom container image may include packages

399
00:25:11,194 --> 00:25:14,958
and installed tools which may be vulnerable.

400
00:25:15,134 --> 00:25:19,422
So let's say that at this point, your custom container image

401
00:25:19,566 --> 00:25:23,262
and the libraries installed there may have no vulnerabilities

402
00:25:23,326 --> 00:25:26,882
built. After one year, maybe new vulnerabilities

403
00:25:26,946 --> 00:25:30,694
would be discovered. And yeah, your inference endpoint would

404
00:25:30,812 --> 00:25:34,646
be vulnerable to different types of attacks. So make sure

405
00:25:34,748 --> 00:25:38,714
that your custom container images are scanned and check for

406
00:25:38,832 --> 00:25:41,610
vulnerabilities and weaknesses and risk.

407
00:25:45,230 --> 00:25:49,930
So at this point you will be asking me, hey, how about machine learning pipelines?

408
00:25:50,450 --> 00:25:53,646
We're running this automated pipeline. And would

409
00:25:53,668 --> 00:25:57,200
the same set of concepts be

410
00:25:57,970 --> 00:26:01,694
usable when it comes to ML pipelines? The answer is

411
00:26:01,732 --> 00:26:05,742
yes, especially if your pipelines involves,

412
00:26:05,806 --> 00:26:09,570
let's say, a controller, and then you have

413
00:26:09,720 --> 00:26:13,758
a different set of resources running the jobs.

414
00:26:13,854 --> 00:26:17,654
So let's say that your training job is running inside a server, and then your

415
00:26:17,692 --> 00:26:21,906
deployment step would of course provision

416
00:26:22,098 --> 00:26:25,334
a dedicated ML inference endpoint. So those would

417
00:26:25,372 --> 00:26:29,318
involve resources, and those are areas for attacks.

418
00:26:29,494 --> 00:26:33,258
So a pipeline simply just automates the entire process,

419
00:26:33,424 --> 00:26:37,546
and you should be protecting the resources involved in

420
00:26:37,568 --> 00:26:41,166
the ML flow in the ML pipelines. At the same time,

421
00:26:41,268 --> 00:26:44,878
you also have CTO harden and configure the security

422
00:26:44,964 --> 00:26:48,382
settings properly for the tool used to manage

423
00:26:48,436 --> 00:26:51,530
the pipeline. For example, if you're using Kubernetes

424
00:26:51,610 --> 00:26:55,534
and you're using some other open source tool to manage the ML flow

425
00:26:55,582 --> 00:26:58,370
and the ML pipeline,

426
00:26:59,190 --> 00:27:02,926
then you also have to configure and tweak

427
00:27:03,118 --> 00:27:07,046
the different open source tools and the different services that you're using to

428
00:27:07,068 --> 00:27:11,014
manage this entire workflow, because that will be an opportunity

429
00:27:11,132 --> 00:27:13,080
or an area for attack as well.

430
00:27:15,050 --> 00:27:18,298
So now we have talked about a lot of things when it

431
00:27:18,304 --> 00:27:22,570
comes to attacking different ML environments and systems.

432
00:27:23,390 --> 00:27:27,222
Let's now talk about the different solutions available in order to secure

433
00:27:27,286 --> 00:27:30,730
this. So the first practical way to secure

434
00:27:30,890 --> 00:27:34,334
a machine learning environment or system is

435
00:27:34,372 --> 00:27:36,990
CTO enable network isolation.

436
00:27:37,490 --> 00:27:41,166
So what do we mean by this? So network isolation is

437
00:27:41,188 --> 00:27:44,866
very powerful, especially if you accidentally use

438
00:27:45,048 --> 00:27:49,010
a script or maybe a container image which

439
00:27:49,080 --> 00:27:51,570
has malicious code or a malicious payload,

440
00:27:52,470 --> 00:27:56,390
usually when you're performing training with a specific algorithm.

441
00:27:56,810 --> 00:28:00,390
So you have this training job, and then your training job

442
00:28:00,540 --> 00:28:03,782
would be running a custom set of scripts or maybe a custom

443
00:28:03,836 --> 00:28:08,134
container. Generally that script

444
00:28:08,182 --> 00:28:12,570
or app or container would not need Internet connection.

445
00:28:13,150 --> 00:28:16,982
So if network isolation is enabled, the malicious

446
00:28:17,046 --> 00:28:20,794
code or the malicious payload or scripts would not

447
00:28:20,832 --> 00:28:24,366
be able CTO connect to the outside world. So it will not

448
00:28:24,388 --> 00:28:27,742
be able to send requests, it will not be able to

449
00:28:27,796 --> 00:28:30,974
transfer your data to some other server, or it will

450
00:28:31,012 --> 00:28:33,970
not be able to download additional malicious scripts.

451
00:28:34,310 --> 00:28:38,066
So this is how powerful network isolation is. Because if

452
00:28:38,088 --> 00:28:42,014
you're trying to train Xgboost, for example, I mean, why would your Xgboost

453
00:28:42,062 --> 00:28:45,054
script download other things, right?

454
00:28:45,112 --> 00:28:48,018
Ideally, it's already self contained.

455
00:28:48,114 --> 00:28:51,734
Whenever you're running training jobs, if, let's say

456
00:28:51,772 --> 00:28:55,286
you're using something like distributed model training,

457
00:28:55,468 --> 00:28:59,002
so let's say instead of one server you're going to

458
00:28:59,136 --> 00:29:03,194
chain a model built, you're going to use multiple servers instead.

459
00:29:03,392 --> 00:29:07,734
Ideally, network isolation still allows those different servers

460
00:29:07,782 --> 00:29:12,000
to talk to each other while training the model, and then

461
00:29:12,530 --> 00:29:16,654
those servers, that cluster is protected from the outside world.

462
00:29:16,852 --> 00:29:20,270
So yeah, if this is properly configured, then yes,

463
00:29:20,340 --> 00:29:24,066
this would help prevent different types of attacks, especially if

464
00:29:24,088 --> 00:29:27,666
there's a script which tries to connect CTo the outside world without your

465
00:29:27,688 --> 00:29:31,540
permission. At the same time,

466
00:29:31,990 --> 00:29:35,594
if you have something like a CI CD pipeline,

467
00:29:35,742 --> 00:29:39,762
then make sure that there's the manual approval step whenever

468
00:29:39,826 --> 00:29:43,538
possible. Because if everything is automated and nobody is checking

469
00:29:43,554 --> 00:29:47,094
it manually from time to time, then out of

470
00:29:47,132 --> 00:29:51,082
nowhere maybe your application will already have code

471
00:29:51,216 --> 00:29:55,002
that attacks other users or customers. You do not want everything to be super

472
00:29:55,056 --> 00:29:58,806
automated, that you're already forgetting about the manual processes

473
00:29:58,838 --> 00:30:02,318
and audits required to check the stability and security of

474
00:30:02,324 --> 00:30:06,222
your website. So in some cases your website

475
00:30:06,356 --> 00:30:10,078
would be used to attack other customers. For example,

476
00:30:10,164 --> 00:30:14,158
your website would be used to redirect users from your current website

477
00:30:14,324 --> 00:30:17,394
to some other website which has a lot of

478
00:30:17,432 --> 00:30:21,106
viruses or things that will automatically exploit the

479
00:30:21,128 --> 00:30:24,194
browser witnesses. So there are a lot of other attacks like that.

480
00:30:24,232 --> 00:30:28,146
And a simple redirect by a malicious payload

481
00:30:28,258 --> 00:30:31,974
can already cause a lot of harm. So make sure that your

482
00:30:32,012 --> 00:30:35,346
CI CD pipelines, if it exists, would have this manual approval

483
00:30:35,378 --> 00:30:38,634
step. In addition to this,

484
00:30:38,752 --> 00:30:42,550
it's better if you can automate vulnerability management.

485
00:30:42,710 --> 00:30:46,426
When talking about vulnerability management, you might probably be thinking of

486
00:30:46,528 --> 00:30:50,038
a security scanner. So you have a web endpoint.

487
00:30:50,214 --> 00:30:54,126
It may be your machine learning inference endpoint. So you run

488
00:30:54,148 --> 00:30:57,662
a scanner there and then your scanner would then list down all the different

489
00:30:57,716 --> 00:31:01,354
vulnerabilities and weaknesses of that endpoint.

490
00:31:01,482 --> 00:31:05,454
If there are misconfigured parameters and so on, your scanner

491
00:31:05,502 --> 00:31:09,298
may be able CTO detect it. But there may be a better way to

492
00:31:09,304 --> 00:31:12,798
do this. For example, what if you have a vulnerability

493
00:31:12,894 --> 00:31:16,966
assessment tool which not only scans a

494
00:31:16,988 --> 00:31:20,374
system from the outside, but it also scans the system

495
00:31:20,492 --> 00:31:24,514
from the inside. So for example, if you use something like Amazon

496
00:31:24,562 --> 00:31:28,498
inspector, it would automatically scan the servers

497
00:31:28,674 --> 00:31:31,866
and the container images. So if you were to use a

498
00:31:31,888 --> 00:31:36,006
container image for machine learning training or machine learning deployment,

499
00:31:36,198 --> 00:31:39,686
then if, let's say your custom container image contains

500
00:31:39,718 --> 00:31:43,742
a vulnerability or some other risk, or maybe

501
00:31:43,796 --> 00:31:47,610
a library which has a vulnerability, then your vulnerability

502
00:31:47,690 --> 00:31:51,502
assessment tool would be able to detect that even before it gets

503
00:31:51,556 --> 00:31:55,234
deployed. So that's pretty powerful because a tool

504
00:31:55,272 --> 00:31:59,410
like Amazon inspector would be able to run automatically

505
00:31:59,750 --> 00:32:03,220
every time there's a change. So if your server changes,

506
00:32:03,990 --> 00:32:07,966
Amazon inspector would run. If a new container

507
00:32:07,998 --> 00:32:11,862
image gets pushed then it would run again. So all you need to do is

508
00:32:11,916 --> 00:32:15,974
check the list of vulnerabilities. Here you need to process

509
00:32:16,092 --> 00:32:19,538
each one one at a time and then you

510
00:32:19,564 --> 00:32:23,094
have to list down the different solutions and remediation steps.

511
00:32:23,222 --> 00:32:26,826
It is important to note that these is something that

512
00:32:26,848 --> 00:32:30,154
you need to spend time on because for one thing you

513
00:32:30,192 --> 00:32:34,090
might see 1000 or 5000 vulnerabilities.

514
00:32:34,170 --> 00:32:37,850
So you need to sort it first. You need to assess

515
00:32:37,930 --> 00:32:41,902
which ones may be exploitable. And you also have CTO check

516
00:32:41,956 --> 00:32:45,586
if your application will break if you were to remediate some

517
00:32:45,608 --> 00:32:48,130
of these risk and vulnerabilities.

518
00:32:50,070 --> 00:32:54,100
Next, let's talk about infrastructure as code. So here

519
00:32:54,630 --> 00:32:58,502
we have our infrastructure. Instead of us

520
00:32:58,556 --> 00:33:02,690
trying to deploy things manually, one resource at a time and updating

521
00:33:02,770 --> 00:33:06,306
these resources, we can simply convert

522
00:33:06,338 --> 00:33:08,140
our resources into code.

523
00:33:09,550 --> 00:33:12,826
So what's happening here is that we try to divide our

524
00:33:12,848 --> 00:33:16,858
infrastructure into layers. So the resources, the security

525
00:33:16,944 --> 00:33:20,074
configuration, the network configuration and

526
00:33:20,112 --> 00:33:23,454
so on. And what we want to do here is we want to convert it

527
00:33:23,492 --> 00:33:27,454
into layers of templates. And these templates can be

528
00:33:27,492 --> 00:33:31,050
used to generate automatically different types of environments.

529
00:33:31,130 --> 00:33:34,802
For example, if you want to have a staging environment instead

530
00:33:34,856 --> 00:33:38,642
of manually creating those environments, we use that

531
00:33:38,696 --> 00:33:42,782
template as a reference to automatically

532
00:33:42,846 --> 00:33:45,926
build this environment. So there's of course

533
00:33:45,948 --> 00:33:50,482
a service which converts a securing template to real resources.

534
00:33:50,626 --> 00:33:54,050
If you need these production environment created or updated,

535
00:33:54,210 --> 00:33:57,766
we use a template as reference as well.

536
00:33:57,948 --> 00:34:02,070
So if you need a new environment for manual penetration testing,

537
00:34:02,230 --> 00:34:05,846
instead of the manual penetration testers attacking

538
00:34:05,878 --> 00:34:09,526
your production environment or even a staging environment that your developers

539
00:34:09,558 --> 00:34:13,674
are using, you can create can environment a dedicated environment

540
00:34:13,802 --> 00:34:17,774
for them. If you need an environments for load testing, then yes,

541
00:34:17,812 --> 00:34:20,640
you can create a dedicated environment for these as well.

542
00:34:21,010 --> 00:34:24,654
Once you're done, you delete it. So again, this is a very powerful

543
00:34:24,702 --> 00:34:28,270
tool. And if you're going to these and deploy

544
00:34:28,430 --> 00:34:32,002
security configuration updates or upgrades, it's better

545
00:34:32,056 --> 00:34:35,506
to do it this way so that you may be able to roll

546
00:34:35,538 --> 00:34:39,014
out things properly. So let's say that

547
00:34:39,132 --> 00:34:43,106
you have improved the security configuration of your network

548
00:34:43,218 --> 00:34:46,806
infrastructure. Instead of deploying it first in the

549
00:34:46,828 --> 00:34:50,774
production environment, maybe update the template

550
00:34:50,822 --> 00:34:54,966
first and have it used to update the staging environment.

551
00:34:55,158 --> 00:34:58,634
So now if your application is still stable and working, that's the

552
00:34:58,672 --> 00:35:01,726
time you update the production environment and so on.

553
00:35:01,908 --> 00:35:05,054
So this is something that you can use and you can

554
00:35:05,092 --> 00:35:08,890
even create and manage the security resources and IAM

555
00:35:08,970 --> 00:35:12,750
configuration using infrastructure as code concepts,

556
00:35:14,370 --> 00:35:17,790
account action monitoring. It's hard

557
00:35:17,860 --> 00:35:21,314
to prevent attacks. It's hard

558
00:35:21,352 --> 00:35:24,434
to troubleshoot problems if we're not able

559
00:35:24,472 --> 00:35:28,342
to monitor things properly. For example, let's say

560
00:35:28,396 --> 00:35:32,034
that we have this serverless machine

561
00:35:32,082 --> 00:35:35,494
learning environment and project.

562
00:35:35,692 --> 00:35:39,754
So this machine learning endpoint, this ML inference endpoint, makes use of

563
00:35:39,792 --> 00:35:43,110
an API gateway, a serverless API gateway,

564
00:35:43,270 --> 00:35:46,986
and a lambda function. So a lambda function is

565
00:35:47,008 --> 00:35:50,438
where you can write custom code. And even if you think that

566
00:35:50,464 --> 00:35:54,462
it's serverless, there's no server to attack, it can still be attacked because

567
00:35:54,516 --> 00:35:58,350
your code may be vulnerable to different types of attacks.

568
00:35:58,930 --> 00:36:02,874
So what happens here is that your hacker

569
00:36:02,922 --> 00:36:06,274
may input some payloads and instructions and it will go

570
00:36:06,312 --> 00:36:09,458
straight into your lambda function. So what you need to

571
00:36:09,464 --> 00:36:13,474
do is you have to ensure that you're able cto collect the logs and

572
00:36:13,512 --> 00:36:16,760
you're able to analyze the logs quickly.

573
00:36:17,290 --> 00:36:21,814
If you're able to introduce a tool or

574
00:36:21,852 --> 00:36:25,746
a logging mechanism or system to help process the different logs,

575
00:36:25,858 --> 00:36:30,010
then that would help you detect security attacks earlier,

576
00:36:30,670 --> 00:36:34,506
right? So you need something in place, because it's best

577
00:36:34,608 --> 00:36:37,994
to not assume that your system is secure. It is best to

578
00:36:38,032 --> 00:36:41,598
assume that somebody will always try to attack it from the outside

579
00:36:41,764 --> 00:36:43,120
or from the inside.

580
00:36:44,850 --> 00:36:48,254
In addition to this, we have to restrict the

581
00:36:48,292 --> 00:36:52,390
IAM permissions. We have to ensure that we limit

582
00:36:52,570 --> 00:36:56,340
what different types of resources are capable of doing. For example,

583
00:36:57,430 --> 00:37:01,294
there are different types of resources, real humans and infrastructure

584
00:37:01,342 --> 00:37:04,574
resources. So from an infrastructure

585
00:37:04,622 --> 00:37:08,742
standpoint, you need to take care of the IAM permissions on

586
00:37:08,796 --> 00:37:12,498
what these resources can do. And what we need to implement

587
00:37:12,594 --> 00:37:15,458
is the principle of list privilege,

588
00:37:15,634 --> 00:37:19,334
because, for example, you have hardened your entire infrastructure. What if

589
00:37:19,372 --> 00:37:22,826
the password of one user is not secured in the

590
00:37:22,848 --> 00:37:26,442
sense that maybe the password is just 123456 been

591
00:37:26,496 --> 00:37:29,130
eight? If that has been attacked,

592
00:37:29,550 --> 00:37:33,514
then your entire infrastructure has been compromised because of poor

593
00:37:33,562 --> 00:37:37,834
permission management and poor security guidelines

594
00:37:37,882 --> 00:37:41,626
and enforcement. So you need to ensure this because the weakest

595
00:37:41,658 --> 00:37:43,810
link would always be attacked.

596
00:37:45,190 --> 00:37:49,950
At the same time, you need to train the professionals

597
00:37:50,110 --> 00:37:54,146
working in your team, because professionals are

598
00:37:54,168 --> 00:37:58,070
generally trained to build something or to perform their task at hand.

599
00:37:58,220 --> 00:38:01,654
However, you also need to worry about these

600
00:38:01,692 --> 00:38:05,334
last 50%. So what do I mean by the last 50%? The first

601
00:38:05,372 --> 00:38:08,522
50% would be doing what you're supposed to do.

602
00:38:08,656 --> 00:38:12,454
The last 50% would be configuring and properly

603
00:38:12,502 --> 00:38:16,506
using a tool in a production setting, meaning it

604
00:38:16,528 --> 00:38:20,446
needs to be scalable, it needs to be something you can

605
00:38:20,548 --> 00:38:24,640
easily troubleshoot, and it's something that's hardened and ready

606
00:38:25,650 --> 00:38:29,614
for security attacks. So if you're using a

607
00:38:29,652 --> 00:38:33,634
tool, developers would generally just assume that

608
00:38:33,832 --> 00:38:37,426
the thing that they have built in their local machine can be

609
00:38:37,448 --> 00:38:40,658
directly deployed to a production environment. That's completely

610
00:38:40,744 --> 00:38:44,706
wrong, because a production configuration is more

611
00:38:44,728 --> 00:38:48,166
or less super different compared to how it

612
00:38:48,188 --> 00:38:51,766
looks like when you're running it locally. So make sure that you

613
00:38:51,788 --> 00:38:55,874
have specialists and experts in your team to properly configure

614
00:38:56,002 --> 00:39:00,858
these security settings and implementation before

615
00:39:00,944 --> 00:39:04,794
going into production or staging. So before we end

616
00:39:04,832 --> 00:39:08,458
the talk, let's talk about cost. Because we have talked about a

617
00:39:08,464 --> 00:39:12,480
lot of things, a lot of best practice. We have to

618
00:39:12,930 --> 00:39:16,714
divide it into maybe two or three components or two or three buckets.

619
00:39:16,842 --> 00:39:20,234
The first bucket is the infrastructure

620
00:39:20,282 --> 00:39:24,066
cost, the additional infrastructure cost. And the second bucket would

621
00:39:24,088 --> 00:39:27,314
be, of course, the manpower required to work

622
00:39:27,352 --> 00:39:29,570
on these types of security requirements.

623
00:39:30,790 --> 00:39:34,254
The first bucket, you need to prioritize

624
00:39:34,302 --> 00:39:37,630
the free ones. Sometimes you always think, oh,

625
00:39:37,640 --> 00:39:40,546
we need the firewall, we need to spend this, we need to purchase this subscription

626
00:39:40,578 --> 00:39:43,910
or so on. In some cases, some of the

627
00:39:44,060 --> 00:39:47,662
small tweaks, let's say network isolation,

628
00:39:47,826 --> 00:39:52,566
you may be able to get that for free. A properly configured

629
00:39:52,758 --> 00:40:00,170
IAM setting or IAM configuration implementation

630
00:40:00,910 --> 00:40:04,286
that can be free as well. So list down all the

631
00:40:04,308 --> 00:40:07,840
things you can do for free. And these list down all the

632
00:40:08,450 --> 00:40:12,330
other moves you can do, which may involve additional

633
00:40:12,490 --> 00:40:15,902
fees. For example, additional fees

634
00:40:15,966 --> 00:40:18,978
may be involved when it comes CTO using another service.

635
00:40:19,144 --> 00:40:22,722
Let's say you're using a service which automatically encrypts data

636
00:40:22,856 --> 00:40:26,034
at rest, or maybe it automatically encrypts it on the fly.

637
00:40:26,082 --> 00:40:28,680
For example, if you were to use that service,

638
00:40:31,210 --> 00:40:34,694
that would add maybe these percent or 4% on top

639
00:40:34,732 --> 00:40:38,230
of the infrastructure cost. But if it makes sense,

640
00:40:38,300 --> 00:40:41,210
then yeah, proceed with that and have it approved.

641
00:40:41,790 --> 00:40:45,690
On the other hand, on the other bucket, when you're talking about manpower,

642
00:40:46,110 --> 00:40:50,054
you have to check on where you will get the resources

643
00:40:50,102 --> 00:40:53,406
focused to take care of the security. And you also need to

644
00:40:53,428 --> 00:40:56,766
make sure that there's a proper ratio. Maybe 80% would

645
00:40:56,788 --> 00:41:00,186
be builders and then 20% would be the maintainers.

646
00:41:00,378 --> 00:41:03,630
So the maintainers may be composed

647
00:41:03,710 --> 00:41:09,042
of the analysts, the ones taking

648
00:41:09,096 --> 00:41:13,058
charge of the processes and the management of

649
00:41:13,064 --> 00:41:16,758
the resources. So you have to follow a certain ratio. And you

650
00:41:16,764 --> 00:41:20,802
would also have to check if you're going to utilize

651
00:41:20,866 --> 00:41:24,342
internal team members or if you're going to work with

652
00:41:24,476 --> 00:41:28,086
other companies to help you, or maybe a combination

653
00:41:28,118 --> 00:41:31,850
of both. So always plan ahead, because once you're able

654
00:41:31,920 --> 00:41:35,834
to identify what you need, it is usually

655
00:41:35,952 --> 00:41:40,054
a long term contract. So that would basically affect

656
00:41:40,102 --> 00:41:43,694
the overall cost. Because if you were to hire a company for

657
00:41:43,732 --> 00:41:47,294
one year just to audit your system. Of course,

658
00:41:47,332 --> 00:41:51,274
you have to check, hey, how much is my system contributing

659
00:41:51,322 --> 00:41:54,650
to the final financial numbers in the

660
00:41:54,660 --> 00:41:58,082
first place? Is it worth it? Is it much cheaper to

661
00:41:58,136 --> 00:42:01,730
hire someone or to train someone from the team?

662
00:42:01,880 --> 00:42:04,466
So, yeah, so there are a lot of options. And,

663
00:42:04,568 --> 00:42:08,680
yeah, you have to assess and choose which is the best

664
00:42:09,210 --> 00:42:12,920
collection of solutions, which is best for your team.

665
00:42:16,650 --> 00:42:20,122
So there. So we were able to talk about a lot of things.

666
00:42:20,256 --> 00:42:24,138
We're able to start with discussing how to

667
00:42:24,304 --> 00:42:27,786
attack different scenarios and how to attack the

668
00:42:27,808 --> 00:42:31,770
different components and process of the machine learning process

669
00:42:31,920 --> 00:42:36,110
especially, and how they are applied in a real life setting.

670
00:42:36,530 --> 00:42:40,602
Towards the second half, we were able to talk about the different security measures

671
00:42:40,746 --> 00:42:44,234
because if we're not able to secure our systems properly,

672
00:42:44,362 --> 00:42:48,682
these, the hackers and attackers would be able to take advantage of misconfiguration,

673
00:42:48,826 --> 00:42:52,430
and they would be able to steal our data and

674
00:42:52,500 --> 00:42:56,342
use our resources in ways that would

675
00:42:56,396 --> 00:43:00,086
either harm others or would harm us. So thank you

676
00:43:00,108 --> 00:43:04,070
very much. Thank you again for watching my talk and hope you learned something

677
00:43:04,140 --> 00:43:05,910
new. Bye bye.

