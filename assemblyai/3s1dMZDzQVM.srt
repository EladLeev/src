1
00:01:44,590 --> 00:01:48,034
Welcome to my talk iterative threat modeling enhancing security in

2
00:01:48,072 --> 00:01:51,906
agile development little introduction about me my

3
00:01:51,928 --> 00:01:56,094
name is Jagdesh Chant, also known as Jax. I'm a full stack developer

4
00:01:56,142 --> 00:01:59,422
who plays devsecops role in dev thoughtworks.

5
00:01:59,566 --> 00:02:02,946
The paint trip model shows the skill sets I

6
00:02:02,968 --> 00:02:06,786
have and the deep knowledge respectively. I always find ways

7
00:02:06,888 --> 00:02:10,566
to implement shift security left approach and encourage teams

8
00:02:10,598 --> 00:02:13,974
to follow security development. I'm also an OSWe

9
00:02:14,022 --> 00:02:17,814
batch holder from offensivesyc along with an AWS

10
00:02:17,862 --> 00:02:21,550
security specialist batch. You can follow me in LinkedIn

11
00:02:22,050 --> 00:02:25,790
for any security related news and articles.

12
00:02:26,290 --> 00:02:29,040
This is the outline of the talk.

13
00:02:29,570 --> 00:02:33,354
First we are going to see what is threats modeling, followed by agile

14
00:02:33,402 --> 00:02:37,730
threat modeling. Explain with a simulation of how to run the exercise,

15
00:02:38,070 --> 00:02:42,226
and finally how to incorporate the

16
00:02:42,248 --> 00:02:45,746
same into our agile rituals to achieve iterative threat

17
00:02:45,778 --> 00:02:49,542
modeling. Before finishing, we will take a step back

18
00:02:49,676 --> 00:02:53,586
and see how to run the threat modeling in different parts

19
00:02:53,618 --> 00:02:56,760
of the ongoing project. So first,

20
00:02:57,390 --> 00:03:01,162
what is a threat modeling? It's an exercise used

21
00:03:01,216 --> 00:03:04,618
to identify threats or

22
00:03:04,784 --> 00:03:08,918
different ways to attack a system and model it properly

23
00:03:09,014 --> 00:03:12,906
so that the development and operations team can come up with ideas

24
00:03:12,938 --> 00:03:16,670
to mitigate it. By doing this proactively,

25
00:03:17,010 --> 00:03:20,126
we can prevent the software that we

26
00:03:20,148 --> 00:03:23,502
have developed from being compromised by the attackers

27
00:03:23,566 --> 00:03:27,630
before it is too late. The traditional threat modeling exercise

28
00:03:27,710 --> 00:03:31,234
involves mainly security specialists with very

29
00:03:31,272 --> 00:03:34,810
few stakeholders from tech teams development teams.

30
00:03:34,990 --> 00:03:37,720
They collaborate, discuss,

31
00:03:38,250 --> 00:03:41,890
identify threats and propose a mitigation

32
00:03:41,970 --> 00:03:45,794
response plan for it without the development

33
00:03:45,842 --> 00:03:49,770
teams much involved. The problem with the traditional

34
00:03:50,510 --> 00:03:54,326
threat modeling is that it does not involve development teams

35
00:03:54,438 --> 00:03:58,026
and this creates a

36
00:03:58,048 --> 00:04:01,646
lot of misconceptions around it. The main misconception is that the

37
00:04:01,668 --> 00:04:05,102
penetration revisiting and the code

38
00:04:05,156 --> 00:04:07,930
reviews can compensate for threat modeling.

39
00:04:08,090 --> 00:04:11,262
These two activities are very

40
00:04:11,316 --> 00:04:15,230
effective in finding bugs and making sure the high quality of the software

41
00:04:15,390 --> 00:04:19,726
not for security assessment. Threat modeling will uncover

42
00:04:19,838 --> 00:04:23,474
design flaws which cannot be identified by

43
00:04:23,512 --> 00:04:27,330
these techniques. Without understanding the potential threats

44
00:04:27,410 --> 00:04:31,490
an application faces, we cannot ensure in addressing

45
00:04:31,570 --> 00:04:35,074
all the risk. And the second misconception

46
00:04:35,202 --> 00:04:39,162
is lot of people think that threats modeling can be done after the

47
00:04:39,216 --> 00:04:42,602
delivery the software, which is very big red

48
00:04:42,656 --> 00:04:46,426
flag. This puts the development lifecycle in a

49
00:04:46,448 --> 00:04:50,266
brittle situation where the threat modeling discovers a foundational

50
00:04:50,378 --> 00:04:53,950
security threat which requires a rewrite of the entire

51
00:04:54,020 --> 00:04:58,110
architecture of the system. And last misconception

52
00:04:58,530 --> 00:05:02,454
is that it is too much of time consuming

53
00:05:02,522 --> 00:05:06,114
and it is complex. Yes, it is,

54
00:05:06,312 --> 00:05:10,226
if you only at a first glance, but if

55
00:05:10,248 --> 00:05:14,474
you follow a simple steps, we can achieve threat modeling

56
00:05:14,622 --> 00:05:18,850
in a limited time period. These misconceptions

57
00:05:19,010 --> 00:05:23,110
created the dawn of agile threat modeling

58
00:05:23,530 --> 00:05:27,630
in order to run a threat modeling in an agile software development,

59
00:05:27,810 --> 00:05:32,394
we are in need of certain requirements like we

60
00:05:32,432 --> 00:05:35,834
need to bring a defensive mindset into

61
00:05:35,872 --> 00:05:39,542
the development team so that the development team

62
00:05:39,696 --> 00:05:43,230
have the knowledge on security implications.

63
00:05:43,730 --> 00:05:47,274
Second, we need to create a collaborative,

64
00:05:47,402 --> 00:05:51,194
tailored approach with the development team for capturing threats

65
00:05:51,242 --> 00:05:54,574
proactively. A collaborative approach

66
00:05:54,702 --> 00:05:58,340
with the business teams so that

67
00:06:00,150 --> 00:06:03,380
they can together bring up threats together

68
00:06:04,230 --> 00:06:08,710
and leave some space to individual agile teams

69
00:06:09,130 --> 00:06:12,930
to tailor the need based upon

70
00:06:13,090 --> 00:06:17,000
their working situation. So there should be a space

71
00:06:17,310 --> 00:06:21,382
of each agile teams working in an organization to tailor

72
00:06:21,446 --> 00:06:25,820
the tune the threat modeling to their needs.

73
00:06:26,430 --> 00:06:30,410
And third, one is unawareness.

74
00:06:32,530 --> 00:06:36,346
They need to overcome the human errors because of unawareness.

75
00:06:36,538 --> 00:06:39,962
This development team should be conscious

76
00:06:40,026 --> 00:06:43,642
of the security impacts of the threats,

77
00:06:43,786 --> 00:06:46,926
how it is going to affect the business, how is it going to affect

78
00:06:46,958 --> 00:06:50,802
a different department from their own box small

79
00:06:50,856 --> 00:06:54,254
bubble. They have to think more than their agile

80
00:06:54,302 --> 00:06:57,414
teams. The impact is not only to the development but also

81
00:06:57,452 --> 00:07:01,622
to the business. And the fourth, a simple exercise which

82
00:07:01,676 --> 00:07:05,654
should be introduced at any time of the project and can

83
00:07:05,692 --> 00:07:09,734
be repeated iteratively. So keeping

84
00:07:09,782 --> 00:07:13,174
the requirements in mind and running trial

85
00:07:13,222 --> 00:07:17,942
and errors on various agile teams across thoughtworks.

86
00:07:18,086 --> 00:07:22,158
We came up with these five steps of

87
00:07:22,324 --> 00:07:25,886
agile threat modelling. It is influenced by the

88
00:07:25,908 --> 00:07:29,294
threats modeling framework, but we kept it

89
00:07:29,332 --> 00:07:33,662
very simple to run it in any agile environment.

90
00:07:33,806 --> 00:07:37,474
The first step is to identify what

91
00:07:37,512 --> 00:07:41,250
we want to accomplish in the scope of the exercise,

92
00:07:41,990 --> 00:07:45,510
followed by the representation of the scope.

93
00:07:46,250 --> 00:07:50,280
Then we brainstorm on the ways that can go wrong.

94
00:07:50,890 --> 00:07:53,846
Once we identify what can go wrong,

95
00:07:54,028 --> 00:07:58,540
we discuss about the mitigation values and finally

96
00:07:59,390 --> 00:08:03,110
we reflect our outcomes of the exercise

97
00:08:03,270 --> 00:08:07,034
so that we can do it better next time.

98
00:08:07,232 --> 00:08:11,550
We will go through each of these steps in detail in upcoming slides

99
00:08:12,210 --> 00:08:14,910
to understand the implementation of the exercise.

100
00:08:15,730 --> 00:08:19,454
In the real world scenario, we are going to use

101
00:08:19,652 --> 00:08:23,550
the open source juice shop as our guinea pig

102
00:08:23,710 --> 00:08:27,010
to simulate the agile threat modeling steps.

103
00:08:27,670 --> 00:08:31,362
Little intro about the application the Juice shop is an

104
00:08:31,416 --> 00:08:34,734
online website which takes in

105
00:08:34,792 --> 00:08:38,406
orders of fresh juice and delivers into your home with

106
00:08:38,428 --> 00:08:42,630
a beautiful packaging. Juice shop is the most

107
00:08:42,780 --> 00:08:46,694
vulnerable, insecure application available

108
00:08:46,812 --> 00:08:50,102
in the Internet so that people who want to practice

109
00:08:50,166 --> 00:08:54,154
security, mitigation or security practices, they can

110
00:08:54,192 --> 00:08:57,546
use this application as a guinea pig. And this is

111
00:08:57,568 --> 00:09:01,738
a high level architectural diagram of the juice shop.

112
00:09:01,904 --> 00:09:05,706
We have an front end app, we have a backend juicehop

113
00:09:05,738 --> 00:09:09,866
server which runs in a node JS and we also have a payment service node

114
00:09:09,898 --> 00:09:14,050
js running in the backend with a postgres database.

115
00:09:14,550 --> 00:09:19,170
So few high level legend user

116
00:09:19,590 --> 00:09:22,622
data flow is represented in a vector,

117
00:09:22,686 --> 00:09:26,114
arrow and authorization boundaries also represents

118
00:09:26,162 --> 00:09:30,070
here. So before we get started on our

119
00:09:30,220 --> 00:09:33,858
agile threat modeling exercise, we should have a security objective

120
00:09:33,954 --> 00:09:38,294
to which everyone should adhere to. Security objective

121
00:09:38,422 --> 00:09:41,754
defines the organizational goal towards security,

122
00:09:41,952 --> 00:09:45,754
which includes protecting the main assets of the organization like

123
00:09:45,792 --> 00:09:49,850
customer data, et cetera. If there is an organization

124
00:09:50,450 --> 00:09:53,866
security objective, organizational security objective, we inherit

125
00:09:53,898 --> 00:09:58,202
it, else we create a security objective for our scope.

126
00:09:58,346 --> 00:10:02,134
It is always better to create a security objective

127
00:10:02,202 --> 00:10:05,634
for the organization, but it's not a blocker for

128
00:10:05,672 --> 00:10:09,134
our exercise. Security objectives should revolve

129
00:10:09,182 --> 00:10:13,326
around the principle of CIA triad.

130
00:10:13,518 --> 00:10:17,382
CIA stands for C

131
00:10:17,516 --> 00:10:21,174
for confidentiality. Assets which are

132
00:10:21,212 --> 00:10:24,534
confidential information should never

133
00:10:24,572 --> 00:10:27,642
be compromised. I for

134
00:10:27,696 --> 00:10:31,274
integrity of the data should be protected at all

135
00:10:31,312 --> 00:10:35,366
costs from tampering. Yay for availability.

136
00:10:35,558 --> 00:10:39,382
The service availability should not be interrupted for regular

137
00:10:39,446 --> 00:10:45,022
users because of a security threats and

138
00:10:45,076 --> 00:10:47,280
it should also answer the following questions.

139
00:10:47,970 --> 00:10:51,418
What kind of losses puts the organization

140
00:10:51,514 --> 00:10:54,830
objective in geopolitical? Is it having the customer

141
00:10:54,900 --> 00:10:58,462
database stolen or a payment? Are we worried

142
00:10:58,526 --> 00:11:02,286
about a fraud? Is it malicious insiders

143
00:11:02,478 --> 00:11:06,630
or particularly capable hackers? We will

144
00:11:06,700 --> 00:11:11,170
try to implement the security objective

145
00:11:11,250 --> 00:11:13,000
for our juice shop application.

146
00:11:14,170 --> 00:11:18,070
As the juice shop is an online revenue generating

147
00:11:18,150 --> 00:11:22,220
platform, the impact to

148
00:11:23,310 --> 00:11:26,714
negatively will affect the sales of the shop.

149
00:11:26,832 --> 00:11:30,734
We should take care so that the sales of

150
00:11:30,772 --> 00:11:34,282
the juice shop is not impacted

151
00:11:34,346 --> 00:11:37,226
because of the negative reputation.

152
00:11:37,418 --> 00:11:41,114
Secondly, we should reduce the breach

153
00:11:41,242 --> 00:11:44,580
of personally identifiable information of the customer,

154
00:11:45,350 --> 00:11:48,706
which in turn affects the sales of

155
00:11:48,728 --> 00:11:52,850
this juice shop. Third, we should

156
00:11:52,920 --> 00:11:56,534
reduce the risk of malicious alteration leading to a

157
00:11:56,572 --> 00:11:59,160
financial loss. And finally,

158
00:12:00,010 --> 00:12:04,018
the chance of malicious denial of availability

159
00:12:04,114 --> 00:12:07,270
of the shop to customer should be reduced.

160
00:12:07,610 --> 00:12:10,882
So these are our four security objectives

161
00:12:11,026 --> 00:12:13,260
for the Joshop application.

162
00:12:14,030 --> 00:12:17,226
So let's start with our first step.

163
00:12:17,328 --> 00:12:19,210
What do we want to accomplish?

164
00:12:19,570 --> 00:12:22,830
Scoping. This is an important step of

165
00:12:22,900 --> 00:12:26,414
threat modeling. We should be very conscious in including the

166
00:12:26,452 --> 00:12:31,002
right scoping of the exercise. Always focus on few chunks

167
00:12:31,146 --> 00:12:34,798
before performing the activity. Few best practices in creating

168
00:12:34,814 --> 00:12:38,594
the scope is whenever a new or

169
00:12:38,632 --> 00:12:42,754
upcoming security sensitive feature such as login and checkout flow is coming

170
00:12:42,792 --> 00:12:46,998
up, a particular microservice and its collaborating services

171
00:12:47,164 --> 00:12:50,886
integrating towards it and high level overview of

172
00:12:50,908 --> 00:12:54,310
a system to identify security tech depth.

173
00:12:54,810 --> 00:12:58,634
Stop at the integration level. Do not go

174
00:12:58,672 --> 00:13:02,010
at the details so reducing the scope,

175
00:13:02,510 --> 00:13:05,914
keeping the scope as simple as possible and finally,

176
00:13:06,032 --> 00:13:10,090
the continuous delivery pipeline and delivery infrastructure.

177
00:13:10,450 --> 00:13:14,126
For our simulation. We will scope the customer

178
00:13:14,228 --> 00:13:18,190
login flow as our feature

179
00:13:18,610 --> 00:13:22,378
to run our exercises. So we have a customer login

180
00:13:22,474 --> 00:13:25,534
epic and the acceptance criteria goes

181
00:13:25,572 --> 00:13:29,294
like as a customer I need a page where I can enter login

182
00:13:29,342 --> 00:13:33,006
credentials so that I can access the application as a logged in user.

183
00:13:33,118 --> 00:13:36,694
We also have a dev story card for it.

184
00:13:36,892 --> 00:13:40,726
So this is a new feature that is getting implemented in

185
00:13:40,748 --> 00:13:44,614
a beautiful ecommerce juice shop application. So with

186
00:13:44,652 --> 00:13:48,558
this we'll go to the second equip

187
00:13:48,594 --> 00:13:52,602
representation of the scope. We are going to follow the

188
00:13:52,736 --> 00:13:55,974
software centric approach here in a software

189
00:13:56,022 --> 00:13:59,838
centric model we represent our systems in

190
00:13:59,844 --> 00:14:03,326
a holistic view with the software layers highlighting how

191
00:14:03,348 --> 00:14:07,422
data flows from one system to another system

192
00:14:07,556 --> 00:14:11,134
using an vector arrows and

193
00:14:11,172 --> 00:14:14,846
which is a short form of data flow diagram.

194
00:14:15,038 --> 00:14:19,586
The key principle here is to identify the entry points,

195
00:14:19,768 --> 00:14:23,134
asserts and trust levels that represent

196
00:14:23,182 --> 00:14:26,694
the access rights. You should capture the end

197
00:14:26,732 --> 00:14:30,406
to end flow including the external entity where the

198
00:14:30,428 --> 00:14:33,766
data flows from for every use case with

199
00:14:33,788 --> 00:14:37,618
the system interactions. Of course the key stakeholders

200
00:14:37,714 --> 00:14:41,862
during this exercise is engineers which composes of DevOps

201
00:14:41,926 --> 00:14:46,106
and as well as the development teams. This is an example

202
00:14:46,208 --> 00:14:49,918
of the data flow diagram of the login flow that we

203
00:14:49,924 --> 00:14:53,774
are going to create for the juice shop. So here we have

204
00:14:53,812 --> 00:14:57,470
three systems involved.

205
00:14:57,890 --> 00:15:01,758
The front end app, the back end juice shop server which runs in

206
00:15:01,764 --> 00:15:05,022
the node JS and the external identity provider.

207
00:15:05,166 --> 00:15:08,530
Here the user when

208
00:15:08,600 --> 00:15:11,902
reaches the front end app is redirected to the identity

209
00:15:11,966 --> 00:15:16,134
provider. After authentication it

210
00:15:16,172 --> 00:15:19,590
provides an authentic code auth code which is sent

211
00:15:19,660 --> 00:15:23,510
to juice shop server backend server

212
00:15:24,490 --> 00:15:27,234
backend server validates the auth code.

213
00:15:27,372 --> 00:15:31,162
If the validation is success then

214
00:15:31,216 --> 00:15:35,194
redirects the customer to the home page with

215
00:15:35,232 --> 00:15:38,502
the saved token in the session.

216
00:15:38,646 --> 00:15:42,846
So this is an overview of the dataflow diagram that

217
00:15:42,868 --> 00:15:45,870
we have created for the juice shop login flow.

218
00:15:46,210 --> 00:15:49,822
So moving on with this to the third

219
00:15:49,876 --> 00:15:54,066
step, what can go wrong here?

220
00:15:54,248 --> 00:15:58,260
We are going to evil brainstorm about

221
00:15:59,190 --> 00:16:03,502
how the application can produce threats.

222
00:16:03,646 --> 00:16:07,494
This is where we wear attackers hat in

223
00:16:07,532 --> 00:16:11,126
coming up with ways to attack, break or frustrate a

224
00:16:11,148 --> 00:16:14,710
particular bit of software from attackers mindset.

225
00:16:15,050 --> 00:16:18,762
The key principle is to be aware of the time and never

226
00:16:18,816 --> 00:16:22,714
go into rabbit hole discussion and focus

227
00:16:22,832 --> 00:16:26,140
on quantity over quality.

228
00:16:26,910 --> 00:16:30,926
Create as many as threats possible without stopping to

229
00:16:30,948 --> 00:16:35,978
analyze. Is it really worth or not? And there is a stakeholders

230
00:16:36,074 --> 00:16:39,280
involved in this exercise is a security team,

231
00:16:39,650 --> 00:16:43,090
product owners from the business and engineers.

232
00:16:44,150 --> 00:16:47,294
There are multiple ways or methodologies

233
00:16:47,342 --> 00:16:51,422
to implement the evil brainstorming. Starting from pasta,

234
00:16:51,486 --> 00:16:55,086
attack trees and waste. Each has their own pros

235
00:16:55,118 --> 00:16:58,374
and cons. Pasta is a very

236
00:16:58,412 --> 00:17:02,070
good attacker focus but it has a very comprehensive

237
00:17:02,570 --> 00:17:06,294
assurance exercise. It is a very long running exercise and

238
00:17:06,332 --> 00:17:09,754
we also have a time box strike which is

239
00:17:09,792 --> 00:17:13,146
very applicable for agile teams which we are going to

240
00:17:13,168 --> 00:17:16,634
be concentrating in this exercise or in this

241
00:17:16,672 --> 00:17:19,750
talk specifically this time box

242
00:17:19,840 --> 00:17:22,750
stride is very developer focused.

243
00:17:23,650 --> 00:17:27,274
What is a stride? It's a methodology

244
00:17:27,402 --> 00:17:31,358
to bear attackers hat in different

245
00:17:31,444 --> 00:17:34,526
scenarios, different possible scenarios.

246
00:17:34,718 --> 00:17:37,982
Walking through and identifying,

247
00:17:38,046 --> 00:17:41,540
walking through multiple threats, walking through the different

248
00:17:42,710 --> 00:17:47,110
hats of the attacker like spoofed identity and

249
00:17:47,180 --> 00:17:51,314
identifying if there is a threat or not and capturing

250
00:17:51,362 --> 00:17:57,382
it in our whiteboard or in our beautiful data

251
00:17:57,436 --> 00:18:01,158
flow diagram. So let's understand the stride a little bit,

252
00:18:01,244 --> 00:18:04,794
what it is, the different hacks of the stride and then

253
00:18:04,912 --> 00:18:08,486
try to capture the information s in the stride stands

254
00:18:08,518 --> 00:18:13,054
for spoofed identity. It makes us think if

255
00:18:13,092 --> 00:18:17,310
an attacker can impersonate someone as using

256
00:18:17,380 --> 00:18:20,878
a stolen token, stolen token or a

257
00:18:20,884 --> 00:18:24,798
cookies or just brute forcing it. The key concepts is identity

258
00:18:24,894 --> 00:18:28,782
and authentication and stakeholders

259
00:18:28,846 --> 00:18:33,602
here think through how

260
00:18:33,656 --> 00:18:37,814
an application can fail when there

261
00:18:37,852 --> 00:18:41,750
is lack of authentication, any form of authentication,

262
00:18:42,090 --> 00:18:45,938
tokens or JWT tokens or identifying

263
00:18:46,034 --> 00:18:50,118
if you are the real user to do it. Is there a lack of authentication

264
00:18:50,214 --> 00:18:54,202
inside the system? And we should also go

265
00:18:54,336 --> 00:18:58,566
think through if there is a weakness in the process. The resetting

266
00:18:58,598 --> 00:19:02,682
credentials authentication mechanism

267
00:19:02,746 --> 00:19:06,222
should subject to brute force attack. Are there any

268
00:19:06,356 --> 00:19:10,030
ways attacker can run a brute force attack on

269
00:19:10,100 --> 00:19:14,674
login pages? Can an attacker allow

270
00:19:14,792 --> 00:19:18,290
you use a very

271
00:19:18,360 --> 00:19:22,386
weak password to get into a system or

272
00:19:22,488 --> 00:19:25,910
an already compromised password

273
00:19:26,410 --> 00:19:30,070
to get into a system? So is there any other

274
00:19:30,140 --> 00:19:34,294
way an attacker can spoof themselves as

275
00:19:34,332 --> 00:19:37,522
a customer, a legitimate customer, and get into the system?

276
00:19:37,676 --> 00:19:40,986
So identifying different ways

277
00:19:41,088 --> 00:19:44,378
or scenarios qualifies as a

278
00:19:44,384 --> 00:19:47,878
threat. So once you identify a threat,

279
00:19:47,974 --> 00:19:51,406
capture it in our dataflow diagram. How do

280
00:19:51,428 --> 00:19:55,310
we capture it? We will look into the later slides and

281
00:19:55,380 --> 00:19:59,006
moving on in our stride hacks. T in our

282
00:19:59,028 --> 00:20:03,550
stride stands for tampering with input e. Here the attacker

283
00:20:03,710 --> 00:20:08,034
can go beyond the expected input like giving

284
00:20:08,072 --> 00:20:11,774
an hexadecimal URL, encoded values, special characters in login

285
00:20:11,822 --> 00:20:14,906
credentials, et cetera. The key concept

286
00:20:14,958 --> 00:20:19,090
is validation. Are we doing validation on that unexpected

287
00:20:19,170 --> 00:20:22,040
values the attacker is trying to use?

288
00:20:22,570 --> 00:20:26,098
What is the integrity of the system? What is the injection?

289
00:20:26,274 --> 00:20:29,870
Can the attacker do an cross site scripting?

290
00:20:29,970 --> 00:20:33,660
Inject a malicious script inside the client side and run it?

291
00:20:34,510 --> 00:20:37,706
Does the validation happens in the front end as well as the back

292
00:20:37,728 --> 00:20:41,074
end. These are all the few scenarios and concepts

293
00:20:41,142 --> 00:20:44,958
that the stakeholder has to go through before coming up

294
00:20:45,044 --> 00:20:47,360
a possible threats inside the system.

295
00:20:47,970 --> 00:20:51,146
R in the stride stands for reputation of action.

296
00:20:51,258 --> 00:20:55,262
It makes us think if any attacker can do malicious

297
00:20:55,326 --> 00:20:59,198
activity and get away without getting a proof

298
00:20:59,294 --> 00:21:03,246
of the activity. Key concepts is logging and audit.

299
00:21:03,358 --> 00:21:07,560
Is the logs centralized? Is one of the scenarios that we can think through

300
00:21:08,090 --> 00:21:12,498
if the logs are centralized. Can the malicious user

301
00:21:12,594 --> 00:21:15,974
delete the logs by impersonating other

302
00:21:16,012 --> 00:21:19,638
self or escalating using a different credentials?

303
00:21:19,734 --> 00:21:23,594
So these are the scenarios that we have to look

304
00:21:23,632 --> 00:21:26,938
through or identify in the process of

305
00:21:26,944 --> 00:21:31,210
the exercise or give a chance for the stakeholders

306
00:21:31,290 --> 00:21:35,390
to come up with the threats. So information disclosure,

307
00:21:36,370 --> 00:21:39,150
which is the eye of the stride.

308
00:21:39,810 --> 00:21:42,994
It lets us think if

309
00:21:43,032 --> 00:21:46,898
the system can give more information

310
00:21:47,064 --> 00:21:50,574
what it is supposed to be like. Server versions

311
00:21:50,622 --> 00:21:54,626
in the requested headers, response headers, the key

312
00:21:54,648 --> 00:21:58,162
concepts is the confidentiality, encryption and leakage.

313
00:21:58,306 --> 00:22:02,534
We should not provide an unwanted information when

314
00:22:02,572 --> 00:22:06,614
it is not required. Like are

315
00:22:06,652 --> 00:22:10,682
we handling the unexpected expression gracefully before

316
00:22:10,736 --> 00:22:13,946
sending it to the customer? What's the

317
00:22:13,968 --> 00:22:18,422
applications? What happens if you send an unexpected exception

318
00:22:18,486 --> 00:22:21,898
back to the user? We disclose if you are using a

319
00:22:21,904 --> 00:22:25,350
NoSQL database or SQL database, what is a

320
00:22:25,360 --> 00:22:29,134
version of the server that SQL database we are using

321
00:22:29,252 --> 00:22:32,782
or what is the type of server we are running with

322
00:22:32,836 --> 00:22:36,514
the tech stack. And these are information which

323
00:22:36,552 --> 00:22:39,886
are unwanted to the user.

324
00:22:39,998 --> 00:22:43,742
So we should able to abstract

325
00:22:43,806 --> 00:22:47,286
that information and send it out. So any information

326
00:22:47,388 --> 00:22:51,080
which is not necessary to the user should never be

327
00:22:51,450 --> 00:22:55,494
given to the user. D in stride stands for

328
00:22:55,532 --> 00:22:59,866
denial of service. Can an attacker brings

329
00:22:59,968 --> 00:23:03,766
using bots can run and distribute

330
00:23:03,798 --> 00:23:07,402
a denial of service so that the legitimate users cannot access

331
00:23:07,456 --> 00:23:10,782
the application. Then if they can run

332
00:23:10,836 --> 00:23:14,394
it, then it's a threats. The key concepts is availability.

333
00:23:14,522 --> 00:23:18,442
Whatever threats that compromises

334
00:23:18,506 --> 00:23:22,042
the availability, applications are categorized under

335
00:23:22,116 --> 00:23:24,802
denial of service. Finally,

336
00:23:24,936 --> 00:23:28,078
e in the stripe stands for elevation of privilege.

337
00:23:28,174 --> 00:23:32,146
It makes us think if the attacker can access of

338
00:23:32,328 --> 00:23:35,670
files or systems which they should not be.

339
00:23:35,820 --> 00:23:38,898
This is also applicable to internal employees.

340
00:23:39,074 --> 00:23:42,818
Sensitive files should only be accessed on demand basis.

341
00:23:42,994 --> 00:23:46,710
Key concept is authorization isolation

342
00:23:47,310 --> 00:23:50,906
remote code execution. Few examples that we can

343
00:23:50,928 --> 00:23:54,970
think through is like all the employees,

344
00:23:55,310 --> 00:23:58,934
including nontechnical stakeholders have protection edit

345
00:23:58,982 --> 00:24:02,490
access. Does all the system have authorization

346
00:24:02,570 --> 00:24:06,714
implemented to check the right access of the user

347
00:24:06,842 --> 00:24:11,374
before giving back to the user. So we

348
00:24:11,412 --> 00:24:15,146
had understood what is the stride model till

349
00:24:15,178 --> 00:24:18,834
now and discussed about it. We are going to apply the

350
00:24:18,872 --> 00:24:22,210
stride model on our guinea pig juice shop.

351
00:24:22,360 --> 00:24:26,950
After applying we come up with lot of threats

352
00:24:28,170 --> 00:24:31,794
which is jeopardizing the reputation

353
00:24:31,842 --> 00:24:35,382
of action. Like there is no logs for how many

354
00:24:35,436 --> 00:24:39,510
unauthorized entries comes in. There can be a brute force attack,

355
00:24:39,660 --> 00:24:43,260
there can be a deed distributed denial of service

356
00:24:43,790 --> 00:24:48,038
and tampering with the input. There is no strong password configuration

357
00:24:48,134 --> 00:24:52,154
in our services and also there is a missing configuration

358
00:24:52,282 --> 00:24:55,982
related to elevation of privilege. So these

359
00:24:56,116 --> 00:24:59,710
are all the threats that we have identified

360
00:25:00,610 --> 00:25:03,140
after applying the stride model.

361
00:25:03,590 --> 00:25:07,060
So with this lot of threads in our hand,

362
00:25:07,510 --> 00:25:11,250
we move on to the fourth step. What are we going to do about

363
00:25:11,320 --> 00:25:14,210
it? We are going to prioritize.

364
00:25:14,890 --> 00:25:18,546
This is where the people, the stakeholders

365
00:25:18,658 --> 00:25:22,482
owe the riskiest threats. Keeping our security objective

366
00:25:22,546 --> 00:25:26,326
in mind, the principle is to use a threats model

367
00:25:26,428 --> 00:25:30,010
and the security objective that we have defined in the first

368
00:25:30,080 --> 00:25:33,158
step. Using these two techniques,

369
00:25:33,254 --> 00:25:38,154
we prioritize the most riskiest threat that

370
00:25:38,192 --> 00:25:41,626
we have to concentrate on. What does the dread stands

371
00:25:41,658 --> 00:25:45,566
for? The D stands for damage. How bad

372
00:25:45,668 --> 00:25:49,326
the damage of the threats is? Is it business

373
00:25:49,428 --> 00:25:52,662
as well as the technical how big is the damage?

374
00:25:52,826 --> 00:25:55,906
How reproducible is the attack?

375
00:25:56,088 --> 00:25:59,630
How easy it is reproducible exploitable?

376
00:25:59,710 --> 00:26:04,020
How much work has to be done to launch the attack?

377
00:26:04,630 --> 00:26:07,686
Affected users how many people are affected by the

378
00:26:07,708 --> 00:26:10,886
impact or impacted by this discoverability? D for

379
00:26:10,908 --> 00:26:14,742
discoverability, how easy is to discover the threat? So using the

380
00:26:14,796 --> 00:26:18,746
threats model and security objective, we prioritize the

381
00:26:18,768 --> 00:26:22,186
cards. The stakeholders who prioritize are the security

382
00:26:22,288 --> 00:26:26,170
team, the business stakeholders and the engineers.

383
00:26:26,910 --> 00:26:30,030
And how do we this is an example of

384
00:26:30,100 --> 00:26:35,214
prioritization of the juice shop that

385
00:26:35,252 --> 00:26:38,862
we have done before. The stride model

386
00:26:38,916 --> 00:26:42,546
applying the stride model. So here, as you can

387
00:26:42,568 --> 00:26:46,562
see, we have two cards, ddos and no

388
00:26:46,616 --> 00:26:50,130
strong password configuration. The DDoS

389
00:26:50,550 --> 00:26:54,206
is prioritized top because it affects

390
00:26:54,238 --> 00:26:58,082
the availability and damages the reputation

391
00:26:58,146 --> 00:27:03,654
of the application and it

392
00:27:03,692 --> 00:27:07,110
also increases the possibility

393
00:27:07,870 --> 00:27:12,140
of the reputation of the juice shop because

394
00:27:12,670 --> 00:27:16,010
there is a direct security objective associated with it.

395
00:27:16,080 --> 00:27:19,420
We should reduce the malicious denial of availability of the shop

396
00:27:19,730 --> 00:27:22,160
and the checkout services to the customers.

397
00:27:22,850 --> 00:27:26,606
So that's why the DDoS has been prioritized at

398
00:27:26,628 --> 00:27:31,006
the top. No strong password configuration also

399
00:27:31,108 --> 00:27:35,042
affects the availability of the application and

400
00:27:35,096 --> 00:27:39,362
with a high chance of reproducibility using

401
00:27:39,496 --> 00:27:43,362
an already compromised password or

402
00:27:43,496 --> 00:27:47,234
easily guessable passwords, the tools

403
00:27:47,282 --> 00:27:51,046
available in the market can make sure we run

404
00:27:51,068 --> 00:27:54,760
a brute force attack on dictionary attack on the application

405
00:27:55,130 --> 00:27:58,714
and get the details out of it once the information,

406
00:27:58,832 --> 00:28:01,210
the customer information is revealed.

407
00:28:02,750 --> 00:28:06,540
If the password is too much guessable or

408
00:28:07,150 --> 00:28:10,974
compromised by the attack, it breaches the

409
00:28:11,012 --> 00:28:14,682
personal information identifier

410
00:28:14,746 --> 00:28:18,766
information by the customers, which is our second security

411
00:28:18,868 --> 00:28:22,718
objective. Based upon this security objective and

412
00:28:22,804 --> 00:28:26,580
our dread model, we say that this is a

413
00:28:27,190 --> 00:28:30,610
top security threats. Along with this,

414
00:28:30,680 --> 00:28:34,450
we have three other no logs about how unauthorized entries

415
00:28:34,870 --> 00:28:38,390
APIs are unauthorized. All the APIs are unauthenticated.

416
00:28:39,050 --> 00:28:43,714
Storing customer details in JWT as a classified

417
00:28:43,842 --> 00:28:47,826
or prioritized threat. After identifying

418
00:28:47,858 --> 00:28:51,418
the threat, we are going to mitigate it. How we are

419
00:28:51,424 --> 00:28:55,242
going to mitigate capture the mitigation. It can be a tech step

420
00:28:55,376 --> 00:28:59,146
user story acceptance criteria or Epics or even a

421
00:28:59,168 --> 00:29:03,070
spike to identify if it is a real threats or not. By any

422
00:29:03,140 --> 00:29:07,866
one of these methods we capture the mitigation methods

423
00:29:07,898 --> 00:29:12,202
that we are going to be applied. The common antipattens is not

424
00:29:12,276 --> 00:29:15,780
capturing the mitigations in a project management platform.

425
00:29:17,350 --> 00:29:21,182
If you are using a jira, capture the mitigations in the jira

426
00:29:21,326 --> 00:29:24,926
not in a spreadsheet or emails, which is

427
00:29:24,968 --> 00:29:28,246
not a project management platforms. So you make sure that you

428
00:29:28,268 --> 00:29:31,894
capture the mitigations in the project management platforms and

429
00:29:32,012 --> 00:29:36,118
prioritizing the mitigations over threats just because

430
00:29:36,204 --> 00:29:39,898
the mitigation is a low hanging fruit that should not be done

431
00:29:39,984 --> 00:29:43,882
as first. The threat which is

432
00:29:43,936 --> 00:29:47,062
more riskiest has to be handled

433
00:29:47,126 --> 00:29:50,574
first even though the mitigation is too much complex for

434
00:29:50,612 --> 00:29:53,934
it. And this is an example of

435
00:29:53,972 --> 00:29:57,614
an mitigating that we applied for our juice shop

436
00:29:57,732 --> 00:30:01,418
for the threats identified previously.

437
00:30:01,594 --> 00:30:05,794
So we have created a definition of done which makes sure

438
00:30:05,912 --> 00:30:09,442
all our APIs are authenticated before the moving

439
00:30:09,496 --> 00:30:13,406
the cards to a done. For ddos. We have created acceptance

440
00:30:13,438 --> 00:30:17,666
criteria where the attacker IP

441
00:30:17,698 --> 00:30:21,414
address has to be rejected if

442
00:30:21,452 --> 00:30:24,610
it is found to be malicious and a tech tab

443
00:30:24,690 --> 00:30:28,646
for strong password configuration and epic

444
00:30:28,758 --> 00:30:32,330
for an logging of the unauthorized entries

445
00:30:32,670 --> 00:30:36,314
and finally a spike to see if

446
00:30:36,432 --> 00:30:40,178
we are really vulnerable by storing customer details

447
00:30:40,214 --> 00:30:44,254
in the JWT. And finally we go

448
00:30:44,292 --> 00:30:48,078
into the did we do a good job? Step final

449
00:30:48,164 --> 00:30:51,838
fifth step what are we going to do is we are going

450
00:30:51,844 --> 00:30:54,958
to reflect ourselves on the outcomes of the exercise.

451
00:30:55,134 --> 00:30:59,218
Feedback and continuous improvement is essential to

452
00:30:59,384 --> 00:31:03,454
managing risk. Without feedback, we will never improvise

453
00:31:03,502 --> 00:31:07,142
or do a better job. The key principle is

454
00:31:07,196 --> 00:31:10,802
analyze. Analyzing the scope was the scope

455
00:31:10,866 --> 00:31:14,662
too granular? Was it very big? Can we do anything about

456
00:31:14,716 --> 00:31:18,854
it or should we not do anything? Analyze the tools

457
00:31:18,902 --> 00:31:21,946
used what about the location and remote tools used?

458
00:31:22,128 --> 00:31:25,654
Analyze the outcome is a thread discovered

459
00:31:25,702 --> 00:31:29,514
where a rare find or just a stones should

460
00:31:29,552 --> 00:31:33,546
we tweak the stride model? Should we tweak the examples

461
00:31:33,578 --> 00:31:36,702
that is given to the stakeholders? Should we tween about it?

462
00:31:36,756 --> 00:31:40,826
Should we work on it or not? That's a way depending

463
00:31:40,858 --> 00:31:44,786
upon the outcomes of the exercise you tween and

464
00:31:44,968 --> 00:31:48,226
make it better. The stakeholders. Here is security

465
00:31:48,328 --> 00:31:52,206
teams and the engineers. Once the reflection

466
00:31:52,238 --> 00:31:55,960
is over, we go through the cycle again

467
00:31:56,570 --> 00:31:59,634
for every agile sprints or iterations,

468
00:31:59,762 --> 00:32:03,106
which leads to iterative threat

469
00:32:03,138 --> 00:32:06,626
modeling. How effective is iterative threat

470
00:32:06,658 --> 00:32:10,362
modeling? The main hindering factor of running

471
00:32:10,416 --> 00:32:14,060
a threat modeling exercise is the alignment between

472
00:32:14,750 --> 00:32:18,122
stakeholders like security team,

473
00:32:18,256 --> 00:32:22,110
business team and the development team. Each one

474
00:32:22,260 --> 00:32:26,080
has their own perspective of security

475
00:32:26,930 --> 00:32:30,634
in their mind and agile

476
00:32:30,682 --> 00:32:33,762
threat modelling exercise aligns them

477
00:32:33,816 --> 00:32:37,250
together is common security goal.

478
00:32:37,750 --> 00:32:41,810
This workshop or this exercise should not run

479
00:32:41,880 --> 00:32:45,650
more than 16 minutes. In this exercise

480
00:32:45,730 --> 00:32:50,002
we align on the factor what is the final destination

481
00:32:50,066 --> 00:32:54,438
that we are going to reach or

482
00:32:54,524 --> 00:32:58,122
what we want to deliver. We align together on the

483
00:32:58,256 --> 00:33:01,866
goal threats, prioritization and the

484
00:33:01,888 --> 00:33:05,478
mitigation actions. Once everyone is aligned,

485
00:33:05,574 --> 00:33:09,274
it is very easy to repeat and inject into our every

486
00:33:09,312 --> 00:33:12,858
iteration. One of the agile rituals

487
00:33:12,954 --> 00:33:16,750
is a backlog refining where we refine the stories

488
00:33:17,170 --> 00:33:20,446
that are going to be delivered or picked up in the

489
00:33:20,468 --> 00:33:24,382
next iteration. We can run the exercise

490
00:33:24,446 --> 00:33:27,682
in the same session which should not take more than 15

491
00:33:27,736 --> 00:33:30,834
minutes. By running this using the

492
00:33:30,872 --> 00:33:34,666
simple steps in the backlog refining

493
00:33:34,718 --> 00:33:38,246
for every iteration, we brings in the security

494
00:33:38,348 --> 00:33:42,530
mindset to the development teams and make sure we deliver

495
00:33:42,610 --> 00:33:46,022
secure products. Depending upon your team

496
00:33:46,076 --> 00:33:49,526
position, you can run this exercise the way you want.

497
00:33:49,708 --> 00:33:53,622
If your team sits next to you in the same physical

498
00:33:53,686 --> 00:33:56,300
environment, you can run it face to face.

499
00:33:56,830 --> 00:34:00,650
The steps is print the cue cards from this presentation,

500
00:34:00,990 --> 00:34:05,250
gather everyone against the whiteboard and draw a high level dataflow

501
00:34:05,270 --> 00:34:08,586
diagram on the board. Use stickies or sharpies to capture the threats

502
00:34:08,618 --> 00:34:12,510
and mitigating save the artifacts digitally,

503
00:34:12,930 --> 00:34:16,514
not physically. If the team is hybrid and

504
00:34:16,552 --> 00:34:20,002
remote. Take an inspiration from the pdf attached and use

505
00:34:20,056 --> 00:34:24,018
any whiteboard presentation in your organization to create the capture the

506
00:34:24,024 --> 00:34:27,682
data flow diagram architecture diagram. In this template,

507
00:34:27,826 --> 00:34:31,654
use stickies and capture the threats mitigation one important

508
00:34:31,772 --> 00:34:36,518
point to running the workshop is be time conscious because

509
00:34:36,684 --> 00:34:40,586
you can easily get into a rabbit hole. And if you

510
00:34:40,608 --> 00:34:44,182
want to learn more about threat modeling, there are various

511
00:34:44,246 --> 00:34:48,118
ways. One is an OASP slack

512
00:34:48,294 --> 00:34:52,314
where there are more than 500 threat modelers actively

513
00:34:52,362 --> 00:34:56,320
discussing about threat modeling and its future

514
00:34:56,770 --> 00:35:00,382
and there is a community in Reddit you can

515
00:35:00,436 --> 00:35:03,518
follow for public talks or examples or tools

516
00:35:03,534 --> 00:35:07,742
or techniques. In thoughtworks there is a separate blog

517
00:35:07,806 --> 00:35:11,438
for security which exclusively talks

518
00:35:11,454 --> 00:35:14,260
about threats modeling and the devsecops information.

519
00:35:14,630 --> 00:35:18,546
And finally there is a Martin Fowler blog which talks

520
00:35:18,578 --> 00:35:22,662
about threats modeling for developers and the links are

521
00:35:22,716 --> 00:35:25,830
in the respective blocks.

522
00:35:26,490 --> 00:35:30,314
Now that we have gone through the iterative threat modeling for

523
00:35:30,352 --> 00:35:33,706
development, let's take a step back and understand

524
00:35:33,808 --> 00:35:37,862
how threat modeling is applicable in different stage of projects.

525
00:35:38,006 --> 00:35:42,154
When a new project starts, we start with planning

526
00:35:42,202 --> 00:35:46,670
stage. We run a business level threat modeling

527
00:35:47,170 --> 00:35:50,906
at the requirement gathering stage followed

528
00:35:50,938 --> 00:35:55,490
by a high level threat modeling and architectural design stage.

529
00:35:55,910 --> 00:35:59,140
Once the planning requirement design happens,

530
00:35:59,510 --> 00:36:02,610
we go into a build deploy testing code

531
00:36:02,680 --> 00:36:05,766
phase before the deploy and release happens.

532
00:36:05,948 --> 00:36:09,942
Build deploy testing in the build deploy testing code we

533
00:36:09,996 --> 00:36:13,954
introduce the agile iterative threat modeling

534
00:36:14,002 --> 00:36:17,606
exercise. So threat modeling

535
00:36:17,638 --> 00:36:21,980
at different stages has different ways or different

536
00:36:22,910 --> 00:36:26,122
outcomes. Business level is different from the

537
00:36:26,176 --> 00:36:30,190
application threats modeling and delivery or design level

538
00:36:30,260 --> 00:36:34,074
is different from iterative or agile threat modeling

539
00:36:34,122 --> 00:36:38,506
here. So there are lot of mnemonics

540
00:36:38,618 --> 00:36:42,394
in this talk. You might be a little bit confused about

541
00:36:42,452 --> 00:36:47,010
what all things let's take a quick recap.

542
00:36:47,350 --> 00:36:50,866
You don't need to be a security engineer or expert to run a

543
00:36:50,888 --> 00:36:54,570
threat model. Threat modeling will identify

544
00:36:54,670 --> 00:36:57,990
threats that you will never find in automation.

545
00:36:58,570 --> 00:37:02,310
Threat modeling at any point can be introduced

546
00:37:02,970 --> 00:37:05,270
in the software development lifecycle.

547
00:37:06,330 --> 00:37:10,780
Extend your existing ways of working and ask what can go wrong?

548
00:37:11,230 --> 00:37:15,382
Apply the stride model that is the most quick and flexible

549
00:37:15,446 --> 00:37:18,714
way and use the

550
00:37:18,752 --> 00:37:22,582
dread and security objectives

551
00:37:22,726 --> 00:37:27,498
to prioritize the cards and always create

552
00:37:27,584 --> 00:37:31,050
stories, tasks, acceptance criteria or spike

553
00:37:31,710 --> 00:37:36,574
never are go outside the project development management

554
00:37:36,622 --> 00:37:40,354
tools and don't worry, there is a lot of

555
00:37:40,552 --> 00:37:44,322
people out there in the community to help you

556
00:37:44,376 --> 00:37:47,522
support. Hope you enjoyed my talk.

557
00:37:47,656 --> 00:37:50,818
Feel free to reach to me for any questions

558
00:37:50,904 --> 00:37:54,254
related in my link using my LinkedIn profile.

559
00:37:54,382 --> 00:37:55,760
Thank you for joining my talk.

