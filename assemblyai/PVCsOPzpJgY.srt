1
00:00:00,250 --> 00:00:04,830
Are you an sre? A developer?

2
00:00:06,610 --> 00:00:10,014
A quality engineer who wants to tackle the challenge of

3
00:00:10,052 --> 00:00:13,534
improving reliability in your DevOps? You can enable your

4
00:00:13,572 --> 00:00:16,510
DevOps for reliability with chaos native.

5
00:00:16,930 --> 00:00:20,800
Create your free account at Chaos native Litmus Cloud

6
00:01:16,940 --> 00:01:21,282
everyone, thanks for joining this session today. My name is Ozioma Uzoegwu

7
00:01:21,346 --> 00:01:24,774
and I'm a solutions architect in AWS. In my day

8
00:01:24,812 --> 00:01:28,406
job I work with our SMB customers in the UK and I'm also part

9
00:01:28,428 --> 00:01:32,406
of our front end and mobile specialist team. In this session we'll

10
00:01:32,438 --> 00:01:36,170
be talking about observability in serverless applications.

11
00:01:37,230 --> 00:01:40,346
Hello view of an agenda of what we're going to go through. I'll start by

12
00:01:40,368 --> 00:01:44,014
covering kind of defining what is a serverless application. Then we start

13
00:01:44,052 --> 00:01:47,438
looking at really what is observability and then I'll cover some

14
00:01:47,444 --> 00:01:51,434
of the AWS services that you could use for observability, then wrap

15
00:01:51,482 --> 00:01:54,466
up with some of the open source tools and some of the useful links and

16
00:01:54,488 --> 00:01:57,998
resources you'll find useful as well. When we talk about serverless,

17
00:01:58,094 --> 00:02:01,940
we mean the actions of an event driven application.

18
00:02:02,550 --> 00:02:06,210
It usually consists of an event source which

19
00:02:06,280 --> 00:02:10,254
generates an event, and this can be either identifying

20
00:02:10,302 --> 00:02:14,278
events from changes in the data state or changes in a resource state,

21
00:02:14,364 --> 00:02:17,554
or it can also be changes in a request endpoint,

22
00:02:17,602 --> 00:02:21,594
for example a rest API. And then what an event basically does

23
00:02:21,632 --> 00:02:25,050
is to trigger a lambda function. So a lambda function

24
00:02:25,120 --> 00:02:29,274
is a small single purpose functionality that

25
00:02:29,312 --> 00:02:32,578
can be programmed with any of the six programming languages supported

26
00:02:32,614 --> 00:02:36,634
by lambda. Or you can also bring your own custom runtime using the runtime

27
00:02:36,682 --> 00:02:40,446
API, and then the lambda function basically performs an

28
00:02:40,468 --> 00:02:43,502
action. It can be either based on your business logic,

29
00:02:43,566 --> 00:02:47,970
retrieving data from a data store, storing data from a data store, or just returning

30
00:02:48,470 --> 00:02:51,634
items to the UI, or potentially even

31
00:02:51,672 --> 00:02:54,530
calling an external HTTP endpoint.

32
00:02:55,450 --> 00:02:59,106
If you think about your traditional application stack,

33
00:02:59,218 --> 00:03:03,558
maybe you have some workloads running on Prem. You typically have

34
00:03:03,724 --> 00:03:07,526
number of layers right from the networking storage to

35
00:03:07,548 --> 00:03:10,998
the server hardware, to the operating system to the virtualization

36
00:03:11,094 --> 00:03:14,346
software, right up to your application and data and then your

37
00:03:14,368 --> 00:03:15,530
business logic.

38
00:03:17,550 --> 00:03:21,146
If you can remember as well. You need to kind of monitor all

39
00:03:21,168 --> 00:03:25,326
these various components. They are all your responsibility to kind of manage

40
00:03:25,428 --> 00:03:29,006
and maintain and make sure they are up to date. What tablets does for

41
00:03:29,028 --> 00:03:32,782
you is to really remove that undifferentiated heavy lifting that

42
00:03:32,836 --> 00:03:36,574
comes with managing all these layers of the stack.

43
00:03:36,702 --> 00:03:40,178
So we take care of the responsibility of quite a

44
00:03:40,184 --> 00:03:43,390
number of layers within the typical application stack.

45
00:03:43,470 --> 00:03:46,662
And as a customer you focus only on your application

46
00:03:46,796 --> 00:03:50,454
code and your data and the business logic as well. Let's look

47
00:03:50,492 --> 00:03:53,542
at what an example of a serverless application looks like.

48
00:03:53,676 --> 00:03:57,654
You typically will have a front end,

49
00:03:57,772 --> 00:04:01,926
and we have a service on the platform called AWS amplify console

50
00:04:02,038 --> 00:04:05,546
that you can use to host static content. And by static content I

51
00:04:05,568 --> 00:04:09,430
mean your HTML, your CSS and also your Javascript.

52
00:04:09,590 --> 00:04:13,278
We also have another service on the platform called Amazon Cognito, which you

53
00:04:13,284 --> 00:04:17,162
can use for your authentication. And then from the backend perspective

54
00:04:17,306 --> 00:04:20,942
to kind of service your APIs, we have a number

55
00:04:20,996 --> 00:04:24,446
of services that is really where the serverless comes into the picture.

56
00:04:24,558 --> 00:04:28,530
So we've got API gateway, which is a scalable API

57
00:04:29,030 --> 00:04:32,562
management service that you could use to kind of deploy your rest

58
00:04:32,616 --> 00:04:36,386
or websocket APIs. And they've got the lambda function

59
00:04:36,568 --> 00:04:39,826
which basically responds to events that can be

60
00:04:39,848 --> 00:04:43,426
triggered by your API gateway, which is your API request,

61
00:04:43,538 --> 00:04:47,614
and then an Amazon DynamoDB which is a NoSQL database

62
00:04:47,762 --> 00:04:51,930
that can store your data from the API.

63
00:04:53,790 --> 00:04:56,954
It can even get a bit more complex. So you can

64
00:04:56,992 --> 00:05:00,090
also have other serverless services on the platform. For example,

65
00:05:00,160 --> 00:05:03,646
step function, an example on the slide you could see this is

66
00:05:03,668 --> 00:05:07,454
a simple serverless feedback application whereby a

67
00:05:07,492 --> 00:05:11,322
user can submit a feedback and then it goes through a number of activities

68
00:05:11,386 --> 00:05:15,006
to process that feedback. Starting with sentiment analysis where

69
00:05:15,028 --> 00:05:18,142
it kind of looks at the feedback to say, is it a positive or negative

70
00:05:18,206 --> 00:05:21,870
feedback? Or then it stores the feedback into a DynamoDB

71
00:05:21,950 --> 00:05:25,378
database and then you can send a notification to

72
00:05:25,384 --> 00:05:29,014
the feedback owners to say you've received the feedback, say to

73
00:05:29,052 --> 00:05:31,846
Amazon chime, for example. Okay,

74
00:05:31,948 --> 00:05:35,734
so it can really get complex. And the key message here

75
00:05:35,772 --> 00:05:39,726
is that there are a number of components and services that are involved

76
00:05:39,778 --> 00:05:43,142
here. You could see the lambda functions, you could see the API

77
00:05:43,206 --> 00:05:47,146
gateway. And the key aim of a

78
00:05:47,168 --> 00:05:50,874
serverless web developer is to be able to kind of understand what is

79
00:05:50,912 --> 00:05:54,314
going on between these services, the latency of the transactions,

80
00:05:54,442 --> 00:05:58,126
where there might be potential bottlenecks or failures, or be a lot

81
00:05:58,148 --> 00:06:01,870
more proactive in identifying where there might be issues

82
00:06:02,020 --> 00:06:06,226
and how to resolve those issues. So let's move on to really understand what

83
00:06:06,248 --> 00:06:09,586
is observability. And for me to explain this, I like

84
00:06:09,608 --> 00:06:13,026
to use this analogy that have been used by my colleague Nathan Peck as well

85
00:06:13,048 --> 00:06:16,562
in AWS. So think about this magic box.

86
00:06:16,616 --> 00:06:19,942
You just joined a new company and on your first

87
00:06:19,996 --> 00:06:23,362
day on your onboarding and you are told that you're going to be responsible

88
00:06:23,426 --> 00:06:27,094
for this big magic box. The magic box works basically by taking

89
00:06:27,132 --> 00:06:30,806
in a green circle. The green circle goes in and ten milliseconds

90
00:06:30,838 --> 00:06:34,986
layers, it spits out the Popo Pentagon. And that's how it works.

91
00:06:35,168 --> 00:06:38,954
There's a caveat here that the folks that developed this magic box have now

92
00:06:38,992 --> 00:06:42,146
left the business. They didn't deliver the documentation,

93
00:06:42,278 --> 00:06:45,694
and it's now left for you to manage this magic box. Two, four,

94
00:06:45,732 --> 00:06:49,614
seven, and also make sure it's running 365

95
00:06:49,652 --> 00:06:52,986
days in the year. Now you crack

96
00:06:53,018 --> 00:06:56,146
on with your job, and on the fifth day

97
00:06:56,168 --> 00:07:00,126
of your job you just notice something strange. You put in a green circle

98
00:07:00,238 --> 00:07:03,886
and 2 seconds later you get your popo Pentagon.

99
00:07:03,998 --> 00:07:07,218
This is far, much bigger than the ten milliseconds you are meant to

100
00:07:07,224 --> 00:07:10,694
get out the popo Pentagon. And you wonder what might be wrong, what's going

101
00:07:10,732 --> 00:07:14,578
on? And then another day you put in a green circle

102
00:07:14,674 --> 00:07:17,986
and ten milliseconds layers, you get a blue hexagon.

103
00:07:18,098 --> 00:07:22,006
And again you are wondering what's going wrong here? Why is

104
00:07:22,028 --> 00:07:25,306
it happening? And it might be one of those days. That's how

105
00:07:25,328 --> 00:07:28,826
the system might have behaved. It will correct itself. And then

106
00:07:28,848 --> 00:07:32,486
another day you put in a green cycle, the system catches

107
00:07:32,518 --> 00:07:36,574
fire and this is where it becomes very bad

108
00:07:36,692 --> 00:07:40,442
because your customers are no longer able to kind of fit in their green cycles.

109
00:07:40,506 --> 00:07:43,970
To start looking at your computers, to start looking at who can process

110
00:07:44,040 --> 00:07:47,554
this a lot more better than what you can do. And that's really where

111
00:07:47,592 --> 00:07:51,150
it begins to penetrate and observability

112
00:07:51,230 --> 00:07:56,898
can really help. So why

113
00:07:56,984 --> 00:08:00,166
did you experience a lot of the things you experienced and why couldn't you be

114
00:08:00,188 --> 00:08:03,926
able to kind of resolve that? I think there are a

115
00:08:03,948 --> 00:08:06,898
couple of questions that comes to mind. So the first one is that you didn't

116
00:08:06,914 --> 00:08:10,278
have any observability, so you didn't know anything that was happening in

117
00:08:10,284 --> 00:08:13,914
the box. But some of the questions that you might be asking is really what

118
00:08:13,952 --> 00:08:18,074
is in that box? Why does it behave the way it does when

119
00:08:18,112 --> 00:08:21,994
it behavior changes? Why did it change? And what must be done

120
00:08:22,032 --> 00:08:25,674
to make this behavior a lot more consistent? Because you want consistency

121
00:08:25,722 --> 00:08:28,974
so that you can keep processing those green cycles. There are other

122
00:08:29,012 --> 00:08:32,074
kind of other business stats that you can also look at. What is the usage,

123
00:08:32,122 --> 00:08:35,554
how many customers are expected to be using this box, and what's the kind of

124
00:08:35,592 --> 00:08:39,822
impact in terms of scalability? And also what's the business impact

125
00:08:39,886 --> 00:08:42,766
if green circles are not processed?

126
00:08:42,878 --> 00:08:46,722
What does it mean from a business perspective? If I only process ten green

127
00:08:46,856 --> 00:08:50,402
circles against 20, what does that mean in terms of business impact?

128
00:08:50,466 --> 00:08:53,814
And these are kind of really what

129
00:08:53,932 --> 00:08:57,462
you need to be able to kind of fully understand your whole

130
00:08:57,516 --> 00:09:00,678
system and be able to make sure that you have the right observability

131
00:09:00,774 --> 00:09:04,074
in place. So now what

132
00:09:04,112 --> 00:09:07,706
is observability? For me, a single thing I appreciate if

133
00:09:07,728 --> 00:09:11,090
you can take away from this session is really a good observability.

134
00:09:11,190 --> 00:09:14,286
Allows you to answer questions you did not know you need

135
00:09:14,308 --> 00:09:17,950
to ask. It is proactive, not just reactive.

136
00:09:19,010 --> 00:09:23,086
But when a problem happens, you can basically assess the data in

137
00:09:23,108 --> 00:09:26,978
your system and be able to understand why that problem

138
00:09:27,064 --> 00:09:31,534
occurred. So let's look at the three pillars of observability tooling.

139
00:09:31,582 --> 00:09:35,378
So the first one is the metrics. And metrics are basically

140
00:09:35,464 --> 00:09:38,726
defined AWS, the numeric data that you can measure at

141
00:09:38,748 --> 00:09:42,134
various time intervals. And then you've got the logs which are

142
00:09:42,172 --> 00:09:45,538
basically timestamp records of events, of discrete events

143
00:09:45,554 --> 00:09:49,834
that's really happening within your application. And finally you have traces which

144
00:09:49,872 --> 00:09:53,898
is basically tracing of the HTTP request that

145
00:09:53,984 --> 00:09:57,546
really goes through various components within your application. And these are kind

146
00:09:57,568 --> 00:10:00,570
of the three key pillars when you talk about observability.

147
00:10:02,590 --> 00:10:05,646
Now, if you have a problem within your system and you

148
00:10:05,668 --> 00:10:09,114
want to kind of look at the typical troubleshooting of your query

149
00:10:09,162 --> 00:10:12,366
and your workflow, when you have observability tooling put in

150
00:10:12,388 --> 00:10:15,774
place, the first thing you mostly do is you ask

151
00:10:15,812 --> 00:10:18,994
a question. And this is really what observability helps you to achieve. You can ask

152
00:10:19,032 --> 00:10:22,606
a question to say why is my system behaving this way? Or you might receive

153
00:10:22,638 --> 00:10:26,034
an alarm or a notification about an issue. And the next thing

154
00:10:26,072 --> 00:10:29,270
you do is to be able to kind of use what we call a service

155
00:10:29,340 --> 00:10:33,026
map to look at what might be potentially causing

156
00:10:33,058 --> 00:10:36,258
that issue. Or how can this question I have be answered?

157
00:10:36,434 --> 00:10:40,122
And then you've got the traces which basically looks at the

158
00:10:40,176 --> 00:10:43,434
various touch points of your

159
00:10:43,472 --> 00:10:46,566
request as it goes to the various services. And you can use trace

160
00:10:46,598 --> 00:10:51,286
maps to be able to start identifying the potential reasons

161
00:10:51,318 --> 00:10:54,734
for those issues or to answer the questions you have. And then you can

162
00:10:54,772 --> 00:10:58,106
move over to kind of look at using trace analysis,

163
00:10:58,138 --> 00:11:01,854
to kind of analyze the traces, to kind of have a deeper look of

164
00:11:02,052 --> 00:11:06,254
what might be causing it. And finally, based on that correlation you

165
00:11:06,292 --> 00:11:10,398
have maybe between your traces and metrics, you can then look at your logs

166
00:11:10,494 --> 00:11:13,998
and delve a bit deeper to be able to identify the root cause. And that's

167
00:11:14,014 --> 00:11:17,894
kind of the typical flow of how you kind of troubleshoot when you have

168
00:11:18,012 --> 00:11:21,494
observability tooling in place. But what we then do

169
00:11:21,532 --> 00:11:25,554
is to look at the AWS services that can help you through this workflow

170
00:11:25,682 --> 00:11:29,754
and be able to kind of ensure you have observability put

171
00:11:29,792 --> 00:11:33,514
in place in your application. Now, we have two key

172
00:11:33,552 --> 00:11:36,758
AWS services that helps you to implement observability.

173
00:11:36,854 --> 00:11:40,006
So the first one is the Amazon Cloud Watch, which is a

174
00:11:40,048 --> 00:11:43,658
service that could help you to kind of ingest logs,

175
00:11:43,754 --> 00:11:47,486
create metrics and alarms within your

176
00:11:47,508 --> 00:11:51,626
application. We've also got AWS X ray which is a distributed

177
00:11:51,658 --> 00:11:55,274
tracing service which you could use to instrument tracing

178
00:11:55,322 --> 00:11:58,914
in your application. It also gives you a platform to kind of

179
00:11:59,032 --> 00:12:02,450
perform analytics on your traces and also view a service

180
00:12:02,520 --> 00:12:06,846
map to see kind of where the different components

181
00:12:06,878 --> 00:12:10,070
that your request kind of went through as it's being fulfilled.

182
00:12:10,650 --> 00:12:14,406
Let's delve a bit deep into Amazon Cloud watch, so a

183
00:12:14,428 --> 00:12:18,614
couple of stats here for you. Amazon Cloud Watch processes 1 quadrillion

184
00:12:18,662 --> 00:12:22,090
plus metrics observation each month, and also

185
00:12:22,160 --> 00:12:25,786
it processes 3.9 trillion events each month.

186
00:12:25,888 --> 00:12:29,930
And this is the service we use to monitor our entire

187
00:12:30,000 --> 00:12:33,798
infrastructure of AWS and also Amazon.com, which kind of

188
00:12:33,824 --> 00:12:37,086
gives you a feel of the scale of this service and its suitability to kind

189
00:12:37,108 --> 00:12:39,918
of serve majority of the use cases. Finally,

190
00:12:40,004 --> 00:12:43,662
it also processes 100 petabytes of log ingested every

191
00:12:43,716 --> 00:12:46,610
month, and this is quite massive when it comes to scale.

192
00:12:47,510 --> 00:12:51,070
Let's then go back to the backend of your serverless application, which typically

193
00:12:51,150 --> 00:12:55,214
contains your API gateway, your lambda and your Amazon Dynamodb,

194
00:12:55,262 --> 00:12:58,562
and kind of talk through how you can implement observability

195
00:12:58,706 --> 00:13:02,486
for these services using some of the two key services we've just

196
00:13:02,508 --> 00:13:05,942
talked about on the platform. So the first one

197
00:13:05,996 --> 00:13:09,606
is the built in metrics. So we've got a

198
00:13:09,628 --> 00:13:13,254
number of metrics for AWS lambda service and also the Amazon API

199
00:13:13,302 --> 00:13:17,206
gateway service. So for lambda, for example, we give you beauty metrics

200
00:13:17,238 --> 00:13:20,826
around kind of the invocation errors you have in your lambda function where there might

201
00:13:20,848 --> 00:13:24,106
be potential throttling, the duration of your lambda functions

202
00:13:24,138 --> 00:13:27,706
and potentially the concurrent execution of your lambda functions

203
00:13:27,738 --> 00:13:31,626
as well. With API gateway we have a range of built in APIs.

204
00:13:31,738 --> 00:13:35,134
For the rest APIs, for the HTTP APIs, and also for the websocket

205
00:13:35,182 --> 00:13:38,546
APIs you can start looking at things like latency and also

206
00:13:38,648 --> 00:13:42,260
potential 405 hundred errors you have as well.

207
00:13:43,190 --> 00:13:47,010
Then for Amazon Dynamodb we also have a number of

208
00:13:47,160 --> 00:13:50,718
built in metrics, things like the retro

209
00:13:50,814 --> 00:13:54,150
events, the number of capacity units you have available

210
00:13:54,220 --> 00:13:57,786
on the service as well, those consumed, and those are still kind

211
00:13:57,808 --> 00:14:01,146
of available for you to use. And these are the metrics you can

212
00:14:01,168 --> 00:14:04,982
start ingesting, start understanding a bit more about your serverless

213
00:14:05,046 --> 00:14:08,794
application with

214
00:14:08,832 --> 00:14:12,326
this metrics. We also give you a nice dashboard on Cloudwatch

215
00:14:12,358 --> 00:14:15,774
on how to kind of visualize that metric. So what I've got here

216
00:14:15,812 --> 00:14:19,322
is a pay service metrics dashboard where you can look at your lambda functions

217
00:14:19,386 --> 00:14:22,734
in terms of the invocation of the lambda function and also the duration of those

218
00:14:22,772 --> 00:14:26,814
lambda function. We also provide a cross service metrics

219
00:14:26,862 --> 00:14:30,306
dashboard. And this is really looking at if you have

220
00:14:30,328 --> 00:14:34,094
an application that uses a number of different serverless services like your API,

221
00:14:34,142 --> 00:14:38,218
gateway and step function, you'll be able to kind of use this cross

222
00:14:38,254 --> 00:14:41,794
service metrics dashboard to be able to visualize

223
00:14:41,842 --> 00:14:45,654
what's going on within your application. We know that

224
00:14:45,692 --> 00:14:48,886
the beauty metrics are not enough. There are cases where you

225
00:14:48,908 --> 00:14:52,442
will need your own custom metrics, and this might be, for example,

226
00:14:52,576 --> 00:14:56,298
to look at your business and customer metrics. For example, you want to

227
00:14:56,304 --> 00:14:59,930
monitor the revenue generated by this product,

228
00:15:00,000 --> 00:15:03,366
the sign ups, the daily sign ups you're having, the page views

229
00:15:03,398 --> 00:15:07,134
you're having within your web application. Or you can also start looking

230
00:15:07,172 --> 00:15:10,906
at some of the operational metrics as well. If you think about the CI CD

231
00:15:10,938 --> 00:15:14,218
pipeline, how long it takes you to recover from failure,

232
00:15:14,314 --> 00:15:18,066
the number of calls or pages that you're having, or the

233
00:15:18,088 --> 00:15:21,186
time to resolve an issue, these are some of the metrics that you want to

234
00:15:21,208 --> 00:15:24,420
track that we don't currently support as a built in metrics today.

235
00:15:24,950 --> 00:15:28,142
Also, you can also look at some of the cost errors you have on lambda.

236
00:15:28,206 --> 00:15:31,766
And potentially, if you want to look at other dimensions, add some dimensions to your

237
00:15:31,788 --> 00:15:35,446
metrics. Things like user id, the category or item. These are

238
00:15:35,468 --> 00:15:39,370
some of the scenarios where you might need to build your own custom metrics.

239
00:15:39,790 --> 00:15:44,586
You can create custom metrics for your application using

240
00:15:44,688 --> 00:15:48,374
Cloudwatch, and you use the built in capabilities

241
00:15:48,422 --> 00:15:52,430
of the AWS SDK to call the Cloudwatch putmetric data

242
00:15:52,500 --> 00:15:56,094
API call. And for this API call,

243
00:15:56,132 --> 00:16:00,474
you're charged by metrics and by put call for the data into a metrics

244
00:16:00,602 --> 00:16:03,758
on the right. I've got an example of how this works.

245
00:16:03,844 --> 00:16:08,318
So you just basically call the putmetric data API,

246
00:16:08,414 --> 00:16:12,126
and what it will do is it will kind of take the metrics that you've

247
00:16:12,158 --> 00:16:15,758
defined in your code and the value you've set and push that synchronously

248
00:16:15,774 --> 00:16:19,334
to Cloudwatch. We've also got the

249
00:16:19,372 --> 00:16:22,886
embedded metric format, which I will cover a little bit more shortly on

250
00:16:22,908 --> 00:16:26,550
a different way to do this. So you can also visualize your

251
00:16:26,620 --> 00:16:30,454
custom metrics on Cloudwatch. You could see this is a metric that

252
00:16:30,492 --> 00:16:34,138
kind of tracks upload. So tracks uploaded, just tracks upload to

253
00:16:34,144 --> 00:16:37,626
your system and you'll be able to kind of visualize the line graph of that

254
00:16:37,648 --> 00:16:41,562
metric or so can also view it via numbers. We've also

255
00:16:41,616 --> 00:16:45,306
got what we call the Cloudwatch metrics Explorer,

256
00:16:45,338 --> 00:16:48,874
which lets you kind of drill down to your metrics based on the properties

257
00:16:48,922 --> 00:16:51,040
and tags of that metrics as well.

258
00:16:52,130 --> 00:16:55,370
So let's look at login. Login is one of

259
00:16:55,380 --> 00:16:58,846
the key pillars of observability, and we have a number of built in login

260
00:16:58,878 --> 00:17:03,294
mechanisms for customers across the various services. For API gateway,

261
00:17:03,422 --> 00:17:07,014
we support two levels of login error and info, and you can set

262
00:17:07,052 --> 00:17:10,354
this globally in stage, or you can override it up method

263
00:17:10,402 --> 00:17:14,790
basis for HTTP APIs and also websocket APIs.

264
00:17:15,530 --> 00:17:18,938
We allow customers to kind of use their login using

265
00:17:19,024 --> 00:17:22,330
login variables as well. We also provide

266
00:17:22,400 --> 00:17:25,958
capabilities for customers to kind of enable login within their lambda

267
00:17:25,974 --> 00:17:29,706
function. You can do this through the language specific or

268
00:17:29,728 --> 00:17:33,514
the language equivalent of console log in your application.

269
00:17:33,712 --> 00:17:37,306
Or you can also use the putmetric data API we discussed

270
00:17:37,418 --> 00:17:40,666
shortly in the last slide. Or you can use the embedded metric

271
00:17:40,698 --> 00:17:44,714
format, I'll be covering that to create what we call a structured JSON

272
00:17:44,762 --> 00:17:48,210
Login into Cloud watch, and you can then export that into

273
00:17:48,360 --> 00:17:52,654
Amazon Open search, which is a new name for Amazon Elasticsearch or Amazon

274
00:17:52,702 --> 00:17:56,734
S three, and then do your visualization using tools like kibana or Atena

275
00:17:56,782 --> 00:18:00,246
Quicksight as well. Now let's look

276
00:18:00,268 --> 00:18:03,782
at Cloudwatch embedded metric formats. So if you think

277
00:18:03,836 --> 00:18:07,702
about this, when you log within your application code,

278
00:18:07,756 --> 00:18:11,426
for example within lambda, your log basically comes

279
00:18:11,468 --> 00:18:14,794
out as a text within a log file. And what you then

280
00:18:14,832 --> 00:18:18,426
need to do is you need to kind of process that log, take that

281
00:18:18,608 --> 00:18:21,966
log line, process it, understand what it's all about, and then be able to

282
00:18:21,988 --> 00:18:25,946
potentially create metrics or alarm of it. What Cloudwatch embedded

283
00:18:25,978 --> 00:18:29,386
metric formats helps you to do is to take away that undifferentiated

284
00:18:29,418 --> 00:18:32,942
heavy lifting by basically allowing you to

285
00:18:32,996 --> 00:18:36,314
embed custom metrics within your log file.

286
00:18:36,442 --> 00:18:40,430
And Cloudwatch be able to kind of process that, extract the metrics,

287
00:18:40,510 --> 00:18:43,982
and be able to give you a visualization for that metrics.

288
00:18:44,126 --> 00:18:47,666
You can do that using, you can enable this using the Putlock events

289
00:18:47,698 --> 00:18:50,902
API call, and we support this for a number of open

290
00:18:50,956 --> 00:18:54,166
source client libraries in node, in Python or

291
00:18:54,188 --> 00:18:57,826
in Java. Let's look at an example of Cloudwatch

292
00:18:57,858 --> 00:19:01,706
embedded metric format. On the right, I've got an example of the

293
00:19:01,728 --> 00:19:05,082
structure of the Cloudwatch embedded metric format. So you could

294
00:19:05,136 --> 00:19:08,938
see the details about kind of the lambda function, and you

295
00:19:08,944 --> 00:19:12,954
can also see kind of the snap space and dimension to

296
00:19:12,992 --> 00:19:16,478
help to organize the cloud watch metrics. And then you see the

297
00:19:16,484 --> 00:19:19,802
metric detail, which in this case is price and quantity,

298
00:19:19,946 --> 00:19:23,002
which can be passed by the event payload as well.

299
00:19:23,156 --> 00:19:26,786
This will be sent into Cloudwatch and

300
00:19:26,808 --> 00:19:30,542
the metrics will be extracted and you'll be able to kind of visualize

301
00:19:30,606 --> 00:19:34,706
these metrics within your various dashboards. Let's look

302
00:19:34,728 --> 00:19:37,938
at Amazon Cloudwatch loginsight. So when you've generated your logs,

303
00:19:37,954 --> 00:19:41,494
the next thing is to really start kind of deriving some insights from that

304
00:19:41,532 --> 00:19:44,994
log. And that's really what Amazon Cloud watch loginsight

305
00:19:45,042 --> 00:19:48,726
does for you. It boosts you to interactively search and

306
00:19:48,748 --> 00:19:52,246
analyze your log data within Amazon cloud watch logs.

307
00:19:52,358 --> 00:19:55,434
So for example, here I've got the log

308
00:19:55,472 --> 00:19:59,002
from a lambda functions, and you can be able to kind of filter the log

309
00:19:59,056 --> 00:20:02,826
by a log level, say for error. And you can save your queries

310
00:20:02,938 --> 00:20:06,206
and you can query up to 20 log groups at

311
00:20:06,228 --> 00:20:09,690
a given time. And you do this using a flexible

312
00:20:09,770 --> 00:20:13,870
proposed viewed query language we've built for Cloudwatch login sites.

313
00:20:14,450 --> 00:20:18,542
You can also go a little bit more complex looking at potentially

314
00:20:18,686 --> 00:20:21,934
the top hundred most expensive execution

315
00:20:21,982 --> 00:20:25,742
you've done on your lambda function. And you do this basically via the build duration.

316
00:20:25,886 --> 00:20:29,094
So on the left I've shown the kind of the purpose build

317
00:20:29,132 --> 00:20:32,662
query that you could use for this, and then you could kind of list

318
00:20:32,716 --> 00:20:36,262
out the hundred most expensive invocation based

319
00:20:36,316 --> 00:20:40,006
on the build duration of the lambda function. You can even go

320
00:20:40,028 --> 00:20:43,178
for that to start looking at things around performance. So for example, if you want

321
00:20:43,184 --> 00:20:46,554
to look at the performance of your lambda function, which is a key

322
00:20:46,752 --> 00:20:50,154
info or a key metrics to have or a key insight to have

323
00:20:50,192 --> 00:20:53,018
when you're talking about observability for your serverless application,

324
00:20:53,184 --> 00:20:56,574
I can look at the performance by duration. So based

325
00:20:56,612 --> 00:20:59,774
on the duration of the lambda function, it can start giving you some feel around

326
00:20:59,812 --> 00:21:03,274
the performance of a five minute window looking at the average,

327
00:21:03,322 --> 00:21:07,010
the maximum, the minimum, also the p 90 values

328
00:21:07,830 --> 00:21:09,860
for the duration of the lambda function.

329
00:21:11,030 --> 00:21:14,558
And then when you kind of have your logs done, you have your metrics.

330
00:21:14,574 --> 00:21:17,634
The next thing then is to create alarms, to be able to kind of alert

331
00:21:17,682 --> 00:21:21,382
you when maybe your metrics goes outside

332
00:21:21,436 --> 00:21:25,302
of the threshold or when you kind of identify anomaly within your system.

333
00:21:25,436 --> 00:21:29,046
And to do that, it's quite simple. Within cloud watch, you select your

334
00:21:29,068 --> 00:21:32,666
metrics, you kind of define the statistics for that metric. So you

335
00:21:32,688 --> 00:21:35,818
want the sum of a five minutes period. For example,

336
00:21:35,984 --> 00:21:39,354
you select the threshold type. In this case we're going

337
00:21:39,392 --> 00:21:43,022
for static threshold type and we're looking at anything lower

338
00:21:43,076 --> 00:21:46,974
than five, and then you specify the

339
00:21:47,012 --> 00:21:50,606
notification mechanisms when an alarm occurs, which in this case can be an

340
00:21:50,628 --> 00:21:53,200
SLS notification to an email address.

341
00:21:54,770 --> 00:21:57,886
Something else we have within cloud watch is called cloudwatch

342
00:21:57,918 --> 00:22:01,646
anomaly detection. Think about some types of metrics

343
00:22:01,678 --> 00:22:05,266
you might have where there is potentially some pattern on the

344
00:22:05,288 --> 00:22:08,646
metrics, some discernible pattern on the metrics. What Cloudwatch can

345
00:22:08,668 --> 00:22:12,486
do is to use machine learning to really understand that pattern and be

346
00:22:12,508 --> 00:22:16,770
able to kind of alert when there is an anomaly detected,

347
00:22:16,850 --> 00:22:20,566
something outside of the normal for your metrics. And it

348
00:22:20,588 --> 00:22:23,898
does it for you using a built in machine learning model, and it will be

349
00:22:23,904 --> 00:22:28,090
able to kind of alert you using the various alerting mechanisms within Cloudwatch.

350
00:22:29,070 --> 00:22:32,682
Let's look at AWS X ray. AWS x ray provides

351
00:22:32,746 --> 00:22:36,014
distributed tracing to help you to have an end to end

352
00:22:36,052 --> 00:22:39,486
view of requests flowing through an application for

353
00:22:39,508 --> 00:22:43,194
the lambda service. You can instrument incoming requests for all supported

354
00:22:43,242 --> 00:22:46,526
languages, and you can enable this within your

355
00:22:46,548 --> 00:22:49,858
lambda function by either kind of ticking the checkbox within the settings of

356
00:22:49,864 --> 00:22:53,314
the lambda function, or you can also use any of the infrastructure as

357
00:22:53,352 --> 00:22:56,478
code tools of your choice, if that's the means you use to kind

358
00:22:56,504 --> 00:23:00,310
of deploy your lambda function for API gateway

359
00:23:01,290 --> 00:23:04,674
what API gateway does when it comes to tracing is to insert a tracing

360
00:23:04,722 --> 00:23:08,274
header into HTTP calls, as well as report data tracing

361
00:23:08,322 --> 00:23:12,186
data back to the x ray service. And again, you can enable this

362
00:23:12,288 --> 00:23:15,946
within API gateway via the console or via infrastructure AWS

363
00:23:15,968 --> 00:23:19,046
go to and on the right I've shown what a service map

364
00:23:19,078 --> 00:23:22,918
could look like, which kind of shows the tracing of the

365
00:23:22,944 --> 00:23:26,000
request going through various services for your serverless application.

366
00:23:26,930 --> 00:23:30,126
So on the screen I've got a tracing example. So this is looking at a

367
00:23:30,148 --> 00:23:34,170
particular trace. This is an example of uploading data onto

368
00:23:34,250 --> 00:23:38,238
Amazon SRI. And you can see it kind of shows the various

369
00:23:38,414 --> 00:23:41,934
activities that happen as part of that transaction and the latency

370
00:23:41,982 --> 00:23:45,538
and duration each of them took. So you can see the

371
00:23:45,704 --> 00:23:48,942
initialization of the lambda function and also the upload,

372
00:23:49,006 --> 00:23:52,610
the put object API call to Amazon S three, which unfortunately

373
00:23:52,690 --> 00:23:56,498
returned the full for indices. But that's kind of the level of information you'll

374
00:23:56,514 --> 00:23:59,990
be seeing from the trace. From this transaction.

375
00:24:00,810 --> 00:24:04,218
We've also got the X ray analytics, which you can use to

376
00:24:04,224 --> 00:24:08,218
kind of perform deep analytics on the X ray trace data.

377
00:24:08,384 --> 00:24:11,698
So on the screen you could see a heat

378
00:24:11,734 --> 00:24:15,342
map of retrieved traces, and you can also

379
00:24:15,396 --> 00:24:18,670
kind of filter some of the traces based on a given

380
00:24:18,740 --> 00:24:22,282
time range to be able to compare kind of the traces

381
00:24:22,346 --> 00:24:25,774
returned within those two time range and then to kind of start spotting

382
00:24:25,822 --> 00:24:29,266
potential issues within your application. You can also look at

383
00:24:29,288 --> 00:24:32,706
divergence within a particular parameter within your

384
00:24:32,728 --> 00:24:36,242
trace, for example HTTP status code, or if you've added

385
00:24:36,306 --> 00:24:41,458
additional custom parameter within your traces, for example username.

386
00:24:41,554 --> 00:24:44,914
You can be able to kind of start doing some analysis to compare

387
00:24:44,962 --> 00:24:48,790
different users and what difference you are seeing from the traces

388
00:24:48,870 --> 00:24:52,426
between those two users as well. Let's look

389
00:24:52,448 --> 00:24:55,962
at Cloudwatch service lens. Cloudwatch service lens is

390
00:24:56,016 --> 00:24:59,606
really the service that ties all this together. It provides

391
00:24:59,638 --> 00:25:03,338
a single pane of glass where you can visualize your Cloudwatch metrics

392
00:25:03,354 --> 00:25:06,922
and logs in addition to all the traces from AWS

393
00:25:06,986 --> 00:25:10,494
x ray. It really gives you a complete view of your

394
00:25:10,532 --> 00:25:14,286
application and its dependencies and you'll be able to kind of drill down to

395
00:25:14,308 --> 00:25:18,046
that next level of detail that you need to be able to kind of troubleshoot

396
00:25:18,078 --> 00:25:21,538
or identify where an issue might be going on

397
00:25:21,624 --> 00:25:25,026
within your system. I think it's better to kind

398
00:25:25,048 --> 00:25:28,350
of see a little demo of how service lens works and what you

399
00:25:28,360 --> 00:25:32,118
can do with service lens. You can see all the services within the

400
00:25:32,124 --> 00:25:35,334
service map. It'll be tiny, but we can filter through,

401
00:25:35,532 --> 00:25:38,626
say a particular stage within an API gateway.

402
00:25:38,818 --> 00:25:41,690
Or you can also filter by what we call the x ray group,

403
00:25:41,760 --> 00:25:45,786
which brings out kind of all the services that are involved with

404
00:25:45,808 --> 00:25:49,526
that particular x ray group. You see the trace summary

405
00:25:49,718 --> 00:25:53,040
across the various services. We can select, for example,

406
00:25:53,410 --> 00:25:57,562
a lambda function to be able to see the latency

407
00:25:57,626 --> 00:26:01,070
of the lambda function, the number of requests per minute, and also the

408
00:26:01,220 --> 00:26:04,538
faults per minute. You can drill down for that particular lambda

409
00:26:04,554 --> 00:26:07,810
function where you'll be able to start seeing things like the latency,

410
00:26:08,150 --> 00:26:11,890
number of requests and also the faults as well. You also

411
00:26:11,960 --> 00:26:15,378
be able to drill down to the lambda logs. You can also view the

412
00:26:15,384 --> 00:26:19,078
metrics to the dashboard, also view the traces. I think traces is

413
00:26:19,084 --> 00:26:22,438
where it begins to get interesting, because for the trace within the

414
00:26:22,444 --> 00:26:26,486
lambda function, you have filters that you could select

415
00:26:26,588 --> 00:26:30,170
to be able to filter the trace. You can filter

416
00:26:30,670 --> 00:26:34,346
and also see a very high level view of the traces. Let's focus on

417
00:26:34,368 --> 00:26:39,222
the user agent. We want to see the users from Mozilla Firefox

418
00:26:39,366 --> 00:26:42,682
and also running Windows as the operating system.

419
00:26:42,736 --> 00:26:46,446
So you want to see the users assessing your application from that. Here we

420
00:26:46,468 --> 00:26:49,614
have five traces. We just filter by the P

421
00:26:49,652 --> 00:26:52,846
95 to P 99 trace, and then we'll

422
00:26:52,878 --> 00:26:57,506
be able to see that particular trace for

423
00:26:57,528 --> 00:27:00,894
that percentile, and then we can drill down within that trace.

424
00:27:00,942 --> 00:27:04,898
You'll be able to see what the transaction looks like,

425
00:27:05,064 --> 00:27:08,326
the request, the services that the request went through, so it started from an

426
00:27:08,348 --> 00:27:12,166
API gateway, shows you the latency and the duration and

427
00:27:12,188 --> 00:27:15,698
the response codes from API gateway, and then it moves to a lambda

428
00:27:15,714 --> 00:27:19,926
function and then transacts with Dynamodb to

429
00:27:19,948 --> 00:27:23,386
store data. You also be able to see the logs from the

430
00:27:23,408 --> 00:27:27,702
lambda service. In fact, you also see the logs from API gateway

431
00:27:27,766 --> 00:27:32,670
from lambda, which you can analyze using the Cloudwatch log insights.

432
00:27:33,570 --> 00:27:37,454
So far we have looked at the native AWS services that you could

433
00:27:37,492 --> 00:27:41,454
use for implementing observability within your application.

434
00:27:41,652 --> 00:27:45,066
Now let's go back to that troubleshooting workflow and see

435
00:27:45,108 --> 00:27:48,798
how these services fit into each of the stages of this workflow.

436
00:27:48,974 --> 00:27:52,206
Now in the notification stage you can use Amazon Cloudwatch

437
00:27:52,238 --> 00:27:56,354
alarm to notify if there is any kind of incident within

438
00:27:56,392 --> 00:27:59,590
your application or any metrics that breaches any threshold.

439
00:28:00,010 --> 00:28:03,458
And then you can also use a service lens

440
00:28:03,554 --> 00:28:07,570
with a service map capability to be able to kind of identify potential

441
00:28:07,650 --> 00:28:11,034
points of interest where you might want to deep dive. And then

442
00:28:11,072 --> 00:28:14,586
when it comes to traces, you can use the x ray to

443
00:28:14,608 --> 00:28:18,186
kind of view traces, view maps, see the request as it

444
00:28:18,208 --> 00:28:20,860
goes through various services within the platform,

445
00:28:21,310 --> 00:28:25,518
and then you can start your analysis correlating some of the traces with

446
00:28:25,524 --> 00:28:28,954
the metrics using x ray analytics to kind of dive a bit deep

447
00:28:29,002 --> 00:28:32,446
into each of the traces. And if you need more information and

448
00:28:32,468 --> 00:28:35,842
more context to that particular trace, you can then use

449
00:28:35,976 --> 00:28:39,474
log insights to kind of query your cloud watch logs to be able to

450
00:28:39,512 --> 00:28:42,610
gain more information about that particular incident.

451
00:28:43,270 --> 00:28:47,000
Now let's look at AWS open source observability services.

452
00:28:47,770 --> 00:28:51,666
We have a number of services on the platform for observability,

453
00:28:51,778 --> 00:28:56,162
some open source services. So for example, we've got the AWS distlow

454
00:28:56,226 --> 00:28:59,670
for open telemetry, which you could use for collection.

455
00:28:59,830 --> 00:29:03,094
We've also got the Amazon managed service for Prometheus.

456
00:29:03,142 --> 00:29:07,114
So Prometheus is a very popular open source project

457
00:29:07,232 --> 00:29:10,406
for collecting metrics for your container

458
00:29:10,438 --> 00:29:13,534
workloads, or potentially as well for your serverless application.

459
00:29:13,732 --> 00:29:17,358
We've packaged that AWS a managed service making sure that customers,

460
00:29:17,524 --> 00:29:21,562
you don't need to worry about the online physical infrastructure that runs your primitive

461
00:29:21,626 --> 00:29:25,170
server. We've also got the Amazon Open search service,

462
00:29:25,320 --> 00:29:29,266
which is the new name for the Amazon elasticsearch service,

463
00:29:29,448 --> 00:29:32,786
and you could use that for your logs and traces, to ingest your

464
00:29:32,808 --> 00:29:36,078
logs and traces. And then finally Amazon managed

465
00:29:36,094 --> 00:29:39,702
service for Grafana. Again, Grafana is another popular open

466
00:29:39,756 --> 00:29:43,122
source project to help you to kind of visualize

467
00:29:43,266 --> 00:29:46,742
your metrics, and we've packaged that as well as a managed service,

468
00:29:46,876 --> 00:29:50,646
enabling customers to run Grafana

469
00:29:50,678 --> 00:29:53,770
without worrying about the underlying physical infrastructure.

470
00:29:54,990 --> 00:29:59,142
Let's delve a bit deep into AWS distro for open telemetry.

471
00:29:59,206 --> 00:30:02,054
Before I delve into that, I want to talk a little bit more about open

472
00:30:02,112 --> 00:30:05,742
telemetry. What is it all about? So a recent survey that was done

473
00:30:05,796 --> 00:30:09,850
identified that 50% of companies use at least five observability

474
00:30:09,930 --> 00:30:13,646
tools, and out of within that 50% of the

475
00:30:13,668 --> 00:30:16,882
companies, 30% of them use more than ten

476
00:30:16,936 --> 00:30:20,434
observability tools. Think about developers that work

477
00:30:20,472 --> 00:30:24,178
in these companies. They have to use different

478
00:30:24,264 --> 00:30:27,794
sdks and agents to be able to implement observability within

479
00:30:27,832 --> 00:30:31,654
their application. And this kind of reduces developer velocity and also

480
00:30:31,692 --> 00:30:35,240
increases the learning curve they need to go through to be able to do this.

481
00:30:35,690 --> 00:30:38,422
Also, when it comes to resource consumption,

482
00:30:38,566 --> 00:30:41,866
multiple observability agents and collector agents kind

483
00:30:41,888 --> 00:30:45,414
of increases your resource consumption and can potentially increase

484
00:30:45,462 --> 00:30:48,934
your cost of compute as well. In many cases,

485
00:30:49,062 --> 00:30:52,582
these observability tools do not handshake

486
00:30:52,726 --> 00:30:56,522
in an easy way. So there needs to be some potential manual correlation

487
00:30:56,666 --> 00:31:00,046
with the data you are seeing from one tool with the data you are seeing

488
00:31:00,068 --> 00:31:03,270
from another tools. So mono correlation in some ways is prone

489
00:31:03,290 --> 00:31:06,882
to error. And that is really the problem that the open

490
00:31:06,936 --> 00:31:10,446
telemetry project is looking to solve. So the open telemetry

491
00:31:10,478 --> 00:31:14,274
is an open source project. It's basically an

492
00:31:14,472 --> 00:31:17,858
observability framework for your cloud native software.

493
00:31:18,034 --> 00:31:21,810
It comes with a collection of tools of APIs and sdks,

494
00:31:21,890 --> 00:31:25,234
and it can basically allow you to instrument

495
00:31:25,362 --> 00:31:29,660
to generate, to collect, and also to export telemetry data

496
00:31:30,030 --> 00:31:33,942
for analysis in order to really understand your software

497
00:31:34,006 --> 00:31:37,434
performance and its behavior as well. And by telemetry data,

498
00:31:37,472 --> 00:31:41,542
we're talking about metrics, logs and traces, which are the core pillars

499
00:31:41,606 --> 00:31:45,334
of observability. Let's then look at the AWS

500
00:31:45,382 --> 00:31:49,342
this way. For open telemetry, it's basically a secure, production ready,

501
00:31:49,396 --> 00:31:52,502
open source distribution of open telemetry

502
00:31:52,586 --> 00:31:56,350
supported by AWS. It's an upstream first distro

503
00:31:56,510 --> 00:31:59,854
of open telemetry, which means that AWS contributes

504
00:31:59,902 --> 00:32:03,982
to the upstream first and then builds out the downstream implementation

505
00:32:04,046 --> 00:32:07,130
on AWS distro for open telemetry,

506
00:32:07,310 --> 00:32:10,674
it is certified by AWS for security and predictability,

507
00:32:10,802 --> 00:32:14,582
backed by the AWS support. And what we've also done with

508
00:32:14,636 --> 00:32:18,194
this is to kind of make it easy for customers to integrate

509
00:32:18,242 --> 00:32:21,590
open telemetry in their lambda function via one click deploys.

510
00:32:21,750 --> 00:32:25,782
We've also kind of bundled the open telemetry collector

511
00:32:25,846 --> 00:32:29,674
as a lambda layer. So if you want to integrate open

512
00:32:29,712 --> 00:32:33,054
telemetry into your lambda function using the AWS distro. You can

513
00:32:33,092 --> 00:32:36,366
easily do that via lambda layer, so you don't need to kind of change or

514
00:32:36,388 --> 00:32:40,538
modify your lambda function. You can also export

515
00:32:40,634 --> 00:32:44,014
the data that is collected from AWS distro for open

516
00:32:44,052 --> 00:32:47,006
telemetry to a number of solutions, for example to Cloudwatch,

517
00:32:47,038 --> 00:32:50,722
to x ray, to Amazon managed service for premises, and also to open

518
00:32:50,776 --> 00:32:53,380
site service and other partner solutions as well.

519
00:32:54,630 --> 00:32:58,166
So to end, I'm sharing a couple of resources that will

520
00:32:58,188 --> 00:33:01,686
be useful. So for example, the AWS distro for

521
00:33:01,708 --> 00:33:04,966
Open telemetry will have a GitHub page that you can have a look at

522
00:33:04,988 --> 00:33:08,326
that open source project. Another tool I

523
00:33:08,348 --> 00:33:11,546
didn't talk about in this talk is called the Lambda Power Tool, which you can

524
00:33:11,568 --> 00:33:15,338
also use to implement some availability within your serverless application. Have a

525
00:33:15,344 --> 00:33:19,082
look at that. Also, we've built the

526
00:33:19,136 --> 00:33:22,686
AWS Lambda operator Guide, which is an opinionated guide to

527
00:33:22,708 --> 00:33:26,730
kind of some of the key concepts in operating lambda

528
00:33:26,890 --> 00:33:30,282
within your serverless application. So things around monitoring

529
00:33:30,346 --> 00:33:34,078
is a key area within that guide. Have a look at it as well.

530
00:33:34,164 --> 00:33:38,426
Thank you so much for joining the session. I really appreciate

531
00:33:38,458 --> 00:33:42,202
the time and listening in the session. Again, thank you to comfort

532
00:33:42,266 --> 00:33:45,862
two for inviting me to speak on this session as well and

533
00:33:45,916 --> 00:33:49,620
wish you have a great rest of the conference. Thank you.

