1
00:00:34,610 --> 00:00:38,706
Imagine us. It's Monday, the last sprint

2
00:00:38,818 --> 00:00:42,546
of a project you just had planning. You agreed

3
00:00:42,658 --> 00:00:46,166
with your team that you need to fix two bags, you need to write the

4
00:00:46,188 --> 00:00:50,574
documentation, and you're basically ready to release th

5
00:00:50,692 --> 00:00:53,946
you feel good, you feel motivated, excited,

6
00:00:54,058 --> 00:00:57,390
excited for the release. You've worked so hard.

7
00:00:57,540 --> 00:01:01,360
You're excited for the future and new project that's coming.

8
00:01:02,050 --> 00:01:05,762
It's Monday, but you feel great. You feel that what

9
00:01:05,816 --> 00:01:09,070
you planned with your team is achievable.

10
00:01:09,230 --> 00:01:13,810
So let's just do it on Tuesday,

11
00:01:14,150 --> 00:01:17,638
engineering manager comes to the room and she says,

12
00:01:17,804 --> 00:01:21,894
look, I think it would be good if we run this through

13
00:01:21,932 --> 00:01:24,790
the security just before the release.

14
00:01:25,770 --> 00:01:29,674
And in this case, it would be great, means we

15
00:01:29,712 --> 00:01:33,386
must do it. So you go to the meeting with a

16
00:01:33,408 --> 00:01:37,446
security team, and they ask you tons

17
00:01:37,478 --> 00:01:41,262
of questions, and they look at documentation that

18
00:01:41,316 --> 00:01:43,120
hasn't been finished yet.

19
00:01:43,730 --> 00:01:46,270
And after the meeting,

20
00:01:47,010 --> 00:01:50,894
you end up with a whole bunch of

21
00:01:50,932 --> 00:01:54,546
bugs to fix. And if

22
00:01:54,568 --> 00:01:58,290
you ask me, I also have no idea what a snail is doing

23
00:01:58,440 --> 00:02:02,174
among all of these other bugs. Snails are not bugs.

24
00:02:02,222 --> 00:02:05,960
Right? I've been in this situation

25
00:02:06,890 --> 00:02:10,600
way too many times. Way too many times.

26
00:02:10,970 --> 00:02:16,258
And every project, we would have this lovely

27
00:02:16,354 --> 00:02:20,310
meeting called project retrospective. Do you know this meeting?

28
00:02:20,390 --> 00:02:24,266
And we would be like, oh, you know what? Having security

29
00:02:24,368 --> 00:02:27,802
review at the last sprint of the project,

30
00:02:27,936 --> 00:02:31,006
it's not good. It's stressful. It adds work.

31
00:02:31,108 --> 00:02:34,494
We don't want to do it this way. And the moment,

32
00:02:34,612 --> 00:02:37,882
trust me, the moment the meeting ended

33
00:02:37,946 --> 00:02:41,470
and we closed the door of this

34
00:02:41,620 --> 00:02:45,234
meeting room, we would all

35
00:02:45,352 --> 00:02:49,620
forget. But it. And this

36
00:02:50,070 --> 00:02:53,282
review, security review in the last sprint would

37
00:02:53,336 --> 00:02:56,820
hunt it over and over and over again.

38
00:02:57,530 --> 00:03:01,670
I mean, it would hunt us over and over and over again. To put

39
00:03:01,740 --> 00:03:05,778
things a bit into perspective, my name is Wiktoria Dalach.

40
00:03:05,954 --> 00:03:09,382
I was born in Krakow, Poland, but I'm based in Berlin,

41
00:03:09,446 --> 00:03:13,286
Germany, and I've spent the last decade

42
00:03:13,398 --> 00:03:17,322
building software. Two years ago,

43
00:03:17,456 --> 00:03:21,450
I decided to switch the perspective and

44
00:03:21,520 --> 00:03:25,134
join the security team. And it was great opportunity

45
00:03:25,252 --> 00:03:29,214
for me to see how organization works from

46
00:03:29,252 --> 00:03:33,766
different perspectives, because when I was an engineer,

47
00:03:33,898 --> 00:03:37,534
software engineer would go to the meeting with other engineering

48
00:03:37,582 --> 00:03:41,426
team and other engineering managers, and we

49
00:03:41,448 --> 00:03:45,566
would be peers. We would be like, yeah, let's build it, let's improve it.

50
00:03:45,688 --> 00:03:49,574
Let's do something, whatever this

51
00:03:49,612 --> 00:03:53,542
something was. But when I started working

52
00:03:53,596 --> 00:03:57,320
as a security engineer and I started saying, oh,

53
00:03:57,630 --> 00:03:59,900
this is what is important,

54
00:04:01,230 --> 00:04:04,758
I got pushback. I was like, I was not a peer anymore.

55
00:04:04,774 --> 00:04:08,922
I was another stakeholder. So I

56
00:04:08,976 --> 00:04:12,634
realized that there are some low hanging fruit

57
00:04:12,682 --> 00:04:17,200
like things that you need to pay attention to in order to

58
00:04:17,650 --> 00:04:21,022
create good, secure products. And today

59
00:04:21,076 --> 00:04:25,346
I'm sharing those with you. All the notes from this talk

60
00:04:25,448 --> 00:04:29,442
are available under this link. So no stress about taking

61
00:04:29,496 --> 00:04:33,298
notes or something. We can just enjoy

62
00:04:33,464 --> 00:04:37,480
our one on one conference experience. So first of all,

63
00:04:38,010 --> 00:04:42,710
pay attention to access control. You cannot grant

64
00:04:43,370 --> 00:04:47,522
admin access to everything

65
00:04:47,676 --> 00:04:50,970
and you cannot give it as a freebies.

66
00:04:51,550 --> 00:04:57,162
No, you need to be very careful how

67
00:04:57,216 --> 00:05:00,542
you structure the access control and what

68
00:05:00,596 --> 00:05:04,286
kind of resources people have access to. And look,

69
00:05:04,388 --> 00:05:08,138
this is very difficult for us engineers

70
00:05:08,314 --> 00:05:11,920
because we are like, oh, but we want to see

71
00:05:12,710 --> 00:05:15,886
this feature. We develop some feature,

72
00:05:16,078 --> 00:05:20,994
why can't I access it on

73
00:05:21,032 --> 00:05:24,100
production with my customers data? Right,

74
00:05:24,970 --> 00:05:29,094
you can get the pushback like that. But please be

75
00:05:29,132 --> 00:05:32,120
very strict with the access control.

76
00:05:32,570 --> 00:05:37,654
The role structure in this access control will

77
00:05:37,692 --> 00:05:40,758
not necessarily match the structure of your organization.

78
00:05:40,854 --> 00:05:44,234
Pay attention to that. Even if you are a

79
00:05:44,272 --> 00:05:48,042
senior software engineer, you don't necessarily have to have access

80
00:05:48,096 --> 00:05:51,870
to everything. Even if someone is the CEO of company,

81
00:05:52,020 --> 00:05:55,630
they don't have to access all of their AWS

82
00:05:55,970 --> 00:05:59,246
instances. For example, pay attention to that.

83
00:05:59,428 --> 00:06:02,714
When you are embracing the cloud

84
00:06:02,772 --> 00:06:06,014
native and cloud architecture,

85
00:06:06,142 --> 00:06:09,698
you probably deal with a lot of services,

86
00:06:09,864 --> 00:06:13,874
services that microservices that talk to each other.

87
00:06:14,072 --> 00:06:18,006
And here's the thing, I've heard so

88
00:06:18,028 --> 00:06:21,080
many times that oh, this is an internal service,

89
00:06:21,770 --> 00:06:24,790
we don't need a special authorization for it because,

90
00:06:24,860 --> 00:06:28,762
well, only we know about this

91
00:06:28,816 --> 00:06:31,740
address. This is not true.

92
00:06:32,270 --> 00:06:36,042
This is actually the easiest way to cause a data

93
00:06:36,096 --> 00:06:40,394
breach. So secure your API, secure the connection

94
00:06:40,442 --> 00:06:44,186
between your services and again restrict

95
00:06:44,218 --> 00:06:47,694
the access. Make sure that authorization is

96
00:06:47,732 --> 00:06:50,746
in place. Low hanging fruit,

97
00:06:50,778 --> 00:06:54,782
but super important misconfiguration hurts

98
00:06:54,846 --> 00:06:59,234
if you use defaults. If you

99
00:06:59,432 --> 00:07:03,694
store credentials as a plain text, it's a horrible

100
00:07:03,742 --> 00:07:06,758
threat to security of your product.

101
00:07:06,924 --> 00:07:10,950
So educate yourself. Like search

102
00:07:11,020 --> 00:07:15,910
for the best practices, update your servers,

103
00:07:16,330 --> 00:07:20,074
make sure that if attacker comes to the

104
00:07:20,112 --> 00:07:23,820
system and breaks into your server, for example,

105
00:07:24,830 --> 00:07:28,810
they cannot just read their credentials

106
00:07:29,390 --> 00:07:33,358
for the admin account in plain text. Educate yourself,

107
00:07:33,524 --> 00:07:37,294
read the best practices and follow them. Sometimes it

108
00:07:37,332 --> 00:07:41,600
can be annoying because maybe no one will check it,

109
00:07:42,130 --> 00:07:44,820
but don't overlook it.

110
00:07:45,190 --> 00:07:49,620
Misconfiguration is one of the biggest security

111
00:07:50,230 --> 00:07:53,726
threat for your product. The good thing is that you don't

112
00:07:53,758 --> 00:07:56,962
have to do all of this alone. Lent machines

113
00:07:57,026 --> 00:08:01,302
work for, I mean apps that can

114
00:08:01,356 --> 00:08:05,250
scan your system. So the most popular

115
00:08:05,410 --> 00:08:07,910
solutions are SAS and dust.

116
00:08:08,970 --> 00:08:12,374
Dust is dynamic application security testing

117
00:08:12,422 --> 00:08:17,958
tool and it means that it's

118
00:08:17,974 --> 00:08:21,982
an application that works with

119
00:08:22,036 --> 00:08:25,470
your front end, your web application, and it just

120
00:08:25,540 --> 00:08:29,166
sends malicious input, malicious data there

121
00:08:29,348 --> 00:08:32,554
and sees the response. And if the response is, well,

122
00:08:32,692 --> 00:08:36,820
bad, then it will inform you, alert you about it.

123
00:08:37,350 --> 00:08:40,866
The other type of application

124
00:08:40,968 --> 00:08:46,242
security testing tools is SAS. SaFt is static

125
00:08:46,306 --> 00:08:50,134
application security testing tool.

126
00:08:50,252 --> 00:08:55,830
So the thing is that instead

127
00:08:55,900 --> 00:08:59,802
of dealing with your web

128
00:08:59,856 --> 00:09:03,850
app, SAS tool just goes

129
00:09:03,920 --> 00:09:07,974
into your code base and scans it. So it's

130
00:09:08,022 --> 00:09:12,586
very handy when you're developing things because you can integrate SAS

131
00:09:12,698 --> 00:09:16,538
into your pr, for example, into your workflow.

132
00:09:16,634 --> 00:09:20,574
And every time you

133
00:09:20,692 --> 00:09:24,574
add something new, the SAS tool will run analysis

134
00:09:24,622 --> 00:09:28,242
and tell you, whoa, wait a minute. You just

135
00:09:28,376 --> 00:09:32,094
created a potential SQL injection or misconfiguration.

136
00:09:32,222 --> 00:09:35,800
It is worth implementing, especially if you are

137
00:09:36,250 --> 00:09:39,590
growing organization. If you're a small startup, then maybe,

138
00:09:39,740 --> 00:09:44,066
well, you need to navigate between speed

139
00:09:44,178 --> 00:09:48,362
and security. I understand that. But if you are

140
00:09:48,416 --> 00:09:52,778
already in a growing organization, the sooner you

141
00:09:52,944 --> 00:09:56,380
implement those tools, the better,

142
00:09:57,470 --> 00:10:01,706
because the culture of your organization

143
00:10:01,898 --> 00:10:05,440
will grow with the security in mind, which is

144
00:10:05,890 --> 00:10:09,406
very difficult to implement later. And now

145
00:10:09,508 --> 00:10:13,314
I would like to share something that absolutely blew my

146
00:10:13,352 --> 00:10:16,910
mind when I became my transition

147
00:10:17,070 --> 00:10:19,970
from software engineer to security engineer.

148
00:10:21,750 --> 00:10:25,910
The problem with security is that from

149
00:10:25,980 --> 00:10:30,598
the product team perspective, the product

150
00:10:30,684 --> 00:10:35,170
people. So designers, product managers treat security solely

151
00:10:35,250 --> 00:10:39,002
as an engineering problem. And engineers are

152
00:10:39,056 --> 00:10:42,860
so focused on delivery and on

153
00:10:44,430 --> 00:10:48,060
scoping their mvps that

154
00:10:48,830 --> 00:10:52,894
security features are very often put on

155
00:10:52,932 --> 00:10:57,198
the shelf called nice to have.

156
00:10:57,364 --> 00:11:00,574
The other problem with security is security is an

157
00:11:00,612 --> 00:11:04,306
ocean. It's a vast topic. You have application

158
00:11:04,408 --> 00:11:08,210
security, infrastructure security, cloud security, you have it

159
00:11:08,280 --> 00:11:12,354
security. You have human security. In application

160
00:11:12,472 --> 00:11:16,130
security, you can think, but threats, you can think about vulnerabilities.

161
00:11:18,250 --> 00:11:22,070
It's an ocean, and you're just one developer and

162
00:11:22,140 --> 00:11:26,806
you should deliver secure product.

163
00:11:26,908 --> 00:11:29,930
Right? This is overwhelming,

164
00:11:30,350 --> 00:11:33,180
but I bring you hope.

165
00:11:34,350 --> 00:11:37,740
And the hope is that

166
00:11:38,270 --> 00:11:44,734
we all agree that when

167
00:11:44,772 --> 00:11:48,446
we think about threats, when we think about the dangers for

168
00:11:48,468 --> 00:11:52,694
your product, there is an infinite

169
00:11:52,762 --> 00:11:56,190
amount of threats. It's like an ocean.

170
00:11:56,270 --> 00:11:59,602
Like you cannot analyze enough and find

171
00:11:59,656 --> 00:12:02,974
all of the attack vectors because it's such a dynamic

172
00:12:03,022 --> 00:12:06,802
field. Like every week you get new vulnerabilities.

173
00:12:06,946 --> 00:12:10,146
Every week you hear about a new data breach.

174
00:12:10,258 --> 00:12:13,442
So there is an infinite

175
00:12:13,586 --> 00:12:15,590
amount of threats.

176
00:12:16,970 --> 00:12:20,714
But all

177
00:12:20,752 --> 00:12:24,358
of those threats can be assigned

178
00:12:24,534 --> 00:12:26,570
to one or three categories.

179
00:12:30,410 --> 00:12:33,802
It is so amazing when you think about,

180
00:12:33,856 --> 00:12:35,450
so this ocean,

181
00:12:36,750 --> 00:12:40,122
this ocean, you can

182
00:12:40,176 --> 00:12:44,046
assign to three categories, and these categories are

183
00:12:44,148 --> 00:12:46,990
confidentiality, integrity, and availability,

184
00:12:47,970 --> 00:12:52,430
which are called the CIA triad.

185
00:12:53,570 --> 00:12:57,220
I could make a joke about spice right now,

186
00:12:57,670 --> 00:13:01,630
but the only spice I like to think about are Spice Girls.

187
00:13:01,710 --> 00:13:03,380
So I will skip it.

188
00:13:06,710 --> 00:13:11,094
What it means the CIA triad it

189
00:13:11,212 --> 00:13:14,242
means that you can put the whole ocean,

190
00:13:14,386 --> 00:13:17,778
the whole ocean into three buckets.

191
00:13:17,954 --> 00:13:20,310
Confidentiality, integrity, availability.

192
00:13:21,050 --> 00:13:23,910
The whole ocean and three buckets.

193
00:13:24,350 --> 00:13:27,914
That's amazing. Before I

194
00:13:27,952 --> 00:13:30,860
jump into how to do it,

195
00:13:31,710 --> 00:13:35,082
let's establish what confidentiality,

196
00:13:35,146 --> 00:13:37,502
integrity and availability mean.

197
00:13:37,636 --> 00:13:40,894
Confidentiality means that we want secrets to

198
00:13:40,932 --> 00:13:44,778
be secret. If we are exchanging emails,

199
00:13:44,874 --> 00:13:48,322
I want only you and me to be able to read those

200
00:13:48,376 --> 00:13:51,554
emails. Integrity means

201
00:13:51,592 --> 00:13:54,706
that we get what we expect. When you log in to

202
00:13:54,728 --> 00:13:58,226
your Instagram account, you want to see all of the posts, all of

203
00:13:58,248 --> 00:14:03,554
the followers, all of the following, right? If suddenly

204
00:14:03,602 --> 00:14:06,440
you log in and suddenly everything is wiped out,

205
00:14:06,890 --> 00:14:08,790
that would be suspicious.

206
00:14:09,370 --> 00:14:12,060
Integrity. We get what we expect.

207
00:14:12,510 --> 00:14:16,106
Availability means that we can always access the

208
00:14:16,128 --> 00:14:19,260
information. You can send me an email

209
00:14:19,790 --> 00:14:23,738
right now. You can send me an email in 10 hours,

210
00:14:23,824 --> 00:14:27,422
like during the night. It doesn't matter. You always have access

211
00:14:27,556 --> 00:14:31,246
to your emailing system and you can send an email.

212
00:14:31,428 --> 00:14:34,826
How is it helpful? How is it helpful?

213
00:14:34,938 --> 00:14:38,100
Why am I talking about it?

214
00:14:38,550 --> 00:14:42,706
This is helpful because instead

215
00:14:42,808 --> 00:14:45,890
of approaching the ocean, when you're thinking

216
00:14:45,960 --> 00:14:50,210
about your security, instead of being confused

217
00:14:50,290 --> 00:14:54,070
and looking, oh, should I make sure that this vulnerability

218
00:14:55,130 --> 00:14:59,590
is fixed so we don't introduce this vulnerability or that vulnerability?

219
00:15:00,090 --> 00:15:03,500
Instead of that, instead of

220
00:15:05,870 --> 00:15:09,722
looking at security as an ocean, you can use

221
00:15:09,856 --> 00:15:13,642
the question. The question which

222
00:15:13,696 --> 00:15:18,026
is, how can the CAI of this thing be broken?

223
00:15:18,218 --> 00:15:21,982
Now, I would like you to think, but the project you are working on right

224
00:15:22,036 --> 00:15:25,360
now, and you got it,

225
00:15:25,730 --> 00:15:29,630
you can ask the CIA question for it, how can the CAI

226
00:15:29,710 --> 00:15:33,038
of the project you're

227
00:15:33,054 --> 00:15:36,946
working on be broken? And it changes completely the

228
00:15:36,968 --> 00:15:40,246
way you can approach security. Because instead of being like,

229
00:15:40,348 --> 00:15:44,646
oh my God, I don't know what to think about you look at

230
00:15:44,748 --> 00:15:48,694
the thing that you're building and based

231
00:15:48,732 --> 00:15:52,858
on your building on what you're building, you're asking the question,

232
00:15:53,024 --> 00:15:56,794
it is amazing because

233
00:15:56,912 --> 00:16:00,042
it will work for you. Whatever technology you

234
00:16:00,096 --> 00:16:03,206
use, whether you're

235
00:16:03,238 --> 00:16:05,440
front end, back end, cloud,

236
00:16:06,370 --> 00:16:09,998
no cloud, whether you're, I don't

237
00:16:10,004 --> 00:16:14,090
know, junior me, senior staff director,

238
00:16:14,170 --> 00:16:18,066
product manager, designer. You can always ask

239
00:16:18,168 --> 00:16:21,826
this question. And of course, based on what

240
00:16:21,848 --> 00:16:24,820
you are working on, it won't be just one question.

241
00:16:26,070 --> 00:16:30,514
You will ask questions for each of the categories for confidentiality,

242
00:16:30,642 --> 00:16:32,550
integrity and availability.

243
00:16:33,450 --> 00:16:37,014
For confidentiality, you can ask, who can

244
00:16:37,052 --> 00:16:41,218
see this resource? This is the most basic question.

245
00:16:41,404 --> 00:16:44,010
How do we store credentials?

246
00:16:46,030 --> 00:16:50,282
Do we use default credentials or

247
00:16:50,416 --> 00:16:54,430
credentials? Easy to guess. What do we stored in the logs?

248
00:16:54,930 --> 00:16:58,366
Integrity? Who can create, update and delete a

249
00:16:58,388 --> 00:17:01,934
resource? Is there any way that

250
00:17:01,972 --> 00:17:05,806
a malicious actor sends us malicious code or

251
00:17:05,828 --> 00:17:09,314
malicious data? Via form. Like what happens then?

252
00:17:09,432 --> 00:17:12,610
Is there any way to see a malicious actor

253
00:17:12,950 --> 00:17:16,900
just deleting all the resources of our customer?

254
00:17:19,370 --> 00:17:23,670
Is there a way to prevent that availability?

255
00:17:24,250 --> 00:17:27,302
Of course, the most obvious question

256
00:17:27,356 --> 00:17:30,230
is like is this endpoint rate limited?

257
00:17:30,990 --> 00:17:35,082
But also as developers, we introduce so

258
00:17:35,136 --> 00:17:39,100
many dependencies between our systems. So what happens

259
00:17:39,470 --> 00:17:43,194
when a product that we rely on is down?

260
00:17:43,392 --> 00:17:46,998
Does it mean that the whole product is down or some capabilities

261
00:17:47,094 --> 00:17:51,038
are limited? Asking CI questions

262
00:17:51,124 --> 00:17:54,638
will help you design with security

263
00:17:54,724 --> 00:17:58,402
in mind. And the

264
00:17:58,456 --> 00:18:02,034
question is when should you do it? Like you know what to

265
00:18:02,072 --> 00:18:05,986
do, you know that you should ask the question, but when should

266
00:18:06,008 --> 00:18:09,654
you do it? I cannot tell you

267
00:18:09,692 --> 00:18:13,878
about it without telling you about shifting security left. Shifting security

268
00:18:13,964 --> 00:18:17,670
left is this new approach to security when we

269
00:18:17,740 --> 00:18:21,494
look at the SDL fee. So software development

270
00:18:21,542 --> 00:18:25,482
lifecycle, it is lifecycle if it's a circle of life.

271
00:18:25,616 --> 00:18:29,162
But here's the problem. I don't know about you, but from

272
00:18:29,216 --> 00:18:33,046
my decade experience of developing

273
00:18:33,078 --> 00:18:36,670
software, this is never a cycle. But from my experience,

274
00:18:36,820 --> 00:18:40,990
usually software development timeline

275
00:18:41,410 --> 00:18:44,574
happens. So instead of going around,

276
00:18:44,692 --> 00:18:48,114
going round, you just go analyze, design, develop, test,

277
00:18:48,152 --> 00:18:51,634
maintain, release, basically, and you move

278
00:18:51,672 --> 00:18:55,860
on to a next project. So shifting security left looks at it

279
00:18:56,230 --> 00:18:59,986
and says, well look, remember the story I told you at the beginning,

280
00:19:00,098 --> 00:19:03,974
like when we had security review in the last,

281
00:19:04,172 --> 00:19:07,414
basically last sprint of the

282
00:19:07,452 --> 00:19:10,886
project, shifting security left is

283
00:19:10,908 --> 00:19:14,262
like, no, we ain't going to do it. This is not a good approach.

284
00:19:14,326 --> 00:19:17,818
Let's shift security left, which means let's shift security

285
00:19:17,904 --> 00:19:21,866
to the basically design phase. And why

286
00:19:21,888 --> 00:19:25,854
is it very powerful? Because when

287
00:19:25,892 --> 00:19:29,742
you have code, when you already have design in place,

288
00:19:29,876 --> 00:19:33,326
every change will be very expensive, every change will be

289
00:19:33,348 --> 00:19:36,774
time consuming, every change will be stressful.

290
00:19:36,922 --> 00:19:40,674
But if you design, if you

291
00:19:40,712 --> 00:19:44,674
only have some sketches, then changing your

292
00:19:44,712 --> 00:19:48,002
system is very easy because you just need to move

293
00:19:48,056 --> 00:19:52,386
some lines. So shifting

294
00:19:52,418 --> 00:19:55,702
security left and designing with

295
00:19:55,756 --> 00:20:00,390
security in mind and for security will help you immensely

296
00:20:01,310 --> 00:20:05,386
to build better software and to prevent you from much more

297
00:20:05,408 --> 00:20:09,100
stress and costs. And here's the thing,

298
00:20:10,830 --> 00:20:14,950
how do you implement the CI Triad in your organization?

299
00:20:15,110 --> 00:20:18,654
So first of all, present it to your peers. You can send them this

300
00:20:18,692 --> 00:20:23,326
presentation. You can just email me if you want. I can tell

301
00:20:23,348 --> 00:20:26,462
your company about it. It's not a problem. I would love to help,

302
00:20:26,516 --> 00:20:30,930
I would love more people to use it because it's so easy yet super

303
00:20:31,000 --> 00:20:34,210
powerful. You discuss it with your team, you see

304
00:20:34,280 --> 00:20:38,626
how can you fit in the CIA triad and those questions in

305
00:20:38,648 --> 00:20:42,086
the design phase. And you make it a part

306
00:20:42,108 --> 00:20:45,334
of your process, make it a part of your process

307
00:20:45,452 --> 00:20:49,574
and make it visible. Which means, for example,

308
00:20:49,772 --> 00:20:53,386
you look at templates of, I don't know, the documentation that

309
00:20:53,408 --> 00:20:56,822
you need to write for each project. Maybe it's a solution.

310
00:20:56,886 --> 00:21:00,742
Brief enhancement proposal, request for comments

311
00:21:00,806 --> 00:21:04,414
and you add security section there. Exactly that.

312
00:21:04,452 --> 00:21:08,046
Like how the

313
00:21:08,068 --> 00:21:10,880
CIA of this can be broken. This is the question.

314
00:21:12,210 --> 00:21:16,160
You can add more if you're nice, but basically

315
00:21:16,550 --> 00:21:21,342
you inject security into your product development

316
00:21:21,486 --> 00:21:26,034
process and

317
00:21:26,072 --> 00:21:29,174
that's basically it. And it will help

318
00:21:29,212 --> 00:21:32,840
you develop better solutions for your customers.

319
00:21:33,450 --> 00:21:36,838
And look, there is no week

320
00:21:36,924 --> 00:21:39,110
when we don't hear about a new breach,

321
00:21:40,010 --> 00:21:43,130
about new security vulnerability.

322
00:21:44,750 --> 00:21:48,858
We are in this moment, in this magical moment in history

323
00:21:49,024 --> 00:21:52,762
when we as an industry need to agree

324
00:21:52,896 --> 00:21:56,720
that the time of move fast and break things is over

325
00:21:57,250 --> 00:22:01,182
and we held too much responsibility and

326
00:22:01,236 --> 00:22:04,894
our products influence lives of

327
00:22:04,932 --> 00:22:08,194
so many people that we need to take responsibility and we

328
00:22:08,232 --> 00:22:11,774
need to create better, more secure software

329
00:22:11,902 --> 00:22:15,374
and using the CIA triad. Any tips

330
00:22:15,422 --> 00:22:18,820
that I share with you today is the right good step.

331
00:22:19,910 --> 00:22:23,266
Enjoy the rest of the conference. Thank you

332
00:22:23,288 --> 00:22:27,006
for listening to me and I hope this presentation

333
00:22:27,118 --> 00:22:30,258
was helpful. If you have any comments or questions,

334
00:22:30,344 --> 00:22:33,480
please reach out to me on LinkedIn. Thank you.

