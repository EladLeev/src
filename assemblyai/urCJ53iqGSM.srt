1
00:00:25,410 --> 00:00:29,458
You. Hello. I'm Reuben Rajan

2
00:00:29,474 --> 00:00:32,934
George, and I work as a cloud reliability architect with Accenture. I've been

3
00:00:32,972 --> 00:00:35,750
involved in quality engineering roles for over ten years,

4
00:00:35,820 --> 00:00:38,914
primarily in the area of performance engineering and optimization.

5
00:00:39,042 --> 00:00:41,682
Now, today's talk is directed to the following folks.

6
00:00:41,826 --> 00:00:45,554
Now, these are quality engineers who are currently looking to make a career switch

7
00:00:45,602 --> 00:00:48,726
into SRE. The next folks are the QE engineers who are

8
00:00:48,748 --> 00:00:52,494
currently asked to take up SRE roles, and finally, the product managers who

9
00:00:52,532 --> 00:00:56,542
like to engage their existing QE engineering pool in

10
00:00:56,596 --> 00:01:00,426
operations or SRE activities. And I hope this is going to be helpful.

11
00:01:00,538 --> 00:01:04,010
Modern day sdets, or in other words, software development

12
00:01:04,090 --> 00:01:07,054
engineers in testing, or in other words, quality engineers,

13
00:01:07,102 --> 00:01:10,546
are actually highly skilled automation engineers with not just the

14
00:01:10,568 --> 00:01:14,814
functional knowledge of the applications, but a clear understanding of how systems

15
00:01:14,862 --> 00:01:18,086
function under the hood. Now, these engineers must be aware of all

16
00:01:18,108 --> 00:01:21,606
the black box testing techniques along with hands on development or

17
00:01:21,628 --> 00:01:25,634
coding skills. Many of these sds are equipped with programming skills,

18
00:01:25,682 --> 00:01:29,558
making them capable to read, analyze, troubleshoot and recommend

19
00:01:29,644 --> 00:01:33,078
appropriate grammar and optimized algorithms. Now,

20
00:01:33,164 --> 00:01:36,858
sds today are actually embedded throughout the entire application

21
00:01:36,944 --> 00:01:40,730
development process right from the very beginning. Here are some of these roles

22
00:01:40,810 --> 00:01:44,794
that are played by sdes today. Unlike traditional testers,

23
00:01:44,842 --> 00:01:47,898
sdes today have varied responsibilities.

24
00:01:48,074 --> 00:01:51,882
Traditionally, quality engineers used to focus on manual

25
00:01:51,946 --> 00:01:56,114
functional testing, functional validation, manual testing of all the

26
00:01:56,232 --> 00:01:59,506
application screen flows, and so on. However, today they

27
00:01:59,528 --> 00:02:03,022
have varied responsibilities ranging from functional performance,

28
00:02:03,086 --> 00:02:06,398
security, usability and accessibility validation.

29
00:02:06,494 --> 00:02:09,926
And second thing is that they have a clear understanding of the end to

30
00:02:09,948 --> 00:02:13,206
end functionality of an application from domain and user points of

31
00:02:13,228 --> 00:02:16,918
view. And they always strive to add a bit of sense and context to everything

32
00:02:17,084 --> 00:02:20,634
that can be seen in the way they do their documentation, their test scenarios and

33
00:02:20,672 --> 00:02:24,374
test planning and so on. They also have strong programming skills

34
00:02:24,422 --> 00:02:28,102
to automating repetitive tasks. This could be your test scenario

35
00:02:28,166 --> 00:02:31,662
creation, test data preparation if they have to create

36
00:02:31,716 --> 00:02:35,374
frameworks to do parallel execution, reporting and even

37
00:02:35,412 --> 00:02:39,578
dashboarding, and they have an understanding of potential edge case scenarios.

38
00:02:39,594 --> 00:02:42,926
So they will always look for thinking. They're trained to

39
00:02:42,948 --> 00:02:46,754
think outside the box, and they

40
00:02:46,792 --> 00:02:50,946
help in identifying those edge case scenarios that are usually missed out in application design

41
00:02:51,048 --> 00:02:54,434
and development. And they are also trained to think,

42
00:02:54,472 --> 00:02:58,354
like I said, to think outside the box and create these what if scenarios

43
00:02:58,402 --> 00:03:01,746
that are actually a basis of any hypothesis based testing

44
00:03:01,778 --> 00:03:05,510
techniques. Quality engineers come up with this with a mindset.

45
00:03:06,570 --> 00:03:10,034
These are three words that I use, curiosity, adaptability and exploratory.

46
00:03:10,082 --> 00:03:14,186
Let me explain. Now, they come with a mindset that is very curious to

47
00:03:14,208 --> 00:03:17,482
know things and query whatever that's placed before them,

48
00:03:17,536 --> 00:03:21,254
that actually breeds a positive culture to query why a certain functionality or feature

49
00:03:21,302 --> 00:03:24,694
works a certain way. This leads to more questioning as to why

50
00:03:24,752 --> 00:03:28,174
does even one do the same task over and over again. In other words,

51
00:03:28,212 --> 00:03:32,206
in our modern SRE terms, they always wonder why

52
00:03:32,228 --> 00:03:34,778
are we continuously doing these manual tasks?

53
00:03:34,954 --> 00:03:38,786
We automate those tasks and thereby reducing toil. They also

54
00:03:38,808 --> 00:03:41,874
help create these what if scenarios that probes questions in the house

55
00:03:41,912 --> 00:03:45,170
systems would perform if a certain parameter is changed.

56
00:03:45,510 --> 00:03:49,046
The next attitude that they have is adaptability. And I'm talking from

57
00:03:49,068 --> 00:03:53,190
a third person point of view, so don't mind me taking that angle.

58
00:03:54,330 --> 00:03:57,654
They have an open mindset, and first and foremost is since there

59
00:03:57,692 --> 00:04:01,674
are a lot of new technologies that are coming

60
00:04:01,712 --> 00:04:05,754
out every month quarter, they're open to learning new scripting tools or

61
00:04:05,792 --> 00:04:09,686
languages to enable them to do thorough testing

62
00:04:09,718 --> 00:04:13,482
of the applications that have, irrespective of the technology stack,

63
00:04:13,626 --> 00:04:16,922
whether it be Python, Java, et cetera.

64
00:04:17,066 --> 00:04:20,494
As these architectures evolved, these sdates SRe able to

65
00:04:20,532 --> 00:04:24,346
develop cloud fluency and be able to validate the architecture's

66
00:04:24,378 --> 00:04:28,322
effectiveness, performance and security. What they also are open to do, and are

67
00:04:28,376 --> 00:04:31,694
adaptable, is that they're open to switch roles between functional

68
00:04:31,742 --> 00:04:35,726
validation, which includes API testing and so on, database validation

69
00:04:35,758 --> 00:04:39,218
to test the data consistency, performance validation,

70
00:04:39,314 --> 00:04:42,998
load and stress response resilience, fault orance of the system and the

71
00:04:43,004 --> 00:04:46,326
threat of chaos. And most primarily, they also take up the hat of

72
00:04:46,348 --> 00:04:50,026
the end user and understand how system response actually affects them.

73
00:04:50,048 --> 00:04:53,146
So they see it from an end to end perspective, not only look at the

74
00:04:53,168 --> 00:04:57,210
particular architecture component, and finally they come with an exploratory mindset,

75
00:04:58,670 --> 00:05:02,218
they look out for what can be automated,

76
00:05:02,314 --> 00:05:06,286
so they automate the repetitive tasks, like I said earlier, all those test

77
00:05:06,308 --> 00:05:10,442
scenario creation testers and result analysis, test data generation,

78
00:05:10,506 --> 00:05:13,842
result analytics and inference and so on. And they also would be

79
00:05:13,896 --> 00:05:17,074
helpful in architecting, even architecting and

80
00:05:17,192 --> 00:05:21,134
automating test infrastructures to integrate and orchestrate environment setup,

81
00:05:21,182 --> 00:05:24,270
validation activities, even monitoring setup.

82
00:05:24,430 --> 00:05:27,886
Now, testers today and tomorrow would be involved in these following areas,

83
00:05:27,918 --> 00:05:31,814
and they are mentioned as four bullet points. First thing, and first and foremost is

84
00:05:31,852 --> 00:05:35,254
the autonomous functional validation. And there are a couple of things under that.

85
00:05:35,292 --> 00:05:39,334
They would be able to create automation tests, automation frameworks that are

86
00:05:39,372 --> 00:05:43,462
self maintaining or autonomous. They would be involved in also validating

87
00:05:43,526 --> 00:05:47,562
deployments that are being pushed to production, basically your cloud formation and

88
00:05:47,616 --> 00:05:50,582
your terraform templates.

89
00:05:50,726 --> 00:05:54,494
They are also involved in setting up observability in

90
00:05:54,532 --> 00:05:58,734
the testing space. So in this way that they are able to monitor what

91
00:05:58,772 --> 00:06:03,294
happens under the hood for your test sessions. The second thing that they

92
00:06:03,332 --> 00:06:06,562
would be involved and they have to build skills in the area of machine learning

93
00:06:06,616 --> 00:06:10,126
and so on for any optimization of testing to derive

94
00:06:10,158 --> 00:06:13,822
any sort of analytics and decisions based on those analytics

95
00:06:13,886 --> 00:06:17,106
capture. We'll talk more about that in the coming slides.

96
00:06:17,218 --> 00:06:20,722
Rather than moving from a very reactive performance

97
00:06:20,786 --> 00:06:24,146
testing approach, they will be more evolved in setting

98
00:06:24,178 --> 00:06:28,070
up autonomous frameworks for continuous performance optimization. And I'll talk

99
00:06:28,140 --> 00:06:31,740
some of the key points in this area as well. And finally,

100
00:06:33,230 --> 00:06:36,746
as there is a great impetus to make our systems more reliable and

101
00:06:36,768 --> 00:06:40,166
resilient to any sort of fault, they would be involved

102
00:06:40,198 --> 00:06:43,610
in the evaluation of resilient design patterns.

103
00:06:43,690 --> 00:06:47,338
They would be also evolved in injecting failure scenarios

104
00:06:47,354 --> 00:06:50,762
into production and validating the system behavior.

105
00:06:50,906 --> 00:06:54,462
Now let's go on to the first point now. Autonomous functional validation

106
00:06:54,526 --> 00:06:58,194
in autonomous functional validation, the key points here is that they would be

107
00:06:58,232 --> 00:07:02,862
involved in setting up these test automation frameworks that are autonomous

108
00:07:02,926 --> 00:07:06,454
or self maintaining. Basically what this does is these

109
00:07:06,492 --> 00:07:10,342
frameworks should identify changes in architecture every new

110
00:07:10,476 --> 00:07:13,970
deployment or code push and automatically

111
00:07:14,050 --> 00:07:17,538
update their test code to match up to the updated architecture

112
00:07:17,554 --> 00:07:21,146
and business knowledge. So they would have automation scripts that will be running

113
00:07:21,248 --> 00:07:24,314
and as soon has a new deployment is pushed in,

114
00:07:24,352 --> 00:07:28,234
it senses this new deployment, the new variables, environment variables and so on,

115
00:07:28,272 --> 00:07:32,142
and also updates their test code automatically. The second thing is

116
00:07:32,196 --> 00:07:36,618
this environment provisioning template validation basically is testing

117
00:07:36,714 --> 00:07:40,640
deployment templates. This could be transformation terraform and so on.

118
00:07:41,250 --> 00:07:45,234
And what they would do is validate how

119
00:07:45,272 --> 00:07:49,140
this template ties in those various resources together into an integrated application.

120
00:07:50,710 --> 00:07:54,734
So what the queue would do here is would create the entire stack cloud transformation

121
00:07:54,782 --> 00:07:58,774
stack, for example using the SDK and validate whether the

122
00:07:58,812 --> 00:08:02,278
stack outputs matches the expected behavior and

123
00:08:02,284 --> 00:08:06,306
they pass the test if the stack creation is successful and they'll fail the deployment

124
00:08:06,418 --> 00:08:10,526
if the stack creation integration test fails.

125
00:08:10,658 --> 00:08:14,646
Test session observability what we sre trying to do here is to evaluate

126
00:08:14,678 --> 00:08:18,534
performance regression across application builds while they're doing the functional validation

127
00:08:18,662 --> 00:08:22,042
and identifying any contributing parameters, making use

128
00:08:22,096 --> 00:08:25,418
of your APM tools and applying usage patterns.

129
00:08:25,434 --> 00:08:28,426
This involves setting up observable, even lower environments.

130
00:08:28,618 --> 00:08:32,238
There is trade off with cost and licensing and so on, but there are

131
00:08:32,244 --> 00:08:35,626
a lot of open source solutions that actually your QE

132
00:08:35,658 --> 00:08:39,930
engineers actually use today that facilitate capturing

133
00:08:40,010 --> 00:08:43,278
performance data during your functional validation. This could

134
00:08:43,284 --> 00:08:46,994
be like changes in number of DB call that SRE meta servers API calls metro

135
00:08:47,042 --> 00:08:51,334
service, the time it takes for the DB to read. And since

136
00:08:51,372 --> 00:08:55,362
these environments are actually, as these environments are generated

137
00:08:55,426 --> 00:08:59,190
using transformation thermal, they can be killed even after execution.

138
00:09:00,410 --> 00:09:04,410
So here the test automation engineer

139
00:09:04,830 --> 00:09:08,886
is able to automate even that piece of activity. So it's purely

140
00:09:08,918 --> 00:09:12,574
autonomous in a way. Now, the second thing that

141
00:09:12,692 --> 00:09:16,650
the functional or quality engineers are able to do is to identify

142
00:09:16,730 --> 00:09:20,254
latent failure causal chains because they sre now able to look under

143
00:09:20,292 --> 00:09:23,634
the hood, resulting in outage or

144
00:09:23,672 --> 00:09:27,986
poor experience. Mine usage data from

145
00:09:28,168 --> 00:09:31,986
logs and analyzing key failure patterns and failure propagation across the

146
00:09:32,008 --> 00:09:35,378
stack in test optimization, analytics and decisioning what you see on

147
00:09:35,384 --> 00:09:38,326
the right hand side, the main goal here is to reduce as much toil as

148
00:09:38,348 --> 00:09:41,830
possible. And so how they do this is where quality

149
00:09:41,900 --> 00:09:45,542
engineers should be skilled in statistics and

150
00:09:45,596 --> 00:09:49,146
NLP machine learning techniques to optimize test

151
00:09:49,168 --> 00:09:52,422
suit by performing requirement risk analysis,

152
00:09:52,486 --> 00:09:55,782
removing redundant scenarios, merge these defects,

153
00:09:55,926 --> 00:09:59,734
identify opportunities to sequence test cases,

154
00:09:59,782 --> 00:10:02,898
test scenario prioritization, and improve

155
00:10:02,934 --> 00:10:06,186
test coverage. It also evolved testing failure propensity,

156
00:10:06,298 --> 00:10:09,406
vitality and so on. And one of the

157
00:10:09,428 --> 00:10:13,498
other outcomes of this activity is even optimizing test data

158
00:10:13,604 --> 00:10:16,946
repository. All right, so let me move on

159
00:10:16,968 --> 00:10:21,010
to the next slide. Continuous performance optimization

160
00:10:21,350 --> 00:10:24,546
now this is an interesting area because this applies to my line of

161
00:10:24,568 --> 00:10:28,242
work. And what is the goal of these autonomous

162
00:10:28,386 --> 00:10:32,658
performance optimization techniques is to automatically configure

163
00:10:32,754 --> 00:10:37,106
applications, runtimes, databases, cloud environments individually,

164
00:10:37,218 --> 00:10:40,022
because each of these have their own separate parameters,

165
00:10:40,166 --> 00:10:43,830
and they analyze the relationship between these configuration parameters,

166
00:10:43,990 --> 00:10:48,054
between databases, cloud environments and so on, by continuously

167
00:10:48,102 --> 00:10:51,814
doing performance testing and tuning activities. So for this performance,

168
00:10:51,862 --> 00:10:55,486
engineers today are actually skilled in a couple of things. Earlier they used

169
00:10:55,508 --> 00:10:59,354
to be skilled with your performance testing tools like Jmeter,

170
00:10:59,402 --> 00:11:03,546
neoload and with your pipeline tools and so on, and monitoring tools

171
00:11:03,578 --> 00:11:07,282
like Prometheus, dinosaurs and splunk. But today they should be also

172
00:11:07,336 --> 00:11:11,634
skilled with configuration management tools like

173
00:11:11,672 --> 00:11:15,830
ansible and so on, and also be able to do bash scripting

174
00:11:16,250 --> 00:11:19,986
and able to work with APIs and so on. In addition

175
00:11:20,018 --> 00:11:23,906
to automating the performance test, they're also involved in automating dashboard

176
00:11:23,938 --> 00:11:27,298
creations, which involves automated monitoring environments,

177
00:11:27,394 --> 00:11:29,960
deployments, build version control,

178
00:11:31,150 --> 00:11:34,506
and applying dashboard as a code tools and

179
00:11:34,528 --> 00:11:37,754
techniques. Now, there are cost benefits to this, obviously, there's cost

180
00:11:37,792 --> 00:11:41,070
benefits to any sort of performance optimization. First and foremost

181
00:11:41,490 --> 00:11:45,002
is the system utilization, improves system utilization,

182
00:11:45,066 --> 00:11:48,474
optimized infrastructure and license cost, and improved

183
00:11:48,522 --> 00:11:52,366
customer experience, and improved observability. Now, finally, and one of

184
00:11:52,388 --> 00:11:55,774
my favorite topics is the reliability evaluation. There are two parts to this evaluation

185
00:11:55,822 --> 00:11:59,118
of resilient design patterns that are applied. This involves creating

186
00:11:59,134 --> 00:12:02,206
automated scripts to validate effectiveness of resilience patterns,

187
00:12:02,238 --> 00:12:06,134
applying probably whichever library you use today historics or

188
00:12:06,252 --> 00:12:10,066
Lins four g and so on, and validate patterns like circuit breaking,

189
00:12:10,098 --> 00:12:13,894
rate limiting, bulkheading, timeout handling, and result caching, and so on.

190
00:12:14,092 --> 00:12:17,766
So quality engineers would also be evolved

191
00:12:17,798 --> 00:12:21,766
in determining potential single points of failures and fault

192
00:12:21,798 --> 00:12:25,782
modes using FMEA and STPI techniques. They would evaluate

193
00:12:25,846 --> 00:12:29,846
potential failover scenarios for multi region deployments and testing fallback

194
00:12:29,878 --> 00:12:33,470
scenarios. They would also be involved in identifying potential

195
00:12:33,970 --> 00:12:37,594
dependency failure scenarios. They would also be involved

196
00:12:37,642 --> 00:12:41,290
in evaluating effectiveness or recovery playbooks from a functional

197
00:12:41,370 --> 00:12:45,398
end to end perspective. And not only that, they would be evolved in conducting dry

198
00:12:45,434 --> 00:12:49,022
runs of failure scenarios to validate and finally, chaos testing.

199
00:12:49,086 --> 00:12:52,706
There's a huge ocean of information on this area, but however,

200
00:12:52,808 --> 00:12:56,854
quality engineers will be involved in two key things. One is to automate the

201
00:12:56,892 --> 00:13:00,130
identification, the scenario creation,

202
00:13:00,210 --> 00:13:03,426
the injection of those failure scenarios for pre production and production

203
00:13:03,458 --> 00:13:07,382
environments, and verify whether those testing results match expected system

204
00:13:07,436 --> 00:13:11,026
behavior. This also involves testing failure of all components and external

205
00:13:11,058 --> 00:13:14,594
dependencies, and these failures could be network brownouts, instance failures,

206
00:13:14,642 --> 00:13:18,582
et cetera. So that's all I has for today. I hope this quick

207
00:13:18,636 --> 00:13:22,426
lightning talk would have given you some ideas. You are free to ping

208
00:13:22,458 --> 00:13:26,154
me on LinkedIn with my name, Ruben Rajan George, or on Twitter.

209
00:13:26,202 --> 00:13:30,154
I'm available on the handle. Ruben Rajan

210
00:13:30,282 --> 00:13:32,158
thank you very much. See you later.

