1
00:00:00,410 --> 00:00:06,126
Jamaica. Make up real

2
00:00:06,148 --> 00:00:09,530
time feedback into the behavior of your distributed systems

3
00:00:09,610 --> 00:00:12,490
and observing changes exceptions.

4
00:00:12,570 --> 00:00:16,666
Errors in real time allows you to not only experiment with confidence,

5
00:00:16,778 --> 00:00:20,480
but respond instantly to get things working again.

6
00:00:24,610 --> 00:01:07,030
You sability,

7
00:01:07,130 --> 00:01:11,234
chaos, engineering and game days. I'm really excited to be

8
00:01:11,272 --> 00:01:14,846
with all of you today, so let's

9
00:01:14,878 --> 00:01:18,534
just jump right in. If we've learned anything over the

10
00:01:18,572 --> 00:01:22,226
years, we've the the road to reliability accident

11
00:01:22,338 --> 00:01:26,102
reliability takes work and a plan and a strategy and

12
00:01:26,156 --> 00:01:29,930
a lot of technical actions which include teamwork and collaboration.

13
00:01:30,350 --> 00:01:33,850
So how can you make your systems more reliable and

14
00:01:33,920 --> 00:01:37,194
improve the reliability of everything? Let's talk

15
00:01:37,232 --> 00:01:40,814
about that today. One of the things that we saw a few

16
00:01:40,852 --> 00:01:44,618
weeks ago was this massive outage at AWS,

17
00:01:44,794 --> 00:01:47,600
and think about what that meant for customers.

18
00:01:48,210 --> 00:01:51,710
Look at all of the folks that were impacted.

19
00:01:52,130 --> 00:01:55,170
Our systems are complex,

20
00:01:55,590 --> 00:01:59,422
and when we see something like a major five hour outage,

21
00:01:59,566 --> 00:02:03,026
how can we plan or prepare for those types of

22
00:02:03,048 --> 00:02:05,300
things in the best way possible?

23
00:02:05,990 --> 00:02:10,214
So when we talk about complex systems, what do

24
00:02:10,252 --> 00:02:13,766
we mean? And I'll get there in just a minute. First, I want to let

25
00:02:13,788 --> 00:02:18,002
you know a little bit about me. I'm Julie Gunderson, a senior reliability

26
00:02:18,066 --> 00:02:21,762
advocate here at Gremlin. You can find me on Twitter

27
00:02:21,826 --> 00:02:26,714
at Gund or email me at julie@gremlin.com

28
00:02:26,912 --> 00:02:30,726
prior to joining Gremlin, I was over at Pagerduty

29
00:02:30,758 --> 00:02:35,182
as a DevOps advocate. So I've been in the reliability space for quite some time.

30
00:02:35,316 --> 00:02:39,134
Other than that, I live in the great state of Idaho. Now that

31
00:02:39,172 --> 00:02:42,734
you know who I am, let's jump right in. So a

32
00:02:42,772 --> 00:02:46,990
great resource, if you haven't checked it out, is the book accelerate.

33
00:02:47,150 --> 00:02:49,922
It's a fantastic book written by Dr.

34
00:02:49,976 --> 00:02:53,134
Nicole Forsgren, who's a PhD and responsible

35
00:02:53,182 --> 00:02:56,598
for the Dora report, Gene Kim, who wrote the Phoenix project,

36
00:02:56,684 --> 00:02:59,960
and Jez Humble, who's Sre over at Google.

37
00:03:00,730 --> 00:03:04,226
They've done an amazing job of collecting all the research they've

38
00:03:04,258 --> 00:03:07,462
gathered from practicing DevOps over the years and also

39
00:03:07,516 --> 00:03:11,154
creating the DevOps survey and report. So they took

40
00:03:11,212 --> 00:03:14,890
four years of research and came together to analyze that data

41
00:03:14,960 --> 00:03:19,050
in a great way and bubble it up and say what the most important things

42
00:03:19,120 --> 00:03:23,178
you need to do to create high performing technology organizations.

43
00:03:23,274 --> 00:03:27,054
So building and scaling high performing teams in

44
00:03:27,092 --> 00:03:30,350
accelerate, they focus a lot on tempo and stability.

45
00:03:30,690 --> 00:03:34,618
Now, a lot of times folks ask, how do you measure chaos engineering?

46
00:03:34,714 --> 00:03:37,966
How do you make sure that what you're doing is the right thing when you're

47
00:03:37,998 --> 00:03:41,266
doing this type of work, how do you prove that the work that you

48
00:03:41,288 --> 00:03:44,814
did actually makes a difference and is able to move that needle,

49
00:03:44,942 --> 00:03:48,770
especially if you have a lot of different people doing different projects.

50
00:03:49,190 --> 00:03:52,646
And it's really important to be able to measure back and say,

51
00:03:52,748 --> 00:03:55,794
this is the work that we did, this is how we moved that needle,

52
00:03:55,842 --> 00:03:58,710
and this is the ROI that we got from doing that work.

53
00:03:58,860 --> 00:04:02,154
And over the years, a lot of research has been conducted and

54
00:04:02,192 --> 00:04:06,038
books have been written on how to improve the resilience of our software.

55
00:04:06,214 --> 00:04:09,530
So today I want to dive into two key practices that

56
00:04:09,600 --> 00:04:13,326
improve the key measures of tempo and stability that are outlined in

57
00:04:13,348 --> 00:04:17,178
the book, accelerate. And those two practices are chaos engineering

58
00:04:17,194 --> 00:04:21,194
and game days. And you'll learn practical tips that you can put into action

59
00:04:21,242 --> 00:04:25,570
focused on resource consumption and capacity planning, decoupling services,

60
00:04:25,720 --> 00:04:29,586
large scale outages and deployment pain. And at the end of this, I will let

61
00:04:29,608 --> 00:04:33,490
you know how you can get a free chaos engineering certification.

62
00:04:34,390 --> 00:04:38,258
So what is tempo instability? Tempo is measured

63
00:04:38,274 --> 00:04:42,294
by deployment frequency and change lead time. And stability is measured by

64
00:04:42,332 --> 00:04:46,360
mean time to recover MTTR and change failure rate.

65
00:04:46,810 --> 00:04:50,582
If we break that down even further, deployment frequency

66
00:04:50,646 --> 00:04:54,122
would be the rate that software is deployed to production of

67
00:04:54,176 --> 00:04:58,214
an App Store. So for example, within a range of multiple

68
00:04:58,262 --> 00:05:02,460
times a day to maybe a really long deployment frequency, like once a year,

69
00:05:03,310 --> 00:05:06,798
tempo would be change lead time. So the time it takes to

70
00:05:06,804 --> 00:05:10,382
go from a customer making a request to that feature been

71
00:05:10,436 --> 00:05:14,222
built and rolled out to where the customer can use it. So again,

72
00:05:14,276 --> 00:05:17,998
the time it takes from making the request to the request being satisfied,

73
00:05:18,174 --> 00:05:22,082
and then stability is our mean time to recover. It's the mean

74
00:05:22,136 --> 00:05:26,110
time it takes a company to recover from the downtime of their software

75
00:05:26,270 --> 00:05:30,026
and stability change failures rate is the likelihood of defect

76
00:05:30,078 --> 00:05:33,654
changes. So if you roll out five changes, how many of those will

77
00:05:33,692 --> 00:05:37,286
have a defect? How many of those might you need to roll back, or might

78
00:05:37,308 --> 00:05:40,554
you need to apply a patch for? Is it one out of five or

79
00:05:40,592 --> 00:05:44,042
two out of five? These are the types of metrics that

80
00:05:44,096 --> 00:05:47,050
accelerate recommends that you measure.

81
00:05:47,390 --> 00:05:50,762
So back to the key practices. As I mentioned,

82
00:05:50,816 --> 00:05:53,790
the key practices are chaos engineering and game days.

83
00:05:53,940 --> 00:05:57,802
And according to Accelerate, you should focus on improving reliability,

84
00:05:57,946 --> 00:06:01,946
because it's the foundation that enables you to have a really great tempo.

85
00:06:02,058 --> 00:06:05,502
It enables you to improve developer velocity,

86
00:06:05,646 --> 00:06:09,886
which makes so much sense. But what's really nice is that they're backing

87
00:06:09,918 --> 00:06:12,754
this up with data over years of research.

88
00:06:12,952 --> 00:06:16,542
And we know that engineers feel more confident when software

89
00:06:16,606 --> 00:06:19,750
is reliable. They feel more confident to write new code,

90
00:06:19,820 --> 00:06:23,750
and more confident that the features that they're building are going to work well.

91
00:06:23,900 --> 00:06:27,726
They understand these different failure modes because they've been focusing

92
00:06:27,778 --> 00:06:31,446
on reliability and have been trying to improve reliability.

93
00:06:31,638 --> 00:06:35,002
So that makes you actually able to ship code

94
00:06:35,056 --> 00:06:38,902
faster and more reliably. It's really exciting

95
00:06:38,966 --> 00:06:42,894
when you can ship new features that work and that you can trust and

96
00:06:42,932 --> 00:06:46,266
features that meet requirements in accelerate.

97
00:06:46,298 --> 00:06:49,802
They say that we should build systems that are designed to be deployed easily

98
00:06:49,866 --> 00:06:53,482
and that can detect and tolerate failures and can have various

99
00:06:53,546 --> 00:06:56,350
components of the system updated independently.

100
00:06:56,510 --> 00:07:00,034
And this is a lot of different things that are really great to work towards.

101
00:07:00,152 --> 00:07:04,210
And I want to focus on the detect and tolerate failures specifically.

102
00:07:04,710 --> 00:07:08,722
So what's the best way to know if your system can detect and tolerate failures?

103
00:07:08,866 --> 00:07:12,610
Chaos engineering. And that's the best way, because you're

104
00:07:12,690 --> 00:07:16,534
purposefully injecting real failures to see how your system can

105
00:07:16,572 --> 00:07:20,470
handle that. So let's look at the basics of chaos engineering.

106
00:07:20,630 --> 00:07:24,022
Chaos engineering is a misnomer. We're really simulating

107
00:07:24,086 --> 00:07:28,090
the chaos of the real world in a controlled environment.

108
00:07:28,750 --> 00:07:32,010
Introducing chaos is methodical and scientific.

109
00:07:32,170 --> 00:07:35,290
You start with a hypothesis and experiment

110
00:07:35,370 --> 00:07:39,242
to validate that hypothesis. You start with the smallest

111
00:07:39,306 --> 00:07:42,494
increment that will yield a signal. And then you move safely from

112
00:07:42,532 --> 00:07:46,194
small scale to large scale teams, and safely from dev to staging to

113
00:07:46,232 --> 00:07:49,650
production. Communication is important,

114
00:07:49,720 --> 00:07:52,898
so you want to make sure you share your plans with everyone you want to

115
00:07:52,904 --> 00:07:56,346
think through. What if there's an incident? You don't want to negatively

116
00:07:56,398 --> 00:07:59,654
affect other teams. You also want to share what you learn,

117
00:07:59,692 --> 00:08:03,414
because chaos engineering is about learning, and sharing what you

118
00:08:03,452 --> 00:08:07,234
learn makes everyone better engineers. So share internally

119
00:08:07,282 --> 00:08:10,614
and externally, there is a chaos engineering

120
00:08:10,662 --> 00:08:14,634
slack, which is a great online resource you can find@gremlin.com

121
00:08:14,832 --> 00:08:18,614
community. You can talk to other people who are practicing

122
00:08:18,662 --> 00:08:22,094
chaos engineering, or if allowed, write a blog about it.

123
00:08:22,212 --> 00:08:25,898
Share this with people so that they can learn the best practices

124
00:08:25,994 --> 00:08:29,806
of chaos engineering. Chaos engineering is

125
00:08:29,828 --> 00:08:34,014
about iteration. We're creating a hypothesis. You're running an experiment.

126
00:08:34,142 --> 00:08:37,614
Then you're creating tasks to improve your software and processes,

127
00:08:37,742 --> 00:08:41,266
updating that hypothesis and repeating. And then

128
00:08:41,288 --> 00:08:44,610
you increase your blast radius and keep repeating.

129
00:08:45,110 --> 00:08:49,254
To sum it up, this is what chaos engineering is, thoughtful and

130
00:08:49,292 --> 00:08:52,834
planning experiments to reveal weaknesses in systems,

131
00:08:52,882 --> 00:08:56,486
both technical and human. And so we want to think through where is

132
00:08:56,508 --> 00:09:00,006
our tech broken or insufficient? Where does that user

133
00:09:00,038 --> 00:09:03,786
experience break? Does our auto scaling work? Is our

134
00:09:03,808 --> 00:09:07,194
monitoring and alerting setup? And we also want to think

135
00:09:07,232 --> 00:09:10,838
about our human systems and processes. Are they broken or ill

136
00:09:10,864 --> 00:09:14,254
equipped? Is that alert rotation working? Are the

137
00:09:14,292 --> 00:09:18,250
documentation and playbooks up to date? How about the escalation

138
00:09:18,330 --> 00:09:21,600
process. These are all things that we should be thinking through,

139
00:09:22,130 --> 00:09:25,874
and now is the best time, because systems are

140
00:09:25,912 --> 00:09:29,202
complex and they become more complex over time. So let's start

141
00:09:29,256 --> 00:09:32,706
when things are less complex. Now,

142
00:09:32,728 --> 00:09:36,262
I want to talk a bit about applying the scientific method to

143
00:09:36,316 --> 00:09:40,386
chaos engineering. To measure how systems

144
00:09:40,418 --> 00:09:44,274
change during an experiment. It's important to understand how they behave

145
00:09:44,322 --> 00:09:47,762
now. And this involves collecting relevant metrics from target

146
00:09:47,826 --> 00:09:51,834
systems under normal load, which provide that baseline for

147
00:09:51,872 --> 00:09:55,434
comparison. So using that data, you can measure exactly how

148
00:09:55,472 --> 00:09:58,954
your systems change in response to an attack. And if

149
00:09:58,992 --> 00:10:02,014
you don't have baseline metrics, that's okay.

150
00:10:02,132 --> 00:10:06,250
You can actually start now and start collecting those metrics,

151
00:10:06,330 --> 00:10:09,950
and then use chaos engineering to validate those metrics.

152
00:10:11,250 --> 00:10:14,446
One of the most powerful questions in chaos engineering is,

153
00:10:14,548 --> 00:10:18,306
does this work the way I think it does? Once you've got an idea

154
00:10:18,328 --> 00:10:22,306
of how your system will work, think about how you're going to validate that.

155
00:10:22,408 --> 00:10:25,654
What type of failure could you inject to help prove or

156
00:10:25,692 --> 00:10:29,746
disprove your hypothesis? What happens if your systems don't respond

157
00:10:29,778 --> 00:10:33,282
the way you expected? So you've chosen a scenario,

158
00:10:33,346 --> 00:10:36,934
the exact failure, to simulate what happens next.

159
00:10:37,052 --> 00:10:41,162
And this is an excellent thought exercise to work through as a team,

160
00:10:41,296 --> 00:10:44,854
because by discussing a scenario, you can hypothesize on the expected

161
00:10:44,902 --> 00:10:48,714
outcome. When running that in production, you can think through what the impact to

162
00:10:48,752 --> 00:10:51,558
customers would be to the dependencies.

163
00:10:51,734 --> 00:10:55,674
And once you have a hypothesis, you'll want to determine which metrics to measure

164
00:10:55,722 --> 00:10:59,178
in order to verify or disprove your hypothesis.

165
00:10:59,354 --> 00:11:03,278
And it's good to have a key performance metric that correlates to customer

166
00:11:03,364 --> 00:11:06,766
success, such as orders per minute or stream starts

167
00:11:06,798 --> 00:11:10,146
per second. As a rule of thumb, if you ever see an

168
00:11:10,168 --> 00:11:14,770
impact to these metrics, you want to make sure that you halt the experiment immediately.

169
00:11:15,430 --> 00:11:18,918
And after you've formed your hypothesis, you want to look at

170
00:11:19,004 --> 00:11:22,770
how you can minimize your blast radius prior to the experiment.

171
00:11:22,850 --> 00:11:26,118
And I'm going to talk about blast radius a little bit more

172
00:11:26,284 --> 00:11:30,598
in a few minutes. But blast radius is usually measured

173
00:11:30,614 --> 00:11:34,266
in customer impact. Like, maybe 10% of the customers could

174
00:11:34,288 --> 00:11:38,554
be impact, but it can also be expressed in hosts or services or

175
00:11:38,592 --> 00:11:41,478
other discrete parts of a customer infrastructure.

176
00:11:41,654 --> 00:11:45,254
So when running a chaos experiment, you want to think about that blast

177
00:11:45,302 --> 00:11:49,054
radius. You always want to have a backup plan in case

178
00:11:49,092 --> 00:11:52,222
things go wrong. And you need to accept that sometimes even

179
00:11:52,276 --> 00:11:56,206
the best backup plan can fail. So talk through how you're

180
00:11:56,238 --> 00:11:59,634
going to revert the impact. One of the important things

181
00:11:59,672 --> 00:12:02,958
with chaos engineering is to understand safely.

182
00:12:03,054 --> 00:12:06,966
So you want to make sure the impacts can be

183
00:12:07,148 --> 00:12:10,646
reverted, allowing you to safely abort and return to

184
00:12:10,668 --> 00:12:15,862
that steady state. If things go wrong after

185
00:12:15,916 --> 00:12:19,606
you run your first experiment, there's likely going to be one of

186
00:12:19,628 --> 00:12:23,206
two outcomes. Either you've verified that your system is resilient to the failure

187
00:12:23,238 --> 00:12:26,534
you've introduced, or you found a problem that needs to be fixed.

188
00:12:26,662 --> 00:12:29,946
Both of these are great outcomes because, on one hand, you've increased your

189
00:12:29,968 --> 00:12:33,546
confidence in the system and its behavior, or on the

190
00:12:33,568 --> 00:12:36,430
other hand, you've found a problem before it caused an outage.

191
00:12:36,770 --> 00:12:40,654
Make sure that you have documented the experiments and

192
00:12:40,692 --> 00:12:44,434
the results. And as I mentioned before, a key

193
00:12:44,472 --> 00:12:48,190
outcome of chaos engineering is planning. And through these experiments,

194
00:12:48,270 --> 00:12:52,174
you're planning about your systems, you're validating your hypothesis, you're teaching

195
00:12:52,222 --> 00:12:55,742
your teammates. So share the results of your chaos

196
00:12:55,806 --> 00:12:59,142
engineering experiments with your teams, because you can help

197
00:12:59,196 --> 00:13:02,534
them understand how to run their own experiments and where

198
00:13:02,572 --> 00:13:06,150
the weaknesses in their systems are. So, let's talk about,

199
00:13:06,220 --> 00:13:09,974
how do you get started? As I mentioned, you want to pay

200
00:13:10,012 --> 00:13:13,242
attention to the blast radius. So you want to start small.

201
00:13:13,376 --> 00:13:16,774
You want to be careful. You want to start on a single host

202
00:13:16,822 --> 00:13:19,894
or service, not the whole application or fleet.

203
00:13:20,022 --> 00:13:24,238
You want to start in a controlled environment with a team that's ready.

204
00:13:24,324 --> 00:13:27,306
We're not trying to catch folks off guard.

205
00:13:27,498 --> 00:13:31,470
Then, once you've done that, you want to expand that blast radius,

206
00:13:32,130 --> 00:13:36,446
adopt the practice in development. So engineers are architecting for failure.

207
00:13:36,558 --> 00:13:40,094
Get confident testing in development, and then move to staging.

208
00:13:40,222 --> 00:13:43,842
Start small in staging, then expand your blast radius and

209
00:13:43,896 --> 00:13:47,762
move to production. And start small and increase. This is

210
00:13:47,816 --> 00:13:51,254
really similar to how you do development, so you don't need to overthink it.

211
00:13:51,292 --> 00:13:55,094
You can work iteratively, like with code, and move up the environments, like with

212
00:13:55,132 --> 00:13:57,814
code. You do know how to do this,

213
00:13:58,012 --> 00:14:01,174
and so I want to show you a real demo of what this actually looks

214
00:14:01,212 --> 00:14:05,238
like. Now, we'll be using an open source application and Gremlin

215
00:14:05,334 --> 00:14:08,426
to do this demo, which there is Gremlin free. But I want to let you

216
00:14:08,448 --> 00:14:11,754
know, this is just to show you what it looks like. You can use any

217
00:14:11,792 --> 00:14:15,038
chaos engineering tool. So this is a

218
00:14:15,044 --> 00:14:18,318
really cool open source project, and you can find it on the Google Cloud platform

219
00:14:18,404 --> 00:14:22,154
GitHub webpage. It's a repo called the bank of Anthos. And I'll

220
00:14:22,202 --> 00:14:25,694
send some links so that you can check it out. So, this is the architecture

221
00:14:25,742 --> 00:14:29,486
diagram. It's really great for learning how to practice chaos engineering

222
00:14:29,518 --> 00:14:33,038
because it's an Internet banking application, and it has multiple languages.

223
00:14:33,134 --> 00:14:36,982
So both Python and Java, which is pretty common these days when you're working

224
00:14:37,036 --> 00:14:39,990
on a system, there's oftentimes those multiple languages.

225
00:14:40,330 --> 00:14:44,054
There's also two database. There's the account database and

226
00:14:44,092 --> 00:14:46,786
a ledger database, which are running on postgres.

227
00:14:46,978 --> 00:14:51,018
And then we have our transaction history service, a balance reader service,

228
00:14:51,104 --> 00:14:54,906
a ledger writer context user service, our front end, and a

229
00:14:54,928 --> 00:14:58,060
load generator. So this is what it looks like.

230
00:14:58,830 --> 00:15:01,994
Now, one of the questions we want to ask ourselves when we're starting to practice

231
00:15:02,042 --> 00:15:05,306
chaos engineering is what is our hypothesis?

232
00:15:05,498 --> 00:15:08,590
We want to think through what is going to happen.

233
00:15:08,660 --> 00:15:12,318
So does black holing a critical path service like the

234
00:15:12,324 --> 00:15:16,354
balance reader result in a graceful degradation of the customer experience?

235
00:15:16,552 --> 00:15:19,746
You want to think through that. What would happen if

236
00:15:19,768 --> 00:15:23,662
we make the balance reader unavailable? So we make it unreachable,

237
00:15:23,726 --> 00:15:27,346
which is what we call a black hole attack in Gremlin is. But if

238
00:15:27,368 --> 00:15:31,000
we make that unavailable, what is going to occur to the application?

239
00:15:32,090 --> 00:15:35,494
Do you have any ideas? You want to think through those?

240
00:15:35,612 --> 00:15:38,246
You want to think through what will happen? Will we be able to use the

241
00:15:38,268 --> 00:15:41,666
website? Will we be able to see what the balance is? Will we be able

242
00:15:41,708 --> 00:15:45,430
to deposit funds? And these are the questions we should ask ourselves.

243
00:15:45,590 --> 00:15:49,002
So my guess would be that if we black hole the balance reader service,

244
00:15:49,136 --> 00:15:52,806
I think we might see an error message, like unable to read the balance,

245
00:15:52,918 --> 00:15:56,478
we might get a user friendly message. We also hope that we

246
00:15:56,484 --> 00:16:00,574
would get like a loading, that there was some sort of issue with

247
00:16:00,612 --> 00:16:04,174
the balance reader, that it was no longer available, or maybe

248
00:16:04,212 --> 00:16:08,350
it was really well built and we could just fail over automatically.

249
00:16:08,510 --> 00:16:11,826
So maybe if that one service was unavailable because it was running on

250
00:16:11,848 --> 00:16:15,442
Kubernetes, maybe there's going to be some redundancy there and

251
00:16:15,496 --> 00:16:17,720
we'll be able to actually fail over.

252
00:16:19,210 --> 00:16:22,258
Let's see what we can do. So, within Gremlin,

253
00:16:22,274 --> 00:16:26,226
you can select the balance reader service and we're selecting it as a Kubernetes replica

254
00:16:26,258 --> 00:16:29,606
set. Now, we can already learn a lot here because we can see in

255
00:16:29,628 --> 00:16:33,350
the visualization that there's only one pod impacted.

256
00:16:33,430 --> 00:16:37,126
So if there were multiple pods with the balance reader, we'd actually see two pods

257
00:16:37,158 --> 00:16:40,826
implemented or impacted. So that shows us already that when we run

258
00:16:40,848 --> 00:16:44,158
this chaos engineering experiment, we're going to make all of

259
00:16:44,164 --> 00:16:48,202
the balance reader service unavailable because there's no secondary pod,

260
00:16:48,346 --> 00:16:51,726
which is a pretty large blast radius if you think about it.

261
00:16:51,908 --> 00:16:54,794
So this is what it looks like when we run our experiment,

262
00:16:54,922 --> 00:16:58,274
the balance reader will appear as, and this can

263
00:16:58,312 --> 00:17:02,034
be really confusing for the user. So if I was building this

264
00:17:02,072 --> 00:17:05,154
as a real Internet banking app for a bank, they'd likely say,

265
00:17:05,192 --> 00:17:08,434
no way. We're going to get so many support tickets if this

266
00:17:08,472 --> 00:17:11,654
really happens. That's not even a real error message.

267
00:17:11,852 --> 00:17:15,238
And this could make users really confused. And then they're going to pick up

268
00:17:15,244 --> 00:17:19,062
that phone and start calling the call center. And then that increases

269
00:17:19,126 --> 00:17:23,500
the cost of having to answer all of those calls, and it causes additional problems.

270
00:17:24,030 --> 00:17:26,534
But we also want to check other functionality,

271
00:17:26,582 --> 00:17:30,090
too. Does this affect other dependencies?

272
00:17:31,390 --> 00:17:35,486
So the user is actually still able to make a deposit of $1,000 while

273
00:17:35,508 --> 00:17:39,262
the balance reader service is in this black hole or unreachable state.

274
00:17:39,396 --> 00:17:43,166
And you can see this in the transaction history, that we've added money to our

275
00:17:43,188 --> 00:17:47,360
bank account and we get a successful message, but the balance is still.

276
00:17:49,110 --> 00:17:52,562
But if we try to make a payment, we're unable to do it. And then

277
00:17:52,616 --> 00:17:56,738
we get this awesome engineer friendly message, but not

278
00:17:56,824 --> 00:18:00,274
really a generally friendly customer facing message.

279
00:18:00,472 --> 00:18:03,750
You've got to kind of think about that. Do you think your friends and family

280
00:18:03,820 --> 00:18:07,334
who don't work in tech would know what this means? Or are they going to

281
00:18:07,372 --> 00:18:10,646
start calling you and ask you what's going on?

282
00:18:10,748 --> 00:18:14,474
I mean, I can tell you that every time there's an outage, especially with

283
00:18:14,512 --> 00:18:17,802
Facebook, Hulu, or rarely Netflix, my mom

284
00:18:17,856 --> 00:18:20,826
calls me to see if I can figure out what's wrong, even though I have

285
00:18:20,848 --> 00:18:24,634
repeatedly told her that I do not work at these organizations.

286
00:18:24,762 --> 00:18:27,902
So we want to think about that user experience.

287
00:18:28,036 --> 00:18:31,818
It's something good to think through. I used to get errors

288
00:18:31,834 --> 00:18:35,638
like these all the time, and I actually still do at my current bank,

289
00:18:35,834 --> 00:18:39,454
and they're errors that make sense to them. But when I can

290
00:18:39,502 --> 00:18:43,202
buy my new Lego set and I have this error, it is

291
00:18:43,256 --> 00:18:46,626
really frustrating for me, and it makes me realize that I need to

292
00:18:46,648 --> 00:18:49,974
go to an entire new bank. So that's why

293
00:18:50,012 --> 00:18:53,090
we want to think through the experience of reliability,

294
00:18:53,250 --> 00:18:56,966
because how does the user see the issue? How do we represent the

295
00:18:56,988 --> 00:19:00,070
problems to them? Do they even notice that there is a problem?

296
00:19:00,140 --> 00:19:04,182
Or is there a way to hide that problem from the user and gracefully degrade?

297
00:19:04,326 --> 00:19:07,962
Maybe even if possible, remove the component from the web page

298
00:19:08,016 --> 00:19:11,406
if it's not working at the moment, there's a lot of

299
00:19:11,428 --> 00:19:14,494
things that you can do to allow for graceful degradation that

300
00:19:14,532 --> 00:19:18,046
makes a better user experience. And we

301
00:19:18,068 --> 00:19:21,594
want to think through this always from that user

302
00:19:21,642 --> 00:19:25,330
perspective, how can we reduce stress on those users?

303
00:19:25,750 --> 00:19:29,326
So if you're interested in learning more about the free demo environment,

304
00:19:29,438 --> 00:19:32,562
check it out. It's totally free to spin up on Google Cloud

305
00:19:32,616 --> 00:19:36,050
Shell. Here's the information and the URL.

306
00:19:36,870 --> 00:19:40,822
But I want to show you another example of something

307
00:19:40,876 --> 00:19:44,226
that we're looking for. So let's go back to our demo environment.

308
00:19:44,418 --> 00:19:47,986
So another interesting thing to look at is different types of failure

309
00:19:48,018 --> 00:19:51,746
modes. So let's have a look at the transaction history service and

310
00:19:51,788 --> 00:19:54,700
see how a black hole might impact that.

311
00:19:55,230 --> 00:19:58,554
This is the transaction history here and you can see what it looks like when

312
00:19:58,592 --> 00:20:01,718
things are good. You can see the credits and the debits and who made the

313
00:20:01,744 --> 00:20:05,406
transactions. What you want to see is are we going to get

314
00:20:05,428 --> 00:20:09,134
a graceful degradation of this service if it's made unavailable or

315
00:20:09,172 --> 00:20:12,846
not. During our experiment we can see that the

316
00:20:12,868 --> 00:20:16,218
transaction history is not there. We get an error that

317
00:20:16,244 --> 00:20:19,954
says cloud not load transactions, but we can also see

318
00:20:19,992 --> 00:20:23,294
that our deposit was successful. So this is better than the balance

319
00:20:23,342 --> 00:20:27,346
reader because at least we're not getting that and we have more of a

320
00:20:27,368 --> 00:20:30,820
friendly user experience that doesn't talk about get.

321
00:20:31,770 --> 00:20:34,982
So how can we mitigate against a black

322
00:20:35,036 --> 00:20:38,326
hole? And that's the next question, because before, if you

323
00:20:38,348 --> 00:20:42,166
remember on the balance reader, there was only one pod, now we're

324
00:20:42,198 --> 00:20:45,718
going to make it two. So we'll scale our replicas, and if you're

325
00:20:45,734 --> 00:20:49,226
interested in kubernetes and learning more about this, then this is for you.

326
00:20:49,328 --> 00:20:53,066
So we can run this command, Kubectl scale deployment transaction

327
00:20:53,098 --> 00:20:56,880
history and give it two replicas instead of just one.

328
00:20:57,330 --> 00:21:00,638
We will do this for the transaction history, one for this example.

329
00:21:00,724 --> 00:21:04,222
So run the command and now we can look in the terminal and

330
00:21:04,276 --> 00:21:07,222
see that Kubectl get pods and. Yep,

331
00:21:07,306 --> 00:21:10,898
now we have two pods that are running for the transaction history

332
00:21:11,064 --> 00:21:14,706
that can show us that data. So now what we

333
00:21:14,728 --> 00:21:18,526
can do is a smaller blast radius chaos engineering experiment.

334
00:21:18,638 --> 00:21:21,894
So let's send 50% of the transaction history pods into

335
00:21:21,932 --> 00:21:25,126
a black hole. So just one of the two. And now you can see at

336
00:21:25,148 --> 00:21:28,374
the bottom on the right 50% one of the two pods is

337
00:21:28,412 --> 00:21:31,798
impacted. And I've selected the transaction history replica

338
00:21:31,814 --> 00:21:35,178
set. You can see the two pods, there are two little green dots in the

339
00:21:35,184 --> 00:21:39,062
visualization. So now you want to think through what's your hypothesis?

340
00:21:39,126 --> 00:21:42,458
Now if we send one of the two Transaction pods into a

341
00:21:42,464 --> 00:21:45,326
black hole, will we get an error message? Will things be okay?

342
00:21:45,428 --> 00:21:48,846
Will things get worse? The interesting thing

343
00:21:48,868 --> 00:21:52,026
here is you never really know until you run the experiment.

344
00:21:52,138 --> 00:21:55,374
You're never going to be able to just guess exactly,

345
00:21:55,492 --> 00:21:58,866
because that's very hard to do. And if it was easy, to do, we'd probably

346
00:21:58,968 --> 00:22:02,546
all be Powerball winners right now. So now let's look

347
00:22:02,568 --> 00:22:05,714
at the architecture diagram, just to be able to really understand

348
00:22:05,832 --> 00:22:09,426
this and understand what's happening. So we have our two transaction

349
00:22:09,458 --> 00:22:12,998
history pods, we have the two replicas. And what actually

350
00:22:13,084 --> 00:22:16,786
happens with this is that there will be a very short outage that's

351
00:22:16,818 --> 00:22:19,958
not visible to the human eye, and then the other pod is going to

352
00:22:19,964 --> 00:22:23,338
take over. It will say, this pod is not reachable. So I'm

353
00:22:23,344 --> 00:22:26,666
going to flip over to the other pod. And that's what occurs when

354
00:22:26,688 --> 00:22:29,740
you test this out with chaos engineering in real time,

355
00:22:30,830 --> 00:22:34,018
which is great because there's no error message visible

356
00:22:34,054 --> 00:22:37,646
to the user. They just get the data that they wanted. You're still able

357
00:22:37,668 --> 00:22:41,514
to see all of the transaction history. You no longer receive error measures.

358
00:22:41,562 --> 00:22:44,962
Your mom's probably not calling you. So this is a really

359
00:22:45,016 --> 00:22:47,540
nice way to fail over that service.

360
00:22:48,550 --> 00:22:52,242
So again, here is the URL if you're interested in

361
00:22:52,296 --> 00:22:56,210
looking at the Google cloud platform bank of Anthos.

362
00:22:56,550 --> 00:23:00,194
Now, as I mentioned, there are two key practices, and the next key practice

363
00:23:00,242 --> 00:23:03,254
I want to talk about is game days. So,

364
00:23:03,292 --> 00:23:06,322
game days are a really great team building exercise.

365
00:23:06,386 --> 00:23:09,642
They're something that accelerate talks a lot about in the book,

366
00:23:09,776 --> 00:23:13,258
because game days are a great way to build relationships within

367
00:23:13,344 --> 00:23:16,522
an organization. And it is so true.

368
00:23:16,656 --> 00:23:20,390
They not only help you improve stability and reliability,

369
00:23:20,550 --> 00:23:24,346
but also definitely tempo because it enables you to work closely

370
00:23:24,378 --> 00:23:27,726
with other teams that you want to have better relationships with.

371
00:23:27,828 --> 00:23:32,750
And this is especially important if you're in larger engineering organizations.

372
00:23:34,070 --> 00:23:37,602
The goal is cooperative, proactive testing of our system

373
00:23:37,656 --> 00:23:41,138
to enhance reliability. So by getting the team together

374
00:23:41,224 --> 00:23:44,402
and thinking through your system architecture, you can test

375
00:23:44,456 --> 00:23:48,194
these hypothesis. You can evaluate if your experiments are resilient

376
00:23:48,242 --> 00:23:51,986
to different kinds of failure. And if they're not resilient,

377
00:23:52,098 --> 00:23:55,794
you can fix them before those weaknesses impact

378
00:23:55,842 --> 00:23:59,574
your customers. So now this

379
00:23:59,612 --> 00:24:03,702
is an example of a game day. What you would want to do is invite

380
00:24:03,766 --> 00:24:07,290
four or more people to attend, and it's always good to have at least

381
00:24:07,360 --> 00:24:10,554
two teams. You want to know if you have

382
00:24:10,592 --> 00:24:13,754
some type of failure, how it appears to the other team, or if they have

383
00:24:13,792 --> 00:24:17,658
some sort of failures. You want to see how that affects your systems. And that's

384
00:24:17,674 --> 00:24:20,638
why these are so great, because you're doing it in real time.

385
00:24:20,724 --> 00:24:24,126
They're not happening during an incident. This is planned. You're doing this at

386
00:24:24,148 --> 00:24:27,394
10:00 a.m. With lots of coffee and a zoom, and you

387
00:24:27,432 --> 00:24:30,446
don't have to spend hours doing this. Some folks,

388
00:24:30,478 --> 00:24:33,634
do they want to plan game days for an entire day or a half

389
00:24:33,672 --> 00:24:37,654
a day, but you can really have much shorter game day

390
00:24:37,692 --> 00:24:41,074
experiences. I would definitely say plan for a minimum

391
00:24:41,122 --> 00:24:45,126
of 30 minutes though, in the real world. And oftentimes we

392
00:24:45,148 --> 00:24:48,562
see folks spike load, maybe using Gatling or Jmeter,

393
00:24:48,626 --> 00:24:52,618
and then they introduce different types of failure modes. So for example,

394
00:24:52,704 --> 00:24:56,650
if you use Jmeter, you could be like, all right, let's send a bunch of

395
00:24:56,720 --> 00:25:01,002
requests. But now I'm going to spike cpu because

396
00:25:01,056 --> 00:25:04,346
our auto scaling is based on cpu, or maybe it's

397
00:25:04,378 --> 00:25:07,466
based on a mix of cpu and requests.

398
00:25:07,658 --> 00:25:11,114
So this allows you to create that situation where auto scaling

399
00:25:11,162 --> 00:25:14,494
should occur, and then you can see that it works. And then when

400
00:25:14,532 --> 00:25:17,598
traffic subsides and the cpu attack finishes,

401
00:25:17,774 --> 00:25:21,314
you can run one, maybe for 60 seconds and it will go back

402
00:25:21,352 --> 00:25:24,818
to normal and it'll scale back down. And that's going to

403
00:25:24,824 --> 00:25:28,454
help with other things too. If you're thinking about cost management with

404
00:25:28,492 --> 00:25:31,894
infrastructure, keeping those costs low, and a lot of

405
00:25:31,932 --> 00:25:35,174
sres really care about that too, how can I say

406
00:25:35,212 --> 00:25:39,014
that we saved this much money. We were able to

407
00:25:39,052 --> 00:25:42,954
make sure that we were able to quickly scale down when we don't need

408
00:25:42,992 --> 00:25:46,730
to be running a large number of machines in our fleet.

409
00:25:48,110 --> 00:25:51,834
So when we look at how to run a game day, at least 30 minutes,

410
00:25:51,952 --> 00:25:55,822
30 minutes to 1 hour sessions are fabulous. You want to include two plus

411
00:25:55,876 --> 00:25:59,454
teams. Make sure you decide on your communication tool. Is it

412
00:25:59,492 --> 00:26:02,350
slack? Is it confluence? Is it a Google Doc?

413
00:26:02,770 --> 00:26:05,958
We use Slack here at Gremlin when I was at pager duty.

414
00:26:05,994 --> 00:26:09,634
We also use Slack. You want to plan and design two

415
00:26:09,672 --> 00:26:13,234
to three use cases and you want to make sure that

416
00:26:13,272 --> 00:26:17,126
you have documented this. You want to assign roles such as

417
00:26:17,228 --> 00:26:21,478
commander and general observer and

418
00:26:21,564 --> 00:26:25,190
Scribe, and make sure people understand what their role during the day

419
00:26:25,260 --> 00:26:29,478
is. Document the results and then share widely in the organization

420
00:26:29,574 --> 00:26:33,674
and if possible, share your learnings externally as

421
00:26:33,712 --> 00:26:37,130
well. So here are other examples of game days

422
00:26:37,200 --> 00:26:40,522
you can look at. Dependency testing, capacity plan

423
00:26:40,576 --> 00:26:43,802
testing and auto scaling. Testing capacity

424
00:26:43,866 --> 00:26:47,694
planning is an interesting one because we've seen outages when folks tried

425
00:26:47,732 --> 00:26:51,134
to scale up during a peak traffic day and they actually didn't have

426
00:26:51,172 --> 00:26:55,274
the limits set correctly. They weren't even allowed to do that. They didn't

427
00:26:55,322 --> 00:26:58,546
have the permissions set up. There were caps and they just

428
00:26:58,568 --> 00:27:01,458
couldn't scale. So that's a bad situation.

429
00:27:01,624 --> 00:27:04,930
And you definitely want to test that your caps are not in place

430
00:27:05,000 --> 00:27:08,182
in a bad way that impacts you. These are

431
00:27:08,236 --> 00:27:12,120
things that you're thinking through when you're going through these game days.

432
00:27:12,810 --> 00:27:16,198
Also, here's a scenario planning template. You can actually find all of

433
00:27:16,204 --> 00:27:19,434
this@gremlin.com gamedays and again,

434
00:27:19,472 --> 00:27:23,430
we're documenting the attack target, the attack type, the failure consumption

435
00:27:23,510 --> 00:27:26,854
that we're simulating the expected behavior and risk,

436
00:27:26,902 --> 00:27:30,502
and then that post attack state and impact.

437
00:27:30,646 --> 00:27:33,934
And that's important because going back to the very beginning of what we

438
00:27:33,972 --> 00:27:37,310
talked about, you're creating a hypothesis and you're testing it.

439
00:27:37,380 --> 00:27:41,280
We're not just randomly running around shutting things off.

440
00:27:41,650 --> 00:27:45,070
And yes, you can automate all of this.

441
00:27:45,220 --> 00:27:48,926
And you want to, you want to codify your chaos engineering

442
00:27:48,958 --> 00:27:52,706
experiments because you want to make them shareable. You want to do version control.

443
00:27:52,808 --> 00:27:56,594
You want to show the history of your experiments. So look

444
00:27:56,632 --> 00:28:00,306
at how you can integrate chaos engineering experiments into your CI

445
00:28:00,338 --> 00:28:03,890
CD pipeline. And you might do this for production readiness.

446
00:28:04,050 --> 00:28:07,890
They might say, you need to pass this number of chaos engineering reliability

447
00:28:07,970 --> 00:28:11,238
experiments before you can ship your new service

448
00:28:11,324 --> 00:28:14,874
into production or before you can ship your change. Or if you're going

449
00:28:14,912 --> 00:28:18,314
multi cloud, you might want to make sure that all the code can

450
00:28:18,352 --> 00:28:22,346
pass through a set of chaos engineering experiments, because we

451
00:28:22,368 --> 00:28:25,502
all know that lift and shift really isn't a thing or a thing that works

452
00:28:25,556 --> 00:28:29,422
out well because environments are so different and there's a lot

453
00:28:29,476 --> 00:28:32,686
of fine grained detail. So it's great if you

454
00:28:32,708 --> 00:28:35,986
can automate your chaos engineering experiments, because you don't have to go

455
00:28:36,008 --> 00:28:38,910
around teaching everyone the SRE best practices.

456
00:28:38,990 --> 00:28:42,562
You can just build a system that can quickly go in and check,

457
00:28:42,616 --> 00:28:46,278
and you're giving people tips and knowledge so that they can build

458
00:28:46,364 --> 00:28:49,800
better systems in the future and going forward.

459
00:28:50,170 --> 00:28:53,720
So with that, as I mentioned, I would let you know how to

460
00:28:54,250 --> 00:28:57,622
get a free certification. We have

461
00:28:57,676 --> 00:29:01,010
a chaos engineering practitioner and professional certification,

462
00:29:01,090 --> 00:29:05,142
so you can head over to gremlin.com certification to learn

463
00:29:05,196 --> 00:29:09,174
more about that. And then I want to thank everyone for

464
00:29:09,212 --> 00:29:11,980
being here, and I wish you a great day.

