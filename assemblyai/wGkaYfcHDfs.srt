1
00:00:20,010 --> 00:00:24,046
Everyone. Hope you're having a good time at Conf 42. Welcome to

2
00:00:24,068 --> 00:00:27,234
my session on reinventing speech to text transcriptions.

3
00:00:27,362 --> 00:00:31,122
I'm Pratim Bhosale, developer advocate at SurrealdB.

4
00:00:31,266 --> 00:00:35,202
In today's talk, we will be covering a couple of areas,

5
00:00:35,346 --> 00:00:38,818
starting with the costs associated around speech to

6
00:00:38,844 --> 00:00:41,974
text transcription APIs, an introduction

7
00:00:42,022 --> 00:00:46,134
to Whisper and Whisper CPP. We'll also understand go bindings

8
00:00:46,182 --> 00:00:49,674
and how they relate to our discussion. We are going to see some use

9
00:00:49,712 --> 00:00:52,766
cases of transcription services and we'll end the

10
00:00:52,788 --> 00:00:56,202
session with a live demo to show Whisper CPP in action.

11
00:00:56,346 --> 00:00:59,200
So without further ado, let's dive in.

12
00:00:59,890 --> 00:01:03,762
What is speech to text transcription? Speech to text

13
00:01:03,816 --> 00:01:07,902
transcription is nothing but reinventing spoken language

14
00:01:07,966 --> 00:01:11,762
into written text. All your voice assistants use

15
00:01:11,816 --> 00:01:15,486
speech to text, be it CD, Alexa, or even

16
00:01:15,528 --> 00:01:19,634
ok Google I started exploring speech to text APIs

17
00:01:19,762 --> 00:01:23,138
when I wanted to have subtitles for my meetings,

18
00:01:23,314 --> 00:01:27,782
but most of the applications that I tried were paid and

19
00:01:27,836 --> 00:01:31,066
then the developer instinct kicked in me and

20
00:01:31,088 --> 00:01:34,394
I thought of building one for myself. I explored the

21
00:01:34,432 --> 00:01:38,378
solutions that were given by Google and Amazon, but they were super,

22
00:01:38,464 --> 00:01:42,094
super expensive and that's when I decided to go

23
00:01:42,132 --> 00:01:45,754
ahead with an open source solution. One of the reasons

24
00:01:45,882 --> 00:01:49,774
that these apps were getting too expensive after a certain point was

25
00:01:49,812 --> 00:01:53,086
their pricing point, and I didn't want

26
00:01:53,108 --> 00:01:56,626
to spend a lot of money. That's where Openei's Whisper came

27
00:01:56,648 --> 00:02:00,354
into picture. But before we go ahead and understand what

28
00:02:00,392 --> 00:02:03,614
Whisper is, let's take a look at the pricing table

29
00:02:03,662 --> 00:02:07,418
of both Google's API and Amazon's speech to text API's

30
00:02:07,454 --> 00:02:11,042
costs. But to give you a calculation

31
00:02:11,106 --> 00:02:15,074
of how much it would cost me to use Google's speech to text API,

32
00:02:15,122 --> 00:02:18,786
the screenshot on the screen should speak for itself. If you cross

33
00:02:18,818 --> 00:02:23,178
the given threshold, you might have to shell out at least $1,000

34
00:02:23,264 --> 00:02:26,522
every month on the API transcriptions. This was

35
00:02:26,576 --> 00:02:30,394
definitely not helping my case, and I decided to explore

36
00:02:30,442 --> 00:02:34,282
Whisper. So let's see what Whisper

37
00:02:34,346 --> 00:02:37,886
is and what Whisper CPP is. Whisper is an

38
00:02:37,988 --> 00:02:41,166
opensource automatic recognition system developed by

39
00:02:41,188 --> 00:02:44,674
OpenAI. It has been trained on a vast amount of

40
00:02:44,712 --> 00:02:48,766
multilingual and multitask supervised data collected

41
00:02:48,798 --> 00:02:52,126
from the web. It is one of the most underrated models

42
00:02:52,158 --> 00:02:55,746
of OpenAI. Companies like Snap Inc. The creator of

43
00:02:55,768 --> 00:02:59,302
Snapchat, Shopify, and a lot of other companies are

44
00:02:59,356 --> 00:03:02,966
already using the Whisper API. You can see the architecture of

45
00:03:02,988 --> 00:03:07,094
the Whisper model on the screen. The Whisper architecture is

46
00:03:07,132 --> 00:03:10,642
basically a method used to convert spoken language

47
00:03:10,706 --> 00:03:14,806
into written text. It works in a step by step manner

48
00:03:14,918 --> 00:03:18,662
using a specific type of computer model called a transformer.

49
00:03:18,806 --> 00:03:21,706
The speech is divided into small parts,

50
00:03:21,818 --> 00:03:25,594
each 30 seconds long, and then changed into a format

51
00:03:25,722 --> 00:03:29,514
that can be understood by the model. This format represents

52
00:03:29,562 --> 00:03:33,234
the speech in a visual way, showing its features and

53
00:03:33,272 --> 00:03:36,946
patterns. The model also has two parts to

54
00:03:36,968 --> 00:03:41,054
it, an encoder and a decoder. The encoder processes

55
00:03:41,102 --> 00:03:44,098
the speech and decoder converts it into the text.

56
00:03:44,264 --> 00:03:47,426
This model can do more than just transcribing the speech

57
00:03:47,458 --> 00:03:51,362
to text. It can also identify the language being spoken,

58
00:03:51,506 --> 00:03:54,882
provide information about when certain phrases are spoken,

59
00:03:55,026 --> 00:03:59,094
transcribe speech in multiple languages, and even translate

60
00:03:59,142 --> 00:04:02,362
speech into English. This is done

61
00:04:02,416 --> 00:04:06,122
using a special symbol that helps the model understand what

62
00:04:06,176 --> 00:04:10,002
tasks to perform. And here's where the Whisper CPP

63
00:04:10,086 --> 00:04:14,046
comes in. Picture well, Whisper CPP is nothing but a

64
00:04:14,068 --> 00:04:18,314
lightweight implementation of Whisper. It is a c implementation

65
00:04:18,362 --> 00:04:21,754
of Whisper model, which allows for faster execution

66
00:04:21,882 --> 00:04:25,650
and lower resource consumptions compared to other implementations.

67
00:04:26,390 --> 00:04:30,100
Now you must be thinking where is go in this?

68
00:04:31,590 --> 00:04:34,946
Where does go come into picture? Well,

69
00:04:35,048 --> 00:04:38,162
let's talk about Go bindings. In order to use

70
00:04:38,216 --> 00:04:41,122
Whisper CPP in your Golang projects,

71
00:04:41,266 --> 00:04:44,566
we will be using go bindings that are provided by

72
00:04:44,588 --> 00:04:48,426
the project. Before we go ahead and understand how go

73
00:04:48,448 --> 00:04:51,914
bindings are being used, let's understand what

74
00:04:51,952 --> 00:04:55,274
go bindings are. Well, go bindings are a way

75
00:04:55,312 --> 00:04:59,530
to call functions or use data structures from other programming languages

76
00:04:59,970 --> 00:05:03,566
within your go code. This is useful when you want

77
00:05:03,588 --> 00:05:07,326
to leverage existing libraries or APIs written in

78
00:05:07,348 --> 00:05:11,360
another language while still writing your main application code.

79
00:05:12,130 --> 00:05:15,522
The process usually involves a bridge between

80
00:05:15,576 --> 00:05:19,374
the go code and the code in the target language using the foreign

81
00:05:19,422 --> 00:05:23,570
function interface FFI of the target language.

82
00:05:24,470 --> 00:05:28,022
This also makes sure that there is seamless integration of

83
00:05:28,076 --> 00:05:30,920
Whisper CPP into your Golang application.

84
00:05:33,450 --> 00:05:37,074
I build a basic CLI application which would convert

85
00:05:37,122 --> 00:05:40,614
the audio from a YouTube video into text. Let me take

86
00:05:40,652 --> 00:05:44,150
you through the code so that you get a better understanding of how whisper

87
00:05:44,230 --> 00:05:47,580
CPP works. We will then head over to the demo.

88
00:05:48,110 --> 00:05:51,078
I will be explaining the major function from the code,

89
00:05:51,184 --> 00:05:55,102
which is the transcribe function. The transcribe function

90
00:05:55,156 --> 00:05:58,794
that you see on the screen is responsible for initializing the transcription

91
00:05:58,842 --> 00:06:02,254
model using Whisper new. We are passing it

92
00:06:02,292 --> 00:06:05,858
the path of our audio file as well as of the model.

93
00:06:06,024 --> 00:06:09,874
Now this is the Whisper model from OpenAI. We go

94
00:06:09,912 --> 00:06:13,314
ahead and create a new context for our model. For those

95
00:06:13,352 --> 00:06:16,118
who are not familiar with what a context is,

96
00:06:16,204 --> 00:06:19,762
let me explain it to you in context of the Whisper

97
00:06:19,826 --> 00:06:23,254
architecture. Context usually refers to the

98
00:06:23,292 --> 00:06:26,706
surrounding information or the environment that helps

99
00:06:26,738 --> 00:06:30,602
the model better understand the speech. It is processing when

100
00:06:30,656 --> 00:06:34,586
transcriptions speech having a broader context allows the

101
00:06:34,608 --> 00:06:38,314
model to more accurately recognize and interpret the

102
00:06:38,352 --> 00:06:41,854
words and phrases being spoken. This is

103
00:06:41,892 --> 00:06:45,486
because the meaning and pronunciation of words can be

104
00:06:45,508 --> 00:06:49,486
influenced by the words that come before and after them.

105
00:06:49,668 --> 00:06:53,198
For example, when transcribing a conversation,

106
00:06:53,294 --> 00:06:56,914
knowing the topic being discussed, or having the access to

107
00:06:56,952 --> 00:07:00,526
previous sentences can help the model better predict

108
00:07:00,558 --> 00:07:03,826
the words and phrases likely to be spoken next.

109
00:07:04,008 --> 00:07:07,874
This additional information can lead to improved transcription

110
00:07:07,922 --> 00:07:11,446
accuracy and overall performance. The next step in

111
00:07:11,468 --> 00:07:15,394
building our application is to decode the was file a WAF file

112
00:07:15,442 --> 00:07:19,138
a WAV file is the audio format accepted

113
00:07:19,154 --> 00:07:23,162
by Whisper. We decode it into a slice variable called

114
00:07:23,216 --> 00:07:26,906
data, but we first need to check if the sample rate of

115
00:07:26,928 --> 00:07:30,494
the audio and the number of channels are the same as

116
00:07:30,532 --> 00:07:34,634
accepted by Whisper. If not, we will be returning an error.

117
00:07:34,762 --> 00:07:38,670
We then pass the data variable to context process,

118
00:07:38,820 --> 00:07:42,558
which would do the actual transcription. The final step

119
00:07:42,644 --> 00:07:46,258
of this is to print the results for this demo.

120
00:07:46,344 --> 00:07:49,614
I have also dockerized the dependencies to avoid cross

121
00:07:49,662 --> 00:07:53,310
platform issues. You can see the commands to compile whisper

122
00:07:53,390 --> 00:07:56,838
CPP on the screen. Now, before we dive into the

123
00:07:56,844 --> 00:07:59,350
demo, let's talk about use cases.

124
00:08:00,090 --> 00:08:03,554
Transcription services are used in a plethora

125
00:08:03,602 --> 00:08:06,914
of use cases like meetings, interviews,

126
00:08:07,042 --> 00:08:10,802
podcasts, customer support interactions, voice assistants,

127
00:08:10,946 --> 00:08:14,794
real time closed captioning, and many more. The versatility and

128
00:08:14,832 --> 00:08:18,886
efficiency of Whisper makes it a valuable tool for developers

129
00:08:18,998 --> 00:08:21,130
working on a variety of projects.

130
00:08:21,870 --> 00:08:25,518
Now let's move ahead to our demo and check out how you

131
00:08:25,524 --> 00:08:29,726
can build your own application using Whisper. CPP let

132
00:08:29,748 --> 00:08:33,618
me show you the 32nd video that we are going to transcribe. I found it

133
00:08:33,624 --> 00:08:37,026
on YouTube and it's a quick 32nd video and we are

134
00:08:37,048 --> 00:08:40,290
going to check it out before we see its transcription.

135
00:08:50,670 --> 00:08:53,846
So you're running a little late today and you haven't

136
00:08:53,878 --> 00:08:57,674
had your fresh cup of coffee yet. No matter the

137
00:08:57,712 --> 00:09:02,010
weather or traffic, we deliver fresh coffees and bagels.

138
00:09:05,090 --> 00:09:11,434
The Java cafe Yep,

139
00:09:11,562 --> 00:09:15,310
that was it. And now let's get back.

140
00:09:15,460 --> 00:09:19,220
Okay, let's go ahead and build our Docker image first.

141
00:09:24,150 --> 00:09:26,260
This will take a little bit of time.

142
00:09:28,490 --> 00:09:32,774
2000 years later so

143
00:09:32,812 --> 00:09:36,278
finally 10,000 years later, the docker image has finally built.

144
00:09:36,364 --> 00:09:38,550
We are now going to run the container.

145
00:09:42,190 --> 00:09:45,450
I've added a short YouTube link which is around 30

146
00:09:45,520 --> 00:09:49,082
seconds. A longer YouTube video link would have taken

147
00:09:49,136 --> 00:09:52,700
me long time, so I'm adding a shorter video.

148
00:09:53,330 --> 00:09:56,974
It has now started the transcription. This will

149
00:09:57,012 --> 00:10:01,406
take some time and the

150
00:10:01,428 --> 00:10:04,734
larger the video, the more time the

151
00:10:04,772 --> 00:10:08,674
transcription will take. The transcription is finally done and

152
00:10:08,712 --> 00:10:12,722
now you can see the result. You can see exactly all

153
00:10:12,776 --> 00:10:16,018
the words that were mentioned in the video as a

154
00:10:16,024 --> 00:10:19,682
part of your transcription. You can see it says, so you're running

155
00:10:19,736 --> 00:10:22,894
a little late today and you haven't had your fresh cup of coffee

156
00:10:22,942 --> 00:10:26,434
yet. No matter the weather or traffic, we deliver fresh coffee and

157
00:10:26,472 --> 00:10:30,046
bagels. And there was music then. It also says the Java

158
00:10:30,078 --> 00:10:33,594
cafe. Yeah, and that was our 32nd video, which has been

159
00:10:33,632 --> 00:10:37,226
completely transcribed. And with that, we come to

160
00:10:37,328 --> 00:10:40,426
an end of this session. Thank you so much for going through

161
00:10:40,448 --> 00:10:44,246
my session and giving me this opportunity. If you have any questions regarding

162
00:10:44,278 --> 00:10:47,878
the session, please feel free to reach out to me on Twitter at Bosley

163
00:10:47,894 --> 00:10:51,066
pratim. Hope you have a great day and hope you like the rest of the

164
00:10:51,088 --> 00:10:51,462
conference.

