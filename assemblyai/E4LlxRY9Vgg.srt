1
00:01:55,130 --> 00:01:59,120
Thank you for joining me at DevOps 2022.

2
00:02:02,280 --> 00:02:06,310
My name is Leonard. I am a developer relations engineer at Google.

3
00:02:06,800 --> 00:02:10,092
You in my role I help

4
00:02:10,146 --> 00:02:13,580
developers to improve observability of their applications.

5
00:02:14,320 --> 00:02:18,344
Today I would like to talk to you about logs anonymization

6
00:02:18,472 --> 00:02:20,480
and how it can be implemented.

7
00:02:22,340 --> 00:02:26,544
Logs anonymization is one of the tasks in

8
00:02:26,582 --> 00:02:29,200
an implementation of the data compliance.

9
00:02:31,380 --> 00:02:34,864
As you know, data should be compliant to standards

10
00:02:34,912 --> 00:02:38,164
and regulations existing in the industry such

11
00:02:38,202 --> 00:02:41,732
as JEPR, HIPAA, PSIDSs and many

12
00:02:41,786 --> 00:02:44,952
others. Implementing this

13
00:02:45,006 --> 00:02:48,488
compliance can be very expensive, both from the business

14
00:02:48,574 --> 00:02:52,520
and engineering perspective. It requires changes

15
00:02:52,590 --> 00:02:57,148
to the application code, modification to the environments and

16
00:02:57,234 --> 00:03:01,532
engineering processes can be especially

17
00:03:01,666 --> 00:03:06,300
complex for applications architected

18
00:03:06,880 --> 00:03:10,348
in multi tier distributed service meshes

19
00:03:10,524 --> 00:03:14,716
or deployed across multiple geographic locations,

20
00:03:14,908 --> 00:03:18,764
which can be subject to different standards

21
00:03:18,812 --> 00:03:19,840
and regulations.

22
00:03:25,120 --> 00:03:28,652
The compliance address all data that

23
00:03:28,706 --> 00:03:32,584
application generates, including data input

24
00:03:32,632 --> 00:03:36,092
by the user, data generated and

25
00:03:36,146 --> 00:03:40,192
maintained by the application, and also data

26
00:03:40,326 --> 00:03:43,696
created by other sources such

27
00:03:43,718 --> 00:03:45,920
as CI CD workflows.

28
00:03:47,780 --> 00:03:51,428
Data in the logs is also

29
00:03:51,514 --> 00:03:55,968
a part of the compliance regulations

30
00:03:56,064 --> 00:03:58,100
and has to be compliant.

31
00:04:00,680 --> 00:04:03,930
It can be especially tricky because in many

32
00:04:05,580 --> 00:04:11,092
implementations of the data, compliance logs observed

33
00:04:11,156 --> 00:04:14,932
as a solution of various compliance

34
00:04:14,996 --> 00:04:18,524
requirements and not as a target for

35
00:04:18,562 --> 00:04:21,100
this compliance regulations.

36
00:04:22,960 --> 00:04:27,032
Implementing the compliance also referenced as compliance

37
00:04:27,096 --> 00:04:30,528
controls can be roughly divided into three

38
00:04:30,614 --> 00:04:35,840
types. Preventive controls implement

39
00:04:38,180 --> 00:04:43,040
requirements that don't

40
00:04:43,120 --> 00:04:46,630
allow certain operation or use of the data.

41
00:04:48,520 --> 00:04:51,764
When you think about these types of controls, you can think

42
00:04:51,802 --> 00:04:56,212
about identity and access management as one of the implementation

43
00:04:56,356 --> 00:05:00,264
of this type of controls. Another type

44
00:05:00,302 --> 00:05:02,920
of the controls is detective controls.

45
00:05:04,620 --> 00:05:08,190
It essentially captures all

46
00:05:08,960 --> 00:05:12,060
information about the activities that takes

47
00:05:12,130 --> 00:05:19,456
part and other things,

48
00:05:19,638 --> 00:05:23,440
and it allows to detect

49
00:05:23,860 --> 00:05:28,444
and alert any violations

50
00:05:28,572 --> 00:05:32,630
of the compliance or it can be used

51
00:05:33,160 --> 00:05:37,232
in the postmortem investigations related

52
00:05:37,296 --> 00:05:40,180
to the compliance validation.

53
00:05:40,840 --> 00:05:44,276
Audit logs are often used

54
00:05:44,378 --> 00:05:47,624
as part and other application logs are often used as

55
00:05:47,662 --> 00:05:51,672
part of the implementations of this control. The last

56
00:05:51,726 --> 00:05:54,280
type of controls, corrective controls,

57
00:05:55,120 --> 00:06:00,076
are used to implement the reaction on

58
00:06:00,098 --> 00:06:02,940
the detected compliance violations.

59
00:06:03,680 --> 00:06:07,768
Let's look how these controls are

60
00:06:07,954 --> 00:06:11,424
implemented for the data stored in the

61
00:06:11,462 --> 00:06:12,240
logs.

62
00:06:15,140 --> 00:06:19,504
The data in the logs the compliance controls can

63
00:06:19,542 --> 00:06:23,460
be applied into two processes.

64
00:06:23,800 --> 00:06:27,360
First is log ingestion or logs generation,

65
00:06:27,440 --> 00:06:29,510
and the second logs access.

66
00:06:30,440 --> 00:06:34,628
Compliance controls for log access are straightforward.

67
00:06:34,724 --> 00:06:38,356
They usually focus on preemptive and detective

68
00:06:38,468 --> 00:06:42,500
controls and can be implemented

69
00:06:42,660 --> 00:06:47,084
using identity and access management, audit logs and

70
00:06:47,282 --> 00:06:51,116
infrastructure that

71
00:06:51,218 --> 00:06:55,390
persist the storage of the log data.

72
00:06:59,290 --> 00:07:02,886
This compliance control for the log access are usually

73
00:07:02,988 --> 00:07:08,242
universal and across different regulations

74
00:07:08,306 --> 00:07:12,222
and the standards. Compliance controls about log ingestion

75
00:07:12,306 --> 00:07:15,674
is different in the

76
00:07:15,712 --> 00:07:19,894
way that it usually involves detective

77
00:07:19,942 --> 00:07:23,740
and corrective controls, which can be specific

78
00:07:24,290 --> 00:07:27,386
for the industry

79
00:07:27,498 --> 00:07:31,550
the application is used

80
00:07:31,700 --> 00:07:35,966
as well as to a geographic location where the

81
00:07:35,988 --> 00:07:37,970
application is deployed.

82
00:07:40,070 --> 00:07:43,940
The diagram that you see

83
00:07:44,870 --> 00:07:49,198
roughly depicts the process of the log ingestion and

84
00:07:49,304 --> 00:07:53,110
how the detective and corrective controls can be applied.

85
00:07:53,610 --> 00:07:57,094
As you can see, there are two

86
00:07:57,132 --> 00:08:00,994
types of corrective controls that can be implemented

87
00:08:01,042 --> 00:08:04,922
for the log ingestion flow. The first type is

88
00:08:04,976 --> 00:08:09,194
just removing the

89
00:08:09,232 --> 00:08:13,194
data that violates compliance from

90
00:08:13,232 --> 00:08:17,130
the logs or just dropping the whole log

91
00:08:17,200 --> 00:08:20,922
entry or the second type of

92
00:08:20,976 --> 00:08:24,630
activity is obfuscating partially

93
00:08:24,710 --> 00:08:29,762
or fully the data

94
00:08:29,816 --> 00:08:31,970
that violates the compliance.

95
00:08:32,790 --> 00:08:36,658
Implementing obfuscation logic requires special

96
00:08:36,744 --> 00:08:40,854
knowledge because sometimes

97
00:08:40,972 --> 00:08:46,978
it's not enough just to identify

98
00:08:47,074 --> 00:08:51,030
the data in the logs so the original

99
00:08:51,470 --> 00:08:54,906
information cannot be restored, but sometimes

100
00:08:55,008 --> 00:08:58,758
it requires preserving certain properties

101
00:08:58,854 --> 00:09:04,542
or qualities of this data for

102
00:09:04,596 --> 00:09:09,150
future use. As an example, think about troubleshooting

103
00:09:10,130 --> 00:09:15,518
tasks that engineers have to perform and

104
00:09:15,604 --> 00:09:19,758
to use the logs to restore

105
00:09:19,854 --> 00:09:23,794
the original transaction logic that application run.

106
00:09:23,992 --> 00:09:27,838
If for example, the application logs

107
00:09:27,934 --> 00:09:31,974
store user identity and

108
00:09:32,092 --> 00:09:35,654
use Social Security number of the user of this

109
00:09:35,772 --> 00:09:39,510
as a primary user identity. And yes, I know

110
00:09:39,580 --> 00:09:43,222
it is wrong and unfortunately many applications

111
00:09:43,366 --> 00:09:46,806
still do this. So it's

112
00:09:46,838 --> 00:09:51,066
not enough just to obfuscate the

113
00:09:51,168 --> 00:09:55,610
part in the logs that store SSM

114
00:09:56,050 --> 00:10:00,542
because this way it will be impossible to

115
00:10:00,596 --> 00:10:03,914
follow up on the logic of the application flow.

116
00:10:04,042 --> 00:10:07,842
It is also important that this affuscated part will

117
00:10:07,896 --> 00:10:11,826
still be unique across all other

118
00:10:11,928 --> 00:10:15,838
logs and will be the same for the same under.

119
00:10:16,014 --> 00:10:19,494
So this kind of implementation can

120
00:10:19,532 --> 00:10:23,320
be sometimes changing to do when

121
00:10:23,770 --> 00:10:27,750
developers implement corrective control

122
00:10:27,820 --> 00:10:31,462
for their logs. Now I would like

123
00:10:31,516 --> 00:10:36,650
to review basic implementations

124
00:10:37,550 --> 00:10:40,890
that can be done for the logs anonymization.

125
00:10:41,870 --> 00:10:46,286
I will do it based on the simplified architecture that

126
00:10:46,388 --> 00:10:51,662
captures main challenging elements that

127
00:10:51,716 --> 00:10:55,162
you might see when implementing

128
00:10:55,306 --> 00:10:56,670
logs and minimization.

129
00:10:58,390 --> 00:11:01,938
The architecture includes two tier application with the

130
00:11:01,944 --> 00:11:05,442
front end application running on user devices and

131
00:11:05,496 --> 00:11:08,654
the back end service that runs

132
00:11:08,702 --> 00:11:11,974
behind the firewall. On the diagram you can

133
00:11:12,012 --> 00:11:16,358
see blue arrows that captured business

134
00:11:16,444 --> 00:11:20,310
communication and transactions of the application and

135
00:11:20,380 --> 00:11:23,450
gray arrows that capture flows.

136
00:11:25,390 --> 00:11:29,350
Log ingestion flows. Please pay attention

137
00:11:29,430 --> 00:11:33,334
that it includes logs captured

138
00:11:33,382 --> 00:11:37,470
from the infrastructure. In this diagram

139
00:11:37,970 --> 00:11:41,614
it is presented by the load balancer and the application

140
00:11:41,732 --> 00:11:42,960
logs as well.

141
00:11:45,650 --> 00:11:49,646
The first solution is engineering

142
00:11:49,678 --> 00:11:53,394
oriented solution. This is what R

143
00:11:53,432 --> 00:11:57,234
and D teams usually do when tasked with

144
00:11:57,352 --> 00:11:59,170
the logs anonymization.

145
00:12:01,130 --> 00:12:04,802
It is implementing the corrective and detective

146
00:12:04,866 --> 00:12:08,520
controls as close to the place where the log

147
00:12:09,850 --> 00:12:12,540
entries are generated as possible.

148
00:12:13,070 --> 00:12:16,358
Clearly the ownership of the solution

149
00:12:16,534 --> 00:12:20,186
is on the R D teams which rise the

150
00:12:20,208 --> 00:12:23,974
potential problem for maintaining

151
00:12:24,022 --> 00:12:28,330
the application. This is where DevOps originally

152
00:12:28,490 --> 00:12:29,920
was born from,

153
00:12:31,170 --> 00:12:34,654
so follow up work for

154
00:12:34,692 --> 00:12:37,890
maintaining it can be very expensive.

155
00:12:39,190 --> 00:12:43,054
As mentioned, implementing it requires

156
00:12:43,102 --> 00:12:47,586
specialized knowledge that it

157
00:12:47,608 --> 00:12:51,640
is possible that RND teams don't have.

158
00:12:53,690 --> 00:12:57,170
Additionally, this kind of implementation runs

159
00:12:57,250 --> 00:13:00,822
the solution as part of the business application

160
00:13:00,956 --> 00:13:03,580
process. As such,

161
00:13:04,190 --> 00:13:07,638
it consumes the same resources that originally

162
00:13:07,734 --> 00:13:11,654
allocated for the application itself and reduce

163
00:13:11,702 --> 00:13:15,422
the application performance. Additionally, it means

164
00:13:15,476 --> 00:13:19,146
that if any problem is identified

165
00:13:19,258 --> 00:13:22,522
within the implementation of the compliance controls

166
00:13:22,666 --> 00:13:26,560
or some kind of

167
00:13:26,950 --> 00:13:31,186
modification is required due to

168
00:13:31,368 --> 00:13:35,314
changes in the regulations, it will

169
00:13:35,352 --> 00:13:39,246
require enrolling a new version of the application. Even if nothing

170
00:13:39,368 --> 00:13:42,790
from the business perspective have

171
00:13:42,860 --> 00:13:47,000
changed. Deploying such

172
00:13:47,690 --> 00:13:51,560
solution in multiple geographic location can be

173
00:13:52,110 --> 00:13:56,726
very changing because it will require some complex

174
00:13:56,838 --> 00:14:00,918
and probably again poorly

175
00:14:01,014 --> 00:14:04,718
maintainable configuration solution or

176
00:14:04,804 --> 00:14:08,394
deploying the solution with more than one implementation

177
00:14:08,442 --> 00:14:11,614
of the detective or corrective controls, it will be able to

178
00:14:11,652 --> 00:14:15,230
run correctly in more than one

179
00:14:15,300 --> 00:14:16,750
geographic locations.

180
00:14:17,990 --> 00:14:21,700
And the last but not least important,

181
00:14:22,710 --> 00:14:26,510
you can see that this implementation cannot handle

182
00:14:26,670 --> 00:14:29,800
logs ingested by the infrastructure itself.

183
00:14:31,690 --> 00:14:35,190
So there is another solution

184
00:14:36,810 --> 00:14:40,514
that often can be seen that tries

185
00:14:40,562 --> 00:14:44,410
to mitigate some of these drawbacks.

186
00:14:46,750 --> 00:14:50,330
This solution basically delegates

187
00:14:51,550 --> 00:14:55,806
the actual work to a third party or

188
00:14:55,988 --> 00:14:58,830
standalone implementation.

189
00:14:59,250 --> 00:15:03,034
Usually this kind of implementations are referenced

190
00:15:03,082 --> 00:15:06,842
as data loss prevention service.

191
00:15:06,996 --> 00:15:11,054
They can be found as a commercial solution

192
00:15:11,102 --> 00:15:15,218
or can be developed in house with the same drawbacks of

193
00:15:15,224 --> 00:15:18,610
the specialized knowledge. It depends on each

194
00:15:18,760 --> 00:15:20,370
particular organization.

195
00:15:22,070 --> 00:15:25,270
In this solution, RND teams

196
00:15:25,850 --> 00:15:29,110
share the responsibility with the DevOps because

197
00:15:29,260 --> 00:15:32,906
enrolling and maintaining the

198
00:15:32,928 --> 00:15:38,540
DLP service falls on the DevOps team.

199
00:15:39,070 --> 00:15:43,206
While still some of the implementation

200
00:15:43,398 --> 00:15:47,198
of the changes remain under the R D team

201
00:15:47,284 --> 00:15:49,680
responsibility. For example,

202
00:15:50,370 --> 00:15:54,334
to work properly, DLP solutions should be aware about the

203
00:15:54,372 --> 00:15:58,274
source of the logs. If the

204
00:15:58,312 --> 00:16:01,662
application does not work with structured

205
00:16:01,726 --> 00:16:05,938
logs or it works with the structured logs but does not

206
00:16:06,104 --> 00:16:09,474
provide enough metadata about the logs source,

207
00:16:09,522 --> 00:16:13,078
such as what kind of service

208
00:16:13,164 --> 00:16:16,310
generated the log, where the service

209
00:16:16,380 --> 00:16:20,120
located, what is the specifics of the

210
00:16:21,710 --> 00:16:25,418
environment, and so on. This type of data has

211
00:16:25,504 --> 00:16:29,274
to be added and R d

212
00:16:29,312 --> 00:16:32,522
team will be responsible to implement this change.

213
00:16:32,656 --> 00:16:36,682
Additionally, all logic of ingesting

214
00:16:36,746 --> 00:16:40,590
logs the application site has to be modified

215
00:16:41,090 --> 00:16:43,950
to redirect logs to the DLP.

216
00:16:44,290 --> 00:16:47,954
In many cases, R D teams will have

217
00:16:47,992 --> 00:16:51,138
to do this work. This kind of

218
00:16:51,304 --> 00:16:54,782
changes can be partially mitigated by implementing

219
00:16:54,846 --> 00:16:59,380
some logging agent, but it's not always possible to do.

220
00:17:01,210 --> 00:17:04,946
This solution has many advantages compared

221
00:17:04,978 --> 00:17:08,040
to the previous one. First,

222
00:17:09,370 --> 00:17:13,610
the maintenance is usually

223
00:17:13,680 --> 00:17:16,746
done by the DevOps, so there

224
00:17:16,768 --> 00:17:20,070
is a team that specialized

225
00:17:20,150 --> 00:17:24,530
in the maintenance and it can partially reduce

226
00:17:24,630 --> 00:17:28,222
maintenance cost. Secondary it

227
00:17:28,276 --> 00:17:31,982
can remove a need in specialized knowledge in the case, the third

228
00:17:32,036 --> 00:17:36,042
party solution is used, which also simplifies

229
00:17:36,106 --> 00:17:39,442
the compliance validation process and

230
00:17:39,496 --> 00:17:43,166
guarantees that compliance requirements for logs

231
00:17:43,198 --> 00:17:46,690
and minimization are implemented correctly.

232
00:17:47,270 --> 00:17:48,370
Additionally,

233
00:17:50,570 --> 00:17:53,910
it runs in its own environment. As a result,

234
00:17:53,980 --> 00:17:58,134
it does not consume resources that

235
00:17:58,252 --> 00:18:01,270
originally intended to run business logic.

236
00:18:01,630 --> 00:18:05,226
It can be enrolled separately being a

237
00:18:05,248 --> 00:18:08,758
standalone service, so any changes or configuration

238
00:18:08,854 --> 00:18:13,370
in configuration and implementation don't influence

239
00:18:14,370 --> 00:18:15,280
the application.

240
00:18:18,050 --> 00:18:21,310
Clearly it is better

241
00:18:21,380 --> 00:18:25,406
fit for scaling and for running

242
00:18:25,508 --> 00:18:28,930
in multiple geographic locations.

243
00:18:30,470 --> 00:18:35,266
However, it still has

244
00:18:35,448 --> 00:18:37,970
few drawbacks.

245
00:18:38,870 --> 00:18:43,282
It is still application focused, so infrastructure

246
00:18:43,346 --> 00:18:46,310
logs still get unattended.

247
00:18:47,690 --> 00:18:51,400
It still possess relatively high maintenance cost. Also,

248
00:18:52,430 --> 00:18:56,090
the cost is shifted toward DevOps

249
00:18:56,510 --> 00:19:00,342
and it may, as I mentioned, still require

250
00:19:00,406 --> 00:19:04,150
changes in the application code as a result of

251
00:19:04,320 --> 00:19:07,070
working versus DLP.

252
00:19:08,050 --> 00:19:12,078
So today, when a

253
00:19:12,084 --> 00:19:16,970
lot of applications run in the cloud and

254
00:19:17,140 --> 00:19:21,650
when speaking about the maintenance cost, one of the possible solutions

255
00:19:23,030 --> 00:19:26,914
is to

256
00:19:26,952 --> 00:19:30,966
leverage the cloud so we

257
00:19:30,988 --> 00:19:34,774
can modify the previous implementation by

258
00:19:34,892 --> 00:19:38,374
shifting all

259
00:19:38,572 --> 00:19:42,860
work relevant to logs into the cloud.

260
00:19:45,710 --> 00:19:49,686
This provides us with a couple of advantages.

261
00:19:49,798 --> 00:19:53,338
First, it allows almost completely

262
00:19:53,504 --> 00:19:57,070
remove R D team involvement,

263
00:19:57,730 --> 00:20:02,590
meaning no need for additional work

264
00:20:02,660 --> 00:20:04,160
from the R D team.

265
00:20:05,810 --> 00:20:09,426
DevOps team gets full control over the

266
00:20:09,448 --> 00:20:11,090
solution from the beginning.

267
00:20:14,070 --> 00:20:17,534
The solution implements redirection

268
00:20:17,582 --> 00:20:20,790
of the logs using the proxy

269
00:20:21,690 --> 00:20:25,974
that fronting the logs management backend and

270
00:20:26,092 --> 00:20:30,402
sending all ingested logs into DLP

271
00:20:30,466 --> 00:20:33,846
first and then from DLP

272
00:20:34,038 --> 00:20:36,410
to the logs management.

273
00:20:41,230 --> 00:20:44,654
Usually when the rest of the application already

274
00:20:44,772 --> 00:20:48,398
runs in the cloud

275
00:20:48,484 --> 00:20:52,366
hosting and in

276
00:20:52,388 --> 00:20:55,854
majority cloud hosting, the logs already

277
00:20:55,972 --> 00:21:00,366
get enriched with additional metadata and converted

278
00:21:00,398 --> 00:21:04,450
to some kind of structured logs so it doesn't require

279
00:21:06,150 --> 00:21:09,300
additional modifications in the application code.

280
00:21:09,850 --> 00:21:13,474
And for hosts that don't

281
00:21:13,522 --> 00:21:18,630
do it, it is possible to use various

282
00:21:19,610 --> 00:21:23,226
logs engine such as fluent d or

283
00:21:23,248 --> 00:21:26,970
fluent bit that can reformat

284
00:21:27,630 --> 00:21:31,178
the logs, especially if the logs are printed to

285
00:21:31,184 --> 00:21:35,166
the standard output or just service a local

286
00:21:35,348 --> 00:21:38,814
endpoint for log ingestion and

287
00:21:38,852 --> 00:21:43,280
then forward the logs with additional information

288
00:21:44,130 --> 00:21:47,474
to the back end. The same can be done with open

289
00:21:47,512 --> 00:21:51,374
telemetry, but today I don't want to touch upon

290
00:21:51,422 --> 00:21:55,218
this solution let you

291
00:21:55,384 --> 00:21:59,880
implement the logs anonymization without

292
00:22:00,810 --> 00:22:04,546
having specialized knowledge about data identification

293
00:22:04,658 --> 00:22:08,680
or obfuscation. You can do it

294
00:22:09,050 --> 00:22:13,098
in a scaled and flexible way without

295
00:22:13,184 --> 00:22:17,002
changing single line of code and keeping all the work

296
00:22:17,136 --> 00:22:22,118
within the DevOps team which already specialize

297
00:22:22,214 --> 00:22:26,558
on the maintenance from another side. The additional maintenance cost

298
00:22:26,724 --> 00:22:30,670
can be significantly reduced if you host

299
00:22:31,250 --> 00:22:35,040
this solution in the cloud which already provide you

300
00:22:36,710 --> 00:22:40,274
partial maintenance. It is

301
00:22:40,312 --> 00:22:43,874
especially easy when you use one

302
00:22:43,912 --> 00:22:47,890
of the major cloud providers which have

303
00:22:47,960 --> 00:22:51,320
managed solution for this type of service.

304
00:22:51,850 --> 00:22:55,298
I would like to show you a reference architecture

305
00:22:55,474 --> 00:23:00,214
that will work and

306
00:23:00,412 --> 00:23:03,660
help you implement this solution in the Google Cloud.

307
00:23:05,870 --> 00:23:10,486
This architecture fully

308
00:23:10,518 --> 00:23:14,654
hosted in the Google Cloud. It includes four

309
00:23:14,772 --> 00:23:19,390
different managed services cloud

310
00:23:19,460 --> 00:23:23,902
logging pubsap which is

311
00:23:24,036 --> 00:23:28,100
managed synchronous messaging service,

312
00:23:29,590 --> 00:23:34,830
Apache Beam which is managed

313
00:23:34,910 --> 00:23:38,162
ETL pipeline and cloud

314
00:23:38,216 --> 00:23:41,954
DLP. The service that provides

315
00:23:42,002 --> 00:23:45,634
implementation of the detective and corrective controls

316
00:23:45,682 --> 00:23:49,778
out of the box logging

317
00:23:49,874 --> 00:23:53,820
service in Google Cloud supports not only

318
00:23:54,430 --> 00:23:58,730
storing the logs, it also supports

319
00:23:59,630 --> 00:24:03,674
log routing. So you

320
00:24:03,712 --> 00:24:07,470
will not require to implement this proxy

321
00:24:08,130 --> 00:24:11,998
by yourself. You will have only to configure the proper

322
00:24:12,084 --> 00:24:15,614
routing logic in your

323
00:24:15,652 --> 00:24:16,430
environment.

324
00:24:18,870 --> 00:24:21,714
Additionally, in Google Cloud,

325
00:24:21,912 --> 00:24:25,886
structured logs with all necessary metadata

326
00:24:25,918 --> 00:24:29,494
about the source of the logs is provided out

327
00:24:29,532 --> 00:24:33,250
of the box and Google Cloud provides

328
00:24:33,330 --> 00:24:36,934
you with a log agent that can be installed on

329
00:24:36,972 --> 00:24:40,306
your environment and will enrich

330
00:24:40,338 --> 00:24:42,380
your logs with relevant information.

331
00:24:43,950 --> 00:24:47,690
So what is most interesting about

332
00:24:47,760 --> 00:24:51,046
this flow is the compliance controls implementation.

333
00:24:51,158 --> 00:24:55,514
So let me walk you through the ETL pipeline

334
00:24:55,642 --> 00:24:59,006
implemented in the dataflow service which is

335
00:24:59,028 --> 00:25:01,310
the managed version of the Apache bin.

336
00:25:03,090 --> 00:25:06,254
So for those

337
00:25:06,292 --> 00:25:10,146
of you who are not familiar with Apache bin is

338
00:25:10,248 --> 00:25:14,238
it is extract, transform and cloud pipeline

339
00:25:14,334 --> 00:25:17,554
shortly ETL that allows you to

340
00:25:17,592 --> 00:25:21,718
define multiple transformation for

341
00:25:21,884 --> 00:25:26,200
data that get ingested into the pipeline and

342
00:25:26,570 --> 00:25:31,438
at the end it exports this data to the predefined

343
00:25:31,554 --> 00:25:34,906
destination. It can be done on the bulk of

344
00:25:34,928 --> 00:25:38,394
the data, which is the kind

345
00:25:38,432 --> 00:25:42,380
of final set of the input data, or it can be done

346
00:25:42,750 --> 00:25:45,680
for the stream. So in our case,

347
00:25:47,890 --> 00:25:51,802
all logs entries just get streamed

348
00:25:51,866 --> 00:25:55,642
into this pipeline using the logging

349
00:25:55,706 --> 00:25:59,086
and service which routes all logs

350
00:25:59,118 --> 00:26:02,850
from the application and from the infrastructure into the pipeline.

351
00:26:03,830 --> 00:26:07,460
The first step will be to transform it from the pub sub

352
00:26:08,230 --> 00:26:12,162
message and retrieve the relevant

353
00:26:12,306 --> 00:26:16,098
data of the log entry

354
00:26:16,274 --> 00:26:19,894
and then the second step will be to aggregate this

355
00:26:19,932 --> 00:26:23,642
data into big batches and

356
00:26:23,696 --> 00:26:27,130
then these batches are sent to the DLP.

357
00:26:31,150 --> 00:26:35,114
The purpose of the aggregation of multiple

358
00:26:35,162 --> 00:26:38,814
entries into the batches is to

359
00:26:38,852 --> 00:26:42,046
save both in cost and performance because

360
00:26:42,148 --> 00:26:45,546
all cloud providers,

361
00:26:45,658 --> 00:26:47,300
including Google Cloud,

362
00:26:48,550 --> 00:26:53,250
introduce some kind of quotas, the total API

363
00:26:54,390 --> 00:26:57,278
performance on large volumes.

364
00:26:57,374 --> 00:27:01,154
Additionally, most of the cloud providers

365
00:27:01,202 --> 00:27:06,082
charge you per API call and sending

366
00:27:06,146 --> 00:27:10,278
multiple entries for the single call

367
00:27:10,364 --> 00:27:13,674
can save you significantly on your

368
00:27:13,712 --> 00:27:18,586
cloud bill for

369
00:27:18,608 --> 00:27:21,834
each month. Additionally, it allows you to

370
00:27:21,872 --> 00:27:25,662
scale very well with the log

371
00:27:25,716 --> 00:27:26,960
intensive application.

372
00:27:28,770 --> 00:27:32,014
DLP API allows you to

373
00:27:32,052 --> 00:27:35,742
define configuration both for detective and

374
00:27:35,796 --> 00:27:39,620
corrective controls, and once

375
00:27:40,310 --> 00:27:44,702
detective controls for each entry

376
00:27:44,766 --> 00:27:48,850
that detective control identifies as matching the condition,

377
00:27:49,370 --> 00:27:52,870
the corrective control logic can be applied.

378
00:27:53,690 --> 00:27:57,426
Eventually the processed

379
00:27:57,458 --> 00:28:00,742
batch is returned from DLP. It is

380
00:28:00,796 --> 00:28:06,266
formatted into the log

381
00:28:06,368 --> 00:28:10,234
entries format and ingested eventually to

382
00:28:10,272 --> 00:28:13,850
the log storage bucket.

383
00:28:15,570 --> 00:28:19,550
This flow is implemented.

384
00:28:21,410 --> 00:28:25,326
You can find the implementation of this flow on

385
00:28:25,348 --> 00:28:29,010
the GitHub repo. Please find

386
00:28:29,080 --> 00:28:32,914
the link in the slides and

387
00:28:33,032 --> 00:28:36,754
if you want to have a

388
00:28:36,792 --> 00:28:41,054
more in depth understanding about this reference architecture

389
00:28:41,102 --> 00:28:45,682
implementation, you can read it in the blog post I

390
00:28:45,736 --> 00:28:49,620
posted on the menu. If you have additional questions

391
00:28:49,990 --> 00:28:53,846
about this topic or about any other topic of observability,

392
00:28:53,958 --> 00:28:57,766
I will be glad to chat with you on discord.

393
00:28:57,958 --> 00:28:59,240
Thank you for being with me.

