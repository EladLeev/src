1
00:00:23,610 --> 00:00:27,154
Hello and welcome to run fast catch performance regressions

2
00:00:27,202 --> 00:00:30,994
in Python. I'm Everett Pompeii. I'm the founder

3
00:00:31,042 --> 00:00:33,830
and maintainer of a tool called venture,

4
00:00:34,490 --> 00:00:37,794
and today we're going to be talking about how to catch

5
00:00:37,842 --> 00:00:41,314
performance regressions. Now, in order to catch a performance

6
00:00:41,362 --> 00:00:45,474
regression, you have to first detect it. Detection is a prerequisite

7
00:00:45,522 --> 00:00:49,270
to prevention. So when

8
00:00:49,340 --> 00:00:53,230
do we, when are we able to detect performance regressions?

9
00:00:53,730 --> 00:00:57,614
Well, we can do that in development or we

10
00:00:57,652 --> 00:01:00,922
could do that in CI or in production,

11
00:01:01,066 --> 00:01:04,990
and more often than not, that ends up being in production,

12
00:01:05,350 --> 00:01:09,220
which is unfortunate because that means it's impacting our users already

13
00:01:09,750 --> 00:01:13,234
and whether or not we have an observability tool. And we can see that before

14
00:01:13,272 --> 00:01:16,870
anyone complains, they're nonetheless probably experiencing.

15
00:01:17,770 --> 00:01:21,926
So we would, as developers, want to shift left

16
00:01:22,028 --> 00:01:25,906
as much as we could, the detection of those performance

17
00:01:25,938 --> 00:01:29,114
regressions. So that's what we're going to start off

18
00:01:29,152 --> 00:01:32,598
talking with today, is about how to detect those performance regressions

19
00:01:32,694 --> 00:01:35,962
using benchmarks. But before

20
00:01:36,016 --> 00:01:39,386
we get into that, I'm going to kind of tell a little

21
00:01:39,408 --> 00:01:43,246
tale that may or may not

22
00:01:43,348 --> 00:01:47,594
be reflective or similar to some personal experiences,

23
00:01:47,642 --> 00:01:51,486
but for all intents purposes, it's fictitious. So we've got

24
00:01:51,508 --> 00:01:55,058
an app, I've got an app, v zero of the app. It's a

25
00:01:55,064 --> 00:01:58,766
basic calendar API, right? And so it allows

26
00:01:58,798 --> 00:02:02,402
people to schedule things and create events and things like that.

27
00:02:02,536 --> 00:02:06,374
And so this is created in flask, but it could very

28
00:02:06,412 --> 00:02:09,538
well have been in Django or in fast API.

29
00:02:09,714 --> 00:02:13,186
Take your pick. So, got this calendar

30
00:02:13,218 --> 00:02:17,138
app, it's working great. Got the Vzor app. Minimal, lovable product,

31
00:02:17,324 --> 00:02:21,500
right? And then I decide, hey, I want to

32
00:02:22,190 --> 00:02:25,994
add an additional feature to this, right? And so a

33
00:02:26,032 --> 00:02:29,922
fun notification feature. So every few days it gives our users

34
00:02:30,006 --> 00:02:33,082
a fun notification. Just kind of out of the blue,

35
00:02:33,226 --> 00:02:37,294
right? Help keep engagement. So we're calling

36
00:02:37,332 --> 00:02:40,990
this the Fizz feature. And so with the Fizz feature,

37
00:02:41,490 --> 00:02:44,740
it returns Fizz if the day is divisible by three,

38
00:02:45,510 --> 00:02:48,834
otherwise it returns none. And it's pretty simple

39
00:02:48,872 --> 00:02:52,434
feature to implement. The business logic looks like

40
00:02:52,472 --> 00:02:56,478
this. It's the fun notification

41
00:02:56,574 --> 00:03:00,566
function. It just takes the modulus of three, and if

42
00:03:00,588 --> 00:03:04,406
that's zero, then it returns fake, otherwise it returns not.

43
00:03:04,588 --> 00:03:07,414
So that's great releasing to the customers,

44
00:03:07,532 --> 00:03:09,830
they love our fun notification feature.

45
00:03:10,490 --> 00:03:13,722
And so I'm super happy and I'm like, hey,

46
00:03:13,856 --> 00:03:16,298
I'm going to make this even better. And I think you guys might kind of

47
00:03:16,304 --> 00:03:20,086
know where this is going here, but I decide

48
00:03:20,118 --> 00:03:23,422
to improve the fun notification feature, right? And I add

49
00:03:23,476 --> 00:03:27,226
buzz, so return fizz if the day is divisible

50
00:03:27,258 --> 00:03:30,526
by three, return buzz if it's divisible by five,

51
00:03:30,708 --> 00:03:34,762
or fizz buzz if it's divisible by both. So otherwise,

52
00:03:34,826 --> 00:03:38,446
still the same, return none. And again, this business logic

53
00:03:38,478 --> 00:03:41,714
is pretty simple, right? It's just that

54
00:03:41,752 --> 00:03:45,374
same modulus operator. But this time we got both fizz and buzz

55
00:03:45,422 --> 00:03:49,046
or fizz buzz. So I

56
00:03:49,228 --> 00:03:52,614
ship that to my customers, and they also

57
00:03:52,652 --> 00:03:56,150
love it. And so I've got version two out and things are going great,

58
00:03:56,300 --> 00:03:59,478
and they love it so much, I'm like, hey, you know what? I think I'm

59
00:03:59,494 --> 00:04:03,290
going to add something else to it. And I do

60
00:04:03,360 --> 00:04:07,126
my full desired implementation of the fun notification feature,

61
00:04:07,238 --> 00:04:11,258
right? Which I call fizzbud Buzz fibonacci. So fizzbuzz

62
00:04:11,274 --> 00:04:13,950
fibonacci, though, quite a mouthful.

63
00:04:15,090 --> 00:04:18,490
It starts the same as the good old fizz buzz feature,

64
00:04:18,650 --> 00:04:21,600
which the three, the five, or both.

65
00:04:22,770 --> 00:04:26,238
Except if the day is divisible by seven, then it returns

66
00:04:26,254 --> 00:04:28,690
the nth step of the Fibonacci sequence.

67
00:04:29,030 --> 00:04:32,242
Otherwise, return that. And still

68
00:04:32,296 --> 00:04:35,714
that business logic looks pretty simple. I just have that

69
00:04:35,752 --> 00:04:39,814
extra two lines up top where I'm checking for the modulus seven,

70
00:04:39,932 --> 00:04:43,206
and then I just do the Fibonacci sequence. And I moved on with

71
00:04:43,228 --> 00:04:47,000
my day and shipped it out to customers, and they loved it.

72
00:04:47,950 --> 00:04:51,834
And things were going great until three

73
00:04:51,872 --> 00:04:55,770
weeks later when all of a sudden

74
00:04:56,270 --> 00:04:59,580
production was on fire and I was like, what's going on?

75
00:05:00,750 --> 00:05:04,574
What's happening? Right? I shipped a bunch of code between then

76
00:05:04,612 --> 00:05:08,046
and the past three weeks, right? And so I had

77
00:05:08,068 --> 00:05:11,726
to come in here and spend all day coming back to try and

78
00:05:11,748 --> 00:05:15,806
figure out what was going on before I figured out it was this darn

79
00:05:15,838 --> 00:05:19,506
Fibonacci feature that I had

80
00:05:19,528 --> 00:05:23,186
done three weeks prior. And so I started looking at

81
00:05:23,208 --> 00:05:26,718
this and said I should investigate,

82
00:05:26,814 --> 00:05:30,258
oh, I should investigate a little bit more. And that's what I did,

83
00:05:30,344 --> 00:05:34,006
went and look at my Fibonacci sequence function, and I

84
00:05:34,028 --> 00:05:37,800
had done a very naive implementation of it. And so

85
00:05:38,970 --> 00:05:41,798
I think you guys are probably smarter than I am and know that I shouldn't

86
00:05:41,814 --> 00:05:45,098
have done this to begin with. But before we dig into all that, we're going

87
00:05:45,104 --> 00:05:48,326
to kind of do an aside and look at benchmarking

88
00:05:48,358 --> 00:05:52,222
in Python and how I could have take

89
00:05:52,276 --> 00:05:56,234
this as a learning experience and go and benchmark my naive

90
00:05:56,282 --> 00:05:59,230
implementation as I try and find a better solution.

91
00:06:00,130 --> 00:06:04,366
So Pytest benchmark is a very popular benchmarking

92
00:06:04,398 --> 00:06:07,922
suite within the Python ecosystem. There is also

93
00:06:07,976 --> 00:06:12,242
another one called Airspeed velocity, which isn't quite as popular, but is

94
00:06:12,376 --> 00:06:15,606
also pretty well known. We're going to be working with

95
00:06:15,628 --> 00:06:19,846
Pytest benchmarks here because it works and integrates so well with

96
00:06:19,948 --> 00:06:23,526
Pytest. So in order to install

97
00:06:23,628 --> 00:06:27,326
pytest benchmark, super easy, just a pip env shell

98
00:06:27,458 --> 00:06:31,530
and you just install Python

99
00:06:32,110 --> 00:06:36,140
Pytest benchmark. So I have my

100
00:06:36,750 --> 00:06:41,722
naive Fibonacci implementation

101
00:06:41,786 --> 00:06:45,310
here in my fundnotification py,

102
00:06:46,130 --> 00:06:50,334
and so I'm adding a benchmark to it that

103
00:06:50,372 --> 00:06:53,966
basically cycles through every 7th day of the month and checks

104
00:06:53,998 --> 00:06:57,314
to see how long this takes to run. Now, the key

105
00:06:57,352 --> 00:07:00,866
parts in this and where Pytest benchmark, how it

106
00:07:00,888 --> 00:07:04,686
works is you're passing in this benchmark

107
00:07:04,718 --> 00:07:08,280
argument and that expects to take

108
00:07:08,650 --> 00:07:12,262
a function here and then it basically just times that function. So however

109
00:07:12,316 --> 00:07:15,974
long it takes that function to run is

110
00:07:16,092 --> 00:07:19,674
your benchmarking time, essentially. And so here we're going

111
00:07:19,712 --> 00:07:23,146
through every 7th day of the month just to kind of get a feel of

112
00:07:23,248 --> 00:07:26,746
what the youll scope of

113
00:07:26,848 --> 00:07:29,180
the time that it's going to use is.

114
00:07:29,890 --> 00:07:34,106
So in order to run this, you just run Pytest

115
00:07:34,218 --> 00:07:38,794
and then your file with your functions,

116
00:07:38,842 --> 00:07:42,366
just like you normally do with Pytest. And this

117
00:07:42,388 --> 00:07:45,898
is the output that I got for this naive version,

118
00:07:45,994 --> 00:07:49,890
right. It's pretty high. It takes over a 10th of a second to run,

119
00:07:49,960 --> 00:07:53,618
which is at scale, not a good thing when you

120
00:07:53,624 --> 00:07:55,986
have a lot of people using, when I had a lot of people using my

121
00:07:56,008 --> 00:07:59,830
calendar app. So then if we wanted to,

122
00:07:59,900 --> 00:08:03,414
which is going to be important later, we can run save

123
00:08:03,532 --> 00:08:06,886
on our benchmark output. So this will save it

124
00:08:06,988 --> 00:08:10,650
to a directory which we can add to git, which then means that over time

125
00:08:10,720 --> 00:08:14,314
we can track these benchmarks, even just kind of running

126
00:08:14,352 --> 00:08:18,406
them locally here. And so we've

127
00:08:18,438 --> 00:08:22,986
got my tested benchmarks,

128
00:08:23,178 --> 00:08:26,986
naive implementation here. And so now I'm

129
00:08:27,018 --> 00:08:30,670
going to go and add some memoization which help

130
00:08:30,740 --> 00:08:34,930
improve the performance, hopefully of my function and

131
00:08:35,080 --> 00:08:38,670
do the exact same test. Notice the test has not changed, the benchmark

132
00:08:38,750 --> 00:08:42,734
has not changed, but just the Fibonacci implementation

133
00:08:42,782 --> 00:08:45,926
has. And so I run that again,

134
00:08:46,108 --> 00:08:50,182
same exact call to Pytest and

135
00:08:50,236 --> 00:08:53,862
I get this output, which it's like a six less to run, right,

136
00:08:53,916 --> 00:08:57,670
because memoization helps memoize.

137
00:08:58,970 --> 00:09:02,022
So that is a definite huge performance improvement.

138
00:09:02,166 --> 00:09:05,626
Now if we wanted to compare those, we could copy and paste or

139
00:09:05,648 --> 00:09:09,642
whatever, but Pytest does actually give us a really nice way

140
00:09:09,696 --> 00:09:13,742
to compare. You can just pass the number

141
00:09:13,796 --> 00:09:17,582
that it kind of keeps of the previous version to kind of compare those

142
00:09:17,716 --> 00:09:20,302
within those saved benchmarks that we just did.

143
00:09:20,436 --> 00:09:24,034
So we run that and we get this output, which lets us

144
00:09:24,072 --> 00:09:28,462
see our version now versus that previous naive version

145
00:09:28,606 --> 00:09:31,380
and how drastically improved things are,

146
00:09:32,310 --> 00:09:33,540
which is pretty great.

147
00:09:36,330 --> 00:09:40,146
That is a great example of how to run and compare

148
00:09:40,258 --> 00:09:43,394
with Pytest. Now, a little note

149
00:09:43,442 --> 00:09:46,210
on micro versus macro benchmarks.

150
00:09:46,370 --> 00:09:49,882
So far we've been doing micro benchmarks. I think

151
00:09:49,936 --> 00:09:53,270
these analogously as unit tests,

152
00:09:53,350 --> 00:09:57,034
unit level benchmarking. And so what

153
00:09:57,072 --> 00:10:01,062
this does is it's really about just like a single function versus

154
00:10:01,126 --> 00:10:04,990
what are called macro benchmarks, which are much more like integration tests.

155
00:10:05,330 --> 00:10:08,558
They're kind of full end to end. So with my flask app

156
00:10:08,644 --> 00:10:11,920
that I'm using for my calendar API here,

157
00:10:12,530 --> 00:10:15,026
here's my endpoint, right?

158
00:10:15,128 --> 00:10:18,962
And this is the fun notification endpoint. It gets

159
00:10:19,096 --> 00:10:22,658
the date time, it gets the day from there, and then it calls my

160
00:10:22,664 --> 00:10:25,838
fun notification function and then jsonifies things and then sends

161
00:10:25,854 --> 00:10:29,682
it out. And so the thing is, I will be benchmarking

162
00:10:29,746 --> 00:10:33,734
all of that. So if there's any changes outside of my code, it's great because

163
00:10:33,772 --> 00:10:37,382
I also can detect that if there's any regressions and libraries I use

164
00:10:37,436 --> 00:10:40,678
and things like that. But it is a bit more noisy

165
00:10:40,854 --> 00:10:44,010
because of that. And you're also just going to have larger values,

166
00:10:44,830 --> 00:10:46,540
just a thing to know.

167
00:10:48,510 --> 00:10:52,218
But they work pretty much exactly the same way and the same way that unit

168
00:10:52,234 --> 00:10:55,998
and integration tests are very similar. So back

169
00:10:56,084 --> 00:11:01,210
to our fizzbuzz Fibonacci feature. I have implemented

170
00:11:01,290 --> 00:11:05,102
my memoization, and I was very

171
00:11:05,156 --> 00:11:08,654
silly before implemented

172
00:11:08,702 --> 00:11:11,970
originally, very naively. So now that we have that fix in,

173
00:11:12,120 --> 00:11:15,806
things should be good to go. Right. And so I'm

174
00:11:15,838 --> 00:11:19,270
able to come in, play firefighter and put out the fire

175
00:11:19,340 --> 00:11:22,280
that I caused in production, which is good.

176
00:11:22,970 --> 00:11:26,470
Things aren't on fire anymore. But why

177
00:11:26,540 --> 00:11:28,570
do I have to play firefighter?

178
00:11:30,510 --> 00:11:34,074
It'd be preferable if I didn't, in the same way that

179
00:11:34,112 --> 00:11:37,622
it's preferable that you catch your performance regression or youll feature

180
00:11:37,686 --> 00:11:41,286
regressions before they make it to production and impact

181
00:11:41,318 --> 00:11:44,498
your customers. It would be great to be able to catch your performance regressions

182
00:11:44,614 --> 00:11:47,280
before they make it to production and impact youll customers.

183
00:11:48,690 --> 00:11:51,886
And so youll could have observability tools and

184
00:11:51,908 --> 00:11:55,998
they can help. But still that is too late, right? Like you're still impacting

185
00:11:56,014 --> 00:11:59,714
your customers and users, and so

186
00:11:59,752 --> 00:12:04,206
was I in my calendar app here. So production

187
00:12:04,238 --> 00:12:08,434
is just too late to catch things and then development is

188
00:12:08,472 --> 00:12:12,150
local only. So you've got those saved tests and things like that. But it's very

189
00:12:12,220 --> 00:12:15,206
set to only the one environment that it's running in.

190
00:12:15,308 --> 00:12:18,554
And it makes it very hard to share that across a code base

191
00:12:18,592 --> 00:12:21,500
with multiple users in a development team.

192
00:12:22,910 --> 00:12:26,394
So it's great for local benchmark comparison, both in Pytest and

193
00:12:26,432 --> 00:12:30,720
airspeed velocity, but it is local only really.

194
00:12:31,330 --> 00:12:34,586
And then in CI, continuous benchmarking

195
00:12:34,778 --> 00:12:38,222
is the thing that we're going to talk about next, which is what

196
00:12:38,276 --> 00:12:41,706
allows you to detect and prevent these performance regressions.

197
00:12:41,898 --> 00:12:45,662
In CI, we are going to talk about Bencher,

198
00:12:45,806 --> 00:12:49,682
but I will note that airspeed velocity also

199
00:12:49,736 --> 00:12:53,486
has some kind of rudimentary basic continuous

200
00:12:53,518 --> 00:12:57,214
benchmarking functionality, which if you're kind of looking for a simpler

201
00:12:57,342 --> 00:13:00,838
tool to use, that might be worth checking out. But venture definitely has

202
00:13:00,844 --> 00:13:04,658
a lot, much more features and is much more robust in this category.

203
00:13:04,834 --> 00:13:08,070
So we can go forward taking a look at Bencher.

204
00:13:08,910 --> 00:13:12,070
So what if we had continuous benchmarking?

205
00:13:12,230 --> 00:13:15,926
What if I had continuous benchmarking when I was doing my calendar

206
00:13:15,958 --> 00:13:19,020
API? Right? So rule number one,

207
00:13:19,890 --> 00:13:22,946
let's go time travel back. But yeah, don't set it to 2020.

208
00:13:22,948 --> 00:13:26,574
And so this is

209
00:13:26,692 --> 00:13:30,240
venture. It's the GitHub repo of the open source tool.

210
00:13:32,790 --> 00:13:36,340
As we time travel back here with my calendar app,

211
00:13:36,710 --> 00:13:40,610
and I'm at that first version with the fizz feature,

212
00:13:41,430 --> 00:13:45,026
what would this have looked like? So I

213
00:13:45,048 --> 00:13:48,630
would have gone ahead and written a benchmark at that point in time,

214
00:13:48,700 --> 00:13:54,214
as opposed to kind of trying to do

215
00:13:54,252 --> 00:13:58,646
that proactively, I think is the best way to put that. And so it's

216
00:13:58,678 --> 00:14:01,926
a very similar sort of test function as what we wrote

217
00:14:01,958 --> 00:14:05,514
before, but it goes over every single day of the month,

218
00:14:05,632 --> 00:14:10,406
right. And tests to see how our

219
00:14:10,448 --> 00:14:13,886
function performs for our business logic. And so it

220
00:14:13,908 --> 00:14:17,774
records that. And then in order to run that

221
00:14:17,812 --> 00:14:22,142
in CI, we would need to download the venture CI and

222
00:14:22,196 --> 00:14:26,542
install it, which is a simple debian package and super

223
00:14:26,596 --> 00:14:30,146
quick and easy. And then we'd run that as part of our

224
00:14:30,168 --> 00:14:33,614
CI process. And here we're keeping with the pytest

225
00:14:33,662 --> 00:14:37,206
example, the pytest benchmark example. And we are

226
00:14:37,228 --> 00:14:40,486
going to output our results to a

227
00:14:40,508 --> 00:14:44,294
JSON file. And then Bencher, the CLI will read that

228
00:14:44,332 --> 00:14:48,822
in and take that information and store

229
00:14:48,876 --> 00:14:52,566
our results. So that's

230
00:14:52,598 --> 00:14:56,326
great. We've got our version one instrumented. So then as we move on to version

231
00:14:56,358 --> 00:14:59,658
two, we don't really have to do anything, it just picks it

232
00:14:59,664 --> 00:15:03,114
up and runs it in CI. And we don't have to manually test anything locally

233
00:15:03,162 --> 00:15:06,478
or do any work. It's just automatically picking up and doing the

234
00:15:06,484 --> 00:15:10,046
work for us. So that's great. And things

235
00:15:10,148 --> 00:15:13,646
seem to be going well. So then as we move on to version

236
00:15:13,678 --> 00:15:17,854
three, right, with that naive Fibonacci implementation

237
00:15:17,902 --> 00:15:20,050
there, we'll get an alert,

238
00:15:21,830 --> 00:15:25,362
which is great, because things are running

239
00:15:25,416 --> 00:15:28,966
incredibly slow compared to what they used to. But how does this happen?

240
00:15:29,068 --> 00:15:32,486
Let's kind of take a look at that. As you track your benchmarks with

241
00:15:32,508 --> 00:15:35,974
venture, youll kind of have that first

242
00:15:36,092 --> 00:15:39,126
version, right? And then second version

243
00:15:39,158 --> 00:15:42,586
youll add a little bit more functionality. And that third version is when you get

244
00:15:42,688 --> 00:15:46,460
a huge performance spike, right? And so

245
00:15:47,550 --> 00:15:51,260
that is what triggers the alert. And so

246
00:15:51,710 --> 00:15:55,470
don't worry, we're not going to get too much in the statistics here,

247
00:15:55,540 --> 00:15:58,686
but this is just a probability distribution, average kind

248
00:15:58,708 --> 00:16:02,154
of distribution of what you'd expect. Even if you reran the results

249
00:16:02,202 --> 00:16:05,140
multiple times, there'd be some variation. Right.

250
00:16:05,750 --> 00:16:09,570
And so with that, that first test

251
00:16:09,640 --> 00:16:12,882
is be right there in the middle, and then as you run kind of your

252
00:16:12,936 --> 00:16:16,706
second version of the code, those are going to be clustered. The averages of

253
00:16:16,728 --> 00:16:20,166
those two is going to be very close together. But that third

254
00:16:20,348 --> 00:16:24,086
Fibonacci is going to be all the way out in the extreme. And you

255
00:16:24,108 --> 00:16:27,950
set a threshold in venture, and if anything's outside of that threshold,

256
00:16:28,050 --> 00:16:31,302
which more than likely that Fibonacci sequence

257
00:16:31,446 --> 00:16:35,062
naive implementation would have been, then that is what triggers

258
00:16:35,126 --> 00:16:38,842
the alert. So that

259
00:16:38,896 --> 00:16:42,286
helps you catch performance regressions in CI. Instead of

260
00:16:42,308 --> 00:16:46,062
you manually having to do it yourself, you're able to have

261
00:16:46,196 --> 00:16:49,680
CI do it for you and rely on that to catch it.

262
00:16:51,250 --> 00:16:55,026
So we looked at and talked about trying to

263
00:16:55,048 --> 00:16:58,574
catch things retroactively in production.

264
00:16:58,622 --> 00:17:02,174
And all of the work that that takes, putting out the fires

265
00:17:02,222 --> 00:17:05,406
and things like that, it's just simply too late. We took a look

266
00:17:05,448 --> 00:17:08,930
and learned how to run benchmarks locally,

267
00:17:09,010 --> 00:17:12,242
which is with the very useful tools that the Python ecosystem

268
00:17:12,306 --> 00:17:16,242
offers, Pytest benchmarks. And there's also airspeed velocity.

269
00:17:16,386 --> 00:17:19,446
And then we took a look at using continuous

270
00:17:19,478 --> 00:17:22,950
benchmarking with venture and how that could have helped

271
00:17:23,030 --> 00:17:26,380
prevent all of that anguish and pain before.

272
00:17:27,310 --> 00:17:30,686
And yeah, that's just awesome. So in

273
00:17:30,708 --> 00:17:34,734
review, detection is required for

274
00:17:34,772 --> 00:17:37,786
prevention, production is too late,

275
00:17:37,978 --> 00:17:41,886
development is local only, and continuous benchmarking can

276
00:17:41,908 --> 00:17:45,326
save us a lot of pain. So with that, thank you

277
00:17:45,348 --> 00:17:48,846
all so much. This has been run fast. Catch performance regressions in

278
00:17:48,868 --> 00:17:52,206
Python. That's the GitHub repository for Bencher if you

279
00:17:52,228 --> 00:17:55,926
want to check it out. And if you wouldn't mind, please give

280
00:17:55,948 --> 00:17:59,926
us a star. It really does help the project. And if

281
00:18:00,108 --> 00:18:03,206
that GitHub link is too long to type out, then you can just

282
00:18:03,228 --> 00:18:06,534
go to venture Dev repo, and it'll redirect you right

283
00:18:06,572 --> 00:18:08,660
there. All right. Thank you all so much.

