1
00:00:17,610 --> 00:00:21,146
Hey everybody, my name is Mitri, I'm from Ukraine and I'm

2
00:00:21,178 --> 00:00:24,314
working at Lightsource AI as a software engineer.

3
00:00:24,362 --> 00:00:27,970
As a rough lead software engineer. Little disclaimer,

4
00:00:28,050 --> 00:00:31,554
if you love big money and you are a brilliant rust engineer,

5
00:00:31,602 --> 00:00:35,218
you are very welcome to try out and be a part of late source.

6
00:00:35,394 --> 00:00:38,666
But today I'm going to talk but my a little

7
00:00:38,688 --> 00:00:42,230
bit different passion. It's multimedia programming

8
00:00:42,310 --> 00:00:45,862
and especially video and audio programming.

9
00:00:46,006 --> 00:00:49,994
With Rust, ive been working on a project that

10
00:00:50,032 --> 00:00:53,518
allow you to create video for one point ive years

11
00:00:53,684 --> 00:00:57,322
and things. Video is actually my journey of creating

12
00:00:57,386 --> 00:01:01,246
videos and audios with Rust. So at

13
00:01:01,268 --> 00:01:05,410
the very first I am going to start from the scratch.

14
00:01:05,830 --> 00:01:09,762
What is a video? Today, video are the

15
00:01:09,816 --> 00:01:13,570
most popular type of content on the Internet.

16
00:01:14,070 --> 00:01:18,034
You know that today Internet consists

17
00:01:18,082 --> 00:01:21,490
of like 90% of the videos with kittens.

18
00:01:21,650 --> 00:01:25,142
But in fact today people are spending enormous amount

19
00:01:25,196 --> 00:01:29,114
of time in the watching videos by

20
00:01:29,232 --> 00:01:31,930
stats IO in general,

21
00:01:32,080 --> 00:01:35,370
general user of Internet spending more than 10 hours

22
00:01:35,440 --> 00:01:38,874
per week watching videos. Not so much you say,

23
00:01:38,992 --> 00:01:42,714
but that's actually dozens or hundreds of billions

24
00:01:42,842 --> 00:01:46,174
hours of watching videos per week.

25
00:01:46,372 --> 00:01:50,078
That's a lot. But technologies behind

26
00:01:50,164 --> 00:01:53,310
the videos are completely outdated.

27
00:01:53,970 --> 00:01:57,618
I even want to talk about the

28
00:01:57,784 --> 00:02:01,618
adobe after effects or professional software written in c

29
00:02:01,784 --> 00:02:05,390
that can be replaced with more safe rust.

30
00:02:05,550 --> 00:02:09,382
I'm actually talking about what real users are using to create

31
00:02:09,436 --> 00:02:12,646
videos for TikTok, for example. By the way,

32
00:02:12,668 --> 00:02:16,182
did you manage how we appear in a world where vertical video

33
00:02:16,236 --> 00:02:20,010
is the correct one? I didn't yet,

34
00:02:20,160 --> 00:02:23,462
but people are using really weird

35
00:02:23,526 --> 00:02:27,190
software today to create videos. They are using mobile apps,

36
00:02:27,270 --> 00:02:30,450
mobile video editors, mobile graphics,

37
00:02:30,550 --> 00:02:34,430
video editors to create videos,

38
00:02:34,580 --> 00:02:37,902
and they are really, really far away from being

39
00:02:37,956 --> 00:02:38,750
efficient.

40
00:02:41,410 --> 00:02:45,090
When I firstly understand that people that the most

41
00:02:45,160 --> 00:02:49,266
popular video editor renders video through the

42
00:02:49,448 --> 00:02:52,898
web, through the browser, through the HTML and CSS, I was like,

43
00:02:52,984 --> 00:02:56,454
oh my God, I need to somehow fix this.

44
00:02:56,652 --> 00:02:59,954
And it's actually a great time for Rust

45
00:03:00,082 --> 00:03:03,334
because Rust today probably

46
00:03:03,452 --> 00:03:06,040
the only correct way,

47
00:03:06,570 --> 00:03:10,070
I won't be afraid to say this, to work with audio

48
00:03:10,150 --> 00:03:13,514
or video, because when we will start

49
00:03:13,632 --> 00:03:17,386
figuring out more deeply about what is a video, you will

50
00:03:17,408 --> 00:03:21,600
notice that the main problem of video is memory and

51
00:03:22,370 --> 00:03:25,594
garbage collector. Languages that will handle

52
00:03:25,642 --> 00:03:29,550
videos or audios in runtime is mostly impossible.

53
00:03:30,130 --> 00:03:33,774
But today we will start literally from scratch. And I will

54
00:03:33,812 --> 00:03:37,106
try to describe you how I

55
00:03:37,128 --> 00:03:40,702
did and how you can work with videos in rust.

56
00:03:40,846 --> 00:03:44,754
So let's start from what is a video, like what is

57
00:03:44,792 --> 00:03:48,854
actually a video file and how it works. And if we will take the

58
00:03:48,972 --> 00:03:51,830
most common container for videos.

59
00:03:51,980 --> 00:03:55,602
It's the mp4 and mp4. It's not a codec,

60
00:03:55,666 --> 00:03:59,146
it's only a container for media. Input can

61
00:03:59,168 --> 00:04:02,998
contain different type of codecs, information for different types

62
00:04:03,014 --> 00:04:07,174
of codecs. And the mp4 file actually contains

63
00:04:07,222 --> 00:04:10,526
from the images stream each image. You can see

64
00:04:10,548 --> 00:04:14,414
it on your slide. On the slide right now has the presentation and

65
00:04:14,452 --> 00:04:18,554
decoding timestamp because, I'm sorry, because encoded

66
00:04:18,602 --> 00:04:22,926
itself contains of really depends on the ordering

67
00:04:22,958 --> 00:04:26,738
of frames. You can have

68
00:04:26,824 --> 00:04:32,740
the frame, for example, you can see the presentation frame is 01234.

69
00:04:33,270 --> 00:04:37,294
But the decoding frame is different

70
00:04:37,432 --> 00:04:41,126
because the encoder can use the information from the

71
00:04:41,148 --> 00:04:44,406
next frame in order to decode the current one that's in

72
00:04:44,428 --> 00:04:48,006
the grant schema scene. But you can understand right now that

73
00:04:48,108 --> 00:04:51,414
each pill from this graph is actually a separate

74
00:04:51,462 --> 00:04:54,970
image, like PNG or RGB, actually like in a different

75
00:04:55,040 --> 00:04:58,380
format. But we will talk about things a little bit later.

76
00:04:58,750 --> 00:05:02,510
And also we have an audio

77
00:05:03,170 --> 00:05:06,894
in the video and we

78
00:05:06,932 --> 00:05:10,506
have also the audio stream here. The audio stream

79
00:05:10,538 --> 00:05:14,018
consists of also the frames. The frames are a

80
00:05:14,024 --> 00:05:17,310
little bit different because the audio consists of samples.

81
00:05:17,390 --> 00:05:21,106
Sample is much smaller in amount of

82
00:05:21,128 --> 00:05:26,580
time. We record relevant 40 48,000

83
00:05:27,110 --> 00:05:30,534
samples per rate. And we also capture the

84
00:05:30,572 --> 00:05:33,990
frames of the audio and connect

85
00:05:34,060 --> 00:05:38,114
it with the same architecture of presentation

86
00:05:38,162 --> 00:05:42,218
and decoding timestamps. And that's actually the base for

87
00:05:42,304 --> 00:05:45,734
all the codecs you can find today on the Internet, on the open source,

88
00:05:45,782 --> 00:05:49,814
everywhere. Because decodec itself is mostly

89
00:05:49,862 --> 00:05:54,254
about the mass, it's about how

90
00:05:54,292 --> 00:05:59,406
to make the information of

91
00:05:59,428 --> 00:06:05,394
the specific images sequence to

92
00:06:05,432 --> 00:06:09,042
eat less space from your hard drive. There are

93
00:06:09,096 --> 00:06:12,654
a lot of codecs today you may know, but like Ampec,

94
00:06:12,702 --> 00:06:16,454
four half AV and a lot

95
00:06:16,492 --> 00:06:20,086
of different codecs, some like with transparent images, some is

96
00:06:20,108 --> 00:06:23,254
better for streaming, some better for web,

97
00:06:23,372 --> 00:06:26,934
some better for professional video editing and

98
00:06:26,972 --> 00:06:30,806
used mostly by the cinema creators.

99
00:06:30,998 --> 00:06:35,062
But most of them are actually like the giant specs

100
00:06:35,206 --> 00:06:38,586
of the mathematics that are used inside the

101
00:06:38,608 --> 00:06:42,366
codec to make the video more light

102
00:06:42,468 --> 00:06:46,382
and in order to more easily transfer it

103
00:06:46,436 --> 00:06:49,566
through the net and the stream and so on and so forth. So for example,

104
00:06:49,668 --> 00:06:52,914
the most popular codec, the second most

105
00:06:52,952 --> 00:06:56,354
popular codec today, and probably the one that should

106
00:06:56,392 --> 00:06:59,858
be used everywhere, it's a hefk like

107
00:06:59,944 --> 00:07:03,858
high efficiency video codec. It's h

108
00:07:03,944 --> 00:07:08,210
two six ive. It has specification over 700

109
00:07:08,280 --> 00:07:11,922
pages. And there are plenty amount of implementation

110
00:07:11,986 --> 00:07:15,734
of these codecs. And you can use it, you can use the specification to build

111
00:07:15,772 --> 00:07:18,950
your own codec. You can use an open source implementation of the codec,

112
00:07:19,030 --> 00:07:22,090
but actually it defines the mass of how,

113
00:07:22,240 --> 00:07:26,138
for example, when I'm moving somewhere, you can see the video

114
00:07:26,224 --> 00:07:29,706
should not save all

115
00:07:29,728 --> 00:07:31,470
of the frames of my movement.

116
00:07:35,250 --> 00:07:39,198
It's actually enough to only capture the position

117
00:07:39,364 --> 00:07:43,230
and where the position will be like in a second and then render

118
00:07:43,310 --> 00:07:44,340
it in.

119
00:07:49,190 --> 00:07:53,186
It's perfectly enough to capture the one position, the another one,

120
00:07:53,288 --> 00:07:57,106
and then like render something in between. And that's

121
00:07:57,138 --> 00:08:00,630
actually what codecs are doing mostly.

122
00:08:01,210 --> 00:08:05,030
But you likely as a user or developer who makes

123
00:08:05,100 --> 00:08:08,570
video with code, don't really want to implement 700

124
00:08:08,640 --> 00:08:12,358
specification by yourself. And that's where Libav

125
00:08:12,454 --> 00:08:15,914
helps. Libav, it's an open

126
00:08:16,032 --> 00:08:19,322
library. You may notice that a C library for

127
00:08:19,376 --> 00:08:22,942
audio and video, and you can use it. It's actually

128
00:08:22,996 --> 00:08:27,470
an abstraction over all the codecs you may actually

129
00:08:27,540 --> 00:08:31,722
find on Internet. It supports literally everything, all the audio,

130
00:08:31,786 --> 00:08:35,426
all the video codecs and so on and so forth. And you may know it

131
00:08:35,528 --> 00:08:39,934
by another more popularly used name, it's Ffmpeg.

132
00:08:40,062 --> 00:08:44,526
Originally Ffmpeg was a CLI wrapper around the Libav,

133
00:08:44,718 --> 00:08:48,518
but right now it's maintained it within

134
00:08:48,604 --> 00:08:52,274
one repository. And Libav is actually part of FFmpeg,

135
00:08:52,322 --> 00:08:56,294
but doesn't really matter. But using FFmpeg you

136
00:08:56,332 --> 00:09:00,810
can actually render any kind of video from

137
00:09:00,880 --> 00:09:04,282
any kind of image and audio source. As we noticed at the very

138
00:09:04,336 --> 00:09:07,754
start with literally one comment things

139
00:09:07,792 --> 00:09:11,790
is perfectly enough to generate a video. So basically, like we said

140
00:09:11,860 --> 00:09:15,422
that we want to have a video with 60 FPS like full

141
00:09:15,476 --> 00:09:19,258
hd, have an input of a seconds

142
00:09:19,274 --> 00:09:22,754
of n images. So basically on your file system you can

143
00:09:22,792 --> 00:09:26,654
have pick then the number of the frames PnG

144
00:09:26,702 --> 00:09:29,954
file that then will be decoded and

145
00:09:29,992 --> 00:09:33,922
transformed into the frame using the h

146
00:09:33,976 --> 00:09:38,242
265264 codecs and specific pixel format.

147
00:09:38,306 --> 00:09:42,194
And as an output you'll get the test mp4 file.

148
00:09:42,322 --> 00:09:46,360
And this actually works. And that's how today

149
00:09:48,350 --> 00:09:52,778
most of videos from the free

150
00:09:52,944 --> 00:09:56,860
open source, not open source, free for use

151
00:09:57,230 --> 00:10:00,490
editors on mobile and on web are doing.

152
00:10:00,640 --> 00:10:04,590
But that's really really far away from being

153
00:10:04,660 --> 00:10:08,334
really efficient just because we don't really want to waste a lot of time

154
00:10:08,372 --> 00:10:11,774
on rendering images. And we can do it

155
00:10:11,812 --> 00:10:15,220
directly because Libav has the

156
00:10:17,910 --> 00:10:21,362
public C API, we can use it from rust in order

157
00:10:21,416 --> 00:10:24,974
to make the manual encoding. How it works pretty

158
00:10:25,032 --> 00:10:28,470
easy. You can have the image, an image will be the

159
00:10:28,540 --> 00:10:32,194
BMP image, it's like raw

160
00:10:32,242 --> 00:10:36,200
image sources. Then you need to convert it to

161
00:10:39,230 --> 00:10:42,410
YuV image. We will talk a bit later

162
00:10:42,480 --> 00:10:45,910
about it, then you send it to the encoder,

163
00:10:45,990 --> 00:10:49,706
which is like implementation captured by Libav you

164
00:10:49,728 --> 00:10:54,314
will get a packet. Packet is a compressed

165
00:10:54,362 --> 00:10:57,754
frame of the video. You assign

166
00:10:57,802 --> 00:11:01,498
a specific timestamp when you want it to be encoded,

167
00:11:01,594 --> 00:11:05,214
decoded when you want to be read, and then

168
00:11:05,252 --> 00:11:08,914
you put it into the media container, the same you are doing with the

169
00:11:08,952 --> 00:11:12,146
next image. And the same way you

170
00:11:12,168 --> 00:11:16,374
get a new packet and send it to

171
00:11:16,412 --> 00:11:20,694
your file. The only problem, that you

172
00:11:20,732 --> 00:11:23,974
must encode all the frames one by one

173
00:11:24,172 --> 00:11:28,134
in seconds. Just because that's pretty straightforward. That codex

174
00:11:28,182 --> 00:11:31,980
are using specific math to understand how they should

175
00:11:32,510 --> 00:11:36,122
encoded the images. And here is more about

176
00:11:36,176 --> 00:11:39,578
this YUV image, which is

177
00:11:39,744 --> 00:11:43,854
like it's actually a legacy from

178
00:11:43,892 --> 00:11:47,854
the past times. And that's very interesting story I would like to

179
00:11:47,892 --> 00:11:50,286
talk about a little bit. So basically,

180
00:11:50,468 --> 00:11:54,322
igbric u by images are instead

181
00:11:54,376 --> 00:11:57,886
of like RGB color channels, it's just a different representation

182
00:11:57,918 --> 00:12:01,342
of colors where you have the luma

183
00:12:01,406 --> 00:12:04,798
or the brightness channel, which actually defined

184
00:12:04,814 --> 00:12:08,266
the black and white, and the two additional coral

185
00:12:08,318 --> 00:12:12,146
color planes. That a result gives you the perfectly

186
00:12:12,178 --> 00:12:15,958
colored image. And that's actually a legacy from the

187
00:12:16,044 --> 00:12:20,218
analog television. When companies

188
00:12:20,384 --> 00:12:23,754
television companies face the problem that they need to

189
00:12:23,792 --> 00:12:27,402
support both the black and white television and

190
00:12:27,536 --> 00:12:31,802
the color television, instead of replacing

191
00:12:31,866 --> 00:12:35,182
completely giving the complete breaking change or

192
00:12:35,316 --> 00:12:38,458
putting the new three cables,

193
00:12:38,554 --> 00:12:42,558
they managed to create a new algorithm that allow you to

194
00:12:42,644 --> 00:12:45,918
send to use the same first cable

195
00:12:46,014 --> 00:12:49,282
and two additional one to create the colored image or

196
00:12:49,336 --> 00:12:52,980
still fall back to the black and white if you need to.

197
00:12:53,510 --> 00:12:56,626
Yeah, that's like kind of neat solution, kind of

198
00:12:56,648 --> 00:12:57,890
neat engineering.

199
00:13:00,070 --> 00:13:03,186
I'm sorry, kind of neat engineering solution.

200
00:13:03,298 --> 00:13:06,694
But as a result, right now you need to do something like

201
00:13:06,732 --> 00:13:10,714
this for each frame of your audio. So basically from

202
00:13:10,832 --> 00:13:14,682
pretty any kind of image, when you will render it,

203
00:13:14,736 --> 00:13:18,150
you will need to create a loop

204
00:13:18,230 --> 00:13:27,326
over all the pixels of the image, and you

205
00:13:27,348 --> 00:13:30,686
will need to make a loop over all the pixels of the image. It could

206
00:13:30,708 --> 00:13:34,834
be like for 4k video, it will be the loop over

207
00:13:34,952 --> 00:13:38,258
8 million pixels and convert it using specific

208
00:13:38,344 --> 00:13:40,946
mass. But to be honest,

209
00:13:41,048 --> 00:13:44,674
uv takes less space on a hard drive because

210
00:13:44,712 --> 00:13:48,226
it can contain less information for color planes.

211
00:13:48,418 --> 00:13:51,922
But when you know this, when you know how to convert

212
00:13:51,986 --> 00:13:55,222
the image from the RGB to the

213
00:13:55,356 --> 00:13:58,666
UIV, and then you can send it to encoder and then get a

214
00:13:58,688 --> 00:14:02,634
video, you know that you can create a video. And here

215
00:14:02,672 --> 00:14:05,610
is a problem. You need to render images.

216
00:14:06,190 --> 00:14:09,702
And that's an interesting question, how to render

217
00:14:09,766 --> 00:14:13,120
images. That's a problem because today,

218
00:14:13,730 --> 00:14:17,514
surprisingly, browser is still the most popular

219
00:14:17,562 --> 00:14:21,086
way to render any kind of static content. There are a

220
00:14:21,108 --> 00:14:24,238
lot of developers, a lot of front end engineers

221
00:14:24,334 --> 00:14:28,286
that are producing a lot of content, and they're

222
00:14:28,318 --> 00:14:31,442
using browser literally for everything, even for video

223
00:14:31,496 --> 00:14:35,442
rendering. And that's becoming really ridiculous because

224
00:14:35,496 --> 00:14:39,446
if you will, trying to find the similarity, trying to

225
00:14:39,468 --> 00:14:43,202
find the most common over these two images, you will likely

226
00:14:43,266 --> 00:14:46,566
fail, I suppose. But in fact you can

227
00:14:46,588 --> 00:14:50,234
see that on the left side you can see the streamer that has some

228
00:14:50,272 --> 00:14:53,482
fancy background, some notification appear on the screen

229
00:14:53,536 --> 00:14:56,666
with animations, progress bars, and on the

230
00:14:56,688 --> 00:15:00,598
right side you can see something completely different. You can see the GitHub

231
00:15:00,694 --> 00:15:03,962
preview images for social media graph like

232
00:15:04,016 --> 00:15:07,566
open graph, but in fact appeared that both of

233
00:15:07,588 --> 00:15:11,402
these graphics is rendered on the browser. The Ops,

234
00:15:11,466 --> 00:15:15,474
the open broadcast software is using browser to render all

235
00:15:15,512 --> 00:15:19,410
the animatable content for notification and everything,

236
00:15:19,480 --> 00:15:22,914
and all the plugins are using it. And the GitHub is

237
00:15:23,032 --> 00:15:26,374
also using the headless browser to make this

238
00:15:26,492 --> 00:15:29,880
open source graph previews, which is

239
00:15:31,450 --> 00:15:34,230
really far away from being efficient.

240
00:15:35,050 --> 00:15:38,394
But we are trying like ive been trying to find

241
00:15:38,512 --> 00:15:42,646
a way to make the frames and the image rendering

242
00:15:42,678 --> 00:15:46,060
more efficient. And if we're all thinking about this,

243
00:15:46,830 --> 00:15:51,046
we appear that we need a format that is

244
00:15:51,088 --> 00:15:55,242
dived. It must be like because the image has a fixed

245
00:15:55,386 --> 00:15:59,230
dimensions, it must be fixed, it must be animatable,

246
00:15:59,650 --> 00:16:03,486
easy to animatable, it must be like friendly to DX, it must

247
00:16:03,508 --> 00:16:07,394
be easy to understand, it must support GPU for fast

248
00:16:07,432 --> 00:16:10,782
and efficient rendering, it must have a specification to render

249
00:16:10,846 --> 00:16:14,530
it and to understand by a user. The most important

250
00:16:14,600 --> 00:16:18,598
part, it must be debuggable, which means that nobody wants

251
00:16:18,764 --> 00:16:22,966
open source, nobody wants to cover

252
00:16:23,068 --> 00:16:27,266
or trying to understand the drills of your source

253
00:16:27,298 --> 00:16:30,954
code, debug it. To understand the problem, it must be easy to

254
00:16:30,992 --> 00:16:34,822
figure this out and to write and to render

255
00:16:34,886 --> 00:16:39,034
them. And it appears to be a really hard to

256
00:16:39,072 --> 00:16:42,282
find something like this that covers all of these criteria.

257
00:16:42,426 --> 00:16:45,754
But surprisingly,

258
00:16:45,882 --> 00:16:49,646
there was always, not always actually, but for

259
00:16:49,668 --> 00:16:53,390
a long time there was a format that is perfectly fine,

260
00:16:53,540 --> 00:16:56,898
meets all of these criteria, and is much more

261
00:16:56,984 --> 00:17:00,274
like much better than pretty

262
00:17:00,312 --> 00:17:04,066
much anything else. To render any kind of static content.

263
00:17:04,168 --> 00:17:07,874
It's SVG, it's scalable vector graphics, and it's used everywhere,

264
00:17:08,002 --> 00:17:11,478
especially in a web. To render any kind of like

265
00:17:11,564 --> 00:17:14,754
to render it may be confusing,

266
00:17:14,802 --> 00:17:19,510
it may be like horrific. These puzzles are always horrifying developers,

267
00:17:19,930 --> 00:17:23,734
but in fact SVG is pretty self contained format

268
00:17:23,782 --> 00:17:27,594
and it allows you to render literally everything. Like for

269
00:17:27,632 --> 00:17:31,146
example here you can see that we

270
00:17:31,168 --> 00:17:35,210
are rendering the SVG using the macro of the rust.

271
00:17:35,290 --> 00:17:38,846
This is a public API of my framework. We are coming more

272
00:17:38,868 --> 00:17:42,874
and more to the actual demo of my framework.

273
00:17:43,002 --> 00:17:46,830
And actually you define the SVG file. You define a rectangle

274
00:17:46,910 --> 00:17:50,066
that will be a background because it have the self width and

275
00:17:50,088 --> 00:17:53,550
self hate. Then you define a simple animation.

276
00:17:53,630 --> 00:17:58,006
Here you can see that from zero to

277
00:17:58,108 --> 00:18:01,910
the five second, you will translate from white

278
00:18:01,980 --> 00:18:05,810
to some other color. And then step by step have another colors.

279
00:18:05,890 --> 00:18:09,514
Then you have a text with specific form family on a specific

280
00:18:09,632 --> 00:18:13,478
coordinate, and have you another text. And it, ta da

281
00:18:13,494 --> 00:18:16,586
da da, appears to render something like this.

282
00:18:16,768 --> 00:18:20,478
Things is the editor of Frames. And yeah,

283
00:18:20,564 --> 00:18:23,914
welcome to my framework. That's mostly

284
00:18:23,962 --> 00:18:27,150
the first public demo of my framework I'm working

285
00:18:27,220 --> 00:18:30,366
on, but that's how it works. It renders the

286
00:18:30,388 --> 00:18:34,002
SVG, it renders timeline, and bonus, it actually

287
00:18:34,056 --> 00:18:37,330
renders an SVG. So it's super debuggable,

288
00:18:37,830 --> 00:18:41,794
super easy to preview, easy to

289
00:18:41,832 --> 00:18:45,226
construct, and easy to understand format.

290
00:18:45,278 --> 00:18:48,722
And what is even more important, that is specificated

291
00:18:48,786 --> 00:18:52,594
and pretty widely popular because like in figma, you can literally

292
00:18:52,642 --> 00:18:56,150
construct your frame, then run like right click

293
00:18:56,220 --> 00:18:59,914
on a frame, copy it as SVG, pass directly to

294
00:18:59,952 --> 00:19:03,354
your rust macros, then use any kind

295
00:19:03,392 --> 00:19:07,046
of rust expression inside of the frame definition

296
00:19:07,158 --> 00:19:09,740
and you will get the preview of the video.

297
00:19:10,110 --> 00:19:13,502
That is like the really important part of making

298
00:19:13,556 --> 00:19:17,290
videos. You must make the progress

299
00:19:17,370 --> 00:19:21,242
of making videos really fun and really smooth.

300
00:19:21,386 --> 00:19:23,938
And with rust it's really possible,

301
00:19:24,104 --> 00:19:27,586
because how are we dealing with

302
00:19:27,608 --> 00:19:31,266
it? We have the video definition, you seen this

303
00:19:31,368 --> 00:19:34,766
with an SVG definition that is internally

304
00:19:34,878 --> 00:19:38,410
transformed to the ast sends to the Wassen bridge,

305
00:19:38,510 --> 00:19:42,040
which sends the correct frame to the editor app.

306
00:19:42,810 --> 00:19:46,290
The frame definition can use some APIs

307
00:19:46,370 --> 00:19:49,706
from the code of frames. By the way, it's the name of

308
00:19:49,728 --> 00:19:53,670
my framework, like animation, like subtitles

309
00:19:53,750 --> 00:19:57,334
and so on and so forth. And we create the editor

310
00:19:57,382 --> 00:20:01,182
app, which gets the SVG and shows in the correct time.

311
00:20:01,236 --> 00:20:04,906
It's pretty simple. And we have also the renderer leap

312
00:20:04,938 --> 00:20:08,874
that takes the same video definition and creates the images

313
00:20:08,922 --> 00:20:12,942
from SVG, sends them to the encoder, and then gives

314
00:20:12,996 --> 00:20:16,606
you the real world file. And like creating the WaSm

315
00:20:16,638 --> 00:20:20,462
bridge in Rust is really simple. You just define a macro

316
00:20:20,606 --> 00:20:24,446
and you have the completely working WaSm

317
00:20:24,478 --> 00:20:27,862
based editor that consumes the video in like 60

318
00:20:27,916 --> 00:20:31,494
FPS for easy. But right now you

319
00:20:31,532 --> 00:20:35,154
need to also render your svgs,

320
00:20:35,282 --> 00:20:38,826
which may not be really easy task to

321
00:20:38,848 --> 00:20:42,554
do at a first glance when you just try

322
00:20:42,592 --> 00:20:46,230
to figure this out. Because SVG,

323
00:20:46,390 --> 00:20:50,070
despite being pretty popular, it's still web based

324
00:20:50,160 --> 00:20:53,278
specification and it's really hard to render it.

325
00:20:53,444 --> 00:20:57,406
But thanks to the perfect rust and the awesome

326
00:20:57,508 --> 00:21:00,894
rust community. When I just started the project,

327
00:21:01,012 --> 00:21:04,686
there already was a library for SVG rendering.

328
00:21:04,798 --> 00:21:09,538
It was created by Rosario Falcon and it has like 1500

329
00:21:09,624 --> 00:21:13,474
tasks that covers pretty

330
00:21:13,512 --> 00:21:17,014
much all the use cases of SVG specification and makes it

331
00:21:17,052 --> 00:21:20,406
even more precise of rendering SVG than

332
00:21:20,428 --> 00:21:24,002
the chrome browser. That's impressive

333
00:21:24,066 --> 00:21:28,002
actually. And as a first glance,

334
00:21:28,146 --> 00:21:31,926
I just completely depend on this library to render images.

335
00:21:32,038 --> 00:21:35,514
Right now I have my own fork of the library to make

336
00:21:35,552 --> 00:21:39,654
it more efficient for sequential rendering to not rerender

337
00:21:39,782 --> 00:21:43,674
some part of the svgs when they are not changed to more efficiently

338
00:21:43,722 --> 00:21:47,486
process the reusability between the frames. But in

339
00:21:47,508 --> 00:21:51,166
fact you

340
00:21:51,188 --> 00:21:54,558
still can render SVG in rust directly

341
00:21:54,654 --> 00:21:56,500
without any kind of problems.

342
00:21:57,830 --> 00:22:01,054
But the problem, it's rendering on cpu,

343
00:22:01,182 --> 00:22:04,910
which means that cpu is pretty much

344
00:22:05,000 --> 00:22:08,534
bad idea for rendering pretty much

345
00:22:08,572 --> 00:22:11,846
anything. But from the

346
00:22:11,868 --> 00:22:15,014
flip side, when we're talking about automate tool

347
00:22:15,132 --> 00:22:18,662
that make you a programming that actually automates

348
00:22:18,726 --> 00:22:22,282
video rendering by giving some input, you get

349
00:22:22,336 --> 00:22:26,202
an output of the video file. It appeared to be like the best

350
00:22:26,256 --> 00:22:29,926
case because nobody will actually create the infrastructure

351
00:22:29,958 --> 00:22:33,422
with GPU, which is pretty expensive just for

352
00:22:33,476 --> 00:22:37,066
some kind of one feature. Like if you have the professional

353
00:22:37,098 --> 00:22:40,574
software, it's another call. But right now it's still

354
00:22:40,612 --> 00:22:44,686
pretty efficient though. If we are focusing on the rendering

355
00:22:44,798 --> 00:22:48,114
and we are doing a clever simplification of

356
00:22:48,152 --> 00:22:51,506
SVG, we're doing this ahead of time. Because you

357
00:22:51,528 --> 00:22:55,154
don't need to support all the effects of SVG, you just

358
00:22:55,192 --> 00:22:59,202
need to have the poses with a specific color scheme.

359
00:22:59,346 --> 00:23:02,822
And for the video that I show you a couple of

360
00:23:02,876 --> 00:23:06,822
slides ago, the hello world video, you probably remember it.

361
00:23:06,956 --> 00:23:10,154
It did like pretty great job. You can see it's not like

362
00:23:10,192 --> 00:23:13,674
speed it up. It's a real world performance of

363
00:23:13,712 --> 00:23:17,946
rendering pure cpu of 9900

364
00:23:18,048 --> 00:23:23,420
frames, full hd of videos with

365
00:23:24,030 --> 00:23:27,786
completely on cpu. Thanks to the rayon

366
00:23:27,978 --> 00:23:31,882
and Ross like parallelization and compile

367
00:23:31,946 --> 00:23:34,050
time optimizations,

368
00:23:36,630 --> 00:23:43,394
when you're avoiding all the copying from the processor and

369
00:23:43,432 --> 00:23:47,062
your rendering is paralyzed across all

370
00:23:47,116 --> 00:23:51,474
the cores like I shown here. So basically, the idea of CPU

371
00:23:51,522 --> 00:23:55,558
based rendering is that each of your cpu renders specific

372
00:23:55,644 --> 00:24:02,742
file, because as you remember, video cannot

373
00:24:02,806 --> 00:24:06,582
be filled with the frames like unordered frames.

374
00:24:06,726 --> 00:24:10,358
And then we prepare the video in that case

375
00:24:10,544 --> 00:24:13,946
to be easy concatenatable

376
00:24:14,058 --> 00:24:17,518
and then just concatenate it in the end. And then we have

377
00:24:17,684 --> 00:24:20,954
the pretty much performant way of rendering

378
00:24:21,002 --> 00:24:24,994
pretty much anything except the things

379
00:24:25,192 --> 00:24:29,074
that breaks performance really hard, like the

380
00:24:29,112 --> 00:24:32,514
shadows, the gradients and the blue are the killers of

381
00:24:32,552 --> 00:24:36,166
CPU. Just because the nature of CPU that you

382
00:24:36,188 --> 00:24:40,214
need to process each pixel, calculate the position one by one.

383
00:24:40,412 --> 00:24:43,590
Things that require going

384
00:24:43,660 --> 00:24:47,922
like several times or smoothing a big amount of gradients,

385
00:24:47,986 --> 00:24:51,338
smooth a giant amount of pixels to calculate the specific

386
00:24:51,424 --> 00:24:55,114
precision per each pixel kills the performance completely.

387
00:24:55,312 --> 00:24:59,974
And here is the

388
00:25:00,032 --> 00:25:05,262
most amazing part of this project is a completely from

389
00:25:05,316 --> 00:25:08,574
scratch created GPU renderer. It's still

390
00:25:08,692 --> 00:25:11,920
not 100% working, it's still

391
00:25:12,470 --> 00:25:16,174
not 100% compatible with SVG

392
00:25:16,222 --> 00:25:19,620
stack, but it's amazingly fast.

393
00:25:22,150 --> 00:25:26,258
But our cpu render is still very fast though you

394
00:25:26,264 --> 00:25:29,874
can see we will compare the pps, the frames

395
00:25:29,922 --> 00:25:33,746
per second, render it without the encoding over CPU

396
00:25:33,778 --> 00:25:37,426
and GPU. You will notice that hello world video due to the

397
00:25:37,468 --> 00:25:40,746
fact it's pretty simple. It renders only text and only color,

398
00:25:40,848 --> 00:25:44,458
but still looks pretty nice. It renders really fast

399
00:25:44,544 --> 00:25:48,860
because of parallelization, because GPU has only like one,

400
00:25:50,590 --> 00:25:54,666
it's less parallelizable across the different frames. And when you parallelize

401
00:25:54,698 --> 00:25:58,254
it over the images, it becomes slightly faster. But when

402
00:25:58,292 --> 00:26:01,370
we increase in the amount of the resolution,

403
00:26:01,530 --> 00:26:04,370
you are getting pretty much same results.

404
00:26:05,030 --> 00:26:08,594
And for the blurs and gradients, when you

405
00:26:08,632 --> 00:26:13,054
have some kind of gradient, full size full page gradient

406
00:26:13,182 --> 00:26:17,190
that is then blurred, it requires six times going

407
00:26:17,260 --> 00:26:20,614
through all the pixels for pretty much

408
00:26:20,652 --> 00:26:24,326
all the background, it becomes like much faster. How it

409
00:26:24,348 --> 00:26:27,000
works pretty interesting question,

410
00:26:27,450 --> 00:26:31,302
because the fact that we are simplification the SVG to

411
00:26:31,356 --> 00:26:34,730
the paths only we can do the tessellation.

412
00:26:35,790 --> 00:26:40,220
That is like the algorithm of parsing the

413
00:26:41,390 --> 00:26:45,050
positives, parsing the dots and the vectors

414
00:26:45,130 --> 00:26:47,802
into the vertices and indices,

415
00:26:47,946 --> 00:26:52,014
and give it directly to GPU and get the result,

416
00:26:52,132 --> 00:26:56,930
the rendering result directly right

417
00:26:57,000 --> 00:27:00,914
from GPU, which is much faster in terms of

418
00:27:01,112 --> 00:27:02,930
effects and shade ring.

419
00:27:04,390 --> 00:27:08,646
And we have not so much time left. I don't know how

420
00:27:08,748 --> 00:27:12,470
I appeared in things situation that I didn't have enough time. But we also

421
00:27:12,540 --> 00:27:16,054
need to have a video, the audio inside the video.

422
00:27:16,252 --> 00:27:20,714
And because the fact that we can work pretty flexible with

423
00:27:20,912 --> 00:27:24,426
images, we can do exactly same with audio. Like we can

424
00:27:24,448 --> 00:27:28,410
even generate the audio with a mass. Because we know that

425
00:27:28,560 --> 00:27:32,826
audio have a sinusoid and frequency

426
00:27:32,938 --> 00:27:36,814
nature. We can generate some sound right from

427
00:27:36,852 --> 00:27:40,222
the code. But in fact what real user needs is

428
00:27:40,276 --> 00:27:43,802
to have something like this. Nothing more than just remixing

429
00:27:43,866 --> 00:27:47,346
the audio. It's a preview of the images, but in fact you get pretty

430
00:27:47,368 --> 00:27:50,786
much the same result in an audio file. And you

431
00:27:50,808 --> 00:27:53,970
actually need to load the image using the

432
00:27:54,040 --> 00:27:57,974
encoder, the decoder, load the audio and

433
00:27:58,012 --> 00:28:01,942
then mix it. But what is really awesome is that

434
00:28:01,996 --> 00:28:05,446
you can define, yeah, here is how you

435
00:28:05,468 --> 00:28:08,646
can define the audio map with frames,

436
00:28:08,758 --> 00:28:13,190
then it will mix

437
00:28:13,270 --> 00:28:16,794
all the audio and mix it into the one and

438
00:28:16,832 --> 00:28:20,070
put it into the file. But what is more interesting,

439
00:28:20,240 --> 00:28:24,874
that by the fact that we already have the audio

440
00:28:24,922 --> 00:28:28,234
data in memory, we can provide an API for users

441
00:28:28,282 --> 00:28:31,760
to create the audio visualization. And that was actually

442
00:28:33,090 --> 00:28:36,402
how the project started. I had a podcast that time

443
00:28:36,456 --> 00:28:40,718
and I always didn't like podcasts,

444
00:28:40,734 --> 00:28:43,986
because you have always a problem, you don't understand who is talking right now.

445
00:28:44,088 --> 00:28:47,654
But with frames and with really not so

446
00:28:47,692 --> 00:28:51,734
much code, with just API that gets the vector of the

447
00:28:51,772 --> 00:28:55,394
frequencies and then render it in using rectangles,

448
00:28:55,522 --> 00:28:59,050
you can get the pretty much awesome looking

449
00:28:59,120 --> 00:29:02,602
visualization with pretty much any

450
00:29:02,656 --> 00:29:05,850
kind of design and render it like 1 hour

451
00:29:05,920 --> 00:29:09,986
video within 15 minutes with AFO

452
00:29:10,038 --> 00:29:14,270
frames, without any kind of additional

453
00:29:14,850 --> 00:29:19,594
GPU usage, only on CPU, which is pretty impressive.

454
00:29:19,722 --> 00:29:22,962
And I think that we have not a lot of time

455
00:29:23,016 --> 00:29:26,674
anymore, but I can say that what

456
00:29:26,712 --> 00:29:31,140
I learned for one point, ive years of developing the

457
00:29:32,310 --> 00:29:35,960
video creation framework and the videos are really interesting.

458
00:29:36,490 --> 00:29:38,440
And if you think the same,

459
00:29:40,570 --> 00:29:44,642
this is the animation of f of frames. I'm really grateful

460
00:29:44,706 --> 00:29:48,278
to invite you to try, but the effort frames,

461
00:29:48,374 --> 00:29:52,118
because just now it came out to beta testing.

462
00:29:52,214 --> 00:29:55,340
Yeah, right now. Yeah, I know, that's amazing.

463
00:29:55,950 --> 00:29:59,722
And today, starting from today, you can sign up to

464
00:29:59,776 --> 00:30:03,562
our discord and just put your GitHub

465
00:30:03,626 --> 00:30:07,326
name to the beta channel. Like you can sign up

466
00:30:07,348 --> 00:30:10,782
for this cup either from this QR code or go into

467
00:30:10,836 --> 00:30:14,014
frames studio and try out the

468
00:30:14,052 --> 00:30:18,106
internals of this project. Try out to play with CPU GPU

469
00:30:18,138 --> 00:30:21,866
rendering, create pretty much any kind of video and automate

470
00:30:21,898 --> 00:30:25,702
it whenever you want to. I'm really.

471
00:30:25,756 --> 00:30:28,758
Thank you for watching this talk. Hey,

