1
00:00:00,730 --> 00:00:04,366
What if you could work with some of the world's most innovative companies,

2
00:00:04,548 --> 00:00:08,366
all from the comfort of a remote workplace? Andela has

3
00:00:08,388 --> 00:00:11,994
matched thousands of technologists across the globe to their next career

4
00:00:12,042 --> 00:00:15,818
adventure. We're empowering new talent worldwide,

5
00:00:15,914 --> 00:00:19,802
from Sao Paulo to Egypt and Lagos to Warsaw.

6
00:00:19,946 --> 00:00:23,038
Now the future of work is yours to create.

7
00:00:23,204 --> 00:00:27,030
Anytime, anywhere. The world is at your fingertips.

8
00:00:27,370 --> 00:00:29,190
This is Andela.

9
00:01:13,110 --> 00:01:16,370
Hello everyone. Thanks for having us at this year's

10
00:01:16,450 --> 00:01:18,550
Conf 42 Golang.

11
00:01:19,450 --> 00:01:23,366
You know who Andy and I are from our introductions, but let

12
00:01:23,388 --> 00:01:27,142
us introduce form three as well. Form three

13
00:01:27,196 --> 00:01:31,530
are a payments technology provider who work with some great customers and

14
00:01:31,600 --> 00:01:35,034
partners. As you can see on this slide, we have

15
00:01:35,072 --> 00:01:39,526
a fully go code base and work with some great cloud native technologies.

16
00:01:39,718 --> 00:01:43,278
We currently have around 260

17
00:01:43,364 --> 00:01:47,242
employees, of which about 130 care engineers.

18
00:01:47,386 --> 00:01:51,070
We are a fully remote company and we're hiring.

19
00:01:51,570 --> 00:01:54,990
Today we will be looking into the world of load

20
00:01:55,070 --> 00:01:58,542
testing. I will very quickly cover performance

21
00:01:58,606 --> 00:02:02,322
testing fundamentals and some common tools that we can use

22
00:02:02,376 --> 00:02:06,306
to write our tests. Then Andy will take over and

23
00:02:06,328 --> 00:02:10,262
tell you about our open source testing tool f one and

24
00:02:10,316 --> 00:02:13,206
give you a live demo of how to use it.

25
00:02:13,308 --> 00:02:16,166
Everyone loves a bit of live coding in a good demo,

26
00:02:16,268 --> 00:02:19,798
right? Okay, without any further ado,

27
00:02:19,894 --> 00:02:23,878
let's dive into the world of performance testing.

28
00:02:24,054 --> 00:02:27,286
Performance testing is the general name for tests

29
00:02:27,318 --> 00:02:30,418
that check how the system behaves and performs.

30
00:02:30,534 --> 00:02:33,630
Hence the named performance testing.

31
00:02:33,970 --> 00:02:37,066
Performance testing examines stability,

32
00:02:37,258 --> 00:02:40,922
scalability and reliability of your software

33
00:02:40,986 --> 00:02:44,302
and infrastructure. Before performance

34
00:02:44,366 --> 00:02:48,226
testing, it's important to determine your system's business needs,

35
00:02:48,328 --> 00:02:52,338
so you can tell if your system behaves satisfactorily or not

36
00:02:52,424 --> 00:02:54,500
according to your customer needs.

37
00:02:55,530 --> 00:02:59,798
Often, performance testing can be done on anticipated future

38
00:02:59,884 --> 00:03:02,946
load to see a system's growth Runway,

39
00:03:03,138 --> 00:03:07,078
this is important for a high volume payments platform like

40
00:03:07,164 --> 00:03:11,062
ours. Under the umbrella of performance

41
00:03:11,126 --> 00:03:14,742
existing, we can look at three test subtypes,

42
00:03:14,886 --> 00:03:19,094
load spike and soak tests. Load testing

43
00:03:19,142 --> 00:03:22,894
tells us how many concurrent users or transactions your

44
00:03:22,932 --> 00:03:26,874
system can actually handle. Different load scenarios

45
00:03:26,922 --> 00:03:31,082
require different resources, so it's important to write multiple

46
00:03:31,146 --> 00:03:34,674
tests. Load tests should be performed all

47
00:03:34,712 --> 00:03:38,418
the time in order to ensure that your system is always

48
00:03:38,504 --> 00:03:42,082
on point, which is why it should be integrated into

49
00:03:42,136 --> 00:03:45,010
your continuous integration cycles.

50
00:03:45,770 --> 00:03:49,542
Now, on the other hand, a stress test is a type of

51
00:03:49,596 --> 00:03:53,558
performance test that checks the upper limits of your system

52
00:03:53,644 --> 00:03:56,866
by testing it under extreme loads.

53
00:03:57,058 --> 00:04:00,566
Stress tests also look for memory leaks,

54
00:04:00,678 --> 00:04:05,450
slowdowns, security issues, and even data corruption.

55
00:04:05,870 --> 00:04:09,642
There are two types of stress tests, spike and

56
00:04:09,696 --> 00:04:14,042
soak. If your stress test includes a sudden

57
00:04:14,186 --> 00:04:17,546
high ramp up in the number of virtual users.

58
00:04:17,658 --> 00:04:20,894
It's called a spike test. If your

59
00:04:20,932 --> 00:04:25,042
stress test is over a long period of time to

60
00:04:25,096 --> 00:04:28,626
check the system's sustainability over time, but with

61
00:04:28,648 --> 00:04:32,386
a slow ramp up that is called a soak test.

62
00:04:32,568 --> 00:04:36,050
You should run stress tests before major events

63
00:04:36,130 --> 00:04:40,550
like, for example, Black Friday. If you're a commercial retailer.

64
00:04:41,610 --> 00:04:45,474
Before you run your tests, it's important to have monitoring

65
00:04:45,522 --> 00:04:49,754
in place and agree what your failure threshold should be.

66
00:04:49,952 --> 00:04:53,686
You can see some common things to monitor on this slide,

67
00:04:53,798 --> 00:04:57,782
such as average response time, error rate, or cpu

68
00:04:57,846 --> 00:05:02,414
usage, which are important indicators that can

69
00:05:02,452 --> 00:05:06,382
show you whether your system is healthy. These important

70
00:05:06,516 --> 00:05:10,350
metrics should therefore be monitored and alerted on before

71
00:05:10,420 --> 00:05:13,874
you write your tests at

72
00:05:13,912 --> 00:05:17,422
form three a lot of our systems use asynchronous

73
00:05:17,486 --> 00:05:21,314
processing and queues. Today we'll be

74
00:05:21,352 --> 00:05:23,940
looking at this simple example application.

75
00:05:24,630 --> 00:05:28,870
We create a service which exposes a single endpoint

76
00:05:29,370 --> 00:05:32,530
payments. This service receives

77
00:05:32,610 --> 00:05:35,622
requests, does background processing on them,

78
00:05:35,676 --> 00:05:38,886
and then outputs a message to an SQS queue

79
00:05:38,998 --> 00:05:41,260
once processing is complete.

80
00:05:42,590 --> 00:05:47,062
Now we need a way of connecting requests to their corresponding

81
00:05:47,126 --> 00:05:51,086
result from the SQS queue. If we rely on the

82
00:05:51,108 --> 00:05:54,814
response, the 202 accepted response, which you can

83
00:05:54,852 --> 00:05:58,490
see on this slide, will make it seem like the request

84
00:05:58,570 --> 00:06:02,122
completes immediately when actually background

85
00:06:02,186 --> 00:06:05,458
processing is still happening. F one

86
00:06:05,544 --> 00:06:09,106
is the open source solution we will be talking about today,

87
00:06:09,208 --> 00:06:12,020
which can help you do just that.

88
00:06:13,270 --> 00:06:17,874
So now that we have established the basics of performance testing,

89
00:06:18,002 --> 00:06:22,120
let's have a look at two common tools that we can use.

90
00:06:23,370 --> 00:06:27,470
The first tool we'll be talking about is jmeter,

91
00:06:27,650 --> 00:06:31,178
and it is an open source Java testing tool

92
00:06:31,264 --> 00:06:34,714
that is widely used. It allows us to

93
00:06:34,752 --> 00:06:39,270
configure tests using a recording GUI and some predefined

94
00:06:39,350 --> 00:06:43,214
templates. For asynchronous testing support,

95
00:06:43,332 --> 00:06:47,102
we can use long polling or another request to check

96
00:06:47,156 --> 00:06:50,910
whether an operation has completed. We can then

97
00:06:50,980 --> 00:06:54,434
configure a number of threads and a ramp up period in

98
00:06:54,472 --> 00:06:58,770
seconds for load specification. Jmeter also

99
00:06:58,840 --> 00:07:02,094
offers a plugin for step and spike ramp

100
00:07:02,142 --> 00:07:06,070
up, even though it is not supported natively

101
00:07:06,490 --> 00:07:10,246
in jmeter. Next up,

102
00:07:10,348 --> 00:07:14,230
another common tool used for performance testing is

103
00:07:14,300 --> 00:07:17,778
k six. It is an open source

104
00:07:17,874 --> 00:07:21,482
go project run by Grafana tests care

105
00:07:21,536 --> 00:07:25,862
configured using a scripting language similar to JavaScript.

106
00:07:26,006 --> 00:07:29,794
K six does not provide support for promises

107
00:07:29,942 --> 00:07:33,422
or asynchronous execution, but we can

108
00:07:33,476 --> 00:07:37,370
achieve asynchronous testing support using virtual

109
00:07:37,450 --> 00:07:40,734
users. We can then configure the

110
00:07:40,772 --> 00:07:44,354
load for the test using an options object

111
00:07:44,552 --> 00:07:48,654
which states how many requests to run for each stage

112
00:07:48,702 --> 00:07:52,306
of the test and how long each stage of the test

113
00:07:52,408 --> 00:07:56,050
is. This allows us to configure linear

114
00:07:56,130 --> 00:07:59,750
and step ramp up. Now at form

115
00:07:59,820 --> 00:08:02,934
three, we invest a lot of engineering time

116
00:08:02,972 --> 00:08:06,550
into performance testing our platform. As we have

117
00:08:06,620 --> 00:08:10,300
already seen, it is a very important test

118
00:08:11,390 --> 00:08:14,938
that should be run on your platform all the time.

119
00:08:15,104 --> 00:08:18,922
We initially used K Six to develop and run these

120
00:08:18,976 --> 00:08:23,066
tests, but it did not fully fit our ideal load

121
00:08:23,098 --> 00:08:26,542
existing tool, which you can see described on

122
00:08:26,596 --> 00:08:30,014
this slide. Our ideal tool should

123
00:08:30,052 --> 00:08:33,762
allow us to easily write asynchronous tests which

124
00:08:33,816 --> 00:08:37,762
integrate with our queues and services. This was not

125
00:08:37,816 --> 00:08:40,446
always easy to do in JavaScript,

126
00:08:40,638 --> 00:08:44,366
especially because our platform is fully written

127
00:08:44,398 --> 00:08:48,054
in Go. It should also allow our engineers to

128
00:08:48,092 --> 00:08:51,990
write tests in Go, which is what they're most comfortable in

129
00:08:52,060 --> 00:08:55,926
anyways. And it should also integrate well with

130
00:08:55,948 --> 00:08:59,562
our CI pipelines as we want to perform and test

131
00:08:59,616 --> 00:09:02,934
our platform. Often, writing in our tests

132
00:09:02,982 --> 00:09:06,902
in Go would be a huge game changer for our engineers,

133
00:09:07,046 --> 00:09:10,974
as it would allow us to make use of go routines and channels for

134
00:09:11,012 --> 00:09:14,494
test configuration, and these are really

135
00:09:14,612 --> 00:09:18,174
important components in the care language that we would like to

136
00:09:18,212 --> 00:09:21,294
leverage. Finally, as our

137
00:09:21,332 --> 00:09:25,314
platform operates under huge amounts of load, the tool should

138
00:09:25,352 --> 00:09:29,298
allow us to run different modes of load as well, not just

139
00:09:29,384 --> 00:09:33,362
linear or step ramp up. Andy will

140
00:09:33,416 --> 00:09:36,934
tell you more about the different modes of load that we need

141
00:09:37,052 --> 00:09:40,242
later. And as you can see, the existing

142
00:09:40,306 --> 00:09:43,910
solutions did not provide us any of these features.

143
00:09:44,250 --> 00:09:48,158
So this is why we decided to write our own solution

144
00:09:48,274 --> 00:09:51,740
and then open source it for the community to use.

145
00:09:52,190 --> 00:09:55,434
I'll now hand over to Andy who will tell you all

146
00:09:55,472 --> 00:09:58,250
about f one. Take it away,

147
00:09:58,320 --> 00:10:02,894
Andy. Okay, so I'm going to take you through what

148
00:10:02,932 --> 00:10:06,974
f one is and why we decided to write it.

149
00:10:07,012 --> 00:10:11,054
So what is f one? Well, f one is our own

150
00:10:11,252 --> 00:10:13,460
internal load testing tool.

151
00:10:14,710 --> 00:10:18,254
We wrote it initially to support our own use cases,

152
00:10:18,382 --> 00:10:21,602
but then we realized actually it was a pretty general purpose tool,

153
00:10:21,656 --> 00:10:24,020
so we decided to open source it.

154
00:10:25,690 --> 00:10:29,874
And it's written in Go. So it natively supports

155
00:10:29,922 --> 00:10:33,334
writing test scenarios in go. And that means

156
00:10:33,372 --> 00:10:37,426
that you can use all of the sort of concurrent and asynchronous primitives

157
00:10:37,458 --> 00:10:40,638
that go offers when writing your test scenarios.

158
00:10:40,674 --> 00:10:44,330
So existing these kind of asynchronous systems

159
00:10:44,910 --> 00:10:48,474
is pretty straightforward in Go, much more

160
00:10:48,512 --> 00:10:52,570
straightforward than it was, for example, using JavaScript based tests

161
00:10:52,730 --> 00:10:56,462
in k six. One of the other things f one

162
00:10:56,516 --> 00:10:59,742
supports is a variety of different modes for

163
00:10:59,796 --> 00:11:03,214
injecting load. One of the problems we had with k

164
00:11:03,252 --> 00:11:07,006
six was that it basically only supports

165
00:11:07,038 --> 00:11:10,846
a single mode of operation, which is using a cool of virtual users

166
00:11:10,878 --> 00:11:14,434
to apply load that wasn't aggressive enough

167
00:11:14,472 --> 00:11:17,346
for some of our use cases. So for some of our use cases, we really

168
00:11:17,368 --> 00:11:20,530
needed to be able to apply load more aggressively.

169
00:11:20,690 --> 00:11:24,594
And so when we wrote f one, we built that in from the beginning.

170
00:11:24,642 --> 00:11:27,686
So f one supports this idea of using a cool

171
00:11:27,718 --> 00:11:31,402
of virtual users, but it does also support a variety of other

172
00:11:31,536 --> 00:11:35,514
modes of injecting load, which makes it much more suitable to

173
00:11:35,552 --> 00:11:39,786
our use cases. So what

174
00:11:39,808 --> 00:11:42,942
I'm going to do now is basically take you through a demo for 15

175
00:11:42,996 --> 00:11:46,174
minutes or so. We're going to set up a

176
00:11:46,292 --> 00:11:50,350
system to test that looks sort of similar to this asynchronous

177
00:11:50,850 --> 00:11:54,018
system that Adelina mentioned earlier. And then we're

178
00:11:54,024 --> 00:11:58,206
going to write a simple load test that's

179
00:11:58,238 --> 00:12:00,820
going to sort of exercise that system.

180
00:12:02,310 --> 00:12:06,062
So I'm just starting with sort of a blank

181
00:12:06,126 --> 00:12:09,110
folder here, and we're going to start from the beginning.

182
00:12:09,690 --> 00:12:13,330
So first of all, I'm going to set up an environment

183
00:12:13,410 --> 00:12:17,030
that we're going to use to run load against using docker compose.

184
00:12:18,650 --> 00:12:22,186
So what I've done here is created a Docker compose file with

185
00:12:22,208 --> 00:12:26,330
two containers. In the first container go AWS

186
00:12:26,830 --> 00:12:30,086
is a local SQs mock. So it's a mock of the

187
00:12:30,128 --> 00:12:33,662
AWS SQS service, and we're going to use

188
00:12:33,716 --> 00:12:38,414
that sort of to mock out an

189
00:12:38,452 --> 00:12:42,186
AWS based message queue. And this docker

190
00:12:42,218 --> 00:12:45,570
compose file also contains a dummy service

191
00:12:45,640 --> 00:12:49,314
which we're going to write in a minute. And you might notice here that go

192
00:12:49,352 --> 00:12:53,282
AWS requires some configuration. So let's create

193
00:12:53,336 --> 00:12:56,834
one of those config files. So this config

194
00:12:56,882 --> 00:13:00,278
file basically just contains a single queue that we're going

195
00:13:00,284 --> 00:13:02,470
to use called test queue.

196
00:13:04,090 --> 00:13:09,100
Let's also create a docker file for our service. So our

197
00:13:09,790 --> 00:13:13,206
docker compose file is using a local docker

198
00:13:13,238 --> 00:13:17,866
file. So here's a

199
00:13:17,888 --> 00:13:22,240
Docker file. So what we're going to do is just build an app

200
00:13:23,410 --> 00:13:27,150
that's in this command service main go file.

201
00:13:29,090 --> 00:13:32,638
So let's dub out that service. What I'm

202
00:13:32,654 --> 00:13:36,066
going to do here is I'm going to make a

203
00:13:36,088 --> 00:13:39,490
new directory command service, put in a file,

204
00:13:40,630 --> 00:13:44,722
a minimal file, and initialize a go

205
00:13:44,776 --> 00:13:47,858
module. So now I've got a go mod file,

206
00:13:47,954 --> 00:13:52,006
and if I have a look in this directory, I've got

207
00:13:52,028 --> 00:13:56,118
an empty main function. So what

208
00:13:56,124 --> 00:14:00,620
we're going to do now is we're going to implement a sort of simple application

209
00:14:01,550 --> 00:14:05,446
in that file that we're going to use when we're writing our load tests.

210
00:14:05,478 --> 00:14:07,260
We're going to inject load against that.

211
00:14:08,030 --> 00:14:11,630
So let's edit that file.

212
00:14:13,170 --> 00:14:15,214
Okay, so first of all,

213
00:14:15,412 --> 00:14:18,320
let's delete this empty function,

214
00:14:20,690 --> 00:14:26,066
and what we'll do is we'll put in a

215
00:14:26,088 --> 00:14:29,598
main function which listens

216
00:14:29,614 --> 00:14:33,330
for HTTP requests on this relative URL payments

217
00:14:33,910 --> 00:14:37,320
and an HTTP handler for that. That's just going to return

218
00:14:38,090 --> 00:14:42,514
an accepted status code. So there's

219
00:14:42,562 --> 00:14:46,086
a sort of simple application. Now what we want

220
00:14:46,108 --> 00:14:49,882
to do is we want to publish SQS messages when

221
00:14:50,016 --> 00:14:53,686
our web requests are made. And that's going to simulate this sort of asynchronous

222
00:14:53,718 --> 00:14:57,386
feedback where we're injecting load synchronously via HTTP and

223
00:14:57,408 --> 00:15:00,690
then asynchronously consuming feedback via SQS.

224
00:15:00,870 --> 00:15:04,922
So let's set up some global variables

225
00:15:05,066 --> 00:15:08,874
to store an SQS

226
00:15:08,922 --> 00:15:13,214
client, and then let's initialize that SQS

227
00:15:13,262 --> 00:15:16,260
client at the start of our main function.

228
00:15:20,310 --> 00:15:24,878
Okay, so what are we doing here? We are setting up

229
00:15:25,064 --> 00:15:29,138
an AWS client to use go AWS.

230
00:15:29,234 --> 00:15:33,110
So our local sqs mock using some dummy credentials,

231
00:15:34,090 --> 00:15:37,706
creating a new SQS client and getting the key URL of

232
00:15:37,728 --> 00:15:38,890
our test queue.

233
00:15:42,510 --> 00:15:47,814
Okay, I just need to replace

234
00:15:47,862 --> 00:15:49,530
one of these imports.

235
00:15:53,710 --> 00:15:57,526
Let's pick

236
00:15:57,568 --> 00:15:58,990
up the wrong imports.

237
00:16:02,690 --> 00:16:03,440
Okay,

238
00:16:12,930 --> 00:16:16,246
got some. Got there. Okay. Right, so there

239
00:16:16,268 --> 00:16:20,434
we go. We've got an application set up there with an SQS

240
00:16:20,482 --> 00:16:23,878
client. Okay, so what do we want

241
00:16:23,884 --> 00:16:28,054
to do next? Right, well let's go to the HTTP

242
00:16:28,102 --> 00:16:32,026
handler. Rather than just returning an

243
00:16:32,048 --> 00:16:36,106
accepted status code, let's add some functionality to

244
00:16:36,128 --> 00:16:39,850
that handler. Let's just delete this entirely.

245
00:16:43,470 --> 00:16:46,846
Okay, so what are we doing here? So we're saying, okay, we only

246
00:16:46,868 --> 00:16:50,478
want to handle post requests. If we don't get a post request, we're going

247
00:16:50,484 --> 00:16:54,574
to return a 405. Then we're going to construct

248
00:16:54,622 --> 00:16:57,778
an SQS message and send it to

249
00:16:57,784 --> 00:17:01,246
that queue. So that's our sort of asynchronous feedback. And this demonstrates

250
00:17:01,278 --> 00:17:03,970
our system doing some work asynchronously.

251
00:17:09,830 --> 00:17:13,078
Oh yeah, and let's, I shouldn't have deleted that.

252
00:17:13,244 --> 00:17:18,614
Let's leave the status

253
00:17:18,662 --> 00:17:25,578
accepted on the end it.

254
00:17:25,664 --> 00:17:30,086
Okay, so with any luck that

255
00:17:30,128 --> 00:17:30,880
will run.

256
00:17:37,250 --> 00:17:40,282
So let's just download the dependencies

257
00:17:40,426 --> 00:17:41,520
for that app,

258
00:17:44,870 --> 00:17:48,414
and then we should be able to run it using docker compose

259
00:17:48,462 --> 00:17:52,506
app. Just wait

260
00:17:52,528 --> 00:17:54,410
for these dependencies to download.

261
00:17:56,510 --> 00:17:58,990
Now, when we run it locally,

262
00:17:59,570 --> 00:18:03,710
we should be able to make web requests to that endpoint

263
00:18:05,010 --> 00:18:08,366
and get a 202 back. And we should also be able

264
00:18:08,388 --> 00:18:11,220
to see SQS messages being published as a result.

265
00:18:11,590 --> 00:18:14,978
So let's see if we

266
00:18:14,984 --> 00:18:16,260
can run that app.

267
00:18:21,030 --> 00:18:24,530
Okay, so if I have a look at what's running in Docker.

268
00:18:24,610 --> 00:18:30,294
Sorry, I'll just kill

269
00:18:30,332 --> 00:18:34,538
all my running containers and

270
00:18:34,624 --> 00:18:35,820
then start again.

271
00:18:38,190 --> 00:18:41,834
Okay, so what have I got running here? Okay, so I've got go

272
00:18:41,872 --> 00:18:45,980
AWS running, that's my sqs mock and I've got my test service.

273
00:18:46,450 --> 00:18:49,230
So if I try making a web request,

274
00:18:50,450 --> 00:18:54,670
great, I get a 202 so I can make some web requests.

275
00:18:55,970 --> 00:18:59,534
And then if I just configure the AWS

276
00:18:59,582 --> 00:19:02,786
cli locally, oh yeah,

277
00:19:02,808 --> 00:19:04,180
that's all set up.

278
00:19:06,390 --> 00:19:09,890
So I should be able to list my queues.

279
00:19:11,450 --> 00:19:14,838
There's my test queue and if I

280
00:19:14,844 --> 00:19:18,806
get the queue attributes I

281
00:19:18,828 --> 00:19:22,454
got three messages there. So if I make

282
00:19:22,492 --> 00:19:23,830
another web request,

283
00:19:26,090 --> 00:19:29,990
I've got four messages there. So sending my web request is publishing

284
00:19:30,150 --> 00:19:34,140
sqs messages that demonstrates our app.

285
00:19:35,470 --> 00:19:38,686
Okay, so now let's write a load test. So what I'm going to do

286
00:19:38,708 --> 00:19:41,840
is write another command line entry point.

287
00:19:42,450 --> 00:19:46,478
So I've now got this command f one main

288
00:19:46,564 --> 00:19:51,166
go. So let's

289
00:19:51,198 --> 00:19:54,946
edit that. First thing

290
00:19:54,968 --> 00:19:58,274
we're going to do is add an import for

291
00:19:58,312 --> 00:20:00,910
f one. So we'll just import this,

292
00:20:01,080 --> 00:20:04,594
oops, this package go imports getting carried

293
00:20:04,642 --> 00:20:08,342
away. And in order to use

294
00:20:08,396 --> 00:20:12,374
f one, all I need to do in an application

295
00:20:12,492 --> 00:20:15,754
entry point is new up

296
00:20:15,792 --> 00:20:19,366
this f one type and call execute.

297
00:20:19,558 --> 00:20:23,382
And this will give me a fully fledged f one command line interface.

298
00:20:23,446 --> 00:20:28,186
So if I download that dependency and

299
00:20:28,208 --> 00:20:31,534
then run that application, I will get a command line interface pre

300
00:20:31,572 --> 00:20:34,798
configured with all of the bells and whistles that f one

301
00:20:34,964 --> 00:20:38,346
comes with. So this is how you use f one. It's not like a separate

302
00:20:38,378 --> 00:20:41,730
binary that you download and add load tests to or something.

303
00:20:41,880 --> 00:20:45,554
You just use this package directly and build your own binary. So if I

304
00:20:45,592 --> 00:20:50,020
run this entry point,

305
00:20:51,030 --> 00:20:54,734
just put help on the end, we'll compile

306
00:20:54,782 --> 00:20:57,958
the app and then we should get some help out. Here we

307
00:20:57,964 --> 00:21:01,154
go. So this is the f one command line interface

308
00:21:01,202 --> 00:21:04,940
that I've got just from importing that package basically.

309
00:21:05,950 --> 00:21:09,018
Okay, so let's go back to our file. What we

310
00:21:09,024 --> 00:21:12,102
need to do now is we need to start registering

311
00:21:12,166 --> 00:21:18,486
new test scenarios. So I

312
00:21:18,608 --> 00:21:21,230
didn't add that correctly. Here we go. Let's,

313
00:21:26,050 --> 00:21:29,726
so this allows me to register a new, a new test scenario

314
00:21:29,838 --> 00:21:33,502
and that test scenario will be available from our command line interface.

315
00:21:33,566 --> 00:21:37,620
So let's just add a sort of dummy implementation here.

316
00:21:39,750 --> 00:21:42,280
So what does this dummy implementation do?

317
00:21:44,090 --> 00:21:47,606
So basically this function runs some code and

318
00:21:47,628 --> 00:21:51,334
then returns a run function. And this code

319
00:21:51,372 --> 00:21:54,486
that it runs at the beginning is where you would put any setup code that

320
00:21:54,508 --> 00:21:58,106
you need to run one time at the beginning of your test scenario. And then

321
00:21:58,128 --> 00:22:02,202
this function that you return is executed every

322
00:22:02,256 --> 00:22:05,738
time you run a test iteration in your load test.

323
00:22:05,824 --> 00:22:08,974
So if you're running 100 iterations a second,

324
00:22:09,092 --> 00:22:12,480
this run function gets executed 100 times per second.

325
00:22:13,570 --> 00:22:17,002
And this testing t has a sort of similar API

326
00:22:17,066 --> 00:22:20,930
to the go testing t, but you'll notice it's actually an f one

327
00:22:21,000 --> 00:22:21,620
type.

328
00:22:24,470 --> 00:22:28,850
Okay, and now if I go

329
00:22:28,920 --> 00:22:32,098
run, add another command on the end,

330
00:22:32,184 --> 00:22:35,250
hopefully we should see that our test scenario has been registered.

331
00:22:35,330 --> 00:22:38,806
Great. So this is now a test scenario that we can execute from

332
00:22:38,828 --> 00:22:42,934
the command line. Okay, so let's do

333
00:22:42,972 --> 00:22:46,726
something similar to our HTTP handler.

334
00:22:46,838 --> 00:22:50,134
Let's configure an SQS

335
00:22:50,182 --> 00:22:53,050
client here. Oops.

336
00:22:59,650 --> 00:23:05,854
Okay, so what we're doing here is

337
00:23:05,892 --> 00:23:09,474
we're configuring an SQS client to again use go

338
00:23:09,512 --> 00:23:12,930
AWS locally with some dummy credentials,

339
00:23:13,350 --> 00:23:16,670
getting the QRL for our test queue.

340
00:23:16,830 --> 00:23:21,086
And so I've got an SQS client here available within

341
00:23:21,128 --> 00:23:24,786
this function, which I can use in all of my test iterations

342
00:23:24,898 --> 00:23:26,950
to receive messages.

343
00:23:29,050 --> 00:23:32,502
And this is where we start to stumble upon the power

344
00:23:32,556 --> 00:23:35,846
of using go to write these load test scenarios.

345
00:23:36,038 --> 00:23:39,686
Because what I'm going to want to do is consume messages

346
00:23:39,718 --> 00:23:43,434
from my SQs queue in the background and then check what

347
00:23:43,472 --> 00:23:46,250
messages are arriving from my test iterations.

348
00:23:46,690 --> 00:23:50,554
So let's do that here. Let's run a go routine

349
00:23:50,682 --> 00:23:54,286
in the background to do that. So what have I got

350
00:23:54,308 --> 00:23:58,854
here? Okay, so having initialized my SQS

351
00:23:58,922 --> 00:24:03,170
client, I've now created a channel that I'm going to use in memory

352
00:24:03,670 --> 00:24:07,342
for receiving messages. And I've started goroutines,

353
00:24:07,486 --> 00:24:11,570
which is basically polling the SQs queue

354
00:24:12,090 --> 00:24:15,474
and sending messages into that channel. So in the background

355
00:24:15,522 --> 00:24:19,634
of my load test, I've got this channel which is sort of buffering inbound

356
00:24:19,762 --> 00:24:21,590
messages from SQS.

357
00:24:22,890 --> 00:24:26,860
And that means that the actual implementation of my run function

358
00:24:27,790 --> 00:24:32,486
is pretty straightforward. So let's

359
00:24:32,518 --> 00:24:34,780
do that. Let's put an implementation in,

360
00:24:35,710 --> 00:24:41,166
and what we want to do here is basically what we were doing from

361
00:24:41,188 --> 00:24:46,766
the terminal earlier. So we're going to make a

362
00:24:46,788 --> 00:24:50,574
post request. So we're going to make a web request to our local web

363
00:24:50,612 --> 00:24:54,100
service. We're going to check that we got a 202.

364
00:24:54,630 --> 00:24:57,954
Then we're going to wait for up to 10 seconds for a

365
00:24:57,992 --> 00:25:01,538
message to be received from that channel. Now, in real life, you'd probably want to

366
00:25:01,544 --> 00:25:05,510
do some logic, execute some logic here to sort of stitch together the SQs message

367
00:25:05,580 --> 00:25:09,158
that was received with the web request that you sent, maybe by

368
00:25:09,244 --> 00:25:12,982
id or something like that. And in reality, that's what we do is

369
00:25:13,116 --> 00:25:16,266
we'll send some kind of HTTP request. There'll be

370
00:25:16,288 --> 00:25:19,622
some attributes about that HTTP request that identify

371
00:25:19,686 --> 00:25:23,942
that unit of work. Then there's a whole load of background

372
00:25:24,006 --> 00:25:27,754
asynchronous processing, the output of which is an SQS message that

373
00:25:27,792 --> 00:25:31,134
contains some ids that let us stitch it back together. So our

374
00:25:31,172 --> 00:25:35,006
test iteration function here will be sending that web request and

375
00:25:35,028 --> 00:25:38,906
then waiting for inbound SQs messages that we can stitch back together.

376
00:25:39,028 --> 00:25:41,410
And if you don't receive one within 10 seconds,

377
00:25:43,030 --> 00:25:45,250
that test iteration fails.

378
00:25:46,710 --> 00:25:50,350
So that's it. We've written our load test scenario,

379
00:25:50,430 --> 00:25:54,054
so we should be able to run it. So we've still got our app

380
00:25:54,092 --> 00:25:58,070
running in the background. Let's compile

381
00:26:00,090 --> 00:26:03,160
our application into a handy binary called f one.

382
00:26:03,530 --> 00:26:07,994
So I should be able to f one help f

383
00:26:08,032 --> 00:26:10,380
one scenarios list.

384
00:26:11,710 --> 00:26:15,354
Okay, so let's see now. I should be able to

385
00:26:15,392 --> 00:26:19,082
f one run constant.

386
00:26:19,146 --> 00:26:23,038
So this is one of the modes, constant mode. I'm going

387
00:26:23,044 --> 00:26:27,102
to run test scenario array of 1 /second

388
00:26:27,236 --> 00:26:29,230
form, let's say 10 seconds.

389
00:26:30,790 --> 00:26:34,002
Okay, so we've got one tests iteration per second

390
00:26:34,056 --> 00:26:37,858
using executed. They're taking about 1.5

391
00:26:37,944 --> 00:26:41,330
milliseconds and they all passed.

392
00:26:43,210 --> 00:26:47,240
I can also do this in a similar mode to

393
00:26:47,610 --> 00:26:51,270
k six, so I can use a pool of virtual users

394
00:26:52,250 --> 00:26:55,450
with a concurrent cool, let's say of, I don't know,

395
00:26:55,520 --> 00:26:59,226
one user, and you'll see

396
00:26:59,248 --> 00:27:03,082
now I get something quite different. So now I'm running, let's say

397
00:27:03,136 --> 00:27:05,180
close to 1000 requests per second,

398
00:27:06,190 --> 00:27:09,614
taking up to three or four milliseconds. And that's because my

399
00:27:09,652 --> 00:27:13,166
pool of one virtual user is making requests one

400
00:27:13,188 --> 00:27:16,766
after another as quickly as it can. So these two

401
00:27:16,788 --> 00:27:20,290
modes allow you to sort of inject load

402
00:27:21,270 --> 00:27:24,914
however you like. That constant mode allows you to

403
00:27:24,952 --> 00:27:28,526
really control the rate which load

404
00:27:28,558 --> 00:27:31,990
is being injected. And that becomes particularly useful

405
00:27:32,730 --> 00:27:36,502
when your cool of virtual users would become

406
00:27:36,556 --> 00:27:40,902
saturated. So if you've got ten users and

407
00:27:40,956 --> 00:27:44,566
each request or each sort of asynchronous process

408
00:27:44,668 --> 00:27:48,438
takes 2 seconds, your pool of ten virtual users

409
00:27:48,454 --> 00:27:52,074
can only make five requests per second because they're each making

410
00:27:52,112 --> 00:27:55,594
their requests consecutively, one after the other, and they have to wait

411
00:27:55,632 --> 00:27:59,214
2 seconds between requests. And that's problematic if you really,

412
00:27:59,252 --> 00:28:02,686
really want to apply ten requests per second load to your

413
00:28:02,708 --> 00:28:06,666
system. The constant mode doesn't care about virtual users,

414
00:28:06,698 --> 00:28:10,290
and it will aggressively apply ten requests per second to

415
00:28:10,360 --> 00:28:14,066
your application. And that's one of the reasons we developed f

416
00:28:14,088 --> 00:28:15,010
one separately.

417
00:28:17,030 --> 00:28:20,850
So that's it. I hope you found that demo useful.

418
00:28:22,310 --> 00:28:26,150
So I guess just to sum up, f one

419
00:28:26,220 --> 00:28:29,862
is a sort of battle tests load testing tool that we use now.

420
00:28:29,996 --> 00:28:33,454
We use it every day. We use it to apply synthetic load

421
00:28:33,602 --> 00:28:36,010
in a number of our pre production environments.

422
00:28:37,310 --> 00:28:41,158
It sends hundreds or thousands of sort of payments

423
00:28:41,174 --> 00:28:44,714
per second into our environments and it's really

424
00:28:44,752 --> 00:28:48,270
a first class citizen in our software development lifecycle.

425
00:28:48,850 --> 00:28:51,982
So I guess this statement at the top is important is that I think

426
00:28:52,036 --> 00:28:55,630
for large systems,

427
00:28:56,130 --> 00:29:00,066
which will be processing volume at scale in

428
00:29:00,088 --> 00:29:03,966
production, load testing needs to be a first class citizen.

429
00:29:03,998 --> 00:29:07,170
It shouldn't be an afterthought and it should be part of

430
00:29:07,240 --> 00:29:10,286
the way you're developing your applications.

431
00:29:10,398 --> 00:29:14,150
And certainly for us, we found it really useful at spotting

432
00:29:14,570 --> 00:29:18,710
performance bottlenecks or scalability problems well before

433
00:29:18,780 --> 00:29:22,294
we would have encountered those problems in production, which gives us plenty of time

434
00:29:22,332 --> 00:29:23,880
to fix those problems.

435
00:29:25,850 --> 00:29:29,190
So this has been us, Adelina and I, thanks for listening.

436
00:29:29,610 --> 00:29:32,854
And if you're interested in learning more, check out f

437
00:29:32,892 --> 00:29:37,278
one on our open source organization or

438
00:29:37,364 --> 00:29:40,880
look us up online at the addresses shown here.

439
00:29:41,730 --> 00:29:43,260
So, yeah, thanks a lot.

