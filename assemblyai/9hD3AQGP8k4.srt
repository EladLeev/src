1
00:00:41,410 --> 00:00:44,950
I joined my first startup in 1998. I had no background in computer

2
00:00:45,020 --> 00:00:48,726
science and no industry experience in software, but they were

3
00:00:48,748 --> 00:00:52,446
looking for someone to run QA or to start a QA function, and I was

4
00:00:52,468 --> 00:00:55,406
interested enough, willing to give it a shot, take a chance.

5
00:00:55,508 --> 00:00:58,366
So I showed up on my first day, excited to get going, but not really

6
00:00:58,388 --> 00:01:01,326
sure what to expect. It turned out the first thing that they wanted me to

7
00:01:01,348 --> 00:01:04,786
look into was a performance issue. This was

8
00:01:04,888 --> 00:01:08,722
fairly straightforward, a page that had started

9
00:01:08,776 --> 00:01:12,898
out responsive and was slowly degrading over time as the total user base

10
00:01:12,984 --> 00:01:16,034
started to grow. And so not really

11
00:01:16,072 --> 00:01:19,714
knowing what to look for seemed like something that I could take on and give

12
00:01:19,752 --> 00:01:22,326
a shot. So I started to dig in and the first thing I did was

13
00:01:22,348 --> 00:01:25,974
go and look at some code. Now remember, this is 1998.

14
00:01:26,012 --> 00:01:29,782
It predates most tools in terms of building

15
00:01:29,836 --> 00:01:33,194
web applications. We were using Java, and so we really

16
00:01:33,232 --> 00:01:36,522
had code that looked a little bit like this. This is probably not exactly right,

17
00:01:36,576 --> 00:01:40,614
but we were building a table with a list of users

18
00:01:40,742 --> 00:01:44,458
by writing strings with HTML tables directly embedded

19
00:01:44,474 --> 00:01:48,046
in them. And so the key point here is every time

20
00:01:48,068 --> 00:01:52,010
we wanted to add another username to the table, we would append

21
00:01:52,090 --> 00:01:55,118
to the string, which is particularly interesting,

22
00:01:55,284 --> 00:01:58,546
and this is now a well known issue in Java, but back

23
00:01:58,568 --> 00:02:01,986
then it was not super well understood by most of us, which is that when

24
00:02:02,008 --> 00:02:05,714
you do this, you write the first string by allocating an object

25
00:02:05,832 --> 00:02:09,286
and writing the content into it. And when you append to it with the

26
00:02:09,308 --> 00:02:12,882
plus operator, you actually create a brand new string,

27
00:02:12,946 --> 00:02:16,678
allocate all of that memory and release the old object to be collected by the

28
00:02:16,684 --> 00:02:19,878
garbage collector. And then when you append to it again, you do the

29
00:02:19,884 --> 00:02:23,178
same thing. So we were doing this over and over and over for all of

30
00:02:23,184 --> 00:02:26,518
the users in the list without realizing the implications.

31
00:02:26,614 --> 00:02:29,722
In the virtual machine, what happens in this case is

32
00:02:29,856 --> 00:02:33,354
you allocate a string buffer and then you append to it with the append method

33
00:02:33,402 --> 00:02:36,574
of the string buffer, and then ultimately write that out

34
00:02:36,612 --> 00:02:40,430
to the output by converting to a string. So what's happening

35
00:02:40,500 --> 00:02:44,186
inside the system is you've allocated a large chunk of memory,

36
00:02:44,298 --> 00:02:47,666
you can continue to write into that chunk, and when you get to the end,

37
00:02:47,768 --> 00:02:51,374
you allocate another chunk, which is actually all done by the string buffer,

38
00:02:51,422 --> 00:02:54,674
not by the developer. And when it's complete, you can write

39
00:02:54,712 --> 00:02:58,034
it all out. So the big takeaway for me in this was,

40
00:02:58,152 --> 00:03:00,850
and it was a great early lesson CTO learn in my career.

41
00:03:01,010 --> 00:03:04,006
We all want to take advantage of the tools that are made available to us,

42
00:03:04,028 --> 00:03:07,830
so that we can focus on the things that matter to our users. But not

43
00:03:07,900 --> 00:03:11,930
understanding how those things are implemented can ultimately lead

44
00:03:12,000 --> 00:03:15,130
CTO degradation for your users. So it's important

45
00:03:15,200 --> 00:03:19,046
to know that you get great advantage by leveraging

46
00:03:19,078 --> 00:03:22,858
the tools that are available, but it's also important to pay attention to how they

47
00:03:22,864 --> 00:03:26,814
would be implemented, because there really is no magic and make good

48
00:03:26,852 --> 00:03:30,426
choices about the tools that you end up using. I'm Rob Zuber,

49
00:03:30,458 --> 00:03:33,774
CTO of Circleci, and today I want to give you a few more examples from

50
00:03:33,812 --> 00:03:37,646
more recent history in the Circleci platform of places where we've

51
00:03:37,678 --> 00:03:41,294
been able to make great use of available technologies. But our initial

52
00:03:41,342 --> 00:03:44,706
choices ultimately caused issues based on how those things were

53
00:03:44,728 --> 00:03:48,622
implemented. So let's start with schemaless databases. At Circleci,

54
00:03:48,686 --> 00:03:51,686
we use Mongo. We've used Mongo for a very long time. We're starting to use

55
00:03:51,708 --> 00:03:54,838
some other data stores and other pieces of our platform, but we still have a

56
00:03:54,844 --> 00:03:58,482
lot of mongo. And one thing that I always tell people about schemaless databases

57
00:03:58,546 --> 00:04:01,866
is there's always a schema. It's just a question of where that schema is

58
00:04:01,888 --> 00:04:05,226
enforced. And in order to understand the issue that we

59
00:04:05,248 --> 00:04:08,314
ultimately ran into, it's important to understand a lot of things about

60
00:04:08,352 --> 00:04:11,094
Mongo and its implementation and schemaless databases.

61
00:04:11,222 --> 00:04:14,730
So this is a comparison of what it would look like to structure a row

62
00:04:14,810 --> 00:04:18,394
in a schema defined database, like a relational database.

63
00:04:18,442 --> 00:04:21,722
And in the schema list or document store, like Mongo,

64
00:04:21,786 --> 00:04:25,486
on the top you have a list of names and email addresses, and all you

65
00:04:25,508 --> 00:04:29,102
need to store is names and email addresses, because the schema defines

66
00:04:29,166 --> 00:04:32,786
what a row looks like. This is a little bit more like a CSV than

67
00:04:32,808 --> 00:04:36,382
a true database table, because it's hard for me to print all the control characters

68
00:04:36,446 --> 00:04:39,846
on a screen, but you get the general idea, the amount of extra space is

69
00:04:39,868 --> 00:04:43,618
very limited. On the other hand, when storing a document in a schema

70
00:04:43,634 --> 00:04:47,222
list database, you have to identify every field in every

71
00:04:47,276 --> 00:04:50,518
record or document, because there's no schema defining what could

72
00:04:50,524 --> 00:04:53,962
be present. So one document might have a name and email and another might not,

73
00:04:54,016 --> 00:04:57,446
and that's totally valid inside the same collection.

74
00:04:57,558 --> 00:05:01,082
So one thing to note when you do this is that that

75
00:05:01,136 --> 00:05:05,006
second document is about 25% bigger than the one

76
00:05:05,028 --> 00:05:08,766
above it, and that's not necessarily a good thing. In many places, bigger is

77
00:05:08,788 --> 00:05:12,494
better in storage, bigger is worse. And in 2021,

78
00:05:12,532 --> 00:05:15,926
or even over the last ten years, we've come CTO believe that storage is effectively

79
00:05:15,978 --> 00:05:19,374
free based on the price that we pay. But storage

80
00:05:19,502 --> 00:05:22,894
has a lot of, or size of rows or documents

81
00:05:22,942 --> 00:05:26,510
in storage has a lot of impact on the overall performance of your systems.

82
00:05:26,590 --> 00:05:30,120
So this growth is not necessarily a positive thing.

83
00:05:30,490 --> 00:05:33,574
So, looking at this a little bit more specifically, if you think of a very

84
00:05:33,612 --> 00:05:37,938
simple system like the one that we use to manage our Mongo instances,

85
00:05:38,034 --> 00:05:41,338
you have compute, doing the actual calculations of what's happening

86
00:05:41,424 --> 00:05:45,610
and running the mongo binary, and then you have disk, which is where

87
00:05:45,680 --> 00:05:49,382
the data is stored, and most likely you have some sort of network

88
00:05:49,446 --> 00:05:52,406
in between those two. In some cases you would have locally attached storage,

89
00:05:52,438 --> 00:05:55,646
but in many cases, in our cloud systems, we're using network attached storage for

90
00:05:55,668 --> 00:05:59,450
the benefits of that. And the result is you're moving this data back and forth

91
00:05:59,530 --> 00:06:02,974
across these networks. And so latency and throughput are

92
00:06:03,012 --> 00:06:05,970
both concerns when moving those large volumes of data.

93
00:06:06,120 --> 00:06:09,458
So, as I said, up in the compute layer, the system

94
00:06:09,544 --> 00:06:12,962
effectively is where parsing and editing of those documents happens.

95
00:06:13,016 --> 00:06:16,530
So when you have an unstructured document, you have to load the entire

96
00:06:16,600 --> 00:06:19,480
thing in order to find any of the pieces of it.

97
00:06:20,330 --> 00:06:23,922
And that's done within the mongo binary. And that's also where editing

98
00:06:23,986 --> 00:06:27,858
happens before it's flushed back out to the disk. And more realistically,

99
00:06:27,954 --> 00:06:31,894
looking at that second example again, what truly happens is there's

100
00:06:31,942 --> 00:06:35,414
no defined ordering of the fields,

101
00:06:35,462 --> 00:06:39,226
so you could write the same content into two different documents. And the

102
00:06:39,248 --> 00:06:42,922
net result is that you have no way of knowing

103
00:06:42,986 --> 00:06:46,446
where in that document those fields might be. So when

104
00:06:46,468 --> 00:06:49,614
you go looking for something, you have to iterate over the

105
00:06:49,652 --> 00:06:53,166
entire document. Now, mongo uses a format called BSON, which is

106
00:06:53,188 --> 00:06:56,434
effectively a binary version of JSON, or close enough so

107
00:06:56,472 --> 00:06:59,954
there are some smaller characters and control functions used.

108
00:06:59,992 --> 00:07:03,394
Both CTO define indicators or separators of fields, as well as

109
00:07:03,432 --> 00:07:06,818
to allow for a couple additional data types that would not be obvious in a

110
00:07:06,824 --> 00:07:10,310
JSON document. But other than that, you can think about the parsing as very similar

111
00:07:10,380 --> 00:07:13,446
to JSOn, meaning you open up an iterator and

112
00:07:13,468 --> 00:07:16,486
you start moving over all the keys until you find the one that you want.

113
00:07:16,508 --> 00:07:19,842
This particular example is from the Mongo C driver docs.

114
00:07:19,906 --> 00:07:23,218
So if you were writing a parser in C, it would look just like

115
00:07:23,244 --> 00:07:26,278
this. You would start at the beginning. I guess it's not the parser, but it's

116
00:07:26,294 --> 00:07:29,834
a search for a particular element. You'd start at the beginning and iterate over

117
00:07:29,872 --> 00:07:33,106
until you found what you needed. Second, there are no joints,

118
00:07:33,158 --> 00:07:37,162
and this is a very common theme in schemaless databases.

119
00:07:37,306 --> 00:07:40,810
Ultimately the goal being that you have different operational

120
00:07:40,890 --> 00:07:44,186
characteristics and different models for deploying your systems

121
00:07:44,218 --> 00:07:47,586
when you don't have to worry about joins between collections. So this

122
00:07:47,608 --> 00:07:51,346
is considered generally to be a good thing. Unfortunately, it means

123
00:07:51,448 --> 00:07:54,642
that there are some specific behaviors that you account for in different ways,

124
00:07:54,696 --> 00:07:57,460
and sometimes they don't work out the way that you would expect.

125
00:07:57,910 --> 00:08:00,958
So, taking a look at the previous example, this is what it would actually look

126
00:08:00,984 --> 00:08:03,926
like laid out in a relational database. I mean, of core, there would be more

127
00:08:03,948 --> 00:08:07,474
to it. But if you had names and emails for your users or your characters

128
00:08:07,522 --> 00:08:11,242
and your superheroes that you're storing, and then you wanted to associate with them their

129
00:08:11,296 --> 00:08:14,122
powers, and that would be a one to many relationship,

130
00:08:14,256 --> 00:08:17,430
meaning an individual superhero could have many powers.

131
00:08:17,510 --> 00:08:21,514
You would store a separate table of powers and then have a relational id back

132
00:08:21,552 --> 00:08:25,166
to the character table to identify with which character they were

133
00:08:25,188 --> 00:08:29,102
associated. Now, that's not possible. It's possible, but there's no

134
00:08:29,156 --> 00:08:33,002
enforcement in the database, in a document store. So the more commonly

135
00:08:33,066 --> 00:08:37,026
proposed and supported pattern is to embed those.

136
00:08:37,128 --> 00:08:40,690
So in this case, we have Wanda as Scarlet Witch, who has some specific

137
00:08:40,760 --> 00:08:44,270
powers. We would list those inside of the document

138
00:08:44,350 --> 00:08:48,626
representing Wanda, and for a small number of powers,

139
00:08:48,738 --> 00:08:52,214
this is actually a totally reasonable approach, minus any

140
00:08:52,252 --> 00:08:55,686
opportunity to enforce uniqueness or constraints on that

141
00:08:55,708 --> 00:08:59,706
list of powers. Now, one of the amazing

142
00:08:59,808 --> 00:09:02,954
convenience functions that Mongo provides to allow you to

143
00:09:02,992 --> 00:09:06,774
manage these lists is something called add to set. So in that previous

144
00:09:06,822 --> 00:09:10,266
example, if I listed mind control, and then I

145
00:09:10,288 --> 00:09:13,414
wanted to add it again, if I call add to set, Mongo will ensure

146
00:09:13,462 --> 00:09:17,466
that that doesn't already exist inside of the record before it appends

147
00:09:17,498 --> 00:09:20,846
it, which sounds great and is super helpful, and it's something that we

148
00:09:20,868 --> 00:09:24,778
chose to use for one of our implementations, specifically our implementation

149
00:09:24,874 --> 00:09:28,494
of artifacts. So, circle CI is a CI and CD

150
00:09:28,542 --> 00:09:31,826
platform. And one of the things that we allow you to do when you run

151
00:09:31,848 --> 00:09:35,682
a build is store artifacts of that build. And this

152
00:09:35,736 --> 00:09:39,042
is a small document that represents a single

153
00:09:39,096 --> 00:09:42,438
artifact at the end of a build. In terms of what we would store,

154
00:09:42,524 --> 00:09:46,246
it describes the name, the actual path in s three, where we would

155
00:09:46,268 --> 00:09:50,102
have stored it, and then a URL to retrieve it. Now, these are obviously

156
00:09:50,236 --> 00:09:53,862
adjusted to fit on the screen, but it's approximately this format.

157
00:09:53,926 --> 00:09:57,370
In fact, I think they would mostly be longer than this. So for every single

158
00:09:57,440 --> 00:10:01,114
artifact that was stored, we had some repetition, which, as I've discussed before,

159
00:10:01,152 --> 00:10:05,006
was probably not great from a total size perspective. And we were storing these

160
00:10:05,028 --> 00:10:08,234
documents in an array and using the add to set operator,

161
00:10:08,282 --> 00:10:11,966
to identify when we had duplication inside of that array and

162
00:10:11,988 --> 00:10:15,626
to avoid that. So, similar to the short list of powers,

163
00:10:15,738 --> 00:10:19,278
when we had builds that ran with a small number of outputs,

164
00:10:19,374 --> 00:10:22,578
this was a great way to list them and a quick way to find the

165
00:10:22,584 --> 00:10:25,458
data we needed and go and fetch those artifacts. We could show the list to

166
00:10:25,464 --> 00:10:28,502
the user so they could see what artifacts were associated with their build,

167
00:10:28,556 --> 00:10:31,926
click on one and download it. Now, what ended up

168
00:10:31,948 --> 00:10:35,874
happening was we had customers who had 30,000 or more of these artifacts

169
00:10:35,922 --> 00:10:39,202
being generated within a build, which, as you can imagine,

170
00:10:39,346 --> 00:10:42,602
started to build some very, very large arrays inside of that

171
00:10:42,656 --> 00:10:46,778
document. So, here's an example or a description of

172
00:10:46,864 --> 00:10:50,138
what that sort of looks like as it's happening. So this is our

173
00:10:50,224 --> 00:10:54,110
very simple mongo instance again with compute, and then disk below

174
00:10:54,180 --> 00:10:57,882
and the little square representing the specific document that we're

175
00:10:57,946 --> 00:11:00,958
interested in editing and adding an artifact to.

176
00:11:01,124 --> 00:11:04,666
And up above, we have a builder machine that's

177
00:11:04,698 --> 00:11:08,014
actually doing the work and wants to write. And so when it makes a request

178
00:11:08,062 --> 00:11:11,678
to Mongo to get access to that build document, Mongo loads

179
00:11:11,694 --> 00:11:14,850
it off disk and holds it in memory in order to operate on it.

180
00:11:15,000 --> 00:11:17,838
And ultimately, we'll flush it back out to disk.

181
00:11:18,014 --> 00:11:21,446
Now, one of the capabilities that we offer at Circleci is the ability to

182
00:11:21,468 --> 00:11:25,362
parallelize your build. So you might have a very large number of teams.

183
00:11:25,426 --> 00:11:28,834
And in order to get through them faster, we will split those tests

184
00:11:28,882 --> 00:11:31,866
up onto different machines and run them at the same time.

185
00:11:31,968 --> 00:11:35,226
Of course, that means that each one of those is computing a

186
00:11:35,248 --> 00:11:38,634
different set of artifacts and writing it back to the

187
00:11:38,672 --> 00:11:41,834
build. And the build is the collection of results from

188
00:11:41,872 --> 00:11:44,986
all of those different machines, not one per machine.

189
00:11:45,098 --> 00:11:48,286
So when each one of those tries to write, it has

190
00:11:48,308 --> 00:11:51,694
to write to the same array. And when we call add to

191
00:11:51,732 --> 00:11:55,202
set, each one of those write requests is going to lock the build

192
00:11:55,256 --> 00:11:58,690
document and iterate over the entire

193
00:11:58,840 --> 00:12:02,334
array of artifacts, looking for any potential

194
00:12:02,462 --> 00:12:05,854
conflicts or duplicates before it ultimately writes

195
00:12:05,902 --> 00:12:09,554
at the end. And this could happen on 100 parallel

196
00:12:09,602 --> 00:12:13,542
builders trying to write 30,000 artifacts in total over

197
00:12:13,676 --> 00:12:17,686
that single document, each one of them locking and searching by the

198
00:12:17,708 --> 00:12:21,126
end, the previous 29,000 documents, in order to

199
00:12:21,148 --> 00:12:24,458
see if there was any duplication or conflict. This was not a

200
00:12:24,464 --> 00:12:28,346
great outcome for us. And even more exciting, we would be writing a

201
00:12:28,368 --> 00:12:31,846
big enough or a large enough number to that artifacts

202
00:12:31,878 --> 00:12:35,786
array that ultimately, Mongo would have to grow the document,

203
00:12:35,898 --> 00:12:39,834
so it would have to allocate a new chunk of memory, copy the existing document

204
00:12:39,882 --> 00:12:43,262
into that memory, and then continue to edit, which is another

205
00:12:43,316 --> 00:12:46,050
operation that happened while locked and blocking all,

206
00:12:46,120 --> 00:12:49,854
potentially 99 other or more builders from writing.

207
00:12:49,982 --> 00:12:53,774
And then we had to write that document back to disk, which requires

208
00:12:53,822 --> 00:12:56,946
Mongo to allocate new space on the disk because there's not

209
00:12:56,968 --> 00:13:00,406
room to fit it where it was before, find a new extent, move the

210
00:13:00,428 --> 00:13:04,054
entire existing document over there and write the new content into

211
00:13:04,092 --> 00:13:07,654
it. Or more likely, just flush the whole document and remove the old one.

212
00:13:07,692 --> 00:13:11,000
So that whole operation had to happen before someone else could write.

213
00:13:11,470 --> 00:13:14,966
Ultimately, this resulted in some very, very slow builds.

214
00:13:15,078 --> 00:13:18,774
So the first quick fix we made was to remove the add to set operator

215
00:13:18,822 --> 00:13:22,054
and replace it with a push operator, which just assumes there's no duplication,

216
00:13:22,102 --> 00:13:25,374
or that duplication doesn't matter, because it actually never did for us,

217
00:13:25,492 --> 00:13:29,166
and writes directly to the end. The next step was

218
00:13:29,268 --> 00:13:32,734
effectively to rebuild large parts of that artifact management system,

219
00:13:32,852 --> 00:13:36,286
shrinking the total amount of storage, because we knew the pattern to

220
00:13:36,308 --> 00:13:39,442
get to a document, and then changing the storage model

221
00:13:39,496 --> 00:13:42,658
so that we didn't need to core it inside the Mongo document at all.

222
00:13:42,744 --> 00:13:46,114
So the key takeaway here for me is that there actually

223
00:13:46,152 --> 00:13:49,586
was a great simple approach in the method that we chose. But when you take

224
00:13:49,608 --> 00:13:52,726
a simple approach like that, it's really important to know when it's going to

225
00:13:52,748 --> 00:13:56,418
break. For us, it was a surprise, and we had to go do some digging

226
00:13:56,434 --> 00:13:59,574
and learning to figure out what was going on, and then find a new system.

227
00:13:59,692 --> 00:14:03,446
If we had understood going in where the limitations of the mongo

228
00:14:03,478 --> 00:14:07,014
array capability would be, then we could have planned

229
00:14:07,062 --> 00:14:10,426
for future work to make a more comprehensive or capable system

230
00:14:10,528 --> 00:14:14,346
at the point where the scale would be a problem, or before that point.

231
00:14:14,528 --> 00:14:17,774
Now, taking another look at how we use mongo, but looking at a different

232
00:14:17,812 --> 00:14:21,070
aspect of it, let's talk a little bit about EBS. Now, this could probably be

233
00:14:21,140 --> 00:14:24,494
any block store. EBS is one that I happen to be fairly familiar with,

234
00:14:24,532 --> 00:14:27,778
because we use it a lot inside of Circleci. And the one thing that

235
00:14:27,784 --> 00:14:31,346
I will definitely highlight here is many things feel like magic. There's never

236
00:14:31,368 --> 00:14:35,054
any actual magic. There's just important, difficult engineering challenges

237
00:14:35,102 --> 00:14:38,726
that have already been solved, but it's important to think about how they've been

238
00:14:38,748 --> 00:14:42,082
solved. So, again, taking our simple example of a Mongo instance,

239
00:14:42,146 --> 00:14:46,018
this is circa 2015, we actually had Mongo

240
00:14:46,034 --> 00:14:49,526
outsourced to a third party provider who managed the database

241
00:14:49,558 --> 00:14:53,142
for us. And again, your simple compute and disk

242
00:14:53,206 --> 00:14:56,998
pairing. And in that model, those were actually locally attached.

243
00:14:57,094 --> 00:15:00,458
So we were using AWS's largest instances at

244
00:15:00,464 --> 00:15:03,886
the time, which meant we had their largest local ssds. Because disk and

245
00:15:03,908 --> 00:15:07,518
compute moved together, there's no way to attach directly, or at

246
00:15:07,524 --> 00:15:11,386
least at the time, larger disks, CTO, the same sized instance.

247
00:15:11,498 --> 00:15:15,098
Then we were running low on space for even a single collection,

248
00:15:15,194 --> 00:15:18,642
meaning we had shifted off multiple different collections, left a single

249
00:15:18,696 --> 00:15:21,842
collection on a particular store, and the system was running

250
00:15:21,896 --> 00:15:25,342
out of space. So we were constantly tweaking and managing the storage.

251
00:15:25,406 --> 00:15:29,062
But no matter how small you get the documents, if you're continuing to add them

252
00:15:29,116 --> 00:15:32,566
at a high rate of growth, you're ultimately going to run out of space.

253
00:15:32,668 --> 00:15:36,054
Additionally, we had operational management issues like

254
00:15:36,092 --> 00:15:39,478
backup and restore, so a backup we were trying to do daily, but we

255
00:15:39,484 --> 00:15:42,738
got to the point where a backup was taking greater than 24 hours because we

256
00:15:42,764 --> 00:15:46,266
were pulling it out of the database and pushing it across the network all through

257
00:15:46,288 --> 00:15:50,310
the compute engine, which was also trying to serve traffic. We ended up with stale,

258
00:15:50,390 --> 00:15:54,130
inconsistent backups by the time they were even created, and we obviously couldn't

259
00:15:54,150 --> 00:15:57,438
run them daily anymore because they weren't even done. Even worse, if we tried to

260
00:15:57,444 --> 00:16:01,214
use restore to do any maintenance operations, that would take two

261
00:16:01,252 --> 00:16:04,446
to three days. So the ability to build out a new host even move

262
00:16:04,468 --> 00:16:08,238
us off when we were having operational issues was severely limited.

263
00:16:08,334 --> 00:16:11,826
We had operational problems all over and we

264
00:16:11,848 --> 00:16:15,294
needed a new solution. So we decided to do two things at the same time.

265
00:16:15,352 --> 00:16:19,222
We moved the overall Mongo operation into

266
00:16:19,276 --> 00:16:23,126
our own AWS environment. So we cloud customize the buildout, and we switched to

267
00:16:23,148 --> 00:16:26,966
using EBS as the disk storage. EBS is

268
00:16:26,988 --> 00:16:31,430
elastic block store within AWS, so now we're back to having a network attached

269
00:16:31,510 --> 00:16:35,254
storage model. We could optimize the disk and compute

270
00:16:35,302 --> 00:16:38,166
separately. We had to pay attention to the operational characteristics,

271
00:16:38,198 --> 00:16:41,722
but ultimately for us, the throughput and latency were both manageable.

272
00:16:41,786 --> 00:16:44,910
Throughput is unbelievable inside of EBS,

273
00:16:45,490 --> 00:16:49,438
and the latency was good enough, with the right mix of

274
00:16:49,604 --> 00:16:53,050
computing power on the other side to store working sets, that it didn't end up

275
00:16:53,060 --> 00:16:56,754
being a significant problem. Also, backups got a lot easier by using

276
00:16:56,792 --> 00:17:00,078
snapshots. So snapshots are not actually instant,

277
00:17:00,174 --> 00:17:03,266
but they capture an instantaneous perspective of the

278
00:17:03,288 --> 00:17:06,514
disk itself, an instantaneous view, and then

279
00:17:06,552 --> 00:17:10,086
are capable of transferring that, despite the fact that it takes time

280
00:17:10,188 --> 00:17:13,542
with that understanding. Meaning if something is edited while

281
00:17:13,596 --> 00:17:17,398
it's still being transferred, the old version is held onto in order

282
00:17:17,484 --> 00:17:20,738
to complete the process of the backup or the

283
00:17:20,764 --> 00:17:24,362
snapshot transfer inside of EBS. So ultimately you get a

284
00:17:24,416 --> 00:17:28,454
consistent view from a moment in time. And because of the way that Mongo operates

285
00:17:28,502 --> 00:17:31,818
with journaling, it's not even necessary to stop operations.

286
00:17:31,914 --> 00:17:35,626
So the disk is known to be consistent at any particular instances.

287
00:17:35,738 --> 00:17:39,194
Additionally, we now had the opportunity to attach

288
00:17:39,242 --> 00:17:42,410
different compute without having CTO make any significant

289
00:17:42,490 --> 00:17:45,762
data transfers. So off of the same disk, we could do

290
00:17:45,896 --> 00:17:49,214
a rebuild of the machine. Whether it was because we wanted to upgrade the operating

291
00:17:49,262 --> 00:17:52,498
system, apply security patches, upgrade Mongo itself,

292
00:17:52,584 --> 00:17:55,806
and without having to try to change the state of the existing

293
00:17:55,838 --> 00:17:59,346
machine, we could just build a new one, throw out the old one, and attach

294
00:17:59,378 --> 00:18:03,510
it. So our hosts became effectively immutable and ephemeral in that way.

295
00:18:03,580 --> 00:18:07,186
And that was a significant improvement from an operational perspective.

296
00:18:07,378 --> 00:18:11,210
And then finally, that same instant transfer made

297
00:18:11,280 --> 00:18:14,746
restores really, really fast. It would take a couple minutes

298
00:18:14,848 --> 00:18:18,106
to build out a multi terabyte EBS volume from a

299
00:18:18,128 --> 00:18:21,766
snapshot that we had stored. And so this was quite magical and allowed

300
00:18:21,798 --> 00:18:25,742
us to again, perform those kinds of operations. Let's say we wanted to add another

301
00:18:25,796 --> 00:18:29,198
host to a replica set or replace one that wasn't working

302
00:18:29,284 --> 00:18:33,006
the way that we wanted. Or sometimes even AWS needs to

303
00:18:33,028 --> 00:18:35,966
take back a vm and we could just build a new one before they did

304
00:18:35,988 --> 00:18:39,806
that. So this was fantastic. Again, a couple of minutes to get multiple terabytes

305
00:18:39,838 --> 00:18:43,266
back online, and it seemed great until we actually tried to start Mongo up

306
00:18:43,288 --> 00:18:46,862
again. And then it was really, really slow, like kind of scary.

307
00:18:46,926 --> 00:18:50,534
Did I break the production database slow. When it takes minutes to

308
00:18:50,572 --> 00:18:54,066
start up a process that's normally pretty much instant.

309
00:18:54,178 --> 00:18:57,766
And I happened to be, or happened to have the opportunity to

310
00:18:57,788 --> 00:19:00,166
speak to some folks from Mongo and ask them if they had seen this type

311
00:19:00,188 --> 00:19:02,954
of behavior before. It turned out they had. And they were able to give me

312
00:19:02,992 --> 00:19:06,426
some clues about what might be happening. And it was

313
00:19:06,528 --> 00:19:10,570
bad enough that it was slow to start, but the more important thing was

314
00:19:10,640 --> 00:19:13,614
when we started the database and it actually did come online,

315
00:19:13,732 --> 00:19:17,306
if we put it into production, even as a secondary for reads,

316
00:19:17,418 --> 00:19:21,294
it would be extremely slow in its performance there as well for

317
00:19:21,332 --> 00:19:24,834
an extended period. So what we learned was happening was

318
00:19:24,872 --> 00:19:28,274
that the restore is not actually a transfer

319
00:19:28,392 --> 00:19:31,714
of all of the data, but it's a reference to

320
00:19:31,752 --> 00:19:35,278
the data that is placed on the new volume.

321
00:19:35,374 --> 00:19:39,378
And so the underlying file system, when it recognizes

322
00:19:39,474 --> 00:19:42,726
that something is missing, goes and fetches it. So first it

323
00:19:42,748 --> 00:19:46,354
starts in sort of sequential order, moving across the disk, but then a request

324
00:19:46,402 --> 00:19:49,954
comes in for something that it doesn't have. It prioritizes

325
00:19:50,002 --> 00:19:53,686
that and fills that in somewhere. So there's an on demand fetching

326
00:19:53,718 --> 00:19:56,966
model and this is a great model for smaller

327
00:19:56,998 --> 00:20:00,266
volumes and for very sequential reads. But in our case, with a

328
00:20:00,288 --> 00:20:03,530
large database and random access across all of our users,

329
00:20:03,610 --> 00:20:07,546
everybody was hitting very random locations around the disk

330
00:20:07,658 --> 00:20:11,134
under high load in a production environment simultaneously and

331
00:20:11,172 --> 00:20:14,862
causing great delays. Every single one of these was actually instead

332
00:20:14,916 --> 00:20:18,354
of a read from disk, a fetch out to s three,

333
00:20:18,392 --> 00:20:22,366
or wherever the snapshot is stored, some data transfer, some decompression,

334
00:20:22,478 --> 00:20:26,478
some placement of that onto the disk before the read could actually be completed.

335
00:20:26,574 --> 00:20:30,258
And so on the startup phase, it was the random sampling

336
00:20:30,274 --> 00:20:34,214
of indexes that Mongo does to ensure that all the content is there and

337
00:20:34,252 --> 00:20:37,574
consistent, or random sampling of the journal to then go look

338
00:20:37,612 --> 00:20:41,318
at the disk to check for consistency. That was taking a

339
00:20:41,324 --> 00:20:44,538
really long time because it's looking all over the disk. And then as soon as

340
00:20:44,544 --> 00:20:47,834
we put it into production, it was customer reads that were taking a really long

341
00:20:47,872 --> 00:20:51,830
time. And so once again, all of our customers are waiting

342
00:20:51,910 --> 00:20:55,646
and not impressed with performance. So ultimately we

343
00:20:55,668 --> 00:20:59,086
had to think about what was causing that and how we could manage it.

344
00:20:59,188 --> 00:21:02,462
And what we ended up doing and still do is when we'd make these large

345
00:21:02,516 --> 00:21:06,270
operations and move CTO new volumes, we run warming

346
00:21:06,350 --> 00:21:10,190
queries that we know will be most representative of the majority

347
00:21:10,270 --> 00:21:13,934
of content that will be fetched once we put it back into production,

348
00:21:13,982 --> 00:21:17,518
which is usually most recently edited, most recently written.

349
00:21:17,694 --> 00:21:21,270
So we drive those queries to force all of this data

350
00:21:21,340 --> 00:21:24,450
to be fetched, because if we wait for the entire disk

351
00:21:24,530 --> 00:21:27,686
to fetch, it will take forever. And a huge amount of it is

352
00:21:27,708 --> 00:21:30,938
not really that important to us. The key takeaway here

353
00:21:31,024 --> 00:21:34,794
is your cloud provider. Your tool provider is

354
00:21:34,912 --> 00:21:38,074
solving for a general case. They are building amazing things,

355
00:21:38,112 --> 00:21:41,706
but they're building them for a very large audience and thinking about what's going to

356
00:21:41,728 --> 00:21:45,626
matter. CTO, the largest subset of those people, probably applying

357
00:21:45,658 --> 00:21:49,422
an 80 20 rule, saying if we solve this 20% case, we're going to cover

358
00:21:49,556 --> 00:21:53,534
80% of our customer base. And the question that you have to ask yourself is,

359
00:21:53,572 --> 00:21:56,962
are you the target? Are you in that 20% bucket in terms of your use

360
00:21:57,016 --> 00:22:00,386
case, such that your usage will be covered? Or do you

361
00:22:00,408 --> 00:22:03,890
need to figure out how to adjust your approach or your problem space,

362
00:22:03,960 --> 00:22:07,506
or work around that in order to have it work for you? Now I'd like

363
00:22:07,528 --> 00:22:10,806
to turn to a final example, which is a little bit

364
00:22:10,828 --> 00:22:14,694
less about the tools that we've used from others and more about how

365
00:22:14,812 --> 00:22:18,262
our own challenges have existed while building out in a cloud

366
00:22:18,316 --> 00:22:21,746
native way. Concurrency has always been a problem,

367
00:22:21,868 --> 00:22:25,354
has always been a challenging part of software development. And that's been true

368
00:22:25,392 --> 00:22:29,034
for as long as I've been writing software, and it's always been true within

369
00:22:29,152 --> 00:22:32,566
a single programming environment, and it hasn't gotten

370
00:22:32,598 --> 00:22:36,206
any easier as a result of most of the tools that we've thrown at it.

371
00:22:36,308 --> 00:22:39,690
So concurrency has always been hard from a programming perspective.

372
00:22:39,770 --> 00:22:43,262
This is a newer article, but speaks to an old problem.

373
00:22:43,396 --> 00:22:46,898
And the great news is distributed systems are also very hard,

374
00:22:46,984 --> 00:22:50,718
and these days we are piling them together. So let's

375
00:22:50,734 --> 00:22:54,082
take a look back at the early days of circleci. Like everybody else,

376
00:22:54,136 --> 00:22:57,426
we started out with a monolith. This monolith did many things. In this

377
00:22:57,448 --> 00:23:01,142
example, we're just talking about a couple of them writing to the database and

378
00:23:01,276 --> 00:23:05,682
fetching data from GitHub, or writing to GitHub, things like statuses.

379
00:23:05,826 --> 00:23:09,094
Even in our very early days, the monolith, we would have had at least two

380
00:23:09,132 --> 00:23:12,666
instances for redundancy, resiliency. These are very very

381
00:23:12,688 --> 00:23:16,554
early days, but ultimately we ended up with much more than two and

382
00:23:16,592 --> 00:23:19,706
far more than even on this diagram. But at some point it

383
00:23:19,728 --> 00:23:23,278
becomes a bit repetitive and we got to a point where each of

384
00:23:23,284 --> 00:23:26,622
these monoliths was effectively thinking of itself still as the

385
00:23:26,676 --> 00:23:30,698
owner of all of the work. And so the way that jobs

386
00:23:30,714 --> 00:23:34,382
were distributed was an individual monolith would talk to the database, take the next

387
00:23:34,436 --> 00:23:37,346
job, and try to start it. But there was a check to make sure that

388
00:23:37,368 --> 00:23:40,946
there wasn't any contention, no one else had taken that job. And at a

389
00:23:40,968 --> 00:23:44,802
certain level there were so many attempts to take the same job

390
00:23:44,936 --> 00:23:48,546
that we were losing the opportunity to process our queue effectively. So we

391
00:23:48,568 --> 00:23:52,134
reached a point where we couldn't really scale any further, which is not great as

392
00:23:52,172 --> 00:23:55,366
a business. So we took a fairly simple approach, CTO solving this problem, because we

393
00:23:55,388 --> 00:23:58,998
were under time constraints. And the first simple approach was to

394
00:23:59,084 --> 00:24:02,666
take a version or a copy effectively of this monolith and

395
00:24:02,688 --> 00:24:06,086
run it in a slightly different role, meaning it executed

396
00:24:06,118 --> 00:24:09,542
the work of determining whether or not a job should be processed

397
00:24:09,606 --> 00:24:13,418
and distributing that out to one of the other instances,

398
00:24:13,514 --> 00:24:16,654
rather than letting each instance make its own decisions about what

399
00:24:16,692 --> 00:24:20,654
work should be done. Now, due to time constraints, as I mentioned,

400
00:24:20,772 --> 00:24:24,522
this was effectively another copy of the monolith

401
00:24:24,666 --> 00:24:28,494
that was started up with instructions to only do this, and all the other instances

402
00:24:28,542 --> 00:24:31,874
were started up with instructions not to do that, but it was basically the same

403
00:24:31,912 --> 00:24:35,214
code base. And so now when it comes to statuses,

404
00:24:35,342 --> 00:24:38,718
you have this dispatcher, which is an instance of the monolith writing

405
00:24:38,734 --> 00:24:42,022
to GitHub and then the monolith doing the work, also writing to GitHub, they write

406
00:24:42,076 --> 00:24:44,886
different statuses based on where they are in different parts of the job. And that

407
00:24:44,908 --> 00:24:48,742
was basically because that code path was where those things happened.

408
00:24:48,876 --> 00:24:51,494
So if we dig into one of those a little bit and look at what

409
00:24:51,532 --> 00:24:55,386
happens in that original process, it's a little more complicated, which is within the

410
00:24:55,408 --> 00:24:58,874
monolith, we have a concept of a build, which is the full piece of work

411
00:24:58,912 --> 00:25:01,834
that we're doing or at the time that we were doing, and we might change

412
00:25:01,872 --> 00:25:06,106
the status of that from requested to queued, from queued

413
00:25:06,138 --> 00:25:10,090
to running, from running to completed, passed or failed. Pretty straightforward.

414
00:25:10,250 --> 00:25:13,758
And we would do that by writing to the database. But instead of also writing

415
00:25:13,854 --> 00:25:17,294
to GitHub, which is an external system, there's network issues and retry

416
00:25:17,342 --> 00:25:21,342
problems and timing issues. We had a watcher,

417
00:25:21,406 --> 00:25:24,382
which effectively was an asynchronous process, identifying,

418
00:25:24,446 --> 00:25:27,826
oh, something has changed on the build, and therefore I'm going to go do

419
00:25:27,848 --> 00:25:31,190
this work. And sort of an inverse of a pub sub sort of model,

420
00:25:31,260 --> 00:25:34,710
but really a concurrency model that allows us to continue

421
00:25:34,780 --> 00:25:37,986
doing the work on the build, knowing that the status will get updated

422
00:25:38,018 --> 00:25:41,386
to GitHub as soon as possible. But the customer would prefer that the

423
00:25:41,408 --> 00:25:44,874
build get run than that we wait on. Our ability to write

424
00:25:44,912 --> 00:25:48,486
that status makes great sense. Fairly straightforward programming

425
00:25:48,518 --> 00:25:51,402
model, plus or minus the fact that concurrency is always hard,

426
00:25:51,536 --> 00:25:55,002
and everything happening inside of that one instance of the monolith.

427
00:25:55,146 --> 00:25:58,846
Now introduce the dispatcher. So the dispatcher is the first thing to see

428
00:25:58,868 --> 00:26:02,094
that build, and it is again using this effectively same code

429
00:26:02,132 --> 00:26:05,738
base writes a build, notices that the build is now queued,

430
00:26:05,834 --> 00:26:09,118
or writes a status that the build is now queued and ready for processing,

431
00:26:09,134 --> 00:26:13,186
or has been handed off to a machine and has started processing. And then one

432
00:26:13,208 --> 00:26:17,074
of these monoliths that receives the work, executes the build,

433
00:26:17,272 --> 00:26:20,598
and updates the status again, which then gets picked up by a

434
00:26:20,604 --> 00:26:24,066
concurrent reader that goes and does the work of writing to GitHub,

435
00:26:24,258 --> 00:26:28,290
which is great under normal conditions. However, it's highly

436
00:26:28,370 --> 00:26:31,946
possible. It certainly is possible. We know it to be possible

437
00:26:32,128 --> 00:26:35,606
for the dispatcher to be under a great degree

438
00:26:35,638 --> 00:26:38,682
of load, because it's processing every job coming into the system,

439
00:26:38,736 --> 00:26:42,234
or a small like maybe there's a few of these. So it's processing a huge

440
00:26:42,272 --> 00:26:45,722
percentage of the jobs coming into the system and can be very busy

441
00:26:45,786 --> 00:26:48,954
on its rights. And then the instance of the monolith,

442
00:26:49,002 --> 00:26:53,066
the builder we'll call it, is going to pick up that work and execute

443
00:26:53,098 --> 00:26:56,994
it and the work might be very small, very short, and then

444
00:26:57,032 --> 00:27:00,626
deliver its status. And its status watcher could be very

445
00:27:00,728 --> 00:27:04,514
quiet because there's only a few builds running on any particular

446
00:27:04,632 --> 00:27:08,754
builder. So the net result is that the completed

447
00:27:08,802 --> 00:27:12,278
status can actually get to GitHub before the starting

448
00:27:12,364 --> 00:27:16,306
status, and GitHub doesn't understand what we're doing enough to determine

449
00:27:16,338 --> 00:27:20,262
that those are out of order and we are not coordinating

450
00:27:20,326 --> 00:27:24,534
in this particular model. So we send to GitHub a completed

451
00:27:24,582 --> 00:27:28,586
status, and then we send a starting status which reverts the

452
00:27:28,608 --> 00:27:32,498
pull request and the status of the pull request to incomplete

453
00:27:32,614 --> 00:27:36,506
in a way that can never be completed. This is the worst kind of waiting.

454
00:27:36,538 --> 00:27:41,034
This is waiting forever. And ultimately we ended up with customer tickets

455
00:27:41,082 --> 00:27:44,426
saying my build cannot be completed or my build was completed,

456
00:27:44,458 --> 00:27:48,014
but I never got this status. Which is another interesting thing about concurrency.

457
00:27:48,142 --> 00:27:51,954
No one told us you're setting the complete status before you set the

458
00:27:51,992 --> 00:27:55,502
starting status. They said you're never setting the complete status because that's what a customer

459
00:27:55,576 --> 00:27:59,554
sees, because they were usually so close together and they were unable

460
00:27:59,602 --> 00:28:03,122
to merge their work. So this minor concurrency

461
00:28:03,186 --> 00:28:07,266
issue on our side resulted in our customers unable

462
00:28:07,298 --> 00:28:10,914
to complete their work. So we ended up having to go find a model for

463
00:28:10,972 --> 00:28:14,778
coordinating that work and ensuring that the sequencing happened in

464
00:28:14,784 --> 00:28:18,298
a way that was obviously no longer guaranteed within that single watcher on the

465
00:28:18,304 --> 00:28:21,706
monolith, but had to be coordinated and guaranteed across

466
00:28:21,808 --> 00:28:25,486
multiple systems in the platform. So I would say services

467
00:28:25,588 --> 00:28:28,878
beget services. When you start to break apart your system,

468
00:28:28,964 --> 00:28:32,238
you end up with more and more systems, often trying to

469
00:28:32,244 --> 00:28:35,234
do the work of coordinating the systems that you have.

470
00:28:35,432 --> 00:28:39,442
And my takeaway in this case is that distributed systems really

471
00:28:39,496 --> 00:28:43,234
are concurrency. There's no world, well, there's a very

472
00:28:43,272 --> 00:28:46,918
small world in which you can build out a complex distributed system without

473
00:28:47,004 --> 00:28:50,950
paying any attention to concurrency. It's very likely going to end up being

474
00:28:51,020 --> 00:28:54,690
a parameter that you deal with because you're trying to handle complexity,

475
00:28:54,770 --> 00:28:58,274
resiliency, breakdowns in the communication network,

476
00:28:58,322 --> 00:29:02,362
whatever it might be. There is going to be concurrency in the conversations between

477
00:29:02,416 --> 00:29:06,234
your systems, and so you want to pay attention to that and manage for it

478
00:29:06,272 --> 00:29:10,140
and use it when it is most beneficial, but understand the cost.

479
00:29:10,590 --> 00:29:14,122
So, to summarize, it's a great time to be a developer.

480
00:29:14,186 --> 00:29:17,706
We are able to build on top of amazing systems

481
00:29:17,738 --> 00:29:21,166
that do amazing things and focus our

482
00:29:21,188 --> 00:29:24,678
time and attention on delivering value to our customers, building the systems

483
00:29:24,714 --> 00:29:28,734
that we're really excited about building in order to support businesses that we're excited

484
00:29:28,782 --> 00:29:32,754
about building, and all of that is novel and new

485
00:29:32,792 --> 00:29:36,386
to us and very, very cool. On the other hand,

486
00:29:36,488 --> 00:29:40,582
it's important to pay attention to what's happening. So do the simple thing,

487
00:29:40,716 --> 00:29:44,422
because that will help you get something out faster. But make sure you understand

488
00:29:44,556 --> 00:29:48,246
the simple thing that you're doing. Understand the tradeoff that you're making so that

489
00:29:48,268 --> 00:29:51,766
you'll know when that tradeoff will expire and you will

490
00:29:51,788 --> 00:29:54,938
want to make a different decision at a different point in the future.

491
00:29:55,104 --> 00:29:58,806
Always consider the constraints of your tools. Think about what the designers

492
00:29:58,838 --> 00:30:01,882
would have had to think about when they built that, and whether that's the case

493
00:30:01,936 --> 00:30:05,262
that you have. If they're not solving for your case, you either want to change

494
00:30:05,316 --> 00:30:08,698
the shape of your case to match theirs or find some mitigating

495
00:30:08,794 --> 00:30:11,934
approaches that will allow your problem CTO fit

496
00:30:11,972 --> 00:30:15,486
into the box of their solution and finally manage the complexity of

497
00:30:15,508 --> 00:30:18,810
distribution. Building distributed systems brings a lot of advantages,

498
00:30:18,890 --> 00:30:22,478
but as soon as we start, we're making the conscious decision, or it should be

499
00:30:22,484 --> 00:30:26,406
a conscious decision, to take on additional city, and we have to know that

500
00:30:26,428 --> 00:30:30,246
we're ready for that and that it's warranted for the particular problem that

501
00:30:30,268 --> 00:30:33,606
we are solving. Thanks so much for listening. And if you find these kinds of

502
00:30:33,628 --> 00:30:38,020
problems interesting, we're always looking to higher grade folks, so come visit us@circleci.com.

