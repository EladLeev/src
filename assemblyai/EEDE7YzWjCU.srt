1
00:00:25,410 --> 00:00:28,838
You. Hey all, thank you

2
00:00:28,844 --> 00:00:32,534
very much for tuning into my talk. And thank you conf 42 for

3
00:00:32,572 --> 00:00:35,990
putting this virtual event together. Today I'm going to be

4
00:00:36,060 --> 00:00:39,570
talking about sprinkles of chaos and fires

5
00:00:39,650 --> 00:00:43,414
and things that can happen in the kitchen. How is it that we can take

6
00:00:43,452 --> 00:00:46,854
a moment to learn in those situations? And what are those

7
00:00:46,892 --> 00:00:50,302
learning methods that we use in the kitchen that we can actually

8
00:00:50,356 --> 00:00:53,690
go ahead and apply to building reliable,

9
00:00:53,770 --> 00:00:57,310
complex applications and systems? Today's first

10
00:00:57,380 --> 00:01:01,038
question is, how did you learn how to cook? Are you someone

11
00:01:01,124 --> 00:01:04,234
that had to learn by watching others cook?

12
00:01:04,282 --> 00:01:08,146
Whether it was YouTube tutorials, cooking shows, watching a

13
00:01:08,168 --> 00:01:11,842
family member, are you someone that had to learn by actually doing

14
00:01:11,896 --> 00:01:15,278
some hands on and actually attempting some of those recipes?

15
00:01:15,374 --> 00:01:18,610
And are you someone that just needs to have feedback

16
00:01:18,690 --> 00:01:22,262
early and often in the cooking process to be able to know

17
00:01:22,316 --> 00:01:25,558
that you're doing things right? This might just be just asking

18
00:01:25,644 --> 00:01:29,302
yourselves as you cook, how much salt am I supposed to be using?

19
00:01:29,436 --> 00:01:32,186
How much temperature do I need to run this on?

20
00:01:32,288 --> 00:01:35,450
Or are you one of those folks that had to use a fire

21
00:01:35,520 --> 00:01:39,606
extinguisher to learn? There's no right or wrong answer. Everyone learns

22
00:01:39,638 --> 00:01:43,614
differently. And that's why I want to kick off today's talk with

23
00:01:43,652 --> 00:01:47,582
this question. How do you learn? Are you someone that needs

24
00:01:47,636 --> 00:01:51,006
a very specific set of methods in

25
00:01:51,028 --> 00:01:54,334
order to pick up a concept? And when we bring it back to

26
00:01:54,372 --> 00:01:58,194
not cooking topics, what is the best way that you learn?

27
00:01:58,312 --> 00:02:01,586
Are you someone that does need that content? Are you someone that

28
00:02:01,608 --> 00:02:05,218
needs that hands on learning and be able to apply it?

29
00:02:05,304 --> 00:02:08,850
We see some folks really go to a lot of conferences

30
00:02:08,930 --> 00:02:13,142
in order for them to learn. A lot of them want to just watch

31
00:02:13,276 --> 00:02:16,546
YouTube content and go through tutorials and read blog

32
00:02:16,578 --> 00:02:19,994
posts in order to get an understanding of a technology,

33
00:02:20,192 --> 00:02:23,542
a different tool, or just take a deep dive

34
00:02:23,606 --> 00:02:27,274
into a certain technology topic. And I know for

35
00:02:27,312 --> 00:02:30,874
me, my favorite way was building and breaking. I know

36
00:02:30,912 --> 00:02:34,606
I wanted to always get hands on learning and then I had

37
00:02:34,628 --> 00:02:37,806
to break it and be able to learn how to debug it and be able

38
00:02:37,828 --> 00:02:41,070
to share a little bit upon that. So I am

39
00:02:41,140 --> 00:02:44,626
talking about the kitchen. I do have to bring it back to things that

40
00:02:44,648 --> 00:02:48,046
in the kitchen. How is it that I, my cooking

41
00:02:48,158 --> 00:02:51,906
noncareer, have learned that food taste is good

42
00:02:52,008 --> 00:02:55,854
for me? I have to spend a lot of time tasting

43
00:02:55,902 --> 00:02:59,782
as I cook, whether it's as I'm seasoning or just trying

44
00:02:59,836 --> 00:03:03,206
to make sure that the food is going to taste out tasty and

45
00:03:03,228 --> 00:03:07,270
that I cook the shrimp and the chicken at the proper temperatures, it comes

46
00:03:07,340 --> 00:03:10,642
to that. But the biggest portion

47
00:03:10,706 --> 00:03:13,958
that happens to me learning how to cook is that I'm

48
00:03:13,974 --> 00:03:17,850
not someone that likes cooking for one. Cooking for myself is not

49
00:03:17,920 --> 00:03:21,494
fun. For me to actually be able to learn and have growth

50
00:03:21,542 --> 00:03:24,846
in this cooking space, I have to cook for others. And as

51
00:03:24,868 --> 00:03:28,314
I cook, I do spend a lot of time reading

52
00:03:28,362 --> 00:03:32,302
content, watching YouTube tutorials, and I end up meshing, like four to five

53
00:03:32,356 --> 00:03:36,046
recipes together. But I'm someone

54
00:03:36,148 --> 00:03:39,426
that has to taste the food as I go. And I

55
00:03:39,448 --> 00:03:42,594
brought that example of, am I using enough salt, or is this

56
00:03:42,632 --> 00:03:45,806
too much salt, or is this too much salt that I need to throw

57
00:03:45,838 --> 00:03:49,622
away my plate and startle over? It goes back to

58
00:03:49,676 --> 00:03:53,798
me learning that I hates to go ask for feedback early and often.

59
00:03:53,964 --> 00:03:57,734
And that's okay. It's you having to learn what works best for

60
00:03:57,772 --> 00:04:01,402
you. And sometimes you're trying to learn a new plate. You might

61
00:04:01,456 --> 00:04:04,810
have to burn it one time, two times, three times,

62
00:04:04,880 --> 00:04:08,790
until you start getting the handle of the recipe and the cooking methods

63
00:04:08,870 --> 00:04:13,146
that you need to use. So, yes, Anna, I'm at a tech conference,

64
00:04:13,258 --> 00:04:17,390
supposed to be talking about chaos engineering. Can I stop talking about.

65
00:04:17,540 --> 00:04:20,622
Yes. Yes, I will. I want to bring it back

66
00:04:20,676 --> 00:04:23,738
to this. There's a lot of beauty in cooking,

67
00:04:23,834 --> 00:04:27,346
and that is because we can learn. We can constantly take a

68
00:04:27,368 --> 00:04:31,074
step back and improve. When I cook, I share that I

69
00:04:31,112 --> 00:04:34,690
love tasting the plates as I go. This is something

70
00:04:34,760 --> 00:04:38,802
very similar to what we do in building our applications.

71
00:04:38,946 --> 00:04:42,194
We want to go ahead and observe and do gradual

72
00:04:42,242 --> 00:04:45,686
rollouts of our applications, whether it's perfecting a

73
00:04:45,708 --> 00:04:49,330
recipe before you show it to a loved one, or whether

74
00:04:49,420 --> 00:04:52,986
it's making sure that you take out the chicken from

75
00:04:53,008 --> 00:04:56,086
the pan and make sure that it's actually cooked properly.

76
00:04:56,278 --> 00:04:59,626
And I also mentioned that other portion that I

77
00:04:59,648 --> 00:05:02,750
love cooking for others. And that is because

78
00:05:02,900 --> 00:05:06,366
my focus is on that end user experience,

79
00:05:06,548 --> 00:05:10,922
those customers. And this is exactly that beauty where experimentation

80
00:05:10,986 --> 00:05:14,786
comes in. Whether I'm actually trying to add a little sweeter kick or

81
00:05:14,808 --> 00:05:18,782
a spicier kick to my plate, or I'm just trying to get my empanadas

82
00:05:18,846 --> 00:05:22,578
crispier. And sometimes, and often,

83
00:05:22,744 --> 00:05:26,694
this actually happens in my house, I actually need to

84
00:05:26,892 --> 00:05:30,534
burn my plate in order for me to learn. This is where we

85
00:05:30,572 --> 00:05:34,674
go ahead and we take that concept into building applications

86
00:05:34,802 --> 00:05:38,550
as replicating past incidents we hates to learn

87
00:05:38,620 --> 00:05:41,798
and practice in order to perfect a skill.

88
00:05:41,974 --> 00:05:46,026
And if that means having to use a fire extinguisher along the

89
00:05:46,048 --> 00:05:49,514
way or throw away your plate, that's okay, because you're doing this

90
00:05:49,552 --> 00:05:52,410
for learning. With that, I wanted to take a moment,

91
00:05:52,480 --> 00:05:55,866
introduce myself. My name is Ana. Ana. Ana.

92
00:05:55,978 --> 00:05:59,454
Ana margarita Medina, senior chaos engineer at Gremlin. I love

93
00:05:59,492 --> 00:06:03,466
introducing myself as a self taught engineer. I started coding

94
00:06:03,498 --> 00:06:06,594
in 2007, got a chance to do a lot of front

95
00:06:06,632 --> 00:06:09,906
end work, moved on to learn a little bit of back end,

96
00:06:10,008 --> 00:06:13,486
and I somehow transitioned to build iOS and Android

97
00:06:13,518 --> 00:06:16,674
applications. In 2016, I got

98
00:06:16,712 --> 00:06:20,450
a chance to come into this beautiful world of site reliability

99
00:06:20,530 --> 00:06:23,622
engineering and get a chance to actually learn.

100
00:06:23,756 --> 00:06:27,234
Where is it that my code runs on? How do I make sure this stays

101
00:06:27,282 --> 00:06:31,302
up and down? And that is also when I picked up chaos

102
00:06:31,366 --> 00:06:34,954
engineering. And it was that moment where I was like, oh no.

103
00:06:35,072 --> 00:06:38,282
I love burning by building and breaking and being able to take

104
00:06:38,336 --> 00:06:42,106
these concepts and break them down into little chunks.

105
00:06:42,218 --> 00:06:46,010
Whether it was trying to understand Linux capabilities,

106
00:06:46,170 --> 00:06:49,434
a certain application, trying to understand the complexity

107
00:06:49,482 --> 00:06:53,280
of microservices, all those things made it really fun.

108
00:06:53,730 --> 00:06:58,062
And one of the things that really, really matters to me is representation.

109
00:06:58,206 --> 00:07:01,906
If you can't see it, you can't be it. So I love making a

110
00:07:01,928 --> 00:07:06,014
comment about being a Latina. I was born and raised in Costa Rica.

111
00:07:06,142 --> 00:07:09,714
My parents are from Nicaragua. So for any underrepresented

112
00:07:09,762 --> 00:07:12,598
person in tech that's watching this, keep on going.

113
00:07:12,684 --> 00:07:16,342
You got this. To bring it back to today's focus,

114
00:07:16,476 --> 00:07:19,578
we're going to be talking about learning.

115
00:07:19,744 --> 00:07:22,970
And what are those things that we can do every single

116
00:07:23,040 --> 00:07:26,758
day in order to push ourselves past our comfort zone

117
00:07:26,854 --> 00:07:30,058
and take a step into learning. Hopefully all of

118
00:07:30,064 --> 00:07:33,966
you have had a chance to think a little bit more about how do

119
00:07:33,988 --> 00:07:37,950
you learn, what is the best way that you can pick up something new?

120
00:07:38,100 --> 00:07:41,870
And maybe you learn very differently than me, and that's okay.

121
00:07:42,020 --> 00:07:46,114
Maybe I actually didn't even cover the way that you actually like learning.

122
00:07:46,312 --> 00:07:50,210
And I did want to touch upon some of the other ways

123
00:07:50,280 --> 00:07:53,842
that folks do learn. And that could just be by

124
00:07:53,896 --> 00:07:57,910
practicing, whether it's trying to pick up a new instrument and going through

125
00:07:57,980 --> 00:08:01,590
and doing that work to learn it, or just making

126
00:08:01,660 --> 00:08:05,606
sure that you're burning that muscle memory in order for you

127
00:08:05,628 --> 00:08:08,838
to continue doing this practice. And hey,

128
00:08:08,924 --> 00:08:12,346
if you have to use a fire extinguisher or burn yourself in

129
00:08:12,368 --> 00:08:16,234
the oven before learning, I've been there. I just burned myself two

130
00:08:16,272 --> 00:08:19,274
days ago trying to use my cast iron. It's always going to

131
00:08:19,312 --> 00:08:22,702
happen. And that's okay. I am trying to bring this back

132
00:08:22,756 --> 00:08:26,350
to software and technologies and as we know it,

133
00:08:26,420 --> 00:08:30,570
the software and technology that we use every single day breaks

134
00:08:30,730 --> 00:08:34,434
the world that we're building relies more and more on

135
00:08:34,472 --> 00:08:38,386
the stability of naturally brittle technology. The challenge that

136
00:08:38,408 --> 00:08:42,414
we face now is how is it that we continue innovating

137
00:08:42,542 --> 00:08:46,454
and delivering products and services for our customers in

138
00:08:46,492 --> 00:08:50,406
a way that minimizes the risk of failure as

139
00:08:50,428 --> 00:08:54,226
much as possible. And when we talk about delivering

140
00:08:54,258 --> 00:08:57,862
these experiences to our customers, we have to understand

141
00:08:57,996 --> 00:09:01,526
that when we are not able to have applications

142
00:09:01,558 --> 00:09:05,894
and systems that are up, we suffer downtime. And downtime

143
00:09:05,942 --> 00:09:09,322
costs a lot of money. We hates things that happen

144
00:09:09,376 --> 00:09:12,230
during the outage that can be quantifiable,

145
00:09:12,390 --> 00:09:15,130
and those things come down to revenue.

146
00:09:15,290 --> 00:09:18,846
Go and ask your accounting or sales team to try to understand

147
00:09:19,028 --> 00:09:22,542
what are some of those costs that come into play. We also

148
00:09:22,596 --> 00:09:26,302
have the portion of employee productivity as your engineers

149
00:09:26,366 --> 00:09:30,238
are dealing with an outage, they're not working on features

150
00:09:30,334 --> 00:09:34,146
or things to make your product battery. And then that brings us

151
00:09:34,168 --> 00:09:37,974
to things that can happen after the outage, which is that

152
00:09:38,012 --> 00:09:41,174
customer chargebacks. Maybe you're breaking some of those

153
00:09:41,212 --> 00:09:44,742
service level agreements and you have to give money back

154
00:09:44,796 --> 00:09:48,106
to your customers. We have this other bucket that

155
00:09:48,128 --> 00:09:51,450
makes downtime really expensive, and those are those

156
00:09:51,520 --> 00:09:55,194
unquantifiable costs. These things can be seen as

157
00:09:55,232 --> 00:09:58,614
brand deformation, whether it's the media picking

158
00:09:58,662 --> 00:10:02,586
up that your company or systems are down, or maybe it's

159
00:10:02,618 --> 00:10:06,574
just happening all over Twitter. And the thing, too, is that customers

160
00:10:06,692 --> 00:10:10,106
don't want to use broken products or applications.

161
00:10:10,218 --> 00:10:14,722
And sometimes you can actually go ahead and see that happen pretty

162
00:10:14,856 --> 00:10:18,514
easily, especially in the stock market. Overnight, one of those

163
00:10:18,552 --> 00:10:22,194
other portions of unquantifiable costs come down to

164
00:10:22,232 --> 00:10:26,354
employee attrition. People don't want to work at places where they're

165
00:10:26,402 --> 00:10:29,602
constantly going to be firefighting. You're going to suffer

166
00:10:29,666 --> 00:10:32,854
burnout rates that are really, really high.

167
00:10:32,972 --> 00:10:36,850
And word gets around in the tech industry, where folks

168
00:10:36,930 --> 00:10:40,794
talk about this vicious cycle of less people to

169
00:10:40,832 --> 00:10:44,266
handle those incidents, which just leads to a

170
00:10:44,288 --> 00:10:48,054
more burnout. The average company is expected to lose

171
00:10:48,102 --> 00:10:51,630
around $300,000 per hour that they're down

172
00:10:51,780 --> 00:10:56,078
and that number chaos. Nothing to do with their high traffic events or

173
00:10:56,164 --> 00:10:59,902
any new launch that they're coming up with. And when we

174
00:10:59,956 --> 00:11:04,002
talk about building reliable applications, we also

175
00:11:04,056 --> 00:11:07,634
have to understand that the world that we're building is

176
00:11:07,672 --> 00:11:11,074
only getting more complex, which makes it

177
00:11:11,112 --> 00:11:14,942
very difficult for us to operate our applications to

178
00:11:15,016 --> 00:11:18,774
continue being reliable. The pressure for

179
00:11:18,812 --> 00:11:22,722
faster innovation is driving the adoption of new technologies,

180
00:11:22,866 --> 00:11:26,614
whether it's new types of infrastructure, new coding languages and

181
00:11:26,652 --> 00:11:30,266
architectures, or just new processes that we want to get

182
00:11:30,288 --> 00:11:33,750
a handle on. And when we talk about this complexity,

183
00:11:33,830 --> 00:11:37,862
we could also take a step back and understand that the complexity

184
00:11:37,926 --> 00:11:41,334
hasn't always been like this in legacy applications.

185
00:11:41,382 --> 00:11:44,814
When we were doing waterfall processes in our companies,

186
00:11:44,932 --> 00:11:48,942
we only had one release. We only had one thing to care about.

187
00:11:49,076 --> 00:11:52,834
We also only had one service to keep up and running. When we had

188
00:11:52,872 --> 00:11:56,702
monolith architectures, and maybe when we were only managing

189
00:11:56,766 --> 00:12:00,878
hundreds of servers as our organizations were on Prem,

190
00:12:01,054 --> 00:12:04,654
that complexity was a lot smaller. But we've

191
00:12:04,702 --> 00:12:08,018
lifted and shifted and rearchitected our applications,

192
00:12:08,114 --> 00:12:11,922
and now we're in this world where a lot of things are cloud native.

193
00:12:12,066 --> 00:12:15,814
And thankfully, we've seen a lot of organizations adopt things

194
00:12:15,852 --> 00:12:19,254
like DevOps, and that allows for us to have daily

195
00:12:19,302 --> 00:12:23,354
releases that allow for us to deliver better experiences to

196
00:12:23,392 --> 00:12:27,322
our customers. We now have microservices. So instead

197
00:12:27,456 --> 00:12:30,666
of having one service to keep up and running during all

198
00:12:30,688 --> 00:12:34,574
this time, we now have hundreds of services to keep up.

199
00:12:34,692 --> 00:12:38,222
And all of those have interdependencies within

200
00:12:38,276 --> 00:12:42,014
each other or other third party vendors. We've also seen

201
00:12:42,052 --> 00:12:45,374
that in this cloud native world, we now don't

202
00:12:45,422 --> 00:12:49,266
only just have hundreds of servers to take care of,

203
00:12:49,368 --> 00:12:52,786
but we have hundreds of thousands of Kubernetes resources that

204
00:12:52,808 --> 00:12:56,854
we need to make sure are all reliable and tested, and that we have

205
00:12:56,892 --> 00:13:00,518
documentation on how to keep them up and running. So with this current

206
00:13:00,604 --> 00:13:04,022
complexity of our systems, we really, really need

207
00:13:04,076 --> 00:13:07,366
experimentation. Folks just want to move fast and

208
00:13:07,388 --> 00:13:11,146
break things. But what if I tell you that there is a better world?

209
00:13:11,248 --> 00:13:14,682
A world where you can just slow down just a bit and spend

210
00:13:14,736 --> 00:13:18,250
more time experimenting and verifying that you're building

211
00:13:18,320 --> 00:13:21,538
things reliably, specifically for our users

212
00:13:21,574 --> 00:13:25,134
to constantly be happy with our products, our services,

213
00:13:25,252 --> 00:13:28,606
and continue being customers of our companies. At the end of

214
00:13:28,628 --> 00:13:32,078
the day, we're building a complex and distributed system,

215
00:13:32,244 --> 00:13:35,934
and there are things that we must test for or you will suffer

216
00:13:35,982 --> 00:13:39,106
an outage. There's failures that you might see in the

217
00:13:39,128 --> 00:13:42,482
industry that happen every few months, that happen once

218
00:13:42,536 --> 00:13:46,114
a year, or just outages that get so

219
00:13:46,152 --> 00:13:50,118
large that we can take a moment to actually learn from other companies

220
00:13:50,204 --> 00:13:54,226
pain points and make our systems better. And that brings

221
00:13:54,258 --> 00:13:57,414
me to my favorite ingredient for today's talk,

222
00:13:57,532 --> 00:14:01,146
chaos engineering. We're going to talk about this the entire rest

223
00:14:01,168 --> 00:14:05,034
of the conversation. The definition of chaos engineering is that

224
00:14:05,072 --> 00:14:08,634
this is thoughtful, planned experiments designed to

225
00:14:08,672 --> 00:14:12,550
reveal the weakness in our systems. And I have bolded the word

226
00:14:12,640 --> 00:14:16,106
thoughtful, planned, and reveal weakness in our systems.

227
00:14:16,218 --> 00:14:19,902
Because this is not about just breaking production for fun or

228
00:14:19,956 --> 00:14:24,034
making sure that the team that you work with can actually

229
00:14:24,232 --> 00:14:28,066
handle their on call rotation. This is about doing it in

230
00:14:28,088 --> 00:14:31,394
a very thoughtful plan way where you communicate and

231
00:14:31,432 --> 00:14:35,570
you build that maturity. And the purpose is not just

232
00:14:35,720 --> 00:14:39,654
for breaking things. We do this with the purpose of breaking things on

233
00:14:39,692 --> 00:14:43,494
purpose, to learn from those failure points and improve our

234
00:14:43,532 --> 00:14:47,074
applications. As we talk about chaos engineering,

235
00:14:47,122 --> 00:14:50,426
I want to take a step back and just explain some of

236
00:14:50,448 --> 00:14:54,394
the terminology that's going to come up in today's talk. We're going to be

237
00:14:54,432 --> 00:14:58,694
using experiments. This goes back to using the scientific method

238
00:14:58,742 --> 00:15:02,154
to go ahead and learn from our systems. By following

239
00:15:02,202 --> 00:15:05,790
that scientific method that we learned many years ago,

240
00:15:05,940 --> 00:15:09,578
we have that fundamental of creating a hypothesis.

241
00:15:09,754 --> 00:15:13,986
If such failure happens to my system, this is what I expect

242
00:15:14,088 --> 00:15:18,082
will happen. We also have some safeguards that come into play

243
00:15:18,136 --> 00:15:21,294
with chaos engineering, such as blast radius.

244
00:15:21,422 --> 00:15:24,594
Blast radius is that surface area that you're running that

245
00:15:24,632 --> 00:15:27,890
experiment on. This can be seen as one server,

246
00:15:27,970 --> 00:15:31,458
ten servers, 10% of your infrastructure,

247
00:15:31,634 --> 00:15:35,426
only one service out of your 100 microservice architecture.

248
00:15:35,538 --> 00:15:38,986
That is that blast radius. The other terminology that

249
00:15:39,008 --> 00:15:42,438
we have, very similar to blast radius, is magnitude.

250
00:15:42,534 --> 00:15:46,438
Magnitude is the intensity of the chaos engineering experiment

251
00:15:46,534 --> 00:15:49,914
that you're unleashing. This can be seen as

252
00:15:50,112 --> 00:15:54,318
increasing cpu by 10%, then gradually going to 20%,

253
00:15:54,404 --> 00:15:58,238
30%, and such. Or it can be seen as just

254
00:15:58,324 --> 00:16:01,566
injecting 100 milliseconds of latency, going up

255
00:16:01,588 --> 00:16:05,726
to 300, and incrementing all the way to 800 milliseconds of latency.

256
00:16:05,838 --> 00:16:09,534
That is your magnitude. While using the blast radius and magnitude,

257
00:16:09,582 --> 00:16:13,054
you can really tell your experiments to be really thoughtful

258
00:16:13,102 --> 00:16:16,242
and planned. That last term that I want to cover

259
00:16:16,296 --> 00:16:20,134
in this section is abort conditions. Abort conditions are

260
00:16:20,172 --> 00:16:24,006
those conditions that can happen to your systems or things that you

261
00:16:24,028 --> 00:16:27,494
might see in the monitoring or user experience that will tell

262
00:16:27,532 --> 00:16:30,946
you that you need to stop this experiment? This portion is really

263
00:16:30,988 --> 00:16:34,506
critical for creating your application. You want to make sure

264
00:16:34,608 --> 00:16:38,198
to ask yourself, when is it that I stop running this experiment?

265
00:16:38,294 --> 00:16:42,000
When is it that I can make sure that the experiment rolls back?

266
00:16:42,370 --> 00:16:45,774
Now that we've covered the terms, let's actually go through

267
00:16:45,812 --> 00:16:48,842
this process of using the scientific method.

268
00:16:48,986 --> 00:16:52,734
That first one that we start doing is actually observing your

269
00:16:52,772 --> 00:16:56,114
system. Observing your system can actually just be

270
00:16:56,152 --> 00:17:00,146
by pulling up your architecture diagrams, trying to understand how

271
00:17:00,168 --> 00:17:03,970
all of your microservices come together. What is the mental model

272
00:17:04,040 --> 00:17:07,958
that you have of today's application? You can also observe your system

273
00:17:08,044 --> 00:17:11,382
by just understanding the metrics that are coming

274
00:17:11,436 --> 00:17:15,234
in. How is it that this ties into all the other systems

275
00:17:15,362 --> 00:17:18,762
in your application? And then that brings us

276
00:17:18,816 --> 00:17:22,742
to the next step of baselining your metrics,

277
00:17:22,886 --> 00:17:26,710
this can be seen as setting those service level objectives,

278
00:17:26,790 --> 00:17:30,366
service level indicators per service. What is it that

279
00:17:30,388 --> 00:17:34,254
I can see today? Now that I've covered the terminology that

280
00:17:34,292 --> 00:17:36,986
gets used in chaos engineering experiments,

281
00:17:37,098 --> 00:17:40,894
let's actually talk about how this scientific method comes

282
00:17:40,932 --> 00:17:44,254
together. That first step that we take in the chaos

283
00:17:44,302 --> 00:17:47,762
engineering experiment is by taking a step

284
00:17:47,816 --> 00:17:51,554
back and observing our systems. This can be done by

285
00:17:51,592 --> 00:17:54,834
just looking at that architecture diagram, trying to

286
00:17:54,872 --> 00:17:58,546
understand the mental models that you currently have of your application.

287
00:17:58,728 --> 00:18:02,534
Or maybe it's trying to understand how all of your microservices talk

288
00:18:02,572 --> 00:18:06,006
to each other. The next step that we take after that is that we

289
00:18:06,028 --> 00:18:09,878
want to go ahead and understand how our system behaves

290
00:18:09,974 --> 00:18:13,146
under normal conditions. This can be done by

291
00:18:13,168 --> 00:18:16,426
just baselining your metrics. This can also be seen as

292
00:18:16,448 --> 00:18:20,730
a great opportunity to set some service level objectives, set some service

293
00:18:20,800 --> 00:18:25,118
level indicators that allow for you to understand whether your application

294
00:18:25,284 --> 00:18:29,086
is healthy or not. This allows for us to move on to

295
00:18:29,108 --> 00:18:32,810
that next step, forming a hypothesis with the work conditions.

296
00:18:32,890 --> 00:18:36,226
This is one of those important steps that you get a chance to take a

297
00:18:36,248 --> 00:18:39,954
step back and try to understand what is it that I

298
00:18:39,992 --> 00:18:43,378
think that will happen to my application now, but how is it

299
00:18:43,384 --> 00:18:46,706
that I can make sure that we don't cause a failure that

300
00:18:46,728 --> 00:18:50,386
can affect our customers, and we do set those abort conditions

301
00:18:50,418 --> 00:18:54,438
and are ready to take action on them? Then we can actually go ahead

302
00:18:54,524 --> 00:18:57,734
and define that blast radius and magnitude and

303
00:18:57,772 --> 00:19:01,526
say, I want to run a cpu experiment

304
00:19:01,638 --> 00:19:05,462
on just 20% of my infrastructure, and that experiment

305
00:19:05,526 --> 00:19:09,754
is going to increase cpu to have all of the cpu running at

306
00:19:09,792 --> 00:19:13,066
70% in all my hosts. We then go

307
00:19:13,088 --> 00:19:16,478
ahead and we run an experiment. This is that

308
00:19:16,564 --> 00:19:19,406
fun time that you get a chance to do with your team.

309
00:19:19,508 --> 00:19:23,306
But many teams don't always get a chance to run the experiment. That doesn't

310
00:19:23,338 --> 00:19:26,786
mean that they didn't just learn anything from step one all

311
00:19:26,808 --> 00:19:30,930
the way to five. As you run that experiment, you want to take a moment

312
00:19:31,000 --> 00:19:33,874
to analyze those results. You want to understand,

313
00:19:33,992 --> 00:19:37,542
after you've inputted these conditions into your system,

314
00:19:37,676 --> 00:19:40,998
how did it behave? How did this behavior correlate to

315
00:19:41,004 --> 00:19:44,194
the hypothesis that you created? And if your experiment

316
00:19:44,242 --> 00:19:48,006
is successful, go ahead and expand your blast radius,

317
00:19:48,118 --> 00:19:51,754
expand that magnitude, and get ready to run

318
00:19:51,792 --> 00:19:55,114
that experiment once again. And if your experiment was

319
00:19:55,152 --> 00:19:59,018
unsuccessful, hey, that's okay. You just learned something.

320
00:19:59,184 --> 00:20:02,734
Take a moment to actually see what will make your application be more

321
00:20:02,772 --> 00:20:06,542
reliable and work on that. Then go ahead and run

322
00:20:06,596 --> 00:20:10,654
this type of experiment again, just to make sure that the improvements that you've put

323
00:20:10,692 --> 00:20:14,402
in actually help your application's reliability. And that

324
00:20:14,456 --> 00:20:18,066
last step is one of the most important steps that we have

325
00:20:18,088 --> 00:20:22,174
in the chaos engineering process, and that is sharing the results.

326
00:20:22,302 --> 00:20:26,154
This comes into actually sharing the results with your leadership

327
00:20:26,222 --> 00:20:29,558
team across your organization. And I always

328
00:20:29,644 --> 00:20:33,682
take it a step further and say, go ahead and share the results

329
00:20:33,746 --> 00:20:37,458
and share those learnings with the wider communities, whether it's

330
00:20:37,474 --> 00:20:40,886
the chaos engineering community, the open source communities of

331
00:20:40,908 --> 00:20:44,266
the tools that you're burning with, or just any other type of

332
00:20:44,288 --> 00:20:47,386
tech conference, and talk a little bit more about some of the ways that

333
00:20:47,408 --> 00:20:51,354
you've been building and breaking things. I did want to go over some

334
00:20:51,392 --> 00:20:54,798
chaos engineering experiments that we can kind of create,

335
00:20:54,964 --> 00:20:58,254
at least to get you all started in thinking about this.

336
00:20:58,372 --> 00:21:01,518
One of the big ones that I've been seeing across the board,

337
00:21:01,604 --> 00:21:05,362
whether it's folks on containerized Kubernetes environments or

338
00:21:05,416 --> 00:21:09,022
those that have adopted cloud technologies, or hopeful

339
00:21:09,086 --> 00:21:12,930
that their applications will scale with regular use,

340
00:21:13,080 --> 00:21:16,958
is making sure that you're planning and you're testing those resource limits.

341
00:21:17,054 --> 00:21:20,614
On Kubernetes, resource limits are in order for you to

342
00:21:20,652 --> 00:21:24,246
make sure that things are scaling properly. But we can also take it a

343
00:21:24,268 --> 00:21:27,894
step back and think, how is it that we're making sure that

344
00:21:27,932 --> 00:21:31,522
when we're using the cloud technologies, auto scaling is actually

345
00:21:31,596 --> 00:21:35,194
set up and that you actually have an understanding on how

346
00:21:35,232 --> 00:21:38,218
long it takes auto scaling to bring a new node in,

347
00:21:38,304 --> 00:21:41,738
how long it takes for that new node to join the rest of them,

348
00:21:41,824 --> 00:21:45,290
and for it to report back to your proper monitoring

349
00:21:45,370 --> 00:21:49,214
observability dashboards in order for you to make sure that things are up

350
00:21:49,252 --> 00:21:52,606
and running. And these things can actually be implemented in

351
00:21:52,628 --> 00:21:55,954
a chaos engineering experiment by just having a

352
00:21:55,992 --> 00:21:59,234
resource impact. So for some of the auto scaling work that I

353
00:21:59,272 --> 00:22:02,834
do, I always start out by just saying, go ahead and run

354
00:22:02,872 --> 00:22:06,994
a chaos engineering experiment and have that increase be

355
00:22:07,112 --> 00:22:10,726
up to 60% of cpu on your servers, and go

356
00:22:10,748 --> 00:22:14,086
ahead and make sure to run that small experiment on all of

357
00:22:14,108 --> 00:22:17,990
your hosts and you create those abort conditions that

358
00:22:18,060 --> 00:22:21,558
you'll stop that experiment if your application is not responsive,

359
00:22:21,654 --> 00:22:25,142
if you start seeing HTTP 400, 500 errors,

360
00:22:25,206 --> 00:22:28,906
anything that doesn't feel right for the customer, and you

361
00:22:28,928 --> 00:22:32,782
can also take a step and understand what were the metrics that you were looking

362
00:22:32,836 --> 00:22:36,698
at for your systems. It might be things like response rates

363
00:22:36,794 --> 00:22:39,934
or traffic rates slowing down. When we

364
00:22:39,972 --> 00:22:43,902
think about the hypothesis for an experiment like this, we want to ask

365
00:22:43,956 --> 00:22:47,950
of what is it that's going to happen to my system when cpu increases,

366
00:22:48,110 --> 00:22:51,186
do I expect that in 2 minutes the new node will

367
00:22:51,208 --> 00:22:54,834
be up and running? Or do I expect that traffic from

368
00:22:54,872 --> 00:22:58,182
one server is also going to be routed for another one

369
00:22:58,236 --> 00:23:01,862
because this new node is actually coming up. One of the other ways

370
00:23:01,916 --> 00:23:05,766
that we can think about chaos engineering experiments is trying to

371
00:23:05,788 --> 00:23:08,906
understand what happens to our systems when one

372
00:23:08,928 --> 00:23:12,198
of our dependencies fails. This can be a dependency

373
00:23:12,294 --> 00:23:16,694
on an image provider, a third party vendor that actually processes

374
00:23:16,742 --> 00:23:20,454
payments. When our application can't access that resource.

375
00:23:20,582 --> 00:23:24,430
What does your user see? What is the user experience like?

376
00:23:24,580 --> 00:23:28,190
And with these type of experiments we get a chance to do things

377
00:23:28,260 --> 00:23:31,934
like inject latency, block off traffic to

378
00:23:31,972 --> 00:23:35,982
a certain port application API

379
00:23:36,046 --> 00:23:40,274
URL, and we can start doing that to try to understand

380
00:23:40,472 --> 00:23:43,310
how is it that the UI handles this failure,

381
00:23:43,470 --> 00:23:47,326
how is it that our entire microservices are coupled

382
00:23:47,358 --> 00:23:51,222
in that this becomes a single point of failure that can actually

383
00:23:51,276 --> 00:23:55,334
bring us down for a while? And when I set the slides up,

384
00:23:55,452 --> 00:23:58,882
the experiment that comes to mind is something running on a Kubernetes

385
00:23:58,946 --> 00:24:02,426
environment that on your architecture diagram might just not

386
00:24:02,448 --> 00:24:05,994
be seen as a primary dependency. We see it as

387
00:24:06,032 --> 00:24:09,066
just a caching layer and that is this redis cart that I

388
00:24:09,088 --> 00:24:12,718
have written down here. That hypothesis comes down to me thinking

389
00:24:12,804 --> 00:24:16,474
that when my caching layer has a latency increase,

390
00:24:16,602 --> 00:24:20,526
this is just my caching layer. The application should also still continue

391
00:24:20,628 --> 00:24:24,494
working without any issues. If you're interested in learning the effects about this

392
00:24:24,532 --> 00:24:28,066
experiment, come to one of my boot camps and you'll get a chance to understand

393
00:24:28,168 --> 00:24:32,066
how this also all couples down. So I am in a kitchen talk

394
00:24:32,168 --> 00:24:36,054
and I now have to talk about that recipe that I do have for

395
00:24:36,092 --> 00:24:39,814
building reliable applications. It first start off by

396
00:24:39,852 --> 00:24:44,098
making sure that we can have availability, that we have capacity

397
00:24:44,194 --> 00:24:47,446
to actually run our applications at the large scale that

398
00:24:47,468 --> 00:24:51,062
we do need to. When we're talking about cloud native

399
00:24:51,126 --> 00:24:54,714
applications, we have to make sure that we're ready for

400
00:24:54,752 --> 00:24:59,098
failure, whether it's an entire region having issues or

401
00:24:59,184 --> 00:25:02,666
that we're ready to fail over from one data center to

402
00:25:02,688 --> 00:25:06,346
the other, from one cloud to the other. If you're multicloud

403
00:25:06,378 --> 00:25:10,334
hybrid and it takes it back to that last step where you

404
00:25:10,372 --> 00:25:14,450
also want to make sure that you have some form of disaster recovery business

405
00:25:14,520 --> 00:25:18,002
continuity plan and that you've been exercising those

406
00:25:18,056 --> 00:25:21,410
plans in a frequent manner, it also comes

407
00:25:21,480 --> 00:25:24,754
down to that portion of reliability, making sure

408
00:25:24,792 --> 00:25:27,942
that our systems can sustain these failures that happen

409
00:25:27,996 --> 00:25:31,334
day to day to our applications. It comes to that

410
00:25:31,372 --> 00:25:34,518
moment where we want our engineering teams to actually

411
00:25:34,604 --> 00:25:38,678
experiment and try to build better products and features

412
00:25:38,774 --> 00:25:42,182
and that we also get a chance to continue innovating.

413
00:25:42,326 --> 00:25:45,546
As I've mentioned multiple times, practice is one

414
00:25:45,568 --> 00:25:49,030
of these key terms in building resilient applications.

415
00:25:49,110 --> 00:25:53,082
We're building really complex things that have a lot of dependencies.

416
00:25:53,226 --> 00:25:57,230
By doing practice, we are able to understand a little bit more about

417
00:25:57,300 --> 00:26:00,798
how all these services and tools play together.

418
00:26:00,964 --> 00:26:04,778
But your team is also going to have a chance to be better equipped

419
00:26:04,874 --> 00:26:08,594
to go back to that point of reliability and keeping things up and

420
00:26:08,632 --> 00:26:12,194
running. So the best thing is that all these things get

421
00:26:12,232 --> 00:26:15,734
a chance to come together and be tested and worked on

422
00:26:15,772 --> 00:26:19,826
and constantly improved on. If you do perform some chaos engineering

423
00:26:19,858 --> 00:26:23,298
experiments, you get a chance to understand the failures,

424
00:26:23,394 --> 00:26:26,930
constantly be learning from them, and continuously

425
00:26:27,010 --> 00:26:30,374
improve on those issues. People and processes,

426
00:26:30,502 --> 00:26:34,074
portions of technologies. Our applications live in

427
00:26:34,112 --> 00:26:37,642
such a distributed architecture that things are always

428
00:26:37,696 --> 00:26:41,274
going to be breaking. In complex systems, you have

429
00:26:41,312 --> 00:26:44,414
to always assume that it will break, or we take

430
00:26:44,452 --> 00:26:48,062
it back to Murphy's law. Anything that can go wrong

431
00:26:48,196 --> 00:26:51,754
will go wrong. We have to prepare for those failures,

432
00:26:51,882 --> 00:26:55,918
and we have to always tell ourselves and our teams

433
00:26:56,014 --> 00:26:59,826
always test it, go ahead and break it. Before you go

434
00:26:59,848 --> 00:27:03,326
ahead and implement it, you want to go ahead and battle

435
00:27:03,358 --> 00:27:06,950
test some of the technologies that you're trying to bring into your organization.

436
00:27:07,290 --> 00:27:10,482
This allows for you to understand those dependencies,

437
00:27:10,626 --> 00:27:14,406
those bottlenecks, those black swans that you might not

438
00:27:14,428 --> 00:27:17,814
be able to see until you get a chance to put it all

439
00:27:17,852 --> 00:27:21,706
together with the rest of your applications. You want to understand what

440
00:27:21,728 --> 00:27:25,210
the default parameters of this tool are and

441
00:27:25,280 --> 00:27:28,842
whether or not this actually works straight out of the box.

442
00:27:28,976 --> 00:27:32,618
Is there any security concerns that you need to have in mind with any of

443
00:27:32,624 --> 00:27:36,062
these tools? And how is it that this tool or

444
00:27:36,116 --> 00:27:39,534
application needs to be connected with the rest of

445
00:27:39,572 --> 00:27:43,366
my application in order for me to build it in a reliable manner.

446
00:27:43,498 --> 00:27:46,642
You also want to go ahead and always ask,

447
00:27:46,776 --> 00:27:49,870
what is it that's going to happen when x fails?

448
00:27:50,030 --> 00:27:53,342
X can be any URL,

449
00:27:53,486 --> 00:27:56,822
any API endpoint, any little

450
00:27:56,876 --> 00:28:00,518
box in your architecture diagram, or even just one of

451
00:28:00,524 --> 00:28:03,986
the processes that you have in place. And especially when you're

452
00:28:04,018 --> 00:28:07,410
looking at those architecture diagrams, please ask yourselves,

453
00:28:07,570 --> 00:28:10,730
what is going to happen if this tier two

454
00:28:10,800 --> 00:28:14,742
application goes down. Hopefully you have a good hypothesis

455
00:28:14,806 --> 00:28:18,474
for it. Hopefully you've gotten a chance to practice on

456
00:28:18,512 --> 00:28:21,822
it and ask that hypothesis question.

457
00:28:21,956 --> 00:28:25,502
You also want to take a step forward

458
00:28:25,636 --> 00:28:29,310
and ask, what is it that your organization is doing

459
00:28:29,380 --> 00:28:33,050
day to day to focus on reliability?

460
00:28:33,210 --> 00:28:36,466
This is something that the entire company needs to be focused on in

461
00:28:36,488 --> 00:28:40,414
order to have the uptime that your customers might be needing,

462
00:28:40,542 --> 00:28:44,786
but these might be things that happen behind the scenes, the shadow work.

463
00:28:44,888 --> 00:28:48,690
Or this is you actually picking up technologies like chaos Engineering

464
00:28:48,770 --> 00:28:52,150
to innovate in your engineering workspace. You can also

465
00:28:52,220 --> 00:28:55,414
just start asking what work is being done today

466
00:28:55,612 --> 00:28:59,042
that makes sure that we're actually not regressing

467
00:28:59,106 --> 00:29:02,454
into a past failure, that we're not about to relive

468
00:29:02,502 --> 00:29:06,442
that past incident that you were on call for five months ago,

469
00:29:06,576 --> 00:29:09,734
making sure that you've gone through those euro tickets,

470
00:29:09,862 --> 00:29:13,754
making sure that you've actually gone through your systems

471
00:29:13,882 --> 00:29:17,166
and maybe replayed some of those conditions that caused that

472
00:29:17,188 --> 00:29:20,842
last incident and ask, can our system sustain

473
00:29:20,906 --> 00:29:24,002
such failures if there were to happen again? And you

474
00:29:24,056 --> 00:29:27,586
want to understand how your system behaves on a day to

475
00:29:27,608 --> 00:29:31,426
day basis under normal behavior so that you

476
00:29:31,448 --> 00:29:35,362
can get ready for those peak traffic events for those

477
00:29:35,416 --> 00:29:39,062
days, that you're going to have more users on

478
00:29:39,116 --> 00:29:42,694
your website, or that other things might be

479
00:29:42,732 --> 00:29:46,534
breaking within the dependencies that you've built in. You want to

480
00:29:46,572 --> 00:29:50,314
remember that you have to practice. You have to question

481
00:29:50,432 --> 00:29:54,122
everything, whether it's in systems or general knowledge about

482
00:29:54,176 --> 00:29:57,914
your applications. And that is that beauty that always keeps me

483
00:29:57,952 --> 00:30:01,722
coming back to chaos engineering. It is a proactive

484
00:30:01,786 --> 00:30:05,246
approach to building reliable systems, and you get a

485
00:30:05,268 --> 00:30:08,746
chance to build reliable applications and systems,

486
00:30:08,858 --> 00:30:12,602
but you also build reliable people and organizations

487
00:30:12,746 --> 00:30:15,986
with that. I would like to close out and offer you a

488
00:30:16,008 --> 00:30:19,506
nice little takeaway. If you're interested in joining the

489
00:30:19,528 --> 00:30:22,894
Chaos engineering community and getting some of the chaos engineering

490
00:30:22,942 --> 00:30:26,626
stickers that you see up here on the slide, head on over to

491
00:30:26,648 --> 00:30:30,270
gremlin.com talk Anna

492
00:30:30,350 --> 00:30:33,830
Anna Conf fourty two. And if you have any questions

493
00:30:33,900 --> 00:30:37,506
about this, talk the topic anything regarding

494
00:30:37,538 --> 00:30:40,662
to do with chaos engineer or Gremlin, feel free to reach

495
00:30:40,716 --> 00:30:43,542
out via email@annaghremlin.com.

496
00:30:43,676 --> 00:30:47,090
Or you can reach out via any of the social media platforms.

497
00:30:47,170 --> 00:30:50,586
I'm usually Anna underscore M underscore my Dina.

498
00:30:50,698 --> 00:30:54,126
And if you're interested in giving a try to Gremlin free,

499
00:30:54,228 --> 00:30:57,854
you can always go to go gremlin.com slash Anna to

500
00:30:57,892 --> 00:31:01,886
sign up and try the full suite of Gremlin attacks with that. Thank you

501
00:31:01,908 --> 00:31:03,420
all very much. Have a great one.

