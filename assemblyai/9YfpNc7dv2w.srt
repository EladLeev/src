1
00:01:41,810 --> 00:01:45,086
Hello everyone, my name is Ankit and today we will be

2
00:01:45,108 --> 00:01:48,394
talking about how to automate merges to keep your builds

3
00:01:48,442 --> 00:01:51,966
healthy. Before we go into the details, a little bit about my

4
00:01:51,988 --> 00:01:55,630
background, I'm cofounder CEO Aviator. We are building

5
00:01:55,700 --> 00:01:58,080
developer workflow automation platform.

6
00:01:58,610 --> 00:02:02,122
Previously I've been an engineer in several companies including

7
00:02:02,186 --> 00:02:06,354
Google, Adobe, Shippo, Home, Enjoy and Sunshine.

8
00:02:06,482 --> 00:02:10,710
You can also find me at Twitter at ankitxG.

9
00:02:12,090 --> 00:02:16,018
So the first question you will be asking is merging.

10
00:02:16,114 --> 00:02:19,514
How hard can it be? Right? All you have to do is press this green

11
00:02:19,552 --> 00:02:23,286
button and your changes are merged. Well, let's take a deeper

12
00:02:23,318 --> 00:02:26,954
look. Before we go into details, let's think

13
00:02:26,992 --> 00:02:30,810
a little bit about different repositories that teams use.

14
00:02:30,960 --> 00:02:34,670
So we have Monorepo, where all the entire engineering team

15
00:02:34,740 --> 00:02:38,426
is causing a single repository, and then we have Polyrepo,

16
00:02:38,458 --> 00:02:42,490
where every team within a company may be using a separate repositories.

17
00:02:42,650 --> 00:02:45,938
In case of Monorepo, the advantages you typically have is easier to

18
00:02:45,944 --> 00:02:49,262
manage dependencies. You can easily identify vulnerabilities

19
00:02:49,326 --> 00:02:53,326
and fix everywhere together. It's easier to do refactoring,

20
00:02:53,358 --> 00:02:56,866
especially if it is cross project. You have a standardization of

21
00:02:56,888 --> 00:03:00,050
tools as well as code sharing becomes important,

22
00:03:00,120 --> 00:03:03,426
you can kind of like share the same libraries across different projects.

23
00:03:03,618 --> 00:03:07,266
In case of poly repos, some of the advantages are simpler CI

24
00:03:07,298 --> 00:03:10,566
CD management. Everyone has their own different cis,

25
00:03:10,678 --> 00:03:13,050
so there's like Lesser Bill failures,

26
00:03:14,750 --> 00:03:18,054
you have independent bid pipelines. Bill failures typically are localized

27
00:03:18,102 --> 00:03:21,426
within the team. In this particular context. For this conversation,

28
00:03:21,478 --> 00:03:24,926
we will primarily be focusing on Monorepo and identifying what are

29
00:03:24,948 --> 00:03:29,230
the challenges in a large team when you're working on a Monorepo.

30
00:03:30,690 --> 00:03:34,062
So the first question you would probably want to ask is how

31
00:03:34,116 --> 00:03:37,634
often do your mainline builds fail? And is

32
00:03:37,672 --> 00:03:41,700
your current CI system enough? There are several reasons why

33
00:03:42,150 --> 00:03:45,742
your mainline builds may fail. For instance, there could be like still

34
00:03:45,816 --> 00:03:49,158
dependencies between different changes that are merging. There could

35
00:03:49,164 --> 00:03:52,760
be implicit conflicts, two developers working on similar code base.

36
00:03:53,210 --> 00:03:56,502
You can have infrastructure issues. There could be issue

37
00:03:56,556 --> 00:04:00,314
with timeouts. There could both internal as well as third

38
00:04:00,352 --> 00:04:04,054
party dependencies that can cause failures. Obviously there's like trade

39
00:04:04,102 --> 00:04:07,180
conditions, shared states that also cause like flaky test.

40
00:04:08,110 --> 00:04:12,346
In this particular conversation, we will primarily be talking about the stale dependencies

41
00:04:12,458 --> 00:04:16,270
and implicit conflicts and why those things are important

42
00:04:16,420 --> 00:04:17,520
to think about.

43
00:04:19,170 --> 00:04:20,960
So to give you an example,

44
00:04:25,810 --> 00:04:29,346
let's kind of just take an example of why this is

45
00:04:29,368 --> 00:04:32,594
important in a Monorepo case. So let's say there are two pull

46
00:04:32,632 --> 00:04:36,222
requests where they're merging together, or like they're

47
00:04:36,286 --> 00:04:40,006
based out at two different times from your main and both

48
00:04:40,028 --> 00:04:44,194
of them have passing CI. But eventually when you go and merges

49
00:04:44,242 --> 00:04:47,734
those changes, the main line fails, right? This could

50
00:04:47,772 --> 00:04:51,146
happen because both of them may be modifying the same pieces of code

51
00:04:51,248 --> 00:04:54,060
where they may not be compatible with each other.

52
00:04:55,310 --> 00:04:58,746
And the challenge is like as your team grows, these kind

53
00:04:58,768 --> 00:05:02,518
of issues become more and more common. Eventually there

54
00:05:02,544 --> 00:05:06,234
will be teams setting up their own bill police

55
00:05:06,362 --> 00:05:09,998
kind of like to make sure that if ever a bill fails that there is

56
00:05:10,004 --> 00:05:13,166
somebody responsible to actually fixing that. There will

57
00:05:13,188 --> 00:05:17,374
be like typically people will do rollbacks, releases get delayed.

58
00:05:17,502 --> 00:05:20,754
There could be like chain reactions where people are basing off of

59
00:05:20,952 --> 00:05:24,626
failing branches and then eventually they'll have to figure out how

60
00:05:24,648 --> 00:05:28,198
to actually resolve those issues. And these kind

61
00:05:28,204 --> 00:05:31,926
of failures increase exponentially as your team size are

62
00:05:31,948 --> 00:05:36,070
growing. And that's why it become very critical at certain point in your team

63
00:05:36,140 --> 00:05:40,586
to make sure you can actually take care of it so

64
00:05:40,608 --> 00:05:44,218
that developers productivity is not significantly impacted. You don't want a situation

65
00:05:44,304 --> 00:05:47,866
where everyone is just like waiting for the bills to become green.

66
00:05:47,968 --> 00:05:51,546
They cannot merge any changes because builds

67
00:05:51,578 --> 00:05:55,102
are always broken and you're losing important

68
00:05:55,236 --> 00:05:56,400
developer hours.

69
00:05:58,610 --> 00:06:00,990
So then what's the solution?

70
00:06:02,530 --> 00:06:06,174
The solution is merge automation, where many companies,

71
00:06:06,372 --> 00:06:10,126
like for instance you may have heard of like GitHub launching their own merge queue.

72
00:06:10,238 --> 00:06:13,346
GitHub also has something similar called merge train. There are

73
00:06:13,368 --> 00:06:16,854
some open source versions that exist today, like hours that can also

74
00:06:16,892 --> 00:06:20,166
provide similar capabilities. So we'll be

75
00:06:20,188 --> 00:06:24,226
diving more into how this merge automation works and how you can adopt

76
00:06:24,258 --> 00:06:27,890
that internally. To give you a very simple example,

77
00:06:28,060 --> 00:06:31,818
let's take here that instead of like. So let's kind

78
00:06:31,824 --> 00:06:35,130
of see this pull request which is pr one. Instead of

79
00:06:35,200 --> 00:06:39,370
developers manually merging these changes, they would typically

80
00:06:39,970 --> 00:06:43,326
inform the system that it's ready. And at

81
00:06:43,348 --> 00:06:47,070
that point, instead of merging changes itself,

82
00:06:47,220 --> 00:06:50,842
the system would actually merges the latest

83
00:06:50,906 --> 00:06:54,462
main into this pull request and then run the CI.

84
00:06:54,606 --> 00:06:58,466
The advantage here is you're always validating the changes with

85
00:06:58,488 --> 00:07:02,530
the most recent main. Now if the CI passes,

86
00:07:03,110 --> 00:07:06,718
this pr will get merged. And meanwhile,

87
00:07:06,814 --> 00:07:09,606
let's say if there's a second pr that comes in while the CI is running,

88
00:07:09,708 --> 00:07:13,538
it's going to wait for the first pr to merge before it picks

89
00:07:13,554 --> 00:07:16,950
up the changes of the latest main and then we'll process

90
00:07:17,020 --> 00:07:20,506
and run the same thing. So once the second pr passes also it's going to

91
00:07:20,528 --> 00:07:21,660
merge the same way.

92
00:07:27,950 --> 00:07:31,286
Let's kind of look at some of these stats. Let's assume for sake

93
00:07:31,318 --> 00:07:34,640
of this conversation that the CI time is about 30 minutes,

94
00:07:35,250 --> 00:07:38,906
hours. Pull request. You're merging in a small team is about ten prs

95
00:07:38,938 --> 00:07:42,734
a day. This would take about. If you kind of run it

96
00:07:42,772 --> 00:07:46,294
serially, it will take about like 5 hours because you're waiting for each PRCI

97
00:07:46,362 --> 00:07:49,698
to pass before running the second one. The total amount of

98
00:07:49,704 --> 00:07:53,506
CI you will run is about 50. Now the challenge is if

99
00:07:53,528 --> 00:07:57,266
you're in a big team where you're merging 100 prs a day in the

100
00:07:57,288 --> 00:08:00,486
same amount of CI, if it takes the same amount of CI now you're looking

101
00:08:00,508 --> 00:08:03,846
at completing about 50 hours of merge time. Now this

102
00:08:03,868 --> 00:08:08,434
is unrealistic for any kind of like system to be able to merges

103
00:08:08,482 --> 00:08:12,380
changes as slowly. So then can we do better?

104
00:08:14,590 --> 00:08:17,926
One way we can think about doing this better is by batching

105
00:08:17,958 --> 00:08:21,542
changes. So instead of merging

106
00:08:21,606 --> 00:08:25,342
one pr at a time, what your system can do is

107
00:08:25,396 --> 00:08:29,226
it can wait for a few prs to get collected before running the CI.

108
00:08:29,338 --> 00:08:32,990
The advantage here is you're creating these batches which essentially

109
00:08:33,910 --> 00:08:37,170
make sure, one, you're reducing the number of CI that you're running,

110
00:08:37,240 --> 00:08:39,170
but also it helps reduce,

111
00:08:41,350 --> 00:08:45,446
essentially help reduce. How long is the wait time. So in

112
00:08:45,468 --> 00:08:48,706
this case, if the CI passes, it's going to merge

113
00:08:48,738 --> 00:08:53,030
all four of the prs together. Now, considering all of them consist

114
00:08:53,370 --> 00:08:55,640
eventually pass the build.

115
00:08:56,890 --> 00:09:00,594
And in cases there's a failure, we are going to bisect

116
00:09:00,642 --> 00:09:03,818
these batches so that we can identify which pr is

117
00:09:03,824 --> 00:09:07,606
causing the failure and merges rest of them. Now here you can imagine like it's

118
00:09:07,638 --> 00:09:10,940
going to cause a little bit of slowdown in the system.

119
00:09:11,390 --> 00:09:14,646
So let's look at the stats in case there is no failure. Let's say best

120
00:09:14,688 --> 00:09:18,062
case scenario, if you're doing a batch size of four now, your total

121
00:09:18,116 --> 00:09:21,662
merges time suddenly drops from 50 hours to twelve and a half hours.

122
00:09:21,796 --> 00:09:25,054
That's a significant improvement. And also the total number

123
00:09:25,092 --> 00:09:26,980
of CI runs are going to be small.

124
00:09:27,750 --> 00:09:31,166
But in a real scenario, right, you're going to have failures.

125
00:09:31,278 --> 00:09:34,686
So if there is even a 10% failure rate, you see like the merges

126
00:09:34,718 --> 00:09:38,406
time increases significantly. So you're like waiting like 24 hours for

127
00:09:38,428 --> 00:09:41,718
all your cis to merge, all your prs to merge and the total number of

128
00:09:41,724 --> 00:09:43,830
cis also increase significantly.

129
00:09:46,010 --> 00:09:49,866
So then the question is, can we still

130
00:09:49,888 --> 00:09:53,146
do better? So we are going

131
00:09:53,168 --> 00:09:56,806
to think a little bit about think of merges slightly differently.

132
00:09:56,918 --> 00:10:00,182
Instead of thinking of merges kind of like happening in a serial

133
00:10:00,246 --> 00:10:04,506
world, you think about this as like parallel universes by parallel

134
00:10:04,538 --> 00:10:08,222
universes. What I mean is if you think of main as

135
00:10:08,276 --> 00:10:11,802
not like a linear graph or like a linear path.

136
00:10:11,866 --> 00:10:16,846
You think of this as sort of several potential futures

137
00:10:16,958 --> 00:10:20,514
that the main can possibly represent. To give an example,

138
00:10:20,632 --> 00:10:24,690
let's think about the optimistic queues. So let's say your main is at this particular

139
00:10:24,760 --> 00:10:28,566
point, a new PR comes in, it's ready to merge. So what

140
00:10:28,588 --> 00:10:31,686
we are going to do is something similar to before. We're going to pull the

141
00:10:31,708 --> 00:10:35,042
latest mainline and create this alternate

142
00:10:35,106 --> 00:10:38,610
main branch where we run the CI.

143
00:10:38,770 --> 00:10:41,846
Once the CI passes, we are going to eventually similarly merge

144
00:10:41,878 --> 00:10:46,006
the changes. But here what we're doing is imagine

145
00:10:46,038 --> 00:10:49,274
while the CI is running, a second PR comes in as well. So instead

146
00:10:49,312 --> 00:10:53,066
of waiting for the first CI to pass, we optimistically assume that

147
00:10:53,088 --> 00:10:56,238
the first PR is going to pass. And in this alternate main,

148
00:10:56,324 --> 00:10:59,886
we're going to start a new CI with second pr as well.

149
00:11:00,068 --> 00:11:03,502
So once the PR for the first one passes, it's going to eventually

150
00:11:03,566 --> 00:11:06,846
merge. And likewise, as soon as the CI

151
00:11:06,878 --> 00:11:09,940
for the second one passes, it's going to merge as well.

152
00:11:11,270 --> 00:11:14,718
Sorry, it's been a bit slow. So it's

153
00:11:14,734 --> 00:11:18,066
going to merge as well. Now, obviously here we are

154
00:11:18,088 --> 00:11:21,394
looking at like what happens if the CI for the first one fails.

155
00:11:21,522 --> 00:11:24,578
The CI for the first one fails is what we're going to do is we're

156
00:11:24,594 --> 00:11:28,246
going to reject this alternate main and essentially create a

157
00:11:28,268 --> 00:11:31,930
new alternate main where we're going to run rest of the changes

158
00:11:32,080 --> 00:11:35,482
and follow the same pattern. And in this particular case,

159
00:11:35,536 --> 00:11:38,314
we're going to make sure the pr one does not merge and because a bill

160
00:11:38,352 --> 00:11:42,094
failure. So in best

161
00:11:42,132 --> 00:11:46,046
case scenario, given that we're now not waiting for NECI to finish,

162
00:11:46,228 --> 00:11:49,566
you can technically merge all your 100 prs in less

163
00:11:49,588 --> 00:11:53,194
than an hour. Obviously, in case of a median

164
00:11:53,242 --> 00:11:56,174
case where we expect like 10% of the prs to fail,

165
00:11:56,302 --> 00:11:59,486
your merge time is still very reasonable. Now you're merging

166
00:11:59,518 --> 00:12:03,186
in 6 hours instead of the twelve and a half hours that we were

167
00:12:03,208 --> 00:12:06,814
seeing before. And alongside your CIA runs

168
00:12:06,862 --> 00:12:10,458
are slightly higher in this case because you can possibly be running this multiple CIA

169
00:12:10,494 --> 00:12:14,198
at the same time. So then

170
00:12:14,284 --> 00:12:17,000
the question is, can we still do better?

171
00:12:19,290 --> 00:12:22,886
One way to improve on this is combining some of the strategies we've discussed

172
00:12:22,918 --> 00:12:26,634
before. So let's say if you combine the strategy of optimistic Q with

173
00:12:26,672 --> 00:12:31,274
batching. So instead

174
00:12:31,312 --> 00:12:34,414
of running a CI on every PR, now we kind of combine them

175
00:12:34,452 --> 00:12:38,142
together. So essentially you're running like these batches of

176
00:12:38,196 --> 00:12:41,930
pures, and again, as they pass, you merge them. If they fail,

177
00:12:42,010 --> 00:12:45,470
you split them up and identify what causes a failure.

178
00:12:47,810 --> 00:12:50,994
Let's look at the stats again. So now we are saying

179
00:12:51,032 --> 00:12:53,986
the total merge time is still less than 1 hour. But what we have done

180
00:12:54,008 --> 00:12:57,138
is we have reduced the total number of cis to 25

181
00:12:57,224 --> 00:13:00,582
instead of 100. And even in the median case,

182
00:13:00,636 --> 00:13:03,974
the merge time is lower, from 6 hours to 4 hours, and your total

183
00:13:04,012 --> 00:13:05,480
number of cis are still lower.

184
00:13:07,130 --> 00:13:09,580
So can we still do better?

185
00:13:11,710 --> 00:13:15,606
Now let's think about some more concepts here. One of the concept

186
00:13:15,638 --> 00:13:19,610
is predictive modeling, but become that. Let's think about

187
00:13:19,760 --> 00:13:24,118
what happens if we assume all possible scenarios

188
00:13:24,214 --> 00:13:28,014
of what the main could look like if a particular CI is going to

189
00:13:28,052 --> 00:13:30,842
pass or fail, or PR is going to pass or fail.

190
00:13:30,986 --> 00:13:34,874
So in this case, we have represented these three prs and all possible scenarios

191
00:13:34,922 --> 00:13:38,558
where all three of them merge, one of them merge or two of them merge.

192
00:13:38,734 --> 00:13:42,146
And if you run these, essentially, if you run in

193
00:13:42,168 --> 00:13:45,186
this way, then we never have to worry about failures, because we

194
00:13:45,208 --> 00:13:48,546
are already running all possible scenarios and we know one of them is going

195
00:13:48,568 --> 00:13:52,166
to be successful. Although the challenge here

196
00:13:52,268 --> 00:13:55,446
is obviously running a lot of CI, right? We don't want to be running too

197
00:13:55,468 --> 00:13:59,050
much CI, and this is where it can be interesting. So instead

198
00:13:59,120 --> 00:14:02,314
of running it on all of them, what we can

199
00:14:02,352 --> 00:14:05,514
do is we can calculate a score and

200
00:14:05,552 --> 00:14:09,322
based on that, essentially identify which ones are worth,

201
00:14:09,456 --> 00:14:12,926
which paths are worth pursuing. So you

202
00:14:12,948 --> 00:14:16,430
can do optimization based on lines of code in a PR,

203
00:14:16,580 --> 00:14:20,346
types of files being modified, test added or removed

204
00:14:20,378 --> 00:14:23,998
in a particular PR, a number of dependencies. So in

205
00:14:24,004 --> 00:14:27,378
this case we have specified the cutoff as zero five. And as you

206
00:14:27,384 --> 00:14:30,900
can see, we are running only a few

207
00:14:31,670 --> 00:14:32,660
of these,

208
00:14:37,110 --> 00:14:40,406
excuse me, we are running only a few of

209
00:14:40,428 --> 00:14:44,006
these builds paths, and that's why I'm reducing the number of

210
00:14:44,028 --> 00:14:44,710
CI.

211
00:14:48,830 --> 00:14:52,060
So now you're obviously asking, can we still do better?

212
00:14:54,590 --> 00:14:57,446
Now we're going to think about concepts of multi queues.

213
00:14:57,558 --> 00:15:01,374
So this is applicable in certain specific cases where we can understand

214
00:15:01,492 --> 00:15:05,370
different builds. So instead of thinking of this as a singular

215
00:15:05,450 --> 00:15:09,358
queue, now we're going to think of this as many different paths you

216
00:15:09,364 --> 00:15:13,118
can take and many disjoint queues that you

217
00:15:13,124 --> 00:15:16,494
can run. So we use this concept called affected target.

218
00:15:16,622 --> 00:15:19,966
So there are systems like Bazel that actually produce

219
00:15:20,078 --> 00:15:23,506
these results, or like these affected targets. So essentially, if you

220
00:15:23,528 --> 00:15:27,110
can identify what builds within your

221
00:15:27,260 --> 00:15:31,442
primary repository that a particular change impacts,

222
00:15:31,586 --> 00:15:37,014
you can create disjoint queues where all

223
00:15:37,052 --> 00:15:40,810
these queues can be independently run, while making

224
00:15:40,880 --> 00:15:44,746
sure hours builds are not going to impact it. So let's assume that there are

225
00:15:44,768 --> 00:15:48,410
like four different kinds of bills that your system

226
00:15:48,480 --> 00:15:52,586
produces A-B-C and D. And this is kind of like the order of the prs

227
00:15:52,618 --> 00:15:56,474
that they came in. You can potentially create hours different queues

228
00:15:56,522 --> 00:16:01,854
out of it. So let's say kind of like the prs that impact a are

229
00:16:01,892 --> 00:16:05,366
in first queue, the prs that impact b are in second queue,

230
00:16:05,418 --> 00:16:09,330
and so on. So one thing to note here is

231
00:16:09,480 --> 00:16:12,706
a PR can be in more than one queue if it's impacting more

232
00:16:12,728 --> 00:16:15,918
than one target, and that's totally fine. So essentially

233
00:16:16,094 --> 00:16:19,414
for PR four or PR five to pass, in this

234
00:16:19,452 --> 00:16:23,730
case it need to wait for PR two to pass or fail.

235
00:16:23,890 --> 00:16:27,106
But at the same time, we are still making sure that in a worst

236
00:16:27,138 --> 00:16:31,274
case scenario where a PR fails, we are still

237
00:16:31,472 --> 00:16:35,322
not impacting all the prs in the queue, but only the ones which are

238
00:16:35,376 --> 00:16:38,666
behind that particular queue. This definitely

239
00:16:38,768 --> 00:16:42,126
increases the velocity at which

240
00:16:42,148 --> 00:16:46,058
you're merging the changes, because it's in some ways localizing

241
00:16:46,154 --> 00:16:48,510
failures to a particular affected target.

242
00:16:51,330 --> 00:16:55,190
So this is a great example where we are looking at two separate queues.

243
00:16:55,290 --> 00:16:58,626
Let's say one target is back end, one target is front end, and there are

244
00:16:58,648 --> 00:17:02,466
multiple prs queued, but they can independently be

245
00:17:02,488 --> 00:17:06,386
compiled and run while making sure that you're not impacting

246
00:17:06,578 --> 00:17:10,774
one change is not impacting the other one. And that way you can

247
00:17:10,892 --> 00:17:14,626
run them parallel as well as merge them while impacting,

248
00:17:14,658 --> 00:17:18,730
while not impacting the builds. So now

249
00:17:18,800 --> 00:17:20,140
can we still do better?

250
00:17:21,790 --> 00:17:25,580
There are like few other concepts that we can think about to actually

251
00:17:25,950 --> 00:17:29,306
make it further optimize these workflows. So one

252
00:17:29,328 --> 00:17:32,942
of them is thinking about reordering changes.

253
00:17:33,076 --> 00:17:37,102
For instance, you can select

254
00:17:37,156 --> 00:17:41,578
the high priority changes or the changes where there's lower failure

255
00:17:41,674 --> 00:17:45,122
risk and put them ahead in the queue. The advantage here

256
00:17:45,176 --> 00:17:49,326
is it's not going to cause a possible can

257
00:17:49,358 --> 00:17:52,738
reaction of failures, and it's going to kind of reduce the amount of

258
00:17:52,824 --> 00:17:56,626
possible failures you can have. You can also kind of order it based on

259
00:17:56,648 --> 00:18:00,146
priority, something which is like really big change. You can probably say it's

260
00:18:00,178 --> 00:18:03,254
going to be lower priority and we're going to pick it up later.

261
00:18:03,452 --> 00:18:06,406
There are other concepts of like, for instance, fail fast,

262
00:18:06,508 --> 00:18:10,434
so you can reorder the text execution, the ones which typically fail

263
00:18:10,482 --> 00:18:14,058
more often. You'd probably want to run it sooner. That way, as soon

264
00:18:14,064 --> 00:18:18,140
as the PR gets skewed, you identify these failures and are able to fail fast.

265
00:18:18,910 --> 00:18:22,286
The other things you can do is you can split the test execution. This is

266
00:18:22,308 --> 00:18:25,534
what many companies do where they will

267
00:18:25,572 --> 00:18:29,226
run many of the fast test before merging.

268
00:18:29,258 --> 00:18:32,542
And making sure kind of like these are the ones which are more

269
00:18:32,596 --> 00:18:36,814
critical, or things which possibly fail more often and

270
00:18:36,932 --> 00:18:40,190
then run the smoke test, or like things which typically

271
00:18:40,350 --> 00:18:43,746
are stable but maybe slower, but you

272
00:18:43,768 --> 00:18:47,154
run them after they're merging. Obviously you expect

273
00:18:47,272 --> 00:18:50,562
the tests you're running after merge fail

274
00:18:50,626 --> 00:18:54,470
very rarely, but if it fails, you can just roll back.

275
00:18:54,540 --> 00:18:57,906
So essentially you're trying to find the best of both world to make sure your

276
00:18:57,948 --> 00:19:01,126
builds are generally passing. And very rarely, if it fails,

277
00:19:01,158 --> 00:19:04,220
you have a way of automatically rolling it back.

278
00:19:06,430 --> 00:19:09,754
So that's about it.

279
00:19:09,872 --> 00:19:12,686
I'm going to share a little bit about some of the other things we at

280
00:19:12,708 --> 00:19:16,506
aviator work on. So we also support scenarios of Polyrepo.

281
00:19:16,538 --> 00:19:20,522
To give you a very quick example. Let's say you have different repositories

282
00:19:20,586 --> 00:19:23,818
for different types of projects, and you're kind of

283
00:19:23,844 --> 00:19:27,378
like merging a change. Let's say you're modifying an API. That's going to

284
00:19:27,384 --> 00:19:30,594
also impact how that

285
00:19:30,632 --> 00:19:34,126
API interacts with web, how it interacts with iOS and Android.

286
00:19:34,238 --> 00:19:37,474
Now here the issue is, let's say

287
00:19:37,592 --> 00:19:40,758
you make this change, which kind of requires all of them to

288
00:19:40,764 --> 00:19:44,370
be modified, but you merges three of them and one of them fails.

289
00:19:44,450 --> 00:19:47,030
Now this can cause eventual inconsistency,

290
00:19:47,390 --> 00:19:51,386
and our system essentially ensure we have

291
00:19:51,408 --> 00:19:55,830
a workflows, we call it chain sets, that essentially combines

292
00:19:55,910 --> 00:19:59,722
or defines these dependencies of changes across

293
00:19:59,776 --> 00:20:03,386
the repositories. So you consider them as like single atomic

294
00:20:03,418 --> 00:20:07,630
unit. So essentially we make sure all of these prs either

295
00:20:07,780 --> 00:20:11,200
merge altogether or none of them merge at all.

296
00:20:12,610 --> 00:20:15,902
We also have a system to manage flaky test. As you can imagine,

297
00:20:15,966 --> 00:20:19,758
as your system and teams grows, everyone is very familiar with flaky

298
00:20:19,774 --> 00:20:24,414
teams. Your system becomes unstable. You'll have like these shared states or inconsistent

299
00:20:24,462 --> 00:20:28,086
test behaviors where your test may fail, even though you may

300
00:20:28,108 --> 00:20:31,606
not have made any change related to that. So what

301
00:20:31,628 --> 00:20:34,886
hours system typically does is we identify all these

302
00:20:34,908 --> 00:20:38,940
flaky tests in your runs and essentially provide

303
00:20:40,510 --> 00:20:44,570
with a customized check that you can use to essentially

304
00:20:45,790 --> 00:20:49,382
automatically merges the changes. So what we typically

305
00:20:49,446 --> 00:20:52,982
do here is we identify

306
00:20:53,046 --> 00:20:56,654
whether a particular flaky test which has happened is related to your

307
00:20:56,692 --> 00:21:00,174
changes or not. If it is not, then we suppress that test in the test

308
00:21:00,212 --> 00:21:02,894
report so that you get a clean health of build,

309
00:21:03,092 --> 00:21:06,802
clean build health, and then you're able to merge that changes. So this

310
00:21:06,856 --> 00:21:10,306
works very well when you're thinking about automatic merging, because you can use

311
00:21:10,328 --> 00:21:13,858
this check as a validation to make sure your systems are

312
00:21:13,864 --> 00:21:17,314
still healthy. We also have

313
00:21:17,352 --> 00:21:21,238
capabilities to manage stack prs. So if you have prs which are

314
00:21:21,324 --> 00:21:25,074
stacked on top of each other. We have capabilities through which you can automatically

315
00:21:25,122 --> 00:21:29,080
merge these changes as well as there's a CLI to

316
00:21:29,610 --> 00:21:32,874
sync all your stacked prs together as well as be able to

317
00:21:32,992 --> 00:21:35,578
queue all of the pr to be merged together.

318
00:21:35,744 --> 00:21:39,622
And again, kind of like it follows similar patterns of chain set that we described.

319
00:21:39,686 --> 00:21:43,490
So we automatically are able to identify dependencies of all these stacked prs

320
00:21:43,590 --> 00:21:46,938
and consider them as atomic units. So all of them merge together or none

321
00:21:46,954 --> 00:21:50,734
of them merge at all. I think

322
00:21:50,772 --> 00:21:54,558
that's about it. So thank you very much. These are some of the references that

323
00:21:54,564 --> 00:21:57,998
we use for this talk, but I really appreciate you spending time

324
00:21:58,084 --> 00:22:01,502
listening to this. If you have any questions, you can always reach out to me.

325
00:22:01,556 --> 00:22:05,574
My email is ankit at aviator Co. Let me

326
00:22:05,612 --> 00:22:08,680
see if this is going to the next screen.

327
00:22:09,610 --> 00:22:13,234
And yeah, check it out. Check us out. At aviator we do automatic

328
00:22:13,282 --> 00:22:16,946
merging as well as many other capabilities, many automated workflows

329
00:22:16,978 --> 00:22:20,502
for developers. If you have any questions,

330
00:22:20,636 --> 00:22:23,126
as I said, you can reach out to me. You can also send me a

331
00:22:23,148 --> 00:22:25,926
DM on Twitter. Thank you and have a great day.

