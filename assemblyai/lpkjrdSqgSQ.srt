1
00:00:34,690 --> 00:00:37,954
Hi and welcome to this presentation on the best audit

2
00:00:38,002 --> 00:00:41,810
logging practices when using Kubernetes. My name is Kenneth Dumez,

3
00:00:41,890 --> 00:00:45,094
a developer relations engineer here at Teleport. So for a little

4
00:00:45,132 --> 00:00:48,710
background on my history, I came to teleport around a year ago

5
00:00:48,780 --> 00:00:52,478
after working at Pivotal Cloud Foundry and then was at VMware Tanzu for

6
00:00:52,484 --> 00:00:56,286
a few years working on their Kubernetes build service solution. Thank you

7
00:00:56,308 --> 00:00:59,722
so much for coming and I hope you can learn a little bit about Kubernetes

8
00:00:59,786 --> 00:01:03,966
best practices as it's such a rabbit hole and gets confusing very quickly.

9
00:01:04,068 --> 00:01:07,474
There's a bunch of other awesome talks today as well. Conf 42 is a great

10
00:01:07,512 --> 00:01:10,562
place for developers and leaders in various fields to come together

11
00:01:10,616 --> 00:01:13,842
and share some of their knowledge. So just want to shout out Mark

12
00:01:13,896 --> 00:01:17,230
Paulikowski for putting this together. It's always a pleasure to

13
00:01:17,240 --> 00:01:21,042
be here. So today in this presentation we'll be discussing

14
00:01:21,106 --> 00:01:25,094
the importance of good audit logging practices in Kubernetes and the best

15
00:01:25,132 --> 00:01:28,738
practices to follow to ensure a secure and compliant environment

16
00:01:28,834 --> 00:01:32,886
at scale. We'll talk about the native built in logging functionality

17
00:01:32,918 --> 00:01:36,678
in Kate's and its limitations. We'll also look at some third party

18
00:01:36,774 --> 00:01:39,958
opensource tools that can help make following all of these practices

19
00:01:40,054 --> 00:01:44,278
a little easier, while making your administrators and security engineers

20
00:01:44,374 --> 00:01:47,518
a little bit better. So the first thing we're going to talk about is the

21
00:01:47,524 --> 00:01:51,850
audit logging capabilities you get out of the box when you deploy your Kubernetes cluster.

22
00:01:52,010 --> 00:01:55,954
Kubernetes has a built in logging system that is used to record information

23
00:01:56,072 --> 00:01:59,554
about events that occur in the cluster. This information can include things

24
00:01:59,592 --> 00:02:03,310
like API requests, opensource changes, system events,

25
00:02:03,390 --> 00:02:07,070
basically everything and anything that happens inside of your cluster.

26
00:02:07,150 --> 00:02:10,306
Kubernetes stores this information as log files on the cluster

27
00:02:10,338 --> 00:02:14,194
nodes, which can be accessed using various tools such as Kubectl,

28
00:02:14,322 --> 00:02:18,226
or if you're using a hosted Kubernetes environment, there's usually a dashboard

29
00:02:18,258 --> 00:02:21,030
or UI or something that you can use to access these logs.

30
00:02:21,110 --> 00:02:24,998
The important thing to note here is that these logs are super granular

31
00:02:25,094 --> 00:02:29,254
and highly configurable. Kubernetes clusters, especially larger

32
00:02:29,302 --> 00:02:32,826
ones, can generate a lot of events and thus a lot

33
00:02:32,848 --> 00:02:36,254
of log data. This can make it difficult to separate the

34
00:02:36,292 --> 00:02:39,582
wheat from the chaff, so to speak, and maintaining a good signal to

35
00:02:39,636 --> 00:02:43,098
noise ratio can be really tough. One of the most important things when setting

36
00:02:43,114 --> 00:02:46,850
up your logging and to manage the spamminess of your cluster's log data

37
00:02:47,000 --> 00:02:51,214
is this object called the Kubernetes audit policy. The Kubernetes Audit

38
00:02:51,262 --> 00:02:55,118
policy configuration object is a native Kubernetes resource

39
00:02:55,214 --> 00:02:59,126
which you provide to your API server that defines the rules and settings for

40
00:02:59,148 --> 00:03:02,146
auditing events that occur within a Kubernetes cluster.

41
00:03:02,258 --> 00:03:05,830
This audit policy configuration object is defined like

42
00:03:05,900 --> 00:03:09,506
all the other Kate's resources in a YAML file that defines

43
00:03:09,538 --> 00:03:12,826
the audit rules and settings. This is the first object you want

44
00:03:12,848 --> 00:03:16,566
to configure when determining your logging strategy. The file contains

45
00:03:16,598 --> 00:03:20,218
several fields that can be configured to customize the audit policy. We're going to

46
00:03:20,224 --> 00:03:23,566
look at some of those fields in depth in a second. For one example,

47
00:03:23,668 --> 00:03:27,598
you can say only log anything that's done to secrets or

48
00:03:27,684 --> 00:03:31,338
just events concerning pods, or say everything that's

49
00:03:31,354 --> 00:03:34,918
done to any of the core APIs, but none of the custom resource

50
00:03:34,954 --> 00:03:38,706
definitions or extensions. As a good starting point, you can check

51
00:03:38,728 --> 00:03:42,190
out the audit profile for the Google Container optimized os.

52
00:03:42,350 --> 00:03:45,650
This is publicly available and you can then configure it from there

53
00:03:45,720 --> 00:03:49,282
to whatever best suits your logging needs. Within the Kubernetes

54
00:03:49,346 --> 00:03:52,790
audit policy object, the rules field is the most important.

55
00:03:52,940 --> 00:03:56,770
This field defines the audit rules that dictate which events should be audited

56
00:03:56,850 --> 00:04:00,246
and how they should be handled. Just as an example and so you can kind

57
00:04:00,268 --> 00:04:04,166
of see what an audit policy configuration would look like, here's a little walkthrough

58
00:04:04,198 --> 00:04:08,246
of the various audit rules fields. I would highly recommend not just copying

59
00:04:08,278 --> 00:04:11,754
this one and plugging it into your own clusters because like I said,

60
00:04:11,792 --> 00:04:14,686
this is just an example and you probably want to tailor it a little bit

61
00:04:14,708 --> 00:04:18,442
better to your specific needs. So first we have this omit stages

62
00:04:18,506 --> 00:04:21,914
field. This defines the audit stages to be skipped for your various

63
00:04:21,962 --> 00:04:25,486
events, such as request received or response started. This is

64
00:04:25,508 --> 00:04:28,626
crucial for cutting down on the parts of the events that you don't care about.

65
00:04:28,728 --> 00:04:32,466
You don't need every stage and you shouldn't track it

66
00:04:32,488 --> 00:04:36,038
all in your audit log. Then you have level which defines the level of

67
00:04:36,044 --> 00:04:40,610
the event to be audited, such as request, response or metadata.

68
00:04:40,770 --> 00:04:44,402
Next is your resources field which defines which kubernetes

69
00:04:44,466 --> 00:04:47,794
API resource that are to be audited, such as pods,

70
00:04:47,842 --> 00:04:50,946
deployments or services. Then you have verbs which

71
00:04:50,988 --> 00:04:54,250
defines the kubernetes API verbs to be audited, such as create,

72
00:04:54,320 --> 00:04:58,314
update, or delete. Then of course you have users which you use to tell

73
00:04:58,352 --> 00:05:01,658
the audit service which kubernetes users or groups are to

74
00:05:01,664 --> 00:05:05,534
be audited. And finally namespaces, which as it implies just

75
00:05:05,572 --> 00:05:09,274
defines the Kubernetes namespaces you want to include in the audit collection.

76
00:05:09,402 --> 00:05:12,702
As I said before, the audit policy object is very

77
00:05:12,756 --> 00:05:15,938
flexible and configurable depending on your various needs.

78
00:05:16,104 --> 00:05:18,974
When creating your Kubernetes audit policy configuration,

79
00:05:19,102 --> 00:05:22,594
there's a lot to consider and it can be pretty intimidating at first.

80
00:05:22,712 --> 00:05:25,958
In general though, here are some good best practices to follow.

81
00:05:26,124 --> 00:05:30,066
First, clearly define the audit policy scope it's

82
00:05:30,098 --> 00:05:33,350
important to define the scope of the audit policy configuration object

83
00:05:33,500 --> 00:05:36,514
and identify the kubernetes, resources, verbs,

84
00:05:36,642 --> 00:05:40,194
users and namespaces that need to be audited. This will help ensure

85
00:05:40,242 --> 00:05:43,462
that the audit policy is focused on the areas that require

86
00:05:43,526 --> 00:05:46,906
auditing and is not overly broad, which can result in a

87
00:05:46,928 --> 00:05:50,186
bunch of spam that isn't really useful to anyone. It's hard

88
00:05:50,208 --> 00:05:53,790
to parse, expensive to store and obfuscates actual

89
00:05:53,860 --> 00:05:57,326
useful important log events. If you have millions and

90
00:05:57,348 --> 00:06:00,846
millions and millions of log lines, it's going to be really hard to

91
00:06:00,868 --> 00:06:04,382
actually access the good data, the useful data that you're wanting to keep track

92
00:06:04,436 --> 00:06:08,062
of. Another good practice is to use meaningful audit rule names.

93
00:06:08,126 --> 00:06:11,746
It's important to use meaningful names for audit rules to ensure that they are

94
00:06:11,768 --> 00:06:15,202
easily understood and maintainable. Names should clearly describe the event

95
00:06:15,256 --> 00:06:19,254
being audited, the resource, verb and other relevant attributes just

96
00:06:19,292 --> 00:06:22,290
as we all know, maintaining legacy code can be challenging.

97
00:06:22,450 --> 00:06:25,590
The same thing applies to audit configurations.

98
00:06:26,170 --> 00:06:29,226
You want to do yourself a favor for the future and make sure

99
00:06:29,248 --> 00:06:33,100
that you'll be able to parse what you wrote. Another important step is

100
00:06:33,630 --> 00:06:37,974
regularly reviewing audit logs regularly reviewing

101
00:06:38,022 --> 00:06:41,646
audit logs is an important step in maintaining the security and compliance of

102
00:06:41,668 --> 00:06:45,306
the Kubernetes cluster. It's important to establish a process for reviewing

103
00:06:45,338 --> 00:06:48,810
audit logs and to regularly review them to identify

104
00:06:48,890 --> 00:06:53,070
any anomalies or security risks. SiEM tools, security information

105
00:06:53,140 --> 00:06:57,010
and event management tools can help with this task. Another important step

106
00:06:57,080 --> 00:07:00,526
is to use a dedicated storage solution. Storing audit

107
00:07:00,558 --> 00:07:04,098
logs in a separate and dedicated storage solution can help opensource that they

108
00:07:04,104 --> 00:07:07,394
are protected and available for analysis and review. It also

109
00:07:07,432 --> 00:07:10,742
helps save space for the actual functioning of the cluster. It's important

110
00:07:10,796 --> 00:07:14,498
to use a secure and reliable storage solution that can handle the volume of audit

111
00:07:14,514 --> 00:07:16,790
logs generated by the Kubernetes cluster.

112
00:07:17,610 --> 00:07:21,174
S three, for example, is a very popular place to store audit logs,

113
00:07:21,302 --> 00:07:25,174
and from there you can pipe them to different solutions and have monitoring

114
00:07:25,222 --> 00:07:28,602
and alerting tools in place. Similar to the above, it's really important

115
00:07:28,656 --> 00:07:32,454
to aggregate your logs. This is especially important if you have multiple

116
00:07:32,502 --> 00:07:35,594
clusters or if you have many nodes in a single cluster.

117
00:07:35,722 --> 00:07:39,674
But aggregating all of your log data into a single location makes it much easier

118
00:07:39,722 --> 00:07:42,878
to filter, ingest and manage that log data.

119
00:07:42,964 --> 00:07:47,022
It helps with observability and compliance as well. It's easier to show an auditor

120
00:07:47,086 --> 00:07:50,914
one central secure location rather than having to prove compliance for

121
00:07:50,952 --> 00:07:54,558
dozens of different infrastructure resources. You're leveraging to help with logging

122
00:07:54,654 --> 00:07:58,242
while the native Kubernetes API logging is powerful by itself,

123
00:07:58,376 --> 00:08:02,066
all of the logs in the world are useless if you aren't actively monitoring

124
00:08:02,098 --> 00:08:05,554
them. Audit logging is more than just a postmortem reactive

125
00:08:05,602 --> 00:08:09,338
solution to help you figure out what happened after your cluster is already

126
00:08:09,424 --> 00:08:12,790
compromised. If properly configured and monitored,

127
00:08:12,870 --> 00:08:16,714
it can be used to prevent attacks as they happen, rather than just used

128
00:08:16,752 --> 00:08:20,506
to look for something or someone to blame after the fact.

129
00:08:20,608 --> 00:08:23,930
The simple truth is that, especially at scale, it's completely

130
00:08:24,000 --> 00:08:28,218
impractical for a security team to constantly be looking at these logs themselves manually.

131
00:08:28,314 --> 00:08:31,694
Luckily, there are a few great Opensource tools that can help. One of these

132
00:08:31,732 --> 00:08:34,878
tools that I really like is Falco. Falco is

133
00:08:34,884 --> 00:08:38,146
an Opensource cloud native runtime security project that can

134
00:08:38,168 --> 00:08:41,902
be used to detect an alert on anomalous behavior in Kubernetes clusters.

135
00:08:41,966 --> 00:08:45,118
It can be used to monitor an alert on Kubernetes audit logs,

136
00:08:45,214 --> 00:08:48,406
and it supports a wide range of rules for detecting security threats and

137
00:08:48,428 --> 00:08:52,194
policy violations. Falco can also be integrated with external systems

138
00:08:52,242 --> 00:08:55,478
for alerting and incident response. Another great tool

139
00:08:55,564 --> 00:08:59,386
is Openraven. Openraven can collect audit logs from

140
00:08:59,408 --> 00:09:02,566
kubernetes clusters, including API server logs,

141
00:09:02,678 --> 00:09:05,754
and logs from other Kubernetes components. A great

142
00:09:05,792 --> 00:09:09,286
feature of Openraven is that it can centralize these logs from multiple

143
00:09:09,318 --> 00:09:13,038
Kubernetes clusters, making it easier to manage and analyze them.

144
00:09:13,124 --> 00:09:16,762
Openraven can also analyze these logs to identify

145
00:09:16,826 --> 00:09:20,234
potential security threats and compliance issues. It includes

146
00:09:20,282 --> 00:09:24,094
pre built compliance rules for various regulations such as PCI,

147
00:09:24,222 --> 00:09:27,666
HIPAA, and GDPR, and it can be customized to

148
00:09:27,688 --> 00:09:31,154
meet specific compliance requirements. Another important feature is

149
00:09:31,192 --> 00:09:34,514
Openraven's real time alerting. This tool can send

150
00:09:34,552 --> 00:09:38,326
alerts for potential security threats or compliance violations based on

151
00:09:38,348 --> 00:09:42,594
the analysis of your audit logs. It can also integrate with external incident

152
00:09:42,642 --> 00:09:46,226
response systems for automated incident response. One drawback,

153
00:09:46,258 --> 00:09:49,366
however, is that it can be pretty difficult to configure, especially if

154
00:09:49,388 --> 00:09:53,206
you have a multicluster setup, and managing that complexity can be costly.

155
00:09:53,318 --> 00:09:56,726
Another good tool out there, though, is elastic. The elastic

156
00:09:56,758 --> 00:10:00,246
stack is a suite of open source tools that can be used for log management

157
00:10:00,278 --> 00:10:03,322
and analysis. It includes tools for collecting,

158
00:10:03,386 --> 00:10:07,050
processing, and analyzing logs, including Kubernetes audit logs.

159
00:10:07,130 --> 00:10:10,282
The elasticstack can be used to centralize these logs from Kubernetes

160
00:10:10,346 --> 00:10:14,194
clusters and it includes features for searching and analyzing this log data.

161
00:10:14,312 --> 00:10:18,334
Elasticstack can centralize these logs and allow for easier

162
00:10:18,382 --> 00:10:21,486
management and analysis. It can provide real time analysis

163
00:10:21,518 --> 00:10:25,686
of Kubernetes audit logs, allowing for faster detection and response to

164
00:10:25,708 --> 00:10:28,934
security threats, threats and compliance issues. It also

165
00:10:28,972 --> 00:10:32,486
comes with kibana, a powerful visualization tool that

166
00:10:32,508 --> 00:10:36,246
can help in understanding the logs and identifying trends, patterns and

167
00:10:36,268 --> 00:10:40,198
anomalies. It's pretty similar to Grafana, another honorable mention

168
00:10:40,284 --> 00:10:44,074
in our Opensource tooling. While all of those other solutions are great

169
00:10:44,192 --> 00:10:48,410
and a huge step up from just sifting through logs manually, none of them address

170
00:10:48,480 --> 00:10:52,142
the big picture of Kubernetes audit logging and security.

171
00:10:52,276 --> 00:10:55,582
This is in large part due to them missing the key component of

172
00:10:55,716 --> 00:10:59,434
access. Configuring access to your Kubernetes cluster

173
00:10:59,562 --> 00:11:03,786
managing who has access to what resources, when, how privilege escalation

174
00:11:03,818 --> 00:11:07,870
is handled, and providing can of custody over all of your different resources

175
00:11:07,950 --> 00:11:11,566
can be a huge hassle. Access is not divorced from audit

176
00:11:11,598 --> 00:11:15,566
logging practices, however, as a key part of audit logging is

177
00:11:15,608 --> 00:11:19,126
knowing exactly who or what, in the case

178
00:11:19,148 --> 00:11:22,706
of machines and automated workers, is executing commands

179
00:11:22,738 --> 00:11:26,038
on your Kubernetes cluster. Open source Teleport, which is

180
00:11:26,044 --> 00:11:29,482
a secure access control platform for managing access across

181
00:11:29,536 --> 00:11:32,714
your infrastructure, solves all of these problems while

182
00:11:32,752 --> 00:11:35,946
also centralizing your audit logging not only just for your

183
00:11:35,968 --> 00:11:39,762
Kubernetes resources, but for your SSH database,

184
00:11:39,926 --> 00:11:43,946
Windows RDP and application access. Centralizing your audit logging

185
00:11:43,978 --> 00:11:47,646
at scale for organizations requires you to go beyond just

186
00:11:47,668 --> 00:11:51,514
your various Kubernetes clusters. For a truly secure infrastructure

187
00:11:51,562 --> 00:11:55,234
setup, you need to implement all of the previous principles and best

188
00:11:55,272 --> 00:11:58,466
practices across your organization that

189
00:11:58,488 --> 00:12:01,986
tens all of your various infrastructure resources as soon as

190
00:12:02,008 --> 00:12:05,286
you have siloing, whether it be at the cluster level or at

191
00:12:05,308 --> 00:12:08,834
the cloud resource level. This creates much more overhead,

192
00:12:08,962 --> 00:12:13,010
meaningless duplication and headache for both your security engineers

193
00:12:13,090 --> 00:12:16,962
and cloud administrators. Teleport coupled with fluentd,

194
00:12:17,026 --> 00:12:20,394
which handles all of the plumbing so to speak,

195
00:12:20,512 --> 00:12:24,186
the formatting, exporting and consolidation of your logs is

196
00:12:24,208 --> 00:12:27,130
the ultimate solution for Kubernetes audit logging.

197
00:12:27,710 --> 00:12:31,294
With teleport, you can tie every event in Kubernetes to can

198
00:12:31,332 --> 00:12:35,086
identity, meaning that you'll know exactly who did what on

199
00:12:35,108 --> 00:12:38,400
any given resource. Even at the Kubernetes pod level,

200
00:12:38,770 --> 00:12:42,906
each event is audited based on your configured audit strategy tied

201
00:12:42,938 --> 00:12:46,386
to the entity's identity, mapped to a teleport user with

202
00:12:46,408 --> 00:12:49,842
a teleport RBAC role. This makes it easier than ever

203
00:12:49,896 --> 00:12:53,282
to configure secure access and thus ensuring secure use

204
00:12:53,336 --> 00:12:57,362
and best practice enforcement across your entire cloud ecosystem

205
00:12:57,506 --> 00:13:01,318
and this is not just for human engineers. Teleport machine id

206
00:13:01,404 --> 00:13:05,106
ensures that every microservice, process or automated worker

207
00:13:05,138 --> 00:13:08,646
node also has an identity in the form of short lived

208
00:13:08,678 --> 00:13:12,326
X 509 certificates, eliminating long lived credentials,

209
00:13:12,438 --> 00:13:15,606
access silos, and allowing for a full rich audit

210
00:13:15,638 --> 00:13:18,950
log in real time. Teleport fully eliminates secrets,

211
00:13:19,030 --> 00:13:22,634
replacing them with short lived certificates tied to a user's

212
00:13:22,682 --> 00:13:26,698
identity. And again, this is for every piece of infrastructure,

213
00:13:26,794 --> 00:13:30,334
not just your Kubernetes resources, centralizing everything,

214
00:13:30,452 --> 00:13:34,282
allowing for easy monitoring and log management for not only your Kubernetes

215
00:13:34,346 --> 00:13:37,774
cluster, but for every resource in your stack. Another powerful

216
00:13:37,822 --> 00:13:41,006
feature of teleport is that it actually allows for session playback

217
00:13:41,038 --> 00:13:43,570
of kubernetes sessions conducted over SSH,

218
00:13:43,910 --> 00:13:47,470
meaning that if someone is accessing a node in your cluster, you'll be able

219
00:13:47,480 --> 00:13:51,254
to prevent obfuscation of commands, allowing you to see exactly what is

220
00:13:51,292 --> 00:13:54,806
happening on your cluster. Teleport acts as a gateway for all of

221
00:13:54,828 --> 00:13:58,182
your resources, ensuring security and compliance across

222
00:13:58,236 --> 00:14:01,930
your entire infrastructure. So let's take a look at exactly what I mean

223
00:14:02,000 --> 00:14:05,366
when I say that it consolidates all of this access and audit logging

224
00:14:05,398 --> 00:14:08,806
into one place. So here we are in the teleport

225
00:14:08,838 --> 00:14:12,894
web UI. The first use case I'm going to show you is the

226
00:14:12,932 --> 00:14:16,830
session recording when you're accessing your kubernetes clusters over Ssh.

227
00:14:17,810 --> 00:14:21,486
So here we have our kubernetes cluster. It's called Cookie, which of

228
00:14:21,508 --> 00:14:25,410
course, and here we have all of our servers.

229
00:14:26,070 --> 00:14:29,746
Down here we can see this server called Kate's host, and this is

230
00:14:29,768 --> 00:14:32,610
actually the server that's hosting our kubernetes cluster.

231
00:14:34,390 --> 00:14:38,206
So if we log in, we can actually open an SSH session directly

232
00:14:38,238 --> 00:14:41,766
from the web terminal. And all of this session data is tied directly to my

233
00:14:41,788 --> 00:14:45,046
user and identity. So we can go

234
00:14:45,068 --> 00:14:48,758
ahead and execute a couple of commands here. We can say Kubectl

235
00:14:48,854 --> 00:14:52,822
git pods a we can see all these pods,

236
00:14:52,966 --> 00:14:55,500
we can go ahead and describe this one here,

237
00:14:56,350 --> 00:14:58,570
Kubectl describe,

238
00:14:58,990 --> 00:15:04,350
describe pod colormatic.

239
00:15:05,170 --> 00:15:08,314
We can see all of the pod's information. We can see the container

240
00:15:08,362 --> 00:15:11,662
id, which container image it's using, and some health

241
00:15:11,716 --> 00:15:15,266
about what the pod is doing. We can

242
00:15:15,288 --> 00:15:18,434
go ahead and exit this session now that we know our pod is

243
00:15:18,552 --> 00:15:22,046
functioning the way we should and that we know the container

244
00:15:22,078 --> 00:15:25,398
image now it's correct. We're going to go

245
00:15:25,404 --> 00:15:28,646
ahead and exit this session. Then we

246
00:15:28,668 --> 00:15:32,354
can come back in the web UI and go into our management

247
00:15:32,402 --> 00:15:36,242
session here. We can see when the session

248
00:15:36,306 --> 00:15:39,290
started and that the session has ended.

249
00:15:40,110 --> 00:15:43,946
We can go into the session recordings and actually view exactly what

250
00:15:43,968 --> 00:15:47,258
we did. And as we

251
00:15:47,264 --> 00:15:50,918
can see, these are the commands that we just ran within the session.

252
00:15:51,094 --> 00:15:54,646
And this is actually not a video, it's a rich Json

253
00:15:54,678 --> 00:15:58,014
log describing exactly all of the commands that we ran, which means

254
00:15:58,052 --> 00:16:01,594
that this whole session can be forwarded to other Siem

255
00:16:01,642 --> 00:16:05,558
tools or other logging management

256
00:16:05,594 --> 00:16:09,678
tools that we can actually monitor these so you can play back these sessions

257
00:16:09,854 --> 00:16:11,890
based on every command that we ran.

258
00:16:13,270 --> 00:16:16,646
So the next thing I wanted to show you is how we log into a

259
00:16:16,668 --> 00:16:20,594
Kubernetes cluster without using a teleport managed

260
00:16:20,642 --> 00:16:24,710
ssh node. So in this case I'm going to be using my personal workstation.

261
00:16:25,210 --> 00:16:29,014
So in here in our web UI, we can go to our Kubernetes

262
00:16:29,062 --> 00:16:32,010
resources and we find our cookie.

263
00:16:32,990 --> 00:16:36,618
So this is the same cluster that we were using before, but now we're going

264
00:16:36,624 --> 00:16:40,218
to access it from my workstation. So first we're

265
00:16:40,234 --> 00:16:44,110
going to go ahead and log into our teleport cluster.

266
00:16:45,090 --> 00:16:48,382
We're going to execute this Tsh login. Here's the

267
00:16:48,436 --> 00:16:52,846
address of our proxy, which is the publicly accessible

268
00:16:52,878 --> 00:16:54,770
address of our teleport cluster.

269
00:16:56,070 --> 00:16:58,340
And we're going to go ahead and log in.

270
00:17:01,300 --> 00:17:04,844
Great, we're logged in. This used the same authentication

271
00:17:04,892 --> 00:17:08,272
method as before. It logged in through my GitHub. So we're using GitHub

272
00:17:08,336 --> 00:17:12,084
as an SSO here. Next we're going to select what

273
00:17:12,122 --> 00:17:15,552
Kubernetes cluster we want. So right now we can do Tsh Cube

274
00:17:15,616 --> 00:17:19,044
ls and we can

275
00:17:19,082 --> 00:17:23,144
see all of the Kubernetes clusters that we have available to us. Right now my

276
00:17:23,182 --> 00:17:26,200
user role only has access to the cookie cluster.

277
00:17:27,100 --> 00:17:31,472
Next we're going to go ahead and log in to our Kubernetes cluster

278
00:17:31,556 --> 00:17:35,100
and this will actually give us the Kubeconfig from teleport.

279
00:17:38,820 --> 00:17:41,840
Going to take a second. Great. So we're logged in.

280
00:17:41,990 --> 00:17:45,840
Now let's try to get all of our pods.

281
00:17:46,660 --> 00:17:50,196
Awesome. So now we're in and we can run our commands on

282
00:17:50,218 --> 00:17:53,620
the cluster. So let's go ahead and do what we did before and

283
00:17:53,690 --> 00:18:00,296
let's describe this colormatic pod here in

284
00:18:00,318 --> 00:18:01,480
the namespace.

285
00:18:03,420 --> 00:18:04,520
Colormatic,

286
00:18:07,100 --> 00:18:10,568
great. So we can see all that same information that we saw before when we

287
00:18:10,574 --> 00:18:13,916
were connected to the direct host. Now even from

288
00:18:13,938 --> 00:18:17,932
my personal workstation we're securely logged in through teleport and can actually

289
00:18:17,986 --> 00:18:21,340
run Kubectl commands on our cluster.

290
00:18:22,000 --> 00:18:25,904
Now if we go back in our web UI we can

291
00:18:25,942 --> 00:18:29,664
actually see the results of our session here.

292
00:18:29,862 --> 00:18:33,836
So we can see that the certificate was issued for my user.

293
00:18:33,948 --> 00:18:37,776
We can see all of the details about that, the AWS

294
00:18:37,808 --> 00:18:41,236
role arns that I have access to, all of the various metadata for

295
00:18:41,258 --> 00:18:44,784
this session. All of this is tied

296
00:18:44,832 --> 00:18:48,612
directly to my identity and

297
00:18:48,666 --> 00:18:51,640
we can see all of the various Kubectl commands that we ran.

298
00:18:52,140 --> 00:18:55,288
We can see the request to the cluster and we can see all of the

299
00:18:55,294 --> 00:18:58,644
various metadata for that. We can see the Kubernetes users,

300
00:18:58,692 --> 00:19:02,104
the teleport login, the namespace, all of the different protocol

301
00:19:02,152 --> 00:19:05,564
information. And like I said before, all of this

302
00:19:05,602 --> 00:19:09,790
information is very easy to export and ingest in a seam tool

303
00:19:10,320 --> 00:19:14,200
for easy monitoring and easy alerting on anomalies

304
00:19:14,280 --> 00:19:17,856
and various other things. Because all of this is just raw Json that we can

305
00:19:17,958 --> 00:19:21,648
choose to use however we want and this

306
00:19:21,654 --> 00:19:25,372
is how we use teleport to from my workstation

307
00:19:25,516 --> 00:19:29,424
access it securely. All of the traffic passing through the teleport

308
00:19:29,472 --> 00:19:32,820
proxy all being centrally logged in one location.

309
00:19:33,880 --> 00:19:36,180
So that was teleport in action.

310
00:19:37,080 --> 00:19:40,336
Thank you so much for watching and check out some of the other talks.

311
00:19:40,368 --> 00:19:44,330
We got some great ones here at Comp 42 cloud native 2023.

312
00:19:44,940 --> 00:19:49,304
You can also check us out on Slack at teleport slack.com.

313
00:19:49,422 --> 00:19:53,128
I'm always hanging out there and am totally free to answer any questions you

314
00:19:53,134 --> 00:19:56,856
may have or any clarifications. Or if you need help getting started with

315
00:19:56,878 --> 00:20:00,984
Teleport, you can also check us out@teleport.com

316
00:20:01,102 --> 00:20:04,796
you can sign up for a cloud trial for our enterprise solution or download

317
00:20:04,828 --> 00:20:08,176
our open source version and try it out for yourself. However you start

318
00:20:08,198 --> 00:20:12,032
your journey with teleport, it's the easiest and most secure way to access

319
00:20:12,166 --> 00:20:15,790
all of your infrastructure. Thank you SoC much. Have a great day.

