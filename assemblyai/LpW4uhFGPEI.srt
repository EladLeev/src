1
00:00:39,170 --> 00:00:42,898
Hi. Today we are going to discuss but observability

2
00:00:42,994 --> 00:00:46,486
standardization, and we are

3
00:00:46,508 --> 00:00:50,014
going to see what I call the elephant that I believe

4
00:00:50,092 --> 00:00:53,562
still in the room. So a typical

5
00:00:53,706 --> 00:00:56,560
observability setup looks like this.

6
00:00:57,090 --> 00:01:01,086
So we have some kind of applications or

7
00:01:01,188 --> 00:01:04,674
systems that are exposing metrics. Then we

8
00:01:04,712 --> 00:01:08,366
have time series databases or logs

9
00:01:08,398 --> 00:01:11,762
databases where we centralize all our logs and all our

10
00:01:11,816 --> 00:01:15,814
metric data. And of course then we have a

11
00:01:15,852 --> 00:01:20,054
tool to provide dashboards. This tool

12
00:01:20,252 --> 00:01:23,974
usually queries this time

13
00:01:24,012 --> 00:01:27,726
series data or logs data and creates

14
00:01:27,778 --> 00:01:31,882
beautiful charts. And then we have alerting, an alerting engine that

15
00:01:31,936 --> 00:01:35,594
again performs the same. So it queries time

16
00:01:35,632 --> 00:01:38,794
series data and sends notifications if

17
00:01:38,832 --> 00:01:41,790
something exceeds the threshold.

18
00:01:42,130 --> 00:01:45,838
Now this has some issues and

19
00:01:46,004 --> 00:01:50,126
some complexity may sound simple, but there is

20
00:01:50,228 --> 00:01:53,786
a hidden complexity here. And this is what the hidden

21
00:01:53,818 --> 00:01:57,242
complexity is. In the time series databases,

22
00:01:57,386 --> 00:02:01,474
you have to check, you have to maintain first the database server itself.

23
00:02:01,592 --> 00:02:05,374
You have to take care of the high cardinality and the memory requirements

24
00:02:05,422 --> 00:02:08,418
of that thing, the disk I o requirements.

25
00:02:08,594 --> 00:02:12,230
And you have to think about clustering and high availability.

26
00:02:12,730 --> 00:02:15,894
In the logs database you have the similar thing, but also on top

27
00:02:15,932 --> 00:02:19,882
of it you have a query performance issue, so that in many

28
00:02:19,936 --> 00:02:24,186
cases you have to maintain the indexes of the

29
00:02:24,368 --> 00:02:27,626
log streams that are available. You have

30
00:02:27,648 --> 00:02:31,306
to maintain retention, and you also have the same problem of clustering

31
00:02:31,338 --> 00:02:35,006
availability, high availability, et cetera. Then on the

32
00:02:35,028 --> 00:02:38,654
dashboarding tool, you have to first

33
00:02:38,772 --> 00:02:41,946
learn the query languages of the other database,

34
00:02:42,058 --> 00:02:46,082
of the database servers so that you can query them and create

35
00:02:46,216 --> 00:02:48,994
useful dashboards with the data they have.

36
00:02:49,192 --> 00:02:52,820
These query engines are usually

37
00:02:53,350 --> 00:02:56,470
good in order to convert counters to

38
00:02:56,620 --> 00:03:00,386
rates or aggregate metrics together, correlate metrics

39
00:03:00,418 --> 00:03:04,086
together with some aggregation functions, pivot them, group them in

40
00:03:04,108 --> 00:03:07,446
a way in order to present them, et cetera. So you have

41
00:03:07,468 --> 00:03:10,810
to learn a query language and you also have to learn

42
00:03:10,960 --> 00:03:14,794
what the visualization tool can do, how, what kind

43
00:03:14,832 --> 00:03:18,506
of visualizations you have available, what kind of customizations are

44
00:03:18,528 --> 00:03:21,806
there available. So in order to

45
00:03:21,828 --> 00:03:26,010
have at the end a meaningful monitoring solution

46
00:03:26,170 --> 00:03:29,994
and something similar exists also, some kind of complexity exists

47
00:03:30,042 --> 00:03:33,118
also for alerting. So while building this,

48
00:03:33,284 --> 00:03:36,786
what you need is a deep understanding, first of

49
00:03:36,808 --> 00:03:41,070
the metrics that you have. So you need to know what the database

50
00:03:41,150 --> 00:03:44,594
has and what labels are there, how you should

51
00:03:44,632 --> 00:03:47,942
query them. In order

52
00:03:47,996 --> 00:03:51,170
to maintain this processing pipeline,

53
00:03:51,330 --> 00:03:54,834
you need to go through various steps

54
00:03:54,882 --> 00:03:58,314
of configurations in

55
00:03:58,352 --> 00:04:02,266
different phases. So in order, for example, to reduce the

56
00:04:02,288 --> 00:04:06,554
cardinality of some metrics, you may have to relabel some

57
00:04:06,592 --> 00:04:10,106
of the metrics. At some point you have

58
00:04:10,128 --> 00:04:14,080
to learn the query language that, the languages that we said,

59
00:04:14,450 --> 00:04:17,598
you need to understand the tools and have a very good understanding of

60
00:04:17,604 --> 00:04:21,566
the tools. And of course you need experience. So if you

61
00:04:21,588 --> 00:04:25,246
don't know, if you have never done this before, most likely you are

62
00:04:25,268 --> 00:04:28,786
doomed. You know, you need to have an understanding of what

63
00:04:28,808 --> 00:04:32,094
is a heat map, what's a histogram, how to visualize

64
00:04:32,142 --> 00:04:35,654
this kind of data. You need to have a lot of best

65
00:04:35,692 --> 00:04:39,830
practices in order for this to be actually

66
00:04:39,900 --> 00:04:42,790
useful for people while troubleshooting.

67
00:04:43,210 --> 00:04:46,102
If you are at scale, then you have additional problems.

68
00:04:46,236 --> 00:04:49,450
So you have to go through scalability challenges,

69
00:04:49,790 --> 00:04:53,354
how the database servers can be scaled, how I can

70
00:04:53,392 --> 00:04:56,746
have high availability there. You have to

71
00:04:56,928 --> 00:05:00,182
work on the data overload and the noise

72
00:05:00,246 --> 00:05:03,354
that may exist in all these dashboards,

73
00:05:03,402 --> 00:05:06,766
in all these alerts, et cetera. You have a

74
00:05:06,788 --> 00:05:10,206
cost management aspect that is important and you have

75
00:05:10,228 --> 00:05:13,486
to manage because you may need at some point to

76
00:05:13,508 --> 00:05:17,054
cherry pick what you want, what you really want, what is really useful

77
00:05:17,102 --> 00:05:20,446
for you, because otherwise the cost of the monitoring

78
00:05:20,478 --> 00:05:23,666
infrastructure will skyrocket. And of course you have

79
00:05:23,688 --> 00:05:26,966
to check also compliance and security. So you

80
00:05:26,988 --> 00:05:30,674
have to check what kind of information is in your logs

81
00:05:30,722 --> 00:05:34,086
and who has access to them and all this kind

82
00:05:34,108 --> 00:05:36,840
of stuff. If you're in a team,

83
00:05:37,450 --> 00:05:41,034
you have an additional layer, then you have

84
00:05:41,072 --> 00:05:44,550
to come up with some kind of monitoring policies.

85
00:05:44,710 --> 00:05:48,710
You have to agree on a unified monitoring framework.

86
00:05:48,870 --> 00:05:52,474
You have to have some kind of change management and shared

87
00:05:52,522 --> 00:05:58,000
responsibility on the dashboards and the alerts and

88
00:05:58,850 --> 00:06:02,350
the data in general that are in these database servers.

89
00:06:03,430 --> 00:06:07,300
You have to take care of documenting everything and

90
00:06:07,670 --> 00:06:10,770
letting others know how this thing works,

91
00:06:10,920 --> 00:06:14,366
what they should do, how this needs to be changed, et cetera.

92
00:06:14,478 --> 00:06:18,760
And you need to have quite some discipline in order to

93
00:06:19,370 --> 00:06:22,440
follow your design principles always.

94
00:06:23,210 --> 00:06:25,960
Otherwise it usually becomes a mess.

95
00:06:26,570 --> 00:06:29,382
So to understand this,

96
00:06:29,516 --> 00:06:33,162
I asked Chachi PT to come

97
00:06:33,216 --> 00:06:36,700
up with a few phrases that actually

98
00:06:39,630 --> 00:06:43,262
they are the challenges, let's say that these engineers that

99
00:06:43,396 --> 00:06:47,242
work on a monitoring setup have in their minds

100
00:06:47,306 --> 00:06:50,634
every day what they usually think, what are the challenges

101
00:06:50,682 --> 00:06:54,146
they face every day. CHPT came up

102
00:06:54,248 --> 00:06:59,106
with this, so I made it a word cloud for

103
00:06:59,128 --> 00:07:02,418
us to see. So CHPT, you rate them with a

104
00:07:02,424 --> 00:07:06,566
frequency, how frequently its

105
00:07:06,668 --> 00:07:10,406
phrase comes up, and this

106
00:07:10,428 --> 00:07:13,506
is what it came with. So balance, scrape,

107
00:07:13,538 --> 00:07:17,030
interval structure, multidimensional query

108
00:07:17,390 --> 00:07:21,094
test and validate queries, monitoring exporter,

109
00:07:21,142 --> 00:07:25,142
health time series, database I o bottlenecks,

110
00:07:25,206 --> 00:07:28,554
dynamic alert, threshold, regular expressions for

111
00:07:28,592 --> 00:07:31,690
label rematching, federation efficiency,

112
00:07:32,110 --> 00:07:36,126
fine tune, chart access and scales, filter metrics and

113
00:07:36,148 --> 00:07:40,058
exporters. You see, it's all the details

114
00:07:40,234 --> 00:07:43,826
that people have to go through

115
00:07:44,008 --> 00:07:46,850
in order to have a monitoring,

116
00:07:47,990 --> 00:07:51,634
to build a monitoring with such a setup. Now, I also

117
00:07:51,672 --> 00:07:55,462
asked satypt to tell me what people

118
00:07:55,516 --> 00:07:59,462
that are monitoring infrastructure are usually thinking of

119
00:07:59,596 --> 00:08:04,454
independently of the monitoring system. So what people should

120
00:08:04,492 --> 00:08:08,598
be thinking in general when they are responsible

121
00:08:08,694 --> 00:08:12,666
for the performance and the stability and the availability of some kind

122
00:08:12,688 --> 00:08:16,602
of infrastructure. And touch APD came up with this

123
00:08:16,656 --> 00:08:19,942
list. Now, this list is quite

124
00:08:20,016 --> 00:08:23,418
different. Now it says, incidents, response,

125
00:08:23,514 --> 00:08:27,210
application stability, data encryption, cost optimization,

126
00:08:27,370 --> 00:08:31,722
service availability, client satisfaction, operational efficiency.

127
00:08:31,786 --> 00:08:34,834
It's completely different. It's another level,

128
00:08:35,032 --> 00:08:38,946
actually. Now this is what I think is

129
00:08:38,968 --> 00:08:42,610
the gap of the current monitoring tools.

130
00:08:43,110 --> 00:08:46,306
Most of our monitoring tools, most of the monitoring tools that exist

131
00:08:46,338 --> 00:08:50,662
today force us to think like

132
00:08:50,716 --> 00:08:53,670
this. This is the challenges we face every day,

133
00:08:53,820 --> 00:08:57,106
how to do this little thing, how to create a heat map

134
00:08:57,138 --> 00:09:01,206
query for quantiles, how to configure external labels.

135
00:09:01,398 --> 00:09:05,306
These are details of the internals of

136
00:09:05,328 --> 00:09:08,602
the monitoring system. While the other list,

137
00:09:08,656 --> 00:09:12,894
this list is what we

138
00:09:12,932 --> 00:09:16,590
need our engineers to think. This is their

139
00:09:16,660 --> 00:09:20,366
primary role. This is what they need to achieve. This is what they need

140
00:09:20,388 --> 00:09:23,314
to focus on. Now, some may think,

141
00:09:23,352 --> 00:09:27,918
okay, wait a moment, we have a lot of standardization

142
00:09:28,014 --> 00:09:31,442
bodies that are taking care of this. Of course,

143
00:09:31,496 --> 00:09:34,990
we do have, and we have, for example,

144
00:09:35,080 --> 00:09:39,506
open telemetry, we have CNCF,

145
00:09:39,618 --> 00:09:43,462
we have w three c, et cetera. But you know what?

146
00:09:43,516 --> 00:09:47,518
If you actually check what all these standardization

147
00:09:47,634 --> 00:09:50,794
bodies do, is the following. Do you remember

148
00:09:50,832 --> 00:09:55,274
this chart, this graph that we started with? They focus

149
00:09:55,472 --> 00:09:58,140
here. So what they do,

150
00:09:58,590 --> 00:10:02,522
all our standardization effort is

151
00:10:02,576 --> 00:10:06,046
above data exchange is, okay,

152
00:10:06,228 --> 00:10:09,566
let everyone have all the data. If you need the

153
00:10:09,588 --> 00:10:13,566
data, okay, take them. But all the complexity

154
00:10:13,758 --> 00:10:17,326
that we have is outside this. Of course, this is an enabler.

155
00:10:17,358 --> 00:10:20,750
We need it. It's good to have data compatibility

156
00:10:20,830 --> 00:10:23,060
and being able to exchange data,

157
00:10:24,890 --> 00:10:28,262
because otherwise it's a lot more complex. But I think that the

158
00:10:28,316 --> 00:10:32,482
most important aspects of efficient

159
00:10:32,546 --> 00:10:36,374
monitoring are not there. So actually we

160
00:10:36,412 --> 00:10:40,790
don't have any standardization. This lack of standardization

161
00:10:41,850 --> 00:10:45,898
is actually the major

162
00:10:45,984 --> 00:10:50,146
shift in our focus. So instead of improving

163
00:10:50,278 --> 00:10:54,654
our infrastructure, we spent most of our time in

164
00:10:54,692 --> 00:10:58,526
a sea of challenges around

165
00:10:58,708 --> 00:11:02,366
the monitoring itself, about how to achieve something with

166
00:11:02,388 --> 00:11:05,060
the monitoring system. Now,

167
00:11:05,990 --> 00:11:09,186
I also researched what analysts say.

168
00:11:09,368 --> 00:11:12,734
So for analysts, they have this DevOps

169
00:11:12,782 --> 00:11:16,342
role. The DevOps role that is supposed

170
00:11:16,396 --> 00:11:20,054
to be the clue, is supposed to

171
00:11:20,092 --> 00:11:24,982
fix the gaps in this thing. But now what

172
00:11:25,036 --> 00:11:28,678
analysts believe is that the DevOps,

173
00:11:28,774 --> 00:11:32,810
the DevOps guy, a DevOps guy is a data scientist

174
00:11:33,790 --> 00:11:37,594
who understands software engineering and

175
00:11:37,632 --> 00:11:40,734
is an IT network architect at the same time.

176
00:11:40,772 --> 00:11:44,410
So he understands technology as a sysadmin,

177
00:11:44,570 --> 00:11:47,834
software as a developer, and data science

178
00:11:47,882 --> 00:11:51,774
as a data scientist, and it's a combination of these

179
00:11:51,812 --> 00:11:55,586
three. So what the analysts are saying is actually that there

180
00:11:55,608 --> 00:11:58,340
is a guy or a girl, of course,

181
00:11:58,710 --> 00:12:02,850
that knows what is coefficient of variation,

182
00:12:03,830 --> 00:12:07,106
that knows what is IPC instructions per cycle,

183
00:12:07,218 --> 00:12:11,160
and somehow can figure out if an application,

184
00:12:11,610 --> 00:12:15,362
a running capital texture production application, is memory

185
00:12:15,426 --> 00:12:19,420
bound or cpu bound, and at the same time can understand

186
00:12:20,670 --> 00:12:24,230
what is the disk utilization of an NVMe

187
00:12:24,310 --> 00:12:27,690
or an SSD disk, what's I ops and

188
00:12:27,760 --> 00:12:31,230
under which conditions such a disk, for example,

189
00:12:31,380 --> 00:12:34,830
can get congested. To my understanding,

190
00:12:35,330 --> 00:12:39,440
the whole thing is a utopia. So these

191
00:12:39,810 --> 00:12:43,138
people that can actually

192
00:12:43,304 --> 00:12:47,442
know data science, the vast area of data

193
00:12:47,496 --> 00:12:52,078
science, have huge experience in software engineering,

194
00:12:52,254 --> 00:12:55,960
and have vast experience in

195
00:12:57,370 --> 00:13:01,974
IT infrastructure and network architecture in

196
00:13:02,012 --> 00:13:05,654
some companies, bigger companies solve this

197
00:13:05,692 --> 00:13:09,026
problem by having a lot of roles. So they have an army of

198
00:13:09,068 --> 00:13:13,126
people to take care of. A few things like the monitoring,

199
00:13:13,238 --> 00:13:16,842
but for smaller or medium sized companies, and also

200
00:13:16,896 --> 00:13:20,350
for a lot of force 500 companies that don't invest

201
00:13:20,420 --> 00:13:23,450
in this, this is a breakpoint.

202
00:13:23,530 --> 00:13:27,262
So this kind of engineers that have

203
00:13:27,316 --> 00:13:31,386
all these magical knowledge, experience and skills,

204
00:13:31,498 --> 00:13:33,070
simply does not exist.

205
00:13:34,390 --> 00:13:37,890
Now the result for all of us, the result

206
00:13:37,960 --> 00:13:41,700
for most companies is something like this.

207
00:13:42,070 --> 00:13:45,986
So monitoring is very expensive and

208
00:13:46,088 --> 00:13:49,942
a constant strangy. So it's never

209
00:13:50,076 --> 00:13:54,040
complete, never finished, never. Okay, never enough.

210
00:13:56,650 --> 00:13:58,810
While being extremely expensive,

211
00:14:01,070 --> 00:14:03,638
it requires a lot of skills.

212
00:14:03,814 --> 00:14:06,540
And actually for most of the companies,

213
00:14:07,150 --> 00:14:10,906
the kind, the quality of the monitoring they have reflects the

214
00:14:10,928 --> 00:14:14,782
skills of the engineers. So if they have good engineers, they have good

215
00:14:14,916 --> 00:14:18,202
monitoring. If the engineers are not that experienced,

216
00:14:18,266 --> 00:14:22,270
do not have that many skills, then the monitoring is a toy. It's a joke.

217
00:14:22,870 --> 00:14:26,100
Frequently we see, even in very big companies,

218
00:14:26,870 --> 00:14:31,470
that monitoring is severely under engineered.

219
00:14:31,630 --> 00:14:35,206
So it's next to zero. They have some

220
00:14:35,228 --> 00:14:38,262
kind of visibility on the workload, but that's it.

221
00:14:38,396 --> 00:14:41,110
This is where it starts, then attends.

222
00:14:41,610 --> 00:14:46,082
And it's frequently illusional,

223
00:14:46,226 --> 00:14:49,978
and I say illusional. I was the first that to experience this.

224
00:14:50,064 --> 00:14:52,940
So before I built any data,

225
00:14:54,910 --> 00:14:58,726
I spent quite some time in monitoring,

226
00:14:58,918 --> 00:15:02,542
and I had quite some

227
00:15:02,596 --> 00:15:06,398
money and time and effort in monitoring, and I

228
00:15:06,404 --> 00:15:10,078
had built a great team. But at the end of the day,

229
00:15:10,164 --> 00:15:13,758
I had the impression that everything that I have built,

230
00:15:13,924 --> 00:15:17,758
all the dashboards and all the tools and everything that has been installed,

231
00:15:17,854 --> 00:15:21,394
is there just to make me happy, because I cannot troubleshoot anything with

232
00:15:21,432 --> 00:15:24,500
it. It's not useful for what I needed.

233
00:15:24,890 --> 00:15:28,070
So in many cases, I still see this today.

234
00:15:28,220 --> 00:15:32,594
With many companies that we cooperate with, that the monitoring

235
00:15:32,642 --> 00:15:33,430
gaps,

236
00:15:35,850 --> 00:15:40,182
and it leads them, the monitoring inefficiency

237
00:15:40,326 --> 00:15:44,326
leads them to wrong conclusions, to increase

238
00:15:44,358 --> 00:15:48,070
their time, to resolution, a lot of frustration, a lot of issues, et cetera.

239
00:15:48,150 --> 00:15:53,146
Lost money, of course. So now

240
00:15:53,168 --> 00:15:56,880
I'm going to talk to you about Netdata. Netdata is an open source tool

241
00:15:57,490 --> 00:16:00,506
that provides opinionated observability.

242
00:16:00,618 --> 00:16:03,706
So the idea of net data was to solve

243
00:16:03,898 --> 00:16:07,120
all these problems that we saw so far.

244
00:16:07,570 --> 00:16:11,218
The idea of netdata, let me tell you a

245
00:16:11,224 --> 00:16:15,058
few things. So the first thing is that it was born out of a need.

246
00:16:15,224 --> 00:16:18,280
So I needed the dumb thing.

247
00:16:18,730 --> 00:16:22,422
I had problems. I had issues with some infrastructure and

248
00:16:22,476 --> 00:16:26,200
I couldn't solve them. I spent quite some time there.

249
00:16:27,290 --> 00:16:31,094
The problems remained. So after several months of frustration and lost

250
00:16:31,142 --> 00:16:35,066
money and lost effort, I decided that

251
00:16:35,168 --> 00:16:39,206
I should do something about it. Since the monitoring tools that exist

252
00:16:39,238 --> 00:16:42,734
today, they are not sufficient enough for

253
00:16:42,772 --> 00:16:46,480
this kind of job, then we need a new monitoring tool.

254
00:16:46,850 --> 00:16:50,750
Initially, it was out of curiosity, so I said, okay, let's build

255
00:16:50,820 --> 00:16:55,106
something. Let's see if we can build something. Because I couldn't believe

256
00:16:55,288 --> 00:16:59,006
that all the monitoring

257
00:16:59,038 --> 00:17:02,820
tools have this design

258
00:17:03,910 --> 00:17:06,658
out of, I don't know, accident.

259
00:17:06,834 --> 00:17:10,726
So I was thinking that, okay, they tried different ways and this

260
00:17:10,748 --> 00:17:13,800
is the only way that actually worked.

261
00:17:14,650 --> 00:17:18,134
So it was curiosity why they didn't do monitoring

262
00:17:18,182 --> 00:17:21,766
real time, why they don't ingest all the metrics,

263
00:17:21,798 --> 00:17:24,154
why cardinality is such a big problem,

264
00:17:24,352 --> 00:17:28,486
why monitoring systems

265
00:17:28,518 --> 00:17:31,886
don't work out of the box, they don't come predefined with

266
00:17:31,908 --> 00:17:35,790
the dashboards and the likes that we all have, et cetera.

267
00:17:36,210 --> 00:17:39,342
So I started building it,

268
00:17:39,476 --> 00:17:42,666
and after a couple of years, I released it on GitHub.

269
00:17:42,778 --> 00:17:46,178
It was on GitHub from the first day, but I actually pressed the button to

270
00:17:46,184 --> 00:17:49,794
release it. Anyway, nothing happened. It was a funny story. Nothing happened.

271
00:17:49,832 --> 00:17:53,998
So one day on Reddit, I posted and boom, it skyrocketed.

272
00:17:54,174 --> 00:17:57,542
So the data way says that we

273
00:17:57,596 --> 00:18:01,382
all have a lot in common. So my

274
00:18:01,436 --> 00:18:04,710
infrastructure, your infrastructure, their infrastructure,

275
00:18:06,490 --> 00:18:10,822
we are using the same components,

276
00:18:10,886 --> 00:18:15,146
the same parts of a Lego. So we

277
00:18:15,168 --> 00:18:19,050
are using the same or similar physical and virtual hardware,

278
00:18:19,470 --> 00:18:23,306
similar operating systems. These are finite

279
00:18:23,418 --> 00:18:27,082
sets of stuff. It's not infinite. The combinations

280
00:18:27,226 --> 00:18:30,638
are infinite. So we can combine these Lego things,

281
00:18:30,724 --> 00:18:33,762
these building blocks, the way we see fit.

282
00:18:33,896 --> 00:18:38,382
But all the building blocks are pretty much packaged

283
00:18:38,526 --> 00:18:42,130
today, even for custom

284
00:18:42,200 --> 00:18:46,038
applications, applications that we built ourselves. In most of

285
00:18:46,044 --> 00:18:49,350
the cases, we use standard libraries, and these standard

286
00:18:49,420 --> 00:18:53,286
libraries expose their telemetry in a standard and

287
00:18:53,308 --> 00:18:56,518
predictable and expected way. So even for custom

288
00:18:56,604 --> 00:19:00,854
applications today, this becomes increasingly

289
00:19:00,902 --> 00:19:03,020
true, incrementally true.

290
00:19:03,950 --> 00:19:07,866
As time passes, even these custom applications will

291
00:19:07,888 --> 00:19:12,160
be completely packaged like packets. They will

292
00:19:12,850 --> 00:19:17,034
provide a finite and predictable and expected

293
00:19:17,082 --> 00:19:20,398
set of metrics that we can all consume to actually say if the

294
00:19:20,404 --> 00:19:24,082
application is healthy or not. Of course, there will be

295
00:19:24,136 --> 00:19:27,586
common metrics, sorry, custom metrics all the time.

296
00:19:27,768 --> 00:19:30,914
So we have a lot

297
00:19:30,952 --> 00:19:34,610
in common. The next thing is that I wanted

298
00:19:34,680 --> 00:19:38,518
high fidelity monitoring. High fidelity monitoring means

299
00:19:38,604 --> 00:19:42,470
everything collected every second. Like the console tools.

300
00:19:43,690 --> 00:19:47,230
My original idea was to kill the console

301
00:19:47,410 --> 00:19:49,450
for troubleshooting.

302
00:19:51,550 --> 00:19:54,986
What most monitoring tools provide is a

303
00:19:55,008 --> 00:19:58,602
helicopter view, so you can see that

304
00:19:58,736 --> 00:20:02,318
the road is congested, you can see the dive or

305
00:20:02,324 --> 00:20:06,062
the spike on that thing, but you cannot actually see what's happening.

306
00:20:06,116 --> 00:20:09,038
Why is that? This is a helicopter view.

307
00:20:09,204 --> 00:20:12,850
So this happens mainly because they want

308
00:20:12,920 --> 00:20:15,758
the minimum all, including commercial providers,

309
00:20:15,854 --> 00:20:19,454
including companies that provide monitoring

310
00:20:19,502 --> 00:20:22,686
solutions as a service. They do this because it's

311
00:20:22,718 --> 00:20:26,054
expensive to ingest all the

312
00:20:26,092 --> 00:20:30,054
information, so they prefer to select which

313
00:20:30,092 --> 00:20:33,894
information to ingest and maintain so

314
00:20:33,932 --> 00:20:37,126
that you can have the helicopter view that you need.

315
00:20:37,228 --> 00:20:41,194
But once it comes to the actual details of what is

316
00:20:41,232 --> 00:20:44,806
happening there, why this is happening like this, they don't

317
00:20:44,838 --> 00:20:48,538
have any information to help. And this is where the console tools usually

318
00:20:48,624 --> 00:20:52,426
come in place. So with Netdata, I wanted the console

319
00:20:52,458 --> 00:20:56,346
tools, I wanted to kill the console for monitoring.

320
00:20:56,458 --> 00:21:00,094
So every metric that you can find in console, it should

321
00:21:00,132 --> 00:21:03,850
be available in the monitoring system without exceptions,

322
00:21:03,930 --> 00:21:07,498
even if something is extremely rare or is

323
00:21:07,524 --> 00:21:11,186
not very common to be used. The next thing

324
00:21:11,208 --> 00:21:14,900
is that I wanted all the metrics visualized, so I don't, come on,

325
00:21:15,530 --> 00:21:18,934
it's an Nginx, it's a database postgres. I don't want to

326
00:21:18,972 --> 00:21:22,342
configure visualization for

327
00:21:22,396 --> 00:21:25,160
this packaged application myself. Why do you do that?

328
00:21:25,690 --> 00:21:29,174
It exposes workload and errors and this

329
00:21:29,212 --> 00:21:32,266
and that, and tables and index performance and whatever it is.

330
00:21:32,368 --> 00:21:35,658
But I want this visualization to come out of

331
00:21:35,664 --> 00:21:39,306
the box. The next is that I didn't want

332
00:21:39,328 --> 00:21:43,102
to learn a new query language, so I wanted to have all

333
00:21:43,156 --> 00:21:46,782
the controls required directly on the dashboard to actually

334
00:21:46,836 --> 00:21:50,190
slice and dice the data the way I see fit.

335
00:21:50,340 --> 00:21:54,014
So in the data, we have added a nice ribbon

336
00:21:54,062 --> 00:21:57,822
above every chart that allows you to filter the data, slow slice

337
00:21:57,886 --> 00:22:01,506
the data by label or by whatever

338
00:22:01,608 --> 00:22:05,182
node, instance, whatever it is there, but also to

339
00:22:05,256 --> 00:22:09,234
group them differently. So it's like a cube to see different aspects

340
00:22:09,282 --> 00:22:12,998
of the cube. And of course

341
00:22:13,084 --> 00:22:15,762
we added unsupervised anomaly detection.

342
00:22:15,826 --> 00:22:19,254
And this is an innovation we have among

343
00:22:19,302 --> 00:22:23,302
all the other monitoring solutions, mainly because our anomaly detection

344
00:22:23,366 --> 00:22:27,126
happens for all metrics unconditionally and it's totally

345
00:22:27,158 --> 00:22:31,358
unsupervised, so you don't need to provide feedback to it. This is what unsupervised means.

346
00:22:31,444 --> 00:22:34,734
You don't have to train it yourself. Also, it is

347
00:22:34,772 --> 00:22:38,286
trained at the edge, so we don't train somewhere what

348
00:22:38,468 --> 00:22:42,080
a good postgres means and actually give you

349
00:22:43,010 --> 00:22:46,198
the model to apply it to your database.

350
00:22:46,314 --> 00:22:49,358
You will never, it will be full of false positives.

351
00:22:49,454 --> 00:22:53,074
Mainly because in monitoring you have the workload that

352
00:22:53,112 --> 00:22:57,026
determines the actually queries that you send to a database server

353
00:22:57,138 --> 00:23:00,786
determine what the metrics will do. So it's

354
00:23:00,818 --> 00:23:04,758
impossible to learn to share

355
00:23:04,924 --> 00:23:08,826
models. The only viable solution is to train

356
00:23:09,008 --> 00:23:13,930
models for each metric individually

357
00:23:14,350 --> 00:23:18,458
and out of the box. Alerts for alerts what I wanted is to actually

358
00:23:18,624 --> 00:23:22,238
have predefined alerts that once they see a

359
00:23:22,244 --> 00:23:25,866
network interface, they attach to it. They see this, they attach disk

360
00:23:25,898 --> 00:23:29,280
alerts attached to it, they see, I don't know,

361
00:23:30,130 --> 00:23:34,314
hardware sensors, they attach to them, they see a postgres database,

362
00:23:34,362 --> 00:23:37,646
they see a web server, they attach to them automatically.

363
00:23:37,758 --> 00:23:41,474
So in a data today sips with hundreds. Actually we

364
00:23:41,512 --> 00:23:44,830
counted a few days before, it is 344

365
00:23:45,000 --> 00:23:48,434
distinct alerts that are all dynamic.

366
00:23:48,482 --> 00:23:52,214
So there are no fixed threshold there. There are all

367
00:23:52,252 --> 00:23:55,590
of them rolling windows, et cetera, et cetera. So they compare

368
00:23:56,570 --> 00:24:01,066
different parts of the metric to understand if

369
00:24:01,168 --> 00:24:05,178
there is a big spike or a big dive or an attack

370
00:24:05,344 --> 00:24:08,778
or something wrong. And of course there are plenty of alarms that

371
00:24:08,784 --> 00:24:12,270
are just counting errors or things that are mathematically,

372
00:24:12,610 --> 00:24:16,142
even if there is one, there is an error condition of it and

373
00:24:16,276 --> 00:24:19,040
users need to be alerted. Now,

374
00:24:19,810 --> 00:24:23,362
Netdata, I wanted also netdata to

375
00:24:23,416 --> 00:24:26,286
be able to be installed mid crisis.

376
00:24:26,478 --> 00:24:30,126
So you have a crisis, you never installed Netdata

377
00:24:30,158 --> 00:24:34,018
before. You can install Netdata right there

378
00:24:34,104 --> 00:24:37,586
while the thing is happening and Netdata will be

379
00:24:37,608 --> 00:24:40,534
able to help you figure it out. You are not going to have the help

380
00:24:40,572 --> 00:24:44,358
of the anomaly detection because this thing needs to

381
00:24:44,524 --> 00:24:48,558
learn what is normal in order to help you. But Netdata

382
00:24:48,674 --> 00:24:51,818
has a lot of tools, additional tools on

383
00:24:51,824 --> 00:24:55,994
top of anomaly detection that will

384
00:24:56,032 --> 00:24:58,458
help you identify what is wrong,

385
00:24:58,544 --> 00:25:02,426
correlate what is happening, find similarities in metrics,

386
00:25:02,538 --> 00:25:06,634
et cetera. It will also allow you to explore the journal logs

387
00:25:06,682 --> 00:25:10,400
directly on the servers. So all this

388
00:25:10,770 --> 00:25:14,866
is about removing the focus

389
00:25:15,048 --> 00:25:19,010
of the monitoring system of what the monitoring system

390
00:25:19,080 --> 00:25:22,770
internals from users and putting some extra

391
00:25:22,840 --> 00:25:26,050
knowledge into the tool. So unlike, for example,

392
00:25:26,120 --> 00:25:29,606
if you take Prometheus and Grafana, when you get them and you

393
00:25:29,628 --> 00:25:33,046
install them, they are blank, they cannot do anything. They are

394
00:25:33,068 --> 00:25:37,186
just a database server. And the visualization engine, great. They are great database

395
00:25:37,218 --> 00:25:40,394
server and great visualization engine, but there is

396
00:25:40,432 --> 00:25:44,202
no use of them if you don't go through the process of

397
00:25:44,256 --> 00:25:47,100
configuring them, setting them up,

398
00:25:47,630 --> 00:25:51,034
pushing metrics to them, et cetera, in the data. The story

399
00:25:51,152 --> 00:25:54,406
is quite different. So data knows

400
00:25:54,518 --> 00:25:58,286
the metrics, it knows already when we ship it. It knows how

401
00:25:58,308 --> 00:26:01,354
to collect cpu metrics, memory metrics, container metrics,

402
00:26:01,402 --> 00:26:02,830
database metrics.

403
00:26:05,750 --> 00:26:08,130
It comes with pre configured alerts,

404
00:26:08,550 --> 00:26:12,194
so it knows how to visualize the metrics correlate and come up with

405
00:26:12,232 --> 00:26:16,006
meaningful visualizations. So the idea is that data is a

406
00:26:16,028 --> 00:26:19,622
monitoring out of the box, it's ready

407
00:26:19,756 --> 00:26:23,910
to be used. The internals of what is happening there and

408
00:26:24,060 --> 00:26:27,474
why this is like this, and how to convert a founder,

409
00:26:27,522 --> 00:26:31,510
CEO a rate. And all this kind of stuff is already baked

410
00:26:31,590 --> 00:26:34,742
into the tool for each metric individually,

411
00:26:34,886 --> 00:26:38,854
including the monitoring of each component individually.

412
00:26:38,902 --> 00:26:42,266
So for the data, when you have a disk,

413
00:26:42,378 --> 00:26:45,918
it's an object in the data. It has their

414
00:26:46,084 --> 00:26:50,730
metrics attached to it, alerts attached to it. So we monitor

415
00:26:50,810 --> 00:26:54,222
infrastructure bottom up, we don't go helicopter

416
00:26:54,286 --> 00:26:58,274
view, we go down deep, we deep dive to

417
00:26:58,312 --> 00:27:01,554
the highest level we can, we monitoring and set

418
00:27:01,592 --> 00:27:04,580
alerts at that level and we start building,

419
00:27:08,870 --> 00:27:12,198
see, because even Nadeda has a lot

420
00:27:12,204 --> 00:27:15,298
of innovations, even in deployment,

421
00:27:15,394 --> 00:27:19,174
for example. So Netdata is an open

422
00:27:19,212 --> 00:27:21,900
source software, as I said, you can use it for free.

423
00:27:22,670 --> 00:27:26,694
So the software you are going to get is a monitoring

424
00:27:26,742 --> 00:27:30,214
in a box. So the moment you install the data agent,

425
00:27:30,352 --> 00:27:34,266
it's not an agent, it's not the same as an exporter

426
00:27:34,458 --> 00:27:38,350
in Prometheus. And a data agent is like something

427
00:27:38,420 --> 00:27:42,106
like exporters time series

428
00:27:42,138 --> 00:27:45,662
databases. So you have Prometheus,

429
00:27:45,806 --> 00:27:49,054
you have the visualization engine, you have the alert

430
00:27:49,102 --> 00:27:52,414
manager, and you have also machine

431
00:27:52,462 --> 00:27:55,434
learning and the likes, including logs,

432
00:27:55,582 --> 00:27:58,600
everything combined into one application.

433
00:27:59,210 --> 00:28:03,334
Now this application is modular. So for

434
00:28:03,372 --> 00:28:06,406
each installation you do, you have the ability, of course,

435
00:28:06,428 --> 00:28:09,734
you can use it by itself. So you can install it on one

436
00:28:09,772 --> 00:28:13,418
server and use it on one server. So it has an API, it has a

437
00:28:13,424 --> 00:28:16,646
dashboard, you can see the dashboard there, you can explore the metrics,

438
00:28:16,678 --> 00:28:19,900
et cetera. But when you can build,

439
00:28:20,510 --> 00:28:24,094
sorry, I can show you this, you can also use

440
00:28:24,132 --> 00:28:27,582
them. So you have a number of servers, you install them,

441
00:28:27,636 --> 00:28:30,974
you install netdata on all of them, then you can use our

442
00:28:31,012 --> 00:28:34,642
SaaS offering to actually have a combined view of all of them.

443
00:28:34,696 --> 00:28:38,642
If you don't want that, you can use the same

444
00:28:38,696 --> 00:28:42,034
software, the Netdata agent, as a parent.

445
00:28:42,232 --> 00:28:45,686
So in this parent, now, this parent receives all

446
00:28:45,708 --> 00:28:48,610
the metrics in real time from all the servers.

447
00:28:48,770 --> 00:28:52,600
So all the other servers are streaming in real time to it.

448
00:28:53,370 --> 00:28:56,646
This server now can have all the

449
00:28:56,668 --> 00:29:00,294
functions of the others, so it can alert

450
00:29:00,342 --> 00:29:05,046
for them, anomaly for them, visualization for them, everything required.

451
00:29:05,238 --> 00:29:08,378
This allows you to offload the other servers. So these

452
00:29:08,464 --> 00:29:12,238
extra features, let's say take some cpu, take some

453
00:29:12,404 --> 00:29:15,930
disk space so you can offload if you want the other servers

454
00:29:16,010 --> 00:29:20,010
and use only the parent. Of course this is infinitely

455
00:29:20,090 --> 00:29:24,406
scalable. So you can have data centers,

456
00:29:24,538 --> 00:29:27,694
different data centers, or many places

457
00:29:27,742 --> 00:29:32,114
all over the world where you have infrastructure, you can have a parent there

458
00:29:32,232 --> 00:29:35,910
and then use the data cloud to aggregate the parents now,

459
00:29:36,060 --> 00:29:39,654
or you can have a grandparent. So you can have a

460
00:29:39,692 --> 00:29:42,818
grandparent, or a grand grand grand grand grandparent.

461
00:29:42,914 --> 00:29:47,174
So it's infinite, you can scale it as

462
00:29:47,212 --> 00:29:50,082
you see fit, as your infrastructure grows.

463
00:29:50,226 --> 00:29:54,298
The whole point with this now is that data is

464
00:29:54,384 --> 00:29:58,422
a lot faster compared for example to Prometheus

465
00:29:58,566 --> 00:30:01,594
and requires a lot less resources.

466
00:30:01,722 --> 00:30:05,770
So for Netata, we distress tested Netdata in Prometheus.

467
00:30:05,850 --> 00:30:09,854
We set it up 500 servers with

468
00:30:09,892 --> 00:30:13,714
40,000 containers. We had about 2.7

469
00:30:13,752 --> 00:30:17,154
million metrics collected every second. And we

470
00:30:17,192 --> 00:30:20,642
configured actually Prometheus to collect all

471
00:30:20,696 --> 00:30:24,686
these metrics in real time also per second. And we measured

472
00:30:24,718 --> 00:30:29,160
then the resources that were required on this data and

473
00:30:30,330 --> 00:30:32,920
Prometheus. And the result is this,

474
00:30:33,290 --> 00:30:36,854
35% less cpu utilization. So one

475
00:30:36,892 --> 00:30:41,302
third less cpu utilization, half the memory of Prometheus,

476
00:30:41,446 --> 00:30:43,910
10%, 12% less bandwidth,

477
00:30:44,070 --> 00:30:48,038
98% less disk I o. This is because we don't

478
00:30:48,054 --> 00:30:51,098
need a wall Sony that doesn't write all the time.

479
00:30:51,264 --> 00:30:54,734
We rely on streaming and replication for

480
00:30:54,772 --> 00:30:58,366
high availability. So each of the parents can be

481
00:30:58,388 --> 00:31:01,886
a cluster, it's very easy, you just set them up in a loop. You can

482
00:31:01,908 --> 00:31:04,958
have three parents in a cluster, four parents in a cluster,

483
00:31:05,134 --> 00:31:08,914
and all of them are in a loop. So the idea is

484
00:31:08,952 --> 00:31:12,946
that instead of committing data to disk and

485
00:31:13,048 --> 00:31:16,774
trying to have something that

486
00:31:16,812 --> 00:31:20,774
can sustain failures on each

487
00:31:20,812 --> 00:31:24,390
server, we rely on replication and streaming

488
00:31:25,050 --> 00:31:28,810
to make sure that we will not lose data in case of failures.

489
00:31:29,230 --> 00:31:33,354
So 98% less

490
00:31:33,392 --> 00:31:36,262
disk I o and also on retention.

491
00:31:36,406 --> 00:31:40,186
So you see that net data, we say there 75%

492
00:31:40,368 --> 00:31:43,806
less storage footprint, but actually it is actually a

493
00:31:43,828 --> 00:31:47,502
lot more. The problem here is that the key

494
00:31:47,556 --> 00:31:51,246
characteristic of net data is that it can downsample data

495
00:31:51,428 --> 00:31:54,674
as time passes. So it has tiers, it can have up to five

496
00:31:54,712 --> 00:31:58,194
tiers. We ship it with three, but you can configure up to

497
00:31:58,232 --> 00:32:01,614
five, where you downsample data from tier

498
00:32:01,662 --> 00:32:03,540
to tier. Now,

499
00:32:05,690 --> 00:32:09,734
NetData also is one of the

500
00:32:09,852 --> 00:32:13,894
most power energy efficient platforms out

501
00:32:13,932 --> 00:32:17,366
there. So last month, the University of

502
00:32:17,388 --> 00:32:20,906
Abstention did a research we didn't know, we saw it when it

503
00:32:20,928 --> 00:32:25,306
was published that they

504
00:32:25,328 --> 00:32:29,050
said Netdata excels in energy

505
00:32:29,120 --> 00:32:32,238
efficiency, is the most energy efficient tool,

506
00:32:32,404 --> 00:32:36,122
and excels in cpu usage, ram usage and execution

507
00:32:36,186 --> 00:32:40,506
time when it monitoring docker containers. The whole study was about Docker

508
00:32:40,538 --> 00:32:44,660
containers. Let's move on to

509
00:32:45,030 --> 00:32:48,834
AI, to artificial intelligence, and what

510
00:32:48,872 --> 00:32:52,706
is there? What happens there? So in

511
00:32:52,728 --> 00:32:56,260
2019, Todd Underwood from Google

512
00:32:56,950 --> 00:33:00,690
made this speech. This pitch says that actually all

513
00:33:00,760 --> 00:33:04,920
the male ideas that Google engineers had were bad.

514
00:33:06,490 --> 00:33:09,826
They couldn't have the expected outcome. So the

515
00:33:09,868 --> 00:33:13,514
engineers set some goals and they tried. They put them down

516
00:33:13,552 --> 00:33:17,290
and they tried to do it, but the goals were not there.

517
00:33:17,440 --> 00:33:20,666
It was impossible to achieve them. So all the

518
00:33:20,688 --> 00:33:24,094
ML's ideas are bad, and we should also feel bad,

519
00:33:24,132 --> 00:33:27,566
as Todd says here. Now in

520
00:33:27,588 --> 00:33:30,350
the data, we have mls.

521
00:33:30,690 --> 00:33:33,380
Now what we do,

522
00:33:33,910 --> 00:33:37,506
the first goal of machine learning in a

523
00:33:37,528 --> 00:33:41,374
data is to understand, to learn the patterns

524
00:33:41,422 --> 00:33:44,900
of the metrics. So we didn't want to.

525
00:33:45,370 --> 00:33:48,920
That's the first goal. Can we understand

526
00:33:50,490 --> 00:33:54,230
the pattern of the metrics so that the next time

527
00:33:54,300 --> 00:33:58,140
we collect a sample, we can know

528
00:33:58,670 --> 00:34:02,486
reliably if the collected sample

529
00:34:02,598 --> 00:34:06,154
is an outlier or not. And we wanted this

530
00:34:06,192 --> 00:34:09,386
unsupervised, so we didn't want to

531
00:34:09,408 --> 00:34:12,894
do, to provide any feedback to

532
00:34:12,932 --> 00:34:16,206
the training. We train at the edge, or as

533
00:34:16,228 --> 00:34:19,214
close to the edge, so you can train as the parents if you want.

534
00:34:19,412 --> 00:34:23,058
But the whole point was to

535
00:34:23,144 --> 00:34:27,780
understand if we can have a way to

536
00:34:28,230 --> 00:34:31,838
detect if a collected sample, just collected sample,

537
00:34:31,934 --> 00:34:35,266
is anomalous or not. And I think we have achieved that. So in

538
00:34:35,288 --> 00:34:38,726
a data train, say 18 models, it learns the behavior of

539
00:34:38,748 --> 00:34:41,720
each medic individual for the last 57 hours.

540
00:34:42,490 --> 00:34:46,306
This is two points and a half. Let's say it detects

541
00:34:46,338 --> 00:34:50,810
anomalies in real time. And all

542
00:34:50,960 --> 00:34:53,946
18 machine learning models need to agree.

543
00:34:54,128 --> 00:34:57,366
This is how we remove the noise from ML. Because it's noise,

544
00:34:57,398 --> 00:35:00,734
it has false positives. So all 18 models have to

545
00:35:00,772 --> 00:35:04,574
agree that a sample is an outlier in order to say

546
00:35:04,612 --> 00:35:08,542
that it is an outlier. And we

547
00:35:08,596 --> 00:35:12,846
store the anomaly rate in

548
00:35:12,868 --> 00:35:16,334
the collected data together with the collected data in the time series.

549
00:35:16,382 --> 00:35:20,370
So it's like anomaly rate is an additional

550
00:35:21,270 --> 00:35:24,222
time series for every other time series.

551
00:35:24,286 --> 00:35:28,454
It's like having all the time series twice, one for

552
00:35:28,572 --> 00:35:32,374
anomalous, not anomalous. And we also

553
00:35:32,412 --> 00:35:36,310
calculate a host level anomalous score that we will see how

554
00:35:36,380 --> 00:35:40,010
it is used. Now in a data.

555
00:35:40,080 --> 00:35:43,642
One of the innovations we did in a data is that we

556
00:35:43,696 --> 00:35:47,894
added a scoring engine. A scoring engine tries

557
00:35:47,942 --> 00:35:51,406
to score the metrics, tries to

558
00:35:51,428 --> 00:35:54,960
understand given some parameters, it tries to understand

559
00:35:56,130 --> 00:35:59,658
which metrics, out of the thousands or millions

560
00:35:59,674 --> 00:36:03,582
of metrics available, are the more relevant to the query

561
00:36:03,646 --> 00:36:07,554
we do. So it can do scoring based on

562
00:36:07,592 --> 00:36:11,060
two windows to find the rate of change.

563
00:36:13,430 --> 00:36:17,640
It can score based on the anomaly rate. So which

564
00:36:18,090 --> 00:36:21,640
metrics were the most anomalies from that time to that time?

565
00:36:22,810 --> 00:36:27,154
We have also metric correlations that tries

566
00:36:27,202 --> 00:36:30,234
to correlate metrics together. So by

567
00:36:30,272 --> 00:36:33,706
similarity or by volume. So it tries to

568
00:36:33,728 --> 00:36:37,420
understand how the metrics correlate together.

569
00:36:38,030 --> 00:36:42,750
Now let's see how this appear in

570
00:36:42,820 --> 00:36:45,630
a data dashboard. And a data dashboard is like this.

571
00:36:45,780 --> 00:36:48,894
It's a single dashboard, one chart is below the other,

572
00:36:49,012 --> 00:36:52,654
infinite, scrolling hundreds of charts. Of course, there is

573
00:36:52,692 --> 00:36:56,618
a menu here that groups everything into sections so

574
00:36:56,724 --> 00:37:00,478
that you can quickly jump from section to section and see the charts.

575
00:37:00,654 --> 00:37:04,162
Now, this dashboard is fully automated. You don't have to do anything about

576
00:37:04,216 --> 00:37:07,302
it. Of course, if you want to cherry pick charts and build custom

577
00:37:07,356 --> 00:37:10,806
dashboards and change the visualization, all this is there.

578
00:37:10,908 --> 00:37:14,406
But the whole point is that we wanted all of it to

579
00:37:14,428 --> 00:37:18,494
be, every metric to be visualized in a fully automated

580
00:37:18,562 --> 00:37:22,438
way. Each chart

581
00:37:22,534 --> 00:37:25,786
we will see has a number of controls. So the charts that you

582
00:37:25,808 --> 00:37:29,562
see in the data are a little bit different compared to the others.

583
00:37:29,696 --> 00:37:33,006
Let's go to that thing. The first thing is that when

584
00:37:33,028 --> 00:37:36,494
you are in this dashboard that you have, in this case, I think it

585
00:37:36,532 --> 00:37:39,950
says five, 90, 500, almost 600

586
00:37:40,020 --> 00:37:43,246
charts in this dashboard. It says it

587
00:37:43,268 --> 00:37:46,850
here when you are there and

588
00:37:47,000 --> 00:37:51,070
you can press this button, this AR button that's here, this is in Zoom

589
00:37:51,230 --> 00:37:55,206
and netdata. What will do is that it

590
00:37:55,228 --> 00:37:59,106
will fill the sections with their anomaly

591
00:37:59,138 --> 00:38:02,774
rates. So for the daytime picker from

592
00:38:02,812 --> 00:38:06,530
the duration you want it, it will score

593
00:38:06,690 --> 00:38:10,714
all the metrics and figure out

594
00:38:10,912 --> 00:38:15,114
what's the anomaly rate for that duration for

595
00:38:15,152 --> 00:38:18,250
each chart within them, and then for each section,

596
00:38:18,910 --> 00:38:22,394
this allows you to quickly spot. So if you have a problem and you want

597
00:38:22,432 --> 00:38:25,998
to find you don't know what it is, you have a spike or

598
00:38:26,004 --> 00:38:28,894
a dive on a web server, something is wrong. You don't know even what is

599
00:38:28,932 --> 00:38:32,942
wrong. You can just go there and hit that AR button and the data

600
00:38:32,996 --> 00:38:36,702
will tell you where the anomalies are. So you will be able to immediately

601
00:38:36,766 --> 00:38:39,822
see that, oh, my database server, my storage layer,

602
00:38:39,886 --> 00:38:43,874
or an application is doing something,

603
00:38:43,992 --> 00:38:47,526
has a crash or something. Now, this is

604
00:38:47,548 --> 00:38:50,774
in a data chart, and a data chart looks like

605
00:38:50,892 --> 00:38:53,398
all the charts out there,

606
00:38:53,484 --> 00:38:56,582
but not quite. So.

607
00:38:56,636 --> 00:39:00,674
The first thing that you will see is that there is this anomaly

608
00:39:00,722 --> 00:39:05,020
reborn. The anomaly ribbon is this. This purple color

609
00:39:05,630 --> 00:39:09,290
indicates on the top the anomaly rate

610
00:39:09,440 --> 00:39:13,520
of all the metrics that are included here. In this case,

611
00:39:14,930 --> 00:39:17,802
the metrics are coming from seven nodes,

612
00:39:17,866 --> 00:39:22,078
115 applications, and there are 33

613
00:39:22,164 --> 00:39:26,178
labels there. So the entire,

614
00:39:26,264 --> 00:39:30,158
all of them, all of them together. The anomaly

615
00:39:30,174 --> 00:39:33,714
rate, the combined anomaly rate is visualized here.

616
00:39:33,912 --> 00:39:37,646
Of course, you can have individual anomaly rate like

617
00:39:37,688 --> 00:39:40,934
this. So you click the nodes. This model comes

618
00:39:40,972 --> 00:39:44,326
in. It has the seven nodes one by one. It says,

619
00:39:44,428 --> 00:39:48,206
how many instances, how many components. If this is about disks,

620
00:39:48,338 --> 00:39:51,126
this is disks. If it is applications, these applications,

621
00:39:51,238 --> 00:39:54,394
these processes in this case. So how many

622
00:39:54,432 --> 00:39:57,626
applications are there? How many metrics are available?

623
00:39:57,808 --> 00:40:01,662
What's the volume, the relative volume. So in the

624
00:40:01,716 --> 00:40:05,534
chart that you see, some of them contribute more

625
00:40:05,652 --> 00:40:09,482
than the others. This is sorting by the volume,

626
00:40:09,626 --> 00:40:13,406
a sorting by anomaly rate. If there are related alerts to

627
00:40:13,428 --> 00:40:16,914
context switches, in this case about applications, you would see them here.

628
00:40:17,112 --> 00:40:21,470
And you can see the minimum, average, and maximum value per node

629
00:40:21,630 --> 00:40:25,460
for this kind of data. The same happens for

630
00:40:25,910 --> 00:40:29,526
applications, for dimensions or for labels. So it's a similar

631
00:40:29,628 --> 00:40:32,966
model that shows all applications in

632
00:40:32,988 --> 00:40:36,306
a list where you can see the volume, the anomaly rate, the minimum

633
00:40:36,338 --> 00:40:39,020
average and maximum, et cetera. And of course,

634
00:40:39,790 --> 00:40:42,460
you can use the group by.

635
00:40:43,630 --> 00:40:46,618
Sorry, I didn't tell you that. You can filter from here. So if you want

636
00:40:46,624 --> 00:40:51,126
to include or exclude something, you can just include

637
00:40:51,158 --> 00:40:54,654
it or exclude it here, and it will automatically change

638
00:40:54,692 --> 00:40:57,710
the chart. So similarly,

639
00:40:58,450 --> 00:41:02,462
you can use the group by feature to change how data

640
00:41:02,516 --> 00:41:06,180
are grouped. So you can group by node, you can group by application,

641
00:41:06,710 --> 00:41:10,146
you can group by dimension. In this case, it is read or

642
00:41:10,168 --> 00:41:13,822
write or whatever it is. You can also group by any label,

643
00:41:13,966 --> 00:41:17,474
whatever label is there, and actually by combinations, two labels,

644
00:41:17,522 --> 00:41:21,094
three labels, nodes and labels. So you can do all the combinations and

645
00:41:21,132 --> 00:41:24,626
group the data. See the different aspects

646
00:41:24,658 --> 00:41:27,946
of the data from this menu. Now,

647
00:41:27,968 --> 00:41:32,586
this menu is standard on every chart. Then we

648
00:41:32,608 --> 00:41:36,682
have the anomaly advisor. Anomaly advisor is a tool

649
00:41:36,736 --> 00:41:39,914
that we developed in order to find the needle in

650
00:41:39,952 --> 00:41:43,406
the haystack. So you have a problem.

651
00:41:43,508 --> 00:41:46,654
There is an anomaly. We saw this AR button that you press

652
00:41:46,692 --> 00:41:51,134
it and you can actually see the

653
00:41:51,172 --> 00:41:54,354
anomaly rate of each section. But how can I

654
00:41:54,392 --> 00:41:57,794
find the individual metrics or

655
00:41:57,832 --> 00:42:02,578
the most anomalous metrics that

656
00:42:02,664 --> 00:42:07,014
exist for a given time frame, current or past. So we

657
00:42:07,052 --> 00:42:10,822
use the host anomaly rate. The host anomaly rate looks like

658
00:42:10,876 --> 00:42:14,822
this. So this is a chart, you see here that

659
00:42:14,876 --> 00:42:18,780
it is a percentage, and it shows the number

660
00:42:19,310 --> 00:42:23,414
of metrics of the host, of each host. These are hosts

661
00:42:23,462 --> 00:42:26,170
here of the nodes,

662
00:42:27,150 --> 00:42:31,354
the number of metrics in the node that are concurrently

663
00:42:31,402 --> 00:42:35,470
anomalous. You can see that when you have anomalies,

664
00:42:35,890 --> 00:42:39,614
they are widespread. So you see a lot of

665
00:42:39,652 --> 00:42:43,094
metrics in that node become anomalous.

666
00:42:43,242 --> 00:42:46,862
So if there is a stress on the database server

667
00:42:47,006 --> 00:42:50,882
disk will have increased, I O CPU will be

668
00:42:51,016 --> 00:42:57,454
a lot more, probably network

669
00:42:57,502 --> 00:43:00,162
interface will have a lot more bandwidth.

670
00:43:00,306 --> 00:43:03,382
So all this combined together with

671
00:43:03,436 --> 00:43:09,414
all the individual metrics that we check, like the

672
00:43:09,452 --> 00:43:13,510
containers and the page

673
00:43:13,580 --> 00:43:17,170
faults, how many memory process shall locate,

674
00:43:17,250 --> 00:43:21,614
et cetera, or the text switches or whatever

675
00:43:21,732 --> 00:43:25,710
happens, even interrupts how interrupts are affected

676
00:43:26,370 --> 00:43:29,902
in the system. So all this information comes

677
00:43:29,956 --> 00:43:33,534
together and is aggregated here to see a huge spike when

678
00:43:33,572 --> 00:43:37,140
something anomalous happen. Now when something anomalous happens

679
00:43:37,830 --> 00:43:40,722
like this, what you can do is highlight this area.

680
00:43:40,776 --> 00:43:44,686
So there is a toolbox here that you can highlight this area. And immediately

681
00:43:44,718 --> 00:43:48,274
the data will give you a list of all the metrics sorted

682
00:43:48,322 --> 00:43:52,086
by relevance for that highlighted window. So for

683
00:43:52,108 --> 00:43:55,446
that highlighted window, it goes through all the metrics, no matter how many

684
00:43:55,468 --> 00:43:59,130
they are. It scores them according to their

685
00:43:59,200 --> 00:44:03,002
anomaly rate, sorts them, and gives

686
00:44:03,056 --> 00:44:06,826
you the list in a sorted way. So you can see for example

687
00:44:07,008 --> 00:44:11,230
that the whole point of this is that in the top 1020

688
00:44:11,380 --> 00:44:15,200
items that you have there, you should have your aha moment.

689
00:44:15,730 --> 00:44:19,898
So you should have ho someone ssh

690
00:44:20,074 --> 00:44:23,890
to this server or ho we have

691
00:44:23,960 --> 00:44:28,174
tcp resets, something is broken somewhere

692
00:44:28,222 --> 00:44:31,602
else and this doesn't play.

693
00:44:31,736 --> 00:44:35,414
So the whole point is to have your

694
00:44:35,452 --> 00:44:39,510
aha moment within the top few items.

695
00:44:40,090 --> 00:44:43,414
Now the way I see it, if I go

696
00:44:43,452 --> 00:44:47,094
through, is that, the way I understand it

697
00:44:47,132 --> 00:44:51,306
is that we have really a lot in common.

698
00:44:51,488 --> 00:44:55,130
Our infrastructures under the hood are quite

699
00:44:55,200 --> 00:44:59,002
similar. We all deserve to have real time

700
00:44:59,056 --> 00:45:02,238
high fidelity monitoring solutions like net data

701
00:45:02,324 --> 00:45:06,490
keep up to this promise. So we spread

702
00:45:06,570 --> 00:45:10,270
net data like this in a distributed fashion,

703
00:45:10,610 --> 00:45:14,926
mainly to avoid the

704
00:45:15,028 --> 00:45:18,206
bottlenecks that all other monitoring solutions face.

705
00:45:18,388 --> 00:45:22,414
So net data should

706
00:45:22,452 --> 00:45:26,070
be scalable better than anything else. The data cloud,

707
00:45:26,140 --> 00:45:31,766
for example, is our SaaS offering today

708
00:45:31,868 --> 00:45:35,238
works at about, I don't know, less than 1%

709
00:45:35,324 --> 00:45:39,414
of its capacity, and it has 100,000 connected

710
00:45:39,462 --> 00:45:42,826
nodes. And it's just a Kubernetes cluster, not much,

711
00:45:43,008 --> 00:45:46,410
a small one actually, a few nodes. So the idea

712
00:45:46,480 --> 00:45:51,018
is that we want monitoring to be high resolution,

713
00:45:51,114 --> 00:45:54,430
to be high fidelity, to be real

714
00:45:54,500 --> 00:45:58,074
time. We open sourced everything. So Netdata

715
00:45:58,122 --> 00:46:02,574
is a gift to the world, and we

716
00:46:02,612 --> 00:46:05,730
open sourced, even advanced machine learning

717
00:46:05,800 --> 00:46:09,598
techniques, everything we do, all the innovations

718
00:46:09,694 --> 00:46:13,694
in observability are baked into the open source

719
00:46:13,742 --> 00:46:17,286
agent. And even when you view one

720
00:46:17,388 --> 00:46:21,618
agent or a parent with 2 million metrics,

721
00:46:21,714 --> 00:46:25,346
the dashboard is the same. We don't change dashboards.

722
00:46:25,378 --> 00:46:29,370
It's one thing, the same as the cloud. Netdata cloud has

723
00:46:29,440 --> 00:46:32,060
exactly the same dashboard as the agent.

724
00:46:35,230 --> 00:46:38,602
And monitoring, to our

725
00:46:38,656 --> 00:46:41,914
understanding, should be simple. It should be easy to use,

726
00:46:42,032 --> 00:46:46,000
easy to maintain. The data is maintenance free, doesn't require anything.

727
00:46:46,530 --> 00:46:50,222
Of course there are a few things to learn. How the tool behaves like this,

728
00:46:50,276 --> 00:46:53,826
and how I do streaming, how to build parent. You need to

729
00:46:53,848 --> 00:46:57,460
learn a few things, but even

730
00:46:58,070 --> 00:47:01,634
there is nothing to maintain in indexes. Most of the stuff

731
00:47:01,672 --> 00:47:04,580
are zero configuration and work out of the box.

732
00:47:06,250 --> 00:47:10,342
And at the same time we believe that the monitoring tool

733
00:47:10,396 --> 00:47:13,526
should be a powerful tool at

734
00:47:13,548 --> 00:47:17,014
the experts, at the hands of experts, but a

735
00:47:17,052 --> 00:47:21,062
strong educational tool for newcomers.

736
00:47:21,206 --> 00:47:25,114
So people should be using these

737
00:47:25,152 --> 00:47:29,222
kind of tools like Netdata, to learn, to troubleshoot,

738
00:47:29,286 --> 00:47:33,146
understand the infrastructure, feel the pulse

739
00:47:33,258 --> 00:47:37,006
of the infrastructure, and at the

740
00:47:37,028 --> 00:47:40,334
same time we are trying to optimize it all over

741
00:47:40,372 --> 00:47:44,558
the place. So we want my data to be a thin

742
00:47:44,734 --> 00:47:48,014
layer compared to the infrastructure

743
00:47:48,062 --> 00:47:50,946
it monitors. It should never become huge.

744
00:47:51,128 --> 00:47:54,846
This is why we wanted to spread over the infrastructure,

745
00:47:55,038 --> 00:47:58,546
to utilize the resources that are already available. And spare

746
00:47:58,658 --> 00:48:02,070
data on a single node requires just

747
00:48:02,140 --> 00:48:05,794
5% of a single node utilization of a single core,

748
00:48:05,842 --> 00:48:09,222
sorry, of a single core cpu utilization and about

749
00:48:09,276 --> 00:48:12,646
100 megabytes of ram. So we want this to

750
00:48:12,668 --> 00:48:16,198
be extremely thin compared to

751
00:48:16,364 --> 00:48:19,998
the whole thing, so that it can be affordable for

752
00:48:20,044 --> 00:48:23,040
everyone. Thank you very much for watching,

753
00:48:24,130 --> 00:48:26,860
try new data and see you online.

