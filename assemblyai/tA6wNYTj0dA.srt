1
00:00:23,450 --> 00:00:26,710
So before I jump directly into the different

2
00:00:26,780 --> 00:00:29,974
terms, Greenfield and Brown field, I want to give you a very short intro into

3
00:00:30,012 --> 00:00:33,686
data labeling. Most likely every one of you already heard of it, but just a

4
00:00:33,708 --> 00:00:36,998
very short basic concepts. So of course, if you

5
00:00:37,004 --> 00:00:40,338
want to build some classifier or information extractor,

6
00:00:40,514 --> 00:00:43,686
you don't only need raw data, but you need labeled data,

7
00:00:43,868 --> 00:00:47,622
right? So for instance, if we have some email, we want to mark

8
00:00:47,756 --> 00:00:51,280
or categorize different information that we want to

9
00:00:51,890 --> 00:00:55,614
basically predict using an AI model.

10
00:00:55,812 --> 00:00:59,150
And this is typically done via manually labeling the data,

11
00:00:59,220 --> 00:01:02,382
right. So you have some person that labeling the data and you can then use

12
00:01:02,436 --> 00:01:04,660
this labeling data to build your model.

13
00:01:05,670 --> 00:01:09,314
Well, I want to do some analogy and talk about this

14
00:01:09,352 --> 00:01:13,278
kind of data labeling. And we talk a lot about Greenfield and Brownfield

15
00:01:13,374 --> 00:01:16,826
in it projects. Right. So in Greenfield is typically,

16
00:01:16,878 --> 00:01:20,870
is when you can start from scratch, you can build in a completely new environment.

17
00:01:21,290 --> 00:01:24,722
And on the contrary, in Brownfield

18
00:01:24,866 --> 00:01:28,454
you basically build on an existing system. You have to work with legacy

19
00:01:28,502 --> 00:01:32,026
code and basically work with integrations and

20
00:01:32,048 --> 00:01:35,562
stuff like this. So it's not about designing something new, but improving something

21
00:01:35,616 --> 00:01:39,722
continuously. And we can transfer those

22
00:01:39,776 --> 00:01:43,134
concepts also to data labeling because we have something quite

23
00:01:43,172 --> 00:01:46,394
similar there. So in Greenfield labeling,

24
00:01:46,442 --> 00:01:49,902
we basically want to start from scratch. We only have the raw data,

25
00:01:50,036 --> 00:01:53,746
but we want to build some proof of concepts really fast and

26
00:01:53,848 --> 00:01:57,794
go from basically zero to 90 or something like this.

27
00:01:57,992 --> 00:02:01,442
And on the contrary, in Brownfield labeling we already

28
00:02:01,496 --> 00:02:05,266
have existing training data, but we are most likely sure that

29
00:02:05,288 --> 00:02:09,110
there are some potential quality improvements so that we can

30
00:02:09,180 --> 00:02:13,446
continuously work on that and by doing so improve the performance of our model.

31
00:02:13,548 --> 00:02:16,706
That's basically the idea about Greenfield

32
00:02:16,738 --> 00:02:21,030
and Brownfield data labeling and from some other perspectives,

33
00:02:21,110 --> 00:02:25,242
basically is that you mostly focus on

34
00:02:25,376 --> 00:02:29,066
training quantity in Greenfield, and that you really create a lot of

35
00:02:29,088 --> 00:02:33,066
training data. You know that the quality won't be perfect, but you can then improve

36
00:02:33,098 --> 00:02:36,830
on it continuously during brownfield labeling.

37
00:02:37,730 --> 00:02:41,054
So I'm going to talk first about Greenfield, give you

38
00:02:41,092 --> 00:02:44,698
some ideas about that, talk about really cool technologies. Then we're

39
00:02:44,714 --> 00:02:48,366
going to Brownfield. Then we are making our conclusion,

40
00:02:48,558 --> 00:02:52,306
right. And so when we talk about Windfield labeling, we first talk

41
00:02:52,328 --> 00:02:55,570
about how you label from scratch, what kind of options you have.

42
00:02:55,640 --> 00:02:59,094
And we also want to understand what are the real problems we

43
00:02:59,132 --> 00:03:02,934
have there. So the first two options you have if you want to labeling data

44
00:03:02,972 --> 00:03:06,066
is that you either go via crowd labeling,

45
00:03:06,098 --> 00:03:09,946
which is globally scalable, so you can have lots of people working on

46
00:03:09,968 --> 00:03:13,898
that. But typically you have issues when it comes to

47
00:03:14,064 --> 00:03:17,462
very difficult tasks where you need a lot of domain knowledge,

48
00:03:17,526 --> 00:03:19,740
like for instance in insurance companies.

49
00:03:20,990 --> 00:03:24,810
And the contrary to crowd labeling

50
00:03:24,890 --> 00:03:28,538
basically is in house labeling, so that you let your experts in house label

51
00:03:28,554 --> 00:03:32,142
the data, but of course, then you don't have the global scale, right?

52
00:03:32,196 --> 00:03:36,100
So that becomes a lot more expensive and also

53
00:03:37,190 --> 00:03:41,554
oftentimes a bottleneck in your projects. So it

54
00:03:41,592 --> 00:03:45,010
really is difficult to create a large training set

55
00:03:45,080 --> 00:03:48,754
that you can start with, that you can use to prove

56
00:03:48,802 --> 00:03:52,422
your concept, basically. And that's why a lot of people

57
00:03:52,476 --> 00:03:56,374
think about how you can automate your labeling such that you can create large

58
00:03:56,412 --> 00:03:59,706
training sets easily. And one of

59
00:03:59,728 --> 00:04:03,194
those ideas is weak supervision, which is

60
00:04:03,232 --> 00:04:06,474
basically a perspective from a machine learning point

61
00:04:06,512 --> 00:04:09,260
of view on integrating information,

62
00:04:09,970 --> 00:04:13,280
right? And the basic concept is quite easy,

63
00:04:13,730 --> 00:04:17,738
but you can build really cool applications using weak supervision.

64
00:04:17,914 --> 00:04:21,946
And in a sense that for each heuristic

65
00:04:21,978 --> 00:04:25,214
that you can come up with. And the heuristic can be something, we go into

66
00:04:25,252 --> 00:04:29,058
this in a bit more detail, but can be something like a labeling function that

67
00:04:29,144 --> 00:04:32,498
is not perfect, like predicting the right

68
00:04:32,584 --> 00:04:36,430
label 100% of the time, because then you would also have the classifier,

69
00:04:36,590 --> 00:04:40,614
but it's something that gives you the right label in 80%

70
00:04:40,652 --> 00:04:44,066
of the cases, or 70% of the cases, and not for all records,

71
00:04:44,098 --> 00:04:47,286
but just for some small subset. And you

72
00:04:47,308 --> 00:04:50,326
want to come up with several of those heuristics and compute them for each

73
00:04:50,348 --> 00:04:54,310
of every of your records, so that you then have like a matrix

74
00:04:54,390 --> 00:04:57,238
with all of your heuristics that create noisy labels.

75
00:04:57,414 --> 00:05:00,698
And the task of weak supervision is to basically combine them,

76
00:05:00,784 --> 00:05:04,062
right? And again, weak supervision is not one

77
00:05:04,116 --> 00:05:07,470
algorithm, but it's a family of algorithms that you can use.

78
00:05:07,540 --> 00:05:10,654
Two, look at your noise label metrics and come up with the

79
00:05:10,692 --> 00:05:14,062
potentially best synthesized labels for your

80
00:05:14,116 --> 00:05:17,794
data, right? So you also, most of the times, don't have

81
00:05:17,832 --> 00:05:20,930
like a discrete label, but you have a probabilistic label.

82
00:05:21,590 --> 00:05:24,718
And one algorithm could be, for instance, majority vote,

83
00:05:24,814 --> 00:05:28,514
that you just look at the counts of the heuristics

84
00:05:28,562 --> 00:05:31,990
that make a vote for each record. But you can also go into more

85
00:05:32,060 --> 00:05:35,138
sophisticated algorithms that analyze precision,

86
00:05:35,234 --> 00:05:39,078
that analyze coverage, that analyze conflicts,

87
00:05:39,174 --> 00:05:42,298
stuff like that, so that you

88
00:05:42,304 --> 00:05:45,734
can really create sophisticated weekly supervised

89
00:05:45,782 --> 00:05:49,686
labels. And if we now talk about heuristics, I just want to showcase

90
00:05:49,718 --> 00:05:52,862
you what kind of types heuristics can be.

91
00:05:52,996 --> 00:05:56,506
So one of the most simplest one is labeling

92
00:05:56,538 --> 00:06:00,158
functions, which can be just like a very simple python function,

93
00:06:00,244 --> 00:06:03,982
just few lines of code that

94
00:06:04,036 --> 00:06:07,234
basically just takes this input a record and returns then

95
00:06:07,272 --> 00:06:10,814
the label that you want to products other heuristics

96
00:06:10,862 --> 00:06:14,738
can be, for instance distance supervision, which is basically looking up values that

97
00:06:14,824 --> 00:06:18,070
are very much associated to some kind of label

98
00:06:18,730 --> 00:06:22,390
or active learning modules that continuously learn

99
00:06:22,460 --> 00:06:26,006
on the data that you already labeled manually. It can be

100
00:06:26,028 --> 00:06:29,766
zero shot classifiers, for example from hugging phase, which are very

101
00:06:29,788 --> 00:06:33,686
similar to labeling functions, but you don't really write the code of the labeling

102
00:06:33,718 --> 00:06:37,100
function, but you instead just provide the label names, which is really cool.

103
00:06:38,270 --> 00:06:41,994
Can be something like unexperienced labelers. So still manual labeling,

104
00:06:42,122 --> 00:06:45,566
like crowd labeling or interns, and it can

105
00:06:45,588 --> 00:06:48,906
of course be anything that you can integrate. So third party

106
00:06:48,938 --> 00:06:52,746
systems, legacy systems, so in general you really have a generic

107
00:06:52,778 --> 00:06:56,734
interface and the idea is that you collect noisy labels

108
00:06:56,862 --> 00:07:00,434
and the relevance of each heuristic is then determined and

109
00:07:00,472 --> 00:07:04,418
you can combine them into wiki supervised labels. If you

110
00:07:04,424 --> 00:07:07,638
can now automate the labeling, we have to think about why do we even want

111
00:07:07,644 --> 00:07:10,982
to train a classifier? And for that we can have a short

112
00:07:11,036 --> 00:07:14,406
comparison. And the main idea is that you label to

113
00:07:14,428 --> 00:07:18,202
build, whereas for building a classifier do this for real

114
00:07:18,256 --> 00:07:21,718
inference, real time. So for labeling,

115
00:07:21,734 --> 00:07:25,754
the runtime doesn't essentially matter. You can also just run a program

116
00:07:25,952 --> 00:07:30,230
over the night, whereas for inference you oftentimes only have milliseconds.

117
00:07:30,390 --> 00:07:34,078
Also in labeling you can have access two data that potentially is not available

118
00:07:34,164 --> 00:07:37,226
at runtime. And hasso, you don't

119
00:07:37,258 --> 00:07:41,054
aim for like 100% coverage, but instead you

120
00:07:41,092 --> 00:07:44,834
want to have a really high confidence. So there's like a trade off

121
00:07:44,872 --> 00:07:48,958
and you decide for the confidence in data labeling.

122
00:07:49,134 --> 00:07:52,926
Hasso, it's much more that in labeling you produce an artifact.

123
00:07:53,038 --> 00:07:56,374
So like something that you can build software with, whereas on the other side,

124
00:07:56,412 --> 00:07:59,570
again, that software is what you want to use for inference.

125
00:07:59,650 --> 00:08:04,034
So there's like this comparison. And also what's

126
00:08:04,082 --> 00:08:07,654
oftentimes seen and also great studies about it,

127
00:08:07,692 --> 00:08:11,210
is that if you have a model and you then use the labeling training

128
00:08:11,280 --> 00:08:14,906
data from something like supervision, the calcifier that you

129
00:08:14,928 --> 00:08:18,666
train oftentimes generalizes very well, so you still

130
00:08:18,848 --> 00:08:22,240
gain a lot of value from just training your model on the data.

131
00:08:23,010 --> 00:08:26,574
But as we talk about automating labeling, we also have to talk

132
00:08:26,612 --> 00:08:30,234
about that. Even in greenfield labeling, manual labeling

133
00:08:30,282 --> 00:08:34,302
still matters a lot because you have different problems also here

134
00:08:34,356 --> 00:08:38,114
that you want to tackle, because you not only want to automate, but you also

135
00:08:38,152 --> 00:08:41,426
want to explore your data. So you want to see what kind of

136
00:08:41,448 --> 00:08:44,370
patterns there are and get familiar with that.

137
00:08:44,520 --> 00:08:47,534
You also oftentimes for automatic labeling, needs some reference

138
00:08:47,582 --> 00:08:50,934
data so that you know how good your automation actually is.

139
00:08:51,132 --> 00:08:54,998
You want to measure how good is the human performance. Is there any subjectivity in

140
00:08:55,004 --> 00:08:58,182
my data so that two people that label the same data might

141
00:08:58,236 --> 00:09:02,074
disagree every now and then? And of course, manually labeling data

142
00:09:02,192 --> 00:09:05,770
helps a lot when you want to come up with techniques for automation,

143
00:09:06,110 --> 00:09:09,750
right? And also there are different strategies

144
00:09:09,830 --> 00:09:12,880
that you can follow if you want to manually label your data.

145
00:09:13,330 --> 00:09:16,766
So for exploring, for instance, you can make great usage of

146
00:09:16,788 --> 00:09:20,474
neural search, which is for instance, using so called embeddings,

147
00:09:20,602 --> 00:09:25,006
which are vector representations of, for instance, your texts or emails.

148
00:09:25,198 --> 00:09:29,038
And you can then use that information or like metadata

149
00:09:29,134 --> 00:09:32,786
to navigate through your data. I'm going to give you an example in

150
00:09:32,808 --> 00:09:36,354
a second. Of course, then for reference data, you can

151
00:09:36,392 --> 00:09:40,242
just use random sampling if you want to understand the performance

152
00:09:40,306 --> 00:09:43,954
of people on your data. You can filter for subsets

153
00:09:44,002 --> 00:09:47,814
that are already labeled by other people so that you can easily calculate something

154
00:09:47,852 --> 00:09:51,386
like an internetator agreement. Also going shown to you this in

155
00:09:51,408 --> 00:09:54,780
a second. And of course you also want to validate how good,

156
00:09:55,230 --> 00:09:59,354
like come up with new ideas and validate your heuristics and use therefore also

157
00:09:59,392 --> 00:10:02,560
filters for that. Also going to show this in a second.

158
00:10:04,050 --> 00:10:07,726
I'm first jumping into neural search and as I just mentioned, you can

159
00:10:07,748 --> 00:10:10,522
compute embeddings for data using for instance,

160
00:10:10,586 --> 00:10:13,998
pretrained transformer models that put your

161
00:10:14,084 --> 00:10:17,294
textual data into numeric vector representation.

162
00:10:17,422 --> 00:10:21,058
And if you have that data, you can make very good usage of it.

163
00:10:21,144 --> 00:10:24,082
So for instance, if you want to find outliers in your data,

164
00:10:24,216 --> 00:10:27,494
one very sophisticated approach is to use

165
00:10:27,532 --> 00:10:31,394
diversity sampling. And it basically is that you start by grabbing one random

166
00:10:31,442 --> 00:10:35,574
sample, like for instance, this one. And if

167
00:10:35,612 --> 00:10:39,850
you have it labeled, calculate the most distant

168
00:10:40,430 --> 00:10:44,182
record, that is to this reference point, which it will be, for instance,

169
00:10:44,326 --> 00:10:47,386
this green record. And if you

170
00:10:47,408 --> 00:10:51,126
do this continuously and always compute

171
00:10:51,158 --> 00:10:54,606
a vector that is the most distant to

172
00:10:54,628 --> 00:10:58,474
your current pool of labeled data sets, you will find the outliers

173
00:10:58,522 --> 00:11:02,362
of your records, which is super interesting because you can then really

174
00:11:02,436 --> 00:11:06,146
analyze what kind of obstacles will you face when you

175
00:11:06,248 --> 00:11:10,146
really have your model deployed and when it's running and

176
00:11:10,168 --> 00:11:13,700
you want to infer new predictions using that model.

177
00:11:14,150 --> 00:11:17,286
So that's always super interesting to understand what kind

178
00:11:17,308 --> 00:11:20,722
of outliners there are in texts or images

179
00:11:20,786 --> 00:11:24,198
or whatever kind of data you have. On a

180
00:11:24,204 --> 00:11:28,482
different side, neural search can also be used to find very representative

181
00:11:28,546 --> 00:11:32,346
data, but not to stay in one cluster. But for instance, if you have your

182
00:11:32,448 --> 00:11:36,362
embeddings clustered, find a certain number of data

183
00:11:36,416 --> 00:11:39,626
points per cluster that really are representative. And if you do

184
00:11:39,648 --> 00:11:43,190
so, you will very easily explore

185
00:11:43,270 --> 00:11:46,954
the data that really helps your model to learn, right? So for instance,

186
00:11:47,002 --> 00:11:49,454
if you have the three clusters, you can decide that you want to have,

187
00:11:49,492 --> 00:11:52,834
for instance, two or three data points per

188
00:11:52,872 --> 00:11:56,114
cluster really depends on how complicated your

189
00:11:56,152 --> 00:12:00,130
text, data, image data is, but it can really help you to

190
00:12:00,200 --> 00:12:03,090
progress and label efficiently.

191
00:12:04,550 --> 00:12:08,290
So now we talked about greenfield labeling

192
00:12:08,370 --> 00:12:12,562
and we saw that it is really a good usage

193
00:12:12,626 --> 00:12:16,578
to automate your labeling and that you can use great technologies.

194
00:12:16,754 --> 00:12:20,022
I'm going to show some more in a second also that are

195
00:12:20,076 --> 00:12:23,014
very tightly bound to Brownfield labeling.

196
00:12:23,142 --> 00:12:26,390
But you really see that you can automate

197
00:12:26,470 --> 00:12:29,802
labeling to some extent using

198
00:12:29,856 --> 00:12:33,866
technologies like Wix provision, so that you can achieve

199
00:12:33,898 --> 00:12:37,646
the goal of greenfield labeling much faster, which is

200
00:12:37,668 --> 00:12:41,530
that you want to prove concepts, you want to show that some kind of task

201
00:12:41,610 --> 00:12:44,602
might be automated using machine learning models.

202
00:12:44,666 --> 00:12:48,446
So that is really helpful for that case. And now we are jumping

203
00:12:48,478 --> 00:12:52,482
into the second case, which is we have now shown, we now

204
00:12:52,536 --> 00:12:56,130
see that our usage, like our use case, actually works,

205
00:12:56,280 --> 00:12:59,906
but we have not achieved the performance that we want. We need to continuously

206
00:12:59,938 --> 00:13:03,362
improve the performance, and only in the rarest occasions

207
00:13:03,426 --> 00:13:06,934
it is that we really have a super clean data set. In real world,

208
00:13:06,972 --> 00:13:10,246
we mostly have messy data, and that is why

209
00:13:10,268 --> 00:13:13,180
in brownfield we want to improve on the data quality,

210
00:13:13,790 --> 00:13:17,034
right? So for instance, we have those examples from very

211
00:13:17,072 --> 00:13:21,702
well known data sets, and you can see that they have been labeled incorrectly.

212
00:13:21,846 --> 00:13:25,198
So by correcting them, you would improve the data quality

213
00:13:25,284 --> 00:13:29,310
and thus also would improve the performance of your model. The problem

214
00:13:29,380 --> 00:13:32,846
here is you don't know which records are

215
00:13:32,868 --> 00:13:36,834
the ones that have been mislabeled. Of course, you don't want to label everything again.

216
00:13:37,032 --> 00:13:40,514
So how do you make best usage of your time and money?

217
00:13:40,712 --> 00:13:43,778
And this is where technologies like confident learning come

218
00:13:43,784 --> 00:13:47,320
into place, right? So confident learning basically

219
00:13:47,930 --> 00:13:51,394
uses already trained models, like for instance,

220
00:13:51,442 --> 00:13:54,466
your products model or the model that you use per inference,

221
00:13:54,658 --> 00:13:58,070
and it calculates the outcomes of the predictions

222
00:13:58,150 --> 00:14:02,700
and puts them into probabilities so that you have basically

223
00:14:03,310 --> 00:14:07,366
not only one discrete prediction, but one prediction

224
00:14:07,478 --> 00:14:10,858
per label. And using

225
00:14:10,944 --> 00:14:14,454
that, you can not only compare that to your noise

226
00:14:14,502 --> 00:14:18,058
labels, where noise label doesn't essentially have to be some weekly supervised label,

227
00:14:18,074 --> 00:14:21,246
but any kind of training data where you show that there

228
00:14:21,268 --> 00:14:24,674
might be some flaws in your data. And in

229
00:14:24,712 --> 00:14:29,006
confident learning, you try to estimate the joint

230
00:14:29,198 --> 00:14:32,834
distribution of your true labels and

231
00:14:32,872 --> 00:14:36,882
your noisy labels, so that you can then compute

232
00:14:36,946 --> 00:14:39,894
or at least estimate the number of errors, right?

233
00:14:39,932 --> 00:14:43,586
So for instance, if we sum

234
00:14:43,618 --> 00:14:47,238
up the true cases, we have a probability of 75.

235
00:14:47,404 --> 00:14:50,634
And if we sum up the false cases, we have a probability of

236
00:14:50,672 --> 00:14:55,786
25%. So in general, what we could say here that we

237
00:14:55,808 --> 00:14:59,686
most likely have something of roughly 25% potential errors

238
00:14:59,718 --> 00:15:03,342
in our data, which is quite a large

239
00:15:03,396 --> 00:15:07,294
number, right? So of course, this is not a

240
00:15:07,332 --> 00:15:09,950
perfect computation, but it is an estimation.

241
00:15:10,850 --> 00:15:15,054
And what you can now do is that you can, using the model outcomes,

242
00:15:15,182 --> 00:15:18,914
compute confidence scores per each prediction and

243
00:15:18,952 --> 00:15:22,414
then sort so that you have the lowest scores

244
00:15:22,462 --> 00:15:25,858
first. And if you know that you have an error rate of 25%,

245
00:15:25,944 --> 00:15:29,414
chances are hide that in those first quarter of your data,

246
00:15:29,532 --> 00:15:33,014
there are a lot of label errors. And by looping over them

247
00:15:33,052 --> 00:15:36,806
or looking and investigating them, you will

248
00:15:36,828 --> 00:15:39,500
most likely find some labeling issues.

249
00:15:40,670 --> 00:15:44,554
So, confident learning essentially helps to estimate how

250
00:15:44,592 --> 00:15:48,630
large the error rate is, which ultimately helps you to determine

251
00:15:48,710 --> 00:15:52,474
the quality and to find those records

252
00:15:52,522 --> 00:15:55,470
which potentially are still mislabeled.

253
00:15:56,450 --> 00:15:59,802
Then again, if we use technologies like weak supervision,

254
00:15:59,866 --> 00:16:03,294
which makes use of lots of heuristics, you can

255
00:16:03,332 --> 00:16:06,686
also debug those heuristics in many cases. And this is what I meant,

256
00:16:06,718 --> 00:16:10,318
that manual labeling also is very important for burn feed labeling.

257
00:16:10,414 --> 00:16:14,402
And that, for instance, if you have set up a labeling function that looks

258
00:16:14,456 --> 00:16:17,846
for whether a text starts with a digit and then

259
00:16:17,868 --> 00:16:21,538
products, that this is clickbait. What you could do in Burnfeed labeling

260
00:16:21,554 --> 00:16:25,986
is that you filter for those records that are hit by this labeling

261
00:16:26,018 --> 00:16:29,714
function and then try to investigate in which cases

262
00:16:29,762 --> 00:16:33,178
this heuristic is wrong. So, for instance, we see that

263
00:16:33,264 --> 00:16:36,886
clickbait is only the case if it starts with a digit and the sentiment

264
00:16:36,918 --> 00:16:40,522
is also rather positive, so that we can narrow down

265
00:16:40,576 --> 00:16:43,120
our heuristics, they become better over time,

266
00:16:43,890 --> 00:16:47,646
and we can work on that and debug basically our heuristics. Of course,

267
00:16:47,668 --> 00:16:50,766
this works when you use weak supervision. Then again,

268
00:16:50,868 --> 00:16:55,054
if you also labeling with multiple users, and you use strategies

269
00:16:55,102 --> 00:16:58,210
to label on data that also has been labeled by other people,

270
00:16:58,360 --> 00:17:02,002
you can calculate the inter annotator agreement to see where

271
00:17:02,056 --> 00:17:05,746
potential disagreements are and also how subjective

272
00:17:05,778 --> 00:17:08,886
labeling might be in your task. But you can also,

273
00:17:08,988 --> 00:17:12,246
again, if you use something like greek supervision, use your

274
00:17:12,268 --> 00:17:16,600
existing heuristics to estimate where there might be some

275
00:17:17,210 --> 00:17:20,162
explicit bias, right? So, for instance,

276
00:17:20,226 --> 00:17:23,878
if this, my coworker Zimon and I were

277
00:17:23,964 --> 00:17:27,194
labeled on the same heuristic, and he has a very different position

278
00:17:27,312 --> 00:17:31,378
than I have, then it might be that we need to talk about this heuristic

279
00:17:31,414 --> 00:17:35,038
because we have a different understanding about it. So it really helps us understand

280
00:17:35,124 --> 00:17:37,600
the bias that we potentially have.

281
00:17:39,010 --> 00:17:42,490
So you see, for both Greenfield and Brownfield, we have a

282
00:17:42,500 --> 00:17:46,114
lot of very interesting technologies that we can use to

283
00:17:46,152 --> 00:17:49,890
really help us create the training data that we need, both for

284
00:17:49,960 --> 00:17:53,698
creating prototypes quickly,

285
00:17:53,864 --> 00:17:57,186
but also to continuously improve our models.

286
00:17:57,378 --> 00:18:01,186
So if we now think about how data labeling

287
00:18:01,218 --> 00:18:05,094
can change over time, we also can think about if

288
00:18:05,132 --> 00:18:08,650
training data is an integral part of machine learning applications,

289
00:18:08,990 --> 00:18:12,422
how this will look like also with respect to maintenance and documentation,

290
00:18:12,486 --> 00:18:16,026
because if it is an integral part of

291
00:18:16,128 --> 00:18:19,340
the software should also, at least

292
00:18:19,870 --> 00:18:23,166
that we can think about, should also be

293
00:18:23,188 --> 00:18:26,590
documented. And it's essentially different

294
00:18:26,660 --> 00:18:30,346
than software artifact would look like, right? So you don't have a doc

295
00:18:30,378 --> 00:18:33,806
string, but what could it be looking like? Again,

296
00:18:33,908 --> 00:18:37,714
this is just something I want to provide us with some food for

297
00:18:37,752 --> 00:18:40,834
thoughts. Not a definitive answer, but just something to think

298
00:18:40,872 --> 00:18:44,178
about because it's quite interesting. And also,

299
00:18:44,344 --> 00:18:48,520
if we talk about labeling, we see that now technologies like

300
00:18:49,050 --> 00:18:52,454
neural search or weak supervision create lots of

301
00:18:52,492 --> 00:18:56,162
metadata. Then will this potentially shift

302
00:18:56,306 --> 00:18:59,446
our idea of labeling? That is where we've

303
00:18:59,478 --> 00:19:03,030
focused, to an idea of enrichment that is rather holistic.

304
00:19:03,190 --> 00:19:06,710
So, for instance, if we're able to quickly automate data labeling,

305
00:19:06,790 --> 00:19:10,746
this might lead to us creating more classifiers in

306
00:19:10,768 --> 00:19:14,906
shorter time and ultimately helps us to iterate on product reviews,

307
00:19:14,938 --> 00:19:17,440
product feedbacks, stuff like this.

308
00:19:18,050 --> 00:19:21,342
So how will the future of this look like? And what part

309
00:19:21,396 --> 00:19:25,170
will data labeling look like in building machine learning applications?

310
00:19:26,470 --> 00:19:29,906
So, as promised, if you're interested in those

311
00:19:30,008 --> 00:19:33,794
techniques or want to research a bit about it,

312
00:19:33,912 --> 00:19:37,746
I have some great resources that

313
00:19:37,768 --> 00:19:41,046
you can look into. And if this is not enough, you can also

314
00:19:41,148 --> 00:19:44,994
just reach out to me and I will show you some further cool resources

315
00:19:45,042 --> 00:19:49,610
because those are very interesting and state of the art technologies.

316
00:19:51,390 --> 00:19:55,030
And we also have what I just described,

317
00:19:55,110 --> 00:19:59,370
technologies integrated to an open source application that

318
00:19:59,440 --> 00:20:03,102
you can try out if you want to. We're going to publish it

319
00:20:03,156 --> 00:20:06,606
very soon, and if you're interested, you can just register for

320
00:20:06,628 --> 00:20:09,694
our newsletter on our web app, sorry, not web app,

321
00:20:09,732 --> 00:20:13,006
website. And we will reach out to you once we

322
00:20:13,028 --> 00:20:16,606
have published it. So thank you

323
00:20:16,628 --> 00:20:20,030
so much for your attention. I'm super happy to be able to

324
00:20:20,100 --> 00:20:23,566
talk here at Conf 42. If you have any further questions,

325
00:20:23,668 --> 00:20:27,286
please don't hesitate at all to contact me. And thank you so much

326
00:20:27,308 --> 00:20:27,730
for your attention.

