1
00:00:39,010 --> 00:00:42,550
Hello everyone, thank you for coming to

2
00:00:42,620 --> 00:00:45,778
our talk. Cocktail of environments, how to mix

3
00:00:45,874 --> 00:00:49,334
dev and test and stay alive. My name

4
00:00:49,372 --> 00:00:53,374
is Alex Aleksandr Tarasov and you can find me

5
00:00:53,572 --> 00:00:56,666
on different social networks. My names

6
00:00:56,698 --> 00:01:00,414
are strictly consistent and I'm happy to present my

7
00:01:00,452 --> 00:01:03,150
co speaker today, Dmitry Ulianov Dima.

8
00:01:03,970 --> 00:01:08,186
Hi guys, and welcome to our talk about cocktail

9
00:01:08,218 --> 00:01:12,058
of environments. And let's start from the beginning.

10
00:01:12,154 --> 00:01:16,066
Definitely. Let's assume that you're

11
00:01:16,098 --> 00:01:20,680
working in the young tech company and

12
00:01:22,010 --> 00:01:25,542
you are at very early stage, you have only

13
00:01:25,596 --> 00:01:28,794
development and production, and at some

14
00:01:28,832 --> 00:01:33,100
point CDO comes to you and asking

15
00:01:33,870 --> 00:01:37,702
what about testing? We don't have it. And let's

16
00:01:37,766 --> 00:01:41,166
establish testing process. There are

17
00:01:41,268 --> 00:01:45,402
obvious solutions, just let's

18
00:01:45,466 --> 00:01:49,786
set up staging or testing environment in between of development and production.

19
00:01:49,978 --> 00:01:53,250
We are calling it typical environments.

20
00:01:53,750 --> 00:01:57,506
But today we'll present yet another

21
00:01:57,688 --> 00:02:00,740
approach, how to make it better.

22
00:02:01,510 --> 00:02:05,974
Let's set goals first. And our

23
00:02:06,092 --> 00:02:09,302
initial goal was to have always

24
00:02:09,356 --> 00:02:13,174
stable testing environments. We expect that

25
00:02:13,212 --> 00:02:16,502
it will work all the time. It will stable enough.

26
00:02:16,556 --> 00:02:19,850
And it would be great as well to

27
00:02:20,000 --> 00:02:23,674
have development environments stable too,

28
00:02:23,872 --> 00:02:28,326
because if you want to test your new service which somehow

29
00:02:28,358 --> 00:02:31,360
interact with the front end,

30
00:02:31,730 --> 00:02:35,262
probably you want to have front

31
00:02:35,316 --> 00:02:38,686
end and all dependent services stable too,

32
00:02:38,788 --> 00:02:42,650
right? Second thing is we

33
00:02:42,820 --> 00:02:46,546
will try to minimize the gap between development and

34
00:02:46,648 --> 00:02:49,620
qas, because usually what I've seen in my experience,

35
00:02:50,790 --> 00:02:55,194
if you have separate testing environments where only qas

36
00:02:55,342 --> 00:02:59,014
work, developers will not pay enough attention on these

37
00:02:59,052 --> 00:03:02,566
environments. And finally, when you are getting more and

38
00:03:02,588 --> 00:03:06,230
more microservices, it's becoming more fragile.

39
00:03:06,650 --> 00:03:09,450
And despite of microservices,

40
00:03:11,870 --> 00:03:16,090
microservices architecture, it's designed to be stable.

41
00:03:16,990 --> 00:03:21,454
That's funny, but actually it's not as

42
00:03:21,492 --> 00:03:25,326
good as it sounds, because if you

43
00:03:25,348 --> 00:03:29,454
have hundreds of microservices, it's becoming quite

44
00:03:29,572 --> 00:03:32,750
tricky and hard to keep it stable.

45
00:03:33,110 --> 00:03:36,930
So this is a second goal to

46
00:03:37,000 --> 00:03:40,050
minimize this gap between developers and QAS.

47
00:03:40,470 --> 00:03:44,382
Third, we'll try to unlock parallel

48
00:03:44,446 --> 00:03:48,006
testing here. I mean that if you

49
00:03:48,028 --> 00:03:52,662
have two or three qas, basically two

50
00:03:52,716 --> 00:03:56,978
or more, their tests potentially

51
00:03:57,074 --> 00:04:00,700
could affect each other and

52
00:04:02,270 --> 00:04:05,834
we would like to solve it somehow. We thought about that and

53
00:04:05,872 --> 00:04:09,946
we'll share our thoughts on this topic. And finally,

54
00:04:10,048 --> 00:04:12,880
it would be great to keep it as simple as possible,

55
00:04:13,330 --> 00:04:16,654
but let's see what we'll have. Yeah, the main

56
00:04:16,692 --> 00:04:20,830
question here is to create new test environment or not. And if we think

57
00:04:20,900 --> 00:04:24,114
differently here, so we can imagine that we have

58
00:04:24,152 --> 00:04:27,694
some atypical environments and mixing development

59
00:04:27,742 --> 00:04:31,138
and stage environment into one environment, at least it

60
00:04:31,144 --> 00:04:34,462
could be, for example, one physical Kubernetes cluster.

61
00:04:34,606 --> 00:04:37,794
But even if we have one physical cluster,

62
00:04:37,842 --> 00:04:42,166
we have several logical environments. It means that so we have

63
00:04:42,348 --> 00:04:46,678
different, maybe namespaces, or it will be different

64
00:04:46,844 --> 00:04:50,554
deployments or argo allowed. And so,

65
00:04:50,672 --> 00:04:54,422
and if we consider which environments,

66
00:04:54,486 --> 00:04:59,446
logical environments we have, we can define that. First, we have stabledef

67
00:04:59,638 --> 00:05:03,354
that always contains all the services with the same versions

68
00:05:03,482 --> 00:05:07,514
as in production to test something, right? So it's

69
00:05:07,562 --> 00:05:10,986
our foundation and all default routes

70
00:05:11,098 --> 00:05:14,878
come to it. And yeah, as I said, it's a foundation

71
00:05:14,974 --> 00:05:18,558
for developing, for testing and for staging.

72
00:05:18,734 --> 00:05:22,450
And if we talk and try to

73
00:05:22,520 --> 00:05:26,034
explain what stable dev means, so I can show

74
00:05:26,072 --> 00:05:29,694
you this mem, and we have development environment,

75
00:05:29,742 --> 00:05:33,318
we have testing and staging environment, we mix them and

76
00:05:33,484 --> 00:05:36,994
we get stabledev. It's like a development,

77
00:05:37,042 --> 00:05:41,100
but it's a stable part of development. It could sounds

78
00:05:41,630 --> 00:05:45,578
a little bit controversial, but let's try to not create

79
00:05:45,664 --> 00:05:48,982
new environment, at least new physical environment,

80
00:05:49,046 --> 00:05:52,558
right? And try to put all these components inside

81
00:05:52,644 --> 00:05:56,800
one. And because of that we have different

82
00:05:57,170 --> 00:05:59,230
logical environments.

83
00:06:00,130 --> 00:06:03,646
For example, we definitely have branch dev,

84
00:06:03,748 --> 00:06:07,614
and branch Dev is a second part. So it means that every developer

85
00:06:07,662 --> 00:06:11,906
can test their own feature branches on

86
00:06:11,928 --> 00:06:15,230
the same cluster, right? So when they develop some feature,

87
00:06:15,390 --> 00:06:18,900
and also we have release candidate and deF,

88
00:06:19,370 --> 00:06:23,240
because every new release we deployed, it should be

89
00:06:24,010 --> 00:06:27,814
presented as candidate. First, we need to evaluate, we need to assess

90
00:06:27,862 --> 00:06:31,130
it before we can go further.

91
00:06:31,470 --> 00:06:35,654
And to implement it, we need to address several

92
00:06:35,702 --> 00:06:39,034
issues. Mitri, could you please tell us more what

93
00:06:39,072 --> 00:06:43,342
these issues are? Yeah, after we thought

94
00:06:43,396 --> 00:06:47,120
about that a lot. And finally,

95
00:06:47,490 --> 00:06:51,258
initially it was mind blowing how we can mix

96
00:06:51,434 --> 00:06:54,930
different logical environments in one physical infrastructure.

97
00:06:55,350 --> 00:06:59,054
And finally we defined the following

98
00:06:59,102 --> 00:07:03,134
groups of issues. First is how to rotate traffic

99
00:07:03,182 --> 00:07:07,062
between microservices. That's obvious thing.

100
00:07:07,116 --> 00:07:10,694
If you want to test somehow to pass the traffic to

101
00:07:10,732 --> 00:07:12,920
a feature branch of some specific service,

102
00:07:14,490 --> 00:07:17,430
you need kind of service mesh.

103
00:07:19,230 --> 00:07:23,210
Second topic is event routing.

104
00:07:24,350 --> 00:07:27,782
Not all the time you're passing real time traffic.

105
00:07:27,846 --> 00:07:31,722
Sometimes it's background events generated

106
00:07:31,786 --> 00:07:34,958
by cron jobs or whatever,

107
00:07:35,124 --> 00:07:38,638
and you need somehow to pass

108
00:07:38,724 --> 00:07:41,518
events to specific version of your service.

109
00:07:41,684 --> 00:07:45,406
And third topic here is data isolation.

110
00:07:45,518 --> 00:07:50,660
If you want to ensure that your

111
00:07:51,350 --> 00:07:55,414
parallel tests, our third goal, is not affecting each

112
00:07:55,452 --> 00:07:58,630
other, you need to isolate the data somehow.

113
00:07:58,970 --> 00:08:03,046
Yeah, let's talk about all these things

114
00:08:03,228 --> 00:08:07,094
and start with the easiest part, that is

115
00:08:07,132 --> 00:08:11,210
called service mesh. So in fact we have these

116
00:08:11,280 --> 00:08:15,494
issues to address. So in fact we want to test our release

117
00:08:15,542 --> 00:08:19,398
candidates and branch versions of developer in a cold chain.

118
00:08:19,494 --> 00:08:23,930
And to implement it we need to do service injection.

119
00:08:24,090 --> 00:08:27,614
Imagine we have payment service, front end

120
00:08:27,652 --> 00:08:31,466
application, some Nginx and I as a developer created

121
00:08:31,498 --> 00:08:34,914
new branch feature MP 101 blah blah blah and

122
00:08:34,952 --> 00:08:39,314
deployed it to dev cluster with

123
00:08:39,432 --> 00:08:43,106
GitLab pipeline. And then in fact I want

124
00:08:43,128 --> 00:08:47,000
to test my code, right? And to do it I need to

125
00:08:48,490 --> 00:08:51,910
wrote the traffic, wrote my requests to

126
00:08:52,060 --> 00:08:56,198
my concrete version of payment service,

127
00:08:56,364 --> 00:08:59,926
and from payment service I want to call as usual

128
00:09:00,038 --> 00:09:03,498
other services. I need to do some integration testing here.

129
00:09:03,584 --> 00:09:06,742
And to implement it we can use a special header

130
00:09:06,806 --> 00:09:11,120
like IQ service route that consists of the name of

131
00:09:11,570 --> 00:09:15,934
desired service and the reference name MP 101

132
00:09:15,972 --> 00:09:19,466
here. So it's like some reference name our system is aware

133
00:09:19,498 --> 00:09:22,942
of. And if we want to test

134
00:09:23,076 --> 00:09:27,134
front end application, it's easier to use cookie

135
00:09:27,182 --> 00:09:30,594
with the same name and Nginx can unpack it for us.

136
00:09:30,712 --> 00:09:34,514
If you want to test more than one branches, then we can expand our

137
00:09:34,552 --> 00:09:37,782
specification and include into it

138
00:09:37,836 --> 00:09:41,206
several services with several reference name as well.

139
00:09:41,388 --> 00:09:44,834
And if we talk about release candidate testing,

140
00:09:44,882 --> 00:09:48,506
that is very crucial for QA engineers, they can do

141
00:09:48,528 --> 00:09:52,422
it the same way by using a stable reference

142
00:09:52,486 --> 00:09:55,850
name called RC for this candidate, right.

143
00:09:56,000 --> 00:09:59,020
And we can implement it different ways.

144
00:10:01,090 --> 00:10:04,080
Which ways you can suggest to implement it?

145
00:10:05,170 --> 00:10:08,766
There are a lot of ways how we can

146
00:10:08,868 --> 00:10:12,640
do it. Nowadays there are

147
00:10:14,310 --> 00:10:18,434
few implications of service mesh which will

148
00:10:18,472 --> 00:10:21,518
work out of the box like ISIO or LinkRd.

149
00:10:21,694 --> 00:10:25,150
There is another approach which is client side building,

150
00:10:25,240 --> 00:10:28,166
but we decided to go with istio. Yeah,

151
00:10:28,268 --> 00:10:32,306
it's mature solution for service mesh

152
00:10:32,338 --> 00:10:36,502
and we can define some istio virtual service and

153
00:10:36,556 --> 00:10:39,974
deploy this virtual service with every stable version via

154
00:10:40,022 --> 00:10:43,514
our common helm chart. But there is

155
00:10:43,552 --> 00:10:47,242
a problem, we cannot do it the same for all

156
00:10:47,296 --> 00:10:50,906
our branches and for release candidates because it's a separated

157
00:10:51,098 --> 00:10:54,734
helm charts and so we cannot create and

158
00:10:54,772 --> 00:10:59,242
manage one CRD from all these deployments.

159
00:10:59,306 --> 00:11:02,914
Right. So to solve this issue we can

160
00:11:02,952 --> 00:11:06,402
use virtual service merge operator that

161
00:11:06,456 --> 00:11:09,842
can patch target virtual service with

162
00:11:09,896 --> 00:11:11,410
some new routes.

163
00:11:13,110 --> 00:11:16,582
And in that case we can

164
00:11:16,636 --> 00:11:20,854
solve our issue and deploy this CRD with every

165
00:11:21,052 --> 00:11:24,966
branch with release candidates. So looks

166
00:11:24,988 --> 00:11:28,630
like we solve our issue. Do we have any other issues

167
00:11:28,700 --> 00:11:31,850
with service with request routing?

168
00:11:32,350 --> 00:11:36,250
Looks quite elegant. Thanks Alexander. Yes, I think

169
00:11:36,400 --> 00:11:39,580
there is one open question still.

170
00:11:40,210 --> 00:11:44,110
For services everything is quite clear,

171
00:11:44,260 --> 00:11:47,982
but in the same time we have webhooks when our service is

172
00:11:48,036 --> 00:11:51,214
called by some third party external service,

173
00:11:51,412 --> 00:11:54,814
and this service obviously is not aware

174
00:11:54,862 --> 00:11:58,126
of our internal infrastructure, our releases, service names,

175
00:11:58,238 --> 00:12:01,410
versions and so on. So what to do here?

176
00:12:01,560 --> 00:12:05,278
That's a good question. So we have several solutions. The first solution,

177
00:12:05,374 --> 00:12:08,566
it's quite simple, we can just go to third party system and

178
00:12:08,588 --> 00:12:12,182
change our webhook URL but it's not very convenient first,

179
00:12:12,316 --> 00:12:15,990
and the second we can affect our stable version and

180
00:12:16,060 --> 00:12:20,490
our testing process. That is not good. So let's consider better

181
00:12:20,560 --> 00:12:23,846
solutions here. The second one is to create advanced

182
00:12:23,878 --> 00:12:27,562
mock or fake and get rid of external service

183
00:12:27,616 --> 00:12:31,062
dependency at all. And because we

184
00:12:31,136 --> 00:12:36,234
implement this fake by our own, for example, yes we can implement

185
00:12:36,282 --> 00:12:39,534
any logic we want there and we can understand

186
00:12:39,652 --> 00:12:43,426
by request who called the

187
00:12:43,448 --> 00:12:47,266
fake and which particular version of service we

188
00:12:47,288 --> 00:12:50,782
need to call back. And the third solution

189
00:12:50,846 --> 00:12:54,082
here is to using smart proxy and use

190
00:12:54,136 --> 00:12:58,514
some correlation id for matching request from and to external

191
00:12:58,562 --> 00:13:02,594
service. In this case we do not call external service directly.

192
00:13:02,642 --> 00:13:06,722
We use smart proxy and using database

193
00:13:06,786 --> 00:13:09,974
on in memory k value storage we can correlate

194
00:13:10,022 --> 00:13:13,942
our requests and change the route

195
00:13:14,006 --> 00:13:17,722
of incoming requests back to our

196
00:13:17,776 --> 00:13:22,190
system and to desired version

197
00:13:22,610 --> 00:13:26,698
as a release candidate or branch version.

198
00:13:26,794 --> 00:13:30,910
So Mitri, what your thoughts on these solutions?

199
00:13:31,970 --> 00:13:35,538
Both are good and have their own

200
00:13:35,624 --> 00:13:39,362
advantages. In case of third solution which we see

201
00:13:39,416 --> 00:13:43,330
now, it still

202
00:13:43,480 --> 00:13:47,666
will communicate with external service, right? So it's

203
00:13:47,858 --> 00:13:51,720
good for end to end testing. And smart proxy is

204
00:13:52,330 --> 00:13:55,830
quite simple thing, just keeping

205
00:13:56,810 --> 00:14:02,346
in our case we use in memory storage to

206
00:14:02,448 --> 00:14:06,502
extract, we extracted correlation

207
00:14:06,566 --> 00:14:09,942
id, it's basically just object id in our system.

208
00:14:10,016 --> 00:14:14,080
It could be order id, payment id, whatever and

209
00:14:15,170 --> 00:14:18,746
very simple, very simple and elegant elective

210
00:14:18,778 --> 00:14:22,078
solution here. But second

211
00:14:22,164 --> 00:14:25,854
solution where we had fake

212
00:14:25,902 --> 00:14:26,500
service,

213
00:14:29,430 --> 00:14:34,062
the advantage there is that the solution is independent

214
00:14:34,126 --> 00:14:37,622
of external service. So depending on the use case,

215
00:14:37,676 --> 00:14:41,990
depending on maybe test scenario, you can choose any

216
00:14:42,060 --> 00:14:45,462
of these solutions, both will work for their

217
00:14:45,516 --> 00:14:48,794
cases, fake will help

218
00:14:48,832 --> 00:14:52,380
us in case of external services down currently for example.

219
00:14:53,550 --> 00:14:57,254
And your tests just becoming

220
00:14:57,302 --> 00:15:00,958
more stable and reliable, which is good too. Yeah,

221
00:15:01,044 --> 00:15:04,270
good. And looks like we solved our first

222
00:15:04,420 --> 00:15:08,362
bunch of issues with routing and we can move further

223
00:15:08,426 --> 00:15:12,586
to event routing. So why we need route

224
00:15:12,618 --> 00:15:16,674
our events? We have routing for

225
00:15:16,792 --> 00:15:19,934
logic, for traffic routing, but in case of events

226
00:15:19,982 --> 00:15:23,982
it's more untrival

227
00:15:24,046 --> 00:15:27,206
I would say because we have more

228
00:15:27,308 --> 00:15:30,150
scenarios here. For example,

229
00:15:30,220 --> 00:15:34,040
as a developer I'm creating new version of

230
00:15:34,490 --> 00:15:38,140
my microservice which is

231
00:15:38,590 --> 00:15:43,094
let's say consumer. And in this case I need somehow

232
00:15:43,142 --> 00:15:47,094
to pass specific event generated

233
00:15:47,142 --> 00:15:51,050
by producer to my concurred

234
00:15:51,210 --> 00:15:54,350
new version of microservice.

235
00:15:54,850 --> 00:15:57,520
How to do it? Not really clear.

236
00:15:58,930 --> 00:16:02,990
In the same time we have perpendicular

237
00:16:03,750 --> 00:16:08,126
option when we need to test producer, we need to generate let's

238
00:16:08,158 --> 00:16:11,474
say event on the new

239
00:16:11,512 --> 00:16:15,346
version of producer and handle it

240
00:16:15,368 --> 00:16:18,654
on the stable version of consumer. So it's matrix

241
00:16:18,702 --> 00:16:22,438
of options and let's see what can we do here. Yeah,

242
00:16:22,524 --> 00:16:25,974
the main question here is who should process a message, right? If you have

243
00:16:26,012 --> 00:16:30,598
for example one subscription and one topic and several consumers

244
00:16:30,774 --> 00:16:34,666
in different implications of

245
00:16:34,848 --> 00:16:36,460
our service, right?

246
00:16:37,390 --> 00:16:40,846
In its different versions. So we can use the

247
00:16:40,868 --> 00:16:45,194
same approach as we did for request

248
00:16:45,242 --> 00:16:48,462
routing. We can use event routing. It means that we can

249
00:16:48,596 --> 00:16:52,882
use some discriminator, some built

250
00:16:52,936 --> 00:16:56,210
in attributes, for example in our message and

251
00:16:56,280 --> 00:16:59,634
pass them our x service route as we

252
00:16:59,752 --> 00:17:02,574
did it for request routing,

253
00:17:02,622 --> 00:17:04,660
right? And based on this information,

254
00:17:07,290 --> 00:17:10,998
based on this information, we can process or do not process

255
00:17:11,084 --> 00:17:14,578
messages. And to implement it, we can use one topic,

256
00:17:14,674 --> 00:17:17,058
still one topic for all messages.

257
00:17:17,234 --> 00:17:21,018
But we need to create

258
00:17:21,184 --> 00:17:24,758
several subscriptions. One subscription for release candidate,

259
00:17:24,934 --> 00:17:28,854
for example one subscription for all branches.

260
00:17:28,982 --> 00:17:32,334
But in that case, if we use one subscription for

261
00:17:32,372 --> 00:17:36,174
all branches, our developers can interfere with each other.

262
00:17:36,212 --> 00:17:40,094
That is not good, right? And the better solution here

263
00:17:40,132 --> 00:17:43,554
is to create separate subscription per branch and in this

264
00:17:43,592 --> 00:17:47,266
case so our messages are not interfere with each

265
00:17:47,288 --> 00:17:50,498
other and to implement it,

266
00:17:50,584 --> 00:17:54,610
to implement this part. So we need to do these things that

267
00:17:54,680 --> 00:17:58,386
first we need to create our static subscriptions for release candidates,

268
00:17:58,498 --> 00:18:01,650
then we need to create dynamic subscriptions for branches.

269
00:18:01,810 --> 00:18:05,366
And finally we need some common library that we

270
00:18:05,388 --> 00:18:09,110
will talk about later. Let's start with static subscriptions

271
00:18:09,190 --> 00:18:13,500
for these candidates. It's quite easy.

272
00:18:14,030 --> 00:18:17,574
We have service catalog that is state machine

273
00:18:17,622 --> 00:18:20,942
with bunch of modelers and we just change our pub sub model,

274
00:18:21,076 --> 00:18:24,606
rerun the state machine for all the services and

275
00:18:24,788 --> 00:18:28,574
get custom subscriptions for

276
00:18:28,772 --> 00:18:32,510
these candidates. And for quality assurance folks

277
00:18:33,030 --> 00:18:36,606
with dynamic subscriptions, it's more complicated

278
00:18:36,798 --> 00:18:40,322
because in this case we need to have one more service.

279
00:18:40,456 --> 00:18:44,942
We called it M Hub and we register every

280
00:18:45,016 --> 00:18:49,302
branch. So when I as a developer create

281
00:18:49,356 --> 00:18:52,822
a new branch, right? So on the first pipeline run,

282
00:18:52,956 --> 00:18:56,754
I register my environment and then reapply

283
00:18:56,802 --> 00:19:01,274
pub sub model and custom subscription is

284
00:19:01,312 --> 00:19:05,066
created after that. And to clean up all these resources we can

285
00:19:05,088 --> 00:19:08,694
use the same. We can deregister

286
00:19:08,742 --> 00:19:12,254
our environment on branch deletion, then reapply pub

287
00:19:12,292 --> 00:19:15,710
sub model once again and our

288
00:19:15,780 --> 00:19:19,694
custom subscription is gone. And this is a

289
00:19:19,812 --> 00:19:23,226
very clear and straightforward process because we have

290
00:19:23,268 --> 00:19:26,834
it in our pipeline. So as you can see

291
00:19:26,872 --> 00:19:30,574
here, provision Resources job creates these subscriptions

292
00:19:30,622 --> 00:19:34,270
for us and the provision resources clean them up and eventually

293
00:19:34,350 --> 00:19:37,910
we will clean them anyway, these subscriptions.

294
00:19:38,810 --> 00:19:42,230
But I think that we have one more issue.

295
00:19:42,380 --> 00:19:46,614
Mitri, could you please think about what

296
00:19:46,652 --> 00:19:50,940
we forgot here? Yeah, the question is,

297
00:19:52,590 --> 00:19:56,378
as you said, first issue is

298
00:19:56,544 --> 00:20:00,140
who should accept the message? And second question,

299
00:20:00,930 --> 00:20:05,246
how to not accept the same message and

300
00:20:05,348 --> 00:20:09,278
handle the same message in all

301
00:20:09,444 --> 00:20:12,786
my releases, right? And there

302
00:20:12,808 --> 00:20:17,266
is another thing which I'm thinking about

303
00:20:17,368 --> 00:20:20,674
is, for example,

304
00:20:20,792 --> 00:20:24,690
if I'm generating events

305
00:20:25,050 --> 00:20:28,920
and this event is not for some

306
00:20:29,450 --> 00:20:33,106
existing environment. Let's say you mentioned MP

307
00:20:33,218 --> 00:20:37,266
101 previously, right? And I'm

308
00:20:37,298 --> 00:20:41,194
generating event with the routing key

309
00:20:41,392 --> 00:20:44,566
mp 102. Let's say how to not skip

310
00:20:44,598 --> 00:20:47,900
this event, because if we'll skip events by design,

311
00:20:49,870 --> 00:20:52,974
our data finally will become inconsistent, right?

312
00:20:53,012 --> 00:20:56,110
So that's not very nice.

313
00:20:56,260 --> 00:21:00,014
Let's see, what can we do here? Yeah, to solve these

314
00:21:00,052 --> 00:21:03,446
issues, we need some common library that will do for us context

315
00:21:03,498 --> 00:21:07,026
propagation and message skip logic. And this library should be

316
00:21:07,048 --> 00:21:10,722
used by every microservice in our system. This common

317
00:21:10,776 --> 00:21:14,146
library do follow the following things. The first,

318
00:21:14,248 --> 00:21:17,670
we grab our Xsource route from

319
00:21:17,820 --> 00:21:21,894
server context and put it into attributes of pub

320
00:21:21,932 --> 00:21:25,094
sub message. Then we send this message, and in all

321
00:21:25,132 --> 00:21:29,150
consumers we receive this message. But before we decrilize

322
00:21:29,170 --> 00:21:33,050
it, we need to decide should we skip or should we process this message,

323
00:21:33,120 --> 00:21:36,394
right? And there is a tricky thing.

324
00:21:36,512 --> 00:21:40,154
So for example, if I pass that, I want

325
00:21:40,352 --> 00:21:43,774
the reference name as MP 101.

326
00:21:43,892 --> 00:21:47,006
So inside the library, my canary. Or this

327
00:21:47,028 --> 00:21:50,862
candidate can say that, okay, it's not for me, definitely. And payment

328
00:21:50,916 --> 00:21:54,510
service MP one four six can say okay, it's not for me too.

329
00:21:54,660 --> 00:21:58,526
And payment service MP 101 said, okay, it's for me because it's

330
00:21:58,558 --> 00:22:01,906
my reference name right here. But what to do with the

331
00:22:01,928 --> 00:22:06,286
stable release? Should we process this message or not? Because imagine

332
00:22:06,318 --> 00:22:09,682
that I pass, as Mitri said, like MP

333
00:22:09,746 --> 00:22:13,334
102, who should process this message. Looks like a stable one,

334
00:22:13,372 --> 00:22:17,074
but stable one should be aware that we have no MP

335
00:22:17,202 --> 00:22:20,634
102 version of payment service,

336
00:22:20,752 --> 00:22:24,262
and it leads us to make our library

337
00:22:24,326 --> 00:22:28,074
aware of all other versions. And so we need

338
00:22:28,112 --> 00:22:31,598
to have some kind of real time configuration. We need

339
00:22:31,604 --> 00:22:34,862
to fetch the current state of all

340
00:22:34,916 --> 00:22:39,102
our version of our services from

341
00:22:39,236 --> 00:22:42,218
environment hub service, right.

342
00:22:42,404 --> 00:22:46,210
And this could help us with this issue.

343
00:22:46,360 --> 00:22:50,050
And finally, we need to put

344
00:22:50,200 --> 00:22:53,454
this x source route back to the client

345
00:22:53,502 --> 00:22:58,646
context. And we need to do it because we

346
00:22:58,668 --> 00:23:02,290
want to follow like a cloud chain. But this cold chain

347
00:23:02,370 --> 00:23:06,434
will include not only our HTTP or GRPC

348
00:23:06,482 --> 00:23:09,866
requests, yes, but also events. And we

349
00:23:09,888 --> 00:23:13,946
can say that our cold chain could consist of real time

350
00:23:14,048 --> 00:23:17,510
messages and some events,

351
00:23:17,590 --> 00:23:20,782
right? Some background messages here. Looks like

352
00:23:20,836 --> 00:23:23,120
we solved the issue admitted, right?

353
00:23:24,610 --> 00:23:28,250
Yes, exactly. Looks we've

354
00:23:28,330 --> 00:23:32,174
really solved the issue. And basically what we have

355
00:23:32,212 --> 00:23:36,094
here is extension of the service mesh logic

356
00:23:36,222 --> 00:23:40,100
for events, right? And one note here,

357
00:23:41,190 --> 00:23:45,290
this solution assumes that our common library,

358
00:23:45,390 --> 00:23:49,350
our service, is aware of its version

359
00:23:50,410 --> 00:23:55,366
to understand that some messages have

360
00:23:55,388 --> 00:23:58,300
to be handled on this service.

361
00:23:59,390 --> 00:24:02,570
Quite nice solution. Let's switch to

362
00:24:02,640 --> 00:24:06,700
data isolation. Yeah, the last one.

363
00:24:08,510 --> 00:24:11,866
Okay, why we need to care of this

364
00:24:11,888 --> 00:24:15,950
data isolation, what we cannot use, for example, one database for all

365
00:24:16,020 --> 00:24:20,554
our versions of services, like let's

366
00:24:20,602 --> 00:24:24,110
developers use the same database. Logical.

367
00:24:24,450 --> 00:24:27,620
Why? It's a good question. Be aware of. Yeah.

368
00:24:28,150 --> 00:24:31,620
Initially we defined the goal for us

369
00:24:32,550 --> 00:24:36,562
to enable real parallel testing,

370
00:24:36,706 --> 00:24:39,794
right? And it assumes

371
00:24:39,842 --> 00:24:43,734
that my database should

372
00:24:43,772 --> 00:24:46,966
not be touched by anyone who is developing something in

373
00:24:46,988 --> 00:24:50,778
parallel or who is testing something in parallel. I want to

374
00:24:50,944 --> 00:24:55,500
have isolated data and break my service by myself only.

375
00:24:56,350 --> 00:25:00,138
So to achieve that we

376
00:25:00,224 --> 00:25:02,998
need isolated databases.

377
00:25:03,094 --> 00:25:06,618
Probably, yeah. So for example, I'm as

378
00:25:06,624 --> 00:25:10,734
a developer can write a migration which will break

379
00:25:10,932 --> 00:25:14,110
our database. Yeah, that's not good.

380
00:25:14,180 --> 00:25:17,874
All our tests will fail. So what we can do with it?

381
00:25:17,912 --> 00:25:21,550
So we can use the same approach that we used for subscriptions.

382
00:25:21,630 --> 00:25:25,490
We can create, for example, every night separate logical

383
00:25:25,570 --> 00:25:29,650
database for all branches. That's easy approach

384
00:25:29,810 --> 00:25:33,254
and it very well suits even with large

385
00:25:33,372 --> 00:25:37,158
amount data in databases. But we have here

386
00:25:37,244 --> 00:25:40,758
the problems that our developers could interfere

387
00:25:40,774 --> 00:25:44,314
with each other once again. And we have another one

388
00:25:44,352 --> 00:25:47,750
solution when we use separate database per branch

389
00:25:47,910 --> 00:25:51,182
and we create this database as we created our

390
00:25:51,236 --> 00:25:55,658
subscriptions here on the first branch deployment.

391
00:25:55,834 --> 00:25:59,578
And when we do it, right, so we have some nightly jobs

392
00:25:59,594 --> 00:26:03,470
that exports all databases from our

393
00:26:03,620 --> 00:26:07,294
stable dev environment, the stable versions

394
00:26:07,342 --> 00:26:10,466
of data to gcs. And then,

395
00:26:10,568 --> 00:26:13,842
so we import this data with terraform DB model when

396
00:26:13,896 --> 00:26:17,560
we need it on branch creation, and we can easily create

397
00:26:18,330 --> 00:26:22,326
new logical database from

398
00:26:22,348 --> 00:26:26,022
these dumps. Mitri, do you see any issues with this

399
00:26:26,076 --> 00:26:29,562
approach? Looks quite

400
00:26:29,696 --> 00:26:33,114
good, but obviously there are some

401
00:26:33,152 --> 00:26:38,186
potential issues. For example, in case of my

402
00:26:38,288 --> 00:26:41,040
database is pretty big.

403
00:26:42,210 --> 00:26:45,678
What else? Yeah, and I think that,

404
00:26:45,764 --> 00:26:49,262
for example, if we use this

405
00:26:49,316 --> 00:26:52,826
approach for things like redis for caching,

406
00:26:52,938 --> 00:26:56,654
it's okay because we have lost our cache, at least we can refill

407
00:26:56,702 --> 00:26:59,874
this for a particular branch. And so.

408
00:27:00,072 --> 00:27:03,486
But if we using it for databases,

409
00:27:03,598 --> 00:27:07,350
it could lead us to incomplete data, right? For example, if you have

410
00:27:07,420 --> 00:27:11,702
a payment service and order service and I

411
00:27:11,836 --> 00:27:15,302
deploy new, for example, payment service, and there

412
00:27:15,356 --> 00:27:19,210
will be situation where we have

413
00:27:19,280 --> 00:27:22,554
orders or we have order that has

414
00:27:22,592 --> 00:27:25,706
no payment and for example, we need to be aware of it.

415
00:27:25,728 --> 00:27:27,900
Mitri, what we can do with it?

416
00:27:28,990 --> 00:27:32,362
I think nothing special. After discussions

417
00:27:32,426 --> 00:27:36,874
with the engineering teams, we decided to accept

418
00:27:36,922 --> 00:27:40,574
this risk because it's quite typical thing

419
00:27:40,612 --> 00:27:44,370
for microservices and services

420
00:27:44,520 --> 00:27:47,858
have to be ready for some data

421
00:27:48,024 --> 00:27:52,162
skew and for

422
00:27:52,216 --> 00:27:55,894
some data inconsistency because in this

423
00:27:55,932 --> 00:27:59,318
case I

424
00:27:59,324 --> 00:28:04,326
would say we couldn't find any good

425
00:28:04,428 --> 00:28:08,650
solution how to keep the data strictly consistent.

426
00:28:09,070 --> 00:28:12,826
So finally we decided to accept that.

427
00:28:13,008 --> 00:28:16,860
Yeah, and looks like we solved all our

428
00:28:17,230 --> 00:28:20,450
problems. So we implemented routing,

429
00:28:20,550 --> 00:28:23,854
event routing and data isolation, and now we can go

430
00:28:23,892 --> 00:28:28,080
to some general part. So I

431
00:28:28,690 --> 00:28:32,382
called it ephemeral environments. Miti, do you have any

432
00:28:32,436 --> 00:28:36,050
clue what are ephemeral environments?

433
00:28:37,190 --> 00:28:41,010
If we are talking about testing of one single

434
00:28:41,080 --> 00:28:42,900
service, that's clear,

435
00:28:45,290 --> 00:28:49,282
let's say it's isolated testing of one feature,

436
00:28:49,346 --> 00:28:54,050
but what to do? For example, if we are changing

437
00:28:54,130 --> 00:28:58,390
or adding or replacing multiple

438
00:28:58,910 --> 00:29:03,018
parts of our system at once, and we want to test how

439
00:29:03,104 --> 00:29:06,538
all these parts works together. Yeah, and it's like

440
00:29:06,624 --> 00:29:10,890
real life examples. And in that case we can use

441
00:29:11,040 --> 00:29:15,706
ephemeral environments. For example, we can create some MP 101 environment,

442
00:29:15,898 --> 00:29:19,674
and as you can see here, so our request comes to stabledev

443
00:29:19,722 --> 00:29:23,330
first, then goes to payment service MP 101

444
00:29:23,400 --> 00:29:27,266
as an HTTP request, or then we

445
00:29:27,448 --> 00:29:30,530
publish some message to the common payment

446
00:29:30,600 --> 00:29:35,050
topic and read this message and process it by specific subscription

447
00:29:35,150 --> 00:29:38,582
in order service MP 101 that has its own

448
00:29:38,636 --> 00:29:43,046
logical database. And then our request come to

449
00:29:43,148 --> 00:29:46,470
stable dev once again, because we don't have order

450
00:29:46,540 --> 00:29:50,678
allocation service MP 101 and it uses the stable

451
00:29:50,774 --> 00:29:54,202
version of database. So we can test any

452
00:29:54,256 --> 00:29:58,490
scenario we want, we can test every complex things

453
00:29:58,560 --> 00:30:01,778
here. And if we talk about types of ephemeral

454
00:30:01,814 --> 00:30:05,166
environments. So yeah, as we discussed, it could be just only one

455
00:30:05,348 --> 00:30:09,594
service, like I'm as a developer deployed from my feature

456
00:30:09,642 --> 00:30:13,506
branch, right? It cloud be several services I deployed, and it

457
00:30:13,528 --> 00:30:16,658
could be custom environments, for example

458
00:30:16,744 --> 00:30:20,798
for a squad or for domain like a warehouse.

459
00:30:20,894 --> 00:30:24,782
And if we look at the bigger picture, we can see that we have

460
00:30:24,936 --> 00:30:28,790
stabledev, that is a boundaries, and we can create

461
00:30:28,940 --> 00:30:32,760
any ephemeral environment, we can mix them with each other,

462
00:30:33,770 --> 00:30:37,074
we can put into this ephemeral environment

463
00:30:37,202 --> 00:30:40,506
any service we want with any versions we want to test.

464
00:30:40,608 --> 00:30:44,362
And it provides for us the great flexibility here.

465
00:30:44,496 --> 00:30:47,914
So I think that it's the

466
00:30:47,952 --> 00:30:51,742
end and we can reflect a little on this

467
00:30:51,796 --> 00:30:55,118
solution, on this hybrid solution. And let's start with benefits,

468
00:30:55,204 --> 00:30:58,320
of course. Why is it good? Yeah,

469
00:30:59,570 --> 00:31:03,170
looks like with this solution, if we thinking

470
00:31:03,240 --> 00:31:07,330
about this IQ service road key,

471
00:31:07,400 --> 00:31:09,300
as in some abstract thing,

472
00:31:11,030 --> 00:31:14,862
it's becoming like possibility to have

473
00:31:14,936 --> 00:31:19,250
endless amount of environments. But let's

474
00:31:19,330 --> 00:31:24,566
switch to conclusions and what

475
00:31:24,588 --> 00:31:26,360
do we have? Finally,

476
00:31:27,790 --> 00:31:31,082
we've solved the natural issue, which comes

477
00:31:31,216 --> 00:31:34,198
when you need to enable parallel testing,

478
00:31:34,374 --> 00:31:38,026
even if you have separate environment for

479
00:31:38,048 --> 00:31:41,654
that. Let's say that we have isolated

480
00:31:41,702 --> 00:31:45,690
staging environments, separate cluster for

481
00:31:45,760 --> 00:31:49,406
that. Anyway, what to do if you want

482
00:31:49,428 --> 00:31:51,390
to test things in parallel.

483
00:31:51,890 --> 00:31:55,774
And we are running integrational tests

484
00:31:55,822 --> 00:31:59,506
and these tests can affect results of each

485
00:31:59,528 --> 00:32:03,586
other, what to do. So finally you

486
00:32:03,608 --> 00:32:06,966
will come probably to something more or

487
00:32:06,988 --> 00:32:10,040
less similar to what we discussed right now.

488
00:32:11,290 --> 00:32:15,446
And honestly, when I thought about that,

489
00:32:15,628 --> 00:32:19,190
this was one of triggers why we decided

490
00:32:19,270 --> 00:32:23,530
to go with this approach.

491
00:32:24,990 --> 00:32:28,154
Second thing, second important point is that

492
00:32:28,272 --> 00:32:32,474
as you've seen, this solution

493
00:32:32,602 --> 00:32:36,414
requires a lot of dynamic parts in

494
00:32:36,452 --> 00:32:42,110
infrastructure. We are creating dynamically environments,

495
00:32:44,070 --> 00:32:47,634
subscriptions we are creating not

496
00:32:47,672 --> 00:32:51,502
really environments, but subscriptions for feature branches.

497
00:32:51,646 --> 00:32:55,446
And first, it assumes that you

498
00:32:55,468 --> 00:32:58,838
are using some managed solution for that. It could be

499
00:32:58,844 --> 00:33:00,760
in house, it could be some cloud,

500
00:33:01,610 --> 00:33:05,090
but you will need definitely some possibility

501
00:33:05,170 --> 00:33:08,730
to dynamically create resources. And second

502
00:33:08,800 --> 00:33:12,442
thing is that you will need to have

503
00:33:12,496 --> 00:33:15,770
some internal developer portal to be able to manage

504
00:33:15,840 --> 00:33:19,574
all this stuff, because it's becoming quite complicated.

505
00:33:19,702 --> 00:33:23,210
But comprehensive tooling helps to reduce

506
00:33:23,370 --> 00:33:25,360
the cognitive cloud here.

507
00:33:26,130 --> 00:33:30,080
And third point is about infrastructure cost.

508
00:33:30,530 --> 00:33:34,866
The solution will have definitely will

509
00:33:35,048 --> 00:33:38,962
help to save definitely maybe ten or

510
00:33:39,016 --> 00:33:43,006
20% of infrastructure costs because you don't have separate

511
00:33:43,038 --> 00:33:46,450
cluster you are sending here

512
00:33:46,520 --> 00:33:50,146
on machines, or you have less implications,

513
00:33:50,258 --> 00:33:54,130
obviously less machines because of that, less operational

514
00:33:54,210 --> 00:33:57,974
cost, less resources. And finally,

515
00:33:58,092 --> 00:34:01,686
your environment configuration is becoming even more consistent

516
00:34:01,718 --> 00:34:06,140
because of that. Yeah, and platform team I think is happy

517
00:34:06,990 --> 00:34:10,570
about it, right? So you need to definitely less number

518
00:34:10,640 --> 00:34:14,186
of, for example, physical clusters. But what is good

519
00:34:14,208 --> 00:34:17,674
for platform team may be not so good for your test engineers.

520
00:34:17,802 --> 00:34:21,342
And when I made a post in LinkedIn about this talk,

521
00:34:21,396 --> 00:34:24,866
so one of my colleagues said that he spent a lot

522
00:34:24,888 --> 00:34:28,594
of money on antidepressants. Yeah, because as every

523
00:34:28,632 --> 00:34:32,402
solution, this solution has its own drawbacks. And the

524
00:34:32,456 --> 00:34:36,210
main drawback here is a high cognitive load for developers and

525
00:34:36,280 --> 00:34:40,038
queengineers. You should hire more qualified guys,

526
00:34:40,124 --> 00:34:43,574
right? That can keep in

527
00:34:43,612 --> 00:34:47,346
their minds all these Hemas who are aware of distributed

528
00:34:47,378 --> 00:34:50,634
traces, for example, to find the issue why

529
00:34:50,752 --> 00:34:53,962
your request comes to another,

530
00:34:54,096 --> 00:34:57,446
for example, service, why it doesn't work or troubleshoot

531
00:34:57,558 --> 00:35:00,934
this. And you need of course to invest your time

532
00:35:00,992 --> 00:35:04,634
into it, into some tooling. But as Mitri

533
00:35:04,682 --> 00:35:08,142
said, yeah, really. So you will invest this time.

534
00:35:08,276 --> 00:35:12,266
I think that in case of you have separated environments for

535
00:35:12,388 --> 00:35:15,518
modern microservice development and testing,

536
00:35:15,694 --> 00:35:19,234
and maybe it's a third one and

537
00:35:19,432 --> 00:35:23,570
unique, specific for this solution. It said,

538
00:35:23,640 --> 00:35:27,446
yes, we have some data isolation, but in

539
00:35:27,468 --> 00:35:30,594
fact it's not fair data isolation.

540
00:35:30,722 --> 00:35:34,646
So sometimes you can interfere with this, especially if you,

541
00:35:34,668 --> 00:35:38,114
for example, do not do it for some kind of gcs.

542
00:35:38,162 --> 00:35:41,906
Or you can say that, okay, we will not isolate

543
00:35:41,938 --> 00:35:45,362
data, for example, for our GCS buckets as well. So let's

544
00:35:45,426 --> 00:35:48,806
use one bucket for all so,

545
00:35:48,828 --> 00:35:54,062
yeah, it's not fair, isolation, and it requires very strong

546
00:35:54,196 --> 00:35:57,614
team to handle it, by the way. I think

547
00:35:57,652 --> 00:36:01,358
that's all. And if you have any questions, you can reach us out

548
00:36:01,444 --> 00:36:05,134
on the social networks and we will. Happy to answer

549
00:36:05,252 --> 00:36:08,830
on your questions. Thank you and goodbye.

550
00:36:09,330 --> 00:36:10,442
Thanks for joining.

