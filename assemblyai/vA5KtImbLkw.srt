1
00:01:28,290 --> 00:01:32,002
Hey everyone, I'm Michael Cade. I'm a senior global technologist

2
00:01:32,066 --> 00:01:35,282
at Kasten by Veeam, where we focus on data management

3
00:01:35,346 --> 00:01:39,062
around kubernetes. But in particular, my background comes

4
00:01:39,116 --> 00:01:42,010
from completely data management, whether it be physical,

5
00:01:42,090 --> 00:01:45,486
virtual, cloud case workloads, and now even more

6
00:01:45,508 --> 00:01:49,550
recently is that requirement around having to protect workloads in

7
00:01:49,620 --> 00:01:53,706
a Kubernetes environment. So I just want to debunk some of those myths

8
00:01:53,738 --> 00:01:56,526
as we go through some of this. But then I've also got some demos,

9
00:01:56,638 --> 00:02:00,094
pretty cool demos as well, to actually debunk

10
00:02:00,222 --> 00:02:03,778
those myths. Any questions, please let me know

11
00:02:03,944 --> 00:02:07,350
either in the chat function or find me on social media.

12
00:02:07,420 --> 00:02:10,520
Email address is also down below.

13
00:02:10,890 --> 00:02:14,166
So I think we've all seen a slide that resembles a lot

14
00:02:14,188 --> 00:02:16,600
of this information around data,

15
00:02:17,130 --> 00:02:22,134
whether it be data on social media, whether it be machine

16
00:02:22,182 --> 00:02:25,862
learning from autonomous cars, whether it be photos,

17
00:02:25,926 --> 00:02:29,242
digital footprints from a personal and business point of view.

18
00:02:29,376 --> 00:02:32,766
But ultimately, we know that data is growing and really it

19
00:02:32,788 --> 00:02:36,302
doesn't matter where the platform is or what we're seeing

20
00:02:36,356 --> 00:02:40,302
out there around that. And I think it's also important

21
00:02:40,436 --> 00:02:44,526
to remember that the data is the new lifeblood

22
00:02:44,558 --> 00:02:48,670
of everything that we're doing. It's the common denominator.

23
00:02:48,830 --> 00:02:52,162
So regardless of where your workload resides, whether it's a web page

24
00:02:52,216 --> 00:02:55,118
or whether it's an actual complete system,

25
00:02:55,224 --> 00:02:58,918
databases, et cetera, that build up your whole system

26
00:02:59,004 --> 00:03:02,120
that your company uses or your customers use,

27
00:03:03,690 --> 00:03:07,366
then the data is probably the most important

28
00:03:07,468 --> 00:03:11,130
thing to you at the point, whether it be a virtual machine, a cloud

29
00:03:11,200 --> 00:03:14,358
based solution, SaaS, paaS, et cetera.

30
00:03:14,454 --> 00:03:18,890
But data is the common denominator, and we're seeing that across

31
00:03:18,960 --> 00:03:22,474
the board when it comes to failure scenarios, most dominated

32
00:03:22,522 --> 00:03:25,914
by things like ransomware in the ecosystem

33
00:03:25,962 --> 00:03:29,694
at the moment, we're seeing a lot of that. And the

34
00:03:29,732 --> 00:03:33,182
important thing to note is that all of these options

35
00:03:33,236 --> 00:03:36,462
that we have, whether it be physical machines, whether it be virtual machines,

36
00:03:36,526 --> 00:03:40,462
whether it be virtual machines in the cloud, or PaaS, SaaS based solutions,

37
00:03:40,606 --> 00:03:44,286
but then even more so, containers and container orchestration engines,

38
00:03:44,398 --> 00:03:48,310
the data still has to live somewhere, whether that be inside these platform.

39
00:03:48,380 --> 00:03:51,574
So a virtual machine with SQL on or MySQL or

40
00:03:51,612 --> 00:03:55,574
NoSQL, or whether it's a cloud based workload that's running RDS within

41
00:03:55,612 --> 00:04:00,060
AWS, or whether it's a container running a stateful set which has

42
00:04:01,070 --> 00:04:04,922
your data service residing there within the same cluster as

43
00:04:04,976 --> 00:04:08,554
maybe your front end website or front

44
00:04:08,592 --> 00:04:12,502
end application, or whether it's taking advantage of data

45
00:04:12,576 --> 00:04:15,950
outside of a cluster maybe leveraging that RDS approach as well.

46
00:04:16,020 --> 00:04:19,546
But either way, we need to think about the data protection and the management

47
00:04:19,578 --> 00:04:23,966
of that and make the correct choices,

48
00:04:24,158 --> 00:04:27,650
because none of those platforms are being to

49
00:04:27,800 --> 00:04:31,890
stop the failure scenarios, the accidental deletions,

50
00:04:32,230 --> 00:04:36,014
the malicious activity, both internal and external, the ransomware

51
00:04:36,062 --> 00:04:39,334
attacks, the security breaches, it's not going to protect against that.

52
00:04:39,372 --> 00:04:42,886
Yes, we have high availability, we have fault tolerance across many of

53
00:04:42,908 --> 00:04:46,614
these different platforms if protected correctly. But one

54
00:04:46,652 --> 00:04:50,374
thing that is for sure is that we don't necessarily have backup built into

55
00:04:50,412 --> 00:04:53,766
those platforms as well. And that's where we want to highlight that and raise

56
00:04:53,798 --> 00:04:56,540
awareness of what that is and what it looks like.

57
00:04:57,790 --> 00:05:00,986
Another important thing that I've been saying for a long time, you see a lot,

58
00:05:01,008 --> 00:05:05,130
if you went onto your favorite search engine and you did continuous

59
00:05:05,210 --> 00:05:09,150
and VMS or continuous versus VMS is what you're going to find.

60
00:05:09,300 --> 00:05:13,166
And actually that shouldn't be. The message that's portrayed out in our

61
00:05:13,188 --> 00:05:17,086
industry is that none of these systems have gone away. None of these platforms

62
00:05:17,118 --> 00:05:20,334
have gone away. We still have the requirement for physical systems,

63
00:05:20,382 --> 00:05:23,666
for virtualization, for cloud and containers. It's about having

64
00:05:23,688 --> 00:05:27,286
can awareness of what each one brings so that

65
00:05:27,308 --> 00:05:31,622
we can make the right decision for our application and for our data within

66
00:05:31,676 --> 00:05:34,006
our businesses. None of them are going away.

67
00:05:34,108 --> 00:05:38,182
Yes, we saw a massive consolidation of physical

68
00:05:38,246 --> 00:05:43,626
systems into virtual, but ultimately there

69
00:05:43,648 --> 00:05:46,330
is still the requirement around physical systems.

70
00:05:47,070 --> 00:05:50,906
But what then that does this freedom of choice as to where we

71
00:05:50,928 --> 00:05:54,318
can then store it? And obviously there's a lot of technologies built on top of

72
00:05:54,404 --> 00:05:58,206
these platforms or the areas that I just touched on, but we have

73
00:05:58,228 --> 00:06:01,626
to make that decision. And if you only know about virtual

74
00:06:01,658 --> 00:06:05,454
and physical and maybe a bit of cloud, as a systems

75
00:06:05,502 --> 00:06:09,294
administrator, DevOps engineer, platform engineer, et cetera,

76
00:06:09,422 --> 00:06:12,020
you're going to tend to go with what you know,

77
00:06:12,790 --> 00:06:16,626
whereas what we're trying to do is raise awareness of these other platforms

78
00:06:16,658 --> 00:06:19,734
out there in other sessions to let you know

79
00:06:19,772 --> 00:06:24,210
that actually you might be better off using kubernetes

80
00:06:24,290 --> 00:06:28,194
or containerized workloads or the cloud rds

81
00:06:28,242 --> 00:06:31,866
and things like that from AWS. So one

82
00:06:31,888 --> 00:06:35,290
of the key aspects that I kind of want to get across today is

83
00:06:35,440 --> 00:06:38,666
just because the same but different is we're going to

84
00:06:38,688 --> 00:06:42,414
focus in on kubernetes and data management and in

85
00:06:42,452 --> 00:06:45,946
particular is focusing on that storing and protecting

86
00:06:45,978 --> 00:06:49,386
your data via backup and restore. So we've been doing backup

87
00:06:49,418 --> 00:06:53,294
and restore for a long time, obviously way back

88
00:06:53,332 --> 00:06:56,618
from physical systems point of view with an agent, virtualization.

89
00:06:56,714 --> 00:07:00,590
We came along and we started hooking into the native APIs

90
00:07:00,750 --> 00:07:04,318
cloud exactly the same. And now here we are with kubernetes.

91
00:07:04,494 --> 00:07:08,342
So it's about choosing the right tool for the right job, but also being

92
00:07:08,396 --> 00:07:12,514
able to leverage some of the platforms underpinning APIs

93
00:07:12,562 --> 00:07:15,766
to be able to take a more efficient and fast way of being able

94
00:07:15,788 --> 00:07:19,042
to protect that data, as well as being able to restore.

95
00:07:19,106 --> 00:07:22,810
No one really cares about the backup, you only really care about the restore,

96
00:07:23,230 --> 00:07:25,770
but you have to back up to be able to restore.

97
00:07:26,270 --> 00:07:30,074
Another key area is disaster recovery. I mentioned around oh,

98
00:07:30,112 --> 00:07:33,662
we've got high availability, we've got fault tolerance built into these

99
00:07:33,716 --> 00:07:36,974
platforms. However, disaster recovery is not

100
00:07:37,012 --> 00:07:40,414
built into them. So we have to think about what happens if

101
00:07:40,532 --> 00:07:44,030
the failure scenario of fire, flood and blood, what happens

102
00:07:44,100 --> 00:07:47,790
if we need to bring up that data somewhere else, that mobility

103
00:07:47,870 --> 00:07:51,614
of data. And then that leads me on to, well, there's other use cases

104
00:07:51,662 --> 00:07:54,802
then that get highlighted from a data

105
00:07:54,856 --> 00:07:58,006
management point of view, is from an application mobility point

106
00:07:58,028 --> 00:08:02,070
of view, how can we move that data wherever we want?

107
00:08:02,140 --> 00:08:06,322
And whether that is to reduce risk, whether it is to increase

108
00:08:06,466 --> 00:08:10,140
efficiency or whether it is to reduce cost,

109
00:08:10,990 --> 00:08:14,934
one of those three things or more is going to impact

110
00:08:14,982 --> 00:08:18,214
the business in a positive way or a negative

111
00:08:18,262 --> 00:08:22,326
way if it is not able. So one of the things that we've

112
00:08:22,358 --> 00:08:26,254
been massively promoting from a casting k ten point of view is the ability to

113
00:08:26,292 --> 00:08:29,934
move data from a to b and back again if need be. But also

114
00:08:29,972 --> 00:08:33,006
think about things like being able to clone that copy of that data and be

115
00:08:33,028 --> 00:08:36,766
able to put it to work around that. So let's

116
00:08:36,798 --> 00:08:40,546
get straight into the first demo. Now, what I've got here is a

117
00:08:40,568 --> 00:08:43,666
very simple environment, and it actually leads on

118
00:08:43,688 --> 00:08:47,410
from another demo that I did in another session that built

119
00:08:47,480 --> 00:08:51,160
out this environments. But for the purposes of this demo is

120
00:08:51,690 --> 00:08:54,546
we have a three node cluster, we have a control plane, we have a node

121
00:08:54,578 --> 00:08:58,242
one and we have node two. We have a service within our Kubernetes

122
00:08:58,306 --> 00:09:02,030
cluster. We have a web application which is written in node

123
00:09:02,050 --> 00:09:05,542
JS, and we have a database that is using MongoDB.

124
00:09:05,686 --> 00:09:08,986
And within that we have a persistent volume claim that

125
00:09:09,008 --> 00:09:12,222
is using the CSI driver to

126
00:09:12,356 --> 00:09:15,710
use the host path driver here in this instance.

127
00:09:16,610 --> 00:09:20,286
But what this demo is really highlighting is

128
00:09:20,388 --> 00:09:23,966
we are using everything is but into the same platform,

129
00:09:24,068 --> 00:09:27,378
into this container, because the next demo is going to talk about

130
00:09:27,464 --> 00:09:31,374
data outside of the Kubernetes cluster that still needs to be protected.

131
00:09:31,422 --> 00:09:34,766
But how do we concentrate on the whole application? Because it's

132
00:09:34,798 --> 00:09:38,030
all well and good being able to take a copy of that persistent volume claim,

133
00:09:38,110 --> 00:09:41,654
which some other subsoftware can do,

134
00:09:41,772 --> 00:09:45,762
and that might be enough for your requirements when it comes to that failure scenario.

135
00:09:45,906 --> 00:09:49,222
But in my opinion, you're going to want to be able to capture that whole

136
00:09:49,276 --> 00:09:52,490
application. You're going to want to be able to restore the service,

137
00:09:52,560 --> 00:09:55,834
the web app, the database, the ingress that goes with that,

138
00:09:55,872 --> 00:09:59,094
the persistent volume claim that goes with that, all of the external

139
00:09:59,142 --> 00:10:03,066
data that lives in that mongo database as well. So let's

140
00:10:03,098 --> 00:10:06,522
get into that. And I'm obviously using my mission critical

141
00:10:06,586 --> 00:10:10,254
application Pacman for those that

142
00:10:10,372 --> 00:10:13,746
want to see this, this is open source. It's out there as a

143
00:10:13,768 --> 00:10:17,666
helm chart now as well as well as deployment yamls as

144
00:10:17,688 --> 00:10:20,770
well. So mission critical application,

145
00:10:20,920 --> 00:10:24,754
front end node js written in is acting as

146
00:10:24,792 --> 00:10:28,006
my front end back end database where all my mission critical high

147
00:10:28,028 --> 00:10:31,862
scores are living, is on a persistent volume. So let me

148
00:10:31,916 --> 00:10:34,840
try and. Okay, so it's kicking off.

149
00:10:36,730 --> 00:10:39,122
So what we're going to do is we're going to play a quick game.

150
00:10:39,196 --> 00:10:43,114
Let's rack up one of those high scores. And if you happen

151
00:10:43,152 --> 00:10:46,410
to be watching this and you go to app Vzilla co.

152
00:10:46,480 --> 00:10:49,690
UK, depending on what other demo

153
00:10:49,760 --> 00:10:52,686
I'm doing at the time, because I tend to use that DNS name quite a

154
00:10:52,708 --> 00:10:56,334
bit, you might find that you can have a play.

155
00:10:56,452 --> 00:11:00,074
As you can see here, I have a lot of very important high scores

156
00:11:00,202 --> 00:11:03,646
across different Kubernetes clusters as well. You can see that

157
00:11:03,668 --> 00:11:07,090
we pick up some of that important information as we go.

158
00:11:07,160 --> 00:11:10,702
Now I didn't log a score that hit on the high leaderboard.

159
00:11:10,846 --> 00:11:14,462
So if I now go into, and this is talking about the application mobility

160
00:11:14,526 --> 00:11:18,226
as the rest of the demo. So here we have our Pacman namespace

161
00:11:18,258 --> 00:11:21,446
within our Kubernetes environment. But now if

162
00:11:21,468 --> 00:11:25,206
I go and switch to a secondary, maybe a disaster recovery or

163
00:11:25,228 --> 00:11:28,118
maybe just a secondary system in particular,

164
00:11:28,204 --> 00:11:32,662
I'm going to go to EKS, AWS, EKS. And now if I go get namespaces,

165
00:11:32,806 --> 00:11:36,618
now you can see I don't have Pacman here. I have custom running, I have

166
00:11:36,624 --> 00:11:40,182
custom running in both, but I don't have the Pacman

167
00:11:40,246 --> 00:11:43,466
namespace. And what I want, I want to be able

168
00:11:43,488 --> 00:11:46,894
to bring that data, that important data, I want to bring that to my

169
00:11:46,932 --> 00:11:51,130
EKS cluster. Now that could be a migration, that could be disaster recovery,

170
00:11:51,210 --> 00:11:54,374
and it could also be a clone. Like there might be a service within EKS

171
00:11:54,442 --> 00:11:57,794
or AWS that I want to take advantage of. That data could really

172
00:11:57,832 --> 00:12:01,410
do with some of the services that are native there

173
00:12:01,480 --> 00:12:04,846
versus it being in GKE or AWS.

174
00:12:04,958 --> 00:12:08,694
Now another thing that we can do with that restore policy is being

175
00:12:08,732 --> 00:12:12,520
able to transform what that looks like. Because what we had in

176
00:12:13,130 --> 00:12:16,934
the primary cluster, we might be using storage type a

177
00:12:17,052 --> 00:12:20,406
and we might be using a load balancer. But where we go

178
00:12:20,428 --> 00:12:24,346
to eks, I want to change that because I want it to come up on

179
00:12:24,368 --> 00:12:28,246
a different storage tier and so on and so forth. So I'm

180
00:12:28,278 --> 00:12:31,626
now running through this restore policy that can be scheduled and

181
00:12:31,648 --> 00:12:35,134
we can automate that. You saw the frequency on there and then we've got this

182
00:12:35,172 --> 00:12:38,510
import policy that we're now going to run within

183
00:12:38,580 --> 00:12:41,966
that. So if I jump into my EKS cluster and that was

184
00:12:41,988 --> 00:12:45,738
a snippet just before where you can see all of my clusters, that's a snippet

185
00:12:45,754 --> 00:12:49,426
of k ten and its multicluster capabilities. So now I'm in my

186
00:12:49,448 --> 00:12:52,962
EKS cluster and I'm running that import policy to bring

187
00:12:53,016 --> 00:12:56,174
that Pacman, that whole application in a consists

188
00:12:56,222 --> 00:13:00,194
fashion over into my EKS cluster with all of the transformation

189
00:13:00,242 --> 00:13:02,806
that I need to get it over there. So if I now go and look

190
00:13:02,828 --> 00:13:06,802
at that namespace which by magic is now being created,

191
00:13:06,946 --> 00:13:10,550
but also now you can start to see the restore configuration,

192
00:13:10,630 --> 00:13:14,934
you see a deployment for both Pacman and Mongo.

193
00:13:15,062 --> 00:13:18,746
And now if I go and check the services that we have

194
00:13:18,768 --> 00:13:22,426
within there now, this won't be,

195
00:13:22,528 --> 00:13:26,010
but it could have been. I could have decided if this was a migration,

196
00:13:26,090 --> 00:13:30,154
I could decide to change that DNS entry from apps Vzilla

197
00:13:30,202 --> 00:13:33,806
Co. UK, which is going to another

198
00:13:33,988 --> 00:13:37,934
forward facing IP address on the Internet or a DNS IP

199
00:13:37,982 --> 00:13:41,326
on the Internet. Now we're going to go to an AWS

200
00:13:41,438 --> 00:13:45,106
session. You can see up in the top it says AWS. And if I

201
00:13:45,128 --> 00:13:48,646
go into this, so I've restored this now and it's running in eks now.

202
00:13:48,748 --> 00:13:52,658
The most important thing is, do I have them mission critical high scores?

203
00:13:52,754 --> 00:13:56,166
Yes, I do. Everything's in there. All good. And that's exactly what

204
00:13:56,188 --> 00:13:59,414
we wanted to show. So this just highlights a few of those

205
00:13:59,452 --> 00:14:03,046
areas. Yes, backup recovery is super important. It's kind of a table stakes,

206
00:14:03,078 --> 00:14:06,762
but you got to do it in the right way. K ten

207
00:14:06,816 --> 00:14:10,186
lives within the Kubernetes cluster, so it leverages that

208
00:14:10,208 --> 00:14:13,902
API so that we're more efficient to be able to capture these whole

209
00:14:13,956 --> 00:14:17,594
application. You can see there that we've just shown the completed

210
00:14:17,642 --> 00:14:19,760
successful run on that.

211
00:14:20,850 --> 00:14:24,722
Let me jump in. So what we just

212
00:14:24,776 --> 00:14:29,310
spoke about was very much storage within Kubernetes

213
00:14:29,390 --> 00:14:32,814
leveraging persistent volume. Persistent volumes. Persistent volume

214
00:14:32,862 --> 00:14:36,674
claims and can external storage volume. Now this

215
00:14:36,712 --> 00:14:40,134
hasn't always been the case from a Kubernetes point of view. Now this is what

216
00:14:40,172 --> 00:14:43,318
we just did. We had a stateful set. In fact I think it was a

217
00:14:43,324 --> 00:14:47,390
deployment, but it was using a persistent volume claim. A persistent volume

218
00:14:47,570 --> 00:14:49,770
and our external storage volume.

219
00:14:52,670 --> 00:14:56,166
I'll work backwards on this. So we have the container

220
00:14:56,198 --> 00:14:59,462
storage interface. Now the CSI driver

221
00:14:59,526 --> 00:15:02,762
enables all storage vendors to write against

222
00:15:02,816 --> 00:15:07,802
the framework that Kubernetes has developed

223
00:15:07,866 --> 00:15:11,294
or the community have developed, so that we're marrying those

224
00:15:11,332 --> 00:15:15,570
up. So functionality with storage vendor functionality,

225
00:15:15,910 --> 00:15:19,326
which means which is better than the intrigue provisioner

226
00:15:19,358 --> 00:15:23,294
which was waiting for the whole code release every single time Kubernetes

227
00:15:23,342 --> 00:15:26,658
was released. So without going into too much of

228
00:15:26,664 --> 00:15:29,298
this detail, all of these will be available afterwards.

229
00:15:29,474 --> 00:15:32,918
But basically what this means is that whatever the storage vendor that

230
00:15:32,924 --> 00:15:36,422
you're choosing here, it means that we've got the ability to use

231
00:15:36,476 --> 00:15:39,974
that within our Kubernetes environment if

232
00:15:40,012 --> 00:15:43,226
we have that CSI driver compliant way of being able to

233
00:15:43,248 --> 00:15:46,454
leverage that, as well as things like volume snapshot classes,

234
00:15:46,502 --> 00:15:50,314
which is what we're going to use to take a very efficient point

235
00:15:50,352 --> 00:15:54,478
of recovery. I wouldn't say that snapshots are the only point of recovery that we

236
00:15:54,564 --> 00:15:58,302
should have and we should have an export out into object storage or another

237
00:15:58,356 --> 00:16:01,690
storage layer, but it gives us a way of being able to recover

238
00:16:01,770 --> 00:16:05,774
super quick into the live production system

239
00:16:05,892 --> 00:16:09,326
if accidental deletion or something very tiny was

240
00:16:09,348 --> 00:16:13,326
to happen with that failure scenario. Now the next

241
00:16:13,348 --> 00:16:16,662
one that we want to talk about is what if we've got a

242
00:16:16,716 --> 00:16:20,898
data service that is actually running external from the Kubernetes cluster,

243
00:16:20,994 --> 00:16:24,534
but maybe our node JS front end is running in

244
00:16:24,652 --> 00:16:28,646
Kubernetes, but we've had a database server that lives on a

245
00:16:28,668 --> 00:16:32,374
virtual machine, in a cloud virtual machine, or we're leveraging RDS,

246
00:16:32,502 --> 00:16:35,754
how do we get access to that? And we can do that as well

247
00:16:35,792 --> 00:16:39,466
with Kubernetes using config maps and secrets. And what

248
00:16:39,488 --> 00:16:43,502
that allows us to do is marry up the Kubernetes cluster or

249
00:16:43,556 --> 00:16:46,318
use the Kubernetes API to access that,

250
00:16:46,484 --> 00:16:49,902
thus giving our node JS application access

251
00:16:49,956 --> 00:16:53,586
to that database. So we're actually seeing this

252
00:16:53,608 --> 00:16:56,130
quite a lot within the environments.

253
00:17:00,870 --> 00:17:04,514
Okay, so as you can see here, I have the RDS. This is actually

254
00:17:04,552 --> 00:17:08,102
a postgres database within my

255
00:17:08,156 --> 00:17:11,442
RDS cluster. You can see where it's located, et cetera.

256
00:17:11,586 --> 00:17:15,430
So think of this, this is where all my mission critical application

257
00:17:15,580 --> 00:17:19,782
is going to be living. And in our Kubernetes

258
00:17:19,846 --> 00:17:23,466
cluster we have a namespace called RDS app. And if

259
00:17:23,488 --> 00:17:26,730
we then go and take a look inside of that and we have

260
00:17:26,800 --> 00:17:30,862
a config map that is saying how do we

261
00:17:30,916 --> 00:17:34,602
connect our application to our RDS

262
00:17:34,666 --> 00:17:38,480
instance? And we also should have a

263
00:17:39,410 --> 00:17:46,546
secret in there as well which

264
00:17:46,568 --> 00:17:50,014
has given us the DB creds into as you saw on these slide

265
00:17:50,062 --> 00:17:53,620
before. So I've also got

266
00:17:53,990 --> 00:17:57,586
cast and k ten deployed and in here I've already got

267
00:17:57,768 --> 00:18:01,574
a policy created. Now if I hit this run once

268
00:18:01,772 --> 00:18:05,206
and I'll come back to what that looks like shortly. So if we

269
00:18:05,228 --> 00:18:08,966
now go into this, basically what this is doing is we're giving it

270
00:18:08,988 --> 00:18:12,614
a name, we're giving it our comments. If we want to give it a description,

271
00:18:12,742 --> 00:18:16,390
we're saying what we want to do with that, it's an action snapshot.

272
00:18:16,550 --> 00:18:19,738
And we're saying when do we want to run it? So I could have it

273
00:18:19,744 --> 00:18:23,190
on a backup frequency or just have it on demand,

274
00:18:23,350 --> 00:18:27,006
then I'm saying how do I. We can just take a snapshot but then

275
00:18:27,028 --> 00:18:30,394
we can also export that out into a separate location,

276
00:18:30,442 --> 00:18:34,154
an object storage location. In this instance I'm sending it to AWS

277
00:18:34,202 --> 00:18:37,586
S three. And there's a few more options around this. So we get

278
00:18:37,608 --> 00:18:41,154
to choose what application we actually want to use. We can do this

279
00:18:41,192 --> 00:18:44,930
by a namespace or we could do it via labels. And then what

280
00:18:45,000 --> 00:18:48,886
application resources you want to actually specifically capture. Now I

281
00:18:48,908 --> 00:18:52,454
want to just do everything in here. And we also

282
00:18:52,492 --> 00:18:55,746
have something where we dive into the postgres database

283
00:18:55,778 --> 00:18:59,170
or any data service that enables us to coerce that workload

284
00:18:59,250 --> 00:19:03,046
comes that application data so that we've got a consistent copy

285
00:19:03,078 --> 00:19:06,954
of that. So that should be running and

286
00:19:06,992 --> 00:19:09,834
it takes a little bit of time. So I'll probably speed this up.

287
00:19:09,872 --> 00:19:14,030
But if we then go back in here and we do a refresh,

288
00:19:14,690 --> 00:19:18,094
we should start to see that we've got this backing up

289
00:19:18,132 --> 00:19:21,902
status. And then what we'll do is we'll just

290
00:19:22,036 --> 00:19:23,540
wait for this to complete.

291
00:19:25,430 --> 00:19:31,730
And then we've got the ability to use that data to

292
00:19:31,800 --> 00:19:35,926
recover from like we saw in

293
00:19:35,948 --> 00:19:38,710
the previous demo in exactly the same fashion,

294
00:19:59,890 --> 00:20:02,030
this dvd rental database.

295
00:20:02,450 --> 00:20:05,822
And I can actually restore this

296
00:20:05,876 --> 00:20:09,534
into an EKS stateful set. And again

297
00:20:09,572 --> 00:20:13,280
we've got these same database, these that we've recovered into.

298
00:20:14,530 --> 00:20:18,014
But let's just make sure that all of this works. So backup

299
00:20:18,062 --> 00:20:21,540
is initially taking that first snapshot which is here.

300
00:20:21,990 --> 00:20:26,262
And then what we're doing after is we're going to export that out into

301
00:20:26,316 --> 00:20:29,942
our object storage. This is also

302
00:20:29,996 --> 00:20:33,558
currently running in a. So my Kubernetes cluster is

303
00:20:33,564 --> 00:20:36,982
a GKE cluster and we're connecting our application into

304
00:20:37,036 --> 00:20:40,646
RDS. So there's a freedom of choice when

305
00:20:40,668 --> 00:20:44,554
it comes to where you want to run your workloads and where

306
00:20:44,592 --> 00:20:48,058
you want to run your data as well. For that use case where

307
00:20:48,144 --> 00:20:51,754
data doesn't always have to reside in the same location or

308
00:20:51,792 --> 00:20:55,134
in the same platform that your application is, it might be

309
00:20:55,172 --> 00:20:58,286
that you're using kubernetes from a compute point of

310
00:20:58,308 --> 00:21:02,078
view in a certain geo or a certain cloud provider that

311
00:21:02,084 --> 00:21:05,810
you wish, but then you're leveraging something like a PaaS solution as

312
00:21:05,880 --> 00:21:10,180
rds to give the best option

313
00:21:13,590 --> 00:21:14,740
for the data.

314
00:21:21,290 --> 00:21:24,646
Okay, so that's everything complete. And if we go

315
00:21:24,668 --> 00:21:28,234
back into our RDS, we should see that we're now

316
00:21:28,272 --> 00:21:32,250
back to being fully available. Although we didn't take anything offline

317
00:21:32,750 --> 00:21:38,266
and again in postgres we've got the ability to see

318
00:21:38,448 --> 00:21:42,282
that database and these from a

319
00:21:42,336 --> 00:21:46,174
previous restore. We've got that in an eks cluster. Now from

320
00:21:46,212 --> 00:21:49,246
a k ten point of view, if we go back to the dashboard, we go

321
00:21:49,268 --> 00:21:52,858
into our applications, we have several restore

322
00:21:52,954 --> 00:21:56,654
opportunities, either from a snapshot or from the exported

323
00:21:56,702 --> 00:22:00,642
copy where we can say okay, something bad has happened,

324
00:22:00,776 --> 00:22:04,226
I want to restore that. So we can then start to say, okay, I need

325
00:22:04,248 --> 00:22:07,846
to restore this. I want to restore everything that

326
00:22:07,868 --> 00:22:10,870
goes with that back into our environment.

327
00:22:16,810 --> 00:22:20,274
So I think from that point of view, obviously data can reside

328
00:22:20,322 --> 00:22:23,642
anywhere, but you still need to be able to protect that. If you just used

329
00:22:23,696 --> 00:22:26,918
a point solution that was protecting Amazon RDS,

330
00:22:27,094 --> 00:22:30,170
then you wouldn't have any idea about the whole application.

331
00:22:30,320 --> 00:22:33,486
So if you had to maybe capture some

332
00:22:33,508 --> 00:22:36,734
of that dvd rental front end application,

333
00:22:36,932 --> 00:22:40,490
maybe it's not just built of a front end and a back end database.

334
00:22:40,570 --> 00:22:44,334
Maybe there's other microservices that build up of that application.

335
00:22:44,532 --> 00:22:48,306
Maybe there's some sort of metrics and login that we also want to capture in

336
00:22:48,328 --> 00:22:52,834
a consistent fashion. So just capturing that point or that

337
00:22:53,032 --> 00:22:56,946
RDS instance is not going to be enough. And that's kind of the same

338
00:22:57,048 --> 00:23:00,758
ethos as we can protect the potential lun that's coming out of

339
00:23:00,764 --> 00:23:03,414
the storage system and you could just protect that.

340
00:23:03,612 --> 00:23:06,470
Take a NAS backup, do something with that.

341
00:23:06,620 --> 00:23:10,582
But when it comes to restore, what does a restore

342
00:23:10,646 --> 00:23:14,026
look like then I'd rather have everything as an application recover as

343
00:23:14,048 --> 00:23:17,820
an application. And these get granular about how you recover that.

344
00:23:18,190 --> 00:23:22,018
I think another misconception is around that stateful

345
00:23:22,054 --> 00:23:25,466
workloads within Kubernetes are the only ones that need to be protected.

346
00:23:25,578 --> 00:23:29,422
However, I could argue that many of the different

347
00:23:29,476 --> 00:23:33,406
applications that you maybe consider to be a stateless workload

348
00:23:33,518 --> 00:23:37,970
still have some sort of data that you would still like

349
00:23:38,120 --> 00:23:40,974
to retain, whether that be just simply logs,

350
00:23:41,102 --> 00:23:43,780
logs of visualization of those,

351
00:23:44,150 --> 00:23:47,570
but also complex environments being able to protect those.

352
00:23:47,640 --> 00:23:51,522
And if you've got more than 100 or 200 namespaces

353
00:23:51,586 --> 00:23:54,418
full of different applications in your Kubernetes cluster,

354
00:23:54,514 --> 00:23:58,486
that's another use case is yes, you might have the actual source code and

355
00:23:58,588 --> 00:24:02,106
be able to recover very quickly, but what if you don't know which one it

356
00:24:02,128 --> 00:24:05,820
is? And then we've got customers doing the same thing there.

357
00:24:06,670 --> 00:24:09,994
This is me going back to that point, about all of those

358
00:24:10,032 --> 00:24:14,066
different platforms are still available. And when we get to Kubernetes,

359
00:24:14,118 --> 00:24:17,406
there's no shining light, there's no shining green button to say, oh, we don't have

360
00:24:17,428 --> 00:24:21,006
to backup stuff anymore, everything's sorted in kubernetes, they've fixed it

361
00:24:21,028 --> 00:24:25,322
all. That's not the case. We still need to recover failed applications.

362
00:24:25,386 --> 00:24:28,526
There's still accidental deletion, it's still a database

363
00:24:28,558 --> 00:24:32,382
at the end of the day. It still requires that application consistency

364
00:24:32,526 --> 00:24:35,762
so that we can recover that. And more to the point, that data

365
00:24:35,816 --> 00:24:39,286
is still the most important asset probably within your business as well. So we

366
00:24:39,308 --> 00:24:43,094
want to make sure that we're covered so that we can recover from any

367
00:24:43,132 --> 00:24:46,406
of those failure scenarios. Just some of these challenges that we

368
00:24:46,428 --> 00:24:49,926
have protecting these persistent storage complex stateless

369
00:24:50,038 --> 00:24:53,974
environments, protecting individual stateful workloads,

370
00:24:54,022 --> 00:24:57,862
these logs and other areas. Application consistency

371
00:24:57,926 --> 00:25:01,254
is one that I don't have on here, but things like stateless configurations

372
00:25:01,302 --> 00:25:04,606
around load balancing, that IP address that I first mentioned in the

373
00:25:04,628 --> 00:25:07,866
first demo could be a huge savior if you're

374
00:25:07,898 --> 00:25:11,134
having to recover across different geos or

375
00:25:11,172 --> 00:25:14,814
across different cloud. Just making sure that we can update the DNS

376
00:25:14,862 --> 00:25:18,354
as part of that process. I've mentioned

377
00:25:18,392 --> 00:25:22,002
this all the way through. The approach has to be on the application.

378
00:25:22,136 --> 00:25:25,694
Now it says Caston's approach. This should just be any data management.

379
00:25:25,742 --> 00:25:29,602
If you don't use Caston, that's absolutely fine. I mean, we have open source

380
00:25:29,666 --> 00:25:34,006
tool sets as well that look after the application data in

381
00:25:34,028 --> 00:25:38,246
canister, but we need to be looking at the whole application.

382
00:25:38,428 --> 00:25:41,834
So that includes the ingress, the service, the pods, the services,

383
00:25:41,952 --> 00:25:45,574
the stateful, the config maps, the secrets, et cetera.

384
00:25:45,702 --> 00:25:49,354
All of the persistent volumes. It needs to contain all of them

385
00:25:49,392 --> 00:25:51,900
together so that we can recover them all together,

386
00:25:52,910 --> 00:25:56,974
and then the freedom of choice, like wherever kubernetes can pretty

387
00:25:57,012 --> 00:26:00,462
much run anywhere. So we need to be able to protect all of those

388
00:26:00,516 --> 00:26:04,238
different areas, be able to run on all of those. But also

389
00:26:04,324 --> 00:26:08,002
no database is the same. Like we might be running postgres. You saw me running

390
00:26:08,056 --> 00:26:11,970
postgres and MongoDB in this demo. But maybe we're using

391
00:26:12,040 --> 00:26:15,390
elasticsearch for our login and metrics, maybe we're using

392
00:26:15,480 --> 00:26:19,014
different tool sets for other

393
00:26:19,052 --> 00:26:23,110
areas of our data services. So being able to protect all of those across

394
00:26:23,180 --> 00:26:26,626
different distributions and then under different storage

395
00:26:26,738 --> 00:26:30,282
gives us the ability to have that freedom of choice when it comes to that.

396
00:26:30,416 --> 00:26:34,394
And then finally how

397
00:26:34,432 --> 00:26:38,170
to get hands on with casting k ten we have some

398
00:26:38,320 --> 00:26:41,686
lots of learning resources at learning casting IO.

399
00:26:41,798 --> 00:26:44,846
I believe that QR code should take you there. If it doesn't, it will take

400
00:26:44,868 --> 00:26:48,078
you to a hands on lab that is very similar, and that means that you

401
00:26:48,084 --> 00:26:51,966
don't have to go and spin up your own cluster so

402
00:26:51,988 --> 00:26:55,440
that you can get hands on and see what it does.

403
00:26:56,050 --> 00:26:59,630
But yeah, with that, I'd just like to say thank you very much for

404
00:26:59,700 --> 00:27:02,590
sticking with us. Hopefully those demos are useful.

405
00:27:03,250 --> 00:27:07,254
But yeah, please reach out if there's questions at all and

406
00:27:07,452 --> 00:27:09,060
enjoy the show. Thank you.

