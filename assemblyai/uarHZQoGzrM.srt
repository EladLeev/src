1
00:02:08,870 --> 00:02:12,810
Started shoreline to solve the problem of runbook automation.

2
00:02:13,390 --> 00:02:17,082
Deal with the false positives, deal with the simple,

3
00:02:17,136 --> 00:02:20,506
repetitive issues, and make sure that even for

4
00:02:20,528 --> 00:02:23,946
a complex issue, you have all the diagnostics before a

5
00:02:23,968 --> 00:02:27,566
human has to come to the machine to take an

6
00:02:27,588 --> 00:02:31,102
action. It just made so much sense to me. After eight teams

7
00:02:31,156 --> 00:02:33,982
at AWS, there's one big problem,

8
00:02:34,036 --> 00:02:37,314
though. Hardly anyone had runbooks, and even

9
00:02:37,352 --> 00:02:41,266
when they did, they were stale or

10
00:02:41,448 --> 00:02:45,314
they were inconsistent with other things out there.

11
00:02:45,512 --> 00:02:49,494
So what was someone to do? What we did

12
00:02:49,532 --> 00:02:54,002
here at Shoreline is we decided to make it easy to create runbooks,

13
00:02:54,066 --> 00:02:58,774
and that's what we're talking about here today. So about

14
00:02:58,812 --> 00:03:02,150
a year ago, when llms first started becoming popular,

15
00:03:02,230 --> 00:03:05,642
even before Chat GPT took off,

16
00:03:05,776 --> 00:03:08,986
we started working on prompt engineering using

17
00:03:09,088 --> 00:03:13,114
the llms that were available then. And of course, we've made

18
00:03:13,152 --> 00:03:16,922
those yet better over time, both for diagnostics

19
00:03:16,986 --> 00:03:20,542
and for repair. Let's take a look at what that looks

20
00:03:20,596 --> 00:03:23,966
like. So over here you'll see a

21
00:03:24,148 --> 00:03:28,034
top problem report where we're pulling data in

22
00:03:28,072 --> 00:03:31,550
from a ticketing engine. In this case, it's pagerduty.

23
00:03:31,630 --> 00:03:35,278
We do that on a continuous basis and measure

24
00:03:35,454 --> 00:03:39,266
MTTA, MTTR, number of people who are involved in

25
00:03:39,288 --> 00:03:43,640
an incident, how long it took, and the number of times we saw it.

26
00:03:44,010 --> 00:03:47,894
So you might go and say, well, let me work on the things

27
00:03:47,932 --> 00:03:51,590
that have the largest overall aggregate MTTR.

28
00:03:52,110 --> 00:03:55,260
In this case, that's the Apache server being down.

29
00:03:55,790 --> 00:03:59,706
And the way we calculate these groups is that we

30
00:03:59,728 --> 00:04:03,834
apply lightweight clustering algorithms using machine learning to

31
00:04:03,872 --> 00:04:07,498
see what tickets look similar. So for example,

32
00:04:07,584 --> 00:04:11,854
just because there's a hostname in the ticket, it doesn't matter. And then

33
00:04:11,972 --> 00:04:15,422
we also apply some semantic understanding using

34
00:04:15,476 --> 00:04:19,234
an LLM to say, hey, this thing is

35
00:04:19,272 --> 00:04:22,894
talking about a disk being full. This other thing is talking about a persistent

36
00:04:22,942 --> 00:04:26,290
volume claim being full. Those are actually

37
00:04:26,360 --> 00:04:30,514
the same issue, or they can be addressed with the same diagnostics

38
00:04:30,562 --> 00:04:33,910
and repair commands. So let's take

39
00:04:34,060 --> 00:04:37,746
this particular thing about the Apache server being down and generate

40
00:04:37,778 --> 00:04:41,450
a runbook so you can see what's happening is

41
00:04:41,520 --> 00:04:45,738
that second by second it's running,

42
00:04:45,904 --> 00:04:49,782
getting me all the diagnostics to check the status

43
00:04:49,846 --> 00:04:53,526
of the VM, check the logs, see if the deployment

44
00:04:53,558 --> 00:04:57,374
is running, see if the VM itself is accessible, and so

45
00:04:57,412 --> 00:05:01,182
on, and if the necessary ports are open. And then I can also pick

46
00:05:01,236 --> 00:05:04,654
other things. So maybe I want to add a script to

47
00:05:04,692 --> 00:05:08,180
say, hey, did it crash? Should I have to restart it?

48
00:05:08,950 --> 00:05:12,882
And now it's going to take a second or two and

49
00:05:12,936 --> 00:05:15,940
generate that script for me, I hope.

50
00:05:16,550 --> 00:05:20,646
And there we are. So here's a

51
00:05:20,668 --> 00:05:24,674
bash script to do that. You can also add your own diagnostic

52
00:05:24,722 --> 00:05:28,534
prompts here, and you can also add

53
00:05:28,572 --> 00:05:32,570
remediations. Right? So in this case, let me go

54
00:05:32,640 --> 00:05:36,234
and do a restart and get

55
00:05:36,272 --> 00:05:39,498
that in my bash script. There we are.

56
00:05:39,664 --> 00:05:43,510
And so you can run this on kubernetes, you can run it on VMS,

57
00:05:43,590 --> 00:05:46,766
you can run it on Linux or Windows, you can

58
00:05:46,788 --> 00:05:50,174
run it on the three major cloud providers, et cetera. And once

59
00:05:50,212 --> 00:05:53,790
you're happy with it, after adding cards, replacing things,

60
00:05:53,860 --> 00:05:57,070
et cetera, you can export it to markdown,

61
00:05:57,650 --> 00:06:01,166
in this case, maybe a conflux wiki, or you can export

62
00:06:01,198 --> 00:06:04,420
it to shoreline. And we'll talk about that in a.

63
00:06:05,110 --> 00:06:08,770
So one of the problems with llms is

64
00:06:08,840 --> 00:06:12,694
that they can hallucinate. We've all seen that over the last

65
00:06:12,732 --> 00:06:15,766
year. And so one of the things we do here

66
00:06:15,788 --> 00:06:19,346
at Shoreline is that we manually curate the runbooks

67
00:06:19,378 --> 00:06:22,294
that we create or are created by our customers.

68
00:06:22,492 --> 00:06:25,866
We're at about a little over 300 right now,

69
00:06:26,048 --> 00:06:29,446
and I hope to get to about 1000. That doesn't

70
00:06:29,478 --> 00:06:33,634
mean you're going to use all thousand. It means that across the variety

71
00:06:33,702 --> 00:06:35,440
of things that you use,

72
00:06:36,930 --> 00:06:41,310
there's a runbook for you that's been created and

73
00:06:41,460 --> 00:06:45,054
tested out already. So you can start from a

74
00:06:45,092 --> 00:06:49,010
clean place, and you don't have to run into an issue

75
00:06:49,080 --> 00:06:53,202
just to have the repair ready at hand. So, for example, here we're seeing

76
00:06:53,336 --> 00:06:56,546
MongoDB issues. I'm not an expert at

77
00:06:56,568 --> 00:07:00,802
MongoDB, but isn't it nice that we have eleven

78
00:07:00,866 --> 00:07:04,440
things from people who are next?

79
00:07:05,050 --> 00:07:08,994
For me, the core problem with runbooks

80
00:07:09,042 --> 00:07:12,070
is that they don't actually run.

81
00:07:12,220 --> 00:07:15,866
You have to cut and paste into every node that you

82
00:07:15,888 --> 00:07:20,182
want to modify, and that makes it super inefficient.

83
00:07:20,326 --> 00:07:23,666
So wouldn't it be nice if our runbooks were like Jupyter

84
00:07:23,718 --> 00:07:28,320
notebooks and just had both the markdown and the

85
00:07:29,490 --> 00:07:32,814
repair actions right there? So this is

86
00:07:32,852 --> 00:07:36,754
something for an application load balancer that's running into

87
00:07:36,792 --> 00:07:41,186
500 errors. And it's basically saying across

88
00:07:41,288 --> 00:07:44,498
all my hosts, which are running, let's say,

89
00:07:44,664 --> 00:07:48,734
an ALB go and grab

90
00:07:48,782 --> 00:07:52,402
the load balancer names, get their details, describe the ingress

91
00:07:52,466 --> 00:07:56,210
paths, and so on, so forth, and eventually

92
00:07:56,290 --> 00:08:00,354
maybe even do some remediation with a heap dump and a rolling

93
00:08:00,402 --> 00:08:02,940
restart and so on.

94
00:08:04,030 --> 00:08:07,786
Last but certainly not least, once you

95
00:08:07,808 --> 00:08:11,420
have these things in an environment that is

96
00:08:11,950 --> 00:08:15,390
controlled, you can apply fine grained access

97
00:08:15,460 --> 00:08:18,558
control and audit capabilities. So, for example,

98
00:08:18,644 --> 00:08:23,326
this is a notebook run for a

99
00:08:23,348 --> 00:08:26,782
high cpu, and in this case there's a set of actions

100
00:08:26,846 --> 00:08:30,974
we want to do. Make sure we have the right number of bookstore

101
00:08:31,102 --> 00:08:35,300
instances, make sure that the release is correct,

102
00:08:36,230 --> 00:08:39,954
check them for high cpu over a minute so that we

103
00:08:39,992 --> 00:08:43,240
aren't bothering if the issue has already gone away.

104
00:08:44,250 --> 00:08:46,920
Keeping the metrics over time,

105
00:08:47,610 --> 00:08:52,380
listing the top processes using a top command or

106
00:08:52,910 --> 00:08:56,554
the top threads. In this case, I'm going to see that.

107
00:08:56,752 --> 00:09:00,218
Yeah, it's the JVM thread, so I probably have a

108
00:09:00,224 --> 00:09:03,594
JVM issue and I might go and look

109
00:09:03,632 --> 00:09:07,854
at the logs and yeah, it's definitely

110
00:09:07,972 --> 00:09:11,294
running into allocation failures. So let me go and

111
00:09:11,332 --> 00:09:16,030
do a dump and restart, and after

112
00:09:16,100 --> 00:09:19,666
that validate that the issue is gone. And so all

113
00:09:19,688 --> 00:09:23,586
of that was done in the past, but I have all of the data

114
00:09:23,768 --> 00:09:28,740
from an auditability perspective, including what

115
00:09:29,110 --> 00:09:32,230
was returned out of standard out and standard error.

116
00:09:32,730 --> 00:09:36,258
And that's really important. The other using that's important that I'm

117
00:09:36,274 --> 00:09:39,794
not showing here is that you can also apply fine grained

118
00:09:39,842 --> 00:09:43,174
access control. Not just who can run a runbook,

119
00:09:43,302 --> 00:09:47,158
but who can run what actions on which resources

120
00:09:47,334 --> 00:09:51,354
at what time, for example, only when on call or

121
00:09:51,472 --> 00:09:55,046
for the other commands, what sorts of approval workflows

122
00:09:55,078 --> 00:09:58,634
do they want and where should those go, and how do I

123
00:09:58,672 --> 00:10:02,326
integrate all of this with my observability tool of choice,

124
00:10:02,518 --> 00:10:07,262
slack or teams or my incident

125
00:10:07,326 --> 00:10:11,246
management tools or ticketing tools?

126
00:10:11,438 --> 00:10:15,122
So hopefully that gives you a quick flyby over.

127
00:10:15,256 --> 00:10:19,134
I hope you found it interesting. You can always reach out to me at Anurag

128
00:10:19,182 --> 00:10:22,754
at Shawline IO if you want to hear more or have any

129
00:10:22,792 --> 00:10:25,440
questions or feedback. Thank you so much.

