1
00:00:34,610 --> 00:00:38,454
Hello everyone, super happy to be were with

2
00:00:38,492 --> 00:00:42,342
you today to discuss how we can build

3
00:00:42,396 --> 00:00:44,360
things, build software, services,

4
00:00:46,490 --> 00:00:49,966
applications faster, while keeping the security

5
00:00:50,108 --> 00:00:53,246
and safety on top of our mind. First of

6
00:00:53,268 --> 00:00:56,906
all, thanks to Conf 42 cloud native conference

7
00:00:56,938 --> 00:01:00,574
for allowing me to be here with you today. And quick

8
00:01:00,612 --> 00:01:04,574
intro. I am Mohammed, I'm a backend developer

9
00:01:04,702 --> 00:01:08,334
in Spotify and I'm also a Google developer expert

10
00:01:08,382 --> 00:01:13,326
in cloud technologies. And let's

11
00:01:13,358 --> 00:01:16,998
the fun begin. So we all know that

12
00:01:17,084 --> 00:01:20,818
the demand for speed and innovation is basically everywhere.

13
00:01:20,914 --> 00:01:25,270
Users nowadays no longer wants to wait for weeks,

14
00:01:25,420 --> 00:01:28,502
days or even days to get their feature

15
00:01:28,646 --> 00:01:33,114
shipped, to get their buck fixed, to get their new

16
00:01:33,232 --> 00:01:36,060
improvements released. However,

17
00:01:36,910 --> 00:01:40,266
that speed or that innovation or that enthusiasm to

18
00:01:40,288 --> 00:01:43,998
release faster can create conflict sometimes when it's butts up

19
00:01:44,084 --> 00:01:48,506
against security, especially that security sometimes tends

20
00:01:48,538 --> 00:01:52,254
to value status quo. And in some

21
00:01:52,292 --> 00:01:56,114
cases the dutched hand to increase velocity can

22
00:01:56,152 --> 00:02:00,334
introduce sorry new challenges and risks such as skipped

23
00:02:00,382 --> 00:02:04,146
processes, insufficient testing, insufficient security

24
00:02:04,248 --> 00:02:06,230
testing and so on and so forth.

25
00:02:07,290 --> 00:02:10,390
And when you skip testing,

26
00:02:11,050 --> 00:02:14,678
you soon going to hit a roadblock. And we all know

27
00:02:14,764 --> 00:02:18,886
about a company that was bragging how fast they are releasing,

28
00:02:19,078 --> 00:02:23,030
how fast they are innovating. They even made it one of their motives

29
00:02:23,110 --> 00:02:27,606
right? However, soon enough they hit a roadblock.

30
00:02:27,718 --> 00:02:31,520
And that's to say that security is also important.

31
00:02:32,530 --> 00:02:36,414
Definitely speed and velocity is

32
00:02:36,612 --> 00:02:40,554
required and desired. DevOps enable

33
00:02:40,602 --> 00:02:43,070
us to release faster, ship faster,

34
00:02:43,430 --> 00:02:46,926
making sure that both developers and ops are aligned

35
00:02:46,958 --> 00:02:50,674
to once the software is ready, ship it to our users. However,

36
00:02:50,792 --> 00:02:55,670
security is also important because once

37
00:02:55,740 --> 00:02:59,830
you break that confidence that you have,

38
00:02:59,900 --> 00:03:03,542
or that moral relationship with

39
00:03:03,596 --> 00:03:07,094
your customers or clients or

40
00:03:07,132 --> 00:03:10,566
users, once that's broken, it's hard to get back. So that's

41
00:03:10,598 --> 00:03:14,410
why it's also important to keep the data

42
00:03:14,480 --> 00:03:18,326
of your users safe and secure. And that's what devsecops tries

43
00:03:18,358 --> 00:03:21,614
to bring to the table, basically. So devsecops try

44
00:03:21,652 --> 00:03:25,342
to make sure that the developers are doing what they do best,

45
00:03:25,476 --> 00:03:29,082
release software, introduce new features, fix bugs,

46
00:03:29,146 --> 00:03:31,658
improve reliability,

47
00:03:31,754 --> 00:03:36,066
resiliency, and improve the

48
00:03:36,088 --> 00:03:40,206
user experience at a whole. They enable operators

49
00:03:40,238 --> 00:03:44,974
to, once this improvements

50
00:03:45,102 --> 00:03:49,046
or a feature is ready to be deployed, deploy it to

51
00:03:49,068 --> 00:03:53,010
deploy it as fast as possible to the users.

52
00:03:53,090 --> 00:03:56,966
And this is what make dipsycops really important.

53
00:03:57,068 --> 00:04:00,298
Really particular and important is it try to save

54
00:04:00,464 --> 00:04:04,374
a seat in the table to security folks to ensure

55
00:04:04,422 --> 00:04:07,786
that the things that we ship and the software that

56
00:04:07,808 --> 00:04:11,520
we releases are also secure to ensure the safety of our

57
00:04:11,970 --> 00:04:16,030
users or the data of our users. So you'll probably figure

58
00:04:16,100 --> 00:04:19,710
it out what the remainder of the talk

59
00:04:19,780 --> 00:04:23,700
going to be. Obviously, we're going to talk about the Formula One

60
00:04:24,950 --> 00:04:28,782
and quick context.

61
00:04:28,846 --> 00:04:32,194
During the pandemic, was sitting back home, nothing much

62
00:04:32,232 --> 00:04:35,970
to do, was trying to kill some

63
00:04:36,040 --> 00:04:39,206
hours. Usual pandemic thing.

64
00:04:39,308 --> 00:04:43,240
And then I started watching drive to survive. So it's basically,

65
00:04:43,690 --> 00:04:47,334
it's between a documentary and the reality tv show. It's not really

66
00:04:47,372 --> 00:04:51,178
a documentary and not really a reality tv show, but it tells the behind the

67
00:04:51,184 --> 00:04:55,034
scenes of a Formula one weekend of a Formula one race in an

68
00:04:55,072 --> 00:04:58,140
entertaining manner. Netflix way.

69
00:04:59,070 --> 00:05:02,300
And in one of the episodes, this actually happened.

70
00:05:03,070 --> 00:05:06,990
So, Roma, during the Bahrain Grand Prix, Roma is a

71
00:05:07,060 --> 00:05:11,066
has driver. Has is one of the Formula

72
00:05:11,098 --> 00:05:13,940
one teams. Was driving super fast,

73
00:05:14,710 --> 00:05:18,402
160 mph, that's almost 300

74
00:05:18,456 --> 00:05:21,714
km/hour was ripping super fast.

75
00:05:21,832 --> 00:05:25,366
Bad maneuver, probably. He hit another driver and

76
00:05:25,388 --> 00:05:29,042
then hit the barrier and the car turned

77
00:05:29,106 --> 00:05:31,350
instantly into a fireball.

78
00:05:32,330 --> 00:05:36,326
Now, Roma remained there

79
00:05:36,508 --> 00:05:40,394
in the extreme heat, in that fireball for a couple of minutes.

80
00:05:40,512 --> 00:05:43,420
And during that time,

81
00:05:43,950 --> 00:05:46,954
it was interesting to hear the thoughts of the Formula one people.

82
00:05:47,072 --> 00:05:51,082
Because by any standard, in a human standard, this is actually a death

83
00:05:51,146 --> 00:05:54,330
sentence and a severe accident.

84
00:05:54,410 --> 00:05:58,154
And the Formula One folks were also worried.

85
00:05:58,202 --> 00:06:01,486
And a lot of them thought that this is

86
00:06:01,588 --> 00:06:04,946
the end of Roma racing career, or at

87
00:06:04,968 --> 00:06:08,414
least it's going to have a severe

88
00:06:08,462 --> 00:06:11,906
injuries. However, the miracle actually

89
00:06:12,008 --> 00:06:15,598
happened. Roma managed to get out of the car

90
00:06:15,784 --> 00:06:19,394
from the fireball, from the extreme heat,

91
00:06:19,522 --> 00:06:23,686
on his own feet. Sane and safe things is

92
00:06:23,708 --> 00:06:27,978
a miracle. But it got me thinking how

93
00:06:28,064 --> 00:06:32,074
the FIA, which is the entity that oversee the

94
00:06:32,112 --> 00:06:35,190
Formula One industry, or races,

95
00:06:35,350 --> 00:06:39,046
or sport, and the teams

96
00:06:39,078 --> 00:06:40,300
in the Formula one,

97
00:06:42,930 --> 00:06:46,734
value the safety of the drivers. And it got

98
00:06:46,772 --> 00:06:51,018
me thinking, what would happen if we design our systems,

99
00:06:51,114 --> 00:06:54,162
our architecture, our applications in the same

100
00:06:54,216 --> 00:06:58,366
way, with the same level of devotion as the Formula

101
00:06:58,398 --> 00:07:02,194
one folks, design the cars and make regulations and

102
00:07:02,232 --> 00:07:05,570
architecture to make sure that the safety of the driver

103
00:07:05,650 --> 00:07:09,698
is insured at any moment, even in the extreme

104
00:07:09,874 --> 00:07:13,714
accident. Now, throughout the documentary,

105
00:07:13,762 --> 00:07:18,066
they were talking about safest and little to no

106
00:07:18,188 --> 00:07:22,154
mentioning security. And I am not

107
00:07:22,192 --> 00:07:26,026
a native english speaker, so I use them interchangeably. For me,

108
00:07:26,048 --> 00:07:29,866
they are more or less the same. So I opened the

109
00:07:29,888 --> 00:07:33,662
dictionary out of curiosity to find that security actually

110
00:07:33,716 --> 00:07:37,562
means the state of being free from danger or threat.

111
00:07:37,706 --> 00:07:41,326
And that, from a software engineering point of view, is not

112
00:07:41,348 --> 00:07:45,554
what were trying to achieve. Right. We know that once

113
00:07:45,592 --> 00:07:49,700
we put a system facing the Internet, there are handle of things

114
00:07:50,870 --> 00:07:54,514
that are considered as danger and try

115
00:07:54,552 --> 00:07:58,274
to break our application and bring it to its knees.

116
00:07:58,402 --> 00:08:01,922
However, safest means the condition of being protected

117
00:08:01,986 --> 00:08:05,526
from danger, risk or injury. And this is what we are trying to

118
00:08:05,548 --> 00:08:08,970
achieve, right? We know that the production system,

119
00:08:09,040 --> 00:08:12,890
the Internet facing application are not safe. However, we try

120
00:08:12,960 --> 00:08:16,534
to design our system in a safe manner,

121
00:08:16,582 --> 00:08:20,570
in a secure manner, build the whole design architecture,

122
00:08:21,630 --> 00:08:25,866
buy other pieces of software like firewalls

123
00:08:25,978 --> 00:08:29,646
and everything, to make sure that. To make sure things

124
00:08:29,748 --> 00:08:33,598
risky and unsafe environment is actually safe,

125
00:08:33,694 --> 00:08:37,326
and ensure the safety of the data, of our users,

126
00:08:37,438 --> 00:08:40,130
our services and our servers.

127
00:08:41,350 --> 00:08:44,594
And that got me thinking that actually good

128
00:08:44,632 --> 00:08:48,230
architecture should allow people to move

129
00:08:48,300 --> 00:08:51,430
as fast as they can in a safe

130
00:08:51,770 --> 00:08:55,430
manner. So I started a journey to

131
00:08:55,500 --> 00:08:59,234
understand actually the safety regulations, the safety

132
00:08:59,282 --> 00:09:02,966
rules that the Formula one forks follow, to ensure the safety

133
00:09:02,998 --> 00:09:07,174
of the driver, the drivers, and check if there are any similarities, any lessons

134
00:09:07,222 --> 00:09:10,334
that we can take and apply them

135
00:09:10,372 --> 00:09:14,126
in software engineering. And this is actually

136
00:09:14,228 --> 00:09:17,786
what I ended up with, were are more safest

137
00:09:17,818 --> 00:09:21,886
measures that the Formula one people apply. But for

138
00:09:21,908 --> 00:09:25,186
the sake of the time, I will limit myself to

139
00:09:25,208 --> 00:09:29,810
ten. I hope that I can make it. It's going to be challenging, but nevertheless,

140
00:09:30,390 --> 00:09:33,810
there are four, five pre crash measures and five

141
00:09:33,880 --> 00:09:37,702
post crash measures. And the data never

142
00:09:37,756 --> 00:09:40,486
lies, as the saying says, right?

143
00:09:40,668 --> 00:09:44,242
You can see here that as the FIA introduced

144
00:09:44,306 --> 00:09:48,102
more and more regulations to ensure the safety of the drivers throughout the years,

145
00:09:48,156 --> 00:09:51,574
you can see the number of deaths has drastically increased

146
00:09:51,702 --> 00:09:55,594
as well. And if we compare the

147
00:09:55,632 --> 00:10:00,002
number of days between fat and incidents, you can see that as we introduced

148
00:10:00,086 --> 00:10:04,666
more and more safety measures, the racing

149
00:10:04,778 --> 00:10:08,762
in the Formula one is becoming more and more safer,

150
00:10:08,826 --> 00:10:13,474
even if it's still a dangerous sport. But the

151
00:10:13,512 --> 00:10:17,666
regulations actually worked and helped to make the Formula one a

152
00:10:17,688 --> 00:10:21,842
safe sport, even if they are driving at a fast,

153
00:10:21,976 --> 00:10:25,220
super fast speed. Anyway,

154
00:10:26,250 --> 00:10:29,640
let the fun begin for the second time.

155
00:10:30,010 --> 00:10:33,222
So here, the first part, we're going to discuss five

156
00:10:33,276 --> 00:10:36,614
precrash measures, which are basically the things that they

157
00:10:36,652 --> 00:10:40,122
do and insured before the crash, before actually

158
00:10:40,176 --> 00:10:43,686
even the driver get into the car. And to ensure

159
00:10:43,718 --> 00:10:47,510
that the driver safety is ensured,

160
00:10:47,670 --> 00:10:51,354
the first one is the seatbelts that the Formula one drivers

161
00:10:51,402 --> 00:10:55,358
put containing of a

162
00:10:55,524 --> 00:10:59,822
six point harness, which can be released by the driver with

163
00:10:59,876 --> 00:11:03,826
a single hand movement. This is actually what the seatbelt for

164
00:11:03,848 --> 00:11:07,598
the Formula one car look like. It contains

165
00:11:07,614 --> 00:11:10,898
six harness and the driver cannot put it

166
00:11:10,904 --> 00:11:14,610
by himself like he needs help. However,

167
00:11:14,680 --> 00:11:18,838
it can be released by a single push, a single click

168
00:11:18,924 --> 00:11:22,806
and things is, from a software engineering perspective, similar to push to

169
00:11:22,828 --> 00:11:26,760
deploy analogy which

170
00:11:29,950 --> 00:11:33,802
make us think of automation, automation is really important

171
00:11:33,936 --> 00:11:37,034
in ensuring speed and safety as well.

172
00:11:37,152 --> 00:11:40,346
Automation can enable SieM to

173
00:11:40,368 --> 00:11:44,030
deliver greater value by eliminating manual efforts.

174
00:11:44,610 --> 00:11:48,282
Tasks like checking software vulnerabilities

175
00:11:48,346 --> 00:11:53,826
can be handled automatically by

176
00:11:53,848 --> 00:11:57,486
a bot, by a software, but by a job, by a pipeline.

177
00:11:57,598 --> 00:12:01,902
And that would enable to free up teams

178
00:12:02,046 --> 00:12:05,634
to pursue more productive and innovative

179
00:12:05,682 --> 00:12:09,000
pursuit and innovative tasks. Obviously,

180
00:12:09,770 --> 00:12:13,750
automation also can decrease manual human errors,

181
00:12:14,730 --> 00:12:17,902
and that's occur with manual approaches.

182
00:12:18,066 --> 00:12:22,314
We, as we all know, humans do

183
00:12:22,352 --> 00:12:26,294
not excels with manual work. Bots and machines excels

184
00:12:26,342 --> 00:12:31,134
in that. So that can help us to reduce bugs and

185
00:12:31,172 --> 00:12:36,602
reduce errors. So automation

186
00:12:36,666 --> 00:12:40,618
is actually a fundamental part in the defsecops movement and the deficops

187
00:12:40,634 --> 00:12:44,314
mindset. And it enables us to release the software faster,

188
00:12:44,362 --> 00:12:48,670
but also make sure that those softwares are actually secure.

189
00:12:48,830 --> 00:12:52,174
The second thing I want to talk about is stranger, dynamic static

190
00:12:52,222 --> 00:12:55,466
and load test to ensure the safest of the drivers.

191
00:12:55,598 --> 00:13:00,070
And that means that they are testing the car in different conditions.

192
00:13:02,330 --> 00:13:06,086
When the weather is hot, when the

193
00:13:06,108 --> 00:13:10,074
weather is raining, when there is actually

194
00:13:10,272 --> 00:13:13,898
wind, when the track is hot, when the track is a

195
00:13:13,904 --> 00:13:17,578
little bit cold. They are testing different

196
00:13:17,664 --> 00:13:21,374
things, the engine, the aerodynamics, a lot of

197
00:13:21,412 --> 00:13:22,000
things,

198
00:13:25,170 --> 00:13:28,702
to make sure that they have data about the car and how

199
00:13:28,756 --> 00:13:32,394
it actually reacts in different conditions.

200
00:13:32,442 --> 00:13:36,580
To make sure that during the race day, the car, they know

201
00:13:37,670 --> 00:13:40,958
a lot of things about the car that enable them to react

202
00:13:41,054 --> 00:13:44,434
if a crash happened or before even the crash happened.

203
00:13:44,632 --> 00:13:48,930
And for software engineering,

204
00:13:49,010 --> 00:13:53,346
that means that it's

205
00:13:53,378 --> 00:13:56,786
actually the equivalent of having a trusted,

206
00:13:56,898 --> 00:14:00,406
repeatable, and most importantly, adversarial ICD

207
00:14:00,438 --> 00:14:04,054
pipeline enable us to effectively and repeatedly

208
00:14:04,182 --> 00:14:08,570
test any chance to our application at any moment

209
00:14:08,720 --> 00:14:12,126
in time. Making sure that our application go through a

210
00:14:12,148 --> 00:14:16,030
stringent process to understand how it will react

211
00:14:16,530 --> 00:14:19,918
facing different conditions. And those conditions needs to

212
00:14:19,924 --> 00:14:23,314
be the same conditions that our application would need

213
00:14:23,352 --> 00:14:27,602
to be in production, because there is no

214
00:14:27,736 --> 00:14:30,674
place as production. It's the perfect place in the world.

215
00:14:30,792 --> 00:14:34,050
And there is where the fun happened.

216
00:14:34,200 --> 00:14:38,040
And that will not only engage security

217
00:14:38,650 --> 00:14:41,314
through the development and operation processes,

218
00:14:41,442 --> 00:14:45,254
but more specifically will ensure the involvement as

219
00:14:45,292 --> 00:14:49,340
we design things process. And this is actually difficult

220
00:14:49,950 --> 00:14:53,290
at scale and difficults at speed.

221
00:14:54,030 --> 00:14:57,866
Another thing we can do to ensure that we are testing our application

222
00:14:58,048 --> 00:15:02,094
in the same conditions that is going to be in production, is can deployments and

223
00:15:02,132 --> 00:15:06,282
canal deployments is a pattern for rolling out releases to a subset

224
00:15:06,346 --> 00:15:10,094
of users. So the idea here

225
00:15:10,132 --> 00:15:14,718
is basically to deploy the change to a small subset of servers,

226
00:15:14,894 --> 00:15:18,862
test it, have thresholds, both errors,

227
00:15:18,926 --> 00:15:21,700
latency, business errors, if you want to.

228
00:15:22,630 --> 00:15:26,166
And once we hit those thresholds and pass over them,

229
00:15:26,268 --> 00:15:29,810
we basically roll back, because this is not a safe release,

230
00:15:29,890 --> 00:15:33,654
otherwise we release it to all the

231
00:15:33,692 --> 00:15:37,346
users and the Canaro deployment serves

232
00:15:37,378 --> 00:15:41,882
basically as an early warning indicator to

233
00:15:41,936 --> 00:15:45,062
us with less impact or downtime,

234
00:15:45,206 --> 00:15:48,554
which enables, as I mentioned, to test our application

235
00:15:48,752 --> 00:15:52,142
in actually production traffic where the fun is actually

236
00:15:52,196 --> 00:15:55,934
happening. The third thing they do or they have

237
00:15:55,972 --> 00:15:59,966
is the cockpit is surrounded by deformable crash protection structures and

238
00:15:59,988 --> 00:16:04,482
this is how the cockpit looks like. And the thing that

239
00:16:04,616 --> 00:16:08,670
strikes me is that they designed the car around things structure

240
00:16:08,750 --> 00:16:11,662
about this piece of structure,

241
00:16:11,726 --> 00:16:15,542
that its sole purpose in life is

242
00:16:15,596 --> 00:16:19,074
actually or in existence is actually to ensure

243
00:16:19,122 --> 00:16:23,560
the safety of the driver at all time.

244
00:16:24,490 --> 00:16:27,802
And from a software engineer perspective, this is similar

245
00:16:27,856 --> 00:16:30,570
to designing for failure.

246
00:16:30,990 --> 00:16:35,210
And we as developers or it folks

247
00:16:35,870 --> 00:16:39,858
need to think about failure

248
00:16:39,974 --> 00:16:44,158
tolerance when designing our application in basically all

249
00:16:44,244 --> 00:16:49,514
layers. No longer can our application developers

250
00:16:49,562 --> 00:16:52,810
confine themselves to thinking about functionality only.

251
00:16:52,980 --> 00:16:56,546
We must also consider

252
00:16:56,728 --> 00:17:00,658
how to provide functionality in

253
00:17:00,744 --> 00:17:03,810
face of databases, outages,

254
00:17:04,710 --> 00:17:08,520
slow networks or even outages as a whole.

255
00:17:09,770 --> 00:17:13,670
Something that we can do to ensure that is basically enable

256
00:17:14,010 --> 00:17:17,490
mtls. For example, MTLS is mutual TLS,

257
00:17:17,570 --> 00:17:21,330
which basically ensure that both the client and the server are

258
00:17:21,420 --> 00:17:25,078
mutually connected and the traffic between them is encrypted.

259
00:17:25,174 --> 00:17:28,934
And this is important in a microservices architecture

260
00:17:28,982 --> 00:17:32,966
where both services are actually interchangeably

261
00:17:33,078 --> 00:17:36,922
becoming service and client, making sure that

262
00:17:37,056 --> 00:17:40,154
the traffic circulating inside your cluster is encrypted.

263
00:17:40,202 --> 00:17:43,934
So even if an attacker manages to gain access to your cluster has

264
00:17:44,052 --> 00:17:47,474
no clue what is happening, and he would need to do additional work to

265
00:17:47,512 --> 00:17:51,106
gain access. Another thing we can do is

266
00:17:51,128 --> 00:17:55,640
design our application in a micro segmented way. And that means

267
00:17:56,170 --> 00:17:59,640
that we are putting the data

268
00:18:00,650 --> 00:18:04,306
as far away from the Internet as possible, and were

269
00:18:04,338 --> 00:18:08,334
ensuring that we are never exposing

270
00:18:08,482 --> 00:18:12,134
sensitive system data. So even if an attacker

271
00:18:12,182 --> 00:18:16,086
compromises the Internet faces system things, structure deforms

272
00:18:16,118 --> 00:18:20,054
itself and contain itself, and the attacker

273
00:18:20,102 --> 00:18:23,386
will not have the final data and they will have

274
00:18:23,488 --> 00:18:26,734
only access to the Internet service that are

275
00:18:26,772 --> 00:18:30,302
not actually sensitive. And we will

276
00:18:30,356 --> 00:18:34,094
make the work hard for them to gain access to the sensitive

277
00:18:34,142 --> 00:18:37,342
data. Moving on. Before they race,

278
00:18:37,406 --> 00:18:40,754
driver must demonstrate they can get out of the can within 5

279
00:18:40,792 --> 00:18:44,226
seconds. Every drivers cannot get out of the

280
00:18:44,248 --> 00:18:47,474
car before the race under 5 seconds.

281
00:18:47,522 --> 00:18:51,800
Goodbye. They cannot race for the day.

282
00:18:52,970 --> 00:18:56,374
So if you want to race, if you want to go to race, show me

283
00:18:56,412 --> 00:18:59,574
that you can get out of car under 5 seconds. Similar to what would happen

284
00:18:59,612 --> 00:19:03,642
if a crash happened. I want you to get out of that car very

285
00:19:03,776 --> 00:19:07,142
fast. And from a software engineering perspective,

286
00:19:07,286 --> 00:19:11,094
this is similar to, this is not only designing for failures,

287
00:19:11,222 --> 00:19:14,670
this is actually testing for failures, right. It's actually

288
00:19:14,740 --> 00:19:18,362
testing for failures. And a similar discipline in software

289
00:19:18,426 --> 00:19:22,454
engineering is the chaos engineering and chaos engineering.

290
00:19:22,522 --> 00:19:26,766
Very briefly, very briefly, sorry. Is an approach to identify

291
00:19:26,878 --> 00:19:30,130
failures before they become outages.

292
00:19:30,470 --> 00:19:33,890
And we do that by proactively testing how

293
00:19:34,040 --> 00:19:37,654
our system respond and their stress and their errors and

294
00:19:37,692 --> 00:19:40,934
their failures. And while doing that,

295
00:19:40,972 --> 00:19:44,598
we can identify failures before they end up in the news,

296
00:19:44,684 --> 00:19:49,130
basically. And nothing

297
00:19:49,200 --> 00:19:52,810
stop you. I mean, you can start small, right?

298
00:19:52,880 --> 00:19:56,074
You can design the smallest experiments possible. You can

299
00:19:56,112 --> 00:19:59,466
just add in some slowness in your

300
00:19:59,488 --> 00:20:02,714
server, add in some seconds to check how your system react,

301
00:20:02,842 --> 00:20:06,126
and then take notes about what

302
00:20:06,228 --> 00:20:09,582
you did, know what you didn't know, and then make

303
00:20:09,636 --> 00:20:12,266
fixes. And then you can grow gradually,

304
00:20:12,458 --> 00:20:16,018
starting adding errors, such in a database, a whole

305
00:20:16,104 --> 00:20:19,554
instance, a whole region. And then you gain confidence over the

306
00:20:19,592 --> 00:20:23,314
releases of your application. And then

307
00:20:23,352 --> 00:20:27,254
the last part in the pre crush measures is they

308
00:20:27,292 --> 00:20:31,190
have constant monitoring and replacement of the tires.

309
00:20:32,250 --> 00:20:35,814
Look at that things is its

310
00:20:35,852 --> 00:20:39,286
readable team. They held

311
00:20:39,318 --> 00:20:42,470
the world record of the fast replacement of the tires.

312
00:20:42,630 --> 00:20:46,090
Sorry. And look how proud they are,

313
00:20:46,240 --> 00:20:49,686
how happy they are. Not by fixing

314
00:20:49,718 --> 00:20:53,870
the tires, not by trying to patch the tires,

315
00:20:55,330 --> 00:20:58,766
but actually by changing the tires. Why in

316
00:20:58,788 --> 00:21:03,566
the hell we as software engineers brag how

317
00:21:03,668 --> 00:21:06,946
long our servers and containers and instances have

318
00:21:06,968 --> 00:21:11,282
been running. What would happen if we start to challenge that mindset and

319
00:21:11,336 --> 00:21:14,802
start adopting the same attitude as

320
00:21:14,856 --> 00:21:18,226
the pit grows, at the pit grows and changing the

321
00:21:18,248 --> 00:21:22,002
chairs as fast as possible? We all know the pit versus

322
00:21:22,066 --> 00:21:25,766
cattle analogy, right? Which basically means that we should not

323
00:21:25,788 --> 00:21:28,940
treat our service as pits, but more as

324
00:21:30,510 --> 00:21:34,474
cattle. Resources should be sorted as

325
00:21:34,512 --> 00:21:38,314
well and removed as well, and killed and switched it off as well,

326
00:21:38,352 --> 00:21:42,560
whenever necessary, of course. But what will happen if we push this

327
00:21:43,170 --> 00:21:46,810
zoologic analogy to a little bit further?

328
00:21:46,970 --> 00:21:49,230
And introducing chicken analogy.

329
00:21:51,170 --> 00:21:54,910
So the amount of food

330
00:21:54,980 --> 00:21:59,310
and amount of resources a cattle need to raise

331
00:21:59,390 --> 00:22:04,002
to reach adulthood needed is six

332
00:22:04,056 --> 00:22:07,462
weeks, or is more compared to the

333
00:22:07,516 --> 00:22:10,950
chicken, which is fewer resources, obviously.

334
00:22:11,100 --> 00:22:15,074
And the period that it needs for a cattle to reach adulthood

335
00:22:15,122 --> 00:22:18,870
is two years, almost 24 months,

336
00:22:18,940 --> 00:22:22,746
compared to the chicken, which is a couple of weeks. So we are

337
00:22:22,768 --> 00:22:25,958
optimizing if we adopt the chickens analogy.

338
00:22:26,054 --> 00:22:29,850
And the chicken analogy is similar to the container analogy, to be honest

339
00:22:29,920 --> 00:22:33,466
or to be transparent. But there are other metrics

340
00:22:33,498 --> 00:22:37,738
that we can adopt basically to ensure

341
00:22:37,914 --> 00:22:41,600
the security of our system. And for that,

342
00:22:42,930 --> 00:22:46,706
I want to introduce an example. So imagine that you have configured and

343
00:22:46,728 --> 00:22:50,222
secured a production cluster. And on that cluster,

344
00:22:50,286 --> 00:22:54,242
basically, you are running a few mission critic application of

345
00:22:54,296 --> 00:22:57,606
your company. Now, a hacker managed to get access to

346
00:22:57,628 --> 00:23:01,110
your system and

347
00:23:01,180 --> 00:23:05,346
has gated root access of one of the nodes.

348
00:23:05,538 --> 00:23:10,070
Now, that alone is already bad. But the attacker

349
00:23:10,570 --> 00:23:14,554
started to use your node as a base to

350
00:23:14,592 --> 00:23:18,038
attack other nodes on your system. So he managed to hide himself,

351
00:23:18,134 --> 00:23:22,266
and without your knowledge, he started to attack other nodes

352
00:23:22,298 --> 00:23:25,674
and other servers on your cluster.

353
00:23:25,802 --> 00:23:29,374
So imagine now what would happen if this

354
00:23:29,412 --> 00:23:33,490
node is replaced. The attacker will

355
00:23:33,560 --> 00:23:37,474
basically need to do the same process over and over again

356
00:23:37,592 --> 00:23:39,700
to keep his base.

357
00:23:41,110 --> 00:23:45,018
Now imagine that we are repeatedly killing this node

358
00:23:45,134 --> 00:23:48,770
after a certain period of time, let's say one day. So the attacker

359
00:23:48,850 --> 00:23:52,518
will need to repeat the same process each and every

360
00:23:52,684 --> 00:23:56,662
day. So once

361
00:23:56,716 --> 00:24:00,490
the node is actually removed, the hacker

362
00:24:00,910 --> 00:24:05,434
has lost their base and they need to do the same process over again.

363
00:24:05,632 --> 00:24:08,922
That's to say that we can backdoor a system

364
00:24:08,976 --> 00:24:12,270
that is constantly being revaged.

365
00:24:12,690 --> 00:24:15,790
So from a security point of view, this is actually

366
00:24:15,940 --> 00:24:19,806
good. So we have an uptime, we have

367
00:24:19,828 --> 00:24:22,942
a certain amount of period that we define, and then

368
00:24:22,996 --> 00:24:27,086
that after that we basically destroy

369
00:24:27,118 --> 00:24:30,830
that node and replace it with a freshly provisioned node.

370
00:24:30,910 --> 00:24:34,974
And that's what we call the reverse uptime. Now combine that with the base freshness

371
00:24:35,022 --> 00:24:39,026
of your image, which is the image

372
00:24:39,058 --> 00:24:42,726
that we use, which is like imagine the OS or your

373
00:24:42,748 --> 00:24:46,050
container image that we use to deploy all your other images.

374
00:24:46,210 --> 00:24:50,026
From a security point of view, even a zero day vulnerability, you know that the

375
00:24:50,048 --> 00:24:53,546
maximum amount of time to deploy or to

376
00:24:53,568 --> 00:24:56,902
fix all your vulnerabilities is basically the reverse uptime.

377
00:24:57,046 --> 00:25:01,034
So the attacker, that he managed to gain access after

378
00:25:01,072 --> 00:25:04,238
the reverse uptime period, no longer have that access

379
00:25:04,324 --> 00:25:07,726
since we fixed the base image and the vulnerability that

380
00:25:07,748 --> 00:25:11,006
he was using. So those are other metrics that we can keep in mind to

381
00:25:11,028 --> 00:25:13,840
ensure the safety and the security of our system.

382
00:25:14,630 --> 00:25:18,206
I'm running a bit behind time, so I'll be a bit faster.

383
00:25:18,238 --> 00:25:23,300
For the five post crash measures, the things that we do and ensure after

384
00:25:23,670 --> 00:25:27,560
the crash has happened. And the first one is the driver can be

385
00:25:27,930 --> 00:25:32,214
extricated from the car by lifting out the entire seat. So if

386
00:25:32,252 --> 00:25:36,790
the crash happens, we lift, actually the entire seat.

387
00:25:38,430 --> 00:25:42,426
If we cannot get the driver, obviously, and he cannot get out by

388
00:25:42,448 --> 00:25:46,140
himself, we lift up the entire seat and provide him with

389
00:25:47,470 --> 00:25:51,642
any measures necessary to save

390
00:25:51,696 --> 00:25:54,954
his life. And take a look here and

391
00:25:54,992 --> 00:25:58,254
notice that designing the car in a modular way enabled him, in case

392
00:25:58,292 --> 00:26:01,950
of crisis, to lift out the car, lift out the seat, the entire

393
00:26:02,020 --> 00:26:05,486
seat from the car. And this is similar to designing the

394
00:26:05,508 --> 00:26:08,802
car in a moderate way and a less coupled way,

395
00:26:08,856 --> 00:26:13,090
enable you to react in case of crisis and in case of

396
00:26:13,240 --> 00:26:17,058
incidents. And there are a lot of benefits

397
00:26:17,144 --> 00:26:20,486
of having a loosely coupled system, since fewer dependencies that you

398
00:26:20,508 --> 00:26:23,574
need to manage and ensure diversion and make sure that they are up to date

399
00:26:23,612 --> 00:26:25,350
and containing no vulnerability.

400
00:26:28,170 --> 00:26:31,622
There are failure, isolation. If one

401
00:26:31,676 --> 00:26:35,114
node or one service failed, you have that resiliency to

402
00:26:35,152 --> 00:26:38,634
not fail your whole system basically, and keep the other

403
00:26:38,672 --> 00:26:42,334
parts of system up and running and evolvable architecture is a great win

404
00:26:42,372 --> 00:26:46,426
as well. You can evolve your system and architecture independently,

405
00:26:46,538 --> 00:26:50,270
reusing other services with less and few

406
00:26:50,420 --> 00:26:53,710
coupling of your system. The second

407
00:26:53,780 --> 00:26:57,186
thing they have in the postcraft measures is a hands system.

408
00:26:57,288 --> 00:27:01,006
And hands stand for hand and neck system that absorbs

409
00:27:01,038 --> 00:27:04,914
and redistribute forces that would otherwise hit the driver's skull and

410
00:27:04,952 --> 00:27:08,406
neck muscles. And this is how a hands look like. It's basically when there is

411
00:27:08,428 --> 00:27:11,846
an incident. The force generated by these accidents are

412
00:27:12,028 --> 00:27:16,070
gigantic since they are moving super fast. So the hands

413
00:27:16,140 --> 00:27:20,922
make sure to redistribute those forces throughout the body

414
00:27:20,976 --> 00:27:24,758
of the driver that otherwise would basically break his neck.

415
00:27:24,854 --> 00:27:29,034
And this is similar in software engineer to have or design our

416
00:27:29,072 --> 00:27:33,226
system in an elastic way. Making sure that we have a set of patterns

417
00:27:33,258 --> 00:27:37,306
to ensure to build our architecture in an elastic manner,

418
00:27:37,418 --> 00:27:41,082
such as loud balancers when the traffic

419
00:27:41,146 --> 00:27:44,386
increase, if traffic increases and our nodes are not

420
00:27:44,408 --> 00:27:47,474
keeping up, we can have auto scaling to

421
00:27:47,512 --> 00:27:51,314
introduce more nodes. We can have request time threshold if some

422
00:27:51,352 --> 00:27:55,206
of the services are starting to get slow. In some

423
00:27:55,228 --> 00:27:59,542
cases having a degraded performance is better

424
00:27:59,596 --> 00:28:03,206
than having an outage or nothing at all.

425
00:28:03,308 --> 00:28:06,914
And also adopting some anti overload patterns such as circuit

426
00:28:06,962 --> 00:28:13,414
breaking and exponential backup help to alleviate

427
00:28:13,462 --> 00:28:17,274
some of load issues.

428
00:28:17,392 --> 00:28:20,714
Basically another thing they have is

429
00:28:20,752 --> 00:28:24,334
driver suits, our fire resistance, and they

430
00:28:24,372 --> 00:28:27,934
can keep the driver's body under 41

431
00:28:27,972 --> 00:28:31,760
degrees for at least 11 seconds. And this is how our

432
00:28:33,170 --> 00:28:36,734
dear friend Roma managed to stay sane and safe,

433
00:28:36,782 --> 00:28:40,386
because his suit can keep his body under

434
00:28:40,488 --> 00:28:45,490
41 degrees, even if it's in

435
00:28:45,560 --> 00:28:48,758
a fireball in the extreme heat. And from a

436
00:28:48,764 --> 00:28:51,926
security point of view, this is similar to containing the damage and to

437
00:28:51,948 --> 00:28:56,210
containing your attacker.

438
00:28:56,370 --> 00:29:00,186
And there are a couple of security principles that we can be followed to

439
00:29:00,208 --> 00:29:03,622
achieve that. Making sure, like adopting least privileged principle,

440
00:29:03,686 --> 00:29:07,626
making sure that our application services are running with the

441
00:29:07,648 --> 00:29:11,882
minimum set of access rights and resources enable them to perform its function,

442
00:29:12,016 --> 00:29:15,294
defense in depth and having layers, basically. So even

443
00:29:15,332 --> 00:29:18,958
if an attacker manages to breach one layer, we have an additional layer and a

444
00:29:18,964 --> 00:29:22,430
second layer, many layers afterward, that can make

445
00:29:22,500 --> 00:29:26,242
his life harder and slow him down until we figure out what's happening

446
00:29:26,296 --> 00:29:30,100
and fix the vulnerability. Having a zero trust policy

447
00:29:31,430 --> 00:29:35,498
and zero trust mean eliminating implicit trust and continuously

448
00:29:35,614 --> 00:29:39,522
validating every stage of digital

449
00:29:39,666 --> 00:29:43,238
interaction and communication between your services. And it's really important

450
00:29:43,324 --> 00:29:45,560
to have no implicit trust,

451
00:29:46,410 --> 00:29:50,310
but every time requesting authorization

452
00:29:50,390 --> 00:29:54,970
authentication from the calling services or

453
00:29:55,120 --> 00:29:57,180
servers or whatever.

454
00:30:00,050 --> 00:30:04,254
Another thing we can do is basically having

455
00:30:04,372 --> 00:30:08,174
hardware security modules. And an

456
00:30:08,212 --> 00:30:11,566
example would help here to understand what I try to

457
00:30:11,588 --> 00:30:15,154
say. So imagine an attacker managed to get access to

458
00:30:15,192 --> 00:30:18,814
your database or to your server and extract

459
00:30:18,862 --> 00:30:22,050
the data from your database that contains,

460
00:30:22,390 --> 00:30:26,440
let's say passwords of your user now

461
00:30:27,210 --> 00:30:30,758
without your knowledge. So he can take that data,

462
00:30:30,844 --> 00:30:34,310
brute force, it manages to break

463
00:30:34,380 --> 00:30:38,140
it and he would gain access of

464
00:30:39,470 --> 00:30:42,582
plain text of your user's password.

465
00:30:42,646 --> 00:30:46,300
And you will not know until you find those data

466
00:30:47,230 --> 00:30:51,082
in the market, in the dark Internet. And you were basically using

467
00:30:51,136 --> 00:30:54,586
a function to hash your script, you hash user's

468
00:30:54,618 --> 00:30:58,382
password and he managed to break it somehow. Imagine now having

469
00:30:58,436 --> 00:31:02,046
a dedicated entity or a dedicated server that give you

470
00:31:02,068 --> 00:31:06,042
a key with which you hash the password

471
00:31:06,186 --> 00:31:09,886
and you cannot or encrypt

472
00:31:09,918 --> 00:31:13,202
the west and you can decrypt it until you have that key to

473
00:31:13,256 --> 00:31:16,770
ensure like compare it until you have that key.

474
00:31:16,840 --> 00:31:20,562
Now even if an attacker gets this data out of your cluster,

475
00:31:20,626 --> 00:31:24,294
he would be severely limited on the impact he can make,

476
00:31:24,332 --> 00:31:27,914
since he would need to stay within your cluster to get that key in order

477
00:31:27,952 --> 00:31:35,466
to be able to break the data and gain the

478
00:31:35,488 --> 00:31:38,762
password. So we are keeping him in and containing him until

479
00:31:38,816 --> 00:31:43,386
you figure out what's happening. And hopefully that can help you gain some precious

480
00:31:43,578 --> 00:31:46,160
minutes until you figure out what's happening.

481
00:31:48,130 --> 00:31:51,646
Another thing they have is basically a fire suppression system that can

482
00:31:51,668 --> 00:31:55,634
be activated by the driver externally or by

483
00:31:55,672 --> 00:31:59,860
the race marshal. So in case of a fire, the driver can

484
00:32:00,550 --> 00:32:03,310
trigger the system by itself, by himself.

485
00:32:03,390 --> 00:32:06,838
Otherwise the race marshal can trigger it.

486
00:32:06,924 --> 00:32:10,518
And this is the equivalent of having access

487
00:32:10,604 --> 00:32:14,200
policies to your system. There are no right or bad way

488
00:32:15,290 --> 00:32:18,662
define the access policies that you want, both from

489
00:32:18,716 --> 00:32:22,602
communication policies between your service. If a service doesn't need access

490
00:32:22,656 --> 00:32:26,026
to a server, don't give him that access, block him.

491
00:32:26,048 --> 00:32:29,722
Basically each server needs to be allow listed before calling

492
00:32:29,776 --> 00:32:33,178
another service for your users.

493
00:32:33,274 --> 00:32:37,610
Having airbag policies and SaL policies, don't be overly restricted,

494
00:32:37,690 --> 00:32:40,958
but don't be very optimistic as well and

495
00:32:41,044 --> 00:32:44,610
very without any

496
00:32:44,760 --> 00:32:48,226
protection in place. And finally, they have data record

497
00:32:48,408 --> 00:32:52,434
data recorder that keeps data about everything.

498
00:32:52,632 --> 00:32:55,826
I've read that in each race

499
00:32:55,938 --> 00:32:59,302
Formula one people, each car can generate more than

500
00:32:59,356 --> 00:33:03,014
1 data, which is a lot of

501
00:33:03,052 --> 00:33:06,966
data for each race. And that goes to say

502
00:33:06,988 --> 00:33:11,002
that no system should go to production without having monitoring and

503
00:33:11,056 --> 00:33:14,298
logging tools in place, especially security

504
00:33:14,384 --> 00:33:18,214
ones that help you to detect unusual behavior and trigger alarms

505
00:33:18,262 --> 00:33:22,240
and allow you to react in case of issues.

506
00:33:23,250 --> 00:33:26,986
I want to end this presentation by highlighting how comfortable

507
00:33:27,098 --> 00:33:30,554
driving a Formula one car is. Look how the driver

508
00:33:30,602 --> 00:33:34,046
sits in a Formula one car. And it's actually a trade

509
00:33:34,078 --> 00:33:37,460
off between security, between speed and.

510
00:33:37,910 --> 00:33:41,102
Between speed and safety and extraction.

511
00:33:41,166 --> 00:33:44,878
The maximum of the car. And the same thing applies for software

512
00:33:44,974 --> 00:33:47,460
engineering and the way we design our system.

513
00:33:48,070 --> 00:33:52,440
So it's basically a trade off of our

514
00:33:52,810 --> 00:33:55,654
system that we need to make between security,

515
00:33:55,852 --> 00:33:57,910
speed and velocity.

516
00:33:58,990 --> 00:34:02,842
And I want to end this presentation with a scary number. From cost

517
00:34:02,896 --> 00:34:05,510
of data breach by IBM security folks,

518
00:34:05,670 --> 00:34:09,926
they run analysis

519
00:34:09,958 --> 00:34:11,850
and found that in average,

520
00:34:13,410 --> 00:34:16,846
the cost of cyber attack is more than 4 million.

521
00:34:16,948 --> 00:34:20,778
However, it took more than 280 days to detect the breach,

522
00:34:20,954 --> 00:34:24,146
which is a long period of time. So I hope that throughout this

523
00:34:24,168 --> 00:34:27,278
presentation, you discovered some patterns

524
00:34:27,374 --> 00:34:31,140
that would help you to ensure the safety of your system, application,

525
00:34:31,750 --> 00:34:35,086
servers and services while increasing

526
00:34:35,118 --> 00:34:38,518
your velocity and moving fast. Thank you

527
00:34:38,604 --> 00:34:41,734
very much and thank

528
00:34:41,772 --> 00:34:44,882
you to conf 42 cloud. I'm a little bit overtime,

529
00:34:44,946 --> 00:34:48,246
so sorry for that. Happy to take your question. If you have anything,

530
00:34:48,428 --> 00:34:52,658
and I'm pretty available on slack,

531
00:34:52,834 --> 00:34:56,818
those are the resources that helped me to build this presentation.

532
00:34:56,994 --> 00:35:00,638
And yeah, that's pretty much it. Thank you very much

533
00:35:00,724 --> 00:35:04,414
and I hope you're enjoying the talk and wish you a

534
00:35:04,452 --> 00:35:06,542
great conference so far.

