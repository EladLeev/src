1
00:00:25,090 --> 00:00:28,706
It. Last March, with the coronavirus spreading

2
00:00:28,738 --> 00:00:32,246
uncontrollably across the United States, cyber soldiers released their own

3
00:00:32,268 --> 00:00:35,638
contagion by sabotaging a tiny piece of computer code buried in a

4
00:00:35,644 --> 00:00:39,266
popular piece of software called solar winds. The hidden

5
00:00:39,298 --> 00:00:42,466
virus spread to 18,000 government up a secret backdoor

6
00:00:42,498 --> 00:00:44,946
to the 18,000 infected networks.

7
00:00:45,138 --> 00:00:49,030
Microsoft has assigned 500 engineers to dig into the attack.

8
00:00:49,180 --> 00:00:52,974
One compared to a Rembrandt painting. The closer they looked, the more

9
00:00:53,012 --> 00:00:56,334
details emerged. When we analyzed everything that we

10
00:00:56,372 --> 00:00:59,726
saw at Microsoft, we asked ourselves how many engineers have

11
00:00:59,748 --> 00:01:03,520
probably worked on these attacks? And the answer we came to

12
00:01:03,970 --> 00:01:07,506
a new phone or a laptop. You trust that that is secure when they

13
00:01:07,528 --> 00:01:10,866
give it to you. And what they've shown us in this attack is

14
00:01:10,888 --> 00:01:14,754
that is not the case. They have the ability to compromise those

15
00:01:14,792 --> 00:01:17,574
supply chains and manipulate whatever they want,

16
00:01:17,772 --> 00:01:21,606
whether it's financial data, source code, the functionality of

17
00:01:21,628 --> 00:01:25,858
these products, they can take control. The hidden virus spread

18
00:01:25,874 --> 00:01:29,158
to 18,000 government and private computer networks by way of one

19
00:01:29,164 --> 00:01:33,034
of those software updates we all take for granted. The attack was

20
00:01:33,072 --> 00:01:36,326
unprecedented in audacity and scope. Fives went rummaging

21
00:01:36,358 --> 00:01:39,786
through the digital files of the US departments of justice, state,

22
00:01:39,888 --> 00:01:43,642
treasury, energy and commerce, and for nine months had unfettered access

23
00:01:43,696 --> 00:01:48,090
to top level communications, court documents, even nuclear secrets.

24
00:01:48,250 --> 00:01:51,040
And by all accounts, it's still going on.

25
00:01:55,650 --> 00:01:59,106
Hello and welcome here to this video. It's a pleasure for me to see

26
00:01:59,128 --> 00:02:02,610
you here and what we want to talk about today. So today

27
00:02:02,680 --> 00:02:06,466
we want to talk a little bit about how to start with security inside DevOps

28
00:02:06,498 --> 00:02:10,306
environment. What is main or what are the four main areas

29
00:02:10,338 --> 00:02:13,510
of cyber defense and what you can do.

30
00:02:13,580 --> 00:02:17,938
What was leading to this executive order of cybersecurity

31
00:02:18,114 --> 00:02:21,986
and why build info or build metadata

32
00:02:22,098 --> 00:02:25,530
is a very good weapon against cybertext. If you're interested

33
00:02:25,600 --> 00:02:29,146
in this, stay tuned. By the way, my name

34
00:02:29,168 --> 00:02:32,770
is van Robert. I'm developer advocate for JFrog and I'm

35
00:02:32,790 --> 00:02:36,526
mostly running around in the german woods. So far I'm here

36
00:02:36,548 --> 00:02:40,414
on my second day of hiking inside the german woods. I'm taking

37
00:02:40,452 --> 00:02:43,982
you here to two journeys. One is here to the german woods and the second

38
00:02:44,036 --> 00:02:47,026
one is to the cybersecurity. And if you like it,

39
00:02:47,128 --> 00:02:50,354
give me a thumbs up and subscribe my channel. I really would

40
00:02:50,392 --> 00:02:52,942
love to see you as my new subscriber.

41
00:02:53,086 --> 00:02:56,322
So enough around, let's start.

42
00:02:56,456 --> 00:02:59,798
Okay. As a small appetizer in the beginning I want to talk a

43
00:02:59,804 --> 00:03:02,902
little bit about what happened in the short pass. And this

44
00:03:02,956 --> 00:03:06,614
was this solar wins hack because this will show us

45
00:03:06,732 --> 00:03:10,074
the different possibilities or the different angles we have to look

46
00:03:10,112 --> 00:03:14,058
at to see where are the attacks are coming from and

47
00:03:14,144 --> 00:03:17,466
what we can do against these different attack vectors on

48
00:03:17,488 --> 00:03:20,266
our side in our daily developer business.

49
00:03:20,368 --> 00:03:23,998
So, first of all, who solowinds? Solowinds is a company in us,

50
00:03:24,084 --> 00:03:28,142
and they have approximately 300,000 customers. And this is

51
00:03:28,196 --> 00:03:31,774
a regular software company, but they

52
00:03:31,812 --> 00:03:35,534
have a special product. And what the product from SolarWinds?

53
00:03:35,582 --> 00:03:39,202
Well, the product from SolarWinds, what makes so interesting

54
00:03:39,336 --> 00:03:43,662
is that they are producing software to manage network infrastructure.

55
00:03:43,726 --> 00:03:47,782
And managing network infrastructure inside a company is a very critical part,

56
00:03:47,836 --> 00:03:51,430
because you have access to the whole communication part inside a

57
00:03:51,500 --> 00:03:55,046
company, and you can get all the information, you can

58
00:03:55,068 --> 00:03:59,730
redirect information, you can disconnect connections,

59
00:03:59,810 --> 00:04:03,046
and so on and so on. So the network infrastructure

60
00:04:03,078 --> 00:04:06,806
is a very, very critical part. And if you have software that's

61
00:04:06,838 --> 00:04:10,038
managing the network infrastructure, you need very high rights.

62
00:04:10,054 --> 00:04:13,674
So per definition, this is running with administrative rights.

63
00:04:13,802 --> 00:04:17,614
And if you are able to compromise this piece of software, you have

64
00:04:17,652 --> 00:04:20,782
a very, very good possibility to break

65
00:04:20,836 --> 00:04:24,098
into a lot of different subsystems. And this was more or

66
00:04:24,104 --> 00:04:27,922
less the case. But they not try to find

67
00:04:27,976 --> 00:04:31,794
a weak point in this software. They have

68
00:04:31,912 --> 00:04:35,586
done completely different approach. So if it is not

69
00:04:35,608 --> 00:04:38,806
the approach to find a weak point inside some piece of

70
00:04:38,828 --> 00:04:42,358
software, what an attacker could do,

71
00:04:42,524 --> 00:04:46,246
and this is really new here at this story. So we

72
00:04:46,268 --> 00:04:49,450
have so many compromised software already. But there was a special

73
00:04:49,520 --> 00:04:53,034
thing. So the hacker group, a person or

74
00:04:53,072 --> 00:04:56,762
group, you never know. But the attack was

75
00:04:56,816 --> 00:05:00,954
not against this product itself. If it is installed somewhere,

76
00:05:01,082 --> 00:05:05,146
it was against the CI environment inside the SolarWinds

77
00:05:05,178 --> 00:05:08,266
company. So inside the SolarWinds network,

78
00:05:08,458 --> 00:05:11,914
they broke into this one, searched for the CI

79
00:05:11,962 --> 00:05:15,470
environment, and then they manipulated

80
00:05:15,550 --> 00:05:17,700
the CI environment itself.

81
00:05:18,390 --> 00:05:23,170
Why? What they've done is they

82
00:05:23,240 --> 00:05:27,058
search for place inside the CI environment and compromise the

83
00:05:27,064 --> 00:05:30,822
CI environment in a way that with every new build. So with every

84
00:05:30,876 --> 00:05:34,566
binary that was produced, they are

85
00:05:34,588 --> 00:05:38,154
adding some compromised binary to this one, so that

86
00:05:38,272 --> 00:05:42,230
after the build was finished, the regular binary that was produced

87
00:05:42,310 --> 00:05:44,940
is a compromised binary already.

88
00:05:45,710 --> 00:05:48,474
And the functionality. So what happened?

89
00:05:48,512 --> 00:05:52,506
So they manipulate the CI environment. The CI environment

90
00:05:52,698 --> 00:05:56,010
was able to build the next binary. The next binary

91
00:05:56,090 --> 00:06:00,154
was released, and this release was provided

92
00:06:00,282 --> 00:06:04,606
via an automatic update to 300,000 customers.

93
00:06:04,788 --> 00:06:08,974
300,000 customers means that not 300,000 servers

94
00:06:09,102 --> 00:06:12,414
are potentially attacked. No networks,

95
00:06:12,462 --> 00:06:16,214
every network will have a bunch of servers. So we are talking about

96
00:06:16,332 --> 00:06:20,470
300,000 potential networks or network

97
00:06:20,970 --> 00:06:24,102
combinations or compositions that

98
00:06:24,156 --> 00:06:27,506
are attacked by this one. So what happened here?

99
00:06:27,548 --> 00:06:31,766
So they built this compromise binary. They pushed it to this automatic update

100
00:06:31,798 --> 00:06:35,658
stream. And approximately 15,000 to 20,000

101
00:06:35,744 --> 00:06:39,206
customers asked this automatic update to load

102
00:06:39,238 --> 00:06:42,826
this binary to verify it's a binary that's provided for SolarWinds

103
00:06:42,858 --> 00:06:46,750
for sure. And then they installed it and updated their own

104
00:06:46,820 --> 00:06:50,046
installation of this Orion platform. So the product from

105
00:06:50,068 --> 00:06:53,578
SolarWinds, and then the software has done

106
00:06:53,764 --> 00:06:56,894
nothing for two weeks, and then it starts

107
00:06:56,942 --> 00:07:00,574
searching around. So what's going on in the network? And started loading

108
00:07:00,622 --> 00:07:04,642
different binaries from the Internet as well. And with

109
00:07:04,696 --> 00:07:07,902
this, every infection bind SolarWind,

110
00:07:08,046 --> 00:07:11,590
or by the initial Solarwind compromise binary

111
00:07:12,170 --> 00:07:14,630
was a different infection.

112
00:07:15,450 --> 00:07:19,318
Because if you have just one infection and okay, this is

113
00:07:19,324 --> 00:07:22,522
the open door, and you're closing this open door, it's fine. But this

114
00:07:22,576 --> 00:07:26,214
software was so cool that it was grabbing different binaries,

115
00:07:26,342 --> 00:07:29,898
started to install different things inside the network and so on.

116
00:07:29,904 --> 00:07:33,194
So every infection with the SolarWinds hack was completely different.

117
00:07:33,312 --> 00:07:36,538
So if you are removing the original SolarWinds infected binary,

118
00:07:36,634 --> 00:07:40,266
that's just closing the door, but you have a bunch of open windows,

119
00:07:40,378 --> 00:07:44,462
it's a nightmare to get rid of this stuff. Mostly what was necessary,

120
00:07:44,606 --> 00:07:47,982
well, mostly it was necessary to destroy the whole infrastructure

121
00:07:48,046 --> 00:07:51,314
and start from scratch and then make sure that

122
00:07:51,352 --> 00:07:54,802
there is no infected binary somewhere so that all

123
00:07:54,856 --> 00:07:58,582
this stuff could happen again. And then you must be able to

124
00:07:58,636 --> 00:08:01,878
identify this so that's never imported again.

125
00:08:02,044 --> 00:08:05,526
But we have a few different points now from the

126
00:08:05,548 --> 00:08:09,098
solar wins. And we have some reactions because this attack was so

127
00:08:09,184 --> 00:08:11,420
huge and the impact was really,

128
00:08:12,590 --> 00:08:16,294
imagine potentially 300,000 networks infected.

129
00:08:16,342 --> 00:08:19,340
And what are the customers of the solar winds platform,

130
00:08:19,870 --> 00:08:23,146
from the orium platform, us governmental

131
00:08:23,178 --> 00:08:26,746
institutions, healthcare, banks,

132
00:08:26,858 --> 00:08:29,934
military, space, automotive, all these

133
00:08:29,972 --> 00:08:33,346
companies with huge networks, because they need

134
00:08:33,448 --> 00:08:37,122
software to manage this huge network. So this

135
00:08:37,176 --> 00:08:40,370
infection, the solar wins hack, was really a nightmare.

136
00:08:41,190 --> 00:08:45,242
Okay, for sure, this solar wins infection was really a disaster.

137
00:08:45,326 --> 00:08:48,902
And it hits a lot of

138
00:08:48,956 --> 00:08:52,418
governmental institutions as well. So we have different departments.

139
00:08:52,514 --> 00:08:56,118
I don't know if it was defense as well, but it was

140
00:08:56,204 --> 00:08:59,606
definitely infecting a bunch

141
00:08:59,638 --> 00:09:03,420
of different governmental institutions from the US government.

142
00:09:03,870 --> 00:09:07,162
And this was leading to a reaction. And this reaction was called

143
00:09:07,296 --> 00:09:11,106
the executive order of cybersecurity. So I'm not a us citizen,

144
00:09:11,158 --> 00:09:15,182
so if someone told me about there was an executive order,

145
00:09:15,316 --> 00:09:18,382
I had no idea what this means.

146
00:09:18,436 --> 00:09:22,078
So what is an executive order? An executive order is something

147
00:09:22,164 --> 00:09:26,290
that is changing the way the governmental internally works.

148
00:09:26,440 --> 00:09:29,794
It means the US president is able to give

149
00:09:29,832 --> 00:09:33,294
this executive orders. And with this executive

150
00:09:33,342 --> 00:09:36,894
order, okay, let's describe

151
00:09:36,942 --> 00:09:40,278
it like the US president

152
00:09:40,364 --> 00:09:43,990
is like the CEO of a company and inside

153
00:09:44,060 --> 00:09:48,070
this company, I can't change the law from outside.

154
00:09:48,140 --> 00:09:52,090
So tax law or whatever, but inside this

155
00:09:52,160 --> 00:09:55,450
area of the law or all the rules, I can change

156
00:09:55,520 --> 00:09:58,694
the way the company is operating internally so the internal

157
00:09:58,742 --> 00:10:01,926
processes I can completely reconfigure as a CEO.

158
00:10:02,038 --> 00:10:05,726
And this is exactly what a president can do in us with

159
00:10:05,748 --> 00:10:09,262
his executive orders. He can't change law, he can't change the way tax

160
00:10:09,316 --> 00:10:12,666
are calculated or whatever. But what he can do is

161
00:10:12,788 --> 00:10:16,180
he can define changes

162
00:10:17,030 --> 00:10:20,686
of internal processes. So how the it is operating,

163
00:10:20,798 --> 00:10:24,226
how whatever thing is going on. So the internal way

164
00:10:24,248 --> 00:10:27,762
of operation, this could be changed by the US

165
00:10:27,816 --> 00:10:31,986
president. And the US president, Ms. Biden has done it. So there is this executive

166
00:10:32,018 --> 00:10:35,542
order of cybersecurity. Before we are talking about the

167
00:10:35,596 --> 00:10:39,386
content of the executive order of the cybersecurity, we have just in

168
00:10:39,408 --> 00:10:43,466
mind that this is just switching the way the internal it

169
00:10:43,568 --> 00:10:47,820
department is working. And I want to explain a little bit about

170
00:10:49,150 --> 00:10:52,302
the four different main areas you have.

171
00:10:52,436 --> 00:10:56,122
If you're fighting against cyberattacks as a regular developer,

172
00:10:56,186 --> 00:10:59,758
we have possibilities every day. And I want to highlight the

173
00:10:59,844 --> 00:11:03,586
four main areas before I'm talking about the content of

174
00:11:03,608 --> 00:11:07,346
the executive order of cybersecurity and then what we can

175
00:11:07,368 --> 00:11:10,594
do against it. So I spoke about the four

176
00:11:10,632 --> 00:11:14,162
main areas, or tool areas we have

177
00:11:14,216 --> 00:11:18,306
against cybertext. And the first one I want to highlight is zaster

178
00:11:18,338 --> 00:11:21,702
static application security testing. So what does it mean?

179
00:11:21,756 --> 00:11:25,554
Static application security testing means that you are scanning

180
00:11:25,602 --> 00:11:29,254
in a static context all parts of your whole tech

181
00:11:29,292 --> 00:11:32,614
stack. So first of all, it makes no sense to scan

182
00:11:32,662 --> 00:11:36,394
just one layer or one technology. If you want to have really the full

183
00:11:36,432 --> 00:11:39,942
impact of all scanning technologies, you need the possibility

184
00:11:40,006 --> 00:11:43,646
or you need a tool that will give you the knowledge or the information

185
00:11:43,748 --> 00:11:47,262
about the full impact graph. It means really of all tech

186
00:11:47,316 --> 00:11:50,862
layers. So whatever tool you're using, use a tool

187
00:11:50,916 --> 00:11:55,138
that is really able to scan all different technologies, not only one single

188
00:11:55,224 --> 00:11:58,366
technology. So static application security testing,

189
00:11:58,398 --> 00:12:01,646
what does it mean? You're writing some code and then you could scan

190
00:12:01,678 --> 00:12:05,266
your source code. Scanning source code is okay, it's more and

191
00:12:05,288 --> 00:12:09,398
more important all the time. But so far it is

192
00:12:09,484 --> 00:12:13,970
asked on machine learning, pattern matching and all this stuff. The technology is evolving

193
00:12:14,130 --> 00:12:17,560
quite fast, but the results are not really,

194
00:12:18,170 --> 00:12:21,962
they're not so strong so far. So it's too

195
00:12:22,016 --> 00:12:25,354
early to just trust the scan of your source code.

196
00:12:25,472 --> 00:12:28,918
On the other side, the opposite of source code is binaries.

197
00:12:29,014 --> 00:12:32,762
So scanning all binaries is a very robust technique so far,

198
00:12:32,816 --> 00:12:36,478
because, you know, they are binaries. You know the fingerprints, you can identify if they

199
00:12:36,484 --> 00:12:40,078
are compromised, you can identify what kind of infection is inside.

200
00:12:40,244 --> 00:12:44,606
And then if you're looking at all the different pieces inside your tech stack,

201
00:12:44,798 --> 00:12:48,466
I assume that most projects will have 99%

202
00:12:48,568 --> 00:12:50,980
binaries compared to source code.

203
00:12:52,630 --> 00:12:55,826
Well, I will cover this in a few minutes. But so

204
00:12:55,848 --> 00:12:59,682
far as the static application security testing, what does it mean is it's scanning

205
00:12:59,746 --> 00:13:03,270
every single component. The pro

206
00:13:03,420 --> 00:13:06,786
of it is that you can do it immediately. So if you're writing

207
00:13:06,818 --> 00:13:09,766
the first line of code, you can scan all components.

208
00:13:09,878 --> 00:13:14,022
What are all components? Your libraries, your dependencies,

209
00:13:14,086 --> 00:13:16,890
operating system, compiler, tooling,

210
00:13:17,230 --> 00:13:20,620
CI environment and so on. So all this stuff,

211
00:13:25,330 --> 00:13:29,242
the negative part here is that you're missing the dynamic

212
00:13:29,306 --> 00:13:32,586
context of an application. So you can scan configuration files,

213
00:13:32,698 --> 00:13:36,018
but you don't have the dynamic context of this.

214
00:13:36,104 --> 00:13:39,746
And then you don't know what it really means in production later. So you

215
00:13:39,768 --> 00:13:43,058
can guess, but you can't really verify it.

216
00:13:43,144 --> 00:13:46,866
So the static application security can start

217
00:13:46,968 --> 00:13:50,598
very early. You have a bunch of tools, it can scan 100%

218
00:13:50,684 --> 00:13:54,322
of it. You're missing a little bit the dynamic context

219
00:13:54,386 --> 00:13:58,330
of the system, but it's a very robust and fast

220
00:13:58,400 --> 00:14:02,346
technique. The next thing is the

221
00:14:02,368 --> 00:14:06,010
opposite of it, the dynamic application security testing.

222
00:14:06,510 --> 00:14:10,666
So what's dynamic application security testing? Dynamic application security

223
00:14:10,768 --> 00:14:15,242
testing is exactly the opposite of dust, the static application security testing,

224
00:14:15,386 --> 00:14:18,522
because here we are doing this hack approach,

225
00:14:18,586 --> 00:14:22,254
so the application is running already and then we

226
00:14:22,292 --> 00:14:27,230
try to break into the system. So we're looking at this facade.

227
00:14:27,390 --> 00:14:30,882
We have no clue what's internally used, we have no access

228
00:14:30,936 --> 00:14:34,862
to the internal components. We just see what is the API

229
00:14:34,926 --> 00:14:37,240
we can use to attack this system.

230
00:14:38,570 --> 00:14:42,514
Attacking this system means we need some defined attack vectors,

231
00:14:42,562 --> 00:14:46,390
and the most attack vectors are defined based on the most common

232
00:14:46,460 --> 00:14:50,534
vulnerabilities. The most common vulnerabilities are a definition of vulnerabilities

233
00:14:50,582 --> 00:14:54,682
of the most available source or mostly available in web

234
00:14:54,736 --> 00:14:58,342
systems. So it means SQL injection, heap dumps

235
00:14:58,406 --> 00:15:02,074
and so on and so on. So there's a list of

236
00:15:02,112 --> 00:15:05,038
these most common vulnerabilities, 1015, 50,

237
00:15:05,124 --> 00:15:08,398
whatever you want to have. But the main thing is here

238
00:15:08,484 --> 00:15:11,934
you can start with dust earliest if you have something that

239
00:15:11,972 --> 00:15:15,794
is running already, so it's way later inside your

240
00:15:15,832 --> 00:15:19,166
production pipeline or inside your product lifecycle,

241
00:15:19,278 --> 00:15:22,820
because you need something that's running. The next thing is

242
00:15:23,430 --> 00:15:26,718
it's good that you are scanning the dynamic part, but it

243
00:15:26,744 --> 00:15:29,602
makes just sense if it is nearly production.

244
00:15:29,746 --> 00:15:33,266
If you're running dust on a test system, you're missing

245
00:15:33,298 --> 00:15:36,806
all the possibilities to identify if this is for example

246
00:15:36,908 --> 00:15:40,314
a weak configuration. Do you have too many open ports and

247
00:15:40,352 --> 00:15:43,942
all that stuff? So the runtime

248
00:15:44,006 --> 00:15:49,110
of dust, and this is really a bad point, is exponentially,

249
00:15:49,190 --> 00:15:53,120
mostly exponentially. So it's really taking a lot of time

250
00:15:55,650 --> 00:15:59,646
because you need this system running and then you need to really

251
00:15:59,748 --> 00:16:03,120
activate every single attack vector at once.

252
00:16:03,490 --> 00:16:07,122
And the system must be strong enough if you want to use dust against

253
00:16:07,176 --> 00:16:10,786
it. So that's surviving. It's a good and

254
00:16:10,808 --> 00:16:13,966
a bad thing. So you need to test it mostly in production.

255
00:16:13,998 --> 00:16:17,446
But on the other side, if production is surviving, then it's really good.

256
00:16:17,548 --> 00:16:21,302
But the main thing here is that you have

257
00:16:21,356 --> 00:16:24,642
mostly software as a service tool. So cloud providers,

258
00:16:24,706 --> 00:16:28,834
so your application needs via VPN or direct Internet

259
00:16:28,882 --> 00:16:32,338
connection so that you can use this software as a service approach

260
00:16:32,434 --> 00:16:36,362
when they are attacking your system. The whole thing must be installed already,

261
00:16:36,416 --> 00:16:40,620
it must be near as production as possible and then

262
00:16:40,990 --> 00:16:44,654
it will take some time, you will have the feedback. But the

263
00:16:44,692 --> 00:16:48,126
attacks are mostly based on this miscon. Vulnerabilities means if there is

264
00:16:48,148 --> 00:16:53,210
a new attack vector, the tools mostly

265
00:16:53,370 --> 00:16:56,930
not, they are not so easy to configure against

266
00:16:57,000 --> 00:17:00,766
new attack vectors. So it's mostly not possible to define

267
00:17:00,798 --> 00:17:04,082
your own attack vectors with this. There are some different

268
00:17:04,136 --> 00:17:07,934
approaches with this tool so that they try to do with fuzzy logic

269
00:17:07,982 --> 00:17:11,682
or whatever, try to identify new attack vectors, but mostly

270
00:17:11,746 --> 00:17:15,474
they're based on the most common vulnerabilities. If there is a dedicated new attack vector,

271
00:17:15,522 --> 00:17:18,934
it will take some time. I assume that this provider software

272
00:17:18,982 --> 00:17:21,820
will try to update it as fast as possible.

273
00:17:22,430 --> 00:17:26,070
But again, this is quite late in the production.

274
00:17:26,230 --> 00:17:29,158
So we have dust,

275
00:17:29,334 --> 00:17:32,558
static application security testing. We have dynamic application

276
00:17:32,644 --> 00:17:36,014
security testing. Dynamic application security testing, by the way,

277
00:17:36,052 --> 00:17:39,694
is not able to test 100% of your system. It's just able to

278
00:17:39,812 --> 00:17:43,114
test directly the functionality that's provided

279
00:17:43,162 --> 00:17:46,370
outside in indirectly all layers internally.

280
00:17:46,790 --> 00:17:50,322
And what would be the next step? If you have the

281
00:17:50,376 --> 00:17:54,146
static one? If you have the dynamic one, what's the next one? And this is

282
00:17:54,168 --> 00:17:57,910
called IAS interactive application security testing.

283
00:17:58,490 --> 00:18:01,702
The combination of zest and dust is called is

284
00:18:01,836 --> 00:18:06,546
interactive application security testing. And interactive

285
00:18:06,578 --> 00:18:10,182
application security testing means that you are mixing

286
00:18:10,246 --> 00:18:13,898
both approaches and adding new functionalities, like this

287
00:18:13,984 --> 00:18:15,580
interaction part.

288
00:18:17,870 --> 00:18:21,542
It's done during the time. So you have first of all the functionality

289
00:18:21,606 --> 00:18:25,466
of the static application security testing. You have the functionality of the dynamic

290
00:18:25,498 --> 00:18:29,758
application security testing, but in an approach that you can do it inside

291
00:18:29,844 --> 00:18:33,502
your development environment or inside your CI environment,

292
00:18:33,646 --> 00:18:36,994
and it means that you have something like

293
00:18:37,032 --> 00:18:40,658
a security debugger. So you're running this application,

294
00:18:40,824 --> 00:18:44,562
you have access to all components. During the SAS part, you have

295
00:18:44,616 --> 00:18:48,006
the dust part that is running with the miscom vulnerabilities against your

296
00:18:48,028 --> 00:18:52,082
system. You are analyzing during this time, this behavior

297
00:18:52,146 --> 00:18:55,750
of your system, and then you are manually

298
00:18:56,810 --> 00:19:00,182
defining new attack vectors. So you are really doing step

299
00:19:00,236 --> 00:19:03,290
a, doing step b, analyzing what's going on,

300
00:19:03,360 --> 00:19:06,854
try to break into the next layer and so on. So this interactive

301
00:19:06,902 --> 00:19:10,798
part is a very powerful part and the combination of both is

302
00:19:10,884 --> 00:19:15,374
just a logical next point for sure. But if

303
00:19:15,412 --> 00:19:19,038
you want to have an effective, is this interactive application

304
00:19:19,124 --> 00:19:23,330
security testing? You need some developers,

305
00:20:52,200 --> 00:20:55,536
cities are testing, but now we are talking about protection.

306
00:20:55,568 --> 00:20:59,540
So runtime application security protection. The big difference

307
00:20:59,610 --> 00:21:02,992
here is that this approach makes only sense

308
00:21:03,146 --> 00:21:06,952
in production or on production systems. It's an agent like

309
00:21:07,006 --> 00:21:10,520
approach. So you're adding an agent, this agent is adding

310
00:21:11,420 --> 00:21:14,996
something like debug information to your system and then

311
00:21:15,118 --> 00:21:18,872
it's possible to identify an ongoing cyber

312
00:21:18,936 --> 00:21:22,876
attack. So what does it mean? So you

313
00:21:22,898 --> 00:21:26,472
have two possibilities. With this software or this approach,

314
00:21:26,536 --> 00:21:30,620
you have this monitoring approach. It means that you are monitoring

315
00:21:30,700 --> 00:21:34,752
and alerting and you are analyzing all data

316
00:21:34,806 --> 00:21:38,224
flows inside your application in real time. So something is going in,

317
00:21:38,262 --> 00:21:42,080
something's going out, there's user interaction. If the user interaction

318
00:21:42,240 --> 00:21:45,844
pattern is good or bad, or you

319
00:21:45,882 --> 00:21:49,364
should identify something or whatever, so it's really

320
00:21:49,402 --> 00:21:52,484
analyzing this machine learning approaches, what's going on

321
00:21:52,682 --> 00:21:55,940
in the system and try to identify this is an action

322
00:21:56,020 --> 00:22:00,164
that is not good, or there is a cascade of actions

323
00:22:00,212 --> 00:22:03,736
that are not really what's mostly going

324
00:22:03,758 --> 00:22:07,084
on here. And then you have the second possibility, not only

325
00:22:07,122 --> 00:22:10,664
alerting, you have the possibility to switch off automatically.

326
00:22:10,712 --> 00:22:14,348
So the system will identify there is something

327
00:22:14,434 --> 00:22:17,980
like in cyber attack, I will switch off the system now,

328
00:22:18,130 --> 00:22:22,076
and then it's just shutting down. So with this runtime

329
00:22:22,108 --> 00:22:25,088
application security testing, the approach itself is perfect.

330
00:22:25,174 --> 00:22:29,184
So I don't want to say something against the approach, but this approach is just

331
00:22:29,302 --> 00:22:32,976
possible. Inside productions makes just no sense in all earlier

332
00:22:33,008 --> 00:22:36,020
stages. So it's really late inside your production.

333
00:22:37,640 --> 00:22:41,028
And if you are identifying just there,

334
00:22:41,114 --> 00:22:44,388
you have a weak point, then it's quite expensive because you have to

335
00:22:44,394 --> 00:22:47,576
go to the earliest stage in your production and have to do all

336
00:22:47,598 --> 00:22:51,476
this stuff again. The next thing is that if you're

337
00:22:51,508 --> 00:22:55,656
using this rust approach, it's not

338
00:22:55,678 --> 00:22:59,212
a good point to start with security. It's very good.

339
00:22:59,346 --> 00:23:02,956
Add on to security because quite often if you

340
00:23:02,978 --> 00:23:06,344
have developers or users of the system or administrators,

341
00:23:06,472 --> 00:23:10,096
then they say, okay, if there is something not good, this will

342
00:23:10,198 --> 00:23:13,490
catch all of this cyber attacks. And this is

343
00:23:15,060 --> 00:23:18,880
difficult and a dangerous mindset. So you have to be aware of this,

344
00:23:18,950 --> 00:23:22,812
that it could happen, and you have to work against this mindset inside

345
00:23:22,886 --> 00:23:25,808
your environment if you're using rasp tools.

346
00:23:25,904 --> 00:23:29,604
So rasp itself is perfect. But now we are coming more or less

347
00:23:29,642 --> 00:23:33,204
to the point. If you have this four different approaches, what should

348
00:23:33,242 --> 00:23:36,504
be the first approach? If you start with security, what is

349
00:23:36,542 --> 00:23:40,024
the order to introduce different steps of this one?

350
00:23:40,222 --> 00:23:44,372
So we have now this four different ways or these different strategies

351
00:23:44,436 --> 00:23:48,040
against cybertex, known vulnerabilities, unknown vulnerabilities and so on.

352
00:23:48,110 --> 00:23:51,564
So it's now the right time to decide what is the

353
00:23:51,602 --> 00:23:55,356
tool you should focus on or not really the tool, the technique you

354
00:23:55,378 --> 00:23:58,976
should focus on. If you start with the cybersecurity or with

355
00:23:58,998 --> 00:24:02,080
a security topic inside your development chain,

356
00:24:03,540 --> 00:24:07,308
having in mind what happened with the SolarWinds hack. So the SolarWinds hack,

357
00:24:07,404 --> 00:24:11,172
it was a hack against the CI environment. And with that we have two new

358
00:24:11,306 --> 00:24:15,476
dimensions to look at. First of all, you have to protect yourself against

359
00:24:15,578 --> 00:24:18,628
consuming compromised stuff. And on the

360
00:24:18,634 --> 00:24:22,432
other side, you have to protect yourself against distributing

361
00:24:22,576 --> 00:24:26,568
compromised stuff. And this is really the new thing. So the attack

362
00:24:26,654 --> 00:24:30,264
against supply chain, so they searching for multiplayers, they're searching for

363
00:24:30,302 --> 00:24:33,304
weak points inside the supply chain to attack.

364
00:24:33,502 --> 00:24:37,792
Did you ever check your own CI environment against known vulnerabilities?

365
00:24:37,876 --> 00:24:41,884
Have you ever hardened your CI environment? Have you firewalled around your

366
00:24:41,922 --> 00:24:45,708
CI environment? And so on and so on. What's with your agents?

367
00:24:45,794 --> 00:24:49,692
What's with your compiler? Did you ever check if your compiler is not compromised?

368
00:24:49,836 --> 00:24:53,184
So all these different things we need to

369
00:24:53,222 --> 00:24:56,752
have in mind, because we have now attacks against all

370
00:24:56,806 --> 00:24:59,980
components inside the production line or supply chain.

371
00:25:00,140 --> 00:25:03,844
Okay, so if you're new to security, what would be the best

372
00:25:03,882 --> 00:25:07,204
place to start or the best technique to start for this? Having in mind

373
00:25:07,242 --> 00:25:11,552
what you have, first of all, you have this runtime application security protection.

374
00:25:11,696 --> 00:25:14,936
This is definitely not the best place to start or not the

375
00:25:14,958 --> 00:25:18,376
best tool to start because it's in the end of your production line and

376
00:25:18,398 --> 00:25:21,972
it's just identifying active

377
00:25:22,036 --> 00:25:25,672
cyber attacks and then it's just too late. So the next thing is

378
00:25:25,726 --> 00:25:29,388
we have these two main areas, a static application security testing and

379
00:25:29,394 --> 00:25:32,988
this dynamic application security testing. The interactive application

380
00:25:33,074 --> 00:25:35,310
security testing is a mix of both.

381
00:25:37,440 --> 00:25:41,136
The interactive application security testing, okay, means that

382
00:25:41,158 --> 00:25:45,232
you need the knowledge of how to attack a system. I assume that

383
00:25:45,286 --> 00:25:49,024
for this you need dedicated people or you need high skilled or high

384
00:25:49,062 --> 00:25:52,996
trained people to do this. If you don't have them, it makes no sense to

385
00:25:53,018 --> 00:25:57,108
do the interactive application security testing. So if the

386
00:25:57,194 --> 00:26:00,864
last two things that I hear left over is static

387
00:26:00,912 --> 00:26:04,692
application security testing and dynamic application security testing,

388
00:26:04,836 --> 00:26:08,580
my personal approach is always try to identify

389
00:26:08,660 --> 00:26:12,664
as early as possible weak points. It's like quality,

390
00:26:12,782 --> 00:26:16,748
it's like performance, it's like everything. So shift left

391
00:26:16,834 --> 00:26:20,284
with security. Shift left means that you start with security as

392
00:26:20,322 --> 00:26:24,284
early as possible inside your production line. And now

393
00:26:24,402 --> 00:26:28,380
comparing this zest and dust. Dust needs a running

394
00:26:28,450 --> 00:26:31,744
system already and it's not able to look inside your

395
00:26:31,782 --> 00:26:35,532
system. So you don't have the full potential of finding

396
00:26:35,596 --> 00:26:38,844
all known vulnerabilities on the other side. With zest

397
00:26:38,892 --> 00:26:41,956
you have the possibility to start immediately with the

398
00:26:41,978 --> 00:26:45,156
first line of code inside your ide, with a plugin to

399
00:26:45,178 --> 00:26:48,628
get all the knowledge about dependencies and this stuff.

400
00:26:48,794 --> 00:26:52,340
And you can fight against known vulnerabilities immediately.

401
00:26:53,240 --> 00:26:56,596
Having in mind that the amount of known vulnerabilities is way bigger

402
00:26:56,628 --> 00:27:00,232
than the amount of unknown vulnerabilities, it makes sense to focus first

403
00:27:00,286 --> 00:27:04,896
of known vulnerabilities. So what you need, you need a vulnerability database

404
00:27:04,948 --> 00:27:08,940
that is a superset of different vulnerability databases.

405
00:27:09,600 --> 00:27:13,100
The different vulnerability databases must be merged.

406
00:27:13,520 --> 00:27:16,376
So we at JFrog,

407
00:27:16,488 --> 00:27:20,148
we know that whatever vulnerability database you're

408
00:27:20,184 --> 00:27:24,492
choosing, you have just a subset

409
00:27:24,556 --> 00:27:27,984
of vulnerabilities. So we have

410
00:27:28,022 --> 00:27:31,684
this approach of merging different vulnerability databases to build this

411
00:27:31,722 --> 00:27:34,356
superset. Okay, if you have this one,

412
00:27:34,458 --> 00:27:38,116
then identify what is better to focus on,

413
00:27:38,218 --> 00:27:41,616
source code or binaries. Source code is mostly

414
00:27:41,648 --> 00:27:44,488
a tiny part inside your whole application.

415
00:27:44,654 --> 00:27:48,100
If you're comparing in all layers, what is the balance

416
00:27:48,180 --> 00:27:51,688
between binaries and the balance between source code?

417
00:27:51,774 --> 00:27:55,700
You will find that in most systems, the amount of binaries

418
00:27:55,780 --> 00:27:59,596
in the corresponding lines of code are huge compared to

419
00:27:59,618 --> 00:28:02,808
what you're writing by yourself. Inside your application you have a few lines

420
00:28:02,824 --> 00:28:06,296
of code and a bunch of binaries. In the operating system you're

421
00:28:06,328 --> 00:28:10,640
just adding a few configurations, and you have a huge amount of binaries inside

422
00:28:10,710 --> 00:28:13,452
your virtualization environment,

423
00:28:13,596 --> 00:28:17,388
kubernetes environment, and so on and so on. So you have mostly

424
00:28:17,484 --> 00:28:20,704
99% binaries compared to what you're writing by yourself

425
00:28:20,822 --> 00:28:24,500
if you're looking at the whole text. So you need a place where

426
00:28:24,570 --> 00:28:28,516
all binaries of all tech layers are coming together so that

427
00:28:28,538 --> 00:28:32,064
you can have the full impact graphs, knowledge about all layers,

428
00:28:32,112 --> 00:28:35,752
all binaries that are really used and how they're used

429
00:28:35,886 --> 00:28:39,524
together. And if you have this one, then with a knowledge

430
00:28:39,572 --> 00:28:43,290
of known vulnerabilities, you're protecting, again the

431
00:28:44,560 --> 00:28:49,016
biggest part of vulnerabilities, and you're protecting the biggest

432
00:28:49,128 --> 00:28:53,272
part of your whole tech stack against these known vulnerabilities.

433
00:28:53,416 --> 00:28:57,412
So, focusing first on static application security testing,

434
00:28:57,496 --> 00:29:01,116
because you can use tools, you don't need special knowledge

435
00:29:01,148 --> 00:29:05,484
about it. You're not only limited against most common vulnerabilities,

436
00:29:05,612 --> 00:29:09,436
you can use the knowledge of all known vulnerabilities,

437
00:29:09,548 --> 00:29:13,188
and you can do it immediately, even if you're doing it right inside

438
00:29:13,274 --> 00:29:17,364
your ide with some plugins that you're connecting to your security

439
00:29:17,482 --> 00:29:20,384
tool, and that will scan your binaries, your dependencies,

440
00:29:20,432 --> 00:29:23,876
immediately if you are adding them to your bomb. If you know

441
00:29:23,978 --> 00:29:28,052
a little bit more how to do it in a practical way, I would suggest

442
00:29:28,116 --> 00:29:31,672
to look at my YouTube channel. I have a few examples, for example,

443
00:29:31,726 --> 00:29:35,276
how to harden the Vardin stack. It's an open

444
00:29:35,298 --> 00:29:39,416
source project. And I will show you how to find against this polymorph

445
00:29:39,528 --> 00:29:43,916
or this polyglot environments where

446
00:29:43,938 --> 00:29:47,944
you have different technologies that are hidden by different other technologies,

447
00:29:47,992 --> 00:29:51,008
but you want to have the full impact graph and so on. So, have a

448
00:29:51,014 --> 00:29:54,396
look at my YouTube channel. There you will find some talks

449
00:29:54,428 --> 00:29:58,336
about how to use tools, what tools you can use, and what is

450
00:29:58,358 --> 00:30:01,872
the potential of scanning against polyglot environments.

451
00:30:02,016 --> 00:30:05,152
So my recommendation is start with dust.

452
00:30:05,296 --> 00:30:08,160
Then if this is established,

453
00:30:08,320 --> 00:30:12,084
then try to add dust to your test and later

454
00:30:12,122 --> 00:30:16,500
to your production system so that you have this dynamic application security testing.

455
00:30:16,660 --> 00:30:20,596
It depends if you have people that are really skilled

456
00:30:20,628 --> 00:30:23,684
in this area that you can. After this merge,

457
00:30:23,732 --> 00:30:27,530
birch approaches with

458
00:30:27,900 --> 00:30:31,332
two. Two is this interactive application security testing.

459
00:30:31,396 --> 00:30:35,588
But mostly it's start with dust, go over dust,

460
00:30:35,684 --> 00:30:38,908
and then finally at RasP

461
00:30:39,084 --> 00:30:43,056
as well. So yeah, this is more or less

462
00:30:43,238 --> 00:30:46,544
what I recommend, but I'm not the only one

463
00:30:46,582 --> 00:30:50,448
that thought this is a direct and good approach,

464
00:30:50,544 --> 00:30:54,404
because now we are talking about the content of the executive order of

465
00:30:54,442 --> 00:30:57,716
cybersecurity, or the content of the

466
00:30:57,738 --> 00:31:00,884
executive order of cybersecurity. So, Mr.

467
00:31:00,922 --> 00:31:04,408
Biden gave this executive order of cybersecurity. And the content is the

468
00:31:04,414 --> 00:31:08,200
following. So every software that's operated,

469
00:31:08,700 --> 00:31:12,600
used, created by the US government must

470
00:31:12,670 --> 00:31:16,056
fulfill the requirement of creating an

471
00:31:16,238 --> 00:31:18,968
ANS bomb is a software build of material.

472
00:31:19,064 --> 00:31:22,910
That means that all component this software is built

473
00:31:23,520 --> 00:31:27,132
of must be written down in terms

474
00:31:27,186 --> 00:31:30,336
of what is the version, where it's coming from.

475
00:31:30,518 --> 00:31:34,770
So the reference in the repository and fingerprint and

476
00:31:35,620 --> 00:31:41,940
all this stuff. So it means you need really 100% complete

477
00:31:42,090 --> 00:31:45,328
component list of all components of software that they're

478
00:31:45,344 --> 00:31:49,750
creating, that they're using or operating by themselves,

479
00:31:50,680 --> 00:31:54,404
or they're using directly or indirectly. Okay, so what does

480
00:31:54,442 --> 00:31:57,844
it mean? So if they're using something on Amazon, then Amazon,

481
00:31:57,892 --> 00:32:01,796
the whole tech stack must fulfill this S bomb. Otherwise Amazon

482
00:32:01,828 --> 00:32:05,064
is not able to make money with the US government. If you're looking how much

483
00:32:05,102 --> 00:32:08,952
money the US government is spending on software or software operations,

484
00:32:09,096 --> 00:32:13,150
then you will see it will affect immediately not only the US market.

485
00:32:13,520 --> 00:32:17,244
I'm in Europe. Should I take care of this one or should

486
00:32:17,282 --> 00:32:20,440
I be prepared? Well, I'm working for

487
00:32:20,450 --> 00:32:23,904
a company. This company is creating a product. This product is used by

488
00:32:23,942 --> 00:32:27,472
a company that's working for the US government. Right. You're in.

489
00:32:27,526 --> 00:32:31,552
So it is more or less affecting the whole economy

490
00:32:31,696 --> 00:32:36,260
because so many companies are working directly or indirectly

491
00:32:36,760 --> 00:32:40,276
for the US government or producing software that's used by

492
00:32:40,298 --> 00:32:43,572
the US government that over short or long,

493
00:32:43,706 --> 00:32:46,784
everybody will be affected by this one. So what's an SBom?

494
00:32:46,832 --> 00:32:50,948
S bomb is a list of all ingredients

495
00:32:51,124 --> 00:32:55,060
that you need to create the sofa. So it's a full component

496
00:32:55,140 --> 00:32:58,860
or dependency list. But on the other side, this is nothing

497
00:32:58,930 --> 00:33:02,764
new. And if you're looking a little bit around what's available.

498
00:33:02,962 --> 00:33:06,616
And now I want to talk a little bit about the metadata

499
00:33:06,648 --> 00:33:09,552
of build information. Okay.

500
00:33:09,686 --> 00:33:13,024
Metadata of build information or the metadata of a build or

501
00:33:13,142 --> 00:33:16,864
built info. Let's call it build info. So what's built

502
00:33:16,902 --> 00:33:21,376
info? Built info is a context of how to create binaries

503
00:33:21,488 --> 00:33:24,692
and what is content of it.

504
00:33:24,746 --> 00:33:28,340
It's all dependencies. It's a date times

505
00:33:28,490 --> 00:33:32,332
operating system that's used agent name, library versions

506
00:33:32,416 --> 00:33:35,976
and so on and so on, compiler version and so on. So the

507
00:33:35,998 --> 00:33:41,384
build information is something that

508
00:33:41,422 --> 00:33:45,144
is describing the context of how to

509
00:33:45,182 --> 00:33:48,360
create this binary. So if you have the description

510
00:33:48,440 --> 00:33:52,680
of this binary, then it's a superset

511
00:33:52,760 --> 00:33:56,444
of the S bomb. So if you need the S bomb and

512
00:33:56,482 --> 00:34:00,496
you have a possibility to create built info already,

513
00:34:00,678 --> 00:34:05,804
then you have this S bomb. It's just subset

514
00:34:05,852 --> 00:34:09,360
of the information you need. Why you should use built info instead

515
00:34:09,430 --> 00:34:12,816
of pure S bomb? Well, if you want to analyze

516
00:34:12,848 --> 00:34:16,564
if something is attacking you or there was an attack against your systems, you need

517
00:34:16,602 --> 00:34:20,612
a lot of information about the context of how

518
00:34:20,666 --> 00:34:24,356
this binary is created, this compromise binary for example.

519
00:34:24,458 --> 00:34:28,328
And then it's good if you have all this information about what's the agent

520
00:34:28,414 --> 00:34:31,736
name, the operating system version patch level, and so on

521
00:34:31,758 --> 00:34:35,784
and so on. So that you can identify what was a weak point or what

522
00:34:35,822 --> 00:34:39,476
is different at this dedicated area compared

523
00:34:39,508 --> 00:34:42,476
to others, so that they use this for nativ and so on and so on.

524
00:34:42,498 --> 00:34:46,396
So if you want to have something from postmortem analysis, if you want

525
00:34:46,418 --> 00:34:50,496
to have a description, so that you can recreate exactly

526
00:34:50,598 --> 00:34:54,064
the context of some situation. You need the

527
00:34:54,102 --> 00:34:57,612
build info. So if you want to know more, search for the term

528
00:34:57,676 --> 00:35:01,332
build info and you will find information about how

529
00:35:01,386 --> 00:35:05,536
to get all this information with free available tools

530
00:35:05,648 --> 00:35:09,008
so that you can create this build info.

531
00:35:09,104 --> 00:35:12,436
And inside the build info, one dedicated part is

532
00:35:12,458 --> 00:35:15,876
the S bomb as well. What you need to work efficiently

533
00:35:15,908 --> 00:35:19,800
with build info is you need a tool that's representing it in a nice

534
00:35:19,870 --> 00:35:24,228
way. You need the possibility to combine it, for example with vulnerability

535
00:35:24,324 --> 00:35:28,012
databases. So you have here the build information. This is

536
00:35:28,066 --> 00:35:32,636
immutable, you are not changing at any time or

537
00:35:32,818 --> 00:35:36,268
not in the future. And then you need something

538
00:35:36,354 --> 00:35:40,812
that is correlating, for example the actual list of vulnerabilities

539
00:35:40,956 --> 00:35:44,624
with this build information so that you know later we

540
00:35:44,662 --> 00:35:47,904
have an update in vulnerability databases there are

541
00:35:47,942 --> 00:35:51,204
new vulnerabilities. Correlating it to

542
00:35:51,242 --> 00:35:54,710
the build information from binaries that are created already.

543
00:35:55,080 --> 00:35:58,580
Then you see this vulnerability is here

544
00:35:58,650 --> 00:36:02,676
active in this build information that was used or that's part of

545
00:36:02,698 --> 00:36:06,216
the creation of this binary that's running there in production. So you

546
00:36:06,238 --> 00:36:10,200
don't need to scan production, you just need to hold build

547
00:36:10,270 --> 00:36:14,024
info so that you are able to decide what

548
00:36:14,062 --> 00:36:17,716
vulnerabilities are active inside your production environment.

549
00:36:17,828 --> 00:36:21,132
So what you need, you need a place where you're storing all

550
00:36:21,186 --> 00:36:25,356
binaries so that you have the full impact graph. If you have the possibility to

551
00:36:25,378 --> 00:36:28,984
store in one central place all binaries from Docker images of

552
00:36:29,042 --> 00:36:32,640
maven dependencies, debian repositories and all this stuff,

553
00:36:32,790 --> 00:36:36,224
then you can come with vulnerability scanner that is

554
00:36:36,262 --> 00:36:40,156
scanning the whole amount of binaries.

555
00:36:40,348 --> 00:36:43,792
You need a place where you're storing this build info

556
00:36:43,856 --> 00:36:47,396
so that you have the information what was part and so on.

557
00:36:47,498 --> 00:36:51,568
And then you have a whole package against non vulnerabilities.

558
00:36:51,664 --> 00:36:55,628
You have the package against attacks like the solar wins

559
00:36:55,664 --> 00:36:58,984
hack. If you want to get rid of infectious binaries, for example,

560
00:36:59,102 --> 00:37:02,584
because what you need to do is there is a vulnerability and then you

561
00:37:02,622 --> 00:37:06,596
need to know what are the places

562
00:37:06,628 --> 00:37:10,292
where this binary is used. So this jar is used in this web archive,

563
00:37:10,356 --> 00:37:13,864
it's asked in this docker layer, it's used in this docker image

564
00:37:13,992 --> 00:37:17,564
consumed by this helm chart running there in production. So that

565
00:37:17,602 --> 00:37:21,696
is what I mean with a full impact graph. So everything together

566
00:37:21,798 --> 00:37:25,056
about this cybersecurity stuff, we have a

567
00:37:25,078 --> 00:37:28,316
huge amount of attacks, we have no attacks against the supply

568
00:37:28,348 --> 00:37:31,804
chain. Focus first on known vulnerabilities

569
00:37:31,932 --> 00:37:36,148
inside boundaries, because with this you are protecting the biggest part

570
00:37:36,314 --> 00:37:40,176
and it's the fastest way to sort then add the dynamic

571
00:37:40,208 --> 00:37:43,780
application security testing if you're doing this already and maybe

572
00:37:43,850 --> 00:37:48,116
later the runtime application security protection

573
00:37:48,228 --> 00:37:52,184
if you have the possibility and allowance to use agent based

574
00:37:52,222 --> 00:37:55,956
approaches in production. On the other side, how to prepare

575
00:37:55,988 --> 00:37:59,948
for the SBOM well, search for build info and you will see

576
00:38:00,034 --> 00:38:04,460
what tools are available to create this information of

577
00:38:04,610 --> 00:38:07,916
what is used for creating a binary. And then you have the

578
00:38:07,938 --> 00:38:11,900
SBOM already and it's cheap because you can do it for free

579
00:38:11,970 --> 00:38:14,528
and you can do it for your open source project. So if you want to

580
00:38:14,534 --> 00:38:18,000
make sure that your open source project is used or is

581
00:38:18,070 --> 00:38:21,824
able to be used in all environments, start creating S

582
00:38:21,862 --> 00:38:25,876
bombs and then you are safe at this site. So for

583
00:38:25,898 --> 00:38:29,700
this I want to say thank you that you attended this talk

584
00:38:29,770 --> 00:38:33,192
or this video and I hope you got a few new

585
00:38:33,246 --> 00:38:36,472
impressions. If you have more questions about

586
00:38:36,526 --> 00:38:39,368
this one, don't hesitate to contact me.

587
00:38:39,534 --> 00:38:43,192
Twitter, LinkedIn, YouTube and

588
00:38:43,326 --> 00:38:47,000
just don't use email. Don't use email.

589
00:38:47,070 --> 00:38:50,076
This is a disaster. So use everything but please don't use email.

590
00:38:50,178 --> 00:38:53,436
But in the end, if you have any questions, feel free to contact me.

591
00:38:53,458 --> 00:38:57,452
I'm giving free workshops. We can have a discussion on different

592
00:38:57,506 --> 00:39:01,392
social media platforms and so on and then let me know what are you thinking

593
00:39:01,446 --> 00:39:05,296
about it? What's your approach? Do you have any experience with

594
00:39:05,318 --> 00:39:08,736
these approaches already? And let's start a

595
00:39:08,758 --> 00:39:12,150
good discussion about the topic security because this is

596
00:39:12,920 --> 00:39:16,612
a really hot topic. So what I'm doing next?

597
00:39:16,746 --> 00:39:20,016
Well, my day is done. It's the second day of my hiking trip,

598
00:39:20,048 --> 00:39:23,364
so I will now pack my stuff. I have my base camp here

599
00:39:23,482 --> 00:39:27,556
from last night. I will pack it now. Together we'll

600
00:39:27,588 --> 00:39:30,904
have something to eat. We'll walk, I think in this

601
00:39:30,942 --> 00:39:34,056
direction to my car. It will take, I don't know, two 3 hours

602
00:39:34,158 --> 00:39:37,864
and then I'm done for today. And I hope you enjoyed not only the

603
00:39:37,902 --> 00:39:40,876
topic but the environment where I'm here as well.

604
00:39:40,978 --> 00:39:44,492
And if you like to have more of these auto starlight here, related videos

605
00:39:44,546 --> 00:39:48,760
or Java related videos, check out my YouTube channel. I really would appreciate

606
00:39:48,840 --> 00:39:52,204
to have you as my new subscriber. So whatever time you're

607
00:39:52,252 --> 00:39:56,290
watching this, I hope you enjoyed it. Have a good rest of your day

608
00:39:56,740 --> 00:40:00,816
and the only thing I can say thank you very much.

609
00:40:00,918 --> 00:40:11,660
Stay safe and see you're.

