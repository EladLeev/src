1
00:00:17,770 --> 00:00:21,214
Hi, I'm Kevin Scott and I'm excited to talk to youll about

2
00:00:21,252 --> 00:00:24,918
upscalerjs, a new open source tool that I wrote for doing

3
00:00:25,044 --> 00:00:28,278
image upscalerjs in the browser using machine learning.

4
00:00:28,444 --> 00:00:32,306
UpscalerJs is built with tensorflowjs and it lets you upscale

5
00:00:32,338 --> 00:00:35,846
images to two, three, or even four x all in your

6
00:00:35,868 --> 00:00:39,318
browser. In this talk, I'm going to discuss a

7
00:00:39,324 --> 00:00:42,554
little bit about how I built it and how you can start to leverage the

8
00:00:42,592 --> 00:00:45,898
power of neural nets in your apps. I want

9
00:00:45,904 --> 00:00:49,846
to start by outlining a use case that I think is really appropriate

10
00:00:49,878 --> 00:00:53,646
for something like this. This use case is inspired by a situation

11
00:00:53,748 --> 00:00:56,926
I encountered at work. Let's say you're working on

12
00:00:56,948 --> 00:01:00,746
an ecommerce platform. Images are critical for attracting

13
00:01:00,778 --> 00:01:04,354
people to products images sell. It could be real

14
00:01:04,392 --> 00:01:07,966
estate, fashion, software. Almost anything performs

15
00:01:07,998 --> 00:01:11,134
better with images. But if you're dealing with user

16
00:01:11,182 --> 00:01:15,170
generated content, you know how difficult it can be to get high quality imagery.

17
00:01:15,510 --> 00:01:18,754
A lot of the time, you take what you can get, which frankly, is not

18
00:01:18,792 --> 00:01:22,566
much, and you design that site with high quality, beautiful images in

19
00:01:22,588 --> 00:01:25,830
mind, and your design looks great. And then you get to deploying the actual

20
00:01:25,900 --> 00:01:29,302
site and suddenly your users are uploading low quality,

21
00:01:29,436 --> 00:01:33,146
pixelated images. It's not their fault. It's probably all that they

22
00:01:33,168 --> 00:01:36,634
have, but it kills the design. So this actually happened to me.

23
00:01:36,752 --> 00:01:39,894
I was working with a team and we put up a site that was extremely

24
00:01:39,942 --> 00:01:43,774
image dependent. It looked amazing in the designs, but when we

25
00:01:43,812 --> 00:01:47,534
actually got to deploying the site, it fell flat. Without high

26
00:01:47,572 --> 00:01:51,514
quality imagery, the design just didn't work. So what's a nontechnical

27
00:01:51,562 --> 00:01:54,878
solution to this problem? Well, I can tell you, because we do this today,

28
00:01:54,964 --> 00:01:58,910
you go back and you ask for better images, and sometimes people can oblige,

29
00:01:58,990 --> 00:02:02,322
but often they can't. The images they've given you is all they've got.

30
00:02:02,456 --> 00:02:05,934
Maybe it's an image screenshotted from a PDF, or maybe it's

31
00:02:05,982 --> 00:02:09,494
an old image and they can't get a better one. Even if they can

32
00:02:09,532 --> 00:02:12,646
get better images, it's a labor intensive ask of your

33
00:02:12,668 --> 00:02:16,118
users to go back and fix their images for you, even if

34
00:02:16,124 --> 00:02:19,754
it's for their benefit. So what else can we do?

35
00:02:19,952 --> 00:02:23,366
Well, there's a whole realm of research in machine

36
00:02:23,398 --> 00:02:26,986
learning called superresolution. The idea is to

37
00:02:27,008 --> 00:02:30,122
take a low superresolution. It look, well,

38
00:02:30,256 --> 00:02:33,662
higher resolution. Can you enhance it? Can we enhance this?

39
00:02:33,716 --> 00:02:36,826
Can you enhance it? Hold on a second, I'll enhance. If you've watched CSI,

40
00:02:36,858 --> 00:02:39,930
you've probably seen this fake technology in action.

41
00:02:40,090 --> 00:02:43,358
This technology is now real, and though it's not perfect,

42
00:02:43,444 --> 00:02:47,186
it's pretty good and it's getting better. One option is

43
00:02:47,208 --> 00:02:50,706
to apply it on the back end. There's lots of

44
00:02:50,728 --> 00:02:53,410
techniques for doing this, most of them are in python.

45
00:02:53,910 --> 00:02:57,894
Applying this technology on the backend has a number of things going for

46
00:02:57,932 --> 00:03:01,106
it. For one, backend code can benefit

47
00:03:01,138 --> 00:03:04,818
from beefy hardware. This lets you run the most accurate,

48
00:03:04,914 --> 00:03:08,226
most powerful models. If getting the most highly

49
00:03:08,258 --> 00:03:11,580
accurate images is important, this is probably the way to go.

50
00:03:12,190 --> 00:03:15,882
Also, a lot of use cases are you upload once,

51
00:03:15,936 --> 00:03:19,274
you display it often. So processing the images ahead

52
00:03:19,312 --> 00:03:22,714
of time, even if it can take a while in processing time.

53
00:03:22,832 --> 00:03:25,360
It's not a big deal because you only do it once.

54
00:03:26,050 --> 00:03:29,418
But there's two big drawbacks that I see to deploying

55
00:03:29,434 --> 00:03:33,038
this on the back end. One, it takes a lot longer to

56
00:03:33,044 --> 00:03:36,098
get immediate feedback. If I'm a user of your site,

57
00:03:36,184 --> 00:03:39,854
I upload an image, it has to go to your server, get processed

58
00:03:39,902 --> 00:03:42,740
there, and then get sent back down to my computer.

59
00:03:43,270 --> 00:03:46,770
There's also the issue of deployment. This can be nontrivial,

60
00:03:46,850 --> 00:03:50,326
especially because so many cutting edge implementations are at

61
00:03:50,348 --> 00:03:54,310
the bleeding edge, with unstable dependencies and changing requirements.

62
00:03:54,890 --> 00:03:57,954
And if your deployment requires gpus,

63
00:03:58,082 --> 00:04:02,250
that could end up being can expensive proposition as well, and hard to scale.

64
00:04:03,070 --> 00:04:06,940
So what about deploying this on the front end? Would that work?

65
00:04:07,470 --> 00:04:11,542
The issues with deploying this on the back end motivated me to explore

66
00:04:11,606 --> 00:04:14,878
whether it'd be feasible to perform upscaling in the

67
00:04:14,884 --> 00:04:19,066
browser using JavaScript. And it turns out that it is. And I'll

68
00:04:19,098 --> 00:04:22,734
discuss some of the technical hurdles and the code in a minute. But first,

69
00:04:22,852 --> 00:04:26,770
let's talk about the advantage of running this technology in JavaScript.

70
00:04:27,270 --> 00:04:30,686
First, that issue of deployment from the previous slide

71
00:04:30,798 --> 00:04:34,206
is gone. Running it in JavaScript means relying

72
00:04:34,238 --> 00:04:38,022
on your user's browser. There's no gpu to provision or keep running.

73
00:04:38,156 --> 00:04:41,846
It all happens on your user's computer, and in fact you

74
00:04:41,868 --> 00:04:45,702
can go to this link right now and upscale can image without

75
00:04:45,756 --> 00:04:49,062
installing anything, not installing anything.

76
00:04:49,196 --> 00:04:52,486
That's a really powerful argument, particularly if you don't have any machine

77
00:04:52,518 --> 00:04:56,262
learning experts on your team. The second big argument

78
00:04:56,326 --> 00:04:59,546
is immediacy. In the back end example, whenever a

79
00:04:59,568 --> 00:05:03,034
user uploads an image, they have to wait for the round trip experience.

80
00:05:03,152 --> 00:05:06,586
They have to upload it to your servers, get it processed,

81
00:05:06,778 --> 00:05:10,026
which depending on your technology, a server might need to be provisioned,

82
00:05:10,058 --> 00:05:13,306
or you may need to wait for a gpu or a lambda spun

83
00:05:13,338 --> 00:05:16,994
up, or any number of other technical issues before you send it back

84
00:05:17,032 --> 00:05:20,334
down the pipe to their computer. If you do it in JavaScript,

85
00:05:20,382 --> 00:05:23,874
it's already there in your browser. No waiting around. It only

86
00:05:23,912 --> 00:05:26,390
takes as long as it takes to do the inference.

87
00:05:27,450 --> 00:05:30,966
The third, and in my mind most compelling argument for

88
00:05:30,988 --> 00:05:33,938
doing this in your browser is bandwidth savings.

89
00:05:34,114 --> 00:05:37,686
In the back end example, we can upscale images ahead of

90
00:05:37,708 --> 00:05:42,230
time, but the image we're sending down is still the full superresolution.

91
00:05:42,390 --> 00:05:45,980
It could be a megabyte or multiple megabytes large.

92
00:05:46,750 --> 00:05:50,130
If you do it on the front end, you can send a smaller image,

93
00:05:50,230 --> 00:05:54,206
sometimes a much smaller image. That's huge. Let's say

94
00:05:54,228 --> 00:05:57,786
you're doing four x scaling. That's an image that is potentially

95
00:05:57,978 --> 00:06:00,320
16 times less file size.

96
00:06:01,330 --> 00:06:04,814
That's a huge file savings. But that's only assuming

97
00:06:04,862 --> 00:06:08,386
that, one, the front end can perform decently fast, and two,

98
00:06:08,488 --> 00:06:11,220
that the image that we upscale looks good.

99
00:06:11,670 --> 00:06:15,538
Can we depend on that? Turns out that mostly we can,

100
00:06:15,624 --> 00:06:19,094
and where we can't, things are getting better. So now, of course,

101
00:06:19,132 --> 00:06:21,960
there are some drawbacks to doing this on the front end.

102
00:06:22,330 --> 00:06:26,150
One drawback is that if you do have those coveted machine learning

103
00:06:26,220 --> 00:06:30,266
experts on your team and those capabilities, front end performance could

104
00:06:30,288 --> 00:06:33,382
be worse, particularly if bandwidth is not a concern.

105
00:06:33,526 --> 00:06:37,286
Maybe your users primarily use desktops, then keeping

106
00:06:37,318 --> 00:06:41,206
things on the back end will probably perform better, and doing so

107
00:06:41,248 --> 00:06:44,862
gives you access to all the latest cutting edge techniques that might not

108
00:06:44,916 --> 00:06:48,574
translate yet to the browser. The second big

109
00:06:48,612 --> 00:06:52,454
concern is that neural networks running on devices benefit

110
00:06:52,522 --> 00:06:54,930
significantly from cutting edge hardware.

111
00:06:55,910 --> 00:06:59,634
The good news here is that consumer companies, namely Apple and Google,

112
00:06:59,752 --> 00:07:03,474
have invested huge sums in increasing the power of their

113
00:07:03,512 --> 00:07:07,266
devices hardware, specifically the ability to process neural networks

114
00:07:07,298 --> 00:07:10,230
on device, what's also known as edge AI.

115
00:07:11,290 --> 00:07:14,502
The downside is that because the improvements are so

116
00:07:14,556 --> 00:07:18,630
significant year after year, it makes the disparity for users running

117
00:07:18,700 --> 00:07:22,086
older devices that much more significant. Some older

118
00:07:22,118 --> 00:07:25,738
devices will just be awful. So if you want a consistent experience,

119
00:07:25,824 --> 00:07:29,414
youll may want to look at superresolution. So while there's

120
00:07:29,462 --> 00:07:33,214
absolutely tradeoffs to be made between back end and front end,

121
00:07:33,412 --> 00:07:37,386
the point is that JavaScript is absolutely a first class citizen

122
00:07:37,418 --> 00:07:40,910
when it comes to applications of machine learning and neural networks.

123
00:07:41,330 --> 00:07:44,706
No longer are you forced into some heavy duty back end

124
00:07:44,728 --> 00:07:47,410
solution. You can run this technology right now,

125
00:07:47,480 --> 00:07:51,346
today in your browser, and in this case in

126
00:07:51,368 --> 00:07:55,086
particular, doing it client side can be a much better choice

127
00:07:55,118 --> 00:07:58,754
than keeping things on the back end. Now, if you're a JavaScript

128
00:07:58,802 --> 00:08:01,510
developer and you're ensconced in the world of JavaScript,

129
00:08:01,930 --> 00:08:05,702
maybe you're wondering how you go about hearing about new machine learning

130
00:08:05,756 --> 00:08:08,946
technologies, how you know whether they're

131
00:08:08,978 --> 00:08:12,234
applicable to your work or whether you can use it. How would you even know

132
00:08:12,272 --> 00:08:15,594
super resolution is a thing unless you happen to see it on

133
00:08:15,632 --> 00:08:19,494
that CSI video? Hold on a second, I'll enhance so I want to briefly

134
00:08:19,542 --> 00:08:23,454
touch on how I became familiar with this research and how you

135
00:08:23,492 --> 00:08:27,322
might leverage a similar strategy to learn about opportunities

136
00:08:27,386 --> 00:08:31,294
that might be relevant to you. The first thing to know is that almost all

137
00:08:31,332 --> 00:08:34,674
machine learning research gets posted publicly and is

138
00:08:34,712 --> 00:08:38,180
accessible for free. This is academic research

139
00:08:38,710 --> 00:08:42,450
papers that can tend to be theory and math heavy and

140
00:08:42,600 --> 00:08:45,858
sometimes pretty hard to penetrate. And this can scare off a lot of

141
00:08:45,864 --> 00:08:49,686
people. It certainly scared me off at first. I don't want to minimize the

142
00:08:49,708 --> 00:08:53,026
importance of fully understanding the research. If you have a deep

143
00:08:53,058 --> 00:08:56,722
understanding of the theory, that can often lead you to novel insights

144
00:08:56,866 --> 00:08:59,740
and new development that's relevant to your field.

145
00:09:00,190 --> 00:09:03,594
But youll don't necessarily need a

146
00:09:03,632 --> 00:09:07,146
full understanding of the technology to use it in your work,

147
00:09:07,328 --> 00:09:11,146
particularly if you're focused on implementing prebuilt models like

148
00:09:11,168 --> 00:09:15,166
we are here, you can rely on others to evaluate the research as

149
00:09:15,188 --> 00:09:17,920
well as implement a lot of the code. For you.

150
00:09:18,610 --> 00:09:21,742
I like to rely on a website called papers with

151
00:09:21,796 --> 00:09:25,202
code. This website lists cutting edge research

152
00:09:25,336 --> 00:09:29,358
organized by topic. You can see the latest papers measured

153
00:09:29,374 --> 00:09:32,910
against metrics. You can also see available code implementations,

154
00:09:32,990 --> 00:09:36,518
as well as information about the frameworks that they're using. In our

155
00:09:36,604 --> 00:09:40,022
specific example, super resolution, there's actually a whole

156
00:09:40,076 --> 00:09:43,970
category dedicated to that research, and we can see the various implementations

157
00:09:44,050 --> 00:09:47,282
wanted. Metrics are a tricky thing

158
00:09:47,436 --> 00:09:51,450
for something like superresolution. Most common metrics are two,

159
00:09:51,520 --> 00:09:55,114
called PsNR or ssIm. They're both

160
00:09:55,152 --> 00:09:58,940
measurements of how different one image is from another.

161
00:09:59,710 --> 00:10:03,310
But as humans, we perceive images differently than a computer does.

162
00:10:03,380 --> 00:10:06,942
A set of pixels that are, say, less saturated but maybe

163
00:10:06,996 --> 00:10:11,086
sharper. That may lead to a lower metric score by

164
00:10:11,108 --> 00:10:14,580
the computer, but a more aesthetically pleasing score for a human.

165
00:10:15,110 --> 00:10:18,690
And this is not just a theoretical concern. At a certain

166
00:10:18,760 --> 00:10:22,434
point, people rate more aesthetically pleasing images as

167
00:10:22,472 --> 00:10:25,634
more similar than the ones the computers measure. And in fact,

168
00:10:25,672 --> 00:10:29,334
for popular metrics, the authors often note that better

169
00:10:29,372 --> 00:10:33,094
performing filters can tend toward a blurry, washed out kind

170
00:10:33,132 --> 00:10:36,498
of look. So metrics are absolutely important, but it's

171
00:10:36,514 --> 00:10:39,850
also important to bring your critical eye to them and consider

172
00:10:39,920 --> 00:10:43,514
your own use cases. For our purposes for super

173
00:10:43,552 --> 00:10:47,702
resolution, we're looking for good accuracy, yes, but not necessarily

174
00:10:47,766 --> 00:10:51,274
the best accuracy. Just as important is that it

175
00:10:51,312 --> 00:10:54,830
be fast and that it be compatible with JavaScript because not

176
00:10:54,900 --> 00:10:58,670
all of the code that we're looking at is the paper

177
00:10:58,740 --> 00:11:02,718
I ended up exploring was something called esrgan and the particular

178
00:11:02,804 --> 00:11:06,334
implementation was this one. You can check out my blog

179
00:11:06,382 --> 00:11:09,842
for more information on how I went about evaluating the different

180
00:11:09,896 --> 00:11:13,374
implementations out there. So with a viable

181
00:11:13,422 --> 00:11:17,098
architecture in hand, we can take the model offered by the author

182
00:11:17,214 --> 00:11:19,670
and see how to make it work in JavaScript.

183
00:11:20,730 --> 00:11:24,902
So we can start off by converting our model. For this example

184
00:11:25,036 --> 00:11:28,614
you can go to a website called Google Colab, which is a

185
00:11:28,652 --> 00:11:31,926
free notebook for running Python code in the browser.

186
00:11:31,958 --> 00:11:35,260
It also offers GPU if you don't have access to one.

187
00:11:36,030 --> 00:11:39,386
And so along the bottom here is a link where you can

188
00:11:39,408 --> 00:11:43,054
run this in your browser. And so here I've set

189
00:11:43,092 --> 00:11:46,382
up a number of cells that demonstrate the

190
00:11:46,436 --> 00:11:50,046
code running and upscaling in

191
00:11:50,068 --> 00:11:53,426
this notebook. This cell in

192
00:11:53,448 --> 00:11:57,506
particular is very important. This saves the model

193
00:11:57,688 --> 00:12:01,522
and not just the weights you can do either.

194
00:12:01,656 --> 00:12:05,222
Built for our purposes, we need the full model

195
00:12:05,276 --> 00:12:08,966
to be saved and converted, otherwise our

196
00:12:08,988 --> 00:12:13,046
JavaScript code won't know how to interpret the

197
00:12:13,068 --> 00:12:16,534
code that we give it. Another thing to note here is

198
00:12:16,572 --> 00:12:20,294
that this highlighted line I found that I needed to do,

199
00:12:20,332 --> 00:12:23,002
and I'm not sure if this is a bug, something that I'm doing wrong,

200
00:12:23,056 --> 00:12:26,630
or if maybe this is something a bug in the software.

201
00:12:26,790 --> 00:12:30,522
But I found that I needed to manually change this

202
00:12:30,576 --> 00:12:34,234
bit of JSON configuration in order to get my JavaScript

203
00:12:34,282 --> 00:12:38,142
code to run. So if you run into a similar issue,

204
00:12:38,276 --> 00:12:41,726
just know that you may need

205
00:12:41,748 --> 00:12:45,234
to run this bit of code in order to get it to run. So once

206
00:12:45,272 --> 00:12:49,490
we have our model saved,

207
00:12:50,470 --> 00:12:54,354
we can zip it up, we can download it, and we can then

208
00:12:54,392 --> 00:12:56,710
upload it in the next step in JavaScript.

209
00:12:59,290 --> 00:13:03,154
Then over in JavaScript this is code sandbox

210
00:13:03,202 --> 00:13:06,680
and here's a link you can follow along in your browser yourself.

211
00:13:07,630 --> 00:13:11,514
So what we can do here is create a folder that'll hold

212
00:13:11,552 --> 00:13:15,206
our model and we can then upload

213
00:13:15,318 --> 00:13:18,060
the files into it.

214
00:13:19,710 --> 00:13:21,520
And there they go.

215
00:13:23,250 --> 00:13:26,446
And there they are. So we can check and it

216
00:13:26,468 --> 00:13:30,926
uploaded correctly. So now on the right is

217
00:13:31,108 --> 00:13:34,900
the panel showing our code running.

218
00:13:35,750 --> 00:13:39,406
This image of a baboon is we're considering it our source image.

219
00:13:39,438 --> 00:13:42,050
This is what we're going to be upscaling.

220
00:13:43,990 --> 00:13:47,880
And so we load our model here,

221
00:13:49,050 --> 00:13:52,230
and the entry point is the JSON file, not the

222
00:13:52,300 --> 00:13:56,054
bin files. The bin files contain information about

223
00:13:56,092 --> 00:13:59,990
the weights and they're sharded to basically enable

224
00:14:00,070 --> 00:14:04,234
caching in the browser. But youll always want to give it the

225
00:14:04,272 --> 00:14:07,914
JSON input here. So on button click. We set up this

226
00:14:07,952 --> 00:14:11,158
function that will start a timer and then do the

227
00:14:11,184 --> 00:14:13,870
conversion of the image into a tensor.

228
00:14:14,450 --> 00:14:17,594
A tensor is sort of the core data structure

229
00:14:17,642 --> 00:14:21,646
that all machine learning works with. You can think of it as a

230
00:14:21,668 --> 00:14:25,954
multidimensional numeric array. And so

231
00:14:26,072 --> 00:14:29,230
we need to convert our image into a tensor

232
00:14:29,390 --> 00:14:33,090
so that we can put it through our model.

233
00:14:33,160 --> 00:14:36,446
So that's what this bit of code is doing is it's

234
00:14:36,478 --> 00:14:40,198
taking the original image and then making it into a

235
00:14:40,204 --> 00:14:43,462
tensor. So then we await the promise of our model

236
00:14:43,516 --> 00:14:47,770
if it hasn't loaded yet. And then we put the tensor through our model

237
00:14:47,840 --> 00:14:51,782
predict function that will return a new tensor,

238
00:14:51,846 --> 00:14:55,210
which represents what it thinks is the upscaled image.

239
00:14:55,550 --> 00:14:59,660
We then put that through this tensor as base 64 function,

240
00:15:00,050 --> 00:15:04,110
which will take that tensor and turn it back into a base

241
00:15:04,180 --> 00:15:07,546
64 source representation, which we can attach

242
00:15:07,658 --> 00:15:10,782
to the image, and we can run it.

243
00:15:10,916 --> 00:15:15,010
And voila, we've got an upscalerjs image.

244
00:15:16,230 --> 00:15:19,586
That's really cool. It worked. We can

245
00:15:19,608 --> 00:15:23,970
see that it took north of 900 milliseconds.

246
00:15:24,470 --> 00:15:29,526
So one thing that's really interesting here is that the

247
00:15:29,548 --> 00:15:33,874
first time takes 900 milliseconds, but subsequent

248
00:15:33,922 --> 00:15:38,282
runs are a lot faster. They take around 100

249
00:15:38,336 --> 00:15:41,100
milliseconds or so. So what's going on here?

250
00:15:43,070 --> 00:15:45,610
So, if you're using tensorflowjs,

251
00:15:46,030 --> 00:15:49,690
you'll want to know about something called warm ups.

252
00:15:50,610 --> 00:15:53,866
Based on how tensorflow JS interacts

253
00:15:53,898 --> 00:15:57,310
with your GPU, the first invocation of a model

254
00:15:57,460 --> 00:16:01,658
tends to be significantly slower than subsequent invocations.

255
00:16:01,834 --> 00:16:05,474
So the way around this is to when

256
00:16:05,512 --> 00:16:09,234
your site loads up, you send some initial dummy data into

257
00:16:09,272 --> 00:16:12,786
your model, and that will warm it up and avoid the

258
00:16:12,808 --> 00:16:16,098
cold start. For this to work,

259
00:16:16,184 --> 00:16:20,086
the image has to be the same size, which will be a particular problem here,

260
00:16:20,188 --> 00:16:24,166
as we probably won't have consistently sized images. And on

261
00:16:24,188 --> 00:16:27,634
top of this, this technique doesn't help the fact that the UI

262
00:16:27,682 --> 00:16:30,906
blocks. So another example is that

263
00:16:30,928 --> 00:16:34,662
we can explore web workers, and they help somewhat,

264
00:16:34,726 --> 00:16:38,554
but they're not a silver bullet. Again, you can check out my blog post.

265
00:16:38,592 --> 00:16:42,206
I go into more technical detail on exactly what's going

266
00:16:42,228 --> 00:16:45,230
on there and why they're not a silver bullet.

267
00:16:46,690 --> 00:16:50,714
So at this point, we've got a working implementation. We're able to upscale

268
00:16:50,762 --> 00:16:54,250
an image in our browser, which is really cool. When I

269
00:16:54,260 --> 00:16:57,540
first got this working, I was blown away that this is even possible,

270
00:16:58,870 --> 00:17:02,626
but it's still pretty slow. And the solution that

271
00:17:02,648 --> 00:17:06,546
we have in place for speeding it up only works if we're giving it

272
00:17:06,568 --> 00:17:09,586
consistently sized images which we can't

273
00:17:09,618 --> 00:17:12,450
really rely on. Plus it's still locking up the GPU,

274
00:17:12,530 --> 00:17:16,054
so we still have a number of roadblocks before we're able to use

275
00:17:16,092 --> 00:17:20,474
this in a consumer app. So what

276
00:17:20,512 --> 00:17:24,214
if instead of feeding our image directly

277
00:17:24,262 --> 00:17:28,186
into the model in its full sense,

278
00:17:28,288 --> 00:17:31,694
what if instead we cut the image into pieces and try

279
00:17:31,732 --> 00:17:34,240
to process those pieces one by one?

280
00:17:35,570 --> 00:17:38,926
If we subdivide our image into sections, we can take a

281
00:17:38,948 --> 00:17:42,346
single long task and break it into four smaller

282
00:17:42,378 --> 00:17:46,050
tasks, where after each one we can release the UI thread.

283
00:17:46,550 --> 00:17:50,526
But we run into a new problem. Now, these upscaled images tend

284
00:17:50,558 --> 00:17:53,970
to have artifacting around the edges, and this is a common

285
00:17:54,040 --> 00:17:57,510
thing that happens with a lot of upscaling algorithms, is that

286
00:17:57,580 --> 00:18:01,910
they introduce this issue of artifacting around the edges. It's sort of inherent

287
00:18:02,650 --> 00:18:05,862
to how they're working. It's generally not very

288
00:18:05,916 --> 00:18:09,106
obvious in a full upscalerjs

289
00:18:09,138 --> 00:18:13,020
image, but when we cut it into pieces like this, it becomes very obvious

290
00:18:13,870 --> 00:18:17,418
to fix it. What we can do is add padding to each of

291
00:18:17,424 --> 00:18:21,502
our chunks. And the interesting thing about this solution is

292
00:18:21,556 --> 00:18:25,134
that going back to the issue of

293
00:18:25,172 --> 00:18:28,160
warming up, we set our images have to be the same size.

294
00:18:29,170 --> 00:18:32,318
So long as we set our patch size small enough,

295
00:18:32,484 --> 00:18:35,794
smaller than the smallest image we expect to receive, we'll always

296
00:18:35,832 --> 00:18:39,326
be able to pass a consistent image in and avoid hitting the warm

297
00:18:39,358 --> 00:18:42,834
up. And I have an implementation at

298
00:18:42,872 --> 00:18:47,106
this link here where you can see

299
00:18:47,288 --> 00:18:51,014
where we're doing this, where we're doing some of the math to basically take

300
00:18:51,052 --> 00:18:54,518
an incoming image and split it into smaller chunks that have a

301
00:18:54,524 --> 00:18:57,986
consistent size that allows us to avoid

302
00:18:58,018 --> 00:19:01,274
hitting that warm up. So there's also other things

303
00:19:01,312 --> 00:19:04,458
we can do if we want to make this run faster in the

304
00:19:04,464 --> 00:19:08,220
browser. We can quantize our model, which means

305
00:19:08,590 --> 00:19:12,350
making it smaller and also easier to zip

306
00:19:12,930 --> 00:19:16,398
as you're passing it down the wire. We can prune our model,

307
00:19:16,484 --> 00:19:20,094
which means dropping poorly performing weights during

308
00:19:20,132 --> 00:19:23,946
training, which makes it run faster. We can also improve the accuracy

309
00:19:23,978 --> 00:19:27,810
of our model by giving it more data or training on a specific domain.

310
00:19:28,230 --> 00:19:31,566
And these are all things that, if you're looking to deploy

311
00:19:31,598 --> 00:19:34,718
this in production, are absolutely worth pursuing.

312
00:19:34,894 --> 00:19:38,518
But the point that I want to emphasize is JavaScript is absolutely

313
00:19:38,604 --> 00:19:42,360
a first class contender for considering can application of this technology,

314
00:19:42,970 --> 00:19:46,678
and it's a contender that, in my opinion is arguably a

315
00:19:46,684 --> 00:19:49,782
better option in a lot of cases than the pure Python

316
00:19:49,846 --> 00:19:53,270
solution. You don't need machine learning experts,

317
00:19:53,350 --> 00:19:56,806
although it probably doesn't hurt, and you don't need to be a machine

318
00:19:56,838 --> 00:20:00,490
learning expert yourself, although again, it probably doesn't hurt.

319
00:20:01,150 --> 00:20:04,890
All the code I showed today is available in upscaler JS,

320
00:20:05,050 --> 00:20:08,846
the open source tool that I built using Tensorflowjs. You can head to

321
00:20:08,868 --> 00:20:12,266
NPM right now and install the package and then run an image

322
00:20:12,298 --> 00:20:15,498
through it, and voila, you've got a working upscaler

323
00:20:15,514 --> 00:20:18,786
in your browser. As I continue to work in this area,

324
00:20:18,888 --> 00:20:22,306
I'll keep improving the package as well as the models that ship with it as

325
00:20:22,328 --> 00:20:25,746
well. Exploring domain specific models

326
00:20:25,778 --> 00:20:29,350
like perhaps face specific models

327
00:20:30,170 --> 00:20:33,366
or illustration models. Imagine the

328
00:20:33,388 --> 00:20:36,966
implications of something like this for video technology. What if

329
00:20:36,988 --> 00:20:40,354
we could reduce the size of a video coming down the pipe by

330
00:20:40,492 --> 00:20:44,166
80 90%? What if we got improved models

331
00:20:44,198 --> 00:20:47,562
that could, instead of upscaling by four x, what if we could do eight

332
00:20:47,616 --> 00:20:51,594
x or 16 x in the browser? Those are

333
00:20:51,632 --> 00:20:54,846
all improvements that are, they're not outlandish, they're very

334
00:20:54,868 --> 00:20:58,686
feasible. I wouldn't be surprised if we see that in the next year

335
00:20:58,868 --> 00:21:02,526
and that's all applicable in JavaScript. That's all technology

336
00:21:02,628 --> 00:21:06,142
that is very feasible to happen in JavaScript. That's really

337
00:21:06,196 --> 00:21:09,470
exciting. That's huge savings that we could be seen in the browser.

338
00:21:10,850 --> 00:21:14,062
I hope you've enjoyed this talk and learned a little bit about

339
00:21:14,116 --> 00:21:17,190
machine learning and javascript today. If you're interested,

340
00:21:17,260 --> 00:21:20,566
you can find me on Twitter, on GitHub, and at

341
00:21:20,588 --> 00:21:24,440
my website where I write and talk about this technology.

342
00:21:24,970 --> 00:21:25,810
Thanks for listening.

