1
00:00:23,450 --> 00:00:27,394
Good day everyone. The topic for today would be machine

2
00:00:27,442 --> 00:00:30,854
learning and machine learning engineering in these cloud with

3
00:00:30,892 --> 00:00:32,470
Amazon Sagemaker.

4
00:00:34,570 --> 00:00:38,150
I am Joshua Arvin Lat. People call me Arbs.

5
00:00:38,570 --> 00:00:42,594
I am the chief technology officer of Nuworks Interactive Labs.

6
00:00:42,722 --> 00:00:46,246
I'm also an AWS machine Learning hero and I'm the

7
00:00:46,268 --> 00:00:50,560
author of Machine Learning with Amazon Sagemaker cookbook book.

8
00:00:51,810 --> 00:00:55,294
So feel free to check this out. So here we

9
00:00:55,332 --> 00:00:59,006
have about 80 recipes to help data scientists and

10
00:00:59,028 --> 00:01:03,114
developers and machine learning practitioners perform ML

11
00:01:03,162 --> 00:01:06,418
experiments and deployments. So you will see that with just

12
00:01:06,424 --> 00:01:09,906
a couple of lines of code, you will be able to perform a lot of

13
00:01:09,928 --> 00:01:13,886
things with Amazon Sagemaker. So let's start with machine

14
00:01:13,918 --> 00:01:17,906
learning. No machine learning talk is complete without introducing

15
00:01:17,938 --> 00:01:21,910
this quickly. So what is machine planning? So machine learning

16
00:01:21,980 --> 00:01:25,320
is about creating something

17
00:01:26,170 --> 00:01:30,694
which helps you perform an intelligent

18
00:01:30,822 --> 00:01:34,902
decision without having to be explicitly

19
00:01:35,046 --> 00:01:38,954
programmed to do it. So one example of this would be,

20
00:01:39,072 --> 00:01:42,862
let's say we have a picture of a cat. So with your

21
00:01:42,916 --> 00:01:46,670
machine learning model, your machine learning model would then decide

22
00:01:47,410 --> 00:01:50,654
if it's a cat or not a cat. So even

23
00:01:50,692 --> 00:01:54,082
without human intervention, the machine learning model should be able

24
00:01:54,136 --> 00:01:58,114
to know if it's a cat or not a cat. And it

25
00:01:58,152 --> 00:02:01,620
can make use of a lot of training data.

26
00:02:02,310 --> 00:02:05,926
CTO help it prepare and generalize a model

27
00:02:06,108 --> 00:02:10,182
which can be used to identify new

28
00:02:10,236 --> 00:02:13,414
images and process new images if they're cats or not

29
00:02:13,452 --> 00:02:17,250
cats. So this is a very simplified example,

30
00:02:17,420 --> 00:02:21,094
but you would definitely get a better understanding

31
00:02:21,142 --> 00:02:24,634
once you have more examples on what machine learning

32
00:02:24,672 --> 00:02:27,306
can do for us next.

33
00:02:27,408 --> 00:02:31,022
When doing machine learning, we will

34
00:02:31,076 --> 00:02:34,682
definitely start with very simple examples in our local machine.

35
00:02:34,826 --> 00:02:38,654
But once we start to work with teams, once we

36
00:02:38,692 --> 00:02:41,818
start to work with more complex requirements,

37
00:02:41,994 --> 00:02:46,340
it becomes essential that we start using

38
00:02:47,030 --> 00:02:50,642
machine learning frameworks and platforms to make our lives

39
00:02:50,696 --> 00:02:54,706
easier. So why is this important? So let's say that

40
00:02:54,728 --> 00:02:57,270
we were to build everything from scratch.

41
00:02:58,170 --> 00:03:01,734
There's a chance that the other person in your team would

42
00:03:01,772 --> 00:03:05,494
have no idea what you just built, unless of course,

43
00:03:05,532 --> 00:03:07,030
you document it properly.

44
00:03:08,430 --> 00:03:11,770
You share this ways of

45
00:03:11,920 --> 00:03:16,726
working with your code through with documents

46
00:03:16,838 --> 00:03:20,374
and sample source code. But the problem there is

47
00:03:20,512 --> 00:03:24,206
that you will be building everything from scratch, and that will

48
00:03:24,228 --> 00:03:28,234
take time. And the advantage of using machine learning frameworks

49
00:03:28,362 --> 00:03:32,170
would be that these machine learning frameworks and platforms

50
00:03:32,330 --> 00:03:35,794
are already complete in a sense that

51
00:03:35,832 --> 00:03:39,582
they already have a lot of features and capabilities

52
00:03:39,646 --> 00:03:43,026
built in already because a lot of people are using them. So of

53
00:03:43,048 --> 00:03:46,774
course, as these people around

54
00:03:46,812 --> 00:03:50,418
the world are using these tools, the tools are being updated,

55
00:03:50,594 --> 00:03:54,130
even if you yourself haven't

56
00:03:54,210 --> 00:03:57,330
encountered this yet. So once you were to encounter

57
00:03:57,410 --> 00:04:01,434
these specific requirements, then you would probably just

58
00:04:01,472 --> 00:04:05,286
need to use that machine learning frameworks or platforms existing

59
00:04:05,318 --> 00:04:09,146
capabilities, which would save you time. Of course there will

60
00:04:09,168 --> 00:04:13,214
be cases where you will build something from scratch, but try to

61
00:04:13,252 --> 00:04:16,640
make sure that it's practical and it makes sense.

62
00:04:17,970 --> 00:04:21,914
So this is one good example of practical

63
00:04:21,962 --> 00:04:25,220
applications of machine learning, and also

64
00:04:26,070 --> 00:04:29,646
possible pragmatic and practical solutions

65
00:04:29,758 --> 00:04:33,422
using existing tools or services or capabilities

66
00:04:33,486 --> 00:04:36,950
of existing platforms. So if we look at these left

67
00:04:37,020 --> 00:04:41,330
side, we can see here that, yeah, there's anomaly detection,

68
00:04:41,490 --> 00:04:44,870
product recommendation forecasting, image and video

69
00:04:44,940 --> 00:04:48,294
analysis, document classification and language translation.

70
00:04:48,342 --> 00:04:52,060
Just a few of what we can do with machine learning.

71
00:04:52,590 --> 00:04:56,010
On the right side, we have the possible solutions.

72
00:04:56,590 --> 00:05:00,490
So how can we solve an anomaly detection

73
00:05:00,850 --> 00:05:04,302
requirements with just a few lines of code? Yeah,

74
00:05:04,356 --> 00:05:08,190
we can make use of sagemaker random cut forest algorithm,

75
00:05:08,770 --> 00:05:12,706
which is already optimized for the cloud. So it

76
00:05:12,728 --> 00:05:16,366
has made use of existing random

77
00:05:16,398 --> 00:05:20,322
cut forest algorithm, and then the AWS team

78
00:05:20,376 --> 00:05:23,794
optimized it to make it work with Sagemaker and

79
00:05:23,912 --> 00:05:27,442
the cloud resources for product recommendation

80
00:05:27,586 --> 00:05:31,254
we can make use of Amazon personalize, another service in

81
00:05:31,292 --> 00:05:34,840
AWS, which is built to solve this type of problem

82
00:05:35,370 --> 00:05:39,366
for forecasting requirements. We can make use of Sagemaker

83
00:05:39,398 --> 00:05:42,822
deeper algorithm. So it's similar to random cut forest

84
00:05:42,886 --> 00:05:46,774
where we just make use of an existing container

85
00:05:46,822 --> 00:05:50,006
image that the AWS team has provided for

86
00:05:50,048 --> 00:05:53,374
us, so that all we need to do is make use

87
00:05:53,412 --> 00:05:57,246
of that container and perform planning

88
00:05:57,348 --> 00:06:00,682
and deployment to solve forecasting requirements.

89
00:06:00,826 --> 00:06:04,500
And the same goes for the other items in this list.

90
00:06:04,950 --> 00:06:08,754
So of course, you won't need one to two

91
00:06:08,792 --> 00:06:12,034
teams of learning the nitty gritty details of

92
00:06:12,072 --> 00:06:15,862
how these things work. These advantage here is that even

93
00:06:15,916 --> 00:06:18,070
if you are a newbie,

94
00:06:19,210 --> 00:06:22,342
you will be able to get something to work within four CTO 8

95
00:06:22,396 --> 00:06:25,240
hours. And that's pretty cool.

96
00:06:25,610 --> 00:06:28,874
So instead of spending six months to one year just

97
00:06:28,912 --> 00:06:32,886
trying to get everything to work, because you built something from scratch,

98
00:06:33,078 --> 00:06:36,938
you can have something which is already working.

99
00:06:37,024 --> 00:06:40,234
You can present a proof of concept work, CTO,

100
00:06:40,272 --> 00:06:44,198
your boss, or to your clients. And then once you

101
00:06:44,224 --> 00:06:48,186
have approved a certain budget, then that's the time you can deep dive

102
00:06:48,218 --> 00:06:51,998
and let's say configure the hyperparameters, prepare a complete

103
00:06:52,164 --> 00:06:56,338
machine learning engineering system and workflows and so on.

104
00:06:56,504 --> 00:06:59,986
So the advantage here is that you can build something fast and also you

105
00:07:00,008 --> 00:07:03,300
can configure this into something that's production ready.

106
00:07:03,910 --> 00:07:07,720
So what can sage maker do for us? And what is Sagemaker anyway?

107
00:07:08,730 --> 00:07:12,342
Sagemaker is the machine learning platform

108
00:07:12,476 --> 00:07:15,878
of AWS, which helps you work with

109
00:07:16,044 --> 00:07:18,890
more complex and custom requirements.

110
00:07:19,390 --> 00:07:22,874
AWS has a lot of machine learning services, but what

111
00:07:22,912 --> 00:07:27,002
makes Sagemaker amazing is that it has a lot of capabilities that

112
00:07:27,056 --> 00:07:30,846
help you migrate your machine learning

113
00:07:31,028 --> 00:07:35,614
requirements and workflows and code to

114
00:07:35,652 --> 00:07:39,646
the cloud with very minimal changes

115
00:07:39,828 --> 00:07:43,154
in your existing scripts. And what it

116
00:07:43,192 --> 00:07:47,166
offers and provides would be a certain level of abstraction

117
00:07:47,278 --> 00:07:51,300
when dealing with cloud resources. If you were to

118
00:07:51,910 --> 00:07:55,922
prepare and run simple experiments

119
00:07:55,986 --> 00:08:01,062
in your local machine, you may not need very

120
00:08:01,196 --> 00:08:05,122
large and very powerful instances

121
00:08:05,186 --> 00:08:08,966
or computers or servers. However, once you

122
00:08:08,988 --> 00:08:12,682
need to deal with production requirements and once you are

123
00:08:12,736 --> 00:08:16,710
going to work with really large files and really large models,

124
00:08:16,870 --> 00:08:20,542
you will start to realize how hard it is to get this

125
00:08:20,596 --> 00:08:24,666
working in the cloud because of course your local machine wouldn't

126
00:08:24,698 --> 00:08:29,566
be enough to get these requirements running.

127
00:08:29,748 --> 00:08:33,026
So here what sagemaker can do for us, which is just one

128
00:08:33,048 --> 00:08:36,258
of the cool things with Sagemaker, is that

129
00:08:36,424 --> 00:08:40,114
with just a single line of code change, you will

130
00:08:40,152 --> 00:08:45,274
be able to configure these infrastructure strength

131
00:08:45,422 --> 00:08:49,586
needed to run a certain part of the ML workflow.

132
00:08:49,698 --> 00:08:53,382
So for example, if you look at these screen in data

133
00:08:53,436 --> 00:08:56,822
preparation and cleaning, if I need two

134
00:08:56,876 --> 00:09:00,618
instances of a certain instance type,

135
00:09:00,784 --> 00:09:04,586
all I need to do is change one line of code and

136
00:09:04,608 --> 00:09:08,134
then that's going to work right away. And the advantage

137
00:09:08,182 --> 00:09:11,514
here also is that the instances,

138
00:09:11,562 --> 00:09:15,114
these automatically get deleted after the data preparation

139
00:09:15,162 --> 00:09:18,746
and cleaning step has completed, meaning you'll

140
00:09:18,778 --> 00:09:22,126
save money because it's not running at all, and you won't pay for

141
00:09:22,148 --> 00:09:25,330
anything which is not running in AWS,

142
00:09:25,830 --> 00:09:29,246
let's say in model training and hyperparameter tuning.

143
00:09:29,358 --> 00:09:33,374
You can see here that, okay, that training and hyperparameter

144
00:09:33,422 --> 00:09:37,174
tuning step will take time. So there,

145
00:09:37,292 --> 00:09:41,842
all I need to do is specify six instances

146
00:09:41,906 --> 00:09:45,238
of a certain type. And if I need to have a

147
00:09:45,244 --> 00:09:49,480
really strong instance type there, then yeah, I can just configure it there.

148
00:09:50,190 --> 00:09:53,782
And when I need to deploy something, and I'm aware

149
00:09:53,846 --> 00:09:57,514
that I'm going to pay for every r that

150
00:09:57,552 --> 00:10:01,182
that instance is running, of course I would choose a small instance type

151
00:10:01,316 --> 00:10:05,774
because of course the instance needed for

152
00:10:05,812 --> 00:10:09,678
deployment may not necessarily be the same

153
00:10:09,764 --> 00:10:13,674
instance type needed for training and will need less resources

154
00:10:13,802 --> 00:10:17,394
during deployment. So there we can specify one, and with

155
00:10:17,432 --> 00:10:20,866
just a single line of code change, we'll be able to get

156
00:10:20,888 --> 00:10:24,162
this working right away, which is pretty cool. So again,

157
00:10:24,296 --> 00:10:27,666
the infrastructure abstraction component of sagemaker

158
00:10:27,858 --> 00:10:31,222
already solves a lot of problems for us, because that

159
00:10:31,276 --> 00:10:34,742
directly maps to the cost of owning this entire

160
00:10:34,796 --> 00:10:38,226
thing. So of course, enough of the concepts let's

161
00:10:38,338 --> 00:10:41,820
take a look at a bit of code and how does this work?

162
00:10:42,190 --> 00:10:47,226
So you can see these source code in the repository here.

163
00:10:47,328 --> 00:10:50,634
So in GitHub you have Amazon Sagemaker cookbook. So feel

164
00:10:50,672 --> 00:10:54,942
free to check that out so that you can see all the other code

165
00:10:54,996 --> 00:10:58,122
snippets. So you will be surprised

166
00:10:58,186 --> 00:11:01,966
that all it takes is a couple of lines of code to

167
00:11:01,988 --> 00:11:05,554
get something working with Sagemaker, of course you will need to prepare your

168
00:11:05,592 --> 00:11:09,490
data, you will need to perform model evaluation.

169
00:11:10,150 --> 00:11:13,474
But if we were to perform training, it would be very

170
00:11:13,512 --> 00:11:17,000
similar to some of the existing libraries fit function.

171
00:11:17,850 --> 00:11:21,606
So what happens here? So first we

172
00:11:21,628 --> 00:11:25,366
initialize the estimator over here, and then we

173
00:11:25,388 --> 00:11:29,494
set the hyperparameters so we can see these, that we're

174
00:11:29,542 --> 00:11:32,874
dealing with a machine learning algorithm that

175
00:11:32,912 --> 00:11:36,918
deals with time series analysis requirements.

176
00:11:37,094 --> 00:11:40,442
So we have here concepts,

177
00:11:40,506 --> 00:11:43,902
length, time prediction length, and so on.

178
00:11:44,036 --> 00:11:48,106
Because we're trying to make use of the deep AR forecasting

179
00:11:48,138 --> 00:11:51,962
algorithm of Sagemaker, we specify

180
00:11:52,106 --> 00:11:56,018
the data channels on the right hand side. As you can

181
00:11:56,024 --> 00:12:00,210
see here, data channels equals train and test dictionary.

182
00:12:00,550 --> 00:12:04,242
And then with one line of code we can perform the training step

183
00:12:04,296 --> 00:12:08,280
with fit function and we pass the data,

184
00:12:08,730 --> 00:12:11,990
these data channels as the argument.

185
00:12:12,810 --> 00:12:16,230
Next, if we need to deploy it,

186
00:12:16,300 --> 00:12:20,518
all we need to do is a single line of code which is deploy.

187
00:12:20,694 --> 00:12:25,238
And you can see here that it's magic.

188
00:12:25,414 --> 00:12:28,730
So here we run the deploy function.

189
00:12:28,880 --> 00:12:32,190
We just specify the instance type and the instance count,

190
00:12:32,340 --> 00:12:36,094
and there you go. All we need to do is wait for probably three

191
00:12:36,132 --> 00:12:39,950
CTO five minutes and then that production

192
00:12:40,370 --> 00:12:43,694
level endpoint is already working. So we won't have

193
00:12:43,732 --> 00:12:47,170
to worry about the DevOps side of things.

194
00:12:47,240 --> 00:12:51,006
We won't have to worry about the engineering side of things because that's

195
00:12:51,038 --> 00:12:54,418
already handled by Sagemaker. So we don't have

196
00:12:54,424 --> 00:12:57,730
to worry about that. And if we need to delete that endpoint,

197
00:12:57,810 --> 00:13:00,920
it takes one line of code as well.

198
00:13:02,250 --> 00:13:06,374
So what's the best practice when dealing with this

199
00:13:06,412 --> 00:13:09,866
type of approach? So we can optimize cost by

200
00:13:09,888 --> 00:13:13,898
using transient ML instances for training models. And this

201
00:13:13,904 --> 00:13:17,130
is automatically being done by Sagemaker.

202
00:13:17,790 --> 00:13:21,310
So during training and even processes,

203
00:13:21,730 --> 00:13:25,150
we can select the type of instance

204
00:13:25,490 --> 00:13:29,166
or server that's going to run

205
00:13:29,268 --> 00:13:31,630
these processing script or scripts.

206
00:13:32,130 --> 00:13:35,314
So in the first example at the top, we can see here

207
00:13:35,352 --> 00:13:38,850
that we have a large instance.

208
00:13:39,670 --> 00:13:43,650
At these bottom we have a two x large instance.

209
00:13:44,470 --> 00:13:48,022
So these, of course the two x large instance is

210
00:13:48,076 --> 00:13:52,194
more expensive than the large instance, but you won't

211
00:13:52,242 --> 00:13:55,922
probably feel that cost much, especially if that instance

212
00:13:55,986 --> 00:13:59,542
runs for only two minutes because of course,

213
00:13:59,596 --> 00:14:02,842
if you were already using AWS for quite some time,

214
00:14:02,976 --> 00:14:06,314
you may notice that, okay, if an instance is running for

215
00:14:06,352 --> 00:14:10,186
24 hours per day, times seven days, times four weeks,

216
00:14:10,288 --> 00:14:13,962
then of course the cost will add up and you will significantly

217
00:14:14,026 --> 00:14:17,646
fill that cost when you check the bill. But if you

218
00:14:17,668 --> 00:14:21,040
are running the training instance in just two minutes,

219
00:14:22,550 --> 00:14:26,766
then it's not that pricey. And increasing

220
00:14:26,798 --> 00:14:30,354
the size of the instance is preferred here because it will

221
00:14:30,392 --> 00:14:33,634
significantly decrease the amount of time used for

222
00:14:33,672 --> 00:14:36,978
training. And given that we're

223
00:14:36,994 --> 00:14:41,238
dealing with transient ML instances, you won't need to

224
00:14:41,404 --> 00:14:45,218
have a separate program or code just to delete

225
00:14:45,234 --> 00:14:49,354
the instances. The instances will

226
00:14:49,392 --> 00:14:53,270
be created and then will automatically be deleted

227
00:14:53,430 --> 00:14:56,666
after the processing or training jobs have completed, which is

228
00:14:56,688 --> 00:15:00,314
pretty cool. Before, you would have to program that.

229
00:15:00,432 --> 00:15:03,822
Now all you need to do is run the fit function, and then

230
00:15:03,876 --> 00:15:07,566
after the fit function has completed, then the instance would get

231
00:15:07,588 --> 00:15:11,406
deleted automatically. So your next question would

232
00:15:11,428 --> 00:15:15,010
be, so, do I need to create everything

233
00:15:15,080 --> 00:15:18,980
from scratch again? Now that I found out about this new platform?

234
00:15:19,510 --> 00:15:23,810
The answer would be no. Sagemaker has been designed

235
00:15:24,890 --> 00:15:29,030
to help existing machine learning practitioners

236
00:15:29,690 --> 00:15:32,710
migrate and work with their existing

237
00:15:33,770 --> 00:15:37,814
code and set of scripts and work to

238
00:15:37,852 --> 00:15:41,154
sagemaker with very minimal modifications.

239
00:15:41,282 --> 00:15:44,140
And there are a lot of options and layers here.

240
00:15:44,590 --> 00:15:47,978
Of course, if you're just getting started, you can make use of the

241
00:15:47,984 --> 00:15:51,566
built in algorithms, as you can see on the left side, in the

242
00:15:51,588 --> 00:15:55,274
middle, you can even bring your own container or container image.

243
00:15:55,402 --> 00:15:59,406
The advantage here is that you

244
00:15:59,428 --> 00:16:02,982
can compile and prepare

245
00:16:03,066 --> 00:16:06,962
and build your own container image with

246
00:16:07,016 --> 00:16:10,402
all the prerequisites there. And if you have something,

247
00:16:10,456 --> 00:16:14,062
let's say an R package,

248
00:16:14,126 --> 00:16:17,974
an R script, where your model

249
00:16:18,172 --> 00:16:21,554
is going to be built using those existing

250
00:16:21,602 --> 00:16:25,462
custom scripts, then yes, you can also port that to sagemaker by

251
00:16:25,516 --> 00:16:28,746
bringing your own container. And on the right side, you can

252
00:16:28,768 --> 00:16:32,266
even bring your own algorithm and make use of

253
00:16:32,448 --> 00:16:36,886
these smooth integration with existing machine

254
00:16:36,918 --> 00:16:40,790
learning frameworks like Tensorflow, Pytorch.

255
00:16:40,870 --> 00:16:44,826
You can even make use of hugging face transformer

256
00:16:44,858 --> 00:16:48,094
models there. So the advantage there is that in the

257
00:16:48,132 --> 00:16:52,094
different things that you have worked on, there's a counterpart for

258
00:16:52,132 --> 00:16:55,330
it in Sagemaker. And you'll realize that,

259
00:16:55,400 --> 00:16:59,314
oh, I didn't expect it to be that smooth and that

260
00:16:59,352 --> 00:17:03,070
flexible. So what's the best practice?

261
00:17:03,150 --> 00:17:06,494
The best practice here would be to choose

262
00:17:06,552 --> 00:17:10,440
what's best for you. You will be given a lot of options,

263
00:17:11,290 --> 00:17:14,726
and given that sagemaker is flexible, all you need to

264
00:17:14,748 --> 00:17:17,906
do is CTO, be aware of the features,

265
00:17:18,098 --> 00:17:20,954
and what would be a good metric for that?

266
00:17:21,072 --> 00:17:23,660
The metric for that would definitely be time,

267
00:17:24,590 --> 00:17:28,074
because the less time it would take you to

268
00:17:28,112 --> 00:17:31,274
build something or to prepare something, then that's

269
00:17:31,322 --> 00:17:34,830
probably the right way to go. Of course,

270
00:17:34,900 --> 00:17:39,290
you will have other things to worry about, let's say the evaluation

271
00:17:39,370 --> 00:17:43,006
metrics, the cost and so on. But one of

272
00:17:43,028 --> 00:17:47,122
the factors you need to take note of is time. If you can build

273
00:17:47,176 --> 00:17:50,866
something in 3 hours, I would prefer that

274
00:17:50,968 --> 00:17:53,970
over something which can be built in three months.

275
00:17:54,120 --> 00:17:57,774
Because after three months the requirements may have changed,

276
00:17:57,902 --> 00:18:01,366
your clients may have changed their mind, or maybe that

277
00:18:01,388 --> 00:18:04,790
would be too expensive already. Because if you were to think about cost,

278
00:18:04,860 --> 00:18:07,566
it would involve the cost of the infrastructure,

279
00:18:07,618 --> 00:18:10,940
resources, the other overhead cost,

280
00:18:11,790 --> 00:18:15,354
the cost of paying the employees, and so on.

281
00:18:15,552 --> 00:18:19,306
So with less time, you'll definitely save a lot.

282
00:18:19,488 --> 00:18:22,654
So make sure that you take that into account because time

283
00:18:22,692 --> 00:18:24,510
will always be a multiplier.

284
00:18:25,650 --> 00:18:29,582
That said, how can we save time? You can save

285
00:18:29,636 --> 00:18:32,990
time by making use of existing features,

286
00:18:33,490 --> 00:18:36,500
and being aware of these features is the first step.

287
00:18:37,030 --> 00:18:40,546
So let's take a step back and see why do

288
00:18:40,568 --> 00:18:44,334
we have so many features here? The reason why we have so many features

289
00:18:44,382 --> 00:18:48,102
here is that there are a lot of different requirements other

290
00:18:48,156 --> 00:18:52,022
than training and deploying your model. Of course, when you're starting

291
00:18:52,076 --> 00:18:56,230
to learn about machine learning, you'll start off with training

292
00:18:56,300 --> 00:19:00,006
your model, deploying your model, and then evaluating your

293
00:19:00,028 --> 00:19:03,338
model. But in reality, there's a lot more things you

294
00:19:03,344 --> 00:19:06,666
need to worry about once you need to work with teams, once you need to

295
00:19:06,688 --> 00:19:10,554
work with different requirements, once you need to work with legal

296
00:19:10,602 --> 00:19:14,126
and other concerns, you need

297
00:19:14,148 --> 00:19:17,726
to worry about. So first, let's look at

298
00:19:17,748 --> 00:19:21,546
the upper left side, sagemaker processing.

299
00:19:21,658 --> 00:19:26,100
So sagemaker processing is there to help you process

300
00:19:26,790 --> 00:19:29,890
your data with a custom script.

301
00:19:30,550 --> 00:19:34,642
The advantage of using sagemaker processing is that if your

302
00:19:34,696 --> 00:19:38,646
local machine or the machine that you're using

303
00:19:38,828 --> 00:19:42,280
is not able to process a large amount of data,

304
00:19:42,650 --> 00:19:46,514
you can make use of sagemaker processing using the same infrastructure

305
00:19:46,562 --> 00:19:50,554
abstraction capabilities that you're using with training your model.

306
00:19:50,752 --> 00:19:54,874
So if you have big data like data,

307
00:19:55,072 --> 00:19:59,062
then you can use sagemaker processing and just use a large instance

308
00:19:59,206 --> 00:20:02,480
to get the task completed within two to three minutes or something.

309
00:20:03,170 --> 00:20:06,394
With sagemaker experiment. So the one just beside

310
00:20:06,442 --> 00:20:10,750
sagemaker processes here at the upper middle

311
00:20:10,820 --> 00:20:14,626
corner. With sagemaker experiments, we can make use of

312
00:20:14,648 --> 00:20:18,002
that to manage multiple experiments. Of course,

313
00:20:18,056 --> 00:20:21,534
you will not be running just a single experiments, but with Sagemaker

314
00:20:21,582 --> 00:20:25,714
experiments you can run a lot of experiments and

315
00:20:25,752 --> 00:20:29,766
not worry about the details on how to connect the

316
00:20:29,788 --> 00:20:33,570
different artifacts. It will be much easier for you to audit

317
00:20:33,650 --> 00:20:37,014
experiments which have been performed in these past. So you can check

318
00:20:37,052 --> 00:20:40,090
it out, especially when you need to get things

319
00:20:40,160 --> 00:20:43,980
working in production and in work in general,

320
00:20:44,990 --> 00:20:48,826
with automatic model tuning on the upper right hand corner with

321
00:20:48,848 --> 00:20:51,580
just a couple of lines of code, which we will show later,

322
00:20:51,950 --> 00:20:55,454
you can see here that we can get the

323
00:20:55,492 --> 00:20:59,630
best version of a model using

324
00:20:59,700 --> 00:21:03,220
automatic model using. So what happens here is that

325
00:21:03,590 --> 00:21:07,454
we'll be able to test a lot of different hyperparameter

326
00:21:07,502 --> 00:21:11,570
configurations and prepare and build different

327
00:21:11,640 --> 00:21:15,490
models, and then we just compare the models and get the best one.

328
00:21:15,640 --> 00:21:19,286
With automatic model tuning, all you need is probably two or

329
00:21:19,308 --> 00:21:23,526
three additional lines of code in addition to what you

330
00:21:23,548 --> 00:21:26,440
saw earlier. And these, you'll see that, oh,

331
00:21:26,810 --> 00:21:30,618
that's magic. Again, with very minimal code changes,

332
00:21:30,704 --> 00:21:34,214
you'll be able to have something which automatically

333
00:21:34,262 --> 00:21:37,770
gets and prepares the best model for you. So we'll discuss

334
00:21:37,840 --> 00:21:42,190
that later with a couple of examples with built in algorithms.

335
00:21:42,610 --> 00:21:46,174
We can see here that we have about

336
00:21:46,212 --> 00:21:50,186
17, I think 17 built in algorithms

337
00:21:50,378 --> 00:21:54,178
which can be used to solve different machine learning requirements. So some of

338
00:21:54,184 --> 00:21:58,260
these algorithms can be used. CTO deal with

339
00:21:58,710 --> 00:22:02,260
numerical data, can also deal with text data,

340
00:22:02,710 --> 00:22:06,402
and you can also deal with images and even time series

341
00:22:06,466 --> 00:22:08,120
analysis stuff.

342
00:22:09,370 --> 00:22:13,174
So you can already get started with built in algorithms so that

343
00:22:13,212 --> 00:22:17,126
you won't have to use your custom containers and

344
00:22:17,148 --> 00:22:20,394
algorithms, especially if you're still getting started. And most

345
00:22:20,432 --> 00:22:24,154
of the time, these algorithms are not

346
00:22:24,192 --> 00:22:27,754
just on par with what you probably will build,

347
00:22:27,872 --> 00:22:31,246
but it's probably already optimized in

348
00:22:31,268 --> 00:22:34,586
solving most of the use cases. There's also machine

349
00:22:34,618 --> 00:22:38,494
learning and deep learning framework support. So the

350
00:22:38,532 --> 00:22:42,454
great thing here is that if you're already using Tensorflow

351
00:22:42,522 --> 00:22:46,210
or Pytorch or Mxnet in your projects,

352
00:22:46,550 --> 00:22:50,514
then with very minimal adjustments, you can

353
00:22:50,552 --> 00:22:54,686
already port that and use it with Sagemaker. With Sagemaker,

354
00:22:54,718 --> 00:22:58,502
clarify the 6th one, you can use that

355
00:22:58,556 --> 00:23:02,818
to detect pretraining

356
00:23:02,914 --> 00:23:06,086
and post training bias. It can also be

357
00:23:06,108 --> 00:23:09,050
used to enable ML explainability.

358
00:23:09,710 --> 00:23:13,254
And we'll discuss that later in detail, and you'll

359
00:23:13,302 --> 00:23:16,986
see that it can be used to help you manage

360
00:23:17,088 --> 00:23:21,182
the other production requirements which you may encounter later

361
00:23:21,236 --> 00:23:25,306
on when you have to deploy your model, especially the legal and ethical concerns

362
00:23:25,418 --> 00:23:28,526
surrounding the type of problem that you're trying

363
00:23:28,548 --> 00:23:32,362
to solve. Sagemaker debugger we'll actually

364
00:23:32,436 --> 00:23:35,838
discuss this in detail in these next set of slides. But sagemaker

365
00:23:35,854 --> 00:23:40,450
debugger can be used to debug your experiments

366
00:23:41,110 --> 00:23:44,850
in near real time in cloud environments.

367
00:23:45,210 --> 00:23:49,474
So later you'll realize that debugging experiments

368
00:23:49,522 --> 00:23:53,510
locally and debugging experiments in the cloud are

369
00:23:53,580 --> 00:23:57,666
quite different because of course when you're using and working with

370
00:23:57,708 --> 00:24:01,514
different instances and servers during training and

371
00:24:01,552 --> 00:24:05,398
there's an error somewhere, how do you debug that, especially if you're dealing

372
00:24:05,414 --> 00:24:08,246
with a distributed setup?

373
00:24:08,438 --> 00:24:11,982
Sagemaker feature store Sagemaker feature store

374
00:24:12,116 --> 00:24:15,802
is used for feature

375
00:24:15,866 --> 00:24:19,406
store requirements from the name itself. So you will have

376
00:24:19,428 --> 00:24:22,926
these offline feature store, and you will have the online feature store.

377
00:24:23,108 --> 00:24:26,930
And the offline feature store can be used to

378
00:24:27,080 --> 00:24:30,786
deal with data which can be used for training, and then

379
00:24:30,968 --> 00:24:34,750
the online feature store can be used to get data which can be used

380
00:24:34,920 --> 00:24:37,270
for the prediction parts.

381
00:24:38,090 --> 00:24:41,602
Sagemaker autopilot is there to help you with your automl

382
00:24:41,666 --> 00:24:44,950
requirements. So with very minimal human

383
00:24:45,020 --> 00:24:48,938
intervention, probably just the initial configuration part,

384
00:24:49,104 --> 00:24:53,226
you can just pass in your planning data and

385
00:24:53,248 --> 00:24:56,618
then run, and then after a few minutes you

386
00:24:56,624 --> 00:25:00,318
will have a trained model. So that's pretty cool because you

387
00:25:00,324 --> 00:25:04,846
can make use of AutomL and Sagemaker has proper

388
00:25:04,948 --> 00:25:08,442
support for it. Sagemaker Studio

389
00:25:08,586 --> 00:25:12,302
so Sagemaker Studio is there to help

390
00:25:12,356 --> 00:25:16,130
us have an interface and basically

391
00:25:16,200 --> 00:25:20,110
a studio which has a lot of features and capabilities

392
00:25:20,190 --> 00:25:23,922
integrated already so that things

393
00:25:23,976 --> 00:25:27,426
would be pretty smooth when you're dealing with experiments

394
00:25:27,458 --> 00:25:31,346
and deployments when using Sagemaker. So they're continuously

395
00:25:31,378 --> 00:25:35,174
upgrading this studio. CTO make it easy for

396
00:25:35,212 --> 00:25:38,486
you to run your code and then there's an interface

397
00:25:38,598 --> 00:25:42,346
for it so that it's very practical for you to work on

398
00:25:42,448 --> 00:25:45,958
real life experiments. Sagemaker Groundsuit

399
00:25:45,974 --> 00:25:49,894
is there to help you prepare your data. Sagemaker model

400
00:25:49,952 --> 00:25:53,866
monitor from the name itself, it's there to help you monitor deployed

401
00:25:53,898 --> 00:25:57,566
models, manage spot planning if

402
00:25:57,588 --> 00:26:01,598
you're aware of what spot instances are. Those are used to

403
00:26:01,684 --> 00:26:04,830
further reduce the cost when performing training.

404
00:26:04,980 --> 00:26:08,306
So with managed spot training, you won't have to worry about the

405
00:26:08,328 --> 00:26:11,886
nitty gritty details when you're using spot instances,

406
00:26:11,998 --> 00:26:16,530
because all you need to do is update a couple of parameters

407
00:26:16,870 --> 00:26:20,840
and then you'll be able to save on costs, especially when you're dealing with

408
00:26:21,610 --> 00:26:23,720
large instances during training.

409
00:26:24,250 --> 00:26:28,026
Sagemaker pipelines, second to the last, will be

410
00:26:28,048 --> 00:26:31,526
able to create complex machine

411
00:26:31,558 --> 00:26:34,922
learning workflows with just a couple of lines of code.

412
00:26:35,056 --> 00:26:38,970
And then finally Sagemaker data Wrangler is

413
00:26:39,040 --> 00:26:43,022
used to help you prepare your data using

414
00:26:43,076 --> 00:26:46,974
an interface. So these are just a few of

415
00:26:47,012 --> 00:26:51,214
the capabilities and features of Sagemaker. You might

416
00:26:51,252 --> 00:26:55,250
be overwhelmed right now, but do not worry because we will choose

417
00:26:55,320 --> 00:26:58,754
about four or five of them, and we will discuss this in

418
00:26:58,792 --> 00:27:01,380
more detail over the next couple of minutes.

419
00:27:02,070 --> 00:27:05,294
What's important here is that you should have

420
00:27:05,352 --> 00:27:09,590
that mindset or way of thinking that

421
00:27:09,660 --> 00:27:13,174
maybe the problem that you want to solve has

422
00:27:13,212 --> 00:27:16,434
already been solved by an existing tool or framework.

423
00:27:16,562 --> 00:27:18,870
And if you were to use Sagemaker,

424
00:27:19,530 --> 00:27:23,206
probably one of the customers of AWS has already requested

425
00:27:23,238 --> 00:27:26,646
for that already, and there's already a solution already prepared

426
00:27:26,678 --> 00:27:30,460
for it. So before trying to build something on your own,

427
00:27:30,910 --> 00:27:34,622
check if all you need to do is add one to two lines of code

428
00:27:34,756 --> 00:27:39,754
in order to solve your problem. It's not about creating

429
00:27:39,802 --> 00:27:43,940
the coolest solution out there, it's about solving your problem

430
00:27:44,310 --> 00:27:47,886
in the shortest time possible with the smallest

431
00:27:47,918 --> 00:27:51,442
amount of expense. Because if you will get the same

432
00:27:51,496 --> 00:27:55,042
output, or even better, why not use something which already built

433
00:27:55,096 --> 00:27:59,566
for you? So let's start first with sagemaker debugger.

434
00:27:59,678 --> 00:28:03,654
So here you will start to see more code, and this will help you

435
00:28:03,692 --> 00:28:06,854
understand how easy it is to use Sagemaker in general.

436
00:28:06,972 --> 00:28:10,362
And actually some parts of the code here are

437
00:28:10,416 --> 00:28:14,650
just snippets which are already used

438
00:28:14,720 --> 00:28:18,406
in other snippets, as you see in the previous slide.

439
00:28:18,518 --> 00:28:22,618
So here at the bottom, this is the same estimator initialization

440
00:28:22,714 --> 00:28:26,574
code. And what's happening at the top here is that

441
00:28:26,612 --> 00:28:30,474
we're just initializing these debugger objects

442
00:28:30,522 --> 00:28:33,940
and properties there before passing it to the estimator object.

443
00:28:34,550 --> 00:28:37,762
So there all it takes is probably three

444
00:28:37,816 --> 00:28:41,202
additional lines of code, and sagemaker debugger is already

445
00:28:41,256 --> 00:28:44,754
enabled. So what's happening here, what's happening here

446
00:28:44,792 --> 00:28:50,022
is that every two steps we will save some

447
00:28:50,076 --> 00:28:53,800
sort of snapshot data, and then

448
00:28:54,250 --> 00:28:56,840
it will save that in Amazon S three,

449
00:28:57,550 --> 00:29:01,162
and then we'll be able to debug that

450
00:29:01,296 --> 00:29:04,060
and have more visibility on what's happening inside.

451
00:29:05,070 --> 00:29:08,346
And we can specify here

452
00:29:08,528 --> 00:29:12,014
that we need to have a rule that the loss should not

453
00:29:12,052 --> 00:29:15,694
be decreasing, so the value

454
00:29:15,812 --> 00:29:19,066
there should not be decreasing. So if that rule

455
00:29:19,098 --> 00:29:23,058
is violated, then we'll be able to detect that during

456
00:29:23,144 --> 00:29:26,020
the execution phase of the planning step.

457
00:29:26,470 --> 00:29:30,478
So you just specify the configuration with sagemaker debugger,

458
00:29:30,654 --> 00:29:35,210
initialize the estimator object with a debugger configuration

459
00:29:35,390 --> 00:29:39,698
specified and enabled, and then you just run the experiment

460
00:29:39,794 --> 00:29:43,750
normally so you won't have to worry about going

461
00:29:43,820 --> 00:29:47,158
deep into these actual execution of the container inside.

462
00:29:47,244 --> 00:29:50,774
Sagemaker and debugger will do its magic

463
00:29:50,822 --> 00:29:54,714
for you. Pretty cool, right? Let's look at our

464
00:29:54,752 --> 00:29:57,210
automatic model tuning with Sagemaker.

465
00:29:58,030 --> 00:30:02,494
With model training and tuning, we can see here that all

466
00:30:02,532 --> 00:30:06,842
we need is a bunch of hyperparameter

467
00:30:06,906 --> 00:30:10,880
configuration ranges, and we will have

468
00:30:11,410 --> 00:30:15,118
multiple planning instances

469
00:30:15,214 --> 00:30:18,654
running at the same time. The advantage

470
00:30:18,702 --> 00:30:22,786
these is that without much

471
00:30:22,888 --> 00:30:26,360
change in your code, you'll be able CTO

472
00:30:27,850 --> 00:30:31,542
improve your existing experiments and

473
00:30:31,596 --> 00:30:35,480
make it run ten times or 100 times more

474
00:30:35,930 --> 00:30:38,310
without having to worry about the details.

475
00:30:39,050 --> 00:30:43,350
So if you were to look at this slide,

476
00:30:43,850 --> 00:30:47,942
you'll see that the estimator initialization step is

477
00:30:48,076 --> 00:30:52,218
just these same. The same way goes for the set hyperparameters

478
00:30:52,314 --> 00:30:55,646
call function call. So if you look

479
00:30:55,668 --> 00:30:59,482
at the lower left section during the initialization

480
00:30:59,546 --> 00:31:03,886
of the hyperparameter ranges section, we specify

481
00:31:04,078 --> 00:31:07,570
the continuous and integer parameter ranges

482
00:31:09,510 --> 00:31:13,250
for minimum child weight, max step and eta,

483
00:31:13,910 --> 00:31:17,426
and then we initialize the hyperparameter object

484
00:31:17,608 --> 00:31:21,400
with those configuration, and then we just call the fit function.

485
00:31:22,490 --> 00:31:25,938
So the cool thing here is that we just added three to four lines

486
00:31:25,954 --> 00:31:29,626
of code, and then we call the fit function. And then there you go.

487
00:31:29,728 --> 00:31:32,922
It's going to run for probably 15 to 20 minutes,

488
00:31:33,056 --> 00:31:36,700
and then after 15 CTO, 20 minutes, depending on your

489
00:31:37,390 --> 00:31:41,470
configuration, then you'll get the best model based

490
00:31:41,540 --> 00:31:44,750
on the objective metric target.

491
00:31:45,090 --> 00:31:48,862
So if the target is validation area under

492
00:31:48,916 --> 00:31:52,880
the curve, then it will select the model

493
00:31:53,430 --> 00:31:57,682
with the best value for it. The next one would

494
00:31:57,736 --> 00:32:00,610
be ML explainability.

495
00:32:01,670 --> 00:32:04,926
So of course there's a

496
00:32:04,968 --> 00:32:08,454
way for us CTO know which features are

497
00:32:08,492 --> 00:32:13,094
important without having to understand the

498
00:32:13,132 --> 00:32:16,450
actual algorithm. There's a difference between interpretability

499
00:32:16,530 --> 00:32:19,866
and explainability, but with explainability it

500
00:32:19,888 --> 00:32:23,562
will allow us to know which

501
00:32:23,616 --> 00:32:28,090
features actually contributed the most to an existing

502
00:32:28,510 --> 00:32:32,126
output to an output. So if

503
00:32:32,148 --> 00:32:35,642
you look at the screen here, we have feature one and feature

504
00:32:35,706 --> 00:32:39,520
zero, the first two features contributing the most

505
00:32:39,970 --> 00:32:43,426
to the actual output. And feature two and

506
00:32:43,448 --> 00:32:47,522
feature three did not really contribute much to the

507
00:32:47,656 --> 00:32:51,826
output, meaning that if we have new data,

508
00:32:52,008 --> 00:32:55,246
there's no point changing the values for feature

509
00:32:55,278 --> 00:32:59,106
two and feature three because they don't really contribute to the final outcome.

510
00:32:59,218 --> 00:33:03,090
So if there are production columns and then there's a target column,

511
00:33:03,250 --> 00:33:07,042
we're pretty sure that feature one and feature zero contributes

512
00:33:07,106 --> 00:33:11,174
the most CTo the final outcome. So how do we prepare

513
00:33:11,222 --> 00:33:14,346
something like this? We prepare something like

514
00:33:14,368 --> 00:33:17,494
this and get this type of output using shaft

515
00:33:17,542 --> 00:33:20,880
values. So shaft values help us

516
00:33:21,490 --> 00:33:25,920
understand the output and the model better.

517
00:33:27,410 --> 00:33:30,782
So how do you do that? With Sagemaker, we do that

518
00:33:30,836 --> 00:33:34,594
by just configuring the

519
00:33:34,632 --> 00:33:38,082
ML explainability job. So you

520
00:33:38,136 --> 00:33:42,050
initialize the sagemaker, clarify processes,

521
00:33:43,030 --> 00:33:48,214
you configure the

522
00:33:48,252 --> 00:33:52,086
data config and the shap config objects and

523
00:33:52,108 --> 00:33:55,490
these. After that you use the run explainability

524
00:33:55,570 --> 00:33:59,554
function and wait for probably three to seven minutes

525
00:33:59,692 --> 00:34:03,914
to get that completed, depending on the size of your data and

526
00:34:03,952 --> 00:34:07,466
these type of instances that you're using. So after three

527
00:34:07,488 --> 00:34:10,300
to seven minutes, you'll get something like this,

528
00:34:11,070 --> 00:34:14,286
and then you'll be surprised. Okay, I didn't have

529
00:34:14,308 --> 00:34:18,046
to learn much about shaft values, but with just using a couple of

530
00:34:18,068 --> 00:34:21,838
lines of code, I got what I needed. And you

531
00:34:21,844 --> 00:34:25,554
can use that to further improve your analysis of

532
00:34:25,592 --> 00:34:29,314
your experiments. So next, let's now talk

533
00:34:29,352 --> 00:34:31,890
about deployments.

534
00:34:33,110 --> 00:34:36,354
The advantage of using Sagemaker

535
00:34:36,482 --> 00:34:40,454
would be that it has great integration with

536
00:34:40,492 --> 00:34:44,710
the other services and features of AWS.

537
00:34:45,370 --> 00:34:48,854
Of course, you may have your own tech stack

538
00:34:48,902 --> 00:34:53,034
for it, but you'll be surprised that Sagemaker probably has

539
00:34:53,232 --> 00:34:56,438
some sort of integration, let's say with kubernetes,

540
00:34:56,614 --> 00:34:59,946
or even with lambda and so on, or if

541
00:34:59,968 --> 00:35:03,166
you're dealing with a new service,

542
00:35:03,268 --> 00:35:06,554
let's say app runner or something. You'll be surprised

543
00:35:06,602 --> 00:35:10,174
that you can deploy sagemaker models there, and even

544
00:35:10,212 --> 00:35:14,346
in easy to instances. But let's start first with a couple of examples

545
00:35:14,378 --> 00:35:17,940
and patterns which may be applicable to you already.

546
00:35:18,550 --> 00:35:21,570
The first one would be deploying the model inside these lambda function,

547
00:35:21,640 --> 00:35:24,494
so you will save a lot of cost there. But of course there are trade

548
00:35:24,542 --> 00:35:28,146
offs and you won't be able to use the other sagemaker features with the lambda

549
00:35:28,178 --> 00:35:32,290
function. But it's really good for simplified

550
00:35:32,450 --> 00:35:36,502
model deployments. We can also create

551
00:35:36,556 --> 00:35:40,314
a lambda function that triggers an existing sagemaker endpoint, so that you can

552
00:35:40,352 --> 00:35:43,866
prepare and process your data first inside the lambda function,

553
00:35:44,048 --> 00:35:47,802
and then trigger the sagemaker endpoint, and then process the data

554
00:35:47,856 --> 00:35:51,754
again before returning it back to the user. So you can combine

555
00:35:51,802 --> 00:35:57,486
lambda and API Gateway to help abstract the

556
00:35:57,508 --> 00:36:00,906
request and response calls before passing it to the sagemaker

557
00:36:00,938 --> 00:36:04,494
endpoint. The third one in the list is the API gateway

558
00:36:04,542 --> 00:36:07,966
mapping templates, where you won't need a lambda

559
00:36:07,998 --> 00:36:11,330
function at all to trigger a sagemaker endpoint.

560
00:36:11,910 --> 00:36:15,198
The fourth one involves deploying the model

561
00:36:15,304 --> 00:36:19,458
in Fargate, and you'll be able to use containers

562
00:36:19,634 --> 00:36:23,558
there in Fargate. Here's the cool thing here.

563
00:36:23,724 --> 00:36:26,866
If you were CTO, make the most out of Sagemaker.

564
00:36:26,978 --> 00:36:31,242
There's a lot of features and capabilities there,

565
00:36:31,376 --> 00:36:34,940
which just requires probably three to four lines of code,

566
00:36:35,550 --> 00:36:39,114
and you'll be able to get something like this. So the first one would be

567
00:36:39,152 --> 00:36:42,746
Sagemaker multimodal endpoint. Of course, it would be weird

568
00:36:42,778 --> 00:36:46,862
to have a set up where you have one

569
00:36:46,996 --> 00:36:50,554
endpoint for each model. You'll realize

570
00:36:50,602 --> 00:36:54,254
that you can actually optimize this and have, let's say, three models

571
00:36:54,302 --> 00:36:57,826
deployed in a single endpoint. And it not only will it

572
00:36:57,848 --> 00:37:01,746
help you reduce cost, it also enable you to perform

573
00:37:01,928 --> 00:37:05,806
other cool things. Let's say a b testing where you're

574
00:37:05,838 --> 00:37:09,254
deploying let's say two models at the same time, and then

575
00:37:09,372 --> 00:37:13,206
you're trying to check which model is performing better. And you can

576
00:37:13,228 --> 00:37:17,026
also deploy a model inside a lambda function with the lambda functions

577
00:37:17,058 --> 00:37:20,474
container support. So there are a lot of variations here.

578
00:37:20,592 --> 00:37:23,578
And being aware of these variations is the first step.

579
00:37:23,744 --> 00:37:27,670
And having the developers skills to customize the solution

580
00:37:27,830 --> 00:37:31,434
is the second step, especially once you need to customize

581
00:37:31,482 --> 00:37:35,306
things a bit based on your use case. Now let's

582
00:37:35,338 --> 00:37:39,338
talk about workflows. So work automated workflows

583
00:37:39,434 --> 00:37:43,794
are very important because you

584
00:37:43,832 --> 00:37:47,042
don't want to run your experiments manually every single

585
00:37:47,096 --> 00:37:50,626
time. Of course, at the start you

586
00:37:50,648 --> 00:37:54,514
will be running these steps manually because

587
00:37:54,552 --> 00:37:58,086
you'll be experiments if it will work or not. But once you need to,

588
00:37:58,108 --> 00:38:02,322
let's say, retrain your model, it would be really tedious

589
00:38:02,386 --> 00:38:06,118
to do that every month or every two weeks and

590
00:38:06,204 --> 00:38:10,250
running the experiment again and again. What if there's some sort of

591
00:38:10,320 --> 00:38:13,402
automated script or automated pipeline which

592
00:38:13,456 --> 00:38:17,402
helps you perform these steps without you

593
00:38:17,456 --> 00:38:20,960
having to do it manually? So for example,

594
00:38:21,490 --> 00:38:25,006
after one month there's data uploaded in an s

595
00:38:25,028 --> 00:38:28,174
three bucket or storage. You want your

596
00:38:28,212 --> 00:38:31,950
automated workflow to run. And if these model

597
00:38:32,020 --> 00:38:35,300
is, let's say, better than your existing model,

598
00:38:36,230 --> 00:38:39,554
then you replace it. And yeah,

599
00:38:39,592 --> 00:38:43,074
you can do it automatically with the different options available with

600
00:38:43,112 --> 00:38:46,246
Sagemaker. So this is these first one. So this is a very

601
00:38:46,268 --> 00:38:50,306
simplified example. Of course, we won't discuss the more complex examples

602
00:38:50,338 --> 00:38:53,922
here, but these are the building blocks to help you prepare

603
00:38:53,986 --> 00:38:57,542
those more complex examples. So here

604
00:38:57,596 --> 00:39:01,926
this is using to help you prepare a linear workflow

605
00:39:02,038 --> 00:39:04,954
where you have the training step,

606
00:39:05,152 --> 00:39:08,826
the build step, and then the deploy step. With just a couple of lines of

607
00:39:08,848 --> 00:39:12,550
code and using the sagemaker SDK

608
00:39:12,630 --> 00:39:17,130
and the step functions, data science SDK,

609
00:39:17,470 --> 00:39:21,054
we'll be able to make use of two services, the first one

610
00:39:21,092 --> 00:39:24,526
being sagemaker and then the second one being the data science

611
00:39:24,558 --> 00:39:27,634
SDK. And with very

612
00:39:27,672 --> 00:39:31,860
minimal changes in your existing sagemaker code,

613
00:39:32,230 --> 00:39:35,654
you'll be able to create a pipeline like this

614
00:39:35,692 --> 00:39:39,030
one. And you can make use of the

615
00:39:39,100 --> 00:39:43,314
features of step functions to help you debug

616
00:39:43,442 --> 00:39:47,910
and keep track of the different steps being executed

617
00:39:48,910 --> 00:39:51,450
during the execution phase.

618
00:39:52,510 --> 00:39:56,534
The second option would be to use sagemaker

619
00:39:56,582 --> 00:39:59,770
pipelines. So with Sagemaker pipelines,

620
00:40:00,850 --> 00:40:04,478
you can do the same set of things as what you

621
00:40:04,484 --> 00:40:07,742
can do with the sagemaker and data

622
00:40:07,796 --> 00:40:11,246
science SDK combo. But here you

623
00:40:11,268 --> 00:40:14,718
can make use of the dedicated sagemaker pipelines to help you prepare

624
00:40:14,734 --> 00:40:17,970
your model. So this one came in much later,

625
00:40:18,120 --> 00:40:21,458
after more people have requested for it. And you

626
00:40:21,464 --> 00:40:24,754
can see here that, wow, you can have an

627
00:40:24,792 --> 00:40:28,386
interface, a UI chart

628
00:40:28,498 --> 00:40:31,942
or graph like this, and you will know what's happening

629
00:40:31,996 --> 00:40:35,880
in each step. And let's say that you want to know

630
00:40:36,730 --> 00:40:40,278
the details after each step has executed,

631
00:40:40,294 --> 00:40:43,978
let's say the metrics during the train step. Then you

632
00:40:43,984 --> 00:40:48,474
can just click on these train step box

633
00:40:48,592 --> 00:40:52,714
and then you'll see the metrics and these other details

634
00:40:52,762 --> 00:40:56,574
there. So this is the source code for

635
00:40:56,612 --> 00:41:00,350
it. You'll see here that with just a couple of lines of code

636
00:41:00,420 --> 00:41:04,426
added to your existing initial Sagemaker

637
00:41:04,458 --> 00:41:08,494
SDK code, you'll be able to create the different steps.

638
00:41:08,542 --> 00:41:11,998
So most likely probably two lines of code, two to three lines

639
00:41:12,014 --> 00:41:15,800
of code for each block. So let's say that you have

640
00:41:16,490 --> 00:41:20,086
the processing step and then you have the train step. Then probably

641
00:41:20,188 --> 00:41:23,474
you'll need four additional

642
00:41:23,522 --> 00:41:28,282
lines of code because of course, in addition to the original code

643
00:41:28,336 --> 00:41:31,802
that you have, where you have configured the different step, let's say

644
00:41:31,856 --> 00:41:36,010
estimator initialization, Sklearn processes

645
00:41:36,350 --> 00:41:39,466
initialization step. These, you will make use of these

646
00:41:39,488 --> 00:41:43,178
sagemaker pipeline's counterpart objects,

647
00:41:43,354 --> 00:41:46,794
and you will link those and then just chain

648
00:41:46,842 --> 00:41:50,542
those AWS you can see here, create a chain and

649
00:41:50,596 --> 00:41:53,730
prepare the pipeline by combining all the other steps.

650
00:41:54,710 --> 00:41:58,530
And in order to run this, all you need to do is run these execute

651
00:41:58,950 --> 00:42:03,026
function. So there, that's pretty cool.

652
00:42:03,208 --> 00:42:06,530
And you'll see that the more you

653
00:42:06,600 --> 00:42:10,242
use a certain platform like

654
00:42:10,296 --> 00:42:13,826
Sagemaker, you'll realize that, hey, there's a patterns.

655
00:42:14,018 --> 00:42:17,960
If I need something like this, I won't have to worry about

656
00:42:18,410 --> 00:42:21,738
changing the other parts of the code because it's probably just

657
00:42:21,824 --> 00:42:25,660
a configuration code change away. So again,

658
00:42:26,110 --> 00:42:29,466
I'm going to share this slide again so that you can have

659
00:42:29,488 --> 00:42:33,450
a quick look at the different features and capabilities of Sagemaker.

660
00:42:33,610 --> 00:42:37,534
But what I will tell you is that Sagemaker continues to

661
00:42:37,572 --> 00:42:39,840
evolve, even today,

662
00:42:40,770 --> 00:42:44,786
probably in one month there's a new release or

663
00:42:44,808 --> 00:42:48,130
new capability or new upgrade CTO existing features,

664
00:42:48,790 --> 00:42:51,794
and it's better for us to stay tuned there by,

665
00:42:51,832 --> 00:42:55,470
let's say, checking the AWS blog. And yeah,

666
00:42:55,640 --> 00:42:59,670
so again, it's not just powerful, it's also

667
00:42:59,820 --> 00:43:03,174
evolving. And the great thing here is that the more

668
00:43:03,212 --> 00:43:06,342
features and capabilities that you're aware of,

669
00:43:06,476 --> 00:43:09,882
the more you can make use of Sagemaker and

670
00:43:09,936 --> 00:43:13,820
further reduce cost, because the importance of

671
00:43:14,990 --> 00:43:19,034
a good professional would

672
00:43:19,072 --> 00:43:22,298
be his or her own ability

673
00:43:22,474 --> 00:43:25,886
to optimize and solve things using the

674
00:43:25,908 --> 00:43:29,790
knowledge and expertise using specific tools.

675
00:43:30,610 --> 00:43:34,398
So again, thank you very much and hope you learned a lot

676
00:43:34,404 --> 00:43:38,158
of things during my talk, and feel free to check out my book

677
00:43:38,324 --> 00:43:42,062
machine learning with Amazon Sagemaker cookbook because that will help

678
00:43:42,116 --> 00:43:45,794
you understand Sagemaker better with the 80

679
00:43:45,842 --> 00:43:49,650
recipes there, which are super simplified

680
00:43:49,810 --> 00:43:54,482
to help you understand something, even if it's your first time using sagemaker.

681
00:43:54,626 --> 00:43:58,260
So there. Thank you again and have a great day ahead.

