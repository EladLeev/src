1
00:00:00,410 --> 00:00:06,126
Jamaica make up real

2
00:00:06,148 --> 00:00:09,902
time feedback into the behavior of your distributed systems and

3
00:00:09,956 --> 00:00:13,374
observing changes exceptions errors in

4
00:00:13,412 --> 00:00:16,666
real time allows you to not only experiment with confidence,

5
00:00:16,778 --> 00:00:20,480
but respond instantly to get things working again.

6
00:00:24,610 --> 00:01:05,746
Close is

7
00:01:05,768 --> 00:01:08,834
a security regression testing CLI that's the front end

8
00:01:08,872 --> 00:01:12,386
and software has a service backend targeting web

9
00:01:12,408 --> 00:01:16,230
applications and APIs specifically built for developers.

10
00:01:16,650 --> 00:01:20,470
The CLI is specifically targeted at sitting within your build pipelines

11
00:01:20,810 --> 00:01:24,550
has if you're running it headless, but can also be runs manually

12
00:01:25,370 --> 00:01:28,614
with a character user interface. You can choose

13
00:01:28,652 --> 00:01:32,618
from either local and or cloud environments. If you

14
00:01:32,624 --> 00:01:36,058
go with the local environment, you'll need to set up both front end that's the

15
00:01:36,064 --> 00:01:39,546
CLI and backend microservices. If you choose the

16
00:01:39,568 --> 00:01:43,134
cloud, all you need to do is get the CLI on your system you want

17
00:01:43,172 --> 00:01:46,782
to run and configure it and create a job

18
00:01:46,836 --> 00:01:47,550
file.

19
00:01:52,290 --> 00:01:55,406
So it's been a four year journey that has brought Purpleteam from a proof

20
00:01:55,438 --> 00:01:59,458
of concept to where it is now finished writing a

21
00:01:59,464 --> 00:02:04,882
book series to help developers upskill their security and

22
00:02:05,016 --> 00:02:08,674
I can lots of workshops with the proof of concept from

23
00:02:08,712 --> 00:02:12,778
that book holistic and Vasec

24
00:02:12,814 --> 00:02:16,406
for web developers to elicit developer feedback and confirm that

25
00:02:16,428 --> 00:02:18,300
what I wrote but was actually true.

26
00:02:20,430 --> 00:02:24,486
Now these are the books I've written. Youre noticed

27
00:02:24,518 --> 00:02:28,694
the holistic infosec for web developers

28
00:02:28,742 --> 00:02:32,458
series there. Now this is the actual website

29
00:02:32,544 --> 00:02:36,318
for it. You can read these books freely online or you

30
00:02:36,324 --> 00:02:39,882
can decide to buy them if you really like them. So the prefer

31
00:02:39,946 --> 00:02:45,362
concept that Purpleteam was born out of was in

32
00:02:45,416 --> 00:02:49,234
this first volume. Most of the time it's been seven days

33
00:02:49,272 --> 00:02:52,050
a week and it's been two full time jobs.

34
00:02:52,710 --> 00:02:55,970
I donated purple team local to OWASp in

35
00:02:56,040 --> 00:03:00,070
quarter one of 2021. Purple Team Cloud

36
00:03:00,140 --> 00:03:03,494
went to market in Q four of 2021.

37
00:03:03,692 --> 00:03:07,506
I couldn't get the publicity that was needed to get enough customers on

38
00:03:07,548 --> 00:03:11,546
board to make cloud financially viable. Plus, family relationships were

39
00:03:11,568 --> 00:03:15,526
getting strained. So I donated cloud to OWASp

40
00:03:15,558 --> 00:03:18,540
in Q one 2022.

41
00:03:19,550 --> 00:03:23,630
So now the community gets to reap the benefits of a production ready, hosted security

42
00:03:23,700 --> 00:03:27,054
aggression testing software as a service that you can plug into your build

43
00:03:27,092 --> 00:03:30,990
pipelines to continuously test your web applications and APIs.

44
00:03:31,410 --> 00:03:34,638
Building a tool that helps developers write secure code is a great way to

45
00:03:34,644 --> 00:03:37,810
learn about security. If you want to learn more about information

46
00:03:37,880 --> 00:03:41,778
security, we can assign you a mentor and you can help yourself

47
00:03:41,864 --> 00:03:45,060
and the community by building purple team with us.

48
00:03:45,750 --> 00:03:49,286
Now this is a high level architectural overview of the

49
00:03:49,308 --> 00:03:53,186
purple team solution in the cloud. This is the same, but run locally

50
00:03:53,218 --> 00:03:56,742
in the local environment. So what you've got here

51
00:03:56,796 --> 00:04:00,246
is you've got the backend components, you've got the orchestrator,

52
00:04:00,278 --> 00:04:03,878
which takes the requests from the CLI

53
00:04:03,974 --> 00:04:07,750
and sends feedback back to the CLI

54
00:04:07,910 --> 00:04:11,260
too. On what's happening with the application,

55
00:04:12,510 --> 00:04:16,266
sorry, on what's happening with the testers. Now, I've got an application tester,

56
00:04:16,298 --> 00:04:19,150
we've got a server tester and we've got a TLS tester.

57
00:04:20,050 --> 00:04:23,190
This is your system under test. This is the Internet.

58
00:04:23,370 --> 00:04:27,826
Now, what happens when you send a job file through from the CLI is

59
00:04:27,848 --> 00:04:31,810
the orchestrator takes that, it sends it to the testers.

60
00:04:33,030 --> 00:04:36,798
Now, with our server scanner

61
00:04:36,814 --> 00:04:40,386
and TLS scanner, the emissaries sit within their containers,

62
00:04:40,418 --> 00:04:43,698
they're embedded. Server scanner is not yet implemented, but it's

63
00:04:43,714 --> 00:04:47,058
going to be soon and we're going to be using Nikto. TLS scanner

64
00:04:47,074 --> 00:04:50,620
is all up and running and it's been in production for quite a few months

65
00:04:51,630 --> 00:04:55,466
now. The application scanner, based on the

66
00:04:55,488 --> 00:04:58,406
number of test sessions that are sent through in the job file from the CLI

67
00:04:58,438 --> 00:05:03,082
to the orchestrator, we spin up that number of emissary

68
00:05:03,146 --> 00:05:07,038
sets. These are your stage two containers, these are

69
00:05:07,044 --> 00:05:11,022
your stage one containers. We spin up n number

70
00:05:11,076 --> 00:05:12,990
of Zapp and seleniums.

71
00:05:13,970 --> 00:05:18,846
And the way this is done is that the application tester talks

72
00:05:18,878 --> 00:05:22,594
to in the local environment. It's Sam CLI. In the cloud it's just

73
00:05:22,632 --> 00:05:26,600
lambda and we've got our lambda functions there which spin up

74
00:05:27,290 --> 00:05:31,350
the zap and selenium containers using Docker compose UI

75
00:05:31,690 --> 00:05:34,070
in the cloud, it's just ecs.

76
00:05:35,370 --> 00:05:39,370
Now, as feedback comes back from the emissaries,

77
00:05:40,190 --> 00:05:43,974
the testers are responsible for sending that feedback, for grooming

78
00:05:44,022 --> 00:05:46,890
it and sending it through redis.

79
00:05:47,630 --> 00:05:51,354
And then the orchestrator subscribes to our redis

80
00:05:51,402 --> 00:05:55,246
channels. Now, if we're using a long pollen between the

81
00:05:55,268 --> 00:05:59,194
CLI and the orchestrator, the orchestrator pushes those messages

82
00:05:59,242 --> 00:06:02,686
back onto a list so that when the

83
00:06:02,708 --> 00:06:05,978
CLI long poll requests come in, the orchestrator can pop those off the

84
00:06:06,004 --> 00:06:09,118
list and send them back in batches. If we're

85
00:06:09,134 --> 00:06:12,386
using server sent events, then as soon as the messages come in

86
00:06:12,408 --> 00:06:16,050
from Redis, they are sent back in real time to the CLI.

87
00:06:16,950 --> 00:06:20,134
For all intents and purposes, it doesn't make a lot of difference

88
00:06:20,332 --> 00:06:24,198
which one of these you use. There are small pros and cons on each

89
00:06:24,284 --> 00:06:28,054
and it's configurable in the config

90
00:06:28,102 --> 00:06:31,738
for the orchestrator. Once the application testers are

91
00:06:31,744 --> 00:06:36,134
finished their testing, they talk to Sam ClI

92
00:06:36,182 --> 00:06:39,718
or lambda if it's in AWS again, which runs

93
00:06:39,734 --> 00:06:43,334
another lambda function to bring these containers

94
00:06:43,382 --> 00:06:46,810
down. How does pipelines help us as developers?

95
00:06:47,390 --> 00:06:51,150
How does pipelines help us as a business that creates software?

96
00:06:51,490 --> 00:06:54,450
And why would I want Purpleteam in my build pipelines?

97
00:06:55,030 --> 00:06:58,226
To answer these questions, I'm going to take you back to a section that's in

98
00:06:58,248 --> 00:07:01,794
a number of my previous talks have

99
00:07:01,832 --> 00:07:05,250
we found bugs in software traditionally?

100
00:07:06,550 --> 00:07:10,162
Basically, we haven't really, or we've done it really

101
00:07:10,216 --> 00:07:14,686
late. So every

102
00:07:14,728 --> 00:07:18,246
team has a week or two to find all the defects we've been conscientiously adding

103
00:07:18,278 --> 00:07:22,442
for months. So it's approximately $20,000

104
00:07:22,576 --> 00:07:26,026
per week. The engagement is generally two

105
00:07:26,048 --> 00:07:29,610
weeks for a small to medium web application or API,

106
00:07:31,330 --> 00:07:34,542
the software project, before release. It's about six months

107
00:07:34,676 --> 00:07:38,382
for the same size project, and it's about $40,000

108
00:07:38,516 --> 00:07:41,360
for the six months per project.

109
00:07:42,710 --> 00:07:45,998
So generally, five criticals, ten highs, ten mediums,

110
00:07:46,094 --> 00:07:49,060
and ten low severity bugs are going to be found,

111
00:07:49,830 --> 00:07:53,410
and many bugs are left waiting to be exploited.

112
00:07:54,390 --> 00:07:58,070
The business decides to only fix the five criticals,

113
00:07:58,410 --> 00:08:02,646
and each bug now has an average cost of 15 plus times what

114
00:08:02,668 --> 00:08:05,846
it would have cost to fix if it was found and fixed when it

115
00:08:05,868 --> 00:08:09,174
was introduced. So that's five bugs

116
00:08:09,222 --> 00:08:12,746
times 15, times $320, which is approximately two

117
00:08:12,768 --> 00:08:16,860
developer hours, is $24,000.

118
00:08:17,310 --> 00:08:20,780
So the bottom line for a six months project,

119
00:08:21,710 --> 00:08:25,034
youre going to have a two weeks red teaming engagement that'll

120
00:08:25,082 --> 00:08:28,686
cost you about $40,000. Now, only five red

121
00:08:28,708 --> 00:08:32,560
team bugs are going to be fixed at a cost of 24,000.

122
00:08:33,730 --> 00:08:37,038
So the bottom line, this is too expensive, it's too late,

123
00:08:37,134 --> 00:08:40,974
and too many bugs are left unfixed because it's now so late in the software

124
00:08:41,022 --> 00:08:44,210
development lifecycle. And each bug now costs 15

125
00:08:44,280 --> 00:08:47,878
tips, plus what it would have cost defined and

126
00:08:47,884 --> 00:08:51,174
fixed if it was found and fixed when it was introduced. Now,

127
00:08:51,212 --> 00:08:54,470
these are based on statistics that I documented

128
00:08:54,810 --> 00:08:58,360
in holistic infosec for web developers. That's my book,

129
00:08:59,290 --> 00:09:01,690
taken from various sources.

130
00:09:03,310 --> 00:09:07,754
Instead of deferring the finding and fixing of security defects to

131
00:09:07,792 --> 00:09:10,918
a traditional red teaming exercise, Purpleteam helps

132
00:09:10,934 --> 00:09:14,574
us find and fix our defects as we're creating them. But how,

133
00:09:14,612 --> 00:09:17,978
you might ask? So Purpleteam runs against our web applications

134
00:09:17,994 --> 00:09:21,802
and APIs has we're creating them, informing us of security defects

135
00:09:21,946 --> 00:09:25,790
that we're introducing in close to real time. So Purpleteam

136
00:09:25,870 --> 00:09:30,146
reports show us how to reproduce the attacks that

137
00:09:30,168 --> 00:09:33,262
were found, and they also provide tips

138
00:09:33,326 --> 00:09:36,642
on how not to introduce the same types of vulnerabilities.

139
00:09:36,706 --> 00:09:37,320
Again,

140
00:09:42,170 --> 00:09:44,390
so now we know we need purple tank.

141
00:09:45,530 --> 00:09:49,366
So for the local setup we're going to be looking at local and

142
00:09:49,388 --> 00:09:52,938
cloud. So for the local setup we get to the setup page and

143
00:09:52,944 --> 00:09:55,450
we're going to work through these components.

144
00:09:56,670 --> 00:10:00,138
So again, we've got the high level architectural overview there

145
00:10:00,224 --> 00:10:02,170
of the local environment.

146
00:10:03,630 --> 00:10:07,006
So wei need to set up a docker network. These are the details on how

147
00:10:07,028 --> 00:10:10,254
to do that. And you're going to need a system under test.

148
00:10:10,292 --> 00:10:13,706
This is the system that you want to be security testing.

149
00:10:13,818 --> 00:10:17,198
If you don't have one at the moment and you're just wanting to get a

150
00:10:17,204 --> 00:10:20,478
take pearl protein for a spin to see how it goes, then we'd

151
00:10:20,494 --> 00:10:24,286
suggest using something like Owasp node goat.

152
00:10:24,398 --> 00:10:28,098
Now we use this as well and we've got a document

153
00:10:28,114 --> 00:10:31,734
bose override that you can use to help you get

154
00:10:31,772 --> 00:10:35,878
going. And there's also Purpleteam infrastructure has code system under test

155
00:10:35,964 --> 00:10:39,446
which basically brings up and brings down node

156
00:10:39,478 --> 00:10:42,940
goat very quickly with a clean slate each time.

157
00:10:44,030 --> 00:10:47,626
So you need to set up your lambda functions. The details on

158
00:10:47,648 --> 00:10:50,990
the readme page here, stage two containers.

159
00:10:51,330 --> 00:10:54,682
The details on the readme for the stage two containers

160
00:10:54,746 --> 00:10:58,746
there, these are all in GitHub, the orchestrator

161
00:10:58,778 --> 00:11:02,154
as well. For the orchestrator there's a couple of environment

162
00:11:02,202 --> 00:11:06,542
variables that you need to set up. You need to apply some permissions

163
00:11:06,606 --> 00:11:10,834
to directories and

164
00:11:10,872 --> 00:11:14,446
if you've got a firewall running, you'll need to ideally

165
00:11:14,478 --> 00:11:18,386
set up some firewall rules. You will need to set up some firewall

166
00:11:18,418 --> 00:11:21,906
rules and you'll need host ip forwarding turned

167
00:11:21,938 --> 00:11:25,158
on. Some details there around that. Now for the

168
00:11:25,164 --> 00:11:28,374
testers we've got the application scanner, we've got the TLS

169
00:11:28,422 --> 00:11:31,750
scanner and the server scanner which is not yet implemented.

170
00:11:31,910 --> 00:11:35,820
So the details for setting these up are in their

171
00:11:36,430 --> 00:11:40,246
readmes. Same for the Purpleteam

172
00:11:40,278 --> 00:11:42,460
CLI, which I'm going to show you now.

173
00:11:44,050 --> 00:11:47,018
So if you're using the cloud environment,

174
00:11:47,194 --> 00:11:50,878
then all you need to do is set up the CLI. You won't need to

175
00:11:50,884 --> 00:11:53,940
set up any of those backend components because they're all done for you.

176
00:11:55,670 --> 00:11:57,620
So the CLi install options.

177
00:11:58,630 --> 00:12:01,758
There's three options here. So if you're planning

178
00:12:01,774 --> 00:12:04,914
on running or debugging purp standalone with

179
00:12:04,952 --> 00:12:09,206
a UI, this is a good option for

180
00:12:09,228 --> 00:12:12,386
this option here. This is good if you're planning on running or debugging

181
00:12:12,418 --> 00:12:16,438
purp as a spawned NodeJs process, for example

182
00:12:16,524 --> 00:12:19,866
from your node JS build pipelines. So yeah, you can

183
00:12:19,968 --> 00:12:24,554
run it and debug it as well. And this

184
00:12:24,592 --> 00:12:28,314
NPM install globally option is good if you're planning on running

185
00:12:28,352 --> 00:12:32,190
or debugging purpleteam from a build pipeline written in a different

186
00:12:32,260 --> 00:12:35,438
language, and you need to configure the

187
00:12:35,444 --> 00:12:38,880
CLI. So that's the configuring details there.

188
00:12:40,370 --> 00:12:43,826
And this is where you work out or you define whether you want

189
00:12:43,848 --> 00:12:47,170
to run headless or with a kiwi.

190
00:12:48,470 --> 00:12:53,010
And some details around the job file there, which is also found in the documentation,

191
00:12:53,990 --> 00:12:57,318
in the documentation on the Purpleteam labs.com website.

192
00:12:57,484 --> 00:12:59,320
There's a lot more information there.

193
00:13:00,810 --> 00:13:04,790
And these are just the run sections, how you actually go about running the CLI.

194
00:13:14,010 --> 00:13:17,660
So these are the sections in that readmute are just a little bit further down

195
00:13:18,030 --> 00:13:21,262
than what I just showed you. So for those three

196
00:13:21,316 --> 00:13:24,320
options, whichever one of those you picked to install,

197
00:13:26,130 --> 00:13:29,726
there's an associated run option that you can

198
00:13:29,748 --> 00:13:33,300
use to work out how you're going to run the CLI. It's pretty simple.

199
00:13:40,150 --> 00:13:43,746
If you're training in the cloud, then job done. All you have to do is

200
00:13:43,768 --> 00:13:47,734
have that ClI on your system and

201
00:13:47,772 --> 00:13:51,074
configured and have a job file ready to feed

202
00:13:51,122 --> 00:13:51,720
it.

203
00:13:56,330 --> 00:14:00,154
If you're using local, then there's a little bit more to know about running

204
00:14:00,192 --> 00:14:01,690
the back end components.

205
00:14:03,470 --> 00:14:07,146
So the back end components workflow, this is

206
00:14:07,168 --> 00:14:10,638
documentation for it steps you through these

207
00:14:10,804 --> 00:14:11,710
sections.

208
00:14:16,770 --> 00:14:20,554
So there's some details here around. If youre actually want to test the lambdas

209
00:14:20,602 --> 00:14:23,886
themselves, generally you won't

210
00:14:23,918 --> 00:14:27,214
need to do that. Just if you are contributing

211
00:14:27,262 --> 00:14:33,154
to the Purpleteam M project and

212
00:14:33,192 --> 00:14:37,350
debugging lambdas, you probably won't need to know that unless youre actually contributing.

213
00:14:42,330 --> 00:14:45,810
Yeah, so this is the debugging section, the main debugging section.

214
00:14:45,890 --> 00:14:50,958
So this is details on how to debug the application scanner and subprocesses.

215
00:14:51,074 --> 00:14:55,146
So that's the subprocessors that spin up the stage two containers which have

216
00:14:55,248 --> 00:15:01,134
cucumber in it as

217
00:15:01,172 --> 00:15:04,814
well. And same

218
00:15:04,852 --> 00:15:08,014
for the other testers, the orchestrator is the same, just that there's no sub

219
00:15:08,052 --> 00:15:11,886
process. And for the front end, this is how

220
00:15:11,908 --> 00:15:16,062
you run the front end. Also, there's some details around this

221
00:15:16,196 --> 00:15:21,058
in the readme of the Purpleteam CLI that

222
00:15:21,064 --> 00:15:24,660
we've already looked at, but this is just a little bit more details here.

223
00:15:27,190 --> 00:15:30,438
Full system run these are the actual steps for the full system run.

224
00:15:30,524 --> 00:15:34,742
So this is starting your CLI and having

225
00:15:34,796 --> 00:15:38,502
all the backend components set up and running, ready to accept

226
00:15:38,646 --> 00:15:41,754
requests. I'm going to walk through this

227
00:15:41,872 --> 00:15:42,540
soon.

228
00:15:48,430 --> 00:15:51,734
Hi. Today I'm going to show you a test run

229
00:15:51,872 --> 00:15:55,582
with the backend components as well. I'm starting

230
00:15:55,636 --> 00:15:58,640
docker stats to show you which containers are coming and going.

231
00:15:59,410 --> 00:16:03,406
We start docker compose Ui, which is responsible for taking orders from our lambda

232
00:16:03,438 --> 00:16:06,770
functions to start and stop the stage two containers.

233
00:16:07,510 --> 00:16:11,406
Wei start Sam local, which is responsible for hosting our lambda functions

234
00:16:11,438 --> 00:16:15,234
locally and we already have

235
00:16:15,272 --> 00:16:19,026
our system under test running. Now once we've built our stage

236
00:16:19,138 --> 00:16:22,422
one images with NPM run DC build,

237
00:16:22,556 --> 00:16:27,046
we can bring them up with NPM run DC up and

238
00:16:27,068 --> 00:16:30,346
then we start the CLI. In the bottom left terminal you can

239
00:16:30,368 --> 00:16:34,118
see the validated, filtered and sanitized job file contents

240
00:16:34,214 --> 00:16:37,754
in the top right terminal. Docker stats is showing us the stage two

241
00:16:37,792 --> 00:16:40,854
containers being brought up in the bottom left terminal.

242
00:16:40,902 --> 00:16:44,494
We're checking and retrying that the stage two containers have come up and are

243
00:16:44,532 --> 00:16:48,014
responsive. All testers are now running as the test

244
00:16:48,052 --> 00:16:51,066
run process in the CLI tester complete panel.

245
00:16:51,098 --> 00:16:54,930
That's the donut meters youre will see the percentages progress.

246
00:16:55,670 --> 00:17:00,014
These are total percentages per tester in the running statistics

247
00:17:00,062 --> 00:17:03,646
panel just to the right of the donut meters. Each row

248
00:17:03,678 --> 00:17:06,926
represents a test session as defined in the job file.

249
00:17:07,038 --> 00:17:10,646
Here I'm training the CLI TLS tester log just

250
00:17:10,668 --> 00:17:13,906
to save right arrowing on the CLI terminal to the TLS

251
00:17:13,938 --> 00:17:17,730
tester screen and not being able to also see the app tester progress.

252
00:17:17,890 --> 00:17:21,434
Back to the running statistics panel. The thresholds you see are

253
00:17:21,472 --> 00:17:25,114
also defined in the job file as alert thresholds. A given test

254
00:17:25,152 --> 00:17:28,550
session will be considered a fail if the bug count exceeds

255
00:17:28,630 --> 00:17:32,210
the alert threshold. Alert thresholds are useful for brownfields

256
00:17:32,230 --> 00:17:35,646
projects where you have existing defects but still want a

257
00:17:35,668 --> 00:17:39,550
test to pass. These are the definitions. You may find yourself

258
00:17:39,620 --> 00:17:42,794
referring to these quite often. Back to the running statistics

259
00:17:42,842 --> 00:17:46,174
panel, you'll notice a complete column. These cells represent

260
00:17:46,222 --> 00:17:49,826
percentage complete of the test session, where you may have more

261
00:17:49,848 --> 00:17:52,610
than one of these for a given tester.

262
00:17:53,510 --> 00:17:57,314
In order to initiate a test run, the build user needs to define

263
00:17:57,362 --> 00:18:01,122
and supply a job file. This is the documentation

264
00:18:01,186 --> 00:18:04,694
that will help explain the schema and help you construct your

265
00:18:04,732 --> 00:18:05,750
job file.

266
00:18:17,620 --> 00:18:20,720
Next, I'll show you some example job files.

267
00:18:24,660 --> 00:18:27,952
This job file is very similar to the one we're using for this test

268
00:18:28,006 --> 00:18:31,836
run, except we're targeting nodegoat sut purple

269
00:18:31,868 --> 00:18:35,824
teamlabs.com, which is deployed using the purple

270
00:18:35,872 --> 00:18:38,950
team infrastructure as code system under test project.

271
00:18:41,800 --> 00:18:45,272
The new bugs panel of the CLI shows bugs over

272
00:18:45,326 --> 00:18:49,176
and above any specified alert thresholds. If this

273
00:18:49,198 --> 00:18:52,712
count is above zero, then you are going to have at least one failed test

274
00:18:52,766 --> 00:18:56,316
session. The total tester progress meter to the

275
00:18:56,338 --> 00:19:00,284
right of new bugs shows the combined progress of

276
00:19:00,322 --> 00:19:01,500
all testers.

277
00:19:09,830 --> 00:19:13,134
These logs I'm showing you are the raw CLI flows

278
00:19:13,182 --> 00:19:16,742
taken from the current finished test run. This particular log

279
00:19:16,796 --> 00:19:20,230
is from the Lowpriv user test session of the current

280
00:19:20,300 --> 00:19:23,762
test run currently being ridden to the top of the two CLI

281
00:19:23,826 --> 00:19:27,418
window panes as we speak. You'll notice that this particular

282
00:19:27,504 --> 00:19:30,806
test session is only testing a single route. The profile route

283
00:19:30,838 --> 00:19:34,442
of our system under test. This particular log

284
00:19:34,496 --> 00:19:37,834
is from the admin user test session of the current test runs

285
00:19:37,952 --> 00:19:41,438
currently being written to the bottom of the two CLI window panes as

286
00:19:41,444 --> 00:19:45,022
we speak. This test session is testing two of our system

287
00:19:45,076 --> 00:19:48,830
under test routes, the profile route followed by the memos route.

288
00:19:49,590 --> 00:19:53,090
As you can see, the server tester is currently inactive.

289
00:19:55,030 --> 00:19:58,274
Now we're looking at the TLS tester log. There is only

290
00:19:58,312 --> 00:20:00,660
ever one of these per test run.

291
00:20:03,450 --> 00:20:07,494
You'll notice the color codes in amongst the text. These are used

292
00:20:07,532 --> 00:20:11,880
to display the log text in color. We'll see how this works soon.

293
00:20:26,580 --> 00:20:30,256
We're looking at the same CLI logs as before. Tools such

294
00:20:30,278 --> 00:20:34,016
as cat less and tail, if configured correctly, will render the

295
00:20:34,038 --> 00:20:37,936
color codes. Just reiterating that these CLI logs

296
00:20:37,968 --> 00:20:41,492
are currently being written. I've just taken them from the finished test

297
00:20:41,546 --> 00:20:45,296
run. This is the lowpriv user test session CLI

298
00:20:45,328 --> 00:20:49,208
log from the application tester. As you can see this is a

299
00:20:49,214 --> 00:20:52,536
failed test session. This is the one and

300
00:20:52,558 --> 00:20:56,584
only TLS scanner test session CLI log that I showed you before,

301
00:20:56,782 --> 00:21:00,660
but with the color codes rendered, these CLI logs

302
00:21:00,740 --> 00:21:04,468
are what is printed to the CLI terminal. If you are running it in Kiwi

303
00:21:04,484 --> 00:21:08,504
mode versus no UI mode, right arrowing and left arrowing

304
00:21:08,552 --> 00:21:12,344
in the CLI terminal will switch between the different testers windows.

305
00:21:12,472 --> 00:21:15,996
As you can see, this is a failed test session. When you see the outcomes

306
00:21:16,028 --> 00:21:19,616
have been downloaded to message, that means the test run

307
00:21:19,638 --> 00:21:23,516
is complete and you can now inspect the report files generated

308
00:21:23,628 --> 00:21:27,940
by the emissaries and the result files generated by cucumber.

309
00:21:29,480 --> 00:21:33,696
This is what the outcomes archive looks like. Once it's been packed by the orchestrator

310
00:21:33,728 --> 00:21:37,044
and sent to the CLI, you'll notice the report and

311
00:21:37,082 --> 00:21:40,724
result files. This is the HTML report file

312
00:21:40,772 --> 00:21:44,600
generated by the application emissary zapproxy

313
00:21:44,940 --> 00:21:48,520
for the Lowpriv user app scanner test session.

314
00:21:48,860 --> 00:21:52,876
It lists the alerts or defects along with how they were found,

315
00:21:53,058 --> 00:21:57,230
how you can reproduce them, as well as directions for fixing them.

316
00:22:47,190 --> 00:22:50,486
This is the HTML report file generated by the application

317
00:22:50,588 --> 00:22:54,470
emissary for the Admin User app scanner test session.

318
00:23:07,660 --> 00:23:11,768
This is the HTML portfolio generated by the TLS emissary

319
00:23:11,944 --> 00:23:15,276
tests sh for the one and

320
00:23:15,298 --> 00:23:48,194
only TLS scanner

321
00:23:48,242 --> 00:23:49,190
test session.

322
00:24:20,450 --> 00:24:24,570
This is the markdown report file generated by the application emissary

323
00:24:24,730 --> 00:24:27,950
for the Admin user app scanner test session.

324
00:25:01,690 --> 00:25:05,586
This is the CSV report file generated by the TLS

325
00:25:05,618 --> 00:25:09,670
emissary for the one and only TLS scanner test session.

326
00:25:16,270 --> 00:25:19,318
Here I'm highlighting the severity levels.

327
00:25:19,494 --> 00:25:24,090
These can be one of low, medium, high, or critical.

328
00:25:25,470 --> 00:25:29,360
Refer to the job failed documentation for further details on these.

329
00:25:38,390 --> 00:25:42,814
This is the JSON report file generated by the TLS emissary

330
00:25:42,942 --> 00:25:46,230
for the one and only TLS scanner test session.

331
00:25:58,730 --> 00:26:02,898
These are the three NDJSON result files generated by cucumber

332
00:26:02,994 --> 00:26:06,326
for the three test sessions Lopriv user

333
00:26:06,358 --> 00:26:09,914
app scanner test session, admin user app scanner test

334
00:26:09,952 --> 00:26:13,770
session, and the one and only TLS scanner test session.

335
00:26:17,950 --> 00:26:21,822
The app scanner admin user test session for the profile route has

336
00:26:21,876 --> 00:26:25,726
completed. It's now starting on the memos route. The app

337
00:26:25,748 --> 00:26:29,818
scanner Lowpriv user test session for the single profile route

338
00:26:29,914 --> 00:26:33,426
has finished. The log, which is just scrolled off the screen,

339
00:26:33,528 --> 00:26:37,138
provides defect counts and details of where to look in

340
00:26:37,144 --> 00:26:40,846
the reports. This is the log and outcomes

341
00:26:40,878 --> 00:26:42,210
files documentation.

342
00:26:52,650 --> 00:26:56,594
The app scanner admin user test session for the memos route

343
00:26:56,642 --> 00:27:00,182
has completed, which means the test session it's in is

344
00:27:00,236 --> 00:27:03,574
finished. In this case, both Lowprov user and admin

345
00:27:03,622 --> 00:27:07,002
user test sessions have failed. The CLI log

346
00:27:07,056 --> 00:27:10,186
file that I showed earlier contains details of how to use the

347
00:27:10,208 --> 00:27:13,642
report files to locate and remediate the defects.

348
00:27:13,786 --> 00:27:17,034
You'll also notice that the stage two containers have been brought

349
00:27:17,082 --> 00:27:20,686
down. Now we've just right arrowed to the TLS tester to

350
00:27:20,708 --> 00:27:21,760
watch it finish.

351
00:28:08,020 --> 00:28:11,420
The test session for the TLS scanner has now finished.

352
00:28:11,580 --> 00:28:15,676
This also failed because the defect count exceeded the alert

353
00:28:15,708 --> 00:28:19,200
threshold that the build user defined in the job file.

354
00:28:19,540 --> 00:28:22,876
You may also notice that the total test of progress meter

355
00:28:22,908 --> 00:28:26,604
hasn't reached 100%. This is because the server scanner

356
00:28:26,652 --> 00:28:30,196
isn't currently enabled. As you can see, the outcomes

357
00:28:30,228 --> 00:28:33,080
files have been downloaded for you to inspect.

358
00:28:39,180 --> 00:28:42,916
We look for contributors to come and join the OWAsp purport

359
00:28:42,948 --> 00:28:47,130
team as well to help us continue to make Purpleteam awesome.

360
00:28:47,580 --> 00:28:47,830
Thanks.

