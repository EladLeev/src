1
00:00:27,330 --> 00:00:30,486
Hello everyone, I'm Karan and today I will be

2
00:00:30,508 --> 00:00:35,026
taking you on a journey into the world of serverless. With Kubernetes

3
00:00:35,218 --> 00:00:38,978
we will be diving deep into what is serverless,

4
00:00:39,154 --> 00:00:42,854
what is knative and how we can leverage this tool

5
00:00:42,972 --> 00:00:47,350
to create serverless applications right within a Kubernetes setup.

6
00:00:47,850 --> 00:00:51,614
Before getting into what is a native and how

7
00:00:51,652 --> 00:00:55,194
we can leverage this tool to create our very own serverless

8
00:00:55,242 --> 00:00:58,702
infrastructure. I would first like to cover what is

9
00:00:58,756 --> 00:01:02,110
serverless in the first place, but before

10
00:01:02,180 --> 00:01:05,714
getting into that we first need to understand what is the

11
00:01:05,832 --> 00:01:09,694
with server architecture. In the traditional

12
00:01:09,822 --> 00:01:13,394
with server architecture you first have to set

13
00:01:13,432 --> 00:01:17,718
up a virtual machine on whatever cloud provider you may be using.

14
00:01:17,884 --> 00:01:21,570
Then once that is set up, you have to deal with the configuration

15
00:01:21,650 --> 00:01:25,254
of that virtual machine, whether it is fitting your

16
00:01:25,372 --> 00:01:29,098
needs and requirements or not. Once that is done, you have to

17
00:01:29,184 --> 00:01:32,746
set up your application and not to mention that you

18
00:01:32,768 --> 00:01:36,790
have to install all the necessary tools, the configuration required

19
00:01:36,950 --> 00:01:40,586
for that application to run. And once it is up

20
00:01:40,608 --> 00:01:43,786
and running, your job is not done. You still have to maintain

21
00:01:43,818 --> 00:01:47,406
this entire setup. So over time if you start seeing

22
00:01:47,508 --> 00:01:50,606
more users using your application, you have to

23
00:01:50,628 --> 00:01:53,922
deal with the scaling of this application as well.

24
00:01:54,056 --> 00:01:58,286
So these are some of the problems that are associated

25
00:01:58,318 --> 00:02:02,242
with the with server architecture and these

26
00:02:02,296 --> 00:02:05,910
problems are addressed by the serverless architecture.

27
00:02:06,410 --> 00:02:08,930
Contrary to popular belief,

28
00:02:09,090 --> 00:02:12,034
serverless is actually a misnomer.

29
00:02:12,162 --> 00:02:15,762
So it's not like a server is not involved,

30
00:02:15,826 --> 00:02:19,014
it is, but it is involved behind the scenes.

31
00:02:19,142 --> 00:02:23,274
So whatever cloud provider you may be using and if they offer

32
00:02:23,392 --> 00:02:25,798
any serverless functionality,

33
00:02:25,974 --> 00:02:29,242
then basically they are dealing with all

34
00:02:29,296 --> 00:02:32,538
the problems that I mentioned in the previous slide.

35
00:02:32,634 --> 00:02:36,206
And you as a developer just have to deal with the

36
00:02:36,228 --> 00:02:39,866
business logic, the coding aspect of building applications.

37
00:02:39,978 --> 00:02:44,114
So that makes it very easy to maintain and scale in the long

38
00:02:44,152 --> 00:02:47,634
run. Because you are not dealing with the configuration the

39
00:02:47,672 --> 00:02:51,474
cloud provider is dealing with, that you are only dealing with the

40
00:02:51,592 --> 00:02:54,530
business aspect of development.

41
00:02:55,210 --> 00:02:58,930
These are some of the cloud providers and their serverless

42
00:02:59,010 --> 00:03:02,930
offerings. So you have lambda for AWS,

43
00:03:03,090 --> 00:03:07,154
cloud functions for GCP, and serverless functions

44
00:03:07,202 --> 00:03:10,698
for Versaille and Azure. These are just some of

45
00:03:10,704 --> 00:03:14,682
the cloud providers that I wanted to mention. So you are familiar with

46
00:03:14,736 --> 00:03:19,338
the offerings that are out there. I'm sure there are a

47
00:03:19,344 --> 00:03:23,360
lot more other offerings, but these are just a few that I wanted to mention.

48
00:03:24,130 --> 00:03:27,774
All right, so next I wanted to cover some

49
00:03:27,812 --> 00:03:32,014
of the basic concepts of kubernetes. I am sure that in

50
00:03:32,052 --> 00:03:35,710
this conference a lot of great folks will be covering

51
00:03:35,870 --> 00:03:39,726
the introduction to Kubernetes fundamentals of kubernetes the core

52
00:03:39,758 --> 00:03:44,020
components and all that jazz. I will not be going deep into

53
00:03:44,550 --> 00:03:47,734
the entire Kubernetes architecture. I will just

54
00:03:47,772 --> 00:03:51,362
be covering some of the core building blocks

55
00:03:51,426 --> 00:03:55,126
that we would be using in the demo part of

56
00:03:55,148 --> 00:03:58,794
this talk. So stick around till the end, because towards the end

57
00:03:58,832 --> 00:04:02,554
we will be exploring how to use knative and

58
00:04:02,672 --> 00:04:06,058
how we can create our very own serverless infrastructure right within

59
00:04:06,144 --> 00:04:09,722
a Kubernetes cluster. So just

60
00:04:09,776 --> 00:04:13,614
some high level overview for

61
00:04:13,812 --> 00:04:17,438
the components or the building blocks that we would be

62
00:04:17,604 --> 00:04:21,294
using or working with in the later part of this talk for

63
00:04:21,332 --> 00:04:25,026
Kubernetes. So first I would like to cover what is

64
00:04:25,048 --> 00:04:28,654
a node. So node is basically a virtual machine.

65
00:04:28,702 --> 00:04:33,150
You can think of it as a physical server located somewhere

66
00:04:33,310 --> 00:04:37,142
where your applications are hosted and

67
00:04:37,196 --> 00:04:40,854
managed by kubernetes. Then next comes the

68
00:04:40,892 --> 00:04:44,822
deployment. So deployment is, you can say

69
00:04:44,956 --> 00:04:48,274
a configuration that is related to your

70
00:04:48,332 --> 00:04:51,654
pods. So it has a lot of things you can configure.

71
00:04:51,702 --> 00:04:54,666
I won't be getting too much into that.

72
00:04:54,848 --> 00:04:58,342
Then next comes the pod itself. So pod

73
00:04:58,406 --> 00:05:02,106
is the smallest unit of abstraction that is created

74
00:05:02,138 --> 00:05:05,962
by kubernetes. Basically you can host

75
00:05:06,106 --> 00:05:10,046
one or multiple containers within a pod that is

76
00:05:10,148 --> 00:05:13,922
related to your application. Then next

77
00:05:13,976 --> 00:05:17,758
comes the replica set. This is also managed by the deployment,

78
00:05:17,854 --> 00:05:21,870
and replica set is nothing but a unit

79
00:05:21,950 --> 00:05:25,154
which ensures that you have n

80
00:05:25,192 --> 00:05:28,662
number of pods, whatever you may have defined up and running at

81
00:05:28,716 --> 00:05:31,974
all times. Then last but not the least,

82
00:05:32,172 --> 00:05:35,862
service. So service is you can think of it as a

83
00:05:35,916 --> 00:05:39,554
logical interface which exposes your pods

84
00:05:39,602 --> 00:05:43,674
to the outside world. So there are a lot of different types of

85
00:05:43,712 --> 00:05:47,434
services which I won't be diving deep into. I'm sure there are

86
00:05:47,472 --> 00:05:51,114
a lot of great folks who would be talking about all this in

87
00:05:51,152 --> 00:05:54,958
depth in this conference. So I won't be diving deep into that.

88
00:05:55,044 --> 00:05:58,542
These are some of the concepts that I wanted to cover

89
00:05:58,596 --> 00:06:02,622
so that it's easier for you to keep up with me in the

90
00:06:02,676 --> 00:06:07,090
later part of this talk where we would be covering the demo of knative.

91
00:06:08,150 --> 00:06:11,554
All right, so it's finally time. We would now

92
00:06:11,592 --> 00:06:15,266
be looking at the knative tool. What are some

93
00:06:15,288 --> 00:06:19,058
of the features provided by this tool, what are the core components

94
00:06:19,154 --> 00:06:22,310
and why? In some cases using this

95
00:06:22,380 --> 00:06:25,970
tool may be better for you than using a serverless

96
00:06:26,050 --> 00:06:29,818
offering provided by your cloud provider. So yeah,

97
00:06:29,904 --> 00:06:33,100
we would be diving deep into what is knative now.

98
00:06:33,550 --> 00:06:37,814
So knative is an open source serverless computing

99
00:06:37,862 --> 00:06:40,830
platform written in Go for kubernetes.

100
00:06:41,170 --> 00:06:45,626
Essentially you can create your very own serverless infrastructure

101
00:06:45,738 --> 00:06:49,614
right within your Kubernetes setup and by using this

102
00:06:49,652 --> 00:06:54,190
tool, you get the advantage of having the control over the configuration

103
00:06:54,270 --> 00:06:58,066
of how your serverless infrastructure should work.

104
00:06:58,168 --> 00:07:01,890
So earlier on in this talk, I discussed that

105
00:07:02,040 --> 00:07:05,922
why a serverless offering may be beneficial because

106
00:07:05,976 --> 00:07:09,186
you don't have to deal with the configuration that is associated

107
00:07:09,298 --> 00:07:13,186
with managing an application, you just have to deal with the business logic.

108
00:07:13,298 --> 00:07:17,282
But in some cases that may be a disadvantage

109
00:07:17,346 --> 00:07:20,314
because you don't have the control over how it works,

110
00:07:20,432 --> 00:07:23,866
and sometimes it can get out of hand. So if

111
00:07:23,888 --> 00:07:27,318
you want the control over your serverless configuration,

112
00:07:27,494 --> 00:07:30,380
this is the tool to go ahead with.

113
00:07:31,250 --> 00:07:34,830
So knative has two different offerings for

114
00:07:34,900 --> 00:07:38,222
managing modern serverless workloads. One is

115
00:07:38,276 --> 00:07:41,706
the serving component and another is the eventing

116
00:07:41,738 --> 00:07:45,762
component. So in the scope of this talk, we would

117
00:07:45,816 --> 00:07:49,650
only be covering the serving component and not the eventing component.

118
00:07:50,070 --> 00:07:53,410
So knative comes with various features.

119
00:07:53,830 --> 00:07:57,554
Some of them are first and foremost the scale

120
00:07:57,602 --> 00:08:01,170
down to zero, which is the flagship feature of knative.

121
00:08:01,330 --> 00:08:04,774
Basically, if your deployment does not

122
00:08:04,812 --> 00:08:08,050
have to deal with any messages or requests,

123
00:08:08,130 --> 00:08:11,642
then it can scale down to zero, and then again

124
00:08:11,696 --> 00:08:15,610
scale back up from zero. If there are any messages later

125
00:08:15,680 --> 00:08:19,286
down the line, then next comes yaml based configuration.

126
00:08:19,318 --> 00:08:23,802
So similarly, how you define objects in Kubernetes,

127
00:08:23,946 --> 00:08:27,626
you can define objects for knative as well using YAmL

128
00:08:27,658 --> 00:08:32,234
files itself. Then next comes the rollout

129
00:08:32,282 --> 00:08:35,442
strategies. So similar to how you can define different

130
00:08:35,496 --> 00:08:39,490
types of rollout strategies for your deployment in Kubernetes, you can

131
00:08:39,560 --> 00:08:42,862
define those same rollout strategies for a knative

132
00:08:42,926 --> 00:08:46,022
deployment as well. Then last but not the least,

133
00:08:46,076 --> 00:08:50,070
easy integration with tools and services. So like

134
00:08:50,140 --> 00:08:53,714
service meshes, monitoring tools, tracing tools,

135
00:08:53,762 --> 00:08:57,640
logging tools, knative is very easy to integrate with.

136
00:08:57,950 --> 00:09:01,850
Knative provides two components to work with

137
00:09:01,920 --> 00:09:06,214
in order to create serverless infrastructures. One is serving

138
00:09:06,262 --> 00:09:10,106
and another is eventing. In this talk, I will not

139
00:09:10,128 --> 00:09:13,774
be covering the eventing aspect of knative, I will only

140
00:09:13,812 --> 00:09:18,042
be covering the serving aspect. If you want me to cover eventing

141
00:09:18,106 --> 00:09:22,030
in the future, you can let me know and reach out to me

142
00:09:22,100 --> 00:09:25,522
through my social media platforms. I will be mentioning those

143
00:09:25,576 --> 00:09:28,946
at the end of this talk. So in this talk

144
00:09:28,968 --> 00:09:33,234
we will be covering only the serving aspect. So in serving there

145
00:09:33,272 --> 00:09:36,834
is a service, there is a revision

146
00:09:36,962 --> 00:09:40,822
and a route associated to that service, and a

147
00:09:40,876 --> 00:09:44,502
URL that points to that route which allows us to

148
00:09:44,556 --> 00:09:48,186
communicate with the service. And revisions are

149
00:09:48,208 --> 00:09:51,738
basically a version of your application.

150
00:09:51,904 --> 00:09:55,798
So essentially you can have multiple revisions

151
00:09:55,814 --> 00:09:59,366
of your application as well if you want. So you can split

152
00:09:59,398 --> 00:10:02,654
the traffic between those revisions, let's say 80% to

153
00:10:02,692 --> 00:10:06,094
revision one and 20% traffic to revision two. So it is

154
00:10:06,132 --> 00:10:10,142
very easy to create sort of an A B test environment with

155
00:10:10,196 --> 00:10:13,502
knative as well. All right, so I have

156
00:10:13,556 --> 00:10:17,266
covered all the theoretical aspects of knative and now

157
00:10:17,288 --> 00:10:20,946
it is time to jump into the demo. Before we do that, I would like

158
00:10:20,968 --> 00:10:24,882
to mention some of the prerequisites that are required for this

159
00:10:24,936 --> 00:10:28,422
demo. So first is Docker, then the next tool

160
00:10:28,476 --> 00:10:32,194
required is kind, which is basically Kubernetes in Docker.

161
00:10:32,322 --> 00:10:35,526
And the last tool that is required is the

162
00:10:35,548 --> 00:10:39,062
knative client. I'll be going over the installation instructions

163
00:10:39,126 --> 00:10:42,922
for the knative client in the demo part for

164
00:10:42,976 --> 00:10:47,034
a macOS operating system. But if you are on a different system,

165
00:10:47,232 --> 00:10:50,534
I have provided a QR code on the slide

166
00:10:50,582 --> 00:10:53,934
right now. So you can scan the QR code. You will be directed to a

167
00:10:53,972 --> 00:10:57,870
GitHub repository. In this repository you can find all the

168
00:10:58,020 --> 00:11:02,602
files that I would be working within the demo and the instructions associated

169
00:11:02,666 --> 00:11:05,954
to the demo. So you can find everything over there

170
00:11:06,072 --> 00:11:09,140
and yeah, let's get started.

171
00:11:09,910 --> 00:11:13,474
Okay, so we are in the demo part of the talk, I would

172
00:11:13,512 --> 00:11:16,806
say the most exciting part and we are inside the

173
00:11:16,828 --> 00:11:20,790
terminal, the home for every DevOps engineer.

174
00:11:21,930 --> 00:11:25,254
So earlier, as I mentioned, we would need

175
00:11:25,372 --> 00:11:28,050
three tools. One is Docker, second is kind,

176
00:11:28,140 --> 00:11:31,866
and third is knative client. So I

177
00:11:31,888 --> 00:11:35,754
hope you already have Docker and kind installed on your system.

178
00:11:35,872 --> 00:11:39,930
I'll be going over how you can install the knative client on

179
00:11:40,080 --> 00:11:43,406
Mac operating system. Don't worry if you are on

180
00:11:43,428 --> 00:11:47,546
a different system. As I mentioned earlier, the QR

181
00:11:47,578 --> 00:11:51,134
code that I provided, if you go to the link provided in that

182
00:11:51,252 --> 00:11:54,526
you can get the installation links and those links

183
00:11:54,558 --> 00:11:58,500
will direct you to a page where you can install

184
00:11:58,950 --> 00:12:02,734
the knative client for your particular operating

185
00:12:02,782 --> 00:12:06,350
system. So for Mac you can use the brew command.

186
00:12:06,430 --> 00:12:11,830
So brew install knative client

187
00:12:12,730 --> 00:12:15,990
kn so I won't be

188
00:12:16,060 --> 00:12:19,658
going ahead and running this command because I already have the

189
00:12:19,744 --> 00:12:23,498
knative client installed on my system, but we are not done

190
00:12:23,584 --> 00:12:27,162
yet. We can also install a quick

191
00:12:27,216 --> 00:12:31,134
start plugin that the knative client has

192
00:12:31,252 --> 00:12:34,446
offered. So basically in production, if you

193
00:12:34,468 --> 00:12:38,618
want to set up knative, you would manually have to install various

194
00:12:38,714 --> 00:12:42,202
tools and custom resource definitions for knative

195
00:12:42,266 --> 00:12:45,746
to work in your Kubernetes cluster. So we don't have

196
00:12:45,768 --> 00:12:49,730
to do that. There is a quick start plugin that we can use and

197
00:12:49,800 --> 00:12:52,674
get started with using knative quickly.

198
00:12:52,792 --> 00:12:56,278
So again I won't be running this command because I already

199
00:12:56,364 --> 00:13:00,374
have the plugin installed. Once both

200
00:13:00,412 --> 00:13:03,862
of these commands have successfully executed on your system,

201
00:13:03,996 --> 00:13:07,758
you can run the following command which is kn quickstart

202
00:13:07,954 --> 00:13:11,020
kind. So I'll go ahead and run this.

203
00:13:11,790 --> 00:13:14,874
This is a command that takes a few

204
00:13:14,912 --> 00:13:18,150
minutes to complete its execution,

205
00:13:18,310 --> 00:13:21,594
so I won't be making you wait for this command

206
00:13:21,642 --> 00:13:26,110
to complete. I'll cut straight to where it has finished execution.

207
00:13:26,770 --> 00:13:30,000
All right, so it seems like the

208
00:13:30,370 --> 00:13:34,066
command has finished its execution and

209
00:13:34,168 --> 00:13:37,954
this is the type of output you may also be seeing

210
00:13:37,992 --> 00:13:41,454
on your screen if you are following along. So let's

211
00:13:41,502 --> 00:13:45,314
go over what this quick start command

212
00:13:45,362 --> 00:13:49,586
has done. So first it installed

213
00:13:49,618 --> 00:13:53,750
the Kubernetes version 1.25.3.

214
00:13:53,820 --> 00:13:58,166
Essentially it installed the entire Kubernetes control plane

215
00:13:58,278 --> 00:14:02,106
in a single docker container. Then once

216
00:14:02,208 --> 00:14:06,134
kind was installed, the knative serving

217
00:14:06,182 --> 00:14:09,734
component was installed, so you can see all the steps

218
00:14:09,782 --> 00:14:13,146
related to that. Then next the courier networking

219
00:14:13,178 --> 00:14:16,970
layer was installed. So courier is nothing but a lightweight

220
00:14:17,050 --> 00:14:20,442
service mesh which was adopted by Knative

221
00:14:20,506 --> 00:14:24,180
in the recent years. Service mesh this particular

222
00:14:24,550 --> 00:14:28,674
service mesh is used for exposing the service

223
00:14:28,872 --> 00:14:32,258
that we would be creating as a serverless application

224
00:14:32,424 --> 00:14:35,486
to expose that to the outside world,

225
00:14:35,608 --> 00:14:39,670
outside of the Kubernetes network. Then it went ahead and

226
00:14:39,740 --> 00:14:43,350
installed the knative eventing component, which we won't be going

227
00:14:43,420 --> 00:14:46,822
over in this talk. And yeah, it finished its

228
00:14:46,876 --> 00:14:50,710
execution and seems like it has successfully installed knative

229
00:14:50,870 --> 00:14:52,970
on our kind cluster.

230
00:14:53,470 --> 00:14:57,322
Just to see what cluster has been created by

231
00:14:57,376 --> 00:15:01,214
the knative client in the previous command we can run

232
00:15:01,252 --> 00:15:03,950
this command kind get clusters.

233
00:15:04,850 --> 00:15:08,638
So as you can see it has created this cluster called

234
00:15:08,724 --> 00:15:11,966
knative. So usually what I like to do is

235
00:15:12,068 --> 00:15:15,650
run the Kubectx command.

236
00:15:16,070 --> 00:15:20,046
Basically this just ensures that I am on the correct context.

237
00:15:20,158 --> 00:15:23,714
For those of you who aren't familiar with Kubectx, this is

238
00:15:23,752 --> 00:15:27,406
a very helpful tool that enables

239
00:15:27,438 --> 00:15:31,590
you to switch between different contexts that you may be working with

240
00:15:31,660 --> 00:15:35,366
in Kubernetes. So yeah, that's what I did. I just ensured that I am

241
00:15:35,388 --> 00:15:38,726
on the correct context. I am sure that the

242
00:15:38,908 --> 00:15:42,186
command that we ran earlier, the quick start command, switches to

243
00:15:42,208 --> 00:15:45,446
this context, but it never hurts to run the command

244
00:15:45,478 --> 00:15:49,098
again. So yeah, now that we are sure

245
00:15:49,184 --> 00:15:52,686
we are on the correct context, the first thing that I like

246
00:15:52,708 --> 00:15:56,174
to do in order to see what all has been installed in my

247
00:15:56,212 --> 00:16:00,366
cluster is to get all the namespaces. So we can do that by

248
00:16:00,548 --> 00:16:02,350
kget namespaces.

249
00:16:03,570 --> 00:16:07,774
K is just an alias that I have set in my system for the Kubectl

250
00:16:07,822 --> 00:16:11,202
command. These are the namespaces present

251
00:16:11,256 --> 00:16:14,766
in our kubernetes cluster and I believe default kubernetes,

252
00:16:14,798 --> 00:16:18,978
lease cube, public cube system and local path storage are the namespaces

253
00:16:19,074 --> 00:16:22,770
that come out of the box with the kind cluster,

254
00:16:22,930 --> 00:16:26,642
but these are the three namespaces

255
00:16:26,706 --> 00:16:30,662
that I can see which has been installed by the knative client.

256
00:16:30,726 --> 00:16:34,086
So eventing, serving and courier system, as I'd

257
00:16:34,118 --> 00:16:37,398
mentioned earlier, we would only be going over the serving component.

258
00:16:37,494 --> 00:16:41,054
So this is the namespace that I would first like to look at.

259
00:16:41,172 --> 00:16:44,810
So the next thing that I'll do is get the resources

260
00:16:44,890 --> 00:16:48,590
present in the knative serving namespace.

261
00:16:49,410 --> 00:16:53,626
So this command that I ran, kget all namespace,

262
00:16:53,738 --> 00:16:57,250
knative serving basically gets all the resources present

263
00:16:57,320 --> 00:17:00,866
inside this particular namespace. And as you can

264
00:17:00,888 --> 00:17:04,066
see there is a lot of information on the screen. Not to worry, we are

265
00:17:04,088 --> 00:17:07,666
just going over what all has been installed in our cluster.

266
00:17:07,778 --> 00:17:11,906
So as we can see there are a bunch of pods, bunch of services associated

267
00:17:11,938 --> 00:17:15,906
to those pods, deployments for those pods and replica sets.

268
00:17:16,018 --> 00:17:19,762
So these are the pods

269
00:17:19,906 --> 00:17:23,466
which help knitting manage all the

270
00:17:23,488 --> 00:17:26,938
serverless workloads. And you can see that there are a

271
00:17:26,944 --> 00:17:30,678
few horizontal pod auto scalers as well. So yeah,

272
00:17:30,864 --> 00:17:34,762
these are the resources that have been installed in our Kubernetes

273
00:17:34,826 --> 00:17:38,014
cluster and now we can jump into installing our

274
00:17:38,052 --> 00:17:41,600
first serverless application. So yeah, let's get into that.

275
00:17:42,210 --> 00:17:45,554
All right, so we are in vs code now,

276
00:17:45,672 --> 00:17:48,686
this is the id of my preference,

277
00:17:48,798 --> 00:17:52,434
and here is a Yaml file that I have named as hello

278
00:17:52,472 --> 00:17:56,126
World Yaml. And this is using the API

279
00:17:56,158 --> 00:17:59,926
version serving knative dev v one. So this is

280
00:17:59,948 --> 00:18:03,778
a custom resource definition that was installed by the knative client

281
00:18:03,874 --> 00:18:07,522
which we would be leveraging to create our very first serverless

282
00:18:07,586 --> 00:18:10,762
application. So the name for the

283
00:18:10,896 --> 00:18:15,110
application would be hello. And here are a few annotations

284
00:18:15,190 --> 00:18:18,346
that I have mentioned. I won't be covering this right now,

285
00:18:18,368 --> 00:18:22,634
I'll get into this later. Then we have the spec containers

286
00:18:22,762 --> 00:18:26,926
image provided for the container, the container port and

287
00:18:27,108 --> 00:18:31,102
env variable that we have mentioned with the value world.

288
00:18:31,236 --> 00:18:35,214
So as you can see that this Yaml file seems very familiar,

289
00:18:35,262 --> 00:18:38,866
right? This is a very similar file that

290
00:18:38,888 --> 00:18:43,006
we would be creating for normal Kubernetes applications.

291
00:18:43,038 --> 00:18:46,962
So yeah, essentially you create your serverless

292
00:18:47,026 --> 00:18:50,390
applications using YAML files itself and it's very similar to

293
00:18:50,460 --> 00:18:54,214
Kubernetes. So let's jump back

294
00:18:54,252 --> 00:18:57,590
to the terminal and apply this yaml file.

295
00:18:58,030 --> 00:19:01,338
Before applying any YAml files, I like to first

296
00:19:01,424 --> 00:19:05,130
do a diff on that Yaml file. So we can do that by running k

297
00:19:05,200 --> 00:19:08,730
diff hello world Yaml.

298
00:19:09,310 --> 00:19:12,574
Yes, so as you can see it is going to be

299
00:19:12,612 --> 00:19:16,014
creating a service named hello and it has

300
00:19:16,052 --> 00:19:19,706
a few annotations defined. It is creating

301
00:19:19,738 --> 00:19:23,554
the image that we had mentioned, and also it is specifying some of the

302
00:19:23,592 --> 00:19:27,934
default values that we did not mention in the YAml file, like the readiness probe,

303
00:19:28,062 --> 00:19:32,174
the traffic with the latest revision and the percentage

304
00:19:32,222 --> 00:19:36,322
split between those revisions. So 100% because

305
00:19:36,376 --> 00:19:39,606
we are going to be creating our first revision. As I

306
00:19:39,628 --> 00:19:43,554
had mentioned earlier, you have the ability to create multiple revisions

307
00:19:43,602 --> 00:19:47,010
in knative and split the traffic between those revisions.

308
00:19:47,170 --> 00:19:50,266
So yeah, this file seems good to me. Let's go ahead and

309
00:19:50,288 --> 00:19:54,890
apply hello world Yaml.

310
00:19:56,270 --> 00:20:00,326
Okay, so it seems like the command ran without any errors.

311
00:20:00,438 --> 00:20:03,786
So what we can do next is get the pods in the default namespace.

312
00:20:03,818 --> 00:20:07,994
Because we did not specify any namespace, it would be created in the default namespace.

313
00:20:08,122 --> 00:20:11,646
As you can see, there is a pod named hello

314
00:20:11,828 --> 00:20:15,534
and it is in the running state. So if I run the command

315
00:20:15,582 --> 00:20:18,562
again, instead of running it again and again,

316
00:20:18,616 --> 00:20:21,570
we can go in the watch mode.

317
00:20:21,910 --> 00:20:25,586
So let's wait for a few seconds, and as you

318
00:20:25,608 --> 00:20:28,802
can see, it has started terminating the pod.

319
00:20:28,946 --> 00:20:32,722
The reason for that is because of the scale to zero functionality

320
00:20:32,786 --> 00:20:36,466
provided by knative. So essentially right now this pod

321
00:20:36,498 --> 00:20:39,606
is not serving any traffic or any messages.

322
00:20:39,718 --> 00:20:43,162
So knative is smart enough to understand that and

323
00:20:43,216 --> 00:20:46,874
scale the deployment down to zero. So that is what

324
00:20:46,912 --> 00:20:51,174
it is doing. Right now it is terminating the multiple containers.

325
00:20:51,222 --> 00:20:55,386
We'll go into that later. As to why there are two containers

326
00:20:55,498 --> 00:20:59,598
instead of one, because we specified only one container. We'll get into that later,

327
00:20:59,684 --> 00:21:03,602
but for now understand that if I run the command again,

328
00:21:03,736 --> 00:21:07,394
there are no resources present, although it was present before.

329
00:21:07,512 --> 00:21:11,060
So it has scaled the deployment down to zero.

330
00:21:11,750 --> 00:21:15,090
Next command that we can run is the

331
00:21:15,240 --> 00:21:18,130
KgetksVC command.

332
00:21:18,570 --> 00:21:22,130
Basically KSVC is short for knative

333
00:21:22,210 --> 00:21:25,682
service. It is a custom resource definition created by the knative

334
00:21:25,746 --> 00:21:28,906
client. And as you can see, this is the service that we

335
00:21:28,928 --> 00:21:32,794
created. So hello, it has a URL, and this

336
00:21:32,832 --> 00:21:35,994
URL points to the route which points to the

337
00:21:36,032 --> 00:21:39,382
revision of our service. So this is a URL

338
00:21:39,446 --> 00:21:43,178
that is created by the courier networking layer,

339
00:21:43,354 --> 00:21:46,750
basically exposing the knative service

340
00:21:46,900 --> 00:21:50,430
from the Kubernetes network outside and

341
00:21:50,500 --> 00:21:53,970
exposing it to us on our local network. So if you

342
00:21:54,040 --> 00:21:57,794
may know that Kubernetes runs its own network and our local network is

343
00:21:57,832 --> 00:22:01,438
different from the Kubernetes network. So this essentially

344
00:22:01,534 --> 00:22:05,282
allows us to communicate with the services present

345
00:22:05,336 --> 00:22:08,994
in the Kubernetes network. So the knative Quickstart

346
00:22:09,042 --> 00:22:12,578
command has set all of this up for us very nicely.

347
00:22:12,674 --> 00:22:16,066
We don't have to deal with the configuration. So I'll just copy

348
00:22:16,098 --> 00:22:19,834
this link and run a simple curl on this. I got

349
00:22:19,872 --> 00:22:23,994
a response. Hello world. If I get the pods again, you can

350
00:22:24,032 --> 00:22:27,910
see that there was a deployment, there was a pod created.

351
00:22:27,990 --> 00:22:32,080
So essentially what it did was it scaled back

352
00:22:32,530 --> 00:22:35,706
from zero to one to serve our request.

353
00:22:35,818 --> 00:22:39,482
So this is how the knative serving

354
00:22:39,546 --> 00:22:43,440
platform works and this is how the scale to zero functionality works.

355
00:22:43,990 --> 00:22:48,018
So the next thing that I would like to go over is how you can

356
00:22:48,104 --> 00:22:51,666
load test your serverless application. So there

357
00:22:51,688 --> 00:22:55,682
is this neat tool called as hay, and this

358
00:22:55,736 --> 00:22:59,814
tool essentially allows you to load test any application for that

359
00:22:59,852 --> 00:23:03,800
matter. So this is the command, I will run this.

360
00:23:04,410 --> 00:23:08,234
Basically what it is doing is it will load test our application for

361
00:23:08,352 --> 00:23:12,534
roughly 10 seconds and it will concurrently try to send 100 requests

362
00:23:12,582 --> 00:23:16,394
at a time on the URL, which would

363
00:23:16,432 --> 00:23:20,246
be the URL of our service. So the URL

364
00:23:20,278 --> 00:23:23,406
that we ran the curl command on, that is what it

365
00:23:23,428 --> 00:23:26,494
will be getting through this. And once it

366
00:23:26,532 --> 00:23:29,822
has finished its execution, it will run the get

367
00:23:29,876 --> 00:23:34,382
pods command. So as we can see, it ran successfully.

368
00:23:34,526 --> 00:23:38,482
And these were the pods at the end of this

369
00:23:38,616 --> 00:23:42,094
lotus. And this was the report generated

370
00:23:42,142 --> 00:23:46,002
by the hay command. So it ran for about 10 seconds roughly.

371
00:23:46,146 --> 00:23:50,066
Slowest request was 1.6 seconds,

372
00:23:50,178 --> 00:23:53,574
fastest was for this long, average was this

373
00:23:53,612 --> 00:23:57,240
much. And in total it was able to

374
00:23:57,550 --> 00:24:01,180
run 4390 requests per second.

375
00:24:01,630 --> 00:24:05,626
So yeah, the next thing that I will be covering is

376
00:24:05,728 --> 00:24:09,142
how we can specify a minimum

377
00:24:09,206 --> 00:24:12,522
number of pod for our serverless

378
00:24:12,586 --> 00:24:16,110
application in order to avoid the cold start problem.

379
00:24:16,260 --> 00:24:20,174
So if you are familiar with this problem, basically what

380
00:24:20,212 --> 00:24:23,982
happens is that if there are sudden requests

381
00:24:24,046 --> 00:24:28,082
that come into your serverless application, so it takes some

382
00:24:28,136 --> 00:24:31,602
time to scale up from zero. So the

383
00:24:31,656 --> 00:24:35,486
first request or the first few requests can take

384
00:24:35,608 --> 00:24:39,494
some time to be responded to rather than having

385
00:24:39,532 --> 00:24:43,922
a consistent experience. So this is a well known problem in the serverless

386
00:24:44,066 --> 00:24:47,606
ecosystem and how we can solve this problem

387
00:24:47,708 --> 00:24:51,002
using the inative client. We'll look at

388
00:24:51,056 --> 00:24:54,380
that by jumping into the vs code id again.

389
00:24:54,830 --> 00:24:58,890
So we are back into the vs code id and as you can see

390
00:24:59,040 --> 00:25:02,442
this is a different file, minscale Yaml.

391
00:25:02,506 --> 00:25:05,886
But it is pretty similar to the hello world Yaml file that we

392
00:25:05,908 --> 00:25:10,110
saw earlier with a few differences here I have

393
00:25:10,180 --> 00:25:14,018
defined a few more annotations for this particular service.

394
00:25:14,184 --> 00:25:18,322
So here we are mentioning a target of ten.

395
00:25:18,456 --> 00:25:22,242
Essentially this tells knative that a

396
00:25:22,296 --> 00:25:26,262
single pod should be handling ten concurrent requests at a time,

397
00:25:26,396 --> 00:25:29,702
then target utilization percentage, so 80%.

398
00:25:29,836 --> 00:25:33,526
So if the target utilization of

399
00:25:33,628 --> 00:25:37,094
the pod has reached 80%, which would be eight in this

400
00:25:37,132 --> 00:25:40,574
case, then scale up to the next pod.

401
00:25:40,722 --> 00:25:44,294
So that we can specify. And next is min scale.

402
00:25:44,342 --> 00:25:47,786
So min scale we have set to two. So keep a minimum of

403
00:25:47,808 --> 00:25:50,774
two pods running at all times. So don't scale down to zero,

404
00:25:50,832 --> 00:25:54,506
basically. And next, we have defined a panic window percentage

405
00:25:54,538 --> 00:25:58,094
and a panic threshold percentage just in case if things go

406
00:25:58,132 --> 00:26:02,042
wrong. So this is how you can customize

407
00:26:02,106 --> 00:26:05,458
your knative service. There are a lot more things you can do,

408
00:26:05,544 --> 00:26:09,422
and I just wanted to show you how you can customize

409
00:26:09,486 --> 00:26:13,202
your serverless application. So let's jump back

410
00:26:13,256 --> 00:26:17,878
to the terminal again and apply this new Yaml file before

411
00:26:17,964 --> 00:26:21,446
applying any new Yaml file. As always, I like to do a diff on that

412
00:26:21,468 --> 00:26:25,750
first. So get the diff. Minscale Yaml.

413
00:26:26,810 --> 00:26:30,406
And since we did not change the service name in the

414
00:26:30,428 --> 00:26:34,026
new Yaml file as well, we have kept it to hello itself. So it is

415
00:26:34,128 --> 00:26:37,386
going to be making changes to the original service that we

416
00:26:37,408 --> 00:26:40,938
created through hello World Yaml file. So as you can

417
00:26:40,944 --> 00:26:45,002
see, it is only making a few additions, which were the annotations

418
00:26:45,066 --> 00:26:47,946
that we had provided in the min scale Yaml file.

419
00:26:48,058 --> 00:26:51,614
So everything good looks good to me. Let's go ahead and

420
00:26:51,652 --> 00:26:54,434
apply so we can do that.

421
00:26:54,632 --> 00:26:58,434
Minscale Yaml seems

422
00:26:58,472 --> 00:27:02,014
like the command ran successfully without running into any errors.

423
00:27:02,142 --> 00:27:04,420
And we can get the pods now.

424
00:27:04,870 --> 00:27:08,082
Kubectl get pods. And as you can see

425
00:27:08,136 --> 00:27:11,302
that this is revision two and there are

426
00:27:11,356 --> 00:27:14,534
two pods running. Let me tell you that there will always be

427
00:27:14,572 --> 00:27:18,154
two pods running at a time because we have set the min scale to

428
00:27:18,192 --> 00:27:21,542
two, and essentially it won't

429
00:27:21,686 --> 00:27:25,754
scale back down to zero. So now that we

430
00:27:25,792 --> 00:27:29,158
have two pods running, I want to do a describe

431
00:27:29,254 --> 00:27:32,270
on one particular pod. I'll do it on this pod.

432
00:27:32,690 --> 00:27:36,558
I just want to show you as to why we have two

433
00:27:36,644 --> 00:27:40,366
containers running for each pod. So one is the

434
00:27:40,388 --> 00:27:43,966
container that we created which knative specifies as user

435
00:27:43,998 --> 00:27:46,770
container. This is the image that we had mentioned.

436
00:27:46,920 --> 00:27:50,626
And if we scroll down a bit, you can see

437
00:27:50,648 --> 00:27:54,642
that there is another container called qproxy. So this

438
00:27:54,696 --> 00:27:58,274
is a sidecar container that knative installs

439
00:27:58,322 --> 00:28:01,926
in every pod so that it can communicate with the outside

440
00:28:02,028 --> 00:28:04,280
world. So yes,

441
00:28:05,290 --> 00:28:09,286
let's run the load testing command again and see if there are any changes,

442
00:28:09,388 --> 00:28:13,146
since we now have minimum of two pods running at all times.

443
00:28:13,248 --> 00:28:16,058
So I'll paste the same command that we ran before.

444
00:28:16,224 --> 00:28:20,554
Again, it will run for roughly 10 seconds, send about 100 concurrent requests

445
00:28:20,602 --> 00:28:24,634
at a time, and send those requests to the service URL

446
00:28:24,682 --> 00:28:28,542
that we have created. So yes, it has

447
00:28:28,596 --> 00:28:31,710
finished its execution and given us

448
00:28:31,780 --> 00:28:35,406
this report. So as you can see, it roughly ran

449
00:28:35,438 --> 00:28:38,754
for about 10 seconds. Slowest was this much.

450
00:28:38,872 --> 00:28:42,414
You can see that the slowest request time has been reduced

451
00:28:42,462 --> 00:28:46,682
drastically because now we have minimum of two pods running. So essentially

452
00:28:46,766 --> 00:28:50,406
we have solved the cold start problem and the

453
00:28:50,428 --> 00:28:54,390
fastest I believe is about the same average. Also I think got

454
00:28:54,460 --> 00:28:58,194
reduced by a bit because of the cold start problem.

455
00:28:58,332 --> 00:29:02,454
And average requests per second has also improved.

456
00:29:02,582 --> 00:29:06,026
So yes, this was it. These were all

457
00:29:06,048 --> 00:29:09,466
the things that I wanted to cover. And yeah, this is

458
00:29:09,488 --> 00:29:12,590
the end of the demo and we can now jump back into

459
00:29:12,660 --> 00:29:16,494
the slides. All right, so we are towards the

460
00:29:16,532 --> 00:29:20,046
end of this talk. Before we conclude, I would like to recap all

461
00:29:20,068 --> 00:29:23,090
the things that we covered in this talk.

462
00:29:23,240 --> 00:29:27,090
So initially we started off with learning about the with

463
00:29:27,160 --> 00:29:30,834
server architecture and the problems associated with it.

464
00:29:30,952 --> 00:29:34,354
Next we looked at the serverless architecture and how those

465
00:29:34,392 --> 00:29:38,262
problems can be addressed. Next we looked at

466
00:29:38,316 --> 00:29:41,622
the conceptual overview of Kubernetes and the

467
00:29:41,676 --> 00:29:45,414
building blocks that were required for the demo presented in this

468
00:29:45,452 --> 00:29:48,918
talk. Then next we saw what is knative,

469
00:29:49,014 --> 00:29:52,634
the features of knative and the components that are

470
00:29:52,672 --> 00:29:56,602
provided by knative. And lastly, we jumped into the demo

471
00:29:56,736 --> 00:30:00,106
where we saw knative in action and how we can

472
00:30:00,208 --> 00:30:03,694
create our very own serverless infrastructure right within our

473
00:30:03,732 --> 00:30:07,070
Kubernetes cluster. So yes, these were the points

474
00:30:07,140 --> 00:30:10,414
that we covered. Before ending this talk, I would like

475
00:30:10,452 --> 00:30:13,854
to mention my social media profiles so that you can

476
00:30:13,892 --> 00:30:17,282
reach out to me if you stuck around till this point.

477
00:30:17,336 --> 00:30:20,546
I would like to thank you and I hope that

478
00:30:20,568 --> 00:30:24,274
you learned something new today. If you want to reach

479
00:30:24,312 --> 00:30:27,698
out to me, if you have any questions, if you want to discuss anything

480
00:30:27,784 --> 00:30:31,462
related to DevOps or anything related to tech in general, you can

481
00:30:31,516 --> 00:30:35,074
do so by reaching out to me through the links provided on the slide

482
00:30:35,122 --> 00:30:38,774
here. There are two QR codes. Also I have

483
00:30:38,812 --> 00:30:42,550
provided for your convenience. So the first QR code will take you to a page

484
00:30:42,620 --> 00:30:46,022
where all of my links would be present, and the second

485
00:30:46,076 --> 00:30:50,106
QR code will take you to a GitHub repository where the file

486
00:30:50,178 --> 00:30:53,354
that I worked with, instructions, the commands that I karan,

487
00:30:53,482 --> 00:30:57,914
installation procedures, everything is mentioned in that GitHub repository.

488
00:30:58,042 --> 00:31:01,374
And I would like to thank Conf 42 for having me

489
00:31:01,412 --> 00:31:05,390
here and giving me this platform to talk about the things I love.

490
00:31:05,540 --> 00:31:07,420
So yes, thank you. Thanks a lot.

