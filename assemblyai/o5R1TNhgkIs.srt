1
00:00:26,210 --> 00:00:29,334
Hello everyone, this is Aman Sharma and today

2
00:00:29,372 --> 00:00:32,710
we are going to talk about a very interesting topic that has been very close

3
00:00:32,780 --> 00:00:36,418
to my heart, which is data, data everywhere,

4
00:00:36,594 --> 00:00:40,466
no time to think. Well this is like a proverb

5
00:00:40,498 --> 00:00:44,086
and saying that we usually have like water, water everywhere and no drop to

6
00:00:44,108 --> 00:00:47,686
drink. I think the perception of finding insights out of

7
00:00:47,708 --> 00:00:51,226
data is kind of the same. So this is going to be an interesting journey

8
00:00:51,258 --> 00:00:55,326
that we are going to take today together and we are going to discuss a

9
00:00:55,348 --> 00:00:58,778
lot of things, but in a very summarized in a very fun manner.

10
00:00:58,874 --> 00:01:01,120
So let's directly dive into it.

11
00:01:02,210 --> 00:01:04,340
Firstly, let me introduce myself.

12
00:01:05,590 --> 00:01:08,562
My name is Aman Sharma. I am cofounder CTO,

13
00:01:08,616 --> 00:01:12,290
chief technology officer at Twimbit. Twimbit is a platform where the world

14
00:01:12,360 --> 00:01:16,086
can create and discover research insights and

15
00:01:16,108 --> 00:01:20,166
I lead the technology team overall to create the platform and the SaaS products.

16
00:01:20,348 --> 00:01:23,542
Also, I am member at deep learning AI which

17
00:01:23,596 --> 00:01:26,754
helps bring technical

18
00:01:26,802 --> 00:01:30,426
knowledge in deep learning understanding to students. Also I

19
00:01:30,448 --> 00:01:33,578
am mentor entrepreneur and also

20
00:01:33,744 --> 00:01:37,162
I'm like a general guy who can span across into

21
00:01:37,216 --> 00:01:40,922
different meta knowledge and technology themes. I advise startups and different

22
00:01:40,976 --> 00:01:45,226
organizations about their technology approach and how to adopt new technology methods

23
00:01:45,258 --> 00:01:48,606
into the tech stacks. So well, enough about me, you can

24
00:01:48,628 --> 00:01:52,122
find more about me on my handle. That is Amantech

25
00:01:52,266 --> 00:01:55,942
and my website is also actually amanin

26
00:01:56,026 --> 00:01:59,314
tech and you can find all the details about me and my

27
00:01:59,352 --> 00:02:03,010
work over there. So let's start with our first

28
00:02:03,080 --> 00:02:07,190
question. What basically is the main key difference between

29
00:02:07,340 --> 00:02:11,494
data and insights? Well, the first

30
00:02:11,532 --> 00:02:15,074
time that I was seeing this popularity of data science,

31
00:02:15,122 --> 00:02:18,594
data science and what the hell it is, it was very confusing

32
00:02:18,642 --> 00:02:22,794
for me. Like there is data and then you can directly see it. But actually

33
00:02:22,992 --> 00:02:26,426
being inside data is like sailing a boat in

34
00:02:26,448 --> 00:02:30,090
a deep ocean, right? You are always

35
00:02:30,160 --> 00:02:33,278
covered with this different stream of options,

36
00:02:33,364 --> 00:02:36,862
different streams of data, and you are not able to identify what are you actually

37
00:02:36,916 --> 00:02:40,874
looking for unless there is a lighthouse

38
00:02:40,922 --> 00:02:44,914
which gives you a direction and it shines you all the pearls and

39
00:02:44,952 --> 00:02:48,290
all the different treasures that are hidden deep beneath

40
00:02:48,630 --> 00:02:52,034
the deep ocean of data. Well,

41
00:02:52,152 --> 00:02:55,750
I think the big data or any data that a company possess has a similar

42
00:02:55,820 --> 00:02:59,366
challenge. And the key objective over here is to

43
00:02:59,388 --> 00:03:03,606
identify the key insights which can help make

44
00:03:03,628 --> 00:03:08,054
people decisions and make

45
00:03:08,092 --> 00:03:11,506
them better decisions and also help them navigate

46
00:03:11,538 --> 00:03:15,194
through the tough course of finding key insights. Well,

47
00:03:15,232 --> 00:03:18,646
that is going to be our agenda of the talk and that has been divided

48
00:03:18,678 --> 00:03:22,042
in such a manner that we'll cover the brief problem that we have on hand.

49
00:03:22,096 --> 00:03:25,614
And what are the different scopes of these problems that usually covers and

50
00:03:25,652 --> 00:03:29,390
also whats are possible solutions that are existingly there.

51
00:03:29,460 --> 00:03:33,134
And what else could we do about it? Then we'll also cover a new

52
00:03:33,172 --> 00:03:37,554
approach, that is data science prints that I myself have

53
00:03:37,592 --> 00:03:41,474
seen over the course of times, like how different organizations are adopting them.

54
00:03:41,592 --> 00:03:45,410
Also we'll see the difference between approaches in code and no code

55
00:03:45,480 --> 00:03:49,074
tools. Today there are many no code tools also available which

56
00:03:49,112 --> 00:03:52,854
helps in data science. And then we'll see how

57
00:03:52,892 --> 00:03:56,386
to do visualizations for betterment of explaining

58
00:03:56,418 --> 00:04:00,190
what you mean by the data. Then we'll see an approach that is called dashboarding,

59
00:04:00,210 --> 00:04:04,026
that is bringing everybody on board onto the same idea and

60
00:04:04,048 --> 00:04:07,926
everybody is aware about what data we are talking about. And then finally documenting

61
00:04:07,958 --> 00:04:11,854
the steps that goes along and how better

62
00:04:11,892 --> 00:04:16,026
documenting and helps in overcoming the challenge of nondiscriminacy

63
00:04:16,058 --> 00:04:19,038
in data. So let's begin with our problems.

64
00:04:19,204 --> 00:04:22,922
The first problem is the problem of goal clarity.

65
00:04:22,986 --> 00:04:26,686
Well, simply explain, goal clarity is

66
00:04:26,788 --> 00:04:30,626
when team that are working on a similar objective doesn't have the

67
00:04:30,648 --> 00:04:34,014
main idea that what they are trying to achieve, as I've written in the definition

68
00:04:34,062 --> 00:04:37,646
as well, important to keep everybody aligned to ultimately achieve and improve

69
00:04:37,678 --> 00:04:41,222
service. Now the key symptoms that you might see

70
00:04:41,356 --> 00:04:45,106
when you are facing this kind of challenge is often your teams are losing

71
00:04:45,138 --> 00:04:48,326
track. They are always asking this common question, why we were

72
00:04:48,348 --> 00:04:52,026
here. Again, like what was the main theme of what we were discussing? Everyone have

73
00:04:52,048 --> 00:04:55,526
a different perception. Somebody sees it as one challenge, somebody sees

74
00:04:55,558 --> 00:04:59,260
as another challenge. And of course when people see these

75
00:04:59,630 --> 00:05:03,226
goals as different, the outcome that would arrive out of

76
00:05:03,248 --> 00:05:07,226
them would also be different and ultimately leading to a poor ROI,

77
00:05:07,338 --> 00:05:10,446
which is the main cause why team then kind of

78
00:05:10,468 --> 00:05:14,446
get demotivated and they don't go with the data science path as often. Now the

79
00:05:14,468 --> 00:05:18,258
solution on a very generalized approach is to first of all identify the

80
00:05:18,264 --> 00:05:22,274
main goal and then communicate that goal easily along the whole team

81
00:05:22,312 --> 00:05:25,640
span, which can help everybody to get onto the same page.

82
00:05:27,850 --> 00:05:31,334
Now the second problem, whats I see is poor planning. Once your

83
00:05:31,372 --> 00:05:35,126
goal is clear, team always struggles with how to plan a

84
00:05:35,148 --> 00:05:38,710
project which can help them achieve that particular

85
00:05:38,780 --> 00:05:42,294
functionality. And this is the main reason of any chaotic

86
00:05:42,342 --> 00:05:45,994
situations and offer also leads to abandonment. I have seen projects even in our

87
00:05:46,032 --> 00:05:49,834
organization and other organizations as well, that often whats the deadline is

88
00:05:49,872 --> 00:05:52,778
too long and there is no decision arrived at right time.

89
00:05:52,864 --> 00:05:56,686
And team often tend to just abandon the project and move ahead.

90
00:05:56,788 --> 00:05:59,982
And this also leads to a lot of wastage of resources and time, right.

91
00:06:00,116 --> 00:06:03,806
So the symptoms that you would see commonly in organizations for this kind

92
00:06:03,828 --> 00:06:07,694
of problem is they are missing deadlines all the time. The results that are yield

93
00:06:07,742 --> 00:06:10,946
are not proper and they are always questioning the resources, that the

94
00:06:10,968 --> 00:06:15,266
resources are not right, the technical skills are not right, and that

95
00:06:15,288 --> 00:06:19,590
is a repeating question always coming. Well, the solution for this is again

96
00:06:19,740 --> 00:06:23,026
a three step approach that is a better project structure,

97
00:06:23,138 --> 00:06:27,240
understanding how to divide the project into proper timelines, and also

98
00:06:27,690 --> 00:06:30,822
making sure that the deliverables are very defined and they are less

99
00:06:30,876 --> 00:06:34,234
like, they are very lean and the scope is not too

100
00:06:34,272 --> 00:06:38,410
broad. And then once you come up with that, always stick to the timelines and

101
00:06:38,560 --> 00:06:42,122
limit the scope to it. We'll talk about this approach in

102
00:06:42,176 --> 00:06:45,534
sprints of how you can make a better timelines and how you can make team

103
00:06:45,572 --> 00:06:48,894
structures better. Then you have a dirty data

104
00:06:48,932 --> 00:06:52,720
problem. Well, this is something that I have seen with almost all

105
00:06:53,090 --> 00:06:56,560
projects, that the vastness of data expands and

106
00:06:56,930 --> 00:07:00,082
there is bad data in the same good data at the same time.

107
00:07:00,136 --> 00:07:03,406
Right? So you spend too much time in data processing.

108
00:07:03,438 --> 00:07:05,966
That is like one of the key things that you would see in teams,

109
00:07:05,998 --> 00:07:08,994
that they are always struggling with, that they are always trying to clean the data.

110
00:07:09,112 --> 00:07:12,630
Sometimes team also do have to do it manually, right. And also

111
00:07:12,780 --> 00:07:16,406
the ratio between the whole data set that you have versus the

112
00:07:16,428 --> 00:07:20,230
amount of insights you gain would always be less because your data is always

113
00:07:20,300 --> 00:07:23,946
already polluted with so much of dirty data that you

114
00:07:23,968 --> 00:07:27,606
are not able to get the actual insights of the main data source.

115
00:07:27,638 --> 00:07:31,514
So it's very important to always clear these results. And for this,

116
00:07:31,552 --> 00:07:34,486
the solutions are advanced tools, which are data preprocessing tools.

117
00:07:34,518 --> 00:07:38,266
We'll talk about them as well. And also that source ingestion,

118
00:07:38,298 --> 00:07:41,310
like how you are capturing the data, if it is analytics data from the website,

119
00:07:41,380 --> 00:07:44,878
you have to rethink about how you are calibrating, how you are capturing the

120
00:07:44,884 --> 00:07:48,078
insights from that website or an app. And also if it's

121
00:07:48,094 --> 00:07:51,406
a surveying tool, how you are capturing this data. So all those source ingestion

122
00:07:51,438 --> 00:07:54,974
tools needs to be improved. And doing these three things parallel

123
00:07:55,022 --> 00:07:58,600
can help in overcoming the dirty data solution problem.

124
00:07:58,970 --> 00:08:02,774
Then we have on the other side, those are more,

125
00:08:02,892 --> 00:08:06,070
not project related, but more technical challenge related. Now,

126
00:08:06,140 --> 00:08:09,686
how I define the technical challenges are like data is important for any

127
00:08:09,708 --> 00:08:13,226
company, whether it's a startup or it's a big organization. But the

128
00:08:13,248 --> 00:08:16,986
challenge for small organization or mid organization or mid teams is that they are

129
00:08:17,008 --> 00:08:20,746
limited on tools that they can use, they are limited on the resources that

130
00:08:20,768 --> 00:08:24,734
they have, and they are limited on the talent that they have. And also for

131
00:08:24,772 --> 00:08:28,586
big company, the challenge goes beyond and they have privacy issues like they cannot

132
00:08:28,618 --> 00:08:32,362
take all the decisions lives that they are dependent upon GDPR

133
00:08:32,426 --> 00:08:36,254
and other data protection policies and they are not able to rectify their

134
00:08:36,292 --> 00:08:39,586
path through this time. And the symptoms that you would see is that people

135
00:08:39,608 --> 00:08:42,866
are complaining about less people, there is lower turnaround time,

136
00:08:42,888 --> 00:08:45,810
whats amount of time you are putting in and the amount of results that are

137
00:08:45,880 --> 00:08:49,318
coming are not very good. You are always complaining about the

138
00:08:49,324 --> 00:08:53,474
system efficiencies, like how different systems are not working properly.

139
00:08:53,522 --> 00:08:57,126
And of course people are complaining about there is less transparency between the

140
00:08:57,148 --> 00:09:00,434
technical team who is working on these challenges and nontechnical

141
00:09:00,482 --> 00:09:04,010
team who is actually there to reap the benefits of the data.

142
00:09:04,080 --> 00:09:07,786
And ultimately there is a silo that becomes between these two

143
00:09:07,808 --> 00:09:11,274
teams. Now, the solution to this is that has been like a time

144
00:09:11,312 --> 00:09:15,182
trial method, at least for me, over the course of time, is this

145
00:09:15,236 --> 00:09:18,538
new wave of no code tools that can be adopted by any organization,

146
00:09:18,634 --> 00:09:22,574
whether they have good technical bandwidth or not. So no code

147
00:09:22,612 --> 00:09:26,594
tools and also documenting your steps on the way. It's helpful for

148
00:09:26,632 --> 00:09:30,978
scaling teams, but also it's helpful for people to understand how

149
00:09:31,064 --> 00:09:34,466
the conclusion to arrive at a certain data sets was made.

150
00:09:34,568 --> 00:09:38,046
So the documentation step is really underrated

151
00:09:38,078 --> 00:09:41,478
in the industry, but it needs to be really highlighted over here. So every step

152
00:09:41,564 --> 00:09:44,662
of the process needs to be documented and read by everybody.

153
00:09:44,796 --> 00:09:47,946
Ultimately, this thing kind of brings the transparency in the teams, right?

154
00:09:48,048 --> 00:09:52,262
And teams are more flexible about discussing different priorities

155
00:09:52,326 --> 00:09:55,766
and options and ultimately leading to less technical challenges

156
00:09:55,798 --> 00:09:59,254
in the team. Then you have the problem of complexity.

157
00:09:59,382 --> 00:10:02,954
Right. Data science is often limited to only the technical

158
00:10:03,002 --> 00:10:06,746
people. That was a notion before, right? And insufficiency in the representation

159
00:10:06,778 --> 00:10:10,254
of data also leads to poor decision making. So, for example,

160
00:10:10,372 --> 00:10:13,898
the person you put in charge of finding insights

161
00:10:13,914 --> 00:10:16,910
of the data, he was not very good at visualizations from his side.

162
00:10:16,980 --> 00:10:20,306
He has presented the insights in the right manner. But the person who

163
00:10:20,328 --> 00:10:23,746
is there to make decisions out of this data is not able to understand that

164
00:10:23,768 --> 00:10:27,534
data very properly. Right? And this often leads to non

165
00:10:27,662 --> 00:10:31,314
judgment. Like there are judgment issues in this clearly,

166
00:10:31,362 --> 00:10:34,806
right? And you are not able to understand what actually this data is

167
00:10:34,828 --> 00:10:39,510
trying to tell me. Right? So you often complain about that the data is unreadable.

168
00:10:39,850 --> 00:10:43,786
Again, you will see poor decisions making out of him. And also

169
00:10:43,888 --> 00:10:47,206
then the stakeholder is always thinking about, like, data science is too complicated,

170
00:10:47,238 --> 00:10:50,602
let's just skip it at all. Right? Solution to this is, again,

171
00:10:50,656 --> 00:10:54,686
no code is a better method to bring nontechnical people on

172
00:10:54,708 --> 00:10:57,866
board to any data science project. And the turnaround

173
00:10:57,898 --> 00:11:01,614
time, from technical to nontechnical people can be reduced by just using no code

174
00:11:01,652 --> 00:11:05,614
tools, a better visualization techniques that we are going to emphasize and talk

175
00:11:05,652 --> 00:11:09,822
about in this presentation as well. And finally, a proper feedback mechanism

176
00:11:09,886 --> 00:11:13,202
that every time the project ends, how do people discuss? They come together

177
00:11:13,256 --> 00:11:16,242
and they discuss about what were the good things that we did in this project,

178
00:11:16,296 --> 00:11:19,302
whats are the bad things we did in this project. Right.

179
00:11:19,436 --> 00:11:22,486
Last problem, but not the least, which is kind

180
00:11:22,508 --> 00:11:26,230
of the cumbersome of all these different problems that we saw.

181
00:11:26,300 --> 00:11:29,762
And that is the problem of silos. Like inside the organization,

182
00:11:29,826 --> 00:11:33,066
there are walls, invisible walls that are built between the data science team

183
00:11:33,088 --> 00:11:36,810
and the non data science team. And often these walls kind of create

184
00:11:36,880 --> 00:11:39,910
these problems of non interdependent department communications,

185
00:11:39,990 --> 00:11:43,078
right. And ultimately, when there is less communication,

186
00:11:43,174 --> 00:11:46,766
people are not talking about the data that often, or they

187
00:11:46,788 --> 00:11:49,998
are not transparent about what is the approach. Of course, it leads to

188
00:11:50,004 --> 00:11:53,818
the lower growth of organization because the person who is there to make decision doesn't

189
00:11:53,834 --> 00:11:57,534
know data science, but the person who is there to do data science doesn't

190
00:11:57,582 --> 00:12:01,090
have the capability to take decision. So the wall is developed and now

191
00:12:01,160 --> 00:12:04,706
nobody is able to reap the benefits and the overall performance is going

192
00:12:04,728 --> 00:12:08,494
down. Right. Again, solution to this is a combined solution

193
00:12:08,542 --> 00:12:12,134
of all these strategies that we did. First. One is dashboarding how to have

194
00:12:12,172 --> 00:12:15,494
dashboards in internal team. So the data is available 24/7

195
00:12:15,612 --> 00:12:19,486
for anybody at any time. Then automation systems

196
00:12:19,538 --> 00:12:22,682
like how we can reduce a dependency on technical team

197
00:12:22,736 --> 00:12:25,894
to always be there to present data feedbacks,

198
00:12:25,942 --> 00:12:29,642
as we discussed already, feedback mechanism that can properly help people

199
00:12:29,696 --> 00:12:32,954
navigate through these steps. And then finally a documentation method

200
00:12:33,002 --> 00:12:36,382
so everybody knows how the process is going. Well.

201
00:12:36,516 --> 00:12:40,318
That is overall the different themes of problems.

202
00:12:40,404 --> 00:12:44,126
Let's dive into the solution. Now, the first solution, which is not

203
00:12:44,148 --> 00:12:48,130
directly mentioned over anywhere, but I kind of tried to

204
00:12:48,280 --> 00:12:51,394
get it from this book by Jake Knapp called a sprint. Now,

205
00:12:51,432 --> 00:12:54,798
sprint is a method that people often use in technical teams

206
00:12:54,814 --> 00:12:57,558
who are into product development as well.

207
00:12:57,644 --> 00:13:01,430
But it has not been that much used in small

208
00:13:01,500 --> 00:13:05,026
teams or organizations which have data science

209
00:13:05,058 --> 00:13:08,646
as their bread and butter. So often it always tend to go into more kind

210
00:13:08,668 --> 00:13:12,186
of agile methodology like how they want to work on it. Well, what I did

211
00:13:12,208 --> 00:13:15,834
was this sprint approach kind of inspired me and it was a method of

212
00:13:15,872 --> 00:13:19,158
doing projects and testing ideas in just five days in different organizations,

213
00:13:19,174 --> 00:13:22,810
including Google and different ventures that Google invests in.

214
00:13:22,960 --> 00:13:26,798
So I kind of picked some of the techniques from there and combined it

215
00:13:26,804 --> 00:13:30,366
with some data science approaches and kind of try to came up with this

216
00:13:30,468 --> 00:13:34,686
sprint approach that works a lot better than before.

217
00:13:34,788 --> 00:13:38,254
So there are four steps to this sprint approach, clear goal,

218
00:13:38,382 --> 00:13:41,966
plan well, execute and test and improvise. So all these stages are divided

219
00:13:41,998 --> 00:13:45,698
into these four tools. And then finally in each step,

220
00:13:45,784 --> 00:13:49,410
everything starts with the introduction of this project. So everybody comes together,

221
00:13:49,560 --> 00:13:52,598
discussed. What is the main idea over here? Whats is the problem that they

222
00:13:52,604 --> 00:13:55,986
are trying to solve? So they set a long term goal. A long term goal

223
00:13:56,018 --> 00:13:59,234
could be a long term questions that they are trying to improve the user consumption

224
00:13:59,282 --> 00:14:02,526
method on the platform or they are trying to minimize the cost. So that's

225
00:14:02,578 --> 00:14:05,706
like a long term aspirational goal. Then you set some

226
00:14:05,728 --> 00:14:09,594
kind of sprint questions, like what are the questions you are trying to answer over

227
00:14:09,632 --> 00:14:12,822
here? Right? So these could be like directly

228
00:14:12,886 --> 00:14:15,914
you are trying to understand the male versus female

229
00:14:15,962 --> 00:14:18,974
ratio of the data. So you are kind of lives trying to be exact over

230
00:14:19,012 --> 00:14:23,034
here. Then what you do is once you create a question bank,

231
00:14:23,082 --> 00:14:26,430
like what are the questions you are. Of course these questions should be limited.

232
00:14:26,510 --> 00:14:30,034
Don't try to exceed it to 2030 or more

233
00:14:30,072 --> 00:14:34,050
than that, because ultimately that would lead to the longer timelines. The whole

234
00:14:34,120 --> 00:14:38,026
target of doing a sprint is to achieve a limited scope in a limited timeline

235
00:14:38,078 --> 00:14:42,134
and having the fixed timeline and fixed scope to do it.

236
00:14:42,332 --> 00:14:45,926
Finally, make a map of how you are going to arrive at

237
00:14:45,948 --> 00:14:48,838
a solution. We will see about how to create a diagram or a map to

238
00:14:48,844 --> 00:14:52,070
this as well. So kind of map you can imagine is like you have data,

239
00:14:52,140 --> 00:14:55,158
how the data is flowing, how you will flow it through different systems. So this

240
00:14:55,164 --> 00:14:58,134
is kind of a project that you are doing in the initial steps of your

241
00:14:58,172 --> 00:15:01,902
project discussions, just kind of sentiments so that everybody

242
00:15:02,036 --> 00:15:05,486
starts imagining what are the resources required to do that. So this kind of will

243
00:15:05,508 --> 00:15:09,422
help you in. Of course, clearly the goal. The second step is now starting

244
00:15:09,476 --> 00:15:13,002
with planning, right? So the first step with this is talk with experts.

245
00:15:13,066 --> 00:15:16,302
If your team already has experts, data science engineers, experts,

246
00:15:16,366 --> 00:15:19,970
go talk to them. But don't kind of always

247
00:15:20,120 --> 00:15:23,682
undermine the solution, just what they are saying, because they might be limited in

248
00:15:23,736 --> 00:15:27,246
their understanding about the project as well. So listen to them, keep the thoughts,

249
00:15:27,278 --> 00:15:30,662
but ultimately you are the decision maker in it. And you can go to other

250
00:15:30,716 --> 00:15:34,166
outside help as well. You can talk with other people, like how somebody else would

251
00:15:34,188 --> 00:15:38,326
have solved that problem. Go to different forums so that could help. Then what

252
00:15:38,348 --> 00:15:41,206
you have to do is pick a small target. So out of this question that

253
00:15:41,228 --> 00:15:44,346
we discussed now what you are doing is for the starting going, you have to

254
00:15:44,368 --> 00:15:46,906
pick a small target and then you have to see how you can arrive at

255
00:15:46,928 --> 00:15:50,794
multiple conclusions from the same small set of questions.

256
00:15:50,992 --> 00:15:54,618
Now, for everybody who is in the team, I am imagining

257
00:15:54,634 --> 00:15:57,520
that the team is usually of the size of four to five people.

258
00:15:57,890 --> 00:16:01,514
Two of them are pure technical, hands on people who are writing

259
00:16:01,562 --> 00:16:05,438
the code. Two of them are into data and visualization and

260
00:16:05,444 --> 00:16:08,274
one of them could be a manager. So ideally it works good with the five

261
00:16:08,312 --> 00:16:11,762
people team. Now what you have to ask is everybody in the team like

262
00:16:11,816 --> 00:16:15,230
how they think they might go for the solution?

263
00:16:15,310 --> 00:16:18,786
What are the different approaches that they think they can adopt? Don't discuss it

264
00:16:18,808 --> 00:16:21,686
out. Let everybody write on a sticky note and stick it to a board.

265
00:16:21,788 --> 00:16:25,574
And then let people vote for these approaches. That would help

266
00:16:25,612 --> 00:16:29,426
us identify what approach we can go for once an approach

267
00:16:29,458 --> 00:16:32,678
is identified. Second thing, what you have to do is to create a flow

268
00:16:32,694 --> 00:16:35,866
diagram. Now this flow diagram is a little bit different than the map whats we

269
00:16:35,888 --> 00:16:39,194
discussed in the previous step. Flow diagram is more like now

270
00:16:39,232 --> 00:16:42,394
you have started to discuss that. This is the data that has to come through.

271
00:16:42,432 --> 00:16:45,646
If the data need a preprocessing, you have to add a preprocessing step. If the

272
00:16:45,668 --> 00:16:49,614
data needs some more big

273
00:16:49,652 --> 00:16:52,826
data solutions or processing on that and so that would be captured.

274
00:16:52,858 --> 00:16:56,610
We'll discuss more about how to do diagramming in the upcoming slides as well.

275
00:16:56,760 --> 00:17:00,466
Now you are clear with what you

276
00:17:00,488 --> 00:17:03,650
are actually trying to solve. You have created a flow diagram as well.

277
00:17:03,720 --> 00:17:07,538
The next step in this step is so this was the first step. Second is

278
00:17:07,544 --> 00:17:11,206
the plan. Well, third is the execute step. Now you have a

279
00:17:11,228 --> 00:17:14,486
plan in action. Now you want to execute that and you want to

280
00:17:14,508 --> 00:17:17,974
bring everybody on board and arrive at a conclusion as soon as

281
00:17:18,012 --> 00:17:21,562
possible. So you have to set the deliverables out of it. So, which is similar

282
00:17:21,616 --> 00:17:25,302
to what you set as a sprint question. Then you set up a pick target

283
00:17:25,366 --> 00:17:28,986
and then you are trying to set deliverables out of them.

284
00:17:29,088 --> 00:17:33,398
Fix these deliverables. Don't let anybody add more deliverables

285
00:17:33,414 --> 00:17:36,814
to it. Do another sprint or maybe a future project to overcome that.

286
00:17:36,852 --> 00:17:40,186
But for now, fix these deliverables and then set a pure

287
00:17:40,218 --> 00:17:43,626
timeline. A timeline could be one to two weeks. Whats ideally

288
00:17:43,658 --> 00:17:46,306
works for the sprint, it could be three weeks as well. If you think that

289
00:17:46,328 --> 00:17:49,982
scope is a little big, divide these tasks according

290
00:17:50,126 --> 00:17:53,538
across the team. So this is normal project management 101.

291
00:17:53,624 --> 00:17:57,134
Then meet regularly. Already decide what would be the meeting

292
00:17:57,182 --> 00:18:00,726
points, what would be the meeting agenda, depending upon how your

293
00:18:00,828 --> 00:18:04,454
project projects, and always do a health check of how different

294
00:18:04,572 --> 00:18:08,520
members of the team and how different aspects of the projects are working.

295
00:18:10,490 --> 00:18:14,262
So then you have the last step that is test and improvise.

296
00:18:14,326 --> 00:18:17,338
Once you have the data in place, now you want to test your hypothesis if

297
00:18:17,344 --> 00:18:20,886
it's working or not. Now, instead of just going into plain dashboarding

298
00:18:20,918 --> 00:18:24,418
and trying to display data, first of all, have a small mvp

299
00:18:24,454 --> 00:18:28,158
or a test report to test. But if your hypothesis were right or not,

300
00:18:28,324 --> 00:18:31,934
go back to the main stakeholder, ask it if it's right or not.

301
00:18:31,972 --> 00:18:35,170
There would be some minor changes that you might need. Do these changes,

302
00:18:35,240 --> 00:18:38,514
bring back the data and then present this data on any live

303
00:18:38,552 --> 00:18:42,366
dashboard. So this is the present findings. Collect feedbacks

304
00:18:42,398 --> 00:18:46,034
in that group, improvise over this feedback if it could be done in the same

305
00:18:46,072 --> 00:18:49,686
sprint, and then finally document these learning. Now, you can see

306
00:18:49,708 --> 00:18:52,998
there is a big blue arrow that goes back to introduction to the project.

307
00:18:53,084 --> 00:18:56,774
So every time you find these learning, discuss them again when

308
00:18:56,812 --> 00:19:00,134
the next sprint is going to start. So these were the feedbacks, these were the

309
00:19:00,172 --> 00:19:03,706
learnings that we did for the last projects. This is how you're going to help.

310
00:19:03,808 --> 00:19:06,966
Again, I would highly recommend to go through the book by JKnAp

311
00:19:06,998 --> 00:19:10,298
that is sprint, and it would really help you understand how you

312
00:19:10,304 --> 00:19:14,362
can arrive at quick decisions, how you can make small projects and create

313
00:19:14,416 --> 00:19:17,806
this sprint approach and add it to your organizations. Now,

314
00:19:17,908 --> 00:19:21,374
we were discussing diagramming a lot, right? So to me,

315
00:19:21,412 --> 00:19:25,118
I think diagrams are really underrated when it comes to

316
00:19:25,284 --> 00:19:29,234
different teams. I have not seen anybody who is very enthusiastic about,

317
00:19:29,272 --> 00:19:32,478
okay, let's create a diagram and let's solve the problem by creating a diagram.

318
00:19:32,574 --> 00:19:35,940
But what basically diagrams do is that they get everybody

319
00:19:36,390 --> 00:19:39,666
on the point, it gets everybody clear about the thoughts

320
00:19:39,698 --> 00:19:42,866
and they bring everybody to the same page. And it also helps

321
00:19:42,898 --> 00:19:46,242
set realistic expectations and timelines,

322
00:19:46,386 --> 00:19:49,846
what people think about how things take time, right? If you're looking

323
00:19:49,868 --> 00:19:52,678
at just a bunch of code, then it doesn't make sense and it doesn't helps

324
00:19:52,694 --> 00:19:55,818
people estimate the resources properly. But if you diagram something,

325
00:19:55,904 --> 00:19:59,430
it's visually appealing and it helps people make decisions faster.

326
00:19:59,510 --> 00:20:02,534
And of course, once you have realistic,

327
00:20:02,582 --> 00:20:05,966
achievable goals that you can set from the diagrams or timelines that you have,

328
00:20:06,068 --> 00:20:09,706
it also helps you in estimating the resources. So I'm

329
00:20:09,738 --> 00:20:12,666
going to show you a small quick demo of how you can create diagrams.

330
00:20:12,698 --> 00:20:16,206
Again, it's a complete diagram 101, but I would highly recommend

331
00:20:16,308 --> 00:20:20,238
to go over small videos over UML diagrams or flowchart diagrams

332
00:20:20,254 --> 00:20:23,906
of how you have to do so. How I actually go always with diagrams is

333
00:20:23,928 --> 00:20:27,346
that I always place the main components and key findings or

334
00:20:27,368 --> 00:20:30,806
the key components of the whole diagrams first. So for example, let's say

335
00:20:30,828 --> 00:20:34,226
I am trying to find the male versus female ratio

336
00:20:34,338 --> 00:20:37,894
out of a web analytics data. So of course what I would do is that

337
00:20:37,932 --> 00:20:41,058
I would kind of make things web chart as first that

338
00:20:41,084 --> 00:20:44,554
this is the data ingestion source. Then I think this

339
00:20:44,592 --> 00:20:48,054
next key step or the next data source is of course a database

340
00:20:48,102 --> 00:20:50,954
or a data lock system that is keeping this data.

341
00:20:51,072 --> 00:20:54,506
Now as I go ahead, I am not putting any arrows

342
00:20:54,538 --> 00:20:58,138
or connectors right now. Firstly, the important thing is just to keep all the elements

343
00:20:58,234 --> 00:21:02,154
over here. Then I would actually need a script

344
00:21:02,202 --> 00:21:06,126
that would do a data preprocessing. So it would be a python script

345
00:21:06,158 --> 00:21:09,298
or something like that. And then once the data

346
00:21:09,384 --> 00:21:13,314
pipe processing is complete, I would probably run some

347
00:21:13,352 --> 00:21:16,754
kind of SQL queries. And let's say if this was more

348
00:21:16,792 --> 00:21:21,190
like a big data situation, I can actually go with bigquery from

349
00:21:21,340 --> 00:21:25,254
Google and that would actually help me solve this thing. So that bigquery is the

350
00:21:25,292 --> 00:21:28,566
script that I have to write and I can write query over here.

351
00:21:28,668 --> 00:21:31,658
Once this query is done, of course I would have bunch of data. Then I

352
00:21:31,664 --> 00:21:34,906
can use something like let's say data studio or

353
00:21:34,928 --> 00:21:38,522
Google data studio to present this visualization. I think the better would be to

354
00:21:38,576 --> 00:21:41,898
kind of have visualization tools like that.

355
00:21:41,984 --> 00:21:45,306
Now this is a typical thing. Now what I have to do is when I'm

356
00:21:45,338 --> 00:21:48,714
connecting it, so the data is constantly updated

357
00:21:48,842 --> 00:21:51,678
onto the databased. So that is like a repeat step.

358
00:21:51,844 --> 00:21:55,214
Now every time, what do you say?

359
00:21:55,332 --> 00:21:58,866
Once in a while I will go and pick up this data and kind of

360
00:21:58,888 --> 00:22:02,558
try to pass this through this data pipeline process. So what I'm

361
00:22:02,574 --> 00:22:06,306
going to do is every 24 hours, let's say

362
00:22:06,408 --> 00:22:09,998
I would pass this data to my python script which will do the data preprocessing

363
00:22:10,014 --> 00:22:13,206
and clear the data. Then I will do some kind of querying on this which

364
00:22:13,228 --> 00:22:16,918
will arrive me at the visualization and this would be the ETL that I

365
00:22:16,924 --> 00:22:20,402
will set for the whole time. And this would be the non tech objective

366
00:22:20,466 --> 00:22:23,674
outcome that any user or any decision maker can

367
00:22:23,712 --> 00:22:26,858
see to identify this thing. So this was a very simple example.

368
00:22:26,944 --> 00:22:30,458
Sometimes things would go complex that you would need conditional things, right?

369
00:22:30,544 --> 00:22:33,882
Sometimes the query won't work, then you have to go back to the main data

370
00:22:33,936 --> 00:22:37,278
and then you have to do the preprocessing again. So the brainstorming that

371
00:22:37,284 --> 00:22:39,854
the teams are doing and the planning that the teams are doing should be done

372
00:22:39,892 --> 00:22:43,326
on these diagramming steps, which can help people understand what

373
00:22:43,348 --> 00:22:45,934
are the main goals, what are the main objectives that they are trying to arrive

374
00:22:45,982 --> 00:22:49,698
at? So next, an important

375
00:22:49,784 --> 00:22:53,266
section of this presentation was to find approaches. Code and no

376
00:22:53,288 --> 00:22:56,926
code tools are very sorry, no code and low code tools are very popular.

377
00:22:56,958 --> 00:23:00,422
So I wanted to do a small comparison between these two tools. So code,

378
00:23:00,476 --> 00:23:04,242
of course, we are all familiar with it has the flexibility, it has the scalability

379
00:23:04,306 --> 00:23:07,666
and high function availability. Like you can pretty much do everything that you can imagine

380
00:23:07,698 --> 00:23:10,726
if you know what are the right code ways to do it. But of course,

381
00:23:10,748 --> 00:23:14,006
the cons on things end is that you need to know technically

382
00:23:14,118 --> 00:23:17,130
how things are done. Talent acquisition is a problem these days.

383
00:23:17,200 --> 00:23:21,318
Again, data is silos because tech people are not the decision makers

384
00:23:21,334 --> 00:23:25,006
and decision maker doesn't know the tech. And of course the model complexity also is

385
00:23:25,028 --> 00:23:28,142
a problem that if you are using any third party models to

386
00:23:28,196 --> 00:23:31,550
process your data using machine learning approach, then you don't know how things

387
00:23:31,620 --> 00:23:34,894
work and you don't have the clear idea of how you can get things done.

388
00:23:34,932 --> 00:23:37,758
So there would be always a time that you will get stuck and you don't

389
00:23:37,774 --> 00:23:41,854
know what to do after that. Now, some of these challenges are overcome

390
00:23:41,902 --> 00:23:45,634
by no code tools. And first of all, the fun aspect of this

391
00:23:45,672 --> 00:23:48,722
is like, it's very fast. Like you can arrive at a conclusion at very fast

392
00:23:48,776 --> 00:23:52,054
things because you are not setting up the bare minimal or the base things over

393
00:23:52,092 --> 00:23:55,942
here. It has a low learning curve, almost very easy to learn

394
00:23:55,996 --> 00:23:59,894
about these drag and drop functions. It's fun and engaging. Usually these tools are very

395
00:23:59,932 --> 00:24:03,782
fun to use. Like I have seen different tools with Google data studios

396
00:24:03,846 --> 00:24:06,998
or intersect labs or any parabola AI. So it's

397
00:24:07,014 --> 00:24:10,538
very fun to use and it's visually appealing. You can easily understand what are

398
00:24:10,544 --> 00:24:13,886
the things going on. It increases the productivity because you don't have to

399
00:24:13,908 --> 00:24:17,486
do different things. It's just simple ingestion of data and

400
00:24:17,508 --> 00:24:20,894
presenting it. And also it's kind of open between the team.

401
00:24:20,932 --> 00:24:24,606
Like anybody can come and see how are the different functions that are working.

402
00:24:24,708 --> 00:24:26,800
But it also has its own cons.

403
00:24:27,830 --> 00:24:31,026
It's not too flexible to do it. You cannot do everything with it.

404
00:24:31,048 --> 00:24:34,062
You can do only the tools that are provided to you on that aspect,

405
00:24:34,126 --> 00:24:38,126
right. And also you're limited to the source that you can choose of your

406
00:24:38,168 --> 00:24:42,258
choice, right. Which also means there are less options of these tools

407
00:24:42,274 --> 00:24:45,906
that are available. And also you are always dependent upon these approaches

408
00:24:45,938 --> 00:24:49,442
and these tools for going forward. So if, let's say, the company shut down tomorrow,

409
00:24:49,506 --> 00:24:53,322
your project is also shut down forever. And also you have these scalability issues

410
00:24:53,376 --> 00:24:56,778
like if the data grows big, then there might be some issues with if you

411
00:24:56,784 --> 00:25:00,454
can use the tools or not. So let's go one step deeper

412
00:25:00,502 --> 00:25:03,726
and see little bit of core tools. What I see usually is

413
00:25:03,748 --> 00:25:07,626
that the core tools are divided into three main sentiments, data science programming

414
00:25:07,658 --> 00:25:12,382
languages which includes Python, R or Scala. These are main

415
00:25:12,516 --> 00:25:15,858
bare minimal ways of doing data science. Then you

416
00:25:15,864 --> 00:25:19,954
have querying and analysis tools which include SQL, MatLab and

417
00:25:19,992 --> 00:25:23,842
Bigquery. And then you have application suit which is like a

418
00:25:23,976 --> 00:25:27,694
packed bunch of things that are packed together. Apache, Spark,

419
00:25:27,742 --> 00:25:31,186
Big ML, Hadoop. Again, this is just a general example. There are other tools

420
00:25:31,218 --> 00:25:34,726
as well. So anybody who is beginner, they can choose one track, like they

421
00:25:34,748 --> 00:25:38,434
can choose the Python track, add SQL to the stack and then use Spark

422
00:25:38,482 --> 00:25:42,170
to kind of have an application suit. You want to go in more

423
00:25:42,320 --> 00:25:45,834
generic manner. You can just go with the querying analysis tool that I've discussed like

424
00:25:45,872 --> 00:25:49,674
Bigquery over here. Then the next side

425
00:25:49,712 --> 00:25:53,114
of tools that we have no code tools. Again, it's just a generalized

426
00:25:53,162 --> 00:25:56,734
way of presenting these things. The tools expands more than

427
00:25:56,772 --> 00:26:00,286
that. So the first set of tools you have is easy to

428
00:26:00,308 --> 00:26:03,966
create dashboards and reporting tools. So popular one

429
00:26:03,988 --> 00:26:08,242
includes Google Data Studio, completely free to use tableau, it's limited free

430
00:26:08,296 --> 00:26:12,174
and then power bi. It's also kind of free to use these tools, doesn't require

431
00:26:12,222 --> 00:26:15,826
any technical knowledge whatsoever. You just come and drag and drop data and

432
00:26:15,848 --> 00:26:18,946
then you are able to do things out of them as well. Then you have

433
00:26:19,048 --> 00:26:22,854
build and automation data science flows tools, right? And these are

434
00:26:22,892 --> 00:26:26,166
more like if you want to do repeat tasks, you don't have time to go

435
00:26:26,188 --> 00:26:29,846
and set up the pipeline. Again, you don't have the manual time of ingesting the

436
00:26:29,868 --> 00:26:33,498
data. So then you can use these tools such as explainti, intersect labs and

437
00:26:33,504 --> 00:26:36,954
data robot. And then there are again complete end to end

438
00:26:36,992 --> 00:26:40,570
data science flow tools that we were discussing on the core tool side as well.

439
00:26:40,640 --> 00:26:44,154
You have obviously AI and Ghana which kind of helps you to

440
00:26:44,192 --> 00:26:47,742
provide all tools at the same place and that kind of helps you do

441
00:26:47,796 --> 00:26:51,306
everything with the data. Again, these are all no code tools, you can explore

442
00:26:51,338 --> 00:26:54,746
them one on one and then that would help you identify what kind of tools

443
00:26:54,778 --> 00:26:58,482
would work best for you. Then now

444
00:26:58,536 --> 00:27:02,002
you want to make things decision that which tool you should go for,

445
00:27:02,056 --> 00:27:06,706
code or no code. This metrics kind of help you understand what

446
00:27:06,728 --> 00:27:10,386
kind of solution would be better for you. So if your functional

447
00:27:10,418 --> 00:27:14,102
requirements are low and you need the results high,

448
00:27:14,156 --> 00:27:17,990
then it is the perfect way to go with the no code solution,

449
00:27:18,070 --> 00:27:21,626
right? Again, if your functional requirements are low

450
00:27:21,728 --> 00:27:25,286
and even the expectations are still slow,

451
00:27:25,318 --> 00:27:29,914
you can still go with no code solution which

452
00:27:29,952 --> 00:27:32,698
are ideal for individual projects. So that is the main thing.

453
00:27:32,784 --> 00:27:36,474
So you can see that the function requirement is the main thing that decides

454
00:27:36,522 --> 00:27:40,686
if you want to go with the no code tools or not. So then if

455
00:27:40,708 --> 00:27:44,622
your function requirements are high and your expectations

456
00:27:44,686 --> 00:27:48,466
are fast, then I don't things the no code solution would actually

457
00:27:48,568 --> 00:27:52,994
make sense to you. And also if

458
00:27:53,032 --> 00:27:56,226
the expectations are slow still you will go

459
00:27:56,248 --> 00:27:59,506
with the traditional ML technique. So it all depends

460
00:27:59,538 --> 00:28:03,078
upon what I've seen is if the low functional requirement is a

461
00:28:03,084 --> 00:28:06,166
key decision maker to choice if you want to go with no code tools or

462
00:28:06,188 --> 00:28:09,954
not. Next step. I think visualizations

463
00:28:10,002 --> 00:28:13,626
is also something that everybody in the team needs to be aware about

464
00:28:13,728 --> 00:28:17,334
how to use different charts and methods and different says to visualize

465
00:28:17,382 --> 00:28:20,726
data when it comes to making these decisions, like some libraries

466
00:28:20,758 --> 00:28:24,554
that helps you make visualizations are d three, plotly and

467
00:28:24,592 --> 00:28:28,474
ratplotly. This is kind of an order of different flowchart

468
00:28:28,522 --> 00:28:31,646
that. What is the kind of data you have which will help you make the

469
00:28:31,668 --> 00:28:35,006
decision? So a common path is if you have more than one

470
00:28:35,028 --> 00:28:38,494
variable, you will go with this path. Then are these variables

471
00:28:38,542 --> 00:28:42,606
similar? Yes, you will go with this part. Is there a hierarchy involved

472
00:28:42,638 --> 00:28:45,982
in it? If you say no, okay, are they ordered? No.

473
00:28:46,056 --> 00:28:49,926
Then go with this. So you can take a screenshot of this slide and that

474
00:28:49,948 --> 00:28:53,702
would help you understand, make proper

475
00:28:53,756 --> 00:28:56,120
judgment of how to present data going forward.

476
00:28:57,690 --> 00:29:01,282
This is a more in detail kind of diagram

477
00:29:01,346 --> 00:29:04,842
which helps you see what are the different charts and when they are used

478
00:29:04,896 --> 00:29:08,074
in certain situations. So again, you can take a screenshot of this as

479
00:29:08,112 --> 00:29:11,660
well and share it with your internal teams. That could help you

480
00:29:12,110 --> 00:29:15,390
devise the proper method of what chart you should use in which situation.

481
00:29:15,540 --> 00:29:19,214
Again, the link to things talk would be also available. And you can use

482
00:29:19,252 --> 00:29:22,526
this for your future projects as a kind of

483
00:29:22,628 --> 00:29:25,280
playbook for your future projects as well.

484
00:29:26,530 --> 00:29:30,526
Now you are done with the whole planning thing. You are done with diagramming

485
00:29:30,558 --> 00:29:33,154
thing, you have done with deciding the tool that you have to use. Now,

486
00:29:33,192 --> 00:29:36,526
the final step in doing all these things is dashboarding.

487
00:29:36,638 --> 00:29:40,646
Basically presenting your findings in a very organized manner and making it

488
00:29:40,668 --> 00:29:44,134
available for everybody. And dashboarding is divided into four

489
00:29:44,172 --> 00:29:47,786
main steps. Whats is collecting these visualizations, what you have to do is you have

490
00:29:47,808 --> 00:29:51,770
all these 1234 question, and every question

491
00:29:51,840 --> 00:29:55,626
has its own visualization, different kind of

492
00:29:55,648 --> 00:30:00,378
charts. You collect all them together and you try to have

493
00:30:00,464 --> 00:30:03,994
one way to do it. Then you organize them based on priority.

494
00:30:04,042 --> 00:30:07,918
The first thing to keep in mind is the most important question.

495
00:30:08,004 --> 00:30:11,550
Always remain on the top, right? Always the main question,

496
00:30:11,620 --> 00:30:13,918
arrive at the top. And the second thing you have to do is if there

497
00:30:13,924 --> 00:30:17,266
is a data connection, like if first question, answer the second. So those

498
00:30:17,288 --> 00:30:20,754
graphs needs to be organized together. So let's say if this was one

499
00:30:20,792 --> 00:30:24,654
graph and there was one conclusion out of it, so you need the second trash

500
00:30:24,782 --> 00:30:28,606
next to it, then this is plain 101. Kind of organizing

501
00:30:28,638 --> 00:30:32,006
and kind of arranging thing doesn't make sense, but we always skip the

502
00:30:32,028 --> 00:30:35,702
steps. And when it comes to dashboarding, we are just applying things as they go.

503
00:30:35,836 --> 00:30:39,334
Then you have to set an automatic schedule. So tools that I have mentioned

504
00:30:39,372 --> 00:30:43,034
over here, like Apache Superset or Airflow or Gramx, they kind of have

505
00:30:43,072 --> 00:30:47,046
inbuilt capability of automating and pulling the data from the main source

506
00:30:47,078 --> 00:30:50,234
on time to time basis. So if that is kind of a niche that you

507
00:30:50,272 --> 00:30:53,934
want, you can then set these things, set up a timer that when you

508
00:30:53,972 --> 00:30:57,230
want these data to be accessed again, again,

509
00:30:57,300 --> 00:31:01,114
tools such as superset, Gramx, plotly, dash and quicksites

510
00:31:01,162 --> 00:31:04,286
have functions that you can include non tech people, share the access with

511
00:31:04,308 --> 00:31:07,522
them and that would actually help them also

512
00:31:07,576 --> 00:31:10,450
come at any time and do this. So this is kind of the dashboarding process

513
00:31:10,520 --> 00:31:14,210
that you need to make as the final step of your journey.

514
00:31:15,190 --> 00:31:18,494
And then finally your dashboarding is done. Now you need to document

515
00:31:18,542 --> 00:31:22,322
stuff, right? So from the day one, only create a shared document.

516
00:31:22,386 --> 00:31:26,034
People, users, notion, excel and all bunch of stuff. For my preference,

517
00:31:26,082 --> 00:31:28,886
I think the simplest way to go about it is just an excel sheet with

518
00:31:28,908 --> 00:31:32,406
a point to point description of what are the different things. Create a shared

519
00:31:32,438 --> 00:31:35,450
document, add different progress as you go,

520
00:31:35,600 --> 00:31:38,842
and then add the findings that you were looking like,

521
00:31:38,896 --> 00:31:42,366
main findings from that project, and then collect feedbacks into the

522
00:31:42,388 --> 00:31:46,302
same document. Make this document available in the next print. And that kind of become

523
00:31:46,356 --> 00:31:50,000
evolutionary cycle improves the overall step and overall planning.

524
00:31:50,690 --> 00:31:54,414
Well, that is all about what we want to discuss today.

525
00:31:54,532 --> 00:31:58,546
So we started with a problem, and we started with what

526
00:31:58,568 --> 00:32:02,530
are the different problems that are into the data science issue

527
00:32:02,600 --> 00:32:06,322
in things space. Then we also looked into some of the solutions, which are

528
00:32:06,376 --> 00:32:09,846
approaches. Then we discovered the code approach and the no

529
00:32:09,868 --> 00:32:13,078
code approach of doing these things. We also saw how you

530
00:32:13,084 --> 00:32:17,874
can use visualizations, different techniques of visualization, to present your data dashboarding,

531
00:32:17,922 --> 00:32:21,298
to collect all things visualization into one organized fashion.

532
00:32:21,314 --> 00:32:24,762
And then finally documenting as this final sprint. And also we

533
00:32:24,816 --> 00:32:29,050
explored a new common method that is going to be popular. These says

534
00:32:29,120 --> 00:32:32,750
that is sprint. And also you can use diagramming to explain

535
00:32:32,900 --> 00:32:36,302
what you want to know. Well, that is

536
00:32:36,356 --> 00:32:40,480
more or less about it that I could find in this time.

537
00:32:41,170 --> 00:32:44,926
I hope I was able to deliver something new. I was able

538
00:32:44,948 --> 00:32:48,366
to open some thoughts about it. Again, it was not a code 101

539
00:32:48,388 --> 00:32:51,774
or DIY that you might be expecting, but this was more around how to bring

540
00:32:51,812 --> 00:32:55,158
that exposure of finding insights out of the data.

541
00:32:55,284 --> 00:32:58,598
This was Aman Sharma. If you really like the presentation, please let me know the

542
00:32:58,604 --> 00:33:02,486
feedback on my handle. And again, the link to this presentation would

543
00:33:02,508 --> 00:33:06,006
be available. So until that time, if you have any

544
00:33:06,028 --> 00:33:08,662
questions, please drop it to me and thanks for your time.

