1
00:00:26,050 --> 00:00:29,190
Hello everyone. Today were going to talk about

2
00:00:29,260 --> 00:00:32,978
polyglot polyglot polyglot polyglot cloudnative debugger beyond APM apms

3
00:00:33,154 --> 00:00:36,726
we don't have much time so I'll get right to it. But first a few

4
00:00:36,748 --> 00:00:39,874
things about me. I was a consultant for over a decade.

5
00:00:39,922 --> 00:00:43,394
I worked at sun, founded a couple of companies, wrote a couple of books.

6
00:00:43,442 --> 00:00:46,454
I wrote a got of open source code, and currently work as

7
00:00:46,492 --> 00:00:49,778
a developer advocate for Lightrun. My email and Twitter

8
00:00:49,794 --> 00:00:52,894
account are listed here, so feel free to write to me.

9
00:00:53,092 --> 00:00:57,530
I have a blog that talks about debugging and production issues at talktodeduck

10
00:00:57,610 --> 00:01:00,686
Dev. It would be great if you check it out and let me

11
00:01:00,708 --> 00:01:04,514
know what you think. I love apms. They are

12
00:01:04,552 --> 00:01:07,986
absolutely wonderful. I'm old enough to remember a time

13
00:01:08,088 --> 00:01:12,066
where they weren't around and I'm so happy we moved past that.

14
00:01:12,248 --> 00:01:15,826
This is absolutely amazing. The dashboards and

15
00:01:15,848 --> 00:01:19,918
the details. You get this great dashboard with just everything you

16
00:01:19,944 --> 00:01:23,346
need. Amazing. Were truly at a golden age of monitoring

17
00:01:23,458 --> 00:01:26,898
hell. When I started, we used to monitor the server by kicking it and listening

18
00:01:26,914 --> 00:01:30,090
to see if the hard drive was spinning properly. Today,

19
00:01:30,160 --> 00:01:34,314
with kubernetes, the deployment scaled to such a level that

20
00:01:34,352 --> 00:01:37,894
we need tools like this to get some insight into production.

21
00:01:38,022 --> 00:01:41,306
Without an APM, we're, well, not as

22
00:01:41,328 --> 00:01:45,086
blind as a bat, but it's pretty close. A lot of the

23
00:01:45,108 --> 00:01:48,874
issues we run into start when we notice an anomaly

24
00:01:48,922 --> 00:01:52,126
in the dashboard. We see a spike in failures or

25
00:01:52,148 --> 00:01:55,438
something that performs a bit too slow. The APM

26
00:01:55,534 --> 00:01:59,614
is amazing in showing those hiccups, but this is where it stops.

27
00:01:59,742 --> 00:02:03,438
It can tell us that a web service performed badly or failed.

28
00:02:03,534 --> 00:02:06,834
It can't tell us why. It can't point us at a

29
00:02:06,872 --> 00:02:10,086
line of code. So let's stop for

30
00:02:10,108 --> 00:02:13,846
a second and talk about a different line. This line. On the

31
00:02:13,868 --> 00:02:17,778
one side we have developers, on the other side we have the ops

32
00:02:17,794 --> 00:02:21,306
or DevOps. This is a line were had for

33
00:02:21,328 --> 00:02:24,634
a long time. It's something we drew out of necessity because when

34
00:02:24,672 --> 00:02:27,290
developers were given access to production,

35
00:02:27,790 --> 00:02:31,646
well, I don't want to be too dramatic, but when developers got

36
00:02:31,668 --> 00:02:35,594
access to production, it didn't end well. This was literally

37
00:02:35,642 --> 00:02:39,374
the situation not too long ago. Yes, we had

38
00:02:39,412 --> 00:02:42,800
sysadmins, but the whole process used to be a mess.

39
00:02:43,170 --> 00:02:46,562
That was no good. We need a better

40
00:02:46,616 --> 00:02:49,858
solution than this hard separation because the ops guys

41
00:02:49,944 --> 00:02:53,774
don't necessarily know how to solve problems made by the developers.

42
00:02:53,902 --> 00:02:57,014
They know how to solve ops problems. So when a

43
00:02:57,052 --> 00:03:00,422
container has a problem and the DevOps don't know how to fix it.

44
00:03:00,476 --> 00:03:03,782
Well, it starts a problematic feedback loop of

45
00:03:03,836 --> 00:03:07,670
test, redeploy, rinse, repeat. That isnt ideal.

46
00:03:08,430 --> 00:03:12,074
Monitoring tools are like the bat signal. They come up

47
00:03:12,112 --> 00:03:15,914
and we, the developers, we're Batman or Batwoman or bat

48
00:03:15,952 --> 00:03:18,970
person. All of us heroes,

49
00:03:19,550 --> 00:03:22,814
we step up to deal with the bugs. We're the last

50
00:03:22,852 --> 00:03:25,630
line of defense against their, well, villainy.

51
00:03:26,130 --> 00:03:29,326
Well were coderbat people. It's kind of the same

52
00:03:29,348 --> 00:03:32,506
thing without the six pack abs, too much baked goods,

53
00:03:32,538 --> 00:03:36,034
you know, in the company kitchen here, coderbat man needs

54
00:03:36,072 --> 00:03:39,394
to know where the crime or bugs are happening in the code.

55
00:03:39,512 --> 00:03:42,626
So these dashboards, they point us toward the

56
00:03:42,648 --> 00:03:47,018
crime we have to fight in our system. But here's

57
00:03:47,054 --> 00:03:50,434
where things get hard. We start digging into the logs,

58
00:03:50,482 --> 00:03:53,750
trying to find the problem. The dashboard sent us into a general

59
00:03:53,820 --> 00:03:58,066
direction, like a performance problem or high error rates.

60
00:03:58,178 --> 00:04:01,706
But now we need to jump into logs and hope that

61
00:04:01,728 --> 00:04:05,414
we can find something there that will somehow explain the problem we're

62
00:04:05,462 --> 00:04:09,034
seeing. That's like going from a jet engine back

63
00:04:09,072 --> 00:04:13,226
to stone age tools. There are many logs processing

64
00:04:13,258 --> 00:04:17,134
platforms that do an amazing job at processing these logs and

65
00:04:17,172 --> 00:04:21,194
finding the gold within them. But even then it's a needle

66
00:04:21,242 --> 00:04:24,538
in a haystack. That's the good outcome

67
00:04:24,714 --> 00:04:28,514
where a log is already there waiting for us. But obviously we

68
00:04:28,552 --> 00:04:32,242
can't have logging all over the place. Our billing will go through the roof

69
00:04:32,296 --> 00:04:35,490
and our performance, well it will suffer.

70
00:04:36,390 --> 00:04:39,842
We're stuck in the sloop of add a new log, go through

71
00:04:39,896 --> 00:04:42,854
CICD which includes the QA cycle and everything.

72
00:04:42,972 --> 00:04:46,866
This can take hours. Then reproduce the issue in production

73
00:04:46,898 --> 00:04:50,614
server with your fingers crossed and try to analyze what

74
00:04:50,652 --> 00:04:54,214
went on. Hopefully you found the issue because if not, it's effectively

75
00:04:54,262 --> 00:04:57,462
rinse repeat for the whole process. In the meantime,

76
00:04:57,526 --> 00:05:00,842
you still have a bug in production and developers are wasting their

77
00:05:00,896 --> 00:05:03,886
time. There just has to be a better way.

78
00:05:03,988 --> 00:05:07,374
It's 2022 and logs are the way

79
00:05:07,412 --> 00:05:11,086
we solve bugs in this day and age. Don't get me

80
00:05:11,108 --> 00:05:14,610
wrong, I love logs and today's logs are

81
00:05:14,680 --> 00:05:18,226
totally different from what we had even ten near ago.

82
00:05:18,408 --> 00:05:22,082
But you need to know about your problems in advance for

83
00:05:22,136 --> 00:05:26,290
a log to work. The problem is, I'm not clairvoyant.

84
00:05:27,350 --> 00:05:30,790
When I write code, I can't tell what bugs or problems

85
00:05:30,860 --> 00:05:34,418
the code will have before the code is written. I'm in the same boat

86
00:05:34,434 --> 00:05:37,698
as you are. The bugs don't exist yet. So I'm

87
00:05:37,714 --> 00:05:41,602
faced with a dilemma of whether to log something. This is a bit

88
00:05:41,676 --> 00:05:45,242
like the dilemma of writing comments does it make the code look

89
00:05:45,296 --> 00:05:49,210
noisy and stupid? Or will I find this useful at 02:00 a.m. When everything

90
00:05:49,280 --> 00:05:52,574
isn't working and I want to rip out a few strands of hair I still

91
00:05:52,612 --> 00:05:55,760
have left because of this damn production issue.

92
00:05:56,530 --> 00:06:00,346
Debugger are amazing. They let us set breakpoints,

93
00:06:00,378 --> 00:06:03,682
see callbacks, call stacks, inspect variables, and more.

94
00:06:03,816 --> 00:06:06,974
If only we could do the same for production

95
00:06:07,022 --> 00:06:10,334
problems. But debuggers weren't

96
00:06:10,382 --> 00:06:13,614
designed for this. They're very insecure when debugging

97
00:06:13,662 --> 00:06:17,886
remotely. They can block your server while sending debugger commands remotely.

98
00:06:17,998 --> 00:06:21,846
A small mistake has such as an expensive condition can

99
00:06:21,868 --> 00:06:25,458
literally destroy your server. I might be repeating an urban

100
00:06:25,474 --> 00:06:28,786
legend were but 20 or so years ago, I heard a story about

101
00:06:28,828 --> 00:06:32,266
a guy who was debugging a railed system located on a

102
00:06:32,288 --> 00:06:35,814
cliff. He stopped at a breakpoint during debugging,

103
00:06:35,862 --> 00:06:39,318
and the multimillion dollar hardware fell into the sea

104
00:06:39,414 --> 00:06:42,960
because he didn't receive the stop command. Again,

105
00:06:43,330 --> 00:06:47,162
I don't know if it's a true story, but that's plausible.

106
00:06:47,306 --> 00:06:51,470
Debuggers weren't really designed for these situations,

107
00:06:52,130 --> 00:06:56,174
were. Debuggers are limited to one server.

108
00:06:56,302 --> 00:07:00,146
If you have a cluster with multiple machines, the problem can manifest on

109
00:07:00,168 --> 00:07:03,314
one machine always, or might manifest on a

110
00:07:03,352 --> 00:07:07,330
random machine. We can't rely on pure lock.

111
00:07:07,850 --> 00:07:11,346
If I have multiple servers with multiple languages, platforms crossing

112
00:07:11,378 --> 00:07:15,042
from one to another with a debugger, well, it's possible in theory,

113
00:07:15,106 --> 00:07:18,146
but I can't even imagine it in reality.

114
00:07:18,338 --> 00:07:22,202
I also want to revisit this slide because I do

115
00:07:22,256 --> 00:07:25,754
love having apms, and looking at their dashboard gives me that type

116
00:07:25,792 --> 00:07:29,594
of joy we get from seeing the result of my work plotted out

117
00:07:29,632 --> 00:07:33,114
as a graph. I feel there should be a german word to describe

118
00:07:33,162 --> 00:07:36,206
that sort of enjoyment. But here's the thing.

119
00:07:36,308 --> 00:07:40,010
Apms aren't one thing. The more you instrument,

120
00:07:40,090 --> 00:07:43,326
the more you have runtime overhead. The more you have

121
00:07:43,348 --> 00:07:46,946
runtime overhead, the more hosts you need to handle the same amount of

122
00:07:46,968 --> 00:07:50,530
tasks. The more hosts you have, the more problems you have,

123
00:07:50,680 --> 00:07:54,418
and they become more complex. I feel Schrodinger should

124
00:07:54,504 --> 00:07:58,326
deliver this next line. By observing, we effectively change some

125
00:07:58,348 --> 00:08:01,846
of the outcome. An APM needs to

126
00:08:01,868 --> 00:08:05,426
observe everything. An APM doesn't know what it's

127
00:08:05,458 --> 00:08:09,274
looking for. Like I said before, it's a bat signal or a check

128
00:08:09,312 --> 00:08:12,954
engine light. It's got sensors all over

129
00:08:12,992 --> 00:08:16,186
the place, and it needs to receive information from

130
00:08:16,208 --> 00:08:19,958
these sensors. Some sensors have almost no overhead,

131
00:08:20,054 --> 00:08:23,950
but some can impact the observed application noticeably.

132
00:08:24,450 --> 00:08:27,562
Some people use that as an excuse to avoid apms.

133
00:08:27,626 --> 00:08:31,022
Which I feel is like throwing away the baby with a bathwater. We need

134
00:08:31,076 --> 00:08:34,418
apms. We can't manage at scale without them,

135
00:08:34,584 --> 00:08:38,814
but we need to tune them. And observing everything isnt

136
00:08:38,862 --> 00:08:42,286
an option. Thankfully, pretty much every APM

137
00:08:42,318 --> 00:08:45,774
vendor knows that, and they all let us tune

138
00:08:45,822 --> 00:08:49,686
the ratio of observability to performance so we

139
00:08:49,708 --> 00:08:53,494
can get a good result. Unfortunately, that means we get

140
00:08:53,532 --> 00:08:56,886
less data. Couple that with the reduced logs that

141
00:08:56,908 --> 00:09:00,426
we need to do for the same reason, and the bad problems we

142
00:09:00,448 --> 00:09:04,010
have in production just got a whole lot worse.

143
00:09:04,990 --> 00:09:08,138
So let's take the Batman metaphor all the way.

144
00:09:08,224 --> 00:09:11,726
We need a team up. We need some help from the server on the

145
00:09:11,748 --> 00:09:15,694
servers, especially in a clustered polyglot environment where the

146
00:09:15,732 --> 00:09:19,390
issue can appear on one container and move to the next, et cetera.

147
00:09:20,050 --> 00:09:24,094
So you remember this slide. We need some way to get through that

148
00:09:24,132 --> 00:09:27,540
line, not to remove it. We like that line.

149
00:09:28,070 --> 00:09:31,298
We need a way to connect with the server and debug it.

150
00:09:31,464 --> 00:09:34,690
Now, I'm a developer, so I try to stay away

151
00:09:34,760 --> 00:09:39,080
from management buzzwords, but the word for this is shift left.

152
00:09:39,770 --> 00:09:43,778
It essentially means we're letting the developer and the QA

153
00:09:43,954 --> 00:09:47,174
get back some of the access we used to have into

154
00:09:47,212 --> 00:09:50,502
the ops without demolishing the gains

155
00:09:50,566 --> 00:09:54,522
we've had in security and stability. We love the ops people,

156
00:09:54,576 --> 00:09:57,782
and we need them. So this is about helping

157
00:09:57,846 --> 00:10:01,738
them keep everything running smoothly in production without stepping

158
00:10:01,754 --> 00:10:04,510
on their toes or blowing up their deployment.

159
00:10:05,330 --> 00:10:09,214
This leads us here. What if you could connect your

160
00:10:09,252 --> 00:10:12,706
server to a debugger agent? That would make

161
00:10:12,728 --> 00:10:16,302
sure you don't overload the server and don't make a mistake,

162
00:10:16,366 --> 00:10:19,618
like setting a breakpoint or something like that.

163
00:10:19,784 --> 00:10:22,322
That's what continuous observability does.

164
00:10:22,456 --> 00:10:26,002
Continuous observability is complementary to the APM.

165
00:10:26,146 --> 00:10:30,040
It works very differently. Before we

166
00:10:30,490 --> 00:10:34,230
go on, I'd like to explain what's continuous observability.

167
00:10:34,570 --> 00:10:38,714
Observability is defined has the ability to understand how

168
00:10:38,752 --> 00:10:42,806
your system works on the inside without hoping

169
00:10:42,838 --> 00:10:46,662
new code. The without hoping new code portion

170
00:10:46,806 --> 00:10:50,830
is key. But what's continuous observability?

171
00:10:51,650 --> 00:10:55,840
With continuous observability, we don't ship new code either,

172
00:10:56,290 --> 00:11:00,346
but we can ask questions about the code. Normal observability

173
00:11:00,458 --> 00:11:04,260
works by instrumenting everything and receiving the information.

174
00:11:05,030 --> 00:11:09,250
With continuous observability, we flip that, we ask

175
00:11:09,320 --> 00:11:12,820
questions and then instrument based on the questions.

176
00:11:13,350 --> 00:11:15,650
So how does that work in practice?

177
00:11:16,470 --> 00:11:19,690
Each tool in this field is different. I'll explain the lightrun

178
00:11:19,710 --> 00:11:23,106
architecture, since that's what I'm familiar with, and I'll

179
00:11:23,138 --> 00:11:26,854
try to qualify where it differs from other tools in

180
00:11:26,892 --> 00:11:31,118
Lightrun. We use a native IDE plugin to vs code or Jetrain's

181
00:11:31,154 --> 00:11:34,134
IDE, such has intellij, Pycharm,

182
00:11:34,182 --> 00:11:38,220
webstorm, etc. It can also use a command line tool

183
00:11:38,670 --> 00:11:42,122
or other tools sometimes have a web interface or CLI.

184
00:11:42,186 --> 00:11:45,582
Only this client lets us interact with

185
00:11:45,636 --> 00:11:49,134
the Lightrun server. This is an important piece of the

186
00:11:49,172 --> 00:11:52,282
architecture that hides the actual production environment.

187
00:11:52,426 --> 00:11:55,778
Developers don't get access to the production area,

188
00:11:55,944 --> 00:11:59,490
which is still the purview of DevOps.

189
00:11:59,830 --> 00:12:03,698
We can insert an action which can be a logs or a

190
00:12:03,704 --> 00:12:07,462
snapshot or a measurement metric. I'll show all of these soon enough.

191
00:12:07,596 --> 00:12:10,438
This talk will go into the code portions soon.

192
00:12:10,604 --> 00:12:14,246
Notice that the Lartran server can be installed in

193
00:12:14,268 --> 00:12:18,086
the cloud as a SaaS or on premise and managed

194
00:12:18,118 --> 00:12:21,654
by Ops. The management server sends

195
00:12:21,702 --> 00:12:24,954
everything to the agent which is installed on your

196
00:12:24,992 --> 00:12:28,538
production or staging servers. This is pretty standard

197
00:12:28,624 --> 00:12:32,030
for all continuous observability solutions. I don't know how

198
00:12:32,180 --> 00:12:36,110
other solutions work, but I assume they are pretty similar. This means

199
00:12:36,180 --> 00:12:39,882
there's clear separation between the developer and production.

200
00:12:40,026 --> 00:12:43,842
As you can see, the DevOps still has that guarding line

201
00:12:43,896 --> 00:12:47,650
were talking about. They need to connect the agent

202
00:12:47,720 --> 00:12:51,518
to the management server and that's where their job ends.

203
00:12:51,694 --> 00:12:55,794
Developers don't have direct access to production, only through

204
00:12:55,832 --> 00:12:59,750
the management server. That means no danger to the running

205
00:12:59,820 --> 00:13:03,560
production servers from a careless developer. Well, like myself,

206
00:13:04,330 --> 00:13:08,450
the agent is just a small runtime you add to your production or staging server.

207
00:13:08,530 --> 00:13:12,326
It's very low overhead and it implements the debugging logic.

208
00:13:12,518 --> 00:13:16,790
Finally, everything is piped through the server back to your ide directly.

209
00:13:16,870 --> 00:13:20,182
So as a developer you can keep working in the IDE without

210
00:13:20,256 --> 00:13:23,214
leaving your comfort zone. Okay,

211
00:13:23,332 --> 00:13:26,542
that should raise the vendor alert right here.

212
00:13:26,676 --> 00:13:29,294
I heard that bullshit line before, right?

213
00:13:29,412 --> 00:13:32,518
Apms have been around forever and have been optimized.

214
00:13:32,634 --> 00:13:36,386
How can a new tool claim to have lower overhead than an established and

215
00:13:36,408 --> 00:13:39,650
proven solution? As I said before,

216
00:13:39,800 --> 00:13:43,950
apms look at everything. A continuous observability

217
00:13:44,030 --> 00:13:47,190
tool is surgical. That means that when

218
00:13:47,260 --> 00:13:50,438
an APM raises an interesting

219
00:13:50,524 --> 00:13:54,614
issue, we can then look at a very specific thing, like a

220
00:13:54,652 --> 00:13:58,454
line of code. When a continuous observability solution isn't

221
00:13:58,502 --> 00:14:01,990
running, its overhead is almost nothing. It literally

222
00:14:02,070 --> 00:14:05,526
does nothing other than check whether we need it. It doesn't

223
00:14:05,558 --> 00:14:09,466
report anything and is practically idle when

224
00:14:09,488 --> 00:14:13,470
we do need it. We need more data than the APM does,

225
00:14:13,620 --> 00:14:17,246
but we get it from one specific area of the code. So there is

226
00:14:17,268 --> 00:14:20,782
an overhead, but because it only impacts one area

227
00:14:20,916 --> 00:14:24,690
of the code, it's tiny this is

228
00:14:24,840 --> 00:14:28,130
the obvious question. What if I look at code

229
00:14:28,200 --> 00:14:31,998
that gets invoked a lot? As I said, continuous observability

230
00:14:32,094 --> 00:14:35,286
gets even more data than an APM does. This can

231
00:14:35,308 --> 00:14:39,046
bring down the system and, well, we could end up

232
00:14:39,068 --> 00:14:42,802
here. So this is where continuous observability

233
00:14:42,866 --> 00:14:46,354
tools differ. Some tools provide the ability to throttle

234
00:14:46,402 --> 00:14:50,060
expensive actions and only show you some of the information.

235
00:14:53,390 --> 00:14:56,090
This is a big deal in high volume requests.

236
00:14:56,910 --> 00:15:00,910
I'm going to show you two demos that highlight what we can do,

237
00:15:00,980 --> 00:15:04,910
and the first is a simple hello world flask server.

238
00:15:06,290 --> 00:15:09,950
So this is a simple hello world flask app which

239
00:15:10,020 --> 00:15:13,694
is running in Pycharm. I'll demonstrate vs

240
00:15:13,742 --> 00:15:17,698
code soon. First I right click and select

241
00:15:17,864 --> 00:15:21,330
the log option in the menu. A log

242
00:15:21,400 --> 00:15:24,594
lets me inject a new log into the code at

243
00:15:24,632 --> 00:15:27,762
runtime without restarting the server.

244
00:15:27,906 --> 00:15:31,142
But there is more. See here. I can log any

245
00:15:31,196 --> 00:15:34,470
expression or variable from the currently running

246
00:15:34,540 --> 00:15:37,830
app. In this case, I am logging the value of

247
00:15:37,900 --> 00:15:41,050
name. Logs can appear in the console below,

248
00:15:41,120 --> 00:15:43,930
or they can appear with the rest of the logs from the code.

249
00:15:44,080 --> 00:15:48,006
Let's press the ok button which inserts

250
00:15:48,038 --> 00:15:52,042
the new log. We can now see the dynamic log appearing just

251
00:15:52,096 --> 00:15:55,566
above the line, as if it was a line we added into the

252
00:15:55,588 --> 00:15:59,850
code. Now let's go to the browser window and hit refresh.

253
00:16:00,010 --> 00:16:03,538
Then we go back to the ide and within a

254
00:16:03,544 --> 00:16:07,154
matter of seconds we can see the log notice you can send

255
00:16:07,192 --> 00:16:10,990
the log to the iD or to be integrated

256
00:16:11,070 --> 00:16:13,220
with the other logs from your app.

257
00:16:14,390 --> 00:16:17,686
Let's delete the log and select a snapshot instead.

258
00:16:17,868 --> 00:16:22,466
A snapshot is kind of like a breakpoint you have in a regular debugger,

259
00:16:22,658 --> 00:16:26,118
but it has one major difference, it doesn't break,

260
00:16:26,284 --> 00:16:30,274
it doesn't stop the threads. When it's hit, it grabs the stack

261
00:16:30,322 --> 00:16:33,994
information, variables, values, et cetera, but doesn't stop

262
00:16:34,032 --> 00:16:37,222
the thread. So a user in production isn't

263
00:16:37,286 --> 00:16:41,306
stuck because you're debugging. Let's go back to the web UI and

264
00:16:41,328 --> 00:16:44,122
hit refresh button to see the snapshot in action.

265
00:16:44,266 --> 00:16:47,694
Then we can go back to the ide and wait for the snapshot result to

266
00:16:47,732 --> 00:16:51,722
arrive. Below you can see the result of the snapshot,

267
00:16:51,866 --> 00:16:55,714
as is the convention Jetbrains ide. You can

268
00:16:55,752 --> 00:16:58,590
walk the stack like you can with any breakpoint,

269
00:16:58,670 --> 00:17:02,094
inspect variable values like you could with any debugger,

270
00:17:02,222 --> 00:17:05,838
and all of that doesn't bother any live user in the

271
00:17:05,864 --> 00:17:09,702
system. I skipped a lot of interesting features were such

272
00:17:09,756 --> 00:17:12,994
as the ability to define conditional logs or snapshots,

273
00:17:13,122 --> 00:17:16,706
which let you do things like define a snapshot

274
00:17:16,738 --> 00:17:20,220
that's only hit when a specific user is in the system.

275
00:17:20,590 --> 00:17:24,470
That means that if a user somewhere has a bug,

276
00:17:24,550 --> 00:17:28,630
you can literally get information that's specific only to that user

277
00:17:28,710 --> 00:17:31,360
and no one else. That's pretty cool.

278
00:17:32,130 --> 00:17:35,610
Airflow lets you write workflows with Python

279
00:17:35,690 --> 00:17:39,134
and execute them at scale. There are many

280
00:17:39,172 --> 00:17:41,962
frameworks with similar concepts such as Spark,

281
00:17:42,026 --> 00:17:46,098
etc. Logs of them have different

282
00:17:46,184 --> 00:17:50,162
use cases and target demographics, but they have

283
00:17:50,216 --> 00:17:54,274
one core concept in common. They launch workers that

284
00:17:54,312 --> 00:17:58,102
are short lived. They perform a task and return a

285
00:17:58,156 --> 00:18:02,070
response. In the case of airflow, this is commonly used

286
00:18:02,140 --> 00:18:05,494
for processing data at scale. A good

287
00:18:05,532 --> 00:18:09,574
example for this is tagging or clarifying

288
00:18:09,622 --> 00:18:13,574
images. Here we have multiple independent

289
00:18:13,622 --> 00:18:16,170
processes that can take pieces of data,

290
00:18:16,320 --> 00:18:19,546
process it, and return a result. One of

291
00:18:19,568 --> 00:18:23,178
the nice things about these tools is that we can create chains

292
00:18:23,194 --> 00:18:26,846
of dependencies where results get passed from one process

293
00:18:26,948 --> 00:18:30,922
to another to use computing resources

294
00:18:30,986 --> 00:18:34,740
in the most effective way. But here's the problem.

295
00:18:35,110 --> 00:18:38,494
This thing is nearly impossible to debug.

296
00:18:38,622 --> 00:18:42,094
This is so bad. Companies just let major bugs

297
00:18:42,142 --> 00:18:45,954
live in production and accept a pretty terrible error

298
00:18:46,002 --> 00:18:49,302
rate because they just can't debugger this thing.

299
00:18:49,436 --> 00:18:53,026
They have logs, but the FMRL processes,

300
00:18:53,218 --> 00:18:55,960
they lose the context very quickly.

301
00:18:56,570 --> 00:18:59,750
This is a perfect use case for continuous observability.

302
00:18:59,830 --> 00:19:03,340
Tools that can deliver more

303
00:19:04,430 --> 00:19:07,754
airflow lets you break down huge tasks like

304
00:19:07,872 --> 00:19:11,274
clarifying a large set of images into distributed

305
00:19:11,322 --> 00:19:14,894
workers that can run on multiple machines and use

306
00:19:14,932 --> 00:19:18,094
available resources intelligently. This makes

307
00:19:18,132 --> 00:19:21,902
it nearly impossible to debug. Your worker might

308
00:19:21,956 --> 00:19:26,002
run somewhere and all you have is a log after

309
00:19:26,056 --> 00:19:30,002
the fact, which you would need to dig through to check for

310
00:19:30,056 --> 00:19:32,100
a bug or a fix.

311
00:19:32,950 --> 00:19:36,522
This time I use vs code to demonstrate this functionality.

312
00:19:36,686 --> 00:19:40,530
This is a simple airflow demo that classifies images.

313
00:19:40,690 --> 00:19:43,766
The problem with airflow is that we don't have an

314
00:19:43,788 --> 00:19:47,030
agent or a server on which our code is running.

315
00:19:47,180 --> 00:19:50,346
An agent can come up, process and

316
00:19:50,368 --> 00:19:53,926
then go away. By the time we set the snapshot

317
00:19:54,038 --> 00:19:57,402
into place, it will be gone. This is where

318
00:19:57,456 --> 00:20:01,094
tags come in. Tags let us apply an action such

319
00:20:01,152 --> 00:20:04,734
as a log or a snapshot to a group of agents.

320
00:20:04,932 --> 00:20:08,586
That means that every agent that logs with the given tag

321
00:20:08,698 --> 00:20:12,746
will implicitly get the actions of that tag.

322
00:20:12,938 --> 00:20:16,594
By the way, notice that in vs code we need to add

323
00:20:16,632 --> 00:20:19,902
actions from the left pane. The UI

324
00:20:19,966 --> 00:20:23,790
is a bit different here. Adding an action

325
00:20:23,870 --> 00:20:27,320
to a tag is pretty similar to adding it to an agent.

326
00:20:27,770 --> 00:20:31,414
We just add it and it looks the same so

327
00:20:31,452 --> 00:20:34,146
far. Now that it's added,

328
00:20:34,258 --> 00:20:37,606
let's move to the agents view and wait for the agent to

329
00:20:37,628 --> 00:20:41,146
come online and trigger the snapshot. By the

330
00:20:41,168 --> 00:20:44,378
way, notice that the UI for all of this is

331
00:20:44,464 --> 00:20:47,370
similar in spirit to the one in Pycharm.

332
00:20:48,510 --> 00:20:52,346
Now we have an agent that's running and we got a notification

333
00:20:52,458 --> 00:20:55,994
that the snapshot was hit. Let's go into the snapshots

334
00:20:56,042 --> 00:21:00,010
tab and click the snapshot. Unlike Pycharm,

335
00:21:00,090 --> 00:21:03,570
we need to open the snapshot manually and it looks like

336
00:21:03,640 --> 00:21:07,026
a vs code breakpoint, which is good as it's native to

337
00:21:07,048 --> 00:21:11,378
the ide. But the core idea the

338
00:21:11,464 --> 00:21:15,318
UI of the snapshot with the stack variables, etc. That's the

339
00:21:15,324 --> 00:21:17,510
same as it was in Pycharm.

340
00:21:21,370 --> 00:21:25,458
The title of this talk refers to polyglot debugging

341
00:21:25,634 --> 00:21:29,366
because of time constraints. I can show the full polyglot

342
00:21:29,398 --> 00:21:34,170
demo, but let's look at this simple kotlin prime number calculator

343
00:21:35,550 --> 00:21:38,902
this is a simple Kotlin prime number calculator.

344
00:21:39,046 --> 00:21:43,114
It simply logs over numbers and checks if they are a prime

345
00:21:43,162 --> 00:21:46,878
number. It sleeps for ten milliseconds, so it won't completely

346
00:21:46,964 --> 00:21:50,094
demolish the cpu, but other than that, it's pretty

347
00:21:50,132 --> 00:21:53,578
simple. Pretty simple application. It just counts

348
00:21:53,594 --> 00:21:57,006
the number of primes it finds along the way and prints

349
00:21:57,038 --> 00:22:00,242
the result at the end. We use this code

350
00:22:00,296 --> 00:22:03,922
a lot when debugging, since it's cpu intensive and yet

351
00:22:03,976 --> 00:22:07,650
very simple. In this case, we would like to observe

352
00:22:07,730 --> 00:22:11,762
the variable I, which is the value we're evaluating

353
00:22:11,826 --> 00:22:15,014
here, and print out CnT, which represents the number

354
00:22:15,052 --> 00:22:18,478
of primes we found so far. The simplest

355
00:22:18,514 --> 00:22:22,460
tool we have is the ability to inject a log into an application.

356
00:22:22,830 --> 00:22:26,202
We can also inject a snapshot or add metrics. I'll discuss

357
00:22:26,256 --> 00:22:29,946
all of those soon. Selecting log

358
00:22:30,048 --> 00:22:33,310
opens the UI to enter a new log.

359
00:22:33,460 --> 00:22:37,146
I can write more than just text in the curly braces.

360
00:22:37,258 --> 00:22:40,846
I can include any expression I want, such as the

361
00:22:40,868 --> 00:22:44,462
value of the variables that I included

362
00:22:44,526 --> 00:22:48,546
in this expression. I can also invoke methods and do all

363
00:22:48,568 --> 00:22:51,986
sorts of things. But here's the thing. If I invoke a

364
00:22:52,008 --> 00:22:55,002
method that's too computationally intensive,

365
00:22:55,086 --> 00:22:58,694
or if I invoke a method that changes the application state,

366
00:22:58,892 --> 00:23:02,390
the log won't be added. I'll get can error.

367
00:23:03,530 --> 00:23:07,374
After clicking OK, we see the log appearing above

368
00:23:07,522 --> 00:23:11,354
the line in the ide. Notice that this behavior is specific to

369
00:23:11,392 --> 00:23:15,174
intellij or Jetrain's files. In visual studio

370
00:23:15,222 --> 00:23:18,940
code, it will show a marker on the side.

371
00:23:19,970 --> 00:23:23,386
Once the log is hit, we'll see logs

372
00:23:23,418 --> 00:23:27,838
appear in batches like before. You'll notice that the experience

373
00:23:28,004 --> 00:23:31,806
is pretty much identical to the one we had

374
00:23:31,988 --> 00:23:35,714
with Python. The next thing

375
00:23:35,752 --> 00:23:37,970
I want to talk about is metrics,

376
00:23:39,510 --> 00:23:43,362
and this is a different demo that I usually use to

377
00:23:43,496 --> 00:23:47,474
show metrics. It's based on Java actually fitting

378
00:23:47,522 --> 00:23:48,920
the polyglot stuff.

379
00:23:50,330 --> 00:23:54,214
Apms give us large scale performance information, but they

380
00:23:54,252 --> 00:23:57,618
don't tell us fine grained details.

381
00:23:57,794 --> 00:24:01,526
Here we can count the number of times a line of code was reached

382
00:24:01,638 --> 00:24:05,606
using a counter. We can even use a condition

383
00:24:05,718 --> 00:24:09,146
to qualify that, so we can do

384
00:24:09,168 --> 00:24:12,650
something like count the number of times a specific user

385
00:24:12,730 --> 00:24:16,110
reached that line of code. We also have a

386
00:24:16,180 --> 00:24:19,886
method duration, which tells us how long

387
00:24:19,988 --> 00:24:23,794
a method took to execute. We can even measure the

388
00:24:23,832 --> 00:24:27,234
time it takes to perform a code block using a

389
00:24:27,272 --> 00:24:30,894
TikTok. This lets us narrow down the performance

390
00:24:30,942 --> 00:24:35,370
impact of a larger method to a specific problematic segment.

391
00:24:35,550 --> 00:24:38,162
In this case, I'll just use the method.

392
00:24:38,226 --> 00:24:42,086
Duration measurements typically have a name

393
00:24:42,188 --> 00:24:46,022
under which you can pipe them or log them,

394
00:24:46,156 --> 00:24:49,946
so I'll just give this method duration a clear name.

395
00:24:50,128 --> 00:24:53,542
In this case, I'm just printing it out to the console,

396
00:24:53,686 --> 00:24:57,834
but all of these measurements can be piped to statsd and

397
00:24:57,872 --> 00:24:58,890
Prometheus.

398
00:25:01,390 --> 00:25:04,462
I'm a pretty awful DevOps, so I really

399
00:25:04,596 --> 00:25:08,702
don't want to demo that in this case, but it does work if

400
00:25:08,756 --> 00:25:12,206
you know how to use those tools. As you

401
00:25:12,228 --> 00:25:16,114
can see, the duration information is now piped into the logs and

402
00:25:16,152 --> 00:25:19,586
provides us some information on the current performance of

403
00:25:19,608 --> 00:25:20,610
this method.

404
00:25:22,790 --> 00:25:25,862
In closing, I'd like to go over what we discussed here,

405
00:25:25,916 --> 00:25:28,806
and a few things we didn't have time for.

406
00:25:28,988 --> 00:25:32,546
Lartran supports Java languages like Java,

407
00:25:32,578 --> 00:25:35,906
Kotlin, Scala, etc. Every JVM language

408
00:25:35,938 --> 00:25:39,334
is supported. It supports node

409
00:25:39,382 --> 00:25:43,178
for both JavaScript and typescript code, and of course

410
00:25:43,264 --> 00:25:46,310
Python, even complex stuff like airflow.

411
00:25:46,470 --> 00:25:49,722
We're working hard on adding new platforms that are

412
00:25:49,776 --> 00:25:52,986
going to doing that really fast. So if

413
00:25:53,008 --> 00:25:55,774
you want a new platform I didn't mention here,

414
00:25:55,892 --> 00:25:59,214
just write to me and I'll connect you with the product team.

415
00:25:59,412 --> 00:26:03,234
You can become a better tester for the new platform and have an impact on

416
00:26:03,272 --> 00:26:07,086
the direction we take when we add actions.

417
00:26:07,198 --> 00:26:10,674
Conditions run within a sandbox so they don't take

418
00:26:10,712 --> 00:26:14,210
up cpu or crash the system. This all happens

419
00:26:14,280 --> 00:26:18,754
without networking, so something like networking hiccup won't

420
00:26:18,802 --> 00:26:23,154
crash the server. Security is especially crucial

421
00:26:23,282 --> 00:26:26,854
with solutions like this. One of the core concepts is

422
00:26:26,892 --> 00:26:29,180
that the server queries information,

423
00:26:30,670 --> 00:26:35,290
not the other way around. As you would see with solutions such as JDWP.

424
00:26:35,710 --> 00:26:39,434
This means operations are atomic and the server can be hidden behind

425
00:26:39,472 --> 00:26:42,750
a firewall, even from the rest of the organization.

426
00:26:43,730 --> 00:26:47,214
PIi reduction lets us define conditions that would

427
00:26:47,252 --> 00:26:51,086
obscure patterns in the logs. So if a user could

428
00:26:51,108 --> 00:26:54,546
print out a credit card number by mistake, you can

429
00:26:54,568 --> 00:26:57,220
define a rule that would block that.

430
00:26:57,830 --> 00:27:01,902
Pii reduction lets us define conditions that would obscure

431
00:27:01,966 --> 00:27:05,646
patterns in the logs. So if a user could print

432
00:27:05,678 --> 00:27:09,094
but a credit card number by mistake, you can

433
00:27:09,132 --> 00:27:12,902
define a rule that would block that. This way the bad

434
00:27:12,956 --> 00:27:16,790
data won't make it into your logs and won't expose you to liability.

435
00:27:17,210 --> 00:27:21,082
Blacklisting lets us block specific classes, methods or

436
00:27:21,136 --> 00:27:24,806
files. This means you can block developers in your organization

437
00:27:24,918 --> 00:27:29,046
from debugging specific files. This means a developer won't

438
00:27:29,078 --> 00:27:32,558
be able to put a snapshot or a log in a place

439
00:27:32,724 --> 00:27:36,654
where a password might be available to steal user credentials or stuff

440
00:27:36,692 --> 00:27:40,990
like that. This is hugely important in large organizations

441
00:27:41,410 --> 00:27:44,394
besides the sandbox.

442
00:27:44,442 --> 00:27:47,602
I'd like to also mention that Lightrun is very efficient and

443
00:27:47,656 --> 00:27:50,846
in our benchmarks has almost no runtime impact.

444
00:27:50,958 --> 00:27:54,398
When it isn't used, it has a very small impact

445
00:27:54,494 --> 00:27:57,810
even with multiple actions in place. Finally,

446
00:27:57,880 --> 00:28:02,214
Lightrun and can be used from the cloud or using an on premise install.

447
00:28:02,412 --> 00:28:05,542
It works with any deployment you might have, whether cloud

448
00:28:05,596 --> 00:28:09,350
based, container based on premise, microservice, serverless, etc.

449
00:28:10,730 --> 00:28:14,070
Thanks for bearing with me. I hope you enjoyed the presentation.

450
00:28:14,410 --> 00:28:18,166
Please feel free to ask any questions and feel free to write to

451
00:28:18,188 --> 00:28:22,206
me. Also, please check out talktoduck dev were I talk

452
00:28:22,228 --> 00:28:23,980
about debugging in depth and check out.

