1
00:00:00,730 --> 00:00:04,366
What if you could work with some of the world's most innovative companies,

2
00:00:04,548 --> 00:00:08,746
all from the comfort of a remote workplace? Andela has matched

3
00:00:08,778 --> 00:00:11,994
thousands of technologists across the globe to their next career

4
00:00:12,042 --> 00:00:15,818
adventure. We're empowering new talent worldwide,

5
00:00:15,914 --> 00:00:19,802
from Sao Paulo to Egypt and Lagos to Warsaw.

6
00:00:19,946 --> 00:00:23,038
Now the future of work is yours to create.

7
00:00:23,204 --> 00:00:27,030
Anytime, anywhere. The world is at your fingertips.

8
00:00:27,370 --> 00:00:29,190
This is Andela.

9
00:01:13,010 --> 00:01:16,870
Welcome to the secting channel. So, slices and maps in go.

10
00:01:17,020 --> 00:01:20,434
We are going to talk about the most commonly used building structures.

11
00:01:20,482 --> 00:01:24,374
In go. Slices, maps and channels. We probably all know

12
00:01:24,412 --> 00:01:27,906
how to use them, but not necessarily how they

13
00:01:27,948 --> 00:01:32,182
work under the hood. In this talk, we are going to follow an experimental approach

14
00:01:32,246 --> 00:01:35,382
to analyze how they behave in memory

15
00:01:35,446 --> 00:01:39,610
when we modify, create or access these structures.

16
00:01:40,030 --> 00:01:43,826
Okay, we are going to need some class materials. The scalpel,

17
00:01:43,878 --> 00:01:48,122
the microscope, and the subject. Let's start with the slices.

18
00:01:48,266 --> 00:01:51,566
What is our escalpel in a slice? We are going

19
00:01:51,588 --> 00:01:55,206
to use a function called escalpel that is going to receive a slice.

20
00:01:55,258 --> 00:01:59,022
In this case, I'm going to use a slice of integrals because it's

21
00:01:59,086 --> 00:02:02,690
simpler. And I'm going to use unsafe to get access

22
00:02:02,760 --> 00:02:05,890
to the memory address of the slice and store

23
00:02:05,960 --> 00:02:08,478
that data in a structure.

24
00:02:08,654 --> 00:02:12,182
Then I have a microscope function. The microscope function

25
00:02:12,236 --> 00:02:16,626
is going to show me the data in a readable way to analyze

26
00:02:16,658 --> 00:02:19,862
what is going on. And the subject in this case

27
00:02:19,916 --> 00:02:23,114
is a slice. A slices is not other than array or one

28
00:02:23,152 --> 00:02:26,954
or more slices. We are going to see what I mean. This is the

29
00:02:26,992 --> 00:02:30,066
structure of anslice. A slice is an array.

30
00:02:30,118 --> 00:02:33,614
It's a pointer to an array in memory, just a

31
00:02:33,652 --> 00:02:37,358
chunk of memory in the heap. In this case, it's a

32
00:02:37,364 --> 00:02:40,190
chunk of memory that stores integers.

33
00:02:41,650 --> 00:02:45,090
Then I have the length and the capacity of the slice.

34
00:02:45,670 --> 00:02:49,326
What happened when I create a new slice of integers?

35
00:02:49,438 --> 00:02:52,866
In this case, I'm creating empty slice of

36
00:02:52,888 --> 00:02:56,438
integers. The memory address

37
00:02:56,524 --> 00:03:00,358
is not especially important here because

38
00:03:00,444 --> 00:03:04,278
we are not storing anything yet. The slice length and the

39
00:03:04,284 --> 00:03:08,230
slice capacity is zero and the stored data is just an empty,

40
00:03:08,590 --> 00:03:12,634
empty. Okay, what happened if I open a

41
00:03:12,672 --> 00:03:14,410
new integral?

42
00:03:16,350 --> 00:03:20,494
The slice code is going to reserve a chunk of memory to

43
00:03:20,532 --> 00:03:24,350
store that integral and store

44
00:03:24,420 --> 00:03:27,200
there the integral value. In this case one.

45
00:03:27,730 --> 00:03:31,360
The slice length is one and the slice capacity is one.

46
00:03:32,470 --> 00:03:36,274
Let's see what happened when I add more data there.

47
00:03:36,392 --> 00:03:39,554
If I add four more elements, it's going to

48
00:03:39,592 --> 00:03:42,814
change the memory address. Why? It's changing the memory

49
00:03:42,862 --> 00:03:46,142
address because I don't have enough space

50
00:03:46,216 --> 00:03:50,214
in the original reserved memory. If I go here

51
00:03:50,412 --> 00:03:53,970
and see the slice capacity. When I added one element,

52
00:03:54,050 --> 00:03:57,094
the slice capacity is one. So I'm not able

53
00:03:57,132 --> 00:04:00,726
to store more data in that array because the slice capacity

54
00:04:00,758 --> 00:04:03,834
is saying the amount of data that is able

55
00:04:03,872 --> 00:04:06,730
to store that array in memory.

56
00:04:07,550 --> 00:04:11,760
This case is one. So every time that we reach

57
00:04:12,210 --> 00:04:15,534
the capacity limit of the slice is

58
00:04:15,572 --> 00:04:20,074
going to happen at resize. A resize is just reserving

59
00:04:20,122 --> 00:04:23,794
another, a bigger chunk of memory in the heap and

60
00:04:23,832 --> 00:04:27,650
migrating all the data to this new chunk of memory.

61
00:04:27,990 --> 00:04:31,282
In this case we added five

62
00:04:31,336 --> 00:04:35,526
elements and in that process the

63
00:04:35,548 --> 00:04:38,710
slice has been growing.

64
00:04:39,130 --> 00:04:42,726
The slices is not going to grow one element at a

65
00:04:42,748 --> 00:04:46,646
time. The slice capacity is going to grow

66
00:04:46,748 --> 00:04:50,634
more than one element normally because you don't want

67
00:04:50,672 --> 00:04:53,770
to resize the slice with

68
00:04:53,920 --> 00:04:57,354
every single insertion. So in this case, at some

69
00:04:57,392 --> 00:05:00,842
dont, I added enough data to grow the slice

70
00:05:00,906 --> 00:05:04,174
and the slice growth to the capacity of

71
00:05:04,212 --> 00:05:07,562
eight. That means that I reserve a memory

72
00:05:07,706 --> 00:05:10,862
for eight elements, but in this case I'm only

73
00:05:10,916 --> 00:05:14,558
using five of them. So the store data in memory

74
00:05:14,654 --> 00:05:18,594
is 123-4500 because

75
00:05:18,632 --> 00:05:22,402
I have eight positions in memory. Eight integrate space for eight

76
00:05:22,456 --> 00:05:25,526
integrates in memory. Okay,

77
00:05:25,628 --> 00:05:28,902
what happened if I create a super slice? A super

78
00:05:28,956 --> 00:05:32,854
slice is just a

79
00:05:33,052 --> 00:05:36,774
slices of a slice. In this

80
00:05:36,812 --> 00:05:40,502
case, I'm creating a super

81
00:05:40,556 --> 00:05:44,120
slice from the position one to the position four.

82
00:05:47,050 --> 00:05:50,040
What is interesting here is the memory address.

83
00:05:50,370 --> 00:05:55,198
You can see that the memory address here is c one,

84
00:05:55,284 --> 00:05:58,718
a five 40, and here

85
00:05:58,804 --> 00:06:04,018
the memory address is c five

86
00:06:04,184 --> 00:06:07,922
four eight. That eight is because

87
00:06:07,976 --> 00:06:11,602
we are using integral. And in my architecture that

88
00:06:11,656 --> 00:06:15,670
means integral 64, what is eight bytes?

89
00:06:17,130 --> 00:06:22,006
Because this is the same, actually it's the

90
00:06:22,028 --> 00:06:25,234
same chunk of memory, but one byte

91
00:06:25,282 --> 00:06:28,120
after, well, sorry, eight bytes after,

92
00:06:28,830 --> 00:06:32,186
eight bytes after because I'm starting in the position

93
00:06:32,288 --> 00:06:36,294
one. So I'm skipping the position zero of the original array

94
00:06:36,342 --> 00:06:39,418
or the original slice. And also it's interesting,

95
00:06:39,504 --> 00:06:42,654
the slice capacity, because it's exactly the

96
00:06:42,692 --> 00:06:46,942
same chunk of memory. The slice capacity is

97
00:06:46,996 --> 00:06:50,670
seven because before was eight. But I'm not able to use

98
00:06:50,740 --> 00:06:54,242
the whole array. I'm just able to use

99
00:06:54,296 --> 00:06:57,506
the rest of the array, the memory that

100
00:06:57,528 --> 00:07:01,074
is reserved from the address that

101
00:07:01,192 --> 00:07:04,770
I'm using. Okay, let's see

102
00:07:04,840 --> 00:07:07,986
what happened if I modify a super slices.

103
00:07:08,098 --> 00:07:12,246
If I modify, for example, the position zero of the super slice, that is

104
00:07:12,268 --> 00:07:15,814
the position one of the original slice, what is

105
00:07:15,852 --> 00:07:19,850
going to happen? Is the original slice also get modified?

106
00:07:21,550 --> 00:07:25,242
It gets modified in the position one, and the super

107
00:07:25,296 --> 00:07:29,146
slice is modified in the position zero as I did in the

108
00:07:29,168 --> 00:07:31,902
code. Okay,

109
00:07:32,036 --> 00:07:35,694
what happened if I append something that is even more

110
00:07:35,732 --> 00:07:39,502
interesting? I'm appending six, the value six, to the

111
00:07:39,556 --> 00:07:43,010
super slice. But the super slices was from position

112
00:07:43,080 --> 00:07:47,618
one to position four. It is just

113
00:07:47,704 --> 00:07:51,582
three elements and is adding a fourth

114
00:07:51,646 --> 00:07:55,494
element at the end. But the end of the super

115
00:07:55,532 --> 00:07:58,898
slice is not the end of the original slice.

116
00:07:59,074 --> 00:08:03,334
So we are overriding the position, the fifth position

117
00:08:03,532 --> 00:08:07,990
in the original array, and we are appending

118
00:08:08,650 --> 00:08:12,374
in the slice. So the behavior from

119
00:08:12,412 --> 00:08:16,242
the perspective of the original array is different, and the behavior

120
00:08:16,306 --> 00:08:19,574
from the super slice, as you can see

121
00:08:19,612 --> 00:08:23,322
there, the value six is affecting

122
00:08:23,386 --> 00:08:27,454
both the super slice and

123
00:08:27,492 --> 00:08:31,246
the original slices. Even more interesting

124
00:08:31,348 --> 00:08:35,326
is if I happen more data and then modify

125
00:08:35,438 --> 00:08:38,802
something in the super slice, if I happen more data

126
00:08:38,856 --> 00:08:42,382
to the original slice and modify something in the super slice,

127
00:08:42,526 --> 00:08:45,686
what I get is because

128
00:08:45,788 --> 00:08:50,406
I added enough data to trigger a resize in

129
00:08:50,428 --> 00:08:57,866
the original slice, we are no longer sharing the

130
00:08:57,888 --> 00:09:01,366
array memory address. We are pointing to a different chunk

131
00:09:01,398 --> 00:09:06,150
of in memory. So that generates

132
00:09:06,230 --> 00:09:09,414
a disconnection between both slices.

133
00:09:09,542 --> 00:09:13,162
So a super slice can be considered

134
00:09:13,226 --> 00:09:17,150
a window to another slices if that slice

135
00:09:18,450 --> 00:09:22,030
hasn't been resized or the super slices hasn't been resized.

136
00:09:22,950 --> 00:09:26,302
That is probably a very unexpected behavior.

137
00:09:26,366 --> 00:09:30,100
So I wouldn't try to relay in this behavior for anything.

138
00:09:31,190 --> 00:09:35,234
Okay, I have the code that I used to run

139
00:09:35,272 --> 00:09:38,406
this experiment here. I have a link at the end of

140
00:09:38,428 --> 00:09:41,846
the talk with all the code.

141
00:09:41,948 --> 00:09:45,960
So if you want to reproduce this experiment, you can. So just

142
00:09:46,330 --> 00:09:49,802
check out the link at the end of the talk. Okay,

143
00:09:49,856 --> 00:09:53,658
let's talk about maps. The scalpel for maps is going to be

144
00:09:53,744 --> 00:09:58,070
pretty much the same. I'm just using unsafe to access the memory

145
00:09:58,230 --> 00:10:02,110
and store that memory in a structure. In this case, as an example,

146
00:10:02,180 --> 00:10:05,514
I'm using a maps of integral

147
00:10:05,562 --> 00:10:09,790
values and integral keys because it's simpler.

148
00:10:10,690 --> 00:10:13,962
The microscope is more complex

149
00:10:14,026 --> 00:10:17,906
because the data structure in maps is way more complex than

150
00:10:17,928 --> 00:10:21,534
the data structure in slices. And the subject is the map.

151
00:10:21,582 --> 00:10:25,118
A map is just a set of map metadata and a set

152
00:10:25,144 --> 00:10:28,934
of buckets. That is where the real data, the data that just

153
00:10:28,972 --> 00:10:31,910
stored in the map, is stored.

154
00:10:32,410 --> 00:10:35,926
Okay, what is the structure that store a

155
00:10:35,948 --> 00:10:39,578
map? Well, we have the count, that is the number of elements in the

156
00:10:39,584 --> 00:10:42,906
map. We have the flags. That is not important for this talk. We have the

157
00:10:42,928 --> 00:10:46,460
b value that represents the number of

158
00:10:48,030 --> 00:10:51,678
resizes of the map. Well, it's related to

159
00:10:51,684 --> 00:10:56,318
the number of buckets. Not super important, but yeah,

160
00:10:56,404 --> 00:11:00,170
it is related to the number of buckets. The number of overflows

161
00:11:00,330 --> 00:11:04,030
give you an approximation of the number of overflow buckets.

162
00:11:04,370 --> 00:11:07,426
The hashiro is a completely

163
00:11:07,528 --> 00:11:11,950
random number that is generated whenever

164
00:11:12,030 --> 00:11:15,622
you create a new map. And this

165
00:11:15,756 --> 00:11:19,574
random number is used to generate the hash of

166
00:11:19,612 --> 00:11:23,510
the keys to decide where the keys are stored

167
00:11:23,850 --> 00:11:27,618
in the maps. This is interesting

168
00:11:27,724 --> 00:11:31,754
because this gives the certain feature to

169
00:11:31,792 --> 00:11:36,250
the maps that it is not predictable

170
00:11:37,710 --> 00:11:41,870
in which bucket the keys are going to fall. It's not predictable

171
00:11:43,090 --> 00:11:47,166
before you create this random number, before you instantiate the

172
00:11:47,188 --> 00:11:50,990
map. So you can't relay in the order of a map or

173
00:11:51,060 --> 00:11:54,494
things like that, or in what the order

174
00:11:54,532 --> 00:11:58,740
of a map is not relatable in go.

175
00:12:00,870 --> 00:12:03,540
One of the reasons is because the hash zero,

176
00:12:04,630 --> 00:12:08,550
the buckets is just a pointer to a chunk of memory that store

177
00:12:08,620 --> 00:12:11,960
a set of buckets. We are going to see what a bucket is

178
00:12:12,730 --> 00:12:16,374
right away. Then we have the all buckets. That is another

179
00:12:16,412 --> 00:12:19,466
pointer to

180
00:12:19,488 --> 00:12:22,538
another chunk of memory. Storing buckets again.

181
00:12:22,704 --> 00:12:25,898
And evacuated is the number of evacuated buckets. We are going

182
00:12:25,904 --> 00:12:29,642
to talk more about that later and some

183
00:12:29,696 --> 00:12:33,120
extra metadata that is not super important for this talk.

184
00:12:33,970 --> 00:12:38,830
We have the bucket extract also. That is

185
00:12:38,980 --> 00:12:42,850
the structure that is stored in the heap, storing the

186
00:12:42,920 --> 00:12:46,290
real data. Each bucket is going to contain

187
00:12:46,630 --> 00:12:50,194
eight elements and is

188
00:12:50,232 --> 00:12:53,794
going to have a top hash that is just a set of

189
00:12:53,832 --> 00:12:57,106
chunks of the hashes of the keys stored

190
00:12:57,138 --> 00:13:01,270
in the bucket. Well, not especially

191
00:13:01,340 --> 00:13:03,640
important for this talk either.

192
00:13:04,490 --> 00:13:07,586
And then we have the keys and the values. The keys and

193
00:13:07,628 --> 00:13:10,970
the values are two arrays of eight elements

194
00:13:11,310 --> 00:13:13,740
storing each key and each value.

195
00:13:15,310 --> 00:13:18,506
Each position in the keys correspond to the

196
00:13:18,528 --> 00:13:22,326
same position in the values. And then we have the overflow

197
00:13:22,358 --> 00:13:26,302
pointer. The overflow pointer is another pointer that points to another memory address

198
00:13:26,356 --> 00:13:29,854
that contains a bucket, an overflow bucket. We are going

199
00:13:29,892 --> 00:13:33,226
to see what an overflow bucket is later. Well,

200
00:13:33,268 --> 00:13:36,286
let's start creating a maps. An empty map.

201
00:13:36,478 --> 00:13:40,046
In this case, I'm creating an empty map with integral values and integrate

202
00:13:40,078 --> 00:13:42,978
keys. The map size,

203
00:13:43,064 --> 00:13:46,950
because the maps is empty, is going to be zero, the flux zero,

204
00:13:47,020 --> 00:13:51,110
the b zero. What is for zero

205
00:13:51,180 --> 00:13:55,254
size? Well, the b zero means

206
00:13:55,292 --> 00:13:59,050
that there's only one bucket, the hashid that is

207
00:13:59,200 --> 00:14:02,220
a random number. The number of overflow buckets is zero.

208
00:14:04,430 --> 00:14:07,782
Well, the buckets is pointing to a chunk in memory

209
00:14:07,926 --> 00:14:11,882
that is storing an empty bucket. An empty bucket means basically top

210
00:14:11,936 --> 00:14:15,806
hash zero. All the keys are zero or the values are zero,

211
00:14:15,908 --> 00:14:19,070
and the overflow pointer is null or zero.

212
00:14:19,140 --> 00:14:22,762
In this case, the old buckets is not pointing anywhere

213
00:14:22,826 --> 00:14:25,540
and the number of evacuated buckets is zero for now.

214
00:14:26,390 --> 00:14:29,790
Okay, what happened if I add one element to this map?

215
00:14:29,870 --> 00:14:33,810
If I, for example, store in the key one the value ten?

216
00:14:33,960 --> 00:14:37,842
Now the map size is one. And everything else

217
00:14:37,896 --> 00:14:41,286
keeps the same except for the bucket. If I go to

218
00:14:41,308 --> 00:14:45,718
the bucket, I see that I store one key, that is the key one

219
00:14:45,884 --> 00:14:50,040
and one value, that is the value ten, both in the same position

220
00:14:50,490 --> 00:14:53,190
in the keys and the value of those arrays.

221
00:14:54,430 --> 00:14:58,134
The top hash is just a chunk of the hash

222
00:14:58,182 --> 00:15:00,640
of the keys, but it's not super important.

223
00:15:02,770 --> 00:15:06,398
Okay, let's keep going. If I add more data,

224
00:15:06,484 --> 00:15:09,550
in this case, I'm adding eight more elements.

225
00:15:10,930 --> 00:15:14,866
Eventually this is going to trigger a resize. In this

226
00:15:14,888 --> 00:15:18,322
case, now the map size

227
00:15:18,376 --> 00:15:22,162
is nine, the b is one. Because this

228
00:15:22,216 --> 00:15:25,830
number of elements has triggered a resize.

229
00:15:26,170 --> 00:15:29,830
When a resize happens, it's going to reserve another

230
00:15:29,900 --> 00:15:33,570
chunk of memory and it's going to migrate

231
00:15:33,650 --> 00:15:36,726
all the data. It's going to migrate the

232
00:15:36,748 --> 00:15:41,386
data from the original bucket to the new set

233
00:15:41,408 --> 00:15:42,890
of buckets in memory.

234
00:15:46,270 --> 00:15:49,420
Normally it duplicates the number of buckets each time.

235
00:15:50,370 --> 00:15:54,174
And in this process of

236
00:15:54,292 --> 00:15:57,674
migration, it's going to evacuate the old bucket.

237
00:15:57,722 --> 00:16:00,954
That means pick all the keys and the values

238
00:16:01,082 --> 00:16:04,990
and store in the corresponding bucket

239
00:16:05,810 --> 00:16:09,294
in the new set of packets. That implies

240
00:16:09,342 --> 00:16:12,020
that the keys have to be.

241
00:16:12,790 --> 00:16:16,326
It needs to recalculate the hash to decide where

242
00:16:16,428 --> 00:16:20,230
it's going to fall in the new buckets.

243
00:16:21,130 --> 00:16:24,566
Okay. And the number of evacuated buckets is going to be one in

244
00:16:24,588 --> 00:16:28,106
this case because the old bucket was evacuated and moved to

245
00:16:28,128 --> 00:16:30,860
the new buckets, as you can see here.

246
00:16:31,470 --> 00:16:35,386
Well the elements doesn't need to be the same of

247
00:16:35,408 --> 00:16:38,918
the old set of buckets. What an overflow

248
00:16:38,934 --> 00:16:42,934
bucket is, the match gets resized

249
00:16:43,062 --> 00:16:47,822
when it reach certain threshold, but cant

250
00:16:47,876 --> 00:16:52,062
happen that you have a maps with

251
00:16:52,116 --> 00:16:55,806
some data that is not enough to justify a resize,

252
00:16:55,918 --> 00:17:00,274
but one of the buckets is completely full and

253
00:17:00,312 --> 00:17:03,634
then suddenly you try to add something and it's going to fall

254
00:17:03,672 --> 00:17:08,514
in that bucket. And instead of triggering

255
00:17:08,562 --> 00:17:12,550
a resize, simplest approach and better

256
00:17:12,620 --> 00:17:16,694
approach to optimize the usage of the map is

257
00:17:16,732 --> 00:17:21,946
just create an overflow bucket that is

258
00:17:21,968 --> 00:17:26,022
going to reserve a chunk of memory to store a new bucket

259
00:17:26,166 --> 00:17:31,530
and it's going to store in that bucket a new key and

260
00:17:31,600 --> 00:17:35,226
link that to the existing bucket. In this case, as you say, the bucket

261
00:17:35,258 --> 00:17:39,070
one have an overflow pointer that points to another bucket in another position

262
00:17:39,140 --> 00:17:43,042
in memory that have just more

263
00:17:43,096 --> 00:17:45,700
information related to the bucket one.

264
00:17:46,310 --> 00:17:49,726
And also you cant see that the number of overflow buckets

265
00:17:49,838 --> 00:17:53,474
is now one. What happened when you have

266
00:17:53,512 --> 00:17:57,542
big resizes, when you have big resizes in

267
00:17:57,596 --> 00:18:01,480
go, what it does is using

268
00:18:02,170 --> 00:18:04,950
these buckets and old buckets,

269
00:18:05,770 --> 00:18:09,442
variables that are pointing to memory

270
00:18:09,506 --> 00:18:12,886
addresses. So what it does is reserve a

271
00:18:12,908 --> 00:18:16,614
new set of buckets, doubling the size of the number

272
00:18:16,652 --> 00:18:20,842
of buckets, and are migrating

273
00:18:20,906 --> 00:18:23,470
the data to that buckets.

274
00:18:24,050 --> 00:18:27,802
That new buckets is going to be buckets and the previous

275
00:18:27,866 --> 00:18:32,030
existing buckets is going to become all buckets.

276
00:18:33,110 --> 00:18:37,140
And it's not going to migrate all the data in

277
00:18:37,510 --> 00:18:41,218
one time because that will take extra

278
00:18:41,304 --> 00:18:44,562
time that can have some

279
00:18:44,616 --> 00:18:47,830
performance impact. So what it does

280
00:18:47,900 --> 00:18:53,526
is just start migrating the data gradually with

281
00:18:53,628 --> 00:18:57,350
each operation. This way you don't have

282
00:18:57,420 --> 00:19:00,986
a big blocked. When you need

283
00:19:01,008 --> 00:19:04,906
to resize a map, you have just resized the map and it's not

284
00:19:05,008 --> 00:19:09,094
blocking that much and it's just getting some performance

285
00:19:09,142 --> 00:19:13,194
degradation during certain time. And whenever

286
00:19:13,322 --> 00:19:17,070
everything is migrated, the map backs to normal.

287
00:19:19,330 --> 00:19:24,814
All buckets and number of evacuated buckets is used for

288
00:19:24,852 --> 00:19:28,846
this process of migration. Once all

289
00:19:28,868 --> 00:19:32,190
the buckets in the old buckets are evacuated,

290
00:19:34,530 --> 00:19:36,870
the system just released that memory.

291
00:19:38,170 --> 00:19:41,560
Okay, here is the code. If you want to reproduce that,

292
00:19:42,010 --> 00:19:45,240
you are going to find them at the end of the talk

293
00:19:46,170 --> 00:19:49,862
channels. For channels, I'm going to use a channel

294
00:19:49,916 --> 00:19:54,810
of infirty two. Again just using

295
00:19:54,880 --> 00:19:58,106
unsafe to access the memory. Storing that in a

296
00:19:58,128 --> 00:20:01,902
structure, the microscope more or less the same. Getting that

297
00:20:01,956 --> 00:20:05,760
structure, printing that in a readable way.

298
00:20:07,650 --> 00:20:11,370
The subject in this case is a channel. More specifically,

299
00:20:11,450 --> 00:20:14,722
I'm going to use the buffered channels because

300
00:20:14,776 --> 00:20:18,562
it's more interesting and you can infer how

301
00:20:18,616 --> 00:20:22,900
a non buffer channel works. Basically not

302
00:20:23,830 --> 00:20:27,106
assigning a buffer of zero to this. And you

303
00:20:27,128 --> 00:20:31,074
are going to have exactly the same behavior. You can infer the behavior

304
00:20:31,202 --> 00:20:35,174
based on that. A channel is going to have

305
00:20:35,212 --> 00:20:38,934
a queue count that is the number of elements stored in the buffer.

306
00:20:39,062 --> 00:20:42,662
A data queue size, that is the number of elements

307
00:20:42,726 --> 00:20:45,882
that the buffer cant store. The buffer itself,

308
00:20:46,016 --> 00:20:50,122
that is just a chunk of memory. In this

309
00:20:50,176 --> 00:20:54,160
case, it's a chunk of four positions of in 32 because

310
00:20:55,570 --> 00:20:59,774
it's a buffer. Channels with size four

311
00:20:59,972 --> 00:21:02,800
and the channel type is in 32.

312
00:21:03,830 --> 00:21:07,970
The element size is the size of each element

313
00:21:09,430 --> 00:21:12,834
in the buffer. The closed defines if the channel

314
00:21:12,872 --> 00:21:16,966
is open or closed. The element type is appointed to, in this case in 32

315
00:21:17,068 --> 00:21:20,630
representation. So it's a pointer to the type that is stored

316
00:21:22,330 --> 00:21:25,990
in the channel buffer. The send x and receive x

317
00:21:26,060 --> 00:21:30,634
are two indexes that points to

318
00:21:30,672 --> 00:21:34,394
the position in the buffer that is going to be the next place where

319
00:21:34,432 --> 00:21:37,740
you send something or where you receive something.

320
00:21:38,910 --> 00:21:43,182
The receive queue and the send queue is

321
00:21:43,236 --> 00:21:47,200
a two wait queue list. A wait queue is basically

322
00:21:49,730 --> 00:21:53,140
a place where you can store

323
00:21:53,750 --> 00:21:56,900
go routines that are waiting for something.

324
00:21:57,510 --> 00:22:01,218
So in this case, the recipe and the send q are where the

325
00:22:01,304 --> 00:22:05,070
channels, sorry, where the goroutines wait

326
00:22:05,240 --> 00:22:08,840
for the channel to have data or to have a space for data.

327
00:22:10,810 --> 00:22:14,150
Okay, let's see an example. If I create a channel

328
00:22:14,220 --> 00:22:18,058
of infertility, two with four positions, with a

329
00:22:18,064 --> 00:22:21,658
buffer of four, what I'm going to have is

330
00:22:21,824 --> 00:22:25,754
a Q count of zero data queue size of

331
00:22:25,792 --> 00:22:29,082
four, because I have space for four

332
00:22:29,216 --> 00:22:33,198
elements. And the element size is going to be four because it's an in 32,

333
00:22:33,284 --> 00:22:36,554
that means four bytes. The buffer

334
00:22:36,602 --> 00:22:39,534
is going to contain for now,

335
00:22:39,652 --> 00:22:43,526
because it's just a four positions buffer of four integrals.

336
00:22:43,578 --> 00:22:45,620
That is no elements yet.

337
00:22:46,310 --> 00:22:49,714
Okay, what happened if I add one element to the

338
00:22:49,752 --> 00:22:53,346
channel? If I add one element to the channel,

339
00:22:53,528 --> 00:22:58,262
the Q count is going to be increased to one because

340
00:22:58,316 --> 00:23:02,706
I'm adding a five. That five is going to be a store in the buffer.

341
00:23:02,818 --> 00:23:07,062
Where the send X index was

342
00:23:07,116 --> 00:23:10,534
pointing to, was pointing to the first position in the buffer.

343
00:23:10,582 --> 00:23:14,682
So I store five in the first position in the buffer and increment the

344
00:23:14,736 --> 00:23:18,170
senex to the next position in the buffer.

345
00:23:20,110 --> 00:23:23,886
What happened if I add more data than the buffer can store?

346
00:23:23,988 --> 00:23:27,120
In this case, I'm adding 4321.

347
00:23:28,050 --> 00:23:31,742
If I add 4321, I'm going to add four

348
00:23:31,796 --> 00:23:35,346
in the senex position. That was the second position. The senex is

349
00:23:35,368 --> 00:23:38,626
going to be increased and I add three, and then I

350
00:23:38,648 --> 00:23:42,750
add two and so on. But whenever

351
00:23:42,830 --> 00:23:46,774
I try to add the one, the Q count is

352
00:23:46,812 --> 00:23:50,118
already four, so there's no enough

353
00:23:50,204 --> 00:23:53,170
space for adding a new element.

354
00:23:53,330 --> 00:23:56,790
So what the goroutines is going to do is going to store

355
00:23:56,860 --> 00:24:00,726
himself in the

356
00:24:00,748 --> 00:24:04,902
send queue and it's going to park himself to

357
00:24:04,956 --> 00:24:08,742
wait until, to wait until there is some

358
00:24:08,796 --> 00:24:12,794
space in the buffer. What happened if somebody reads

359
00:24:12,842 --> 00:24:16,622
something? If somebody reads something, it's going to receive that

360
00:24:16,676 --> 00:24:21,406
five because it's going to read the

361
00:24:21,428 --> 00:24:25,074
data in the receive X position. That was the

362
00:24:25,112 --> 00:24:28,802
first element in the buffer. So it's going to read that data and return

363
00:24:28,856 --> 00:24:32,994
that data to the requester and

364
00:24:33,032 --> 00:24:35,380
it's going to increase the receive x.

365
00:24:36,650 --> 00:24:40,386
The data queue size hasn't changed, but hasn't

366
00:24:40,418 --> 00:24:43,734
changed because once we read that

367
00:24:43,772 --> 00:24:46,962
data, we see that the San queue

368
00:24:47,026 --> 00:24:50,682
have somebody waiting there. So we wake up that

369
00:24:50,736 --> 00:24:54,806
go routine and that goroutines automatically

370
00:24:54,918 --> 00:24:58,554
inserts the one value. The value that was waiting before to

371
00:24:58,592 --> 00:25:01,738
try to insert is going to get inserted in the position

372
00:25:01,824 --> 00:25:03,680
where the ten x was.

373
00:25:05,490 --> 00:25:09,326
And that's the reason why we have still a four in

374
00:25:09,348 --> 00:25:13,458
the q count and the first element in

375
00:25:13,464 --> 00:25:17,006
the buffer now is one. And the receive index

376
00:25:17,038 --> 00:25:19,460
and the send index have moved one position.

377
00:25:21,830 --> 00:25:25,614
Okay, if I read more data from the channel.

378
00:25:25,752 --> 00:25:29,554
What is going to happen is now it's going to decrease

379
00:25:29,682 --> 00:25:32,550
the amount of data. The Q count to three.

380
00:25:32,620 --> 00:25:36,534
Because there's nothing. Adding more data and

381
00:25:36,572 --> 00:25:40,338
there's no more data. Now it's

382
00:25:40,354 --> 00:25:44,138
going to read where the recifex was. That is in the second position.

383
00:25:44,304 --> 00:25:48,074
So it's going to return a four. That is

384
00:25:48,112 --> 00:25:50,540
what was in the second position before.

385
00:25:51,570 --> 00:25:54,110
And it's going to increase the recifex.

386
00:25:56,610 --> 00:26:00,254
And that's it. What happened

387
00:26:00,292 --> 00:26:03,522
if I read more data than I

388
00:26:03,576 --> 00:26:06,866
have in

389
00:26:06,888 --> 00:26:10,066
the buffer? Well, it's going

390
00:26:10,088 --> 00:26:13,250
to start reading data. It's going to read the three,

391
00:26:13,320 --> 00:26:16,742
the two, the one. And when it reached the point where

392
00:26:16,796 --> 00:26:18,200
there's no more data.

393
00:26:20,170 --> 00:26:23,622
The goroutines that is trying to get data

394
00:26:23,676 --> 00:26:25,510
from the channel that is empty.

395
00:26:27,550 --> 00:26:30,310
Is going to add himself to the receive queue.

396
00:26:30,390 --> 00:26:33,930
And park himself waiting for new data

397
00:26:34,000 --> 00:26:37,178
to come in in the channel.

398
00:26:37,344 --> 00:26:41,198
If somebody sends something to the channel, it's going

399
00:26:41,204 --> 00:26:45,614
to wake up that goroutines. But what

400
00:26:45,652 --> 00:26:48,720
happened if I close the channel? If I close the channel,

401
00:26:52,390 --> 00:26:55,940
everybody that is connected to receive data from the channel.

402
00:26:56,310 --> 00:26:58,980
Is going to receive the zero.

403
00:26:59,590 --> 00:27:00,340
Well,

404
00:27:03,830 --> 00:27:07,666
the closed message from the channel in

405
00:27:07,688 --> 00:27:11,046
this case is going to go to the receive queue. Send that message

406
00:27:11,148 --> 00:27:14,246
to any receiver that is in the

407
00:27:14,268 --> 00:27:17,758
receive queue. And it's going to change the closed

408
00:27:17,794 --> 00:27:21,366
value of the channel to one. And that's

409
00:27:21,398 --> 00:27:24,346
it. Here is the code if you want to try it.

410
00:27:24,448 --> 00:27:25,420
It's interesting.

411
00:27:27,630 --> 00:27:31,102
Okay, some references. If you want to know more about

412
00:27:31,156 --> 00:27:34,606
slices, maps and channels. Probably reading the

413
00:27:34,628 --> 00:27:38,298
go runtime code is not complicated.

414
00:27:38,474 --> 00:27:42,122
It's not super straightforward, but it's not especially complicated.

415
00:27:42,186 --> 00:27:45,780
You can get more or less what is going on. Actually,

416
00:27:46,390 --> 00:27:49,380
I wrote this talk just reading that information.

417
00:27:50,870 --> 00:27:54,450
If you want to reproduce that experiment, you can go to

418
00:27:54,520 --> 00:27:59,158
my GitHub. Repo. Dissecting go and

419
00:27:59,244 --> 00:28:02,838
just reproduce these experiments is just a

420
00:28:02,844 --> 00:28:05,830
lot of fun and some conclusions.

421
00:28:08,350 --> 00:28:12,218
Well, understanding the building blocks of the language is going

422
00:28:12,224 --> 00:28:15,434
to help you to understand the implications that

423
00:28:15,552 --> 00:28:18,058
that building blocks comes with.

424
00:28:18,224 --> 00:28:24,446
Because sometimes

425
00:28:24,628 --> 00:28:28,074
these building blocks have some trade offs

426
00:28:28,122 --> 00:28:31,406
in it. Have some decisions that were made by the.

427
00:28:31,428 --> 00:28:35,922
By the Go team. And if you understand why

428
00:28:36,056 --> 00:28:39,842
that decisions are there and how

429
00:28:39,896 --> 00:28:41,250
they really behave,

430
00:28:44,970 --> 00:28:47,160
you can use it better.

431
00:28:49,130 --> 00:28:52,934
Well, also take into

432
00:28:52,972 --> 00:28:56,854
consideration that there are some unexpected behaviors that can be

433
00:28:56,892 --> 00:29:00,614
surprising, especially the slices. One is really

434
00:29:00,652 --> 00:29:01,240
interesting.

435
00:29:03,530 --> 00:29:07,334
And probably this knowledge is not going

436
00:29:07,372 --> 00:29:11,120
to be needed for anything. That you are going to do in

437
00:29:11,730 --> 00:29:15,520
your work, but it can help

438
00:29:16,530 --> 00:29:18,590
in very specific situations.

439
00:29:20,050 --> 00:29:21,886
So that's it. Thank you,

