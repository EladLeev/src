1
00:00:32,770 --> 00:00:36,594
Hello and welcome to my talk on how to build machine learning enhanced event streaming

2
00:00:36,642 --> 00:00:39,926
applications with Java. My name is David Kjerrumgaard and I'm

3
00:00:39,948 --> 00:00:43,286
a developer advocate at Stream Native. I have over two decades of experience in

4
00:00:43,308 --> 00:00:46,898
software development, big data and event streaming. I'm also a committer

5
00:00:46,914 --> 00:00:50,206
on the Apache Pulsar project and a published author. As you can see,

6
00:00:50,228 --> 00:00:53,774
I've worked across a diverse set of companies, everywhere from Amazon and

7
00:00:53,892 --> 00:00:57,226
FedEx to Zappos. As I mentioned in the previous slide,

8
00:00:57,258 --> 00:01:00,826
I'm also a published author. I'm the author of Pulsar in Action by Manning

9
00:01:00,858 --> 00:01:04,094
Press, which is available for free download on the link shown here at the bottom

10
00:01:04,132 --> 00:01:07,666
of the slide, and also a co author of Practical Hive. So let's talk

11
00:01:07,688 --> 00:01:10,926
about the agenda for today. We'll start with why Apache

12
00:01:10,958 --> 00:01:14,814
Pulsar is a great fit for event driven microservices,

13
00:01:14,942 --> 00:01:18,530
and how to build an event driven microservices applications

14
00:01:18,610 --> 00:01:22,006
with pulsar functions. Once we've shown you how to develop a

15
00:01:22,028 --> 00:01:25,458
basic pulsar function, what enhances event driven microservices

16
00:01:25,554 --> 00:01:29,242
to include a machine learning element to it? So let's begin with

17
00:01:29,296 --> 00:01:32,902
event driven microservices and event driven architecture.

18
00:01:33,046 --> 00:01:36,614
Event driven architecture is a completely decoupled

19
00:01:36,662 --> 00:01:40,246
system in which microservices independent systems communicate

20
00:01:40,278 --> 00:01:43,898
with one another asynchronously by exchanging events between them.

21
00:01:43,984 --> 00:01:47,294
Rather than making a point to point call, use a message broker of some

22
00:01:47,332 --> 00:01:50,714
sort as an intermediary to store these events and then deliver

23
00:01:50,762 --> 00:01:54,210
them to all the registered consumers who are interested in these events. So an event

24
00:01:54,280 --> 00:01:57,570
represents something like a change in state to the system,

25
00:01:57,720 --> 00:02:00,670
such as an item being placed into a shopping cart,

26
00:02:00,830 --> 00:02:04,766
ecommerce order being checked out, or an item

27
00:02:04,798 --> 00:02:08,694
being added to your shipment and being delivered on its way for delivery to

28
00:02:08,732 --> 00:02:12,146
your house. Now, event driven architectures are loosely

29
00:02:12,178 --> 00:02:16,258
coupled, and again, they communicate asynchronously, typically via a pub sub mechanism.

30
00:02:16,354 --> 00:02:19,554
Event driven microservices then, are microservices

31
00:02:19,602 --> 00:02:22,906
that are designed to communicate with one another over these message buses, right?

32
00:02:22,928 --> 00:02:26,566
So we talked about event driven architecture, but not necessarily microservices.

33
00:02:26,678 --> 00:02:30,906
So you can couple the microservices philosophy with

34
00:02:31,008 --> 00:02:34,970
decomposing applications in very small pieces based on a business line of unit,

35
00:02:35,050 --> 00:02:38,474
and have them implement that using that same pattern.

36
00:02:38,522 --> 00:02:41,982
Again, communicating over an event bus of some sort. In short,

37
00:02:42,036 --> 00:02:45,586
event driven microservices need an event bus to interact with

38
00:02:45,608 --> 00:02:49,502
one another. That's the critical component that all event driven microservices

39
00:02:49,566 --> 00:02:53,346
share in common, regardless of what programming languages they're written in

40
00:02:53,448 --> 00:02:56,754
such as Java or Python that allows them to be written in any

41
00:02:56,792 --> 00:03:00,386
language of your choice and communicate with one another seamlessly.

42
00:03:00,498 --> 00:03:04,198
So let's pivot a little bit and talk about Apache Pulsar and why it

43
00:03:04,204 --> 00:03:07,362
is a good fit for event driven microservices.

44
00:03:07,506 --> 00:03:10,826
Apache Pulsar was founded originally in Yahoo in

45
00:03:10,848 --> 00:03:14,234
2012, and it was designed to be a cloud native messaging and

46
00:03:14,272 --> 00:03:18,522
event streaming platform. So it includes all the capabilities of

47
00:03:18,576 --> 00:03:21,966
your traditional pub submessaging mechanisms like you would see

48
00:03:21,988 --> 00:03:26,346
in a traditional messaging system like RabbitMQ or IBM

49
00:03:26,378 --> 00:03:29,914
MQ, things like that, and also includes a more modern

50
00:03:29,962 --> 00:03:33,534
event streaming or event consumption messaging model that comes with

51
00:03:33,572 --> 00:03:37,694
Apache kafka or under the covers, Amazon kinesis

52
00:03:37,742 --> 00:03:41,134
and things like that. So it is really designed to support both messaging

53
00:03:41,182 --> 00:03:44,978
semantics natively. Out of the is by default it has a

54
00:03:44,984 --> 00:03:48,706
pub sub model so the producers and consumers don't interact

55
00:03:48,738 --> 00:03:52,994
with one another. A producer connects to a pulsar broker and publishes

56
00:03:53,042 --> 00:03:56,166
messages. These messages are stored on a topic which is

57
00:03:56,188 --> 00:03:59,234
just a name channel between producers and consumers.

58
00:03:59,282 --> 00:04:02,990
Consumers can then, at their leisure when they want to come in attached

59
00:04:03,010 --> 00:04:07,302
to the broker and consume messages from the topic in an asynchronous manner.

60
00:04:07,366 --> 00:04:12,042
So again, they are completely decoupled from one another, they communicate asynchronously,

61
00:04:12,186 --> 00:04:15,466
and they have a single endpoint being the pulsar broker

62
00:04:15,498 --> 00:04:19,274
to communicate between them logically. At the bottom of all pulsar

63
00:04:19,322 --> 00:04:22,618
communications is what's called topics like any other

64
00:04:22,724 --> 00:04:26,386
messaging system. Just wanted to note here that unlike other

65
00:04:26,408 --> 00:04:29,502
messaging systems, it actually has a three tier

66
00:04:29,646 --> 00:04:33,842
URI or uniquely referenceable interface id for each

67
00:04:33,896 --> 00:04:37,358
topic. So a topic exists within a tenant,

68
00:04:37,454 --> 00:04:40,806
and pulsar is a multi tenant system natively out of the box, which is a

69
00:04:40,828 --> 00:04:44,214
different shading feature from other messaging systems. So you can have different

70
00:04:44,332 --> 00:04:47,894
independent departments within your organization, sharing the same

71
00:04:48,012 --> 00:04:51,126
logical cluster and being logically isolated from one another.

72
00:04:51,228 --> 00:04:55,222
Next, under tenants exists the concept of namespaces, which is a logical grouping

73
00:04:55,286 --> 00:04:58,794
of topics who have similar policy requirements around security

74
00:04:58,912 --> 00:05:02,214
or data retention, tiered storage, offloading,

75
00:05:02,262 --> 00:05:05,086
things like that. And then last but not least, there are topics sitting at the

76
00:05:05,108 --> 00:05:08,654
bottom of those, and these are where the messages ultimately end up. And so when

77
00:05:08,692 --> 00:05:12,074
producers produce the topics, they address it that way. And likewise

78
00:05:12,122 --> 00:05:15,858
from a consumer perspective, they give the tenant namespace a

79
00:05:15,864 --> 00:05:19,106
topic to uniquely identify those particular topics they

80
00:05:19,128 --> 00:05:22,878
want to consume messages from I'll touch briefly on the physical architecture

81
00:05:22,894 --> 00:05:26,402
of pulsar cluster that it is. Again, as I mentioned

82
00:05:26,456 --> 00:05:29,958
earlier, it's cloud native, and what this means is it's architected in such a way

83
00:05:29,964 --> 00:05:33,746
that it's designed to run in cloud environments, more containerized environments.

84
00:05:33,858 --> 00:05:37,234
It can take advantage of features like stateful sets

85
00:05:37,282 --> 00:05:40,354
to automatically restore state if one of the instances

86
00:05:40,402 --> 00:05:44,246
goes down or to scale up automatically dynamically. And how we architected

87
00:05:44,278 --> 00:05:47,942
for that way, a pulsar to be that way was that we had a decoupled

88
00:05:48,006 --> 00:05:51,498
architecture in that the serving of the messages, the pulsar brokers shown there

89
00:05:51,504 --> 00:05:54,958
at the top are completely stateless. No data is stored on

90
00:05:54,964 --> 00:05:58,766
the pulsar brokers that's kept completely separate in what's in

91
00:05:58,788 --> 00:06:02,734
a storage layer based on Apache bookkeeper, which is another storage open

92
00:06:02,772 --> 00:06:06,426
source project based on for storage. So when you publish data to a pulsar topic

93
00:06:06,458 --> 00:06:10,734
it is persisted to bookkeeper. This gives a lot of advantages, again for resiliency

94
00:06:10,862 --> 00:06:14,434
because if any broker dies another one could take over

95
00:06:14,472 --> 00:06:18,226
serving that topic because the data doesn't go with it which is completely different

96
00:06:18,328 --> 00:06:21,858
from all other messaging systems out there. This really sets it apart which allows

97
00:06:21,874 --> 00:06:25,506
it to scale dynamically. Now tying the two together is the metadata storage,

98
00:06:25,538 --> 00:06:29,334
right. We're putting this data on a different storage layer. So how do

99
00:06:29,372 --> 00:06:32,618
the brokers know where to go and bookkeeper to get it? Well that's where the

100
00:06:32,624 --> 00:06:36,186
metadata storage comes in. That's where we keep all the

101
00:06:36,208 --> 00:06:39,766
records, policies and what we call the managed ledger

102
00:06:39,878 --> 00:06:43,386
for where this topic components are spread out across Apache

103
00:06:43,418 --> 00:06:47,386
bookkeeper in that component. It's a pluggable architecture. You have a lot of choices

104
00:06:47,418 --> 00:06:51,386
on what you want to use. Historically it's been based on Apache

105
00:06:51,418 --> 00:06:54,922
Zookeeper which is known to have issues and scalability issues at some point.

106
00:06:54,996 --> 00:06:58,610
So if you're running in a containerized environment you might want to consider Etsyd.

107
00:06:59,030 --> 00:07:02,974
We also included a new release by streamnative called Oxia

108
00:07:03,102 --> 00:07:07,454
which is a highly scalable system that solves a lot of the problems that zookeeper

109
00:07:07,502 --> 00:07:11,346
had. So if you're interested in going with pulsar, I highly recommend looking at Oxy

110
00:07:11,378 --> 00:07:15,174
which is indicated by that little pinwheel logo there

111
00:07:15,292 --> 00:07:18,566
on the left inside the metadata storage box. Let's pivot a little bit

112
00:07:18,588 --> 00:07:21,434
and talk about pulsar functions. So now you know what Pulsar is. It's your event

113
00:07:21,472 --> 00:07:24,906
messaging bus. It provides pub sub messaging. That's great David. We need that

114
00:07:24,928 --> 00:07:28,806
for event driven architecture, event driven microservices.

115
00:07:28,918 --> 00:07:32,766
So what are these pulsar functions? Well within patchy Pulsar we decided to create

116
00:07:32,788 --> 00:07:36,446
a serverless computing framework that runs inside pulsar itself. You can think of

117
00:07:36,468 --> 00:07:40,382
them like AWS lambdas, and they enable very low

118
00:07:40,436 --> 00:07:43,886
functional level programming. A very simplistic

119
00:07:43,918 --> 00:07:47,006
API that wires in directly to Apache

120
00:07:47,038 --> 00:07:51,170
Pulsar itself and handles all of behind the scenes

121
00:07:51,670 --> 00:07:54,754
the details of the coding, of setting up a producer to

122
00:07:54,792 --> 00:07:57,934
write data to Pulsar and a consumer to consume

123
00:07:57,982 --> 00:08:01,074
data from Pulsar. And all you have to do is function on the business logic

124
00:08:01,122 --> 00:08:04,246
itself. So you say, I want this to be a pulsar function. This is my

125
00:08:04,268 --> 00:08:08,066
input topic, this is my output topic. And all of that happens for you automatically.

126
00:08:08,098 --> 00:08:11,210
The framework takes care of that for you, and they allow you to run individual

127
00:08:11,280 --> 00:08:14,906
units of code that react to that particular publication of

128
00:08:15,008 --> 00:08:18,538
messages. So they have a programming model, something like this.

129
00:08:18,704 --> 00:08:23,178
Pulsar function is just a deployable piece of code that you control,

130
00:08:23,344 --> 00:08:26,846
and every time a new message comes in, that event gets triggered automatically. We'll see

131
00:08:26,868 --> 00:08:29,886
what the API is here in a second, but every time a message comes in

132
00:08:29,908 --> 00:08:33,454
off of any of the input topics you're subscribed to, boom, your code

133
00:08:33,492 --> 00:08:36,650
gets triggered. Now, as you process that

134
00:08:36,660 --> 00:08:39,694
data, you may want to have an output, generate some output,

135
00:08:39,742 --> 00:08:43,374
do some processing to it, do some manipulation so you can optionally

136
00:08:43,422 --> 00:08:47,182
publish it to an output topic. And also for monitoring and tracking progress,

137
00:08:47,246 --> 00:08:50,758
things like that, debugging, there's an optional logging topic as well, which you can

138
00:08:50,764 --> 00:08:54,834
publish messages to. And this is great. So again, it supports multiple programming

139
00:08:54,882 --> 00:08:58,930
languages, and we'll focus on Java today. But if you want to write your microservices

140
00:08:59,010 --> 00:09:02,254
in Python or go, that is also fully supported.

141
00:09:02,402 --> 00:09:05,066
And the key to this, as we'll see here at the end, is that you

142
00:09:05,088 --> 00:09:08,730
can package third party libraries into these code itself.

143
00:09:08,800 --> 00:09:12,230
So if you want to include a machine learning library,

144
00:09:12,310 --> 00:09:15,774
as we'll see here in the example, you can do that and take

145
00:09:15,812 --> 00:09:18,910
full advantage of that inside your pulsar functions. You don't need to set up

146
00:09:18,980 --> 00:09:22,826
a complex framework to do these sorts of things, you can just easily embed

147
00:09:22,858 --> 00:09:26,578
it and take advantage of that. So why do we think pulsar functions are good

148
00:09:26,664 --> 00:09:30,354
for microservices in general, or just why

149
00:09:30,392 --> 00:09:34,002
pulsar functions versus alternatives, right? When we decided to design

150
00:09:34,056 --> 00:09:37,766
pulsar messaging system, we realized that a lot of

151
00:09:37,868 --> 00:09:41,522
stream processing functionality is really simplistic,

152
00:09:41,586 --> 00:09:44,806
that you need to do a few simple operations on it. And a lot of

153
00:09:44,828 --> 00:09:48,822
people had difficulty in setting up yet an additional data

154
00:09:48,876 --> 00:09:52,166
pipeline tool, something like a stream processing

155
00:09:52,198 --> 00:09:55,402
engine like storm or flink, that's its own distributed system,

156
00:09:55,456 --> 00:09:59,098
just to do some processing of the data. So we

157
00:09:59,104 --> 00:10:03,114
wanted to make it more simplistic. We also wanted to embrace the serverless

158
00:10:03,162 --> 00:10:06,234
computing model so that they can run in containerized

159
00:10:06,282 --> 00:10:10,266
environments. They can be deployed as Kubernetes pods.

160
00:10:10,378 --> 00:10:14,178
This allows them to be resilient to failures and starts and stops, things like that.

161
00:10:14,344 --> 00:10:17,954
And it's also to maximize developer productivity, right? You don't need to

162
00:10:17,992 --> 00:10:21,134
learn a complex framework

163
00:10:21,182 --> 00:10:24,734
like flink and something like Scala to handle spark

164
00:10:24,782 --> 00:10:28,514
or something like that. You can just write a very simple language

165
00:10:28,562 --> 00:10:32,262
native interface in Java and implement a simple method and

166
00:10:32,316 --> 00:10:35,586
it's easy to get going. Again, they're designed for lightweight stream

167
00:10:35,618 --> 00:10:39,298
processing. They excel at basic use cases that don't

168
00:10:39,314 --> 00:10:42,998
require the complexity of full stream processing engine, such as event driven

169
00:10:43,014 --> 00:10:46,266
microservices. Again, so an event comes in, I'm notified of it,

170
00:10:46,288 --> 00:10:49,706
I do my processing logic and I optionally publish an event out, or I

171
00:10:49,728 --> 00:10:53,018
manipulate and store some data. That's entirely up to me and it's a

172
00:10:53,024 --> 00:10:56,190
great fit for that. You can also use them for simple things like

173
00:10:56,340 --> 00:11:00,078
messaging, transformations, ETL sort of processing. I want

174
00:11:00,084 --> 00:11:02,826
to do data enrichment. Something comes in, I want to do lookup in a database,

175
00:11:02,858 --> 00:11:06,958
add that up, clean up some data, maybe offload some bad records coming in,

176
00:11:07,044 --> 00:11:09,938
things like that, and you can chain them together. That's the beauty of them as

177
00:11:09,944 --> 00:11:13,726
well, because you have an input topic in one and an output topic. That output

178
00:11:13,758 --> 00:11:17,282
topic could then be the input to another one. So it really allows you to

179
00:11:17,336 --> 00:11:20,742
start developing some complex chains using some very simple

180
00:11:20,796 --> 00:11:24,438
tools. So let's talk about developing pulsar functions. So I laid the

181
00:11:24,444 --> 00:11:27,718
groundwork here. Now you have a processing engine, you have a compute engine to do

182
00:11:27,724 --> 00:11:31,346
it on what is required to do it. So there are native

183
00:11:31,458 --> 00:11:35,034
pulsar functions, but I won't get into that today. That just

184
00:11:35,072 --> 00:11:38,758
allows you to do it without the SDK, which is an option. But what I'm

185
00:11:38,774 --> 00:11:42,906
going to demonstrate straight today includes a pulsar functions SDK software

186
00:11:42,938 --> 00:11:46,298
development kit that includes an API. Again, it's supported

187
00:11:46,314 --> 00:11:51,834
for all three languages, and it provides a richer set of API

188
00:11:51,882 --> 00:11:55,714
for doing interesting things, right. So you can have a single message come in and

189
00:11:55,752 --> 00:11:59,122
publish it out to multiple output topics if you want. We also

190
00:11:59,176 --> 00:12:02,606
support the retention of state within pulsar functions

191
00:12:02,638 --> 00:12:06,542
themselves. So you can, for example, compute an aggregate,

192
00:12:06,606 --> 00:12:10,066
store that to a state and then come back later on,

193
00:12:10,088 --> 00:12:13,094
or pull that data back out and use that stored value as part of your

194
00:12:13,132 --> 00:12:16,818
manipulation computation. Again, which is great for something like event driven

195
00:12:16,834 --> 00:12:20,626
microservices. Maybe you want to store your database state what you've

196
00:12:20,658 --> 00:12:23,846
seen of these messages, so that you can use that as your external

197
00:12:23,878 --> 00:12:27,078
data store and you can produce to many different topics,

198
00:12:27,174 --> 00:12:30,874
consume data, content based routing. All these different features are available with

199
00:12:30,912 --> 00:12:34,734
the functions SDK. Last but not

200
00:12:34,772 --> 00:12:38,478
least, before I get into the demonstration, obviously we're going to package a

201
00:12:38,484 --> 00:12:42,574
lot of third party libraries together, machine learning libraries specifically for this use

202
00:12:42,612 --> 00:12:46,510
case. And obviously when you deploy them up to this fronttime environment,

203
00:12:46,590 --> 00:12:50,194
it's critical that you bundle all these deployments with them. They're not going to be

204
00:12:50,232 --> 00:12:53,698
available inside pulsar themselves, so they have to

205
00:12:53,704 --> 00:12:56,734
be all within a single deployable artifact.

206
00:12:56,862 --> 00:13:00,114
And for the Java based functions you can use either a Uber

207
00:13:00,162 --> 00:13:03,346
jar or a NAR file. I prefer NAR file

208
00:13:03,378 --> 00:13:07,106
for multitude of reasons, and that's what I'm going to demonstrate today. For Python

209
00:13:07,138 --> 00:13:10,726
you have different options as well, and for go based functions

210
00:13:10,838 --> 00:13:13,610
you can deploy them as a go file.

211
00:13:24,450 --> 00:13:27,550
So let's explore the code from the repository.

212
00:13:28,210 --> 00:13:31,502
There are two maven modules within this repo, the first being

213
00:13:31,556 --> 00:13:35,002
one called sentiment analysis function. This represents

214
00:13:35,066 --> 00:13:38,466
a Java based microservice that will be using the

215
00:13:38,488 --> 00:13:42,354
machine learning model to perform a sentiment analysis on

216
00:13:42,472 --> 00:13:46,610
raw tweet data. As you can see here, it contains

217
00:13:46,770 --> 00:13:50,774
a Java class called sentiment analysis function that implements the

218
00:13:50,812 --> 00:13:54,594
function interface defined in the Apache Pulsar

219
00:13:54,642 --> 00:13:58,750
functions API. It is a typed

220
00:13:58,930 --> 00:14:02,186
interface which specifies the input type value coming in from

221
00:14:02,208 --> 00:14:05,974
the source topic as string, and we will be returning

222
00:14:06,102 --> 00:14:10,066
a type of analyzed tweet which is a user defined

223
00:14:10,118 --> 00:14:13,502
class that will contain the tweet text itself along

224
00:14:13,556 --> 00:14:16,030
with the calculated sentiment for that tweet.

225
00:14:18,370 --> 00:14:22,160
The only method defined in this interface is the one called process

226
00:14:22,610 --> 00:14:26,690
found here, and we mark it with the override annotation.

227
00:14:27,910 --> 00:14:30,926
To note is that we're going to return a type of analyzed tweet,

228
00:14:30,958 --> 00:14:34,466
which is what is specified as the output type in the function,

229
00:14:34,648 --> 00:14:38,130
and these must match. Similarly, the input type

230
00:14:38,200 --> 00:14:42,086
was specified as string and the input parameter. The first one

231
00:14:42,108 --> 00:14:45,618
is going to be of that same type, allowing you to have strongly typed

232
00:14:45,714 --> 00:14:49,260
data coming in so you can manipulate it in the manner you see fit.

233
00:14:50,430 --> 00:14:53,946
We have added a single guard and initializing method to make

234
00:14:53,968 --> 00:14:57,494
sure that we initialize this natural language processing

235
00:14:57,542 --> 00:15:01,758
library just once in order to perform it, rather than do this

236
00:15:01,844 --> 00:15:05,326
multiple times. We can see that this library is

237
00:15:05,348 --> 00:15:09,342
an open source library, third party library available here,

238
00:15:09,476 --> 00:15:12,726
and we include it in the module as a definition

239
00:15:12,778 --> 00:15:16,834
here. So we include it as a normal dependency like you would any other

240
00:15:17,032 --> 00:15:20,846
Java class, and it's freely available inside the pulsar functions

241
00:15:20,878 --> 00:15:22,930
themselves, which is really powerful.

242
00:15:24,710 --> 00:15:27,826
Not a lot is going on inside this particular method, but we just want to

243
00:15:27,848 --> 00:15:31,398
demonstrate the capabilities, right? So a tweet comes in, the text comes in,

244
00:15:31,484 --> 00:15:34,742
and then we leverage this third party library, this machine learning model,

245
00:15:34,876 --> 00:15:38,406
to perform sentiment analysis on it. It calculates a

246
00:15:38,428 --> 00:15:42,166
sentiment for us, and as I mentioned before, we return a value that

247
00:15:42,188 --> 00:15:45,942
contains the original tweet text along with a calculated sentiment.

248
00:15:46,086 --> 00:15:48,746
And this is really it. This is the core of it, but it gives you

249
00:15:48,768 --> 00:15:52,506
an idea of what actually can be done. Now, in addition to including

250
00:15:52,538 --> 00:15:56,378
the third party libraries in the base palm, you can see that we've defined

251
00:15:56,474 --> 00:16:00,510
a plugin, a build plugin here, which is the NAR plugin.

252
00:16:00,930 --> 00:16:04,910
This bundles everything together in a unified single deployable

253
00:16:04,990 --> 00:16:09,090
modules. I discussed in the previous section, makes it easy for deployment.

254
00:16:11,510 --> 00:16:15,258
The second module is called a tweet simulator,

255
00:16:15,454 --> 00:16:19,400
and this is going to publish data out for us.

256
00:16:20,650 --> 00:16:23,926
It is also based on the Pulsar I O

257
00:16:23,948 --> 00:16:27,478
and functions framework, but it implements a different interface here

258
00:16:27,644 --> 00:16:31,210
called source, which is part of the Apache Pulsario

259
00:16:31,790 --> 00:16:35,014
core framework. It allows you to integrate with systems,

260
00:16:35,062 --> 00:16:38,614
publish data in and out. In this case, we're using it to simulate tweet

261
00:16:38,662 --> 00:16:42,786
data, primarily because the tweet API is now locked

262
00:16:42,838 --> 00:16:45,886
down. And after a thousand tweets, you're sort of out

263
00:16:45,908 --> 00:16:49,198
of luck for an entire month for testing. We want

264
00:16:49,284 --> 00:16:52,802
many more tweets than that. So I wrote this little class

265
00:16:52,856 --> 00:16:57,106
instead to generate data into that particular topic to feed our

266
00:16:57,208 --> 00:16:58,900
sentiment analysis function.

267
00:17:00,310 --> 00:17:03,778
This tweet source here reads data from a

268
00:17:03,784 --> 00:17:07,442
local file, just created some random text, some sentences that come in,

269
00:17:07,576 --> 00:17:11,350
some random data that will be passed through, and then we'll perform

270
00:17:11,500 --> 00:17:15,174
analysis on that. So that's really it.

271
00:17:15,212 --> 00:17:17,960
That's where the code is. And this can easily be built.

272
00:17:18,410 --> 00:17:22,902
If you go to your terminal and you run maven clean package,

273
00:17:23,046 --> 00:17:27,338
it will generate NAR files for both the tweet source and

274
00:17:27,504 --> 00:17:31,098
the sentiment analysis function, which we will use for deployment in a

275
00:17:31,104 --> 00:17:34,894
minute. Also want to note that as

276
00:17:34,932 --> 00:17:38,990
part of this particular project, we have a pulsar function,

277
00:17:39,140 --> 00:17:41,998
or pulsar cluster rather, that you want to run locally and can be started with

278
00:17:42,004 --> 00:17:45,566
the start brokers command, which is what we will use down here.

279
00:17:45,748 --> 00:17:49,026
We'll notice that we're already in that particular bin folder, so I'll go ahead

280
00:17:49,048 --> 00:17:52,818
and start the brokers now. So we have a pulsar cluster to

281
00:17:52,824 --> 00:17:56,606
test against locally. Makes it very useful. It's self contained,

282
00:17:56,798 --> 00:18:01,190
and I want to note here that I have specifically used the version 293

283
00:18:01,260 --> 00:18:04,934
of pulsar. And I've used a little bit of a trick to

284
00:18:05,132 --> 00:18:08,934
map the volumes, these internal volumes, to where these nars are being built to.

285
00:18:08,972 --> 00:18:12,774
You can see to the target directory here. I'm mapping it to a file

286
00:18:12,822 --> 00:18:16,790
system on the pulsar cluster,

287
00:18:16,950 --> 00:18:19,834
which is going to make it easier to deploy these using the command line tool

288
00:18:19,872 --> 00:18:23,662
in a second. So I did it once for the source and again

289
00:18:23,796 --> 00:18:27,338
for the analysis function as well. Also note

290
00:18:27,354 --> 00:18:30,890
that you want to make sure that you enable the function worker.

291
00:18:31,050 --> 00:18:34,426
By default, it is disabled in the pulsar standalone.

292
00:18:34,458 --> 00:18:37,762
So you can do that by adding this particular setting and making

293
00:18:37,816 --> 00:18:41,662
sure that you do not have the NFW switch.

294
00:18:41,726 --> 00:18:45,154
A lot of times that's there, and that means no function worker that

295
00:18:45,192 --> 00:18:48,626
disables it. So make sure that that is turned off. Once you've

296
00:18:48,658 --> 00:18:52,166
done that, you should have a pulsar cluster up

297
00:18:52,188 --> 00:18:55,494
and running. Let's verify. Let's look at this

298
00:18:55,532 --> 00:18:58,898
docker logs pulsar f

299
00:18:59,084 --> 00:19:03,034
and we can see it started, it's up and running. Everything is

300
00:19:03,072 --> 00:19:06,730
great. We're going to use this to monitor the progress

301
00:19:07,070 --> 00:19:10,586
of our system. So now let's pivot and

302
00:19:10,608 --> 00:19:13,806
start generating the source data. So as you can

303
00:19:13,828 --> 00:19:17,726
see here, I've already copied and pasted in the command to do it. There is

304
00:19:17,748 --> 00:19:21,498
a command line tool in the pulsar admin called source,

305
00:19:21,674 --> 00:19:25,646
and it has lots of different methods, the first of which is create. And then

306
00:19:25,668 --> 00:19:29,118
you can specify the name of what you want to name that particular source.

307
00:19:29,214 --> 00:19:33,246
And then you specify the archive file or the artifact

308
00:19:33,278 --> 00:19:36,782
that contains the source data. In this case, it's the NAR file that we generated

309
00:19:36,926 --> 00:19:41,254
and specify a destination topic. Where do I want this data to publish to?

310
00:19:41,452 --> 00:19:45,574
So we'll go ahead and execute that and

311
00:19:45,612 --> 00:19:47,846
look at the log here. And we should see it coming in so we can

312
00:19:47,868 --> 00:19:51,274
see that it got received. The tweet simulator came

313
00:19:51,312 --> 00:19:55,126
in. It's being unpacked, the metadata

314
00:19:55,238 --> 00:19:58,794
is coming out. It has some information on how it was deployed. It was

315
00:19:58,832 --> 00:20:02,478
a source, the NAR file was deployed. So if you want

316
00:20:02,484 --> 00:20:06,126
to get down at the details, you can check these things. If there's any issues,

317
00:20:06,308 --> 00:20:19,708
check your log on

318
00:20:19,714 --> 00:20:23,020
that source. We can verify that it was deployed as we wanted.

319
00:20:23,090 --> 00:20:26,380
We can see the configuration values here. Everything looks

320
00:20:26,450 --> 00:20:29,856
correct. We can also check the

321
00:20:29,878 --> 00:20:33,744
status. Right? So let's check the status of

322
00:20:33,782 --> 00:20:36,610
our source just to make sure that we're generating some data.

323
00:20:38,340 --> 00:20:41,270
And it's been executed 17 times already.

324
00:20:41,880 --> 00:20:45,236
So we can come over here and we

325
00:20:45,258 --> 00:20:48,644
can consume from the tweets in. So this particular source is

326
00:20:48,682 --> 00:20:51,030
publishing again, as we saw,

327
00:20:51,900 --> 00:20:56,228
to the tweets in topic. So let's consume.

328
00:20:56,324 --> 00:20:59,844
This is another command we can run in a separate window, create a pulsar client

329
00:20:59,892 --> 00:21:03,800
to consume. N zero means consume indefinitely.

330
00:21:04,220 --> 00:21:07,780
Give it a unique subscription name and the topic name, which is going

331
00:21:07,790 --> 00:21:11,324
to match to where we're publishing the data. And let's verify that the data

332
00:21:11,362 --> 00:21:14,956
is coming in. We're going to see some startup information

333
00:21:15,058 --> 00:21:18,464
here about the kind of connection, but then shortly we'll start

334
00:21:18,502 --> 00:21:22,636
seeing the tweets coming in one by one, data coming from that raw

335
00:21:22,748 --> 00:21:24,690
text file one at a time.

336
00:21:25,380 --> 00:21:27,330
So the source is working.

337
00:21:28,180 --> 00:21:32,516
Now let's pivot and start creating the

338
00:21:32,698 --> 00:21:36,470
pulsar sentiment analysis function.

339
00:21:37,080 --> 00:21:40,836
So I have left in the code itself a

340
00:21:40,858 --> 00:21:44,950
method that encapsulates all this. We don't want to type it

341
00:21:45,640 --> 00:21:49,896
from memory like I don't, so we'll go ahead and use this to

342
00:21:49,918 --> 00:21:52,584
recreate it. I want to break this down a little bit though. So again,

343
00:21:52,622 --> 00:21:55,596
we're executing a command inside pulsar itself,

344
00:21:55,778 --> 00:21:59,596
and inside pulsar there's an admin tool and

345
00:21:59,618 --> 00:22:03,464
a function subcommand, and we tell it to create a new pulsar

346
00:22:03,512 --> 00:22:07,340
function. We specify with a dash jar that where

347
00:22:07,490 --> 00:22:11,356
the entire artifact is to deploy, which is the sentiment analysis nar file.

348
00:22:11,388 --> 00:22:15,596
We just created the class name of the sentiment analysis

349
00:22:15,628 --> 00:22:18,960
function itself, so again, it's the full package name.

350
00:22:19,110 --> 00:22:22,252
This is the class we want it to run. The input

351
00:22:22,316 --> 00:22:26,230
parameters are going to be this tweets input topic here that data is coming into,

352
00:22:26,680 --> 00:22:29,760
and for our output we're going to publish it to a different topic.

353
00:22:29,840 --> 00:22:33,348
Default tweets out. And last but not least, if you want

354
00:22:33,354 --> 00:22:37,384
to, you can specify a log topic as well for informational data there,

355
00:22:37,422 --> 00:22:39,450
but that's really all we need.

356
00:22:40,140 --> 00:22:43,736
This should work correctly. If everything goes correctly, you see

357
00:22:43,758 --> 00:22:47,256
a command created successfully. Again, you'll see things in the log file

358
00:22:47,288 --> 00:22:50,428
coming in, letting you know that

359
00:22:50,434 --> 00:22:53,704
it was successfully received, how it was configured, the tenant

360
00:22:53,752 --> 00:22:57,468
namespace and name class. Everything else should match what you want. You can

361
00:22:57,474 --> 00:23:00,816
quickly verify this as well. Everything's up

362
00:23:00,838 --> 00:23:03,644
and running. If you have any sort of errors, and it would be first noted

363
00:23:03,692 --> 00:23:06,944
here. If you want to

364
00:23:06,982 --> 00:23:10,356
also check on the status and get

365
00:23:10,378 --> 00:23:13,030
the configuration details at any point in the future,

366
00:23:14,040 --> 00:23:18,310
we can copy this real quick.

367
00:23:21,080 --> 00:23:24,116
Run the command here and it should spit

368
00:23:24,148 --> 00:23:27,850
back out the configuration details that we sent in,

369
00:23:30,460 --> 00:23:33,876
again, verifying it was deployed as we see fit. If you want to update

370
00:23:33,908 --> 00:23:36,780
these, if you want to change the output topic,

371
00:23:37,120 --> 00:23:40,830
change the parallelism, things like that, you can change the behavior later,

372
00:23:41,280 --> 00:23:43,790
but it looks like everything is up and running.

373
00:23:44,560 --> 00:23:49,072
So now let's go and see what the output looks

374
00:23:49,126 --> 00:23:51,852
like. So again, as we saw earlier,

375
00:23:51,996 --> 00:23:56,384
it's writing as an output to tweets out, public default tweets out.

376
00:23:56,582 --> 00:24:00,016
So we are going to consume from that same topic over here

377
00:24:00,038 --> 00:24:03,652
in a separate consumer and see this again, there's still the tweets coming in.

378
00:24:03,706 --> 00:24:06,836
So let's see how our machine learning model is working. Is it

379
00:24:06,858 --> 00:24:09,940
getting the information? Is it processing it correctly?

380
00:24:10,440 --> 00:24:13,804
We'll start up here shortly. Again, you see some connection details

381
00:24:13,952 --> 00:24:17,636
coming in and sure enough, you're starting to see here was the original

382
00:24:17,668 --> 00:24:20,680
tweet and it was assigned a sentiment of neutral.

383
00:24:21,420 --> 00:24:23,880
The next one comes in, everyone was curious,

384
00:24:24,460 --> 00:24:27,524
positive, et cetera.

385
00:24:27,572 --> 00:24:30,796
So it starts coming in, it matches. We can get the most recent data and

386
00:24:30,818 --> 00:24:34,236
we're doing some analysis on it. So it's event driven in that regard. As soon

387
00:24:34,258 --> 00:24:37,824
as something comes in, an analysis is done on it

388
00:24:37,862 --> 00:24:41,056
and it's published out. And so you can

389
00:24:41,078 --> 00:24:43,810
see that this is moving and it's going to work in tandem for a while

390
00:24:44,580 --> 00:24:47,090
and that's not a problem.

391
00:24:48,900 --> 00:24:52,804
If you want to check the performance and how long the

392
00:24:52,842 --> 00:24:56,928
processing of each one of these tweets takes, you can use the stats

393
00:24:57,104 --> 00:25:00,864
command, which is going to give you some average processing

394
00:25:00,912 --> 00:25:05,224
latency. This is the average, obviously, processing time

395
00:25:05,342 --> 00:25:09,064
of each tweet. It's going to tell you how many tweets have been

396
00:25:09,102 --> 00:25:13,364
processed, how many over the lifetime of the tweet

397
00:25:13,412 --> 00:25:17,176
itself, and things like that. So lots

398
00:25:17,208 --> 00:25:20,364
of information is available. As you can see here,

399
00:25:20,562 --> 00:25:24,060
everything is working just fine as expected.

400
00:25:34,240 --> 00:25:37,936
So in summary, event driven microservices use a message bus to

401
00:25:37,958 --> 00:25:41,936
communicate between themselves and Pulsar is a cloud native distributed

402
00:25:41,968 --> 00:25:46,048
messaging and event streaming platform that provides the pub subsmantics

403
00:25:46,144 --> 00:25:49,200
that an event driven architecture needs. Furthermore,

404
00:25:49,280 --> 00:25:52,880
Pulsar includes a native lightweight compute capability

405
00:25:52,960 --> 00:25:56,504
called Pulsar functions that allows you to build microservices with

406
00:25:56,542 --> 00:25:59,464
just a few lines of code. And as I've shown you,

407
00:25:59,502 --> 00:26:03,508
you can easily add third party machine learning libraries into your pulsar functions

408
00:26:03,604 --> 00:26:06,920
to enhance your microservices with machine learning capabilities.

409
00:26:07,420 --> 00:26:10,472
Thank you for attending my talk. Let's keep in touch.

410
00:26:10,606 --> 00:26:14,152
Scan the query code for my personal page,

411
00:26:14,286 --> 00:26:17,856
follow me on Twitter, reach out to me on LinkedIn and go get the

412
00:26:17,878 --> 00:26:20,510
source code from my GitHub repo. Again, thank you very much.

