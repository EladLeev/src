1
00:00:00,410 --> 00:00:04,282
I'm Vilas. I am a director of engineering at Walmart.

2
00:00:04,426 --> 00:00:08,142
I focus on enabling developers to deploy their code

3
00:00:08,196 --> 00:00:11,486
in a resilient, performant way into the

4
00:00:11,508 --> 00:00:14,894
cloud of their choice. That's what I focus on. What I'm going to talk about

5
00:00:14,932 --> 00:00:18,714
today is a little bit about what we saw in our journey

6
00:00:18,762 --> 00:00:23,434
towards becoming more resilient as a software

7
00:00:23,482 --> 00:00:27,138
company and what were the challenges we faced, what are the mistakes

8
00:00:27,154 --> 00:00:30,360
we made and all of that stuff. So before I go there,

9
00:00:30,890 --> 00:00:34,086
obviously everyone in the room knows what this is.

10
00:00:34,108 --> 00:00:37,350
I'm not going to repeat, everyone else is going to talk about this.

11
00:00:37,500 --> 00:00:41,814
Suffice to say, the way we looked at this was we realized the importance

12
00:00:41,862 --> 00:00:45,450
of this at Walmart, but we also realized that to

13
00:00:45,520 --> 00:00:48,746
execute something like this at Walmart scale was going to be

14
00:00:48,768 --> 00:00:52,190
a huge challenge. Right. What is Walmart scale?

15
00:00:53,170 --> 00:00:56,750
These are some numbers. We have more than 11,000

16
00:00:56,820 --> 00:01:00,378
stores worldwide that get supply of software

17
00:01:00,554 --> 00:01:03,918
that actually does everything in the store. All of the management on

18
00:01:03,924 --> 00:01:07,570
the supply chaos side, all of the retail business is managed by software.

19
00:01:08,470 --> 00:01:11,714
The annual revenue of all of this combined is more

20
00:01:11,752 --> 00:01:15,778
than half a trillion, which explains to the amount of goods that

21
00:01:15,784 --> 00:01:19,174
are moved across the world for it. Right. That number,

22
00:01:19,212 --> 00:01:23,382
270,000,000, is the number of folks who transact on

23
00:01:23,516 --> 00:01:27,526
our omni services, which means including the website, including the

24
00:01:27,628 --> 00:01:31,740
stores in a week. So that's the amount of foot traffic or

25
00:01:32,430 --> 00:01:36,438
transactions that we see in a week. So if you think about scales

26
00:01:36,454 --> 00:01:39,978
like that, any kind of disruption could cause

27
00:01:40,064 --> 00:01:43,726
a massive amount of damage. So that is something that we wanted to sort of

28
00:01:43,748 --> 00:01:47,146
think about when we even thought about doing this kind of journey

29
00:01:47,178 --> 00:01:50,030
at Walmart. So to begin,

30
00:01:50,100 --> 00:01:53,554
initially, we had to establish some truths, right? So we said,

31
00:01:53,592 --> 00:01:56,420
okay, the following things are true. One,

32
00:01:57,270 --> 00:02:02,174
reliability is no longer just a function of redundancy

33
00:02:02,222 --> 00:02:05,826
and overscaled hardware, right? So we are not going to just throw some servers at

34
00:02:05,848 --> 00:02:08,738
it and we'll obviously fix the problem.

35
00:02:08,824 --> 00:02:12,326
That's no longer the case. Specifically the way

36
00:02:12,348 --> 00:02:15,874
that we were thinking about it. We wanted to exist in a hybrid cloud environment.

37
00:02:16,002 --> 00:02:19,874
If we wanted to do that, we have to acknowledge that external cloud providers,

38
00:02:19,922 --> 00:02:23,302
no matter how much their guarantees could be, they are still a dependency,

39
00:02:23,366 --> 00:02:27,290
a variable. And if something bad happens, we still have to be ready and

40
00:02:27,440 --> 00:02:30,300
resolve essentially what the customers needs are.

41
00:02:31,310 --> 00:02:34,766
Customers expect, do not

42
00:02:34,788 --> 00:02:38,526
like the idea of scheduled downtimes, right. There was a time when that used

43
00:02:38,548 --> 00:02:42,574
to happen. This is no longer the truth anymore, which means customers expect

44
00:02:42,612 --> 00:02:46,226
you to be on all the time, have the best service,

45
00:02:46,328 --> 00:02:50,094
doesn't matter how many parallel connections are open, how many parallel

46
00:02:50,142 --> 00:02:53,490
transactions are running. They want everything to be just

47
00:02:53,640 --> 00:02:57,506
as smooth as it's running at peak as it is running at non

48
00:02:57,538 --> 00:03:01,266
break hours. Right. Any user that's actually performing

49
00:03:01,298 --> 00:03:04,982
any transaction on the entire service does not

50
00:03:05,116 --> 00:03:09,282
expect any loss of behavior.

51
00:03:09,346 --> 00:03:12,634
Essentially like, your cart is not available, your items are not available, they want

52
00:03:12,672 --> 00:03:15,642
it all the time. And that's the expectation. And that's not wrong.

53
00:03:15,696 --> 00:03:17,900
That's how our customers are today.

54
00:03:18,750 --> 00:03:22,730
And a direct correlation from that is the users could lose trust

55
00:03:22,880 --> 00:03:26,126
on a brand because of a single moment

56
00:03:26,228 --> 00:03:29,822
of a bad experience, a glitch, something bad happening in the back end.

57
00:03:29,876 --> 00:03:33,166
Right? That loss could be temporary, which means they feel, oh, yeah, this is not

58
00:03:33,188 --> 00:03:36,366
a good place for me right now, and I'll go back and come back later.

59
00:03:36,548 --> 00:03:39,934
Or they could be like, lifetime, this is it. I don't trust this brand

60
00:03:39,982 --> 00:03:43,282
at all. And they could communicate that to their families. You could lose their entire

61
00:03:43,336 --> 00:03:46,706
business for their entire lifetime. Right. These are pretty big numbers that we had to

62
00:03:46,728 --> 00:03:49,926
consider. So these are truths. We held them as truths. And using this, we said,

63
00:03:49,948 --> 00:03:53,238
okay, fine. So what is the goal? So obviously you will see a

64
00:03:53,244 --> 00:03:56,594
lot of connections to the principles of chaos engineering directly.

65
00:03:56,642 --> 00:04:00,546
But this was our goal to maintain an application ecosystem

66
00:04:00,578 --> 00:04:04,138
where if there are failures in infrastructure and dependencies, they cause

67
00:04:04,224 --> 00:04:08,330
minimal disruption to the end user experience. And what is minimal disruption

68
00:04:08,830 --> 00:04:12,862
is something that we sort of defined over time. We refined it from being

69
00:04:12,916 --> 00:04:16,298
a very macro level, very sort of amorphous

70
00:04:16,474 --> 00:04:19,598
detail to making it more and more fine grained over time.

71
00:04:19,684 --> 00:04:23,406
Right? So the

72
00:04:23,428 --> 00:04:27,986
first thing that we started talking about is, how do we inculcate the idea of

73
00:04:28,088 --> 00:04:31,426
running a chaos exercise? Right? So we said, fine, let's talk

74
00:04:31,448 --> 00:04:35,070
to them about an outage. You had an outage.

75
00:04:35,230 --> 00:04:38,470
There was probably a lot of things going wrong. How did you manage

76
00:04:38,540 --> 00:04:42,118
it? So we realized that by talking about it. We realized that

77
00:04:42,284 --> 00:04:46,114
every outage was essentially a chaos exercise that was completely unintentional,

78
00:04:46,162 --> 00:04:49,350
but was happening nonetheless and was causing people to be reactive.

79
00:04:49,850 --> 00:04:53,962
It was exposing gaps in our systems. It was exposing things where we

80
00:04:54,016 --> 00:04:57,750
were not as good as we could be. Obviously, the revenue impact

81
00:04:57,830 --> 00:05:00,966
could be huge, but essentially this entire thing constituted

82
00:05:00,998 --> 00:05:04,926
a chaos exercise. So you were sort of in that mode already.

83
00:05:05,108 --> 00:05:08,634
The only idea was to say, let's not have it unintentionally.

84
00:05:08,682 --> 00:05:11,358
Let's prepare for this from the start.

85
00:05:11,444 --> 00:05:15,486
Right? Obviously, the measure of all

86
00:05:15,508 --> 00:05:18,658
of these exercises that we did at the start was we said, okay, we want

87
00:05:18,664 --> 00:05:22,194
to calculate what the downtime looks like. Right? So we wanted to calculate a

88
00:05:22,232 --> 00:05:25,906
per incident cost. Any incident that happens, we want to calculate exactly how

89
00:05:25,928 --> 00:05:29,142
much it costs the company. We want to break it down by

90
00:05:29,196 --> 00:05:33,254
quarter and see trends, find exactly where we are

91
00:05:33,452 --> 00:05:36,854
super efficient, where we are not. And then we wanted to track

92
00:05:36,892 --> 00:05:40,162
this and find sort of a path, essentially,

93
00:05:40,226 --> 00:05:43,594
right. We want to plan better a culture of software resilience. Instead of saying,

94
00:05:43,632 --> 00:05:46,060
yeah, just fix this for now and it'll be fine.

95
00:05:47,630 --> 00:05:51,178
So when we started doing calculations for an incident. So this should

96
00:05:51,184 --> 00:05:54,174
be familiar with anyone who's dealt with incidents, there is a path, right?

97
00:05:54,212 --> 00:05:57,680
You identify the incident, you page out,

98
00:05:58,050 --> 00:06:01,806
there is an on call that receives it, they file an issue, or maybe your

99
00:06:01,828 --> 00:06:04,974
l one supports file an issue. There is some

100
00:06:05,012 --> 00:06:08,306
logging that also is sending out some alerts. There is

101
00:06:08,328 --> 00:06:11,810
initial triage with the folks who are on call. They try out some stuff.

102
00:06:11,880 --> 00:06:15,540
They figure out exactly what the playbooks look like. They will try some things out.

103
00:06:16,070 --> 00:06:19,726
If that doesn't work, you will assign this to a subject matter expert

104
00:06:19,758 --> 00:06:23,266
for a fix that could take some time. You could escalate if necessary.

105
00:06:23,458 --> 00:06:26,162
Finally, you would resolve it, you would close it. If you find a bug,

106
00:06:26,226 --> 00:06:29,126
you would deploy it, or you would do a hot deploy. Or if there is

107
00:06:29,148 --> 00:06:32,730
something that requires you to rearchitect something because fundamentally something is wrong,

108
00:06:32,800 --> 00:06:36,266
then you would write that feature in and then you would release it.

109
00:06:36,288 --> 00:06:39,580
Right. This is expensive if you look at it.

110
00:06:40,190 --> 00:06:43,946
We want to try and solve problems or reduce the costs in

111
00:06:43,968 --> 00:06:47,098
such a way that we want to stop it at that third block.

112
00:06:47,194 --> 00:06:50,174
We want to stop it right. Where there is initial triage, we want to have

113
00:06:50,212 --> 00:06:53,534
enough experience for that on call person, enough information for that on call

114
00:06:53,572 --> 00:06:57,178
person to be able to solve it at that third level. Right? So this is

115
00:06:57,204 --> 00:06:59,986
what we called an incident cost, and this is what we calculated for all of

116
00:07:00,008 --> 00:07:03,922
the incidents that we had. So once we had done this

117
00:07:04,056 --> 00:07:06,818
as the initial step, we still had a long way to go because we had

118
00:07:06,824 --> 00:07:10,166
to do a lot of homework. The teams that were running

119
00:07:10,188 --> 00:07:13,878
this had to do some homework. Right? And this

120
00:07:13,884 --> 00:07:17,174
is where I would start talking about how others could

121
00:07:17,212 --> 00:07:20,026
also institute this in your companies. Right.

122
00:07:20,208 --> 00:07:23,546
The homework that is needed is very generic. Everyone who's trying to

123
00:07:23,568 --> 00:07:27,434
run chaos exercises should be doing this. First is

124
00:07:27,472 --> 00:07:30,714
observability. This is a non negotiable. If you

125
00:07:30,752 --> 00:07:33,866
do not know how your system can.

126
00:07:33,968 --> 00:07:37,646
How. How can you sort of keep a pulse on the system and understand if

127
00:07:37,668 --> 00:07:41,214
something goes wrong and identify it in a certain

128
00:07:41,332 --> 00:07:44,710
specific kind of period, then you are not observable,

129
00:07:44,810 --> 00:07:48,594
right? So obviously everyone relies on logging. There's a lot of ways

130
00:07:48,632 --> 00:07:52,238
to do logging. We have splunk dashboards, cabana dashboards,

131
00:07:52,254 --> 00:07:55,698
things like that. But that's not enough. That's only solving part of the

132
00:07:55,704 --> 00:07:58,866
proposal. Right? You need to have intelligent second level metrics

133
00:07:58,898 --> 00:08:02,274
to figure out exactly what challenges, right? You want those deltas,

134
00:08:02,322 --> 00:08:05,750
you want those trends and the changes. You obviously

135
00:08:05,820 --> 00:08:09,446
need alert setup. But I would say the last thing is

136
00:08:09,468 --> 00:08:13,434
important, right? So if an on call engineer, the measure is if at

137
00:08:13,472 --> 00:08:17,082
any team that you run, can an on call engineer who gets

138
00:08:17,136 --> 00:08:21,182
on call for an incident resolve an issue successfully within

139
00:08:21,236 --> 00:08:24,842
the SLA of a p one, right? Typically, the slas for p one resolutions

140
00:08:24,906 --> 00:08:28,794
are short of acknowledgment, incident resolution.

141
00:08:28,922 --> 00:08:32,426
If that person can essentially find the issue root,

142
00:08:32,458 --> 00:08:35,970
cause it to a successful degree, and then

143
00:08:36,120 --> 00:08:39,154
push in a fix within that time, that, to me,

144
00:08:39,192 --> 00:08:42,546
indicates that there is significantly good observability in the

145
00:08:42,568 --> 00:08:45,890
system. Right? Of course, it's not perfect.

146
00:08:45,960 --> 00:08:49,414
I'm sure there is better ways to measure this, but this is something that I

147
00:08:49,452 --> 00:08:52,550
think gives us a good measure of how the system

148
00:08:52,620 --> 00:08:56,134
works. The other

149
00:08:56,172 --> 00:09:00,306
on call prerequisites is imagine

150
00:09:00,338 --> 00:09:03,066
if you're an on call, and if you have a team has an on call

151
00:09:03,088 --> 00:09:06,186
and they wake up in the middle of the night. Let's say they wake up

152
00:09:06,208 --> 00:09:10,170
at 02:00 a.m. And they're on a call with the VP and

153
00:09:10,320 --> 00:09:13,770
the CTO, and they're like they're losing millions every second.

154
00:09:13,840 --> 00:09:17,326
How can we fix this? Right? At that point, you do not want them

155
00:09:17,348 --> 00:09:21,466
stumbling to try out things. You want them to have a specific playbook

156
00:09:21,578 --> 00:09:24,894
for all of the issues that can go wrong, right? So you need to have

157
00:09:24,932 --> 00:09:28,942
a disaster recovery playbook, and you need to have this playbook well tested.

158
00:09:29,086 --> 00:09:32,466
Having a playbook is not the answer. Testing a playbook continuously is

159
00:09:32,488 --> 00:09:36,974
the answer. Right. You need to make sure that for every application or every microservice,

160
00:09:37,102 --> 00:09:40,962
the way you define it needs to define its own critical dependencies.

161
00:09:41,026 --> 00:09:45,318
Like what are the dependencies which, when go down, impact the application

162
00:09:45,404 --> 00:09:48,518
to a degree where it's not functional, it cannot do its job.

163
00:09:48,604 --> 00:09:52,086
Those are critical dependencies, right. For every critical dependency failure,

164
00:09:52,118 --> 00:09:55,626
there needs to be a detailed playbook or an automated way to

165
00:09:55,648 --> 00:09:58,986
have fallbacks instituted whenever the critical dependency is

166
00:09:59,008 --> 00:10:02,286
not available. Non critical dependencies also have to be

167
00:10:02,308 --> 00:10:06,126
defined, right? It's possible that you are sending off to

168
00:10:06,148 --> 00:10:09,200
a log that's like asynchronously sent to another service,

169
00:10:09,570 --> 00:10:12,686
but it's possible that initially the failure may not

170
00:10:12,708 --> 00:10:16,334
affect you, but over time, accumulation of those logs may

171
00:10:16,372 --> 00:10:19,570
impact you in some way. Right. Maybe the space on your system

172
00:10:19,640 --> 00:10:22,738
is being eaten up and eventually run out of disk space. Right.

173
00:10:22,904 --> 00:10:26,606
That kind of non critical dependency needs to be defined along with the thresholds

174
00:10:26,638 --> 00:10:30,086
of when that non critical dependency will start impacting a service.

175
00:10:30,188 --> 00:10:33,894
Right. If you have this, then an oncology engineer, even in the middle

176
00:10:33,932 --> 00:10:36,870
of the night on a call with a high pressure situation,

177
00:10:37,020 --> 00:10:40,086
will be able to navigate this in a systematic way.

178
00:10:40,188 --> 00:10:43,426
So that's what we think is required homework.

179
00:10:43,538 --> 00:10:46,714
Because we realized that anyone who sort of solves goes through this

180
00:10:46,752 --> 00:10:50,842
exercise, realizes a lot of gaps in the system automatically, even without running

181
00:10:50,896 --> 00:10:54,380
a chaos exercise, right. This reveals a lot of gaps in the system.

182
00:10:55,490 --> 00:10:58,958
So these are the two sort of key homeworks. I would say if you do

183
00:10:58,964 --> 00:11:02,382
not have observability and you do not have these prerequisites, you will not be

184
00:11:02,436 --> 00:11:05,390
able to get the most out of a chaos exercise.

185
00:11:06,130 --> 00:11:09,346
The other thing I would say is there needs to be a way for you

186
00:11:09,368 --> 00:11:12,962
to be able to understand your production load, what it looks like,

187
00:11:13,016 --> 00:11:16,280
and be able to generate it in a sensible way. Right.

188
00:11:16,970 --> 00:11:20,200
This is crucial for two reasons. One,

189
00:11:20,730 --> 00:11:24,706
you do not ever want to run in prod

190
00:11:24,818 --> 00:11:28,486
unless you really are confident. So you have to always have

191
00:11:28,508 --> 00:11:32,426
a do no harm approach. Right. You cannot knowingly cause harm to

192
00:11:32,448 --> 00:11:35,974
prod, so you want to know how to do this in a pre prod environment,

193
00:11:36,022 --> 00:11:39,450
but using prod traffic so you can be confident of the results.

194
00:11:40,030 --> 00:11:44,054
There is no point of running failure injection tests if you can't really verify

195
00:11:44,182 --> 00:11:47,066
what will happen if there is a failure and what happens to prod traffic.

196
00:11:47,098 --> 00:11:50,254
Right? And you want to try and do that as much as possible early enough

197
00:11:50,292 --> 00:11:53,242
in the cycle, so that you're not causing the company expense.

198
00:11:53,386 --> 00:11:56,898
By all means, if you're confident, you should be pushing your testing to prod as

199
00:11:56,904 --> 00:11:59,906
well. But if you're not mature enough, this is something that's important,

200
00:12:00,088 --> 00:12:03,300
right? The build or buy question.

201
00:12:03,830 --> 00:12:07,374
This is something that I think has been answered by lots of folks

202
00:12:07,422 --> 00:12:11,350
that have more knowledge about this than me. I don't think there is any preference.

203
00:12:12,650 --> 00:12:16,322
If you have a system that can generate production like road internally,

204
00:12:16,386 --> 00:12:19,606
that's great. If you have proprietary needs to do that, that's fine. But there is

205
00:12:19,628 --> 00:12:22,810
also buy options which other teams and other companies have used.

206
00:12:22,880 --> 00:12:26,394
Right? So I don't have a say in that, but that is something that has

207
00:12:26,432 --> 00:12:31,338
been debated. I don't have a say in that much anyway,

208
00:12:31,424 --> 00:12:34,986
so the other thing I would say needs investment is a CI

209
00:12:35,018 --> 00:12:38,446
CD workflow, right? The diagram that I

210
00:12:38,468 --> 00:12:42,334
have on the screen essentially demonstrates what a real CI CD pipeline looks

211
00:12:42,372 --> 00:12:46,090
like in this day and age. There is a lot of automation.

212
00:12:46,250 --> 00:12:49,538
You'll notice some of the stuff is very familiar to you, right? Which is plan,

213
00:12:49,624 --> 00:12:53,106
code, build, test and deploy. Right. In between there

214
00:12:53,128 --> 00:12:56,386
is a profile stage, right? A profile could be something like run a

215
00:12:56,408 --> 00:12:59,606
performance test, find out exactly how much utilization I've been

216
00:12:59,628 --> 00:13:03,462
using, recommend the best solution for me to exist in.

217
00:13:03,516 --> 00:13:07,250
Like give me the right kind of cpu and memory allocations for my Kubernetes pods.

218
00:13:07,330 --> 00:13:10,886
It could be give me the right kind of flavor for my vms on Azure,

219
00:13:10,998 --> 00:13:14,314
whatever those are, right. That essentially has now come part

220
00:13:14,352 --> 00:13:18,300
of the CI CD cycle. And having that enables you to

221
00:13:18,670 --> 00:13:22,618
solve a lot of these reliability issues way earlier in

222
00:13:22,624 --> 00:13:26,998
the pipeline, rather than wait for some signal to come out of production.

223
00:13:27,094 --> 00:13:30,382
You will also notice there is two key things here, which is

224
00:13:30,516 --> 00:13:33,758
there is a multi cloud environment. So hybrid cloud, I obviously represented that.

225
00:13:33,844 --> 00:13:37,182
But there is two things. Inference layer, right? The inference layer is essentially

226
00:13:37,246 --> 00:13:41,518
a back channel out from prod coming into the pipeline,

227
00:13:41,534 --> 00:13:45,026
the CI CD pipeline. This is something where I say observability is important.

228
00:13:45,128 --> 00:13:49,458
If you have an observable system, you can read what's happening in production

229
00:13:49,554 --> 00:13:52,694
and then feed that back into to make your code do

230
00:13:52,732 --> 00:13:56,502
better, right? The other thing you'll see is a decision engine that's between

231
00:13:56,556 --> 00:14:00,042
the CI CD pipeline and the clouds. This is something

232
00:14:00,096 --> 00:14:03,802
that many teams have started investing in, many big companies

233
00:14:03,856 --> 00:14:07,290
have started investing in, which is figuring out what's the best

234
00:14:07,360 --> 00:14:10,646
kind of cloud configuration,

235
00:14:10,678 --> 00:14:14,334
if you will, for my application. Would it be better on

236
00:14:14,372 --> 00:14:17,486
prem because it has latency restrictions? Would it

237
00:14:17,508 --> 00:14:21,306
be better on a certain kind of cloud provider? Because certain kind of cloud provider

238
00:14:21,338 --> 00:14:25,514
provides a certain kind of platform service? These decisions

239
00:14:25,562 --> 00:14:29,058
have now started to get automated, right? And you'll see more of this coming in

240
00:14:29,064 --> 00:14:32,914
the years. But this is an investment that I feel enables you to

241
00:14:32,952 --> 00:14:34,930
have a better system in production.

242
00:14:36,950 --> 00:14:40,738
Building a maturity model. So we did this at Walmart.

243
00:14:40,914 --> 00:14:44,658
We did not allow teams to just go come in and run chaos engineering tests,

244
00:14:44,674 --> 00:14:48,214
right? We have a detailed maturity model from level one of

245
00:14:48,252 --> 00:14:51,958
maturity to level five, with requirements at each level. And this is all detailed

246
00:14:51,974 --> 00:14:55,130
in that blog post. It talks about

247
00:14:55,200 --> 00:14:59,066
how as a team, you can enable yourself to grow from one level to

248
00:14:59,088 --> 00:15:02,670
another. And that also enables the team to become more and more confident.

249
00:15:03,490 --> 00:15:07,242
It enables management to be more confident on the team running these exercises.

250
00:15:07,386 --> 00:15:10,400
So that maturity model I have seen, it really helps. Right.

251
00:15:11,570 --> 00:15:15,134
What happens essentially, because of that maturity model, is that over time,

252
00:15:15,252 --> 00:15:18,180
as you go from red, which is level one, to green,

253
00:15:18,550 --> 00:15:22,162
at level five, the support costs go down. Right.

254
00:15:22,296 --> 00:15:25,618
What also happens is that the revenue lost per second, per minute, however you

255
00:15:25,624 --> 00:15:29,080
calculate it also goes down, the resiliency obviously shoots up.

256
00:15:30,250 --> 00:15:33,334
At level one, I would say the support costs could be in the five

257
00:15:33,372 --> 00:15:37,254
digit number, five digit dollar number per minute, whereas at

258
00:15:37,292 --> 00:15:40,722
level five, you're probably looking at a few hundred dollars per minute. Right. So imagine

259
00:15:40,786 --> 00:15:44,394
a couple of engineers working on observability systems and just getting

260
00:15:44,432 --> 00:15:47,578
all the answers at level five because they have everything in place, whereas a

261
00:15:47,584 --> 00:15:50,346
whole bunch of team of engineers trying to figure out what do I do next

262
00:15:50,368 --> 00:15:54,106
and what do I shut down to solve this? The other

263
00:15:54,128 --> 00:15:57,454
thing is build the right tools. So we invested a lot of time in making

264
00:15:57,492 --> 00:16:01,114
sure that we have the right tools to enable our teams to run the resiliency

265
00:16:01,162 --> 00:16:04,094
test. One of the tools that we did invest in is resiliency,

266
00:16:04,142 --> 00:16:07,570
doctor. You can read all about it in the

267
00:16:07,640 --> 00:16:11,506
article that Vijita has published. So investing in

268
00:16:11,528 --> 00:16:15,074
tools is important because I believe the ecosystem is still

269
00:16:15,112 --> 00:16:19,206
sort of getting up to speed on that killer product.

270
00:16:19,308 --> 00:16:22,566
So we all need to sort of contribute, chime in and do

271
00:16:22,588 --> 00:16:25,862
our best. So this is essentially something that I would say

272
00:16:25,916 --> 00:16:29,190
all companies would. It would be good value for money.

273
00:16:29,260 --> 00:16:33,290
And this has really helped us enable that maturity model in all the teams.

274
00:16:33,710 --> 00:16:36,986
So apart from the maturity model for the teams, the other thing that I would

275
00:16:37,008 --> 00:16:41,100
focus on also is building the right mindset of each and every individual.

276
00:16:41,470 --> 00:16:44,734
Right? So what we suggest all

277
00:16:44,772 --> 00:16:48,394
companies to do, because we've seen this succeed, is a lot of trainings.

278
00:16:48,442 --> 00:16:51,598
Right. The path is not easy. The journey is

279
00:16:51,604 --> 00:16:55,026
not easy. You have to make sure that people understand what they're trying to

280
00:16:55,048 --> 00:16:58,926
accomplish before they do it. So trainings, certifications, brown back sessions,

281
00:16:58,958 --> 00:17:03,026
all of the usual stuff. Making sure that you're building resilience after an

282
00:17:03,048 --> 00:17:06,654
outage. Right. And resilience doesn't just mean software resilience.

283
00:17:06,702 --> 00:17:09,878
And I know there is other speakers who will talk about this,

284
00:17:10,044 --> 00:17:13,254
which is about human resilience as well. Right. You want to make sure

285
00:17:13,292 --> 00:17:17,190
that the person who was on call doesn't treat this as a traumatic experience.

286
00:17:17,340 --> 00:17:20,646
They actually learn from it because the postmortem itself was

287
00:17:20,668 --> 00:17:23,866
blameless. You're not really pointing fingers. You're trying to figure out what

288
00:17:23,888 --> 00:17:27,210
the system looks like and how to make it better. And teaching that

289
00:17:27,280 --> 00:17:30,646
is also something that doesn't come naturally to human beings.

290
00:17:30,678 --> 00:17:34,074
Right. We tend to want to find blame in someone, and blameless

291
00:17:34,122 --> 00:17:37,550
postmortems is something that I think it really takes a culture

292
00:17:37,970 --> 00:17:40,320
change in companies to accept that.

293
00:17:40,930 --> 00:17:44,354
And the last thing is carrots, not sticks, which teams, you treat them with

294
00:17:44,392 --> 00:17:48,130
rewards, not punishments. Basically, the idea is

295
00:17:48,200 --> 00:17:52,098
you provide some kind of an incentive for folks doing these kind

296
00:17:52,104 --> 00:17:55,886
of resiliency exercises. It's a hard thing to do. The fact that they're

297
00:17:55,918 --> 00:17:59,154
accepting it, doing it means that they're committed to it, they're passionate about

298
00:17:59,192 --> 00:18:03,240
it. You want to make sure that you enable them and you incentivize them.

299
00:18:03,850 --> 00:18:06,854
So what did we learn on our journey? So all of this stuff, I think,

300
00:18:06,892 --> 00:18:11,250
is something that I think works for any company anywhere.

301
00:18:11,410 --> 00:18:15,318
But there are some things that I would say do not do, and that's

302
00:18:15,334 --> 00:18:18,694
what I'm going to talk about next. So these are the things that are don'ts.

303
00:18:18,822 --> 00:18:22,560
So these are learnings. The first learning that we found was

304
00:18:23,010 --> 00:18:26,394
we mistakenly created vanity

305
00:18:26,442 --> 00:18:29,774
positions, right? And this is something that other folks also have done,

306
00:18:29,972 --> 00:18:33,282
which is we did not want those, which is like, this person

307
00:18:33,336 --> 00:18:37,630
is the designated chaos practitioner, or this person is the resiliency

308
00:18:37,710 --> 00:18:40,930
expert, or such. And such that doesn't work

309
00:18:41,080 --> 00:18:45,070
because, one, it shifts the responsibility

310
00:18:45,150 --> 00:18:49,006
of something to be done to that one person instead of democratizing

311
00:18:49,038 --> 00:18:52,578
it to everyone, saying, oh, yeah, we are all enabled and empowered

312
00:18:52,594 --> 00:18:56,086
to be able to do this. It shouldn't be this one person. So we

313
00:18:56,108 --> 00:18:59,322
learned that pretty early on, but it was something

314
00:18:59,376 --> 00:19:02,714
that was, we realized that it was not helping our

315
00:19:02,752 --> 00:19:06,166
cause. Second thing was, the exercises cannot

316
00:19:06,198 --> 00:19:10,310
be conducted without complete participation. When I say complete participation,

317
00:19:10,390 --> 00:19:14,286
it doesn't mean complete participation of just the team. It has to be the

318
00:19:14,308 --> 00:19:17,194
team's dependencies. Maybe the SRE teams,

319
00:19:17,242 --> 00:19:20,734
maybe the other teams that support you in production. All of these

320
00:19:20,772 --> 00:19:23,786
folks need to have sort of, they need to be signed

321
00:19:23,818 --> 00:19:27,070
up, they need to be committed to this cause. And that also takes effort.

322
00:19:27,150 --> 00:19:31,266
It does also take interest from their side and passion from their side.

323
00:19:31,448 --> 00:19:34,894
So this is something that we sort of found out over time, and we realized

324
00:19:34,942 --> 00:19:38,354
that we have to sort of fix this. The other thing was

325
00:19:38,392 --> 00:19:41,606
don't assume, verify. So this is sort of a

326
00:19:41,628 --> 00:19:44,550
take on the same thing, right? So like trust but verify kind of thing.

327
00:19:44,620 --> 00:19:47,990
But it always starts with assumptions, right? All of us in this room,

328
00:19:48,140 --> 00:19:51,606
we know what the value prop of chaos engineering is, but you can't

329
00:19:51,638 --> 00:19:54,630
go in with that assumption with everyone, right? So, for example, observability,

330
00:19:54,790 --> 00:19:57,786
you cannot go into it if you ask a team, hey,

331
00:19:57,888 --> 00:20:01,562
do you think you can find an issue in 15

332
00:20:01,616 --> 00:20:04,974
minutes? They'll probably say yes. I don't think there is any team that has said

333
00:20:05,012 --> 00:20:08,526
no to us or anyone else. Right. But you

334
00:20:08,548 --> 00:20:12,510
have to verify that by checking if the observability truly is as

335
00:20:12,580 --> 00:20:16,434
they say it is. Right. No. Teams, I would say,

336
00:20:16,472 --> 00:20:19,300
is as well instrumented as they think they are.

337
00:20:19,830 --> 00:20:23,090
On call. Being reactive is always the problem.

338
00:20:23,160 --> 00:20:26,814
Right. You have to make sure that you test the on call systems

339
00:20:26,862 --> 00:20:30,082
you want to test. Make sure that the on call person has everything. Doesn't mean

340
00:20:30,136 --> 00:20:33,830
actually test the on call person to see like, hey, I just created an issue.

341
00:20:33,980 --> 00:20:37,206
Did you actually catch it? Right. Not that way, but you want to make sure

342
00:20:37,228 --> 00:20:40,060
that they are empowered before they get into a bad situation.

343
00:20:40,910 --> 00:20:44,282
The other thing is specifying what the

344
00:20:44,336 --> 00:20:47,450
team's goals are about. Resiliency is crucial.

345
00:20:48,110 --> 00:20:51,290
Every team does not see it the same way.

346
00:20:51,440 --> 00:20:54,510
It will change team to team, it will change application to application.

347
00:20:54,660 --> 00:20:57,998
And those goals would be prioritized by that team. It is not something that you

348
00:20:58,004 --> 00:21:01,914
can centrally prioritize. You can prioritize. Loss of revenue

349
00:21:01,962 --> 00:21:05,462
should be minimized, but that is interpreted by different teams differently.

350
00:21:05,546 --> 00:21:08,574
And I think this is something that we learned, and it was a pretty painful

351
00:21:08,622 --> 00:21:12,420
learning for the simple reason that we didn't really understand

352
00:21:12,790 --> 00:21:16,766
that teams had a certain plan as well for how resilient

353
00:21:16,798 --> 00:21:20,294
they want to be. Instead, we were imposing a certain metric which for them was

354
00:21:20,332 --> 00:21:24,034
meaningless. Right. So that's something I would suggest folks to have discussions

355
00:21:24,082 --> 00:21:27,442
about. And obviously their deployment pipelines have to be verified.

356
00:21:27,506 --> 00:21:31,210
But this, I would say, is something that is part of the exercise.

357
00:21:32,510 --> 00:21:36,060
So are teams ready for exercises? So this is something that

358
00:21:36,430 --> 00:21:39,206
no team is going to come in and say, if you just start your chaos

359
00:21:39,238 --> 00:21:42,458
engineering group and you go to someone and you say, okay,

360
00:21:42,544 --> 00:21:45,950
are you ready to do this? They are going to be very reluctant.

361
00:21:46,450 --> 00:21:49,594
Maybe someone will say, yes, we will try it, but in reality,

362
00:21:49,642 --> 00:21:53,198
none of them are right. So you have to make sure that you build the

363
00:21:53,204 --> 00:21:57,086
training, you teach them that it's okay to sort of learn

364
00:21:57,188 --> 00:22:00,606
but don't fail in such a way that you sort of cause that trauma

365
00:22:00,638 --> 00:22:03,746
to the team saying, I'm never going to ever do this again, this was a

366
00:22:03,768 --> 00:22:07,154
bad idea. So in order to teach the right way to do things,

367
00:22:07,272 --> 00:22:11,078
you have to treat chaos engineering as it's supposed to be. It's an experimentation process.

368
00:22:11,244 --> 00:22:14,326
It's a process where you establish a hypothesis and you

369
00:22:14,348 --> 00:22:18,294
prove or disprove it. It's a scientific experiment. It's not a,

370
00:22:18,492 --> 00:22:21,870
let's just hammer out some of these nails into this server

371
00:22:21,890 --> 00:22:25,818
here, and let's see what happens. That's not what chaos engineering is. So I just

372
00:22:25,824 --> 00:22:28,140
want to give you guys a sense of where we are now.

373
00:22:29,070 --> 00:22:32,794
The report card reads really good. I would say that

374
00:22:32,912 --> 00:22:36,478
all of these learnings that you saw, that has obviously given us a lot

375
00:22:36,484 --> 00:22:39,374
of thought about how we want to progress in the future, but it has only

376
00:22:39,412 --> 00:22:43,230
given us more sort of will to do more. The application

377
00:22:43,300 --> 00:22:47,058
teams are eager to run these tests, and because of the maturity model,

378
00:22:47,144 --> 00:22:51,278
they've understood that we do not have to just go in and be glamorous

379
00:22:51,374 --> 00:22:54,580
overachievers overnight. It has to be a slow process.

380
00:22:55,210 --> 00:22:58,754
Management confidence is good because management

381
00:22:58,802 --> 00:23:00,040
invests in this.

382
00:23:01,210 --> 00:23:04,230
Again, in order for management to invest in this,

383
00:23:04,300 --> 00:23:07,746
they need to understand that chaos is not the goal. The goal

384
00:23:07,778 --> 00:23:11,338
is resiliency, but the way to get to that is chaos. Right. And this

385
00:23:11,344 --> 00:23:14,806
has been repeated by many folks, not just me. There's other speakers

386
00:23:14,838 --> 00:23:16,940
also who will repeat this.

387
00:23:17,950 --> 00:23:22,086
Increased resiliency in engineering usually tends

388
00:23:22,118 --> 00:23:26,030
to basically, if your engineering team itself is resilient,

389
00:23:26,930 --> 00:23:30,302
then essentially it opens the way to subsequent learning. So you start

390
00:23:30,356 --> 00:23:33,940
doing more learnings. It encourages them to test things out even more.

391
00:23:34,870 --> 00:23:38,862
And frankly speaking, everyone defines an end state. So application owners,

392
00:23:38,926 --> 00:23:42,034
all of the application owners define, okay,

393
00:23:42,072 --> 00:23:45,694
if something bad happens, this is what I want, right? That's all in their dreams.

394
00:23:45,742 --> 00:23:49,618
There is no verification. But this now allows them to stand in meetings

395
00:23:49,714 --> 00:23:53,618
where maybe there is multiple high level tech leads or senior management

396
00:23:53,714 --> 00:23:57,074
and be able to say, okay, this is what my application does, and I'm confident

397
00:23:57,122 --> 00:24:00,566
about it. And that's actually, I think, the best thing to come out of

398
00:24:00,588 --> 00:24:03,930
it, because you want to empower your tech leads, your engineering managers and such,

399
00:24:04,000 --> 00:24:07,370
so that they can stand their ground whenever they are talking to folks about

400
00:24:07,440 --> 00:24:10,806
how to do this thing better or whatever. Right? Like, good design, good architecture,

401
00:24:10,838 --> 00:24:13,946
all of that is improved by this. So this is where we are today.

402
00:24:13,968 --> 00:24:17,966
And so all of the learnings that we have done has led us to this.

403
00:24:18,068 --> 00:24:21,166
And going forward, what we want to do is build on these

404
00:24:21,188 --> 00:24:24,526
models, right? The maturity models that we see today that I

405
00:24:24,548 --> 00:24:27,854
just described, those were rough around

406
00:24:27,892 --> 00:24:30,654
the edges, right? So there were things that we had not defined very well.

407
00:24:30,692 --> 00:24:33,838
Like I said, resilience of the individual person as well.

408
00:24:33,844 --> 00:24:36,854
Right. The engineer. So we are trying to work on those things and make sure

409
00:24:36,892 --> 00:24:40,642
that we commit to this in a way that is sustainable

410
00:24:40,706 --> 00:24:43,750
and that's actually important for this kind of exercise.

411
00:24:44,570 --> 00:24:47,766
That's the entire story that I wanted to share with you guys today,

412
00:24:47,868 --> 00:24:51,366
and that's all I had. Thank you so much. If you have questions, I'm ready

413
00:24:51,388 --> 00:24:51,700
to hear it.

