1
00:00:20,490 --> 00:00:24,362
Hi everyone, I'm Madhumita, product lead at Startree.

2
00:00:24,426 --> 00:00:27,766
I'm very excited to be here along with Suvadeep, who is

3
00:00:27,788 --> 00:00:31,640
my colleague. We are going to give the talk on

4
00:00:32,010 --> 00:00:35,090
troubleshooting real time business metrics.

5
00:00:35,170 --> 00:00:37,910
It's a very favorite topic for me,

6
00:00:38,060 --> 00:00:41,338
and without further ado, I would like to get started.

7
00:00:41,504 --> 00:00:45,462
I always start with a quote. So today's favorite quote

8
00:00:45,526 --> 00:00:48,874
for me is real time business metrics are

9
00:00:48,912 --> 00:00:52,800
constantly changing. That's why it's very important

10
00:00:53,170 --> 00:00:56,880
to be proactive in detecting those issues.

11
00:00:57,410 --> 00:01:01,550
Don't wait for a problem to become a crisis before

12
00:01:01,620 --> 00:01:05,374
you take action. So that's the crux

13
00:01:05,422 --> 00:01:09,394
of today's talk and something very

14
00:01:09,592 --> 00:01:13,262
close to my heart and I have experienced

15
00:01:13,326 --> 00:01:16,630
it and been living through this for some time.

16
00:01:16,780 --> 00:01:20,114
And today I'm very excited to share my journey,

17
00:01:20,162 --> 00:01:23,106
my story, along with my colleague Savadi,

18
00:01:23,138 --> 00:01:26,454
with all of you. So what are we going to

19
00:01:26,492 --> 00:01:30,406
talk about? So some of the challenges and

20
00:01:30,508 --> 00:01:34,042
introducing to real time metrics, monitoring and

21
00:01:34,096 --> 00:01:37,866
anomaly detection, that's what I will be covering. And then

22
00:01:37,888 --> 00:01:41,562
I'll hand it over to my colleague who will give a walkthrough

23
00:01:41,626 --> 00:01:44,894
of real life use case and how

24
00:01:44,932 --> 00:01:48,974
to troubleshoot that, a live demonstration of that. And then

25
00:01:49,012 --> 00:01:52,654
he will touch base on some of the benefits and advantages and

26
00:01:52,772 --> 00:01:56,034
we will open up the floor for Q A. So stay

27
00:01:56,072 --> 00:01:59,490
tuned. You're going to learn a lot and lot of interesting stuff

28
00:01:59,560 --> 00:02:02,900
we are going to share with you in few minutes.

29
00:02:03,910 --> 00:02:07,186
So to start with, what are these challenges

30
00:02:07,298 --> 00:02:11,062
associated when it comes to troubleshooting real time

31
00:02:11,116 --> 00:02:15,186
business metrics? Real time business metrics are the metrics

32
00:02:15,218 --> 00:02:19,306
that you are monitoring to identify any issues

33
00:02:19,408 --> 00:02:23,018
that are happening in real time. So one

34
00:02:23,104 --> 00:02:26,906
example is in IoT space, if you

35
00:02:26,928 --> 00:02:31,114
have several devices planted across different locations

36
00:02:31,242 --> 00:02:34,814
and those devices are getting heated up and you

37
00:02:34,852 --> 00:02:39,038
would like to know as soon as possible before

38
00:02:39,204 --> 00:02:43,410
it becomes a crisis, which means these device shuts down

39
00:02:43,480 --> 00:02:47,666
or something like that. And that's not good for your business or

40
00:02:47,768 --> 00:02:51,106
not good for your users. So in

41
00:02:51,208 --> 00:02:55,054
Netnet is very important to monitoring

42
00:02:55,102 --> 00:02:58,886
that, but something goes wrong, then troubleshooting as quickly as

43
00:02:58,988 --> 00:03:01,938
possible so that you can take action.

44
00:03:02,114 --> 00:03:05,714
So now to do that, what are the challenges involved?

45
00:03:05,842 --> 00:03:08,954
Well, when we talk about metrics and that too in

46
00:03:08,992 --> 00:03:12,234
real time data is something stands out.

47
00:03:12,432 --> 00:03:16,646
In the era of generative AI, data is everywhere

48
00:03:16,838 --> 00:03:20,634
and the data volume and velocity is becoming

49
00:03:20,682 --> 00:03:24,510
very, very important. So handling

50
00:03:24,930 --> 00:03:28,174
massive amount of data in real time,

51
00:03:28,372 --> 00:03:31,742
what you need an efficient storage solution and

52
00:03:31,796 --> 00:03:35,026
processing solutions, there are not many out there.

53
00:03:35,208 --> 00:03:38,690
So that's a challenge. Now second thing

54
00:03:38,760 --> 00:03:42,290
is, if you are troubleshooting, then you are making

55
00:03:42,360 --> 00:03:45,202
decisions around what are you going to do next?

56
00:03:45,336 --> 00:03:49,110
Whether you have to fix the device or something else going on. To fix

57
00:03:49,180 --> 00:03:52,562
that now, to do that efficiently,

58
00:03:52,626 --> 00:03:56,422
you need to have good quality data, you need to have consistent data.

59
00:03:56,556 --> 00:04:00,374
Otherwise you're not going to be making qualitative decisions

60
00:04:00,422 --> 00:04:04,090
in real time, and that's going to be a big challenge.

61
00:04:04,510 --> 00:04:07,260
Now, what's next? Well,

62
00:04:08,030 --> 00:04:12,030
data quality. We talked about data. We talked about. Now data

63
00:04:12,100 --> 00:04:16,058
is everywhere, as I was saying, and especially if you're talking about IoT

64
00:04:16,154 --> 00:04:20,302
world data is in multiple devices, data is

65
00:04:20,356 --> 00:04:22,906
Internet, data is offline.

66
00:04:23,098 --> 00:04:26,722
You're integrating all that data to make a sense out of it

67
00:04:26,776 --> 00:04:30,722
in real time. That's very complex and that could

68
00:04:30,856 --> 00:04:35,038
be also hindrance if you're not doing that on time

69
00:04:35,144 --> 00:04:39,206
and accurately. So that's another important aspect you need

70
00:04:39,228 --> 00:04:42,802
to consider. And latency and scalability

71
00:04:42,866 --> 00:04:47,094
is another big problem. Like if you are also trying to solve through

72
00:04:47,132 --> 00:04:50,650
a solution, latency becomes a challenge.

73
00:04:52,030 --> 00:04:55,786
Data may not be arriving on time or you're not processing on time. There are

74
00:04:55,808 --> 00:04:59,846
multiple issues involved. And now as data is growing, you can't scale

75
00:04:59,878 --> 00:05:03,198
it either. So these are some of the limiting things

76
00:05:03,284 --> 00:05:06,346
to do, troubleshooting in real time in a smart

77
00:05:06,378 --> 00:05:09,946
and efficient way. So now what's

78
00:05:09,978 --> 00:05:13,686
the solution? Well, since we are talking about metrics,

79
00:05:13,738 --> 00:05:17,246
we will have to monitor the metrics, obviously, but monitoring

80
00:05:17,278 --> 00:05:20,894
is just not enough. You need to identify those anomalous

81
00:05:20,942 --> 00:05:24,866
events as quickly as possible because it's very, very important.

82
00:05:25,048 --> 00:05:29,046
And the sooner you detect, the impact is going to be high in

83
00:05:29,068 --> 00:05:32,966
terms of revenue or cost savings. Now what

84
00:05:32,988 --> 00:05:36,834
is this anomalous events? These could be spike

85
00:05:36,882 --> 00:05:40,554
or drops or could be gradual change over a period of

86
00:05:40,592 --> 00:05:44,266
time, which is very, very hard to detect in

87
00:05:44,288 --> 00:05:47,622
a manual way. And just detecting

88
00:05:47,686 --> 00:05:51,102
anomaly events are not enough. You need

89
00:05:51,156 --> 00:05:54,622
to have the cause, what is

90
00:05:54,676 --> 00:05:58,154
causing this anomalous event so that you can troubleshoot

91
00:05:58,202 --> 00:06:01,358
as quickly as possible in real time,

92
00:06:01,524 --> 00:06:05,154
getting answers and then taking actions. So these

93
00:06:05,192 --> 00:06:08,222
are actionable insights, which is very critical

94
00:06:08,366 --> 00:06:12,222
for a qualitative decisions, which is hugely

95
00:06:12,286 --> 00:06:15,290
associated with cost implications.

96
00:06:15,390 --> 00:06:19,334
So in general, the solution to

97
00:06:19,452 --> 00:06:23,334
troubleshooting real time business metrics is

98
00:06:23,532 --> 00:06:27,762
having a metrics monitoring system and detecting

99
00:06:27,826 --> 00:06:31,766
anomalies and identifying these actionable insights

100
00:06:31,798 --> 00:06:35,260
so you can make qualitative decisions as quickly as possible.

101
00:06:36,350 --> 00:06:39,414
Now, what are the different scenarios

102
00:06:39,462 --> 00:06:42,860
of this anomalous event? So the different

103
00:06:43,170 --> 00:06:47,054
scenarios are, before we talk

104
00:06:47,092 --> 00:06:50,814
about the scenarios, let's talk about how would you build a solution like

105
00:06:50,852 --> 00:06:54,274
that? Right? So the first thing is you're bringing in all these

106
00:06:54,312 --> 00:06:58,526
data, storing it in an efficient storage, making a meaning

107
00:06:58,558 --> 00:07:01,986
out of it, then identifying those anomalies by

108
00:07:02,008 --> 00:07:05,746
applying some algorithms, and then determining

109
00:07:05,778 --> 00:07:09,062
those insights by looking at the data and then

110
00:07:09,116 --> 00:07:14,194
providing the insight. So stitching it all together provides

111
00:07:14,242 --> 00:07:17,058
an automated anomaly detection solution.

112
00:07:17,234 --> 00:07:20,762
And in addition, that is not enough because we were

113
00:07:20,816 --> 00:07:24,234
talking about metrics. Metrics can take any shape and

114
00:07:24,272 --> 00:07:28,026
form. It could be steady, it could be upward trending, it could be

115
00:07:28,048 --> 00:07:31,882
seasonal. So detecting anomalous

116
00:07:31,946 --> 00:07:36,062
events through this different various pattern of data in

117
00:07:36,116 --> 00:07:40,058
real time with a solution that I spoke in my previous slide,

118
00:07:40,154 --> 00:07:42,880
stitching it all together is not easy.

119
00:07:43,190 --> 00:07:47,438
And on top of it, detecting accurate outliers

120
00:07:47,614 --> 00:07:51,150
is also not easy. Applying lot of smart algorithms

121
00:07:51,230 --> 00:07:54,542
is not easy because you need to write the algorithm,

122
00:07:54,606 --> 00:07:58,498
apply the algorithm, or if you are using out of box algorithm

123
00:07:58,594 --> 00:08:02,534
through libraries, but you still have to stitch it together, apply it in

124
00:08:02,572 --> 00:08:06,422
real time, and then detect those accurate anomalies based

125
00:08:06,476 --> 00:08:09,686
on your business context. Combining it all together,

126
00:08:09,788 --> 00:08:13,226
it's a huge challenging. Now, is there a

127
00:08:13,248 --> 00:08:16,842
solution out there? Well, of course. And which is what we will be

128
00:08:16,896 --> 00:08:20,362
giving a live demo of that that will help you to understand

129
00:08:20,496 --> 00:08:22,780
how you can troubleshoot in real time.

130
00:08:23,630 --> 00:08:27,630
So these solution is rati third eye. It helps with

131
00:08:27,700 --> 00:08:31,438
real time metrics, monitoring almost near real time

132
00:08:31,604 --> 00:08:35,422
and anomaly detection of large and complex

133
00:08:35,486 --> 00:08:39,282
time series data. And it fast track problem solving by

134
00:08:39,336 --> 00:08:42,900
unlocking those actionable insights that I was talking about.

135
00:08:43,350 --> 00:08:47,254
Now, it has three close pillars where you are stitching the data real time and

136
00:08:47,292 --> 00:08:51,394
offline, and storing in a very efficient

137
00:08:51,522 --> 00:08:56,194
storage and computing resource like Apache

138
00:08:56,242 --> 00:08:59,686
Pinotree is built. Third eye is built on Apache Pinot

139
00:08:59,718 --> 00:09:04,218
which is a columnar data store and does an olap and

140
00:09:04,304 --> 00:09:07,610
allows you to run massive queries in your data in a very

141
00:09:07,680 --> 00:09:11,146
compute efficient way and gives you results

142
00:09:11,178 --> 00:09:14,714
in fractions of seconds. So you can apply your smart algorithms

143
00:09:14,842 --> 00:09:19,120
in an automated fashion, detect those outliers as quickly as possible

144
00:09:19,650 --> 00:09:22,994
in the accurate outliers and providing an

145
00:09:23,032 --> 00:09:26,654
interactive UI and getting those actionable insights

146
00:09:26,702 --> 00:09:30,830
throwing at you to make a quicker investigation

147
00:09:30,990 --> 00:09:35,018
to get to the root close and then make some informed

148
00:09:35,054 --> 00:09:38,866
and qualitative decisions. Now this solution

149
00:09:38,978 --> 00:09:42,146
is very awesome. It's something my favorite.

150
00:09:42,258 --> 00:09:45,254
It also has a smart UI, low code,

151
00:09:45,292 --> 00:09:48,258
no code UI and also API based solution.

152
00:09:48,434 --> 00:09:51,946
So with that I will hand over to my colleague who

153
00:09:51,968 --> 00:09:55,402
is going to give a live demo of some of the real life use

154
00:09:55,456 --> 00:09:59,162
cases and how you will use this tool to

155
00:09:59,296 --> 00:10:02,734
troubleshoot in real time and be self efficient on

156
00:10:02,772 --> 00:10:06,378
your own. And something very interesting you don't

157
00:10:06,394 --> 00:10:09,662
want to miss out. So stay tuned for the next

158
00:10:09,716 --> 00:10:13,554
half and welcome suvdeep and handing it over to

159
00:10:13,592 --> 00:10:17,042
you to give a walkthrough of the exciting use

160
00:10:17,096 --> 00:10:19,810
cases you have in the live demonstration.

161
00:10:20,310 --> 00:10:23,902
So with that, looking forward to my next segment

162
00:10:23,966 --> 00:10:25,780
of the talk. Thanks.

163
00:10:27,670 --> 00:10:31,378
Thanks Madhumitamantri, for the intro. Hey everyone, my name is Shubhadeep.

164
00:10:31,394 --> 00:10:34,566
I'm a founding engineer at Startree. I'm going to walk you through a couple

165
00:10:34,588 --> 00:10:38,086
of use cases around anomaly detection and also show you under the

166
00:10:38,108 --> 00:10:41,820
hood how thirdeye works and how are we trying to tackle some of these issues.

167
00:10:43,550 --> 00:10:47,034
So for the purposes of this demo, I'll share the

168
00:10:47,072 --> 00:10:51,134
rideshare use case that we have, as well as some IoT use case

169
00:10:51,252 --> 00:10:54,590
which we have in terms of data

170
00:10:54,660 --> 00:10:58,400
around sensors. And yeah, let's jump in.

171
00:10:59,730 --> 00:11:03,498
So here we have an instance of third eye, which is a demo instance.

172
00:11:03,594 --> 00:11:07,038
This is how the dashboard looks like. It gives you an overview of what's

173
00:11:07,134 --> 00:11:10,130
happening around your system. Are there any anomalies,

174
00:11:10,470 --> 00:11:13,890
what are your charts looking like, how are your metrics behaving, et cetera?

175
00:11:15,110 --> 00:11:19,462
So let me quickly jump into the create alert. So I'll click

176
00:11:19,516 --> 00:11:23,286
here and I'll just try to show how a

177
00:11:23,308 --> 00:11:26,994
third eye simple alert works. And what is it to create such an alert.

178
00:11:27,122 --> 00:11:30,486
So let me just go ahead and create a basic alert here. I'm going to

179
00:11:30,508 --> 00:11:34,346
use the write share data set. And let

180
00:11:34,368 --> 00:11:37,574
me just choose wait time. So just to explain the context

181
00:11:37,622 --> 00:11:41,146
here. So we have Pinot, which is a time series database which

182
00:11:41,168 --> 00:11:44,906
is showing all of these data sets. And we're choosing a metric

183
00:11:44,938 --> 00:11:48,526
here which is, in this case, wait time. So ride share is

184
00:11:48,548 --> 00:11:51,726
typically, think of it like a data set for Uber, where you

185
00:11:51,748 --> 00:11:55,166
have these cab rides which are being taken all over the place,

186
00:11:55,268 --> 00:11:58,226
and we are trying to monitor different metrics around them and trying to figure out

187
00:11:58,248 --> 00:12:01,858
if there are anomalies associated with it. So I'm going

188
00:12:01,864 --> 00:12:05,566
to go ahead and load the chart. So, notice that the crime larity

189
00:12:05,598 --> 00:12:09,510
is daily, meaning that we are trying to aggregate daily wait times

190
00:12:09,660 --> 00:12:13,462
over this period of time. And in this case,

191
00:12:13,516 --> 00:12:16,806
I'm aggregating with sum. So I'm adding up all these wait times and showing it

192
00:12:16,828 --> 00:12:20,490
on a per day basis. Now, the metric looks reasonably

193
00:12:21,550 --> 00:12:24,886
well behaved, except probably this weird spike

194
00:12:24,918 --> 00:12:28,086
here. And maybe I'll just change these granularity

195
00:12:28,118 --> 00:12:31,340
to hourly to see how that looks like.

196
00:12:32,110 --> 00:12:35,078
As you can see, the metric is fairly seasonal,

197
00:12:35,174 --> 00:12:39,146
except this particular spike. So I'm going to actually try to create an alert

198
00:12:39,178 --> 00:12:41,678
on top of this so that if we see such kind of spikes, we want

199
00:12:41,684 --> 00:12:45,060
to make sure that the system is actually behaving okay.

200
00:12:46,310 --> 00:12:49,438
So third eye actually shows you a whole suite of algorithms.

201
00:12:49,534 --> 00:12:53,410
In this case, these algorithms are helping you to detect anomalies.

202
00:12:54,390 --> 00:12:58,230
I'm going to actually go ahead and choose the matrix profile in this case,

203
00:12:58,300 --> 00:13:02,738
which is a startree algorithm that helps you with patch

204
00:13:02,914 --> 00:13:08,534
level analysis and figures out anomalies for

205
00:13:08,572 --> 00:13:11,834
use cases especially like this. So let me go ahead and select that and click

206
00:13:11,872 --> 00:13:14,998
next. So I'm not going to change any settings,

207
00:13:15,014 --> 00:13:18,410
I'm just going to just load the chart. And as you can see with

208
00:13:18,480 --> 00:13:22,246
the default setting here, I'm able to actually see that the algorithm correctly

209
00:13:22,278 --> 00:13:25,306
predicts that there is a weird spike here which is very different from the overall

210
00:13:25,338 --> 00:13:28,606
metric. So I'm actually pretty happy with this. I'm going to go ahead and

211
00:13:28,628 --> 00:13:32,106
click next. So I'm going to skip

212
00:13:32,138 --> 00:13:34,770
over all of this and go ahead and create the alert.

213
00:13:37,670 --> 00:13:41,122
Now what happens is that we just created a basic alert in a metric and

214
00:13:41,176 --> 00:13:44,834
third eye in the background is actually running a task which

215
00:13:44,872 --> 00:13:47,870
goes ahead and checks for,

216
00:13:48,040 --> 00:13:52,290
or rather performs the entire detection routine on these metrics

217
00:13:52,370 --> 00:13:55,878
and eventually comes up with its results. In this case, as you can see,

218
00:13:55,964 --> 00:13:59,286
took a few seconds and then it showed that, hey, this is the anomaly that

219
00:13:59,308 --> 00:14:02,882
we have. So this is roughly the workflow of third eye.

220
00:14:02,946 --> 00:14:06,474
And thirdeye not only does a basic level of alerting, but it also

221
00:14:06,592 --> 00:14:09,658
is really good at multidimensional alerting. So let me show an example of what I

222
00:14:09,664 --> 00:14:12,986
mean by that. So I'm going to go back to the homepage and go ahead

223
00:14:13,008 --> 00:14:16,880
and create alert. And I'm going to just go ahead and show you what

224
00:14:17,250 --> 00:14:20,670
a multidimensional alert means here. So imagine that you have

225
00:14:20,740 --> 00:14:24,046
this ride share metric and we were doing sum over wait time. And what if

226
00:14:24,068 --> 00:14:27,810
I wanted to know that, I want to know the wait times across

227
00:14:27,880 --> 00:14:31,380
different cities or different ride types. So in this case,

228
00:14:32,150 --> 00:14:35,586
let me go ahead and choose a data set here and I'm going to just

229
00:14:35,608 --> 00:14:39,078
choose wait time as the same metric. But in this case I have a

230
00:14:39,084 --> 00:14:42,182
bunch of dimensions. So I can choose on city, I can choose

231
00:14:42,236 --> 00:14:45,160
on driver rating, maybe device type.

232
00:14:45,530 --> 00:14:48,506
Write type also looks interesting. So in this case, let me just go ahead and

233
00:14:48,528 --> 00:14:52,806
choose that. So I see that across write types.

234
00:14:52,918 --> 00:14:57,418
So what is the distribution here in terms of the

235
00:14:57,504 --> 00:15:00,902
amount of wait time across these different dimensions?

236
00:15:00,966 --> 00:15:04,154
So in this case I have write type is shared premium

237
00:15:04,202 --> 00:15:08,094
economy and they have more or less similar wait

238
00:15:08,132 --> 00:15:10,954
times across this entire time period.

239
00:15:11,002 --> 00:15:14,334
Right. And the reason is because in this case, we are using a simulated data

240
00:15:14,372 --> 00:15:17,154
set, but with real data, you'll see a lot more color here, and it really

241
00:15:17,192 --> 00:15:21,026
talk about which dimensions or which combinations of dimensions could be important.

242
00:15:21,208 --> 00:15:24,082
I can actually go ahead and choose city and write type here.

243
00:15:24,136 --> 00:15:27,394
So third eye will actually go ahead and run combinations of

244
00:15:27,432 --> 00:15:31,318
these metrics, sorry, these dimensions, and then try to figure out,

245
00:15:31,404 --> 00:15:34,726
hey, which particular faction of your data has

246
00:15:34,748 --> 00:15:37,926
a larger impact to your overall metric. So in this case, as you can

247
00:15:37,948 --> 00:15:41,446
see, folks are weighing a lot more in New York versus

248
00:15:41,638 --> 00:15:45,066
the other slices of data. In this case, San Francisco economy is

249
00:15:45,088 --> 00:15:48,426
probably just 16% of the overall traffic. So in

250
00:15:48,448 --> 00:15:50,860
the interest of time, I'm actually go ahead and,

251
00:15:53,150 --> 00:15:56,398
for example, in this case, I can just go ahead and select all of

252
00:15:56,404 --> 00:16:00,062
them and say, create multidimensional alert. So what thirdeye will do

253
00:16:00,116 --> 00:16:03,854
is actually go ahead and create an alert, going through all

254
00:16:03,892 --> 00:16:07,262
of these different time series and monitoring them in one single alert.

255
00:16:07,326 --> 00:16:11,522
So that really helps you have an overview over different

256
00:16:11,576 --> 00:16:15,090
slices of the metric, all of them in one single alert, which is extremely powerful.

257
00:16:16,390 --> 00:16:19,334
So I can just go ahead in the usual process and go ahead and create

258
00:16:19,372 --> 00:16:22,854
the alert here. For the purpose of this

259
00:16:22,892 --> 00:16:26,614
demo, I actually have an alert created. So let me just quickly

260
00:16:26,652 --> 00:16:27,778
go ahead and jump to. Jump on.

261
00:16:27,804 --> 00:16:36,202
That's cool.

262
00:16:36,256 --> 00:16:39,482
Oh, I see that these dimensionality is slightly different here.

263
00:16:39,536 --> 00:16:43,258
But let me walk you through what the analysis of an

264
00:16:43,344 --> 00:16:47,214
anomaly looks like in third eye. So, third eye not only helps you figure out

265
00:16:47,332 --> 00:16:50,698
what is an anomaly, it also figures out, or rather helps

266
00:16:50,714 --> 00:16:54,318
you in figuring out what could have caused this particular anomaly. So in this case,

267
00:16:54,404 --> 00:16:57,886
what I see is we have right type is equal to economy,

268
00:16:57,998 --> 00:17:01,586
and I can actually go ahead and expand that chart. And I can see that.

269
00:17:01,608 --> 00:17:04,866
Okay. The algorithm is actually pointing to a couple of cases where these

270
00:17:04,888 --> 00:17:08,082
spikes are not favorable. So I can actually go ahead and see

271
00:17:08,216 --> 00:17:11,250
what these anomalies mean or why they're anomalies.

272
00:17:11,330 --> 00:17:14,786
So if I click on this particular red dot, it actually jumps to the anomaly

273
00:17:14,818 --> 00:17:18,678
right away, and I see that there is this big spike here, which is

274
00:17:18,844 --> 00:17:23,482
kind of a little bit odd compared to the metrics surrounding it. So maybe

275
00:17:23,536 --> 00:17:26,554
it is an anomaly I have to investigate and figure out. So what I can

276
00:17:26,592 --> 00:17:30,026
do is I can go ahead and click investigate, and this will give me

277
00:17:30,048 --> 00:17:34,174
a much deeper view into the underlying metric and how

278
00:17:34,212 --> 00:17:37,806
thirdeye is able to analyze all of that and present it to you in one

279
00:17:37,828 --> 00:17:40,990
phase. These is what the root cause analysis module of third eye.

280
00:17:41,730 --> 00:17:45,614
So in this case, what you can see is the algorithms in

281
00:17:45,652 --> 00:17:48,846
third eye root cause analysis is trying to analyze the underlying

282
00:17:48,878 --> 00:17:52,498
data and share with you what could have caused this anomaly. So there are a

283
00:17:52,504 --> 00:17:56,290
few results here. And the common theme, if you see here, is that maybe

284
00:17:56,360 --> 00:18:00,146
the traffic condition here was heavy or moderate, or we don't

285
00:18:00,178 --> 00:18:03,318
know what exactly, but in this case,

286
00:18:03,404 --> 00:18:06,614
seems like that seems to be coming out a lot.

287
00:18:06,812 --> 00:18:10,438
The other thing that Thirdeye care does is offers you different kinds

288
00:18:10,454 --> 00:18:13,610
of tools. In this case, heat map is one such tool,

289
00:18:13,760 --> 00:18:17,734
which gives you a lot of ability

290
00:18:17,782 --> 00:18:20,950
to figure out which dimensions were behaving weirdly.

291
00:18:21,030 --> 00:18:24,782
Like in this case, anything that's blue increased and anything that's red

292
00:18:24,836 --> 00:18:28,698
decreased. Now, since the RCA stock

293
00:18:28,714 --> 00:18:32,410
contributor suggested that the traffic condition could have been one of the reasons,

294
00:18:32,490 --> 00:18:36,562
we can actually see that from here in the heat map, that moderate actually

295
00:18:36,616 --> 00:18:40,434
increased quite a bit in terms of traffic. So we see

296
00:18:40,472 --> 00:18:44,370
that these entire change is 161% increase in

297
00:18:44,520 --> 00:18:47,786
traffic moderate, and also some sort of an increase

298
00:18:47,838 --> 00:18:51,542
in heavy as well, which is in this case tripled. And actually

299
00:18:51,596 --> 00:18:55,574
light traffic is pretty small. So maybe it could have been that in this

300
00:18:55,612 --> 00:18:59,074
particular time frame, these traffic was actually

301
00:18:59,132 --> 00:19:03,434
pretty heavy, and that was probably the reason why there

302
00:19:03,472 --> 00:19:06,746
were issues in the wait time. So we can

303
00:19:06,768 --> 00:19:10,106
actually add some of these things into the chart and see how

304
00:19:10,128 --> 00:19:14,174
they behave. So in this case, I'm going to go ahead and search

305
00:19:14,372 --> 00:19:18,094
traffic equal to heavy and just

306
00:19:18,132 --> 00:19:21,486
go ahead and click that. When I do click this,

307
00:19:21,508 --> 00:19:24,914
you can see that there is this underlying chart which actually

308
00:19:24,952 --> 00:19:28,322
goes ahead and shows me that what percentage of

309
00:19:28,456 --> 00:19:31,858
this metric was actually contributed by

310
00:19:32,024 --> 00:19:35,398
the heavy traffic. I can do these similar for

311
00:19:35,484 --> 00:19:37,080
moderate traffic as well.

312
00:19:41,850 --> 00:19:45,686
It. So in this case, I think I'm adding both.

313
00:19:45,788 --> 00:19:48,150
I'm going to go ahead and add this to the investigation.

314
00:19:50,890 --> 00:19:54,694
So as you can see here, it seems that pretty much a decent

315
00:19:54,742 --> 00:19:58,394
spike is coming because of traffic condition equal to moderate. And that might as

316
00:19:58,432 --> 00:20:02,234
well be one of the reasons why we might be seeing some of these spikes

317
00:20:02,282 --> 00:20:06,080
in wait times. I'm going to go ahead and go to the next step.

318
00:20:06,610 --> 00:20:10,302
So third eye also gives you

319
00:20:10,436 --> 00:20:14,194
an event framework to work with. So the whole point of RCA here is

320
00:20:14,232 --> 00:20:18,706
to basically take

321
00:20:18,728 --> 00:20:22,126
an anomaly and translate it to an event that caused this anomaly.

322
00:20:22,158 --> 00:20:25,842
Right? So in this case, if you had a spike in wait

323
00:20:25,896 --> 00:20:29,698
time, what event could have caused this anomaly? And Thirdeye

324
00:20:29,784 --> 00:20:32,966
tries to put a lot of these information in front of you so

325
00:20:32,988 --> 00:20:36,326
that you can kind of make an informed decision here in this case, we have

326
00:20:36,348 --> 00:20:40,050
a whole bunch of events which are just holidays coming in from different areas.

327
00:20:40,130 --> 00:20:42,138
So I'm going to actually go ahead and select all of that. And you can

328
00:20:42,144 --> 00:20:47,642
see that third eye is trying to find related events around

329
00:20:47,696 --> 00:20:50,806
the time period that the anomaly had occurred and just kind of tries

330
00:20:50,838 --> 00:20:54,046
to plot them across time. So in this case, if I see there was an

331
00:20:54,068 --> 00:20:57,406
armed forces day, for example, which could have been one of the reasons why

332
00:20:57,508 --> 00:21:01,566
there was traffic, maybe in San Francisco, but this

333
00:21:01,588 --> 00:21:05,074
is how third eye would kind of try to correlate different things

334
00:21:05,112 --> 00:21:08,210
together and put them in one place so that you can make an informed decision.

335
00:21:08,630 --> 00:21:14,514
I'm actually going to go ahead and click next, and then

336
00:21:14,552 --> 00:21:17,906
you see that I can have this space where I can save the investigation.

337
00:21:17,938 --> 00:21:21,954
So in this case, I'll say traffic was traffic

338
00:21:22,002 --> 00:21:26,774
heavy or moderate was

339
00:21:26,812 --> 00:21:30,200
the reason for the increase in wait time.

340
00:21:31,850 --> 00:21:35,114
Right. And I can go ahead and save this investigation. And this now

341
00:21:35,152 --> 00:21:38,454
is a shareable entity that you can share with the team or with other analysts

342
00:21:38,502 --> 00:21:41,694
who might be interested in knowing what's actually going on or what your analysis was

343
00:21:41,732 --> 00:21:45,482
and why did you get to that? Right, so this is broadly the workflow

344
00:21:45,546 --> 00:21:49,946
in terms of the overall anomaly

345
00:21:49,978 --> 00:21:53,546
direction to RCA. Right. So let me just quickly

346
00:21:53,668 --> 00:21:57,566
go through another use case which is more related to sensor

347
00:21:57,598 --> 00:22:00,914
data. So in this case, I have an alert which

348
00:22:00,952 --> 00:22:04,594
is just doing temperature analysis. Maybe not

349
00:22:04,632 --> 00:22:06,360
this one. Give me 1 second.

350
00:22:10,810 --> 00:22:11,670
Hmm.

351
00:22:14,330 --> 00:22:16,600
Probably it is this one. All right.

352
00:22:17,770 --> 00:22:21,146
So yeah, in this case, we can actually go ahead and see that for

353
00:22:21,168 --> 00:22:24,620
different devices. So these is not a temperature monitoring of,

354
00:22:29,470 --> 00:22:33,014
this is not again, an alert which is working on the overall temperature, but rather

355
00:22:33,152 --> 00:22:35,882
on the temperatures of each device,

356
00:22:35,946 --> 00:22:39,390
ids. Right. And which is very interesting because you can have a much deeper

357
00:22:39,970 --> 00:22:43,406
insight into every device that is working in this case. So why was

358
00:22:43,428 --> 00:22:47,294
the temperature of this particular device much higher than usual?

359
00:22:47,342 --> 00:22:50,798
Right. And this is, again, we can basically go ahead through the same flow

360
00:22:50,894 --> 00:22:54,740
that we did earlier, and we can get an insight as to

361
00:22:55,190 --> 00:22:58,886
why or which dimensions are actually maybe having an

362
00:22:58,908 --> 00:23:02,022
impact. So in this case, we see a

363
00:23:02,076 --> 00:23:05,894
much fewer set of dimensions compared to our previous. Right. Share use case.

364
00:23:06,012 --> 00:23:10,118
But as you can see here, it seems like simply because

365
00:23:10,204 --> 00:23:14,026
a lot of devices started becoming more active. So maybe in this case,

366
00:23:14,128 --> 00:23:17,974
that's probably one of the reasons why maybe the overall temperature

367
00:23:18,022 --> 00:23:20,906
went up. In this case, I think the alert was set on a sum of

368
00:23:20,928 --> 00:23:24,158
temperature. So I assume that probably that it might be a reason.

369
00:23:24,244 --> 00:23:27,886
So in short, what third eye is trying

370
00:23:27,908 --> 00:23:31,246
to do here is if you have a set of metrics and you

371
00:23:31,268 --> 00:23:34,954
have a set of dimensions associated with it. Third eye can really do a deep

372
00:23:35,002 --> 00:23:38,882
drill down and try to find all sorts of correlations and causations around it

373
00:23:38,936 --> 00:23:43,282
so that you can make an informed decision as to what your anomalies can

374
00:23:43,336 --> 00:23:46,754
be related to or what are the correlated

375
00:23:46,802 --> 00:23:50,614
events, et cetera. That can be reason

376
00:23:50,732 --> 00:23:52,790
for that particular incident.

377
00:23:54,250 --> 00:23:58,054
So, yeah, that's all I had in terms of the

378
00:23:58,092 --> 00:24:01,834
demo. Let me just share a few things now in terms

379
00:24:01,872 --> 00:24:05,050
of how Thirdeye works under the hood.

380
00:24:05,470 --> 00:24:09,110
So I want to really touch upon some of these concepts

381
00:24:09,190 --> 00:24:13,100
just to illustrate that everything is not like

382
00:24:14,190 --> 00:24:16,878
there is some work under the hood that needs to be done to make sure

383
00:24:16,884 --> 00:24:20,106
that your data set is performant and the anomaly

384
00:24:20,138 --> 00:24:24,074
detection goes smoothly. So the way third eye does all of these analysis

385
00:24:24,122 --> 00:24:27,982
is third eye is actually pretty noisy in terms of querying and figuring

386
00:24:28,046 --> 00:24:31,266
out, hey, every minute, every five minutes, depending on what

387
00:24:31,368 --> 00:24:34,626
level or what speed of responsiveness you need

388
00:24:34,648 --> 00:24:38,226
from third eye in terms of getting that current value

389
00:24:38,248 --> 00:24:41,382
of the metric. And this can be expensive. So it's very

390
00:24:41,436 --> 00:24:44,598
important that the data is actually modeled. Right. So some

391
00:24:44,604 --> 00:24:47,766
of the things that I would like to call out here is these is

392
00:24:47,788 --> 00:24:51,126
where actually Apache Pinot really shines. Because it is

393
00:24:51,148 --> 00:24:55,034
a database designed for time series. It really helps us make

394
00:24:55,072 --> 00:24:58,586
sure that we are able to give timely responses to the user in

395
00:24:58,608 --> 00:25:02,138
terms of some of these queries, which are constantly monitoring your critical metrics.

396
00:25:02,234 --> 00:25:05,470
Also, one of the things that is important

397
00:25:05,540 --> 00:25:08,926
is how your data is organized in Apache Pinot or any

398
00:25:08,948 --> 00:25:12,666
kind of these databases, because how your schema

399
00:25:12,698 --> 00:25:16,002
is set up, how your data is set up is immensely important in terms of

400
00:25:16,056 --> 00:25:19,586
getting your results performant. So for

401
00:25:19,608 --> 00:25:23,282
example, I just picked up a couple of use cases here. So in this case,

402
00:25:23,336 --> 00:25:27,254
if you have your timestamp as a string, for example, these are typically much

403
00:25:27,292 --> 00:25:30,934
more expensive in terms of compute power to parse rather

404
00:25:30,972 --> 00:25:35,474
than if you have something like a long right. And it's

405
00:25:35,602 --> 00:25:39,266
keeping these factors into consideration when you're modeling your data that really adds

406
00:25:39,298 --> 00:25:43,114
up in terms of making sure that your monitoring system is performant and

407
00:25:43,152 --> 00:25:46,806
is able to live up to the requirements that your analysts

408
00:25:46,838 --> 00:25:50,090
are providing. Another thing that you might be

409
00:25:50,160 --> 00:25:53,494
thinking is that, okay, time buckets is an interesting use case as well.

410
00:25:53,552 --> 00:25:56,974
So the idea here is that whenever you want to bucket time,

411
00:25:57,012 --> 00:26:00,410
so let's say you want to round it off to the nearest minute,

412
00:26:00,490 --> 00:26:04,158
five minutes, hour, 15 minutes or daily. There is a

413
00:26:04,164 --> 00:26:07,618
lot of translation that happens in queries and sometimes

414
00:26:07,784 --> 00:26:11,298
when you're monitoring a high throughput query, it kind of gets difficult

415
00:26:11,384 --> 00:26:14,706
in terms of aggregating all of these into realtime and can add

416
00:26:14,728 --> 00:26:18,406
up into costs at runtime as well. So making sure that you

417
00:26:18,428 --> 00:26:21,782
have the right derived columns or making sure that your data types are set right

418
00:26:21,836 --> 00:26:25,078
is actually crucial in terms of making sure that your alerts are

419
00:26:25,084 --> 00:26:28,342
performant. Lastly, I also add

420
00:26:28,396 --> 00:26:33,530
that certain kinds of systems are capable of handling aggregations

421
00:26:33,870 --> 00:26:37,434
in a much more faster and more efficient way. The whole point here is

422
00:26:37,472 --> 00:26:40,758
to be able to avoid expensive query scans, sorry, table scans,

423
00:26:40,854 --> 00:26:44,378
and Star Tree index is one such example. What Star Tree

424
00:26:44,394 --> 00:26:47,726
index does is it's able to, given a configuration, it's able

425
00:26:47,748 --> 00:26:51,134
to pre compute a lot of these metrics under the hood and keep

426
00:26:51,172 --> 00:26:54,282
it prepared so that if you're asking for a certain set of queries,

427
00:26:54,346 --> 00:26:57,906
it's not a table scan anymore, it just has all of these things pre

428
00:26:57,928 --> 00:27:00,434
computed and gives you a number right up front.

429
00:27:00,552 --> 00:27:04,142
And this is extremely powerful in terms of whenever you're

430
00:27:04,206 --> 00:27:07,710
doing a large number of dimensions

431
00:27:07,790 --> 00:27:11,380
across a high cardinality data set. And also

432
00:27:11,930 --> 00:27:15,826
if you have a lot of rows getting ingested every minute, this becomes

433
00:27:15,858 --> 00:27:18,998
super important so that you're not reading a

434
00:27:19,004 --> 00:27:22,778
lot of data. So yeah, coming to again, this is

435
00:27:22,784 --> 00:27:26,746
how we're kind of positioning ourselves as well, because Thirdeye

436
00:27:26,848 --> 00:27:30,294
is something which has a high query volume and it requires

437
00:27:30,342 --> 00:27:33,866
low latency because we want to make sure that we are responsive to the user

438
00:27:33,898 --> 00:27:37,886
in terms of reporting anomalies. We actually pair up really well with

439
00:27:37,908 --> 00:27:41,742
Spino, which is a real time time series database, and it really is

440
00:27:41,876 --> 00:27:45,614
capable of handling these aggregations. And it has a lot of indexing capabilities

441
00:27:45,662 --> 00:27:48,834
that Thirdeye is able to leverage and make sure that we are able to stay

442
00:27:48,872 --> 00:27:50,690
performant across the entire vertical.

443
00:27:52,390 --> 00:27:56,130
Another thing that we also make a lot of use

444
00:27:56,200 --> 00:28:00,422
of is Pino's ability to slice across different

445
00:28:00,476 --> 00:28:03,606
dimensions with things like Star Tree index. And thirdeye also

446
00:28:03,628 --> 00:28:07,474
builds on top of that capability to make sure that we just don't monitor

447
00:28:07,522 --> 00:28:11,162
things on an overall level. But we were able to slice much deeper and

448
00:28:11,216 --> 00:28:14,426
give you insights much more quicker in terms of being able

449
00:28:14,448 --> 00:28:18,780
to drill down and look at exactly the right dimensions and

450
00:28:19,310 --> 00:28:24,046
their slices in this case. All right, so let

451
00:28:24,068 --> 00:28:27,646
me talk a little bit about what the detection looks like in

452
00:28:27,668 --> 00:28:31,434
terms of how we're detecting

453
00:28:31,482 --> 00:28:35,670
such anomalies. So third eye actually has a very sophisticated anomaly

454
00:28:35,690 --> 00:28:39,486
detection flow, and this is what we use to kind of model alerts.

455
00:28:39,518 --> 00:28:43,390
So the same flow that you're seeing that we are modeling a single metric

456
00:28:43,470 --> 00:28:47,026
is the same architecture that we are using to model multiple

457
00:28:47,058 --> 00:28:50,774
decisions as well. And this kind of capability gives us

458
00:28:50,812 --> 00:28:54,214
a lot of benefit in terms of being able to

459
00:28:54,252 --> 00:28:57,554
model derived metrics, being able to do runtime computations,

460
00:28:57,682 --> 00:29:01,798
and make sure that we

461
00:29:01,804 --> 00:29:05,066
are able to monitor a diverse set of use cases to kind of give you

462
00:29:05,088 --> 00:29:07,974
the results that you need without doing a lot of pre computation.

463
00:29:08,102 --> 00:29:11,438
So third eye actually is capable of handling a

464
00:29:11,444 --> 00:29:15,482
lot of these flexibility on its own. We do have a solid notification

465
00:29:15,546 --> 00:29:18,958
framework, so currently we support

466
00:29:19,044 --> 00:29:22,174
email slack and pager duties coming soon. The main

467
00:29:22,212 --> 00:29:25,258
goal here is that once your anomalies are detected,

468
00:29:25,354 --> 00:29:27,586
we want to make sure that we are able to present it to you in

469
00:29:27,608 --> 00:29:31,486
a way that's consumable to you. And notifications is exactly designed

470
00:29:31,518 --> 00:29:34,626
for that. So we have a solid notifications flow which makes

471
00:29:34,648 --> 00:29:38,018
sure that we are able to consolidate all the report properly and kind of feed

472
00:29:38,034 --> 00:29:41,538
it to you in whatever way. You can also build your own integrations with webhooks,

473
00:29:41,634 --> 00:29:45,122
but this framework actually prepares

474
00:29:45,186 --> 00:29:48,502
and sends all of these reports to you live in real time.

475
00:29:48,636 --> 00:29:51,866
All right, so third eye is obviously API first.

476
00:29:51,968 --> 00:29:55,194
We pretty much do this pretty much for everything at Star

477
00:29:55,232 --> 00:29:58,486
Tree, and the idea here is to be able to build applications

478
00:29:58,518 --> 00:30:02,138
on top seamlessly and this kind of gives you a lot of scope in

479
00:30:02,144 --> 00:30:05,680
doing that. So pretty much everything that we have showed me on the UI is

480
00:30:06,370 --> 00:30:10,058
very easily integratable by some API provided

481
00:30:10,074 --> 00:30:12,842
by Third Eye. We are cloud ready as well.

482
00:30:12,996 --> 00:30:17,540
You can deploy us in Kubernetes. We have a helm chart and

483
00:30:17,990 --> 00:30:21,698
we are available at GitHub. So we have a

484
00:30:21,704 --> 00:30:26,126
community edition and that is available@GitHub.com slash Startree

485
00:30:26,158 --> 00:30:29,926
Slash Thirdeye and feel free to try this out and let us

486
00:30:29,948 --> 00:30:34,150
know your feedback. Most of the tools that we have shared here is available

487
00:30:34,220 --> 00:30:38,182
in the community edition. There should be no problem in kind of reproducing this and

488
00:30:38,236 --> 00:30:41,506
that's pretty much it. So here are the links

489
00:30:41,618 --> 00:30:44,726
as well. Feel free to try out these,

490
00:30:44,908 --> 00:30:48,134
join the Star Tree community or try out the community edition. If you guys

491
00:30:48,172 --> 00:30:51,262
want to be a little more hands off and want want things to be more

492
00:30:51,396 --> 00:30:54,170
delivered to you in terms of whole package,

493
00:30:54,250 --> 00:30:57,886
the Enterprise version is also available for you to play with. You can go

494
00:30:57,908 --> 00:31:01,134
ahead and use this self serve trial with that

495
00:31:01,172 --> 00:31:05,278
I will wrap up. Thank you so much and

496
00:31:05,364 --> 00:31:06,090
happy holidays.

