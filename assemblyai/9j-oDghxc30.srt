1
00:00:23,690 --> 00:00:27,218
Hello, everybody, and welcome to today we're going to be talking about time series database.

2
00:00:27,314 --> 00:00:29,750
Should I use one in my application architecture?

3
00:00:31,610 --> 00:00:34,786
So, my name is Ana East, Otis, Georgia, as you know, and I'm a developer

4
00:00:34,818 --> 00:00:38,006
advocate at Influxdata, and I want to encourage you to connect with me

5
00:00:38,028 --> 00:00:41,554
on LinkedIn in case you have any questions about time series, influxdB,

6
00:00:41,682 --> 00:00:44,680
or anything else that you want to talk about today.

7
00:00:45,850 --> 00:00:49,478
So for today's agenda, first we're going to be talking about

8
00:00:49,644 --> 00:00:53,006
who is influxdb? What is influxdata? Then I'm going to be

9
00:00:53,028 --> 00:00:56,714
going into what is time series? Next, I'll cover what is a time series

10
00:00:56,762 --> 00:01:00,634
database? And how do I know if a time series database

11
00:01:00,682 --> 00:01:04,338
is right for my application? All right,

12
00:01:04,424 --> 00:01:08,194
let's dive in. So, first I wanted to give a

13
00:01:08,312 --> 00:01:11,694
brief introduction to influx data, which is the creators

14
00:01:11,742 --> 00:01:15,422
of Influxdata. So we were founded in 2013

15
00:01:15,486 --> 00:01:18,398
by Paul Dix, who is our CTO and founder.

16
00:01:18,574 --> 00:01:21,810
We focus on developers who build real time applications,

17
00:01:21,970 --> 00:01:24,758
and we are most widely known for our time series data platform,

18
00:01:24,844 --> 00:01:28,910
Influxdata. But we also have an incredibly popular tool called Telegraph,

19
00:01:28,930 --> 00:01:32,246
which is an open source collection agent for metrics and events.

20
00:01:32,438 --> 00:01:36,442
InfluxDB is where developers can build and scale applications with time

21
00:01:36,496 --> 00:01:39,786
as the foundational component. An influxdata is

22
00:01:39,808 --> 00:01:43,310
one platform with one API across products and environments.

23
00:01:43,650 --> 00:01:48,138
The platform is widely adopted by open source developers and paying customers alike

24
00:01:48,234 --> 00:01:52,334
with over 550,000 unique deployments and over

25
00:01:52,372 --> 00:01:56,098
1300 customers. And some of those customers include Google,

26
00:01:56,184 --> 00:01:59,742
Cisco, SAP, Tesla, Disney,

27
00:01:59,886 --> 00:02:03,426
a bunch of people. So even if you

28
00:02:03,448 --> 00:02:07,414
haven't heard of us before, chances are you've probably used products that

29
00:02:07,452 --> 00:02:10,918
actually use influxdata. So the first example that I want

30
00:02:10,924 --> 00:02:14,466
to talk about is Tesla. So specifically, Tesla Powerwalls

31
00:02:14,498 --> 00:02:18,022
for the home. So Tesla pulls time series data from

32
00:02:18,156 --> 00:02:21,786
connected walls and insoler powered user homes, and they

33
00:02:21,808 --> 00:02:25,754
monitor the health, availability and performance of those solar panels and

34
00:02:25,792 --> 00:02:29,718
battery setup with influxdb. They collect at these edge

35
00:02:29,814 --> 00:02:33,434
all of that data into influxdb

36
00:02:33,482 --> 00:02:36,734
that runs their backend system. The second

37
00:02:36,772 --> 00:02:40,186
example that I want to talk about today is Nest. So Nest is a smart

38
00:02:40,218 --> 00:02:43,726
thermostat for the home. Nest monitors the infrastructure that

39
00:02:43,748 --> 00:02:47,390
powers the IoT data collection system wide for all Nest devices.

40
00:02:47,550 --> 00:02:51,266
This includes their use of kubernetes and other software infrastructure that is

41
00:02:51,288 --> 00:02:54,954
run by Nest that is used to collect, manage, transform and analyze

42
00:02:55,022 --> 00:02:58,886
and aggregate device data. Disney plus. So as we

43
00:02:58,908 --> 00:03:02,520
know, Disney plus is an entertainment, streaming service and delivery application.

44
00:03:03,210 --> 00:03:06,806
And Disney plus uses a

45
00:03:06,828 --> 00:03:10,294
global content delivery network to distribute its video series,

46
00:03:10,342 --> 00:03:13,702
movies and shorts to its users worldwide and these monitor

47
00:03:13,766 --> 00:03:17,046
movement and performance of their video content throughout

48
00:03:17,078 --> 00:03:19,770
this global CDN using influxdata.

49
00:03:20,750 --> 00:03:24,454
So also Rapi. Rappi is a non demand foot and goods delivery

50
00:03:24,502 --> 00:03:27,642
application and Rappi uses influxDB to monitor,

51
00:03:27,706 --> 00:03:31,006
react and adjust the fluctuations in the on demand pricing of

52
00:03:31,028 --> 00:03:34,474
their driver and rider delivery network. They collect time series

53
00:03:34,522 --> 00:03:38,186
data from these mobile delivery network, all of their mobile delivery

54
00:03:38,218 --> 00:03:41,346
riders, and then send it to influxdata and into the

55
00:03:41,368 --> 00:03:44,754
cloud based application they've built on to

56
00:03:44,792 --> 00:03:49,014
run the rappy service. And this

57
00:03:49,052 --> 00:03:53,238
is an awesome service that exists in Latin America and

58
00:03:53,324 --> 00:03:55,830
hope one day they also expand to North America.

59
00:03:56,570 --> 00:04:00,006
Okay, so now that we understand roughly what influxdata

60
00:04:00,118 --> 00:04:03,958
is and what they create influxdata and also telegraph,

61
00:04:04,134 --> 00:04:07,386
and we understand some of the applications and some of the customers

62
00:04:07,488 --> 00:04:11,114
that use influxdata, let's take a step

63
00:04:11,152 --> 00:04:15,146
back and ask what really is time series? So time series

64
00:04:15,178 --> 00:04:19,134
data is a collection of observations obtained through repeated measurements over

65
00:04:19,172 --> 00:04:22,320
time. Okay, that's great, but what does that really mean?

66
00:04:22,770 --> 00:04:25,646
Well, the best way to understand something is through examples.

67
00:04:25,758 --> 00:04:29,682
So one of the most classic examples of time series data is

68
00:04:29,736 --> 00:04:33,458
weather stations. So I don't

69
00:04:33,464 --> 00:04:36,594
know if you've ever received a weather station as a gift or have ever used

70
00:04:36,632 --> 00:04:39,958
a weather station, but it's a pretty neat gift and it's a

71
00:04:39,964 --> 00:04:43,206
pretty good idea in case you want to get someone for

72
00:04:43,228 --> 00:04:46,738
someone you love. But essentially it's a console that sits

73
00:04:46,754 --> 00:04:50,970
inside the house and displays the current temperature, humidity, wind, and other conditions.

74
00:04:51,390 --> 00:04:55,190
But it also gives you optionally

75
00:04:55,350 --> 00:04:58,874
instructions on how to set up the weather station outside and send

76
00:04:58,912 --> 00:05:02,166
its results to weather underground. So you can do that as well.

77
00:05:02,208 --> 00:05:05,758
And you can view your data and send data every 5 minutes,

78
00:05:05,844 --> 00:05:09,114
and send temperature data, dew point data, humidity, wind speed,

79
00:05:09,162 --> 00:05:12,766
gust pressure, precipitation rate, et cetera. So all of

80
00:05:12,788 --> 00:05:16,306
this data is data that has a timestamp associated with

81
00:05:16,328 --> 00:05:19,380
it, and that is what makes it time series data.

82
00:05:19,750 --> 00:05:22,818
And additionally, having all these snapshots of

83
00:05:22,824 --> 00:05:26,734
data over time lets weather underground applications

84
00:05:26,782 --> 00:05:30,486
show much more than just the current weather conditions. So you can see

85
00:05:30,508 --> 00:05:33,926
your historical data, and you can see the high and low temperatures for

86
00:05:33,948 --> 00:05:37,714
the day and even graph it out for the user. Another time series

87
00:05:37,762 --> 00:05:41,494
example that exists is predictive maintenance. So one

88
00:05:41,532 --> 00:05:44,346
thing that I was trying to think to myself is, do I think about time

89
00:05:44,368 --> 00:05:47,626
series data all the time? Because I think about it

90
00:05:47,648 --> 00:05:50,986
for work, or do a lot of other people do as well? So I

91
00:05:51,008 --> 00:05:54,798
was thinking about a friend who has a predictive maintenance company,

92
00:05:54,964 --> 00:05:58,654
and does he think about time series every day? And then I realized that he

93
00:05:58,692 --> 00:06:01,886
does, because his entire business is based on time

94
00:06:01,908 --> 00:06:05,406
series data. So here's a screenshot from his website where he's

95
00:06:05,438 --> 00:06:09,074
showing vibration analysis over time. And he uses this

96
00:06:09,112 --> 00:06:12,290
type of data to help companies predict the life

97
00:06:12,360 --> 00:06:15,634
of things like bearings and fan ventilation systems and many

98
00:06:15,672 --> 00:06:19,154
other types of equipment. So he attaches sensors to this equipment

99
00:06:19,202 --> 00:06:22,706
to measure things like those vibrations

100
00:06:22,738 --> 00:06:26,486
and fluctuations over time to help his customers decide when these

101
00:06:26,508 --> 00:06:30,026
might need to do some sort of predictive maintenance and replace a component that

102
00:06:30,048 --> 00:06:34,250
will likely fail in the future so that they can ensure steady and consistent operation.

103
00:06:34,910 --> 00:06:37,654
And then I was thinking about other examples.

104
00:06:37,702 --> 00:06:41,726
So another great example of time series data is

105
00:06:41,908 --> 00:06:45,646
in the healthcare space. Specifically, when we think about heart health,

106
00:06:45,748 --> 00:06:49,050
we look at things like pulse, blood pressure, and temperature.

107
00:06:49,210 --> 00:06:53,470
And that's all time series data that you need to chart.

108
00:06:53,970 --> 00:06:57,378
And it's critical for delivering care to someone. You need

109
00:06:57,384 --> 00:07:00,660
to be able to monitor the change in those values over time.

110
00:07:01,030 --> 00:07:04,306
All right, so time series data is generally categorized in

111
00:07:04,328 --> 00:07:07,590
two different types. There are both metrics and events.

112
00:07:08,170 --> 00:07:12,054
So, first and foremost, all time

113
00:07:12,092 --> 00:07:16,002
series data is represented on a two dimensional

114
00:07:16,066 --> 00:07:19,686
graph, almost always. And where we have

115
00:07:19,708 --> 00:07:23,514
a y value and an x value, the y value is typically the value

116
00:07:23,552 --> 00:07:27,334
of the time series data itself. And the x value is the actual time series.

117
00:07:27,462 --> 00:07:30,966
And one thing that is really unique about time series data is

118
00:07:31,008 --> 00:07:34,222
that the x axis, the x value,

119
00:07:34,276 --> 00:07:37,754
is actually not an independent variable, but it's a dependent variable

120
00:07:37,802 --> 00:07:41,982
as well, because there are often correlations between the value

121
00:07:42,036 --> 00:07:45,534
of something and the time. Like almost always, it is colder

122
00:07:45,582 --> 00:07:48,994
at night. So that's one unique kind of property about time

123
00:07:49,032 --> 00:07:52,370
series data that it's just fun to mention,

124
00:07:52,440 --> 00:07:56,274
because it makes time series analysis, from a statistical

125
00:07:56,322 --> 00:07:58,470
perspective much more complicated.

126
00:08:00,090 --> 00:08:03,858
But back to focusing on metrics, events. So there are two different types

127
00:08:03,874 --> 00:08:07,646
of time series. There are metrics, and metrics occur in regular

128
00:08:07,698 --> 00:08:12,042
time intervals. So those are examples like

129
00:08:12,176 --> 00:08:15,402
temperature or pressure flow rate that you are

130
00:08:15,456 --> 00:08:19,226
gathering at a particular time. And then we

131
00:08:19,248 --> 00:08:23,360
also have events, and events occur at specific points in time.

132
00:08:23,730 --> 00:08:27,102
So in our health chart, for example, an event

133
00:08:27,156 --> 00:08:30,990
might be something like a seizure or maybe an arrhythmia.

134
00:08:31,330 --> 00:08:35,134
So both events and metrics are important time series

135
00:08:35,182 --> 00:08:39,042
elements that you need to monitor health, because a metric event

136
00:08:39,096 --> 00:08:42,994
might just be, or a

137
00:08:43,032 --> 00:08:46,550
regular metric might just be monitoring

138
00:08:47,130 --> 00:08:51,350
your pulse. So why do we need time series database?

139
00:08:52,890 --> 00:08:55,986
So, essentially,

140
00:08:56,178 --> 00:09:00,122
we want to answer this question, and the best way to answer

141
00:09:00,176 --> 00:09:03,882
this question is to understand where

142
00:09:03,936 --> 00:09:07,110
time series data is advancing in a lot of different areas.

143
00:09:07,270 --> 00:09:11,418
So the first and foremost is in customer and industrial IoT.

144
00:09:11,594 --> 00:09:14,954
So when we think of manufacturing and industrial platforms,

145
00:09:15,082 --> 00:09:18,830
renewable and alternative energy systems, or fleet and management

146
00:09:19,250 --> 00:09:23,170
and telematics, we know that these have sensor data

147
00:09:23,240 --> 00:09:26,610
that is collecting data

148
00:09:26,680 --> 00:09:29,810
like pressure, flow rate, temperature, humidity, concentration,

149
00:09:31,270 --> 00:09:35,246
all these things about your environment, rotations per minute, vibrations,

150
00:09:35,278 --> 00:09:39,058
et cetera. Then we have software infrastructure, which is a huge source

151
00:09:39,074 --> 00:09:42,466
of time series as well. DevOps monitoring is a huge source of timeseries

152
00:09:42,498 --> 00:09:45,282
data, whether or not you're monitoring your containers.

153
00:09:45,346 --> 00:09:48,790
Kubernetes, the availability of endpoints,

154
00:09:49,370 --> 00:09:50,630
CI CD.

155
00:09:52,090 --> 00:09:55,606
We also see timeseries data showing up

156
00:09:55,628 --> 00:09:59,498
in real time applications. So fintech is kind of an obvious example

157
00:09:59,584 --> 00:10:03,294
of time series data, and it's a unique one as well,

158
00:10:03,332 --> 00:10:07,182
where you are very likely collecting data at

159
00:10:07,236 --> 00:10:11,310
really, really high precisions, like even the nanosecond precision, which is

160
00:10:11,380 --> 00:10:15,170
a billion points in a single second. Then we also

161
00:10:15,240 --> 00:10:18,900
look at network monitoring and gaming applications as well.

162
00:10:19,270 --> 00:10:22,654
So some of our largest customers and banks

163
00:10:22,782 --> 00:10:25,874
and crypto companies like Capital one, Bank of America,

164
00:10:25,922 --> 00:10:29,800
and Crypto.com, to name drop, a few

165
00:10:30,170 --> 00:10:32,950
are some companies that use influxdb.

166
00:10:34,570 --> 00:10:37,718
So I wanted to talk about additional data sources as well.

167
00:10:37,884 --> 00:10:41,282
So we have seen an absolute explosion of data, and I still remember

168
00:10:41,356 --> 00:10:44,826
when megabytes of data was considered huge. But now people talk

169
00:10:44,848 --> 00:10:48,186
about petabytes and exabytes of data, and one reason for this

170
00:10:48,208 --> 00:10:51,514
is that the source of data isn't just humans anymore, it's machines

171
00:10:51,562 --> 00:10:54,622
and devices. So DevOps and Internet of things,

172
00:10:54,756 --> 00:10:58,574
or IoT, has made a huge impact here. And the number of

173
00:10:58,612 --> 00:11:01,898
devices is growing in dramatically faster

174
00:11:01,994 --> 00:11:05,318
than the number of people. And the amount of data that each device can generate

175
00:11:05,354 --> 00:11:08,850
is in most cases, exponentially more than one human can generate.

176
00:11:09,670 --> 00:11:12,782
So, I'm a home automation hobbyist, and I have dozens of devices,

177
00:11:12,846 --> 00:11:16,258
like smart light switches, that are sending data every few minutes,

178
00:11:16,424 --> 00:11:19,960
and each one generating more data than I could ever as a human.

179
00:11:20,490 --> 00:11:24,038
But I think all of you know and understand this already, and it's probably just

180
00:11:24,124 --> 00:11:27,910
as good or better than me. So let's move on to the next slide.

181
00:11:28,990 --> 00:11:33,158
So, the next thing I wanted to talk about within the context of timeseries databases

182
00:11:33,334 --> 00:11:36,794
is scalability. So, one thing

183
00:11:36,832 --> 00:11:40,342
that time series databases are especially good at are

184
00:11:40,496 --> 00:11:43,758
these ability to scale, to be able to

185
00:11:43,764 --> 00:11:47,354
handle really high ingest volumes. So it's

186
00:11:47,402 --> 00:11:50,814
not uncommon that people might want to be able

187
00:11:50,852 --> 00:11:54,954
to store data at a minute interval,

188
00:11:55,002 --> 00:11:58,686
but maybe also at a second millisecond, microsecond, and even nanosecond

189
00:11:58,718 --> 00:12:02,706
interval. So if that's the case, just take a look at some of the amount

190
00:12:02,728 --> 00:12:05,794
of records that you're generating per day. And if you are writing

191
00:12:05,842 --> 00:12:09,730
at a nanosecond or collecting data at a nanosecond precision,

192
00:12:09,810 --> 00:12:14,214
then you are writing trillions of points per

193
00:12:14,252 --> 00:12:18,422
day, which is just an insane amount of volume. So one problem

194
00:12:18,476 --> 00:12:22,202
that time series databases have to be able to solve is the ability to

195
00:12:22,336 --> 00:12:25,340
support that high ingest volume. Also,

196
00:12:26,750 --> 00:12:30,150
the way that time series databases achieve this is by making certain

197
00:12:30,240 --> 00:12:33,422
design assumptions and design trade offs, and those are

198
00:12:33,476 --> 00:12:37,086
typically around deprioritizing updates and

199
00:12:37,108 --> 00:12:41,050
deletes in favor of increased

200
00:12:41,210 --> 00:12:44,786
ingest and query. And the way

201
00:12:44,808 --> 00:12:49,086
that that is largely also executed is the fact that time series

202
00:12:49,118 --> 00:12:53,266
databases are indexed by time as

203
00:12:53,288 --> 00:12:57,286
well. So we

204
00:12:57,308 --> 00:13:01,202
also need to be able to prioritize queryability and query performance.

205
00:13:01,346 --> 00:13:04,982
So, time series databases are typically organized by time.

206
00:13:05,116 --> 00:13:08,470
And when you query for data, you are typically interested

207
00:13:08,620 --> 00:13:12,426
in querying for a collection of time series data

208
00:13:12,528 --> 00:13:16,486
of time within a certain range. And because time series database

209
00:13:16,518 --> 00:13:20,506
records are organized by time, this means that time ranges of information are

210
00:13:20,528 --> 00:13:24,494
stored together. And so therefore you're able to retrieve that data more

211
00:13:24,532 --> 00:13:28,366
quickly. And this wouldn't always be the case if their

212
00:13:28,468 --> 00:13:31,790
time is just being stored in one column in a relational database, for example,

213
00:13:31,860 --> 00:13:35,426
by contrast. So when analyzing timeseries data, you typically want

214
00:13:35,448 --> 00:13:39,518
to look at a range of data, and because of its organization

215
00:13:39,614 --> 00:13:43,074
within a time series database, this becomes a really quick observation or

216
00:13:43,112 --> 00:13:46,482
operation. And then another reason

217
00:13:46,536 --> 00:13:49,682
why time series databases get used is because of your ability

218
00:13:49,746 --> 00:13:53,042
to actually manage your timeseries data lifecycle.

219
00:13:53,186 --> 00:13:56,726
So one way that you do that is through having tools that allow you

220
00:13:56,748 --> 00:14:00,614
to automatically expire old data. That's critical, especially if you

221
00:14:00,652 --> 00:14:03,910
are collecting data at a nanosecond precision.

222
00:14:03,990 --> 00:14:07,514
You might not want to retain all that data, most likely more than times,

223
00:14:07,552 --> 00:14:10,586
often not. You don't need to retain that for a long period of time,

224
00:14:10,608 --> 00:14:13,438
and you need to be able to automatically expire it, and you want to be

225
00:14:13,444 --> 00:14:16,858
able to automatically expire it in a reliable fashion.

226
00:14:17,034 --> 00:14:20,574
The other thing that you typically want to be able to do is perform down

227
00:14:20,612 --> 00:14:23,906
sampling. So what is down sampling? Downsampling is the

228
00:14:23,928 --> 00:14:27,586
process of taking high precision data

229
00:14:27,768 --> 00:14:31,026
in its raw form, then applying an

230
00:14:31,048 --> 00:14:34,766
aggregate on top of that data to create a lower precision summary

231
00:14:34,798 --> 00:14:39,174
of it, and then only storing that lower precision summary. So, for example,

232
00:14:39,372 --> 00:14:42,562
maybe today we are storing one sample

233
00:14:42,706 --> 00:14:46,406
of temperature every 5 minutes, which would provide a total of 288

234
00:14:46,428 --> 00:14:50,346
records, and we downsample that data to the

235
00:14:50,368 --> 00:14:54,442
average for the entire day. So we've reduced that data,

236
00:14:54,576 --> 00:14:58,714
excuse me, from 288 records to one record,

237
00:14:58,832 --> 00:15:02,042
and especially if you're using OSS versions of influxdata,

238
00:15:02,186 --> 00:15:05,566
that just helps you reduce your disk size as well as the

239
00:15:05,588 --> 00:15:09,486
index of your database, which would

240
00:15:09,508 --> 00:15:12,350
also in turn increase your query performance.

241
00:15:13,110 --> 00:15:16,478
And so with timeseries database, these type of actions

242
00:15:16,574 --> 00:15:21,506
typically happen at the database engine level, and they

243
00:15:21,528 --> 00:15:24,820
shouldn't require that you build these solutions yourself.

244
00:15:27,350 --> 00:15:31,186
Another typical benefit of time series databases is the reduced storage

245
00:15:31,218 --> 00:15:34,886
size that they can often have. We talked about downsampling already, and how

246
00:15:34,908 --> 00:15:38,540
you can utilize downsampling to additionally reduce your disk size

247
00:15:40,270 --> 00:15:43,446
and reduce the amount of data you need to retain.

248
00:15:43,558 --> 00:15:47,110
But compression is also another big benefit of the time series database.

249
00:15:47,270 --> 00:15:50,410
Timeseries records often have similar data.

250
00:15:50,480 --> 00:15:53,594
Think about a railroad track sensor as an example. It might

251
00:15:53,632 --> 00:15:56,670
show a zero meaning no train for almost all of the day.

252
00:15:56,820 --> 00:16:00,574
And critically important is to know when the train was there so that

253
00:16:00,612 --> 00:16:03,934
gate gets closed and the lights come on. But there may be hours

254
00:16:03,972 --> 00:16:08,002
of samplings of zero before there is a one. The only difference in

255
00:16:08,056 --> 00:16:11,406
some of the records may just be the time interval, which also has a pattern

256
00:16:11,438 --> 00:16:14,814
that can be used in compression. So you typically see great compression

257
00:16:14,862 --> 00:16:18,386
with at least some time series databases. Just because of the nature of time series

258
00:16:18,418 --> 00:16:22,054
data itself. There aren't going to be neighboring values that are

259
00:16:22,092 --> 00:16:25,906
identical or extremely similar, which also makes scanning

260
00:16:25,938 --> 00:16:30,234
the data more easy and more

261
00:16:30,272 --> 00:16:34,662
efficient as well. Time series databases also typically

262
00:16:34,726 --> 00:16:38,678
have data retention policies so that you can automatically delete

263
00:16:38,694 --> 00:16:41,420
your data after a period of time, like we mentioned.

264
00:16:42,190 --> 00:16:45,658
But you could certainly build an application to go and delete old records, but it's

265
00:16:45,674 --> 00:16:49,354
just easier to have the database do that for you. And because time series

266
00:16:49,402 --> 00:16:52,622
typically organizes by time, you don't have the inefficiency issues

267
00:16:52,676 --> 00:16:56,162
you see with some other types of databases when you delete large amounts of data

268
00:16:56,216 --> 00:16:59,458
from them. So when we do perform

269
00:16:59,544 --> 00:17:02,980
deletes, one of those trade offs that I was talking about is

270
00:17:04,310 --> 00:17:07,922
deprioritizing deletes and updates for ingest and querying.

271
00:17:07,986 --> 00:17:11,286
But when we say, when we talk about those deletes, we mean like individual points,

272
00:17:11,388 --> 00:17:15,014
whereas time series is better at deleting a large

273
00:17:15,052 --> 00:17:18,678
group of data. Okay, so you're a

274
00:17:18,684 --> 00:17:22,426
software engineer, and you want to know the following question. How do I

275
00:17:22,448 --> 00:17:24,940
know if time series is right for my application?

276
00:17:25,950 --> 00:17:29,066
So in order to answer that question, we should start

277
00:17:29,088 --> 00:17:32,734
asking ourselves a few questions. These first question to ask is,

278
00:17:32,772 --> 00:17:35,662
does my data have a time element? Most data does,

279
00:17:35,716 --> 00:17:39,802
but certainly not all of it. And sometimes it's not critical for understanding

280
00:17:39,866 --> 00:17:43,434
or problem solving. So if there's no time element,

281
00:17:43,562 --> 00:17:47,106
then a time series database is not a good fit and you

282
00:17:47,128 --> 00:17:50,674
should find a different database for it. The next question

283
00:17:50,712 --> 00:17:54,018
I would ask is do I care about changes in

284
00:17:54,024 --> 00:17:57,940
my data over time? Let's look at that basic weather station example.

285
00:17:58,330 --> 00:18:02,146
Its primary feature is to display the current temperature and humidity

286
00:18:02,258 --> 00:18:05,762
inside a house, and if those were the only features the weather station

287
00:18:05,826 --> 00:18:09,270
had, would these be need for a timeseries database? Maybe not.

288
00:18:09,340 --> 00:18:13,034
You could simply have a current temperature field in a relational database and just

289
00:18:13,072 --> 00:18:16,794
update that field whenever there is a change in the metrics. But if you do

290
00:18:16,832 --> 00:18:20,474
care about other samples of the data besides the current one,

291
00:18:20,672 --> 00:18:23,278
then there are still some more questions to ask,

292
00:18:23,364 --> 00:18:26,558
like do I think that I will get a feature request for

293
00:18:26,564 --> 00:18:30,254
my application that will these need to know about changes over

294
00:18:30,292 --> 00:18:33,406
the time what if someday we wanted to

295
00:18:33,428 --> 00:18:37,246
enhance the application to show today's high and low temperatures on the console?

296
00:18:37,438 --> 00:18:41,410
Now you could still use a timeseries database even

297
00:18:41,480 --> 00:18:45,086
if you didn't care about changes over time. Certainly with time series

298
00:18:45,118 --> 00:18:48,414
data you can often just retrieve the last record,

299
00:18:48,552 --> 00:18:52,594
which in this case would contain the same temperature and current temperature column as previously

300
00:18:52,642 --> 00:18:56,134
described. But these need to use a time series database is less

301
00:18:56,172 --> 00:18:59,990
in that case. Another question

302
00:19:00,060 --> 00:19:03,354
that you would ask yourself is how much data will I be working with?

303
00:19:03,472 --> 00:19:06,826
Will my application be working with a large amount of data now or in

304
00:19:06,848 --> 00:19:10,554
the future, or only a very small amount? If the amount of data

305
00:19:10,592 --> 00:19:13,974
is small, it doesn't mean that there is no need to use a time series

306
00:19:14,022 --> 00:19:17,934
application or database. It still might be the most efficient way

307
00:19:17,972 --> 00:19:21,118
to build your application. But if you're working with a large amount of data with

308
00:19:21,124 --> 00:19:24,514
a time element, then it will definitely help to build

309
00:19:24,552 --> 00:19:27,970
a case for scalability that time series databases can bring.

310
00:19:28,120 --> 00:19:31,998
So there's kind of a trade off between familiarity with the tools

311
00:19:32,014 --> 00:19:36,910
that you already maybe know and comfortability.

312
00:19:36,990 --> 00:19:39,950
You may be more comfortable working with a different database and you might be able

313
00:19:39,960 --> 00:19:43,238
to make it work if you have a small amount of data. But if

314
00:19:43,244 --> 00:19:46,726
you have a large amount of data, then you need to probably consider making that

315
00:19:46,748 --> 00:19:50,006
shift. And then another question to ask is, will there be any need to do

316
00:19:50,028 --> 00:19:53,526
any analytics with my data in the future? Data analytics

317
00:19:53,558 --> 00:19:56,874
are often performed by looking at data over a period of time, which makes time

318
00:19:56,912 --> 00:20:00,426
series database a really great choice for real

319
00:20:00,448 --> 00:20:03,566
time analytics. Really, any comparison to metrics or

320
00:20:03,588 --> 00:20:06,986
events in your data over time make it conductive to quick retrieval

321
00:20:07,018 --> 00:20:10,414
of time series data. Another question you might

322
00:20:10,452 --> 00:20:13,946
ask is am I concerned with storage costs.

323
00:20:14,138 --> 00:20:17,650
I know this sounds like a question that the answer is always yes,

324
00:20:17,720 --> 00:20:21,326
but let me state it better. Am I concerned with storage

325
00:20:21,358 --> 00:20:24,766
costs that could be reduced by a time series database?

326
00:20:24,958 --> 00:20:28,614
This doesn't always have an easy answer and sometimes takes some

327
00:20:28,652 --> 00:20:32,326
prototyping to figure out. But very often with time

328
00:20:32,348 --> 00:20:35,942
series data, the answer is yes, and sometimes by a dramatic amount.

329
00:20:35,996 --> 00:20:40,060
Between dancing, filling retention policies and the compression benefits that

330
00:20:40,510 --> 00:20:44,234
timeseries databases provide, another question that you ask yourself

331
00:20:44,432 --> 00:20:48,300
is am I concerned about the application performance with the time series data?

332
00:20:49,070 --> 00:20:52,534
And this is almost yes in all cases. But let's

333
00:20:52,582 --> 00:20:56,394
restate. Do I need to retrieve data in blocks of time for analytics

334
00:20:56,442 --> 00:21:00,078
to build a graph or do some other analysis over blocks of

335
00:21:00,164 --> 00:21:03,662
time and data? And is the speed in which I can do that important?

336
00:21:03,796 --> 00:21:07,266
This is where time series databases will shine. Your application may

337
00:21:07,288 --> 00:21:10,066
or may not have this need, but if it does, it's a good indicator to

338
00:21:10,088 --> 00:21:11,890
consider a time series database.

339
00:21:13,110 --> 00:21:16,674
Okay, so before we wrap it up, let's just get over

340
00:21:16,712 --> 00:21:19,320
a summary of some of the other great options out there.

341
00:21:21,050 --> 00:21:24,518
So there are places these relational databases are still far and away the

342
00:21:24,524 --> 00:21:27,914
best choice, and these are other great categories as

343
00:21:27,952 --> 00:21:33,114
well. But timeseries is definitely growing category for

344
00:21:33,312 --> 00:21:37,290
IoT use cases and for anything

345
00:21:37,360 --> 00:21:41,054
that has events and metrics. But if you have

346
00:21:41,092 --> 00:21:44,734
other types of data, you should

347
00:21:44,772 --> 00:21:46,560
use the right solution for it.

348
00:21:48,930 --> 00:21:52,282
So now if you want to start playing around with timeseries database

349
00:21:52,426 --> 00:21:55,922
and some of the vendors out there offer a free

350
00:21:55,976 --> 00:21:59,554
hosted database version. An example is influxdb. We offer

351
00:21:59,592 --> 00:22:02,866
an on prem open source free version and a

352
00:22:02,888 --> 00:22:06,866
free basic usage hosted cloud option. I actually recommend using

353
00:22:06,888 --> 00:22:10,438
the free tier cloud option first. That's usually what most people do, because you

354
00:22:10,444 --> 00:22:13,926
don't have to download anything and you can just play around with it and get

355
00:22:13,948 --> 00:22:18,354
an intuitive feel for whether or not it's something that you want to consider investing

356
00:22:18,402 --> 00:22:21,866
in. And then from there I usually see users install the

357
00:22:21,888 --> 00:22:25,674
open source version until they have a requirement where

358
00:22:25,712 --> 00:22:28,970
they don't want to host it themselves, in which case they sometimes

359
00:22:29,040 --> 00:22:32,714
return back to the cloud version. I also want to make you aware

360
00:22:32,762 --> 00:22:36,810
of resources that you can use to learn more about influxdata.

361
00:22:36,970 --> 00:22:40,122
So we have blogs, we have slack,

362
00:22:40,266 --> 00:22:43,742
the discourse forums at community, influxdata.com,

363
00:22:43,796 --> 00:22:47,182
Reddit as well. We offer influxdata University as well,

364
00:22:47,236 --> 00:22:51,466
which is a platform for learning about all things related to influxdata's

365
00:22:51,498 --> 00:22:54,666
technology, including influxdata. And you can earn

366
00:22:54,698 --> 00:22:58,326
badges is for any course that you

367
00:22:58,348 --> 00:23:01,426
complete there, and then our documentation is also excellent.

368
00:23:01,618 --> 00:23:05,494
So with that I want to thank you so much, and I

369
00:23:05,532 --> 00:23:06,580
look forward to seeing you next time.

