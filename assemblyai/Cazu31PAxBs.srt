1
00:02:08,630 --> 00:02:12,394
Hello and welcome everybody to today. We are going to be talking about

2
00:02:12,432 --> 00:02:15,690
the atomic red team and closing the gap with

3
00:02:15,760 --> 00:02:19,434
threats actors. So specifically this talk, we want to

4
00:02:19,552 --> 00:02:23,370
do something proactive where incident management,

5
00:02:24,590 --> 00:02:29,158
it's very professionally rewarding to me in particular whenever we can proactively

6
00:02:29,254 --> 00:02:33,174
reduce a risk and identify something before a threat actor

7
00:02:33,222 --> 00:02:36,850
does it for a customer or organization.

8
00:02:37,350 --> 00:02:40,706
So without further ado, let's go ahead and get started and

9
00:02:40,728 --> 00:02:44,418
jump right in. I do have a quick agenda where I'm going to talk a

10
00:02:44,424 --> 00:02:48,382
little bit about myself. Kind of the problem that we see a potential

11
00:02:48,446 --> 00:02:51,654
solution that we can explore. We'll talk a lot about

12
00:02:51,692 --> 00:02:55,942
the mitreattack framework, the atomic red team, and then know

13
00:02:55,996 --> 00:02:59,030
launching atomics and what that looks like in that perspective.

14
00:02:59,610 --> 00:03:03,386
So jumping into our presentation a little bit

15
00:03:03,408 --> 00:03:07,338
about myself. My name is Chris Haller. I am the offensive security

16
00:03:07,424 --> 00:03:10,586
practice lead at strong crypto. What I

17
00:03:10,608 --> 00:03:13,670
do is a lot of penetration testing, red teaming,

18
00:03:13,750 --> 00:03:17,050
phishing, you name, know, tons of the offensive security

19
00:03:17,120 --> 00:03:20,694
work. I've been doing offense specifically

20
00:03:20,742 --> 00:03:24,734
full time for a little over three years now. Before that

21
00:03:24,772 --> 00:03:28,226
I did eight years active duty with the Navy, number three in

22
00:03:28,248 --> 00:03:32,050
the reserves. And I did some time as a sysadmin,

23
00:03:32,790 --> 00:03:36,338
also deployed on board a carrier, which was a

24
00:03:36,344 --> 00:03:39,954
lot of fun, learned a lot from that. And then I also spent four

25
00:03:39,992 --> 00:03:43,746
years at the Navy Cyber Defense Operations Command and that's

26
00:03:43,778 --> 00:03:47,874
where I got my feet in cyber. I did a lot of incident management

27
00:03:47,922 --> 00:03:51,366
over there at NCDOC, which was a lot of fun.

28
00:03:51,468 --> 00:03:54,982
I learned a lot from it and I'm really glad I had the chance to

29
00:03:55,036 --> 00:03:58,634
do it. I did a little bit of time doing some work for about two

30
00:03:58,672 --> 00:04:02,506
years in cyber threats intelligence as well. And I'm really happy to

31
00:04:02,528 --> 00:04:05,742
be doing the offensive work now because again, like I said,

32
00:04:05,876 --> 00:04:10,046
anytime we can identify and remove or

33
00:04:10,148 --> 00:04:13,550
reduce that risk before a threat actor does is

34
00:04:13,620 --> 00:04:17,306
immensely professionally rewarding. So I do way

35
00:04:17,348 --> 00:04:20,834
too much stuff in my off time. I am the

36
00:04:20,872 --> 00:04:24,382
red versus blue coach for the US cyber team, which I'm very excited.

37
00:04:24,526 --> 00:04:28,322
This is a competition team for CTFs that

38
00:04:28,456 --> 00:04:32,230
got an initiative from SZA and DHS and the

39
00:04:32,380 --> 00:04:35,746
US Cyber team will go around and compete internationally

40
00:04:35,858 --> 00:04:39,414
in cyber competitions. So very excited to do that.

41
00:04:39,452 --> 00:04:42,898
A lot of very young athletes that love doing the

42
00:04:42,924 --> 00:04:47,050
CTF work. I do a lot of speaking. I really enjoy

43
00:04:47,120 --> 00:04:50,426
being a mentor as well. So please reach out to me if

44
00:04:50,448 --> 00:04:53,722
you have any questions. Want to talk about

45
00:04:53,776 --> 00:04:57,294
something. I always love talking

46
00:04:57,492 --> 00:05:00,814
with people, especially junior people that want to try and learn and break

47
00:05:00,852 --> 00:05:04,810
into the industry. So I've got way too many certifications.

48
00:05:04,890 --> 00:05:07,986
The only one I'll talk about is my GSE, which I was very excited to

49
00:05:08,008 --> 00:05:12,018
earn earlier this year, and constantly learning,

50
00:05:12,104 --> 00:05:15,940
always getting new stuff. So really excited to be here today.

51
00:05:16,470 --> 00:05:20,066
So getting into what's

52
00:05:20,098 --> 00:05:23,382
the problem, right? What we see is that

53
00:05:23,436 --> 00:05:27,094
criminal hacking is accelerating. All this information

54
00:05:27,212 --> 00:05:30,946
came from the Sans.org evolution of

55
00:05:31,068 --> 00:05:33,658
cybercriminal operations report in 2023.

56
00:05:33,664 --> 00:05:36,954
And when we look at this

57
00:05:36,992 --> 00:05:39,786
stuff, it's kind of demoralizing, right?

58
00:05:39,888 --> 00:05:43,718
So everything is accelerating with how fast

59
00:05:43,824 --> 00:05:47,514
threat actors are gaining access and then also pivoting

60
00:05:47,562 --> 00:05:51,242
within that access and leveraging tools

61
00:05:51,306 --> 00:05:54,750
and techniques in order to cause harm.

62
00:05:55,890 --> 00:05:59,038
So a lot of this really comes down to some of the commoditization

63
00:05:59,134 --> 00:06:02,542
of cybercrime as well. Initial access brokers

64
00:06:02,606 --> 00:06:06,290
are a pretty interesting bunch. The ones that focus on just

65
00:06:06,360 --> 00:06:10,422
getting that initial access and then selling that beyond that.

66
00:06:10,556 --> 00:06:14,566
And then we're also looking at ransomware as a service,

67
00:06:14,668 --> 00:06:18,950
phishing as a service, all this kind of service

68
00:06:19,020 --> 00:06:22,586
based activities that we see with like 365 and

69
00:06:22,688 --> 00:06:25,610
other types of software,

70
00:06:25,950 --> 00:06:29,706
it's huge in the cybercrime area too,

71
00:06:29,808 --> 00:06:33,418
right? At this point, we really don't even have to

72
00:06:33,424 --> 00:06:36,086
be that technical. As a criminal,

73
00:06:36,278 --> 00:06:39,566
all you have to be good at is just project management, right?

74
00:06:39,668 --> 00:06:43,834
We just buy a few different types of services, cobble them together, get initial

75
00:06:43,882 --> 00:06:47,874
access from an initial access broker, and we can start

76
00:06:47,992 --> 00:06:51,300
handing out ransoms for a couple of hundred thousand dollars.

77
00:06:52,390 --> 00:06:55,586
So along with that, the average breakout time is

78
00:06:55,608 --> 00:06:59,278
now 79 minutes. And when we're talking about the

79
00:06:59,304 --> 00:07:02,854
breakout time, that's from the initial infection vector to

80
00:07:02,892 --> 00:07:06,386
the lateral movement. So this is a five minute

81
00:07:06,418 --> 00:07:09,926
decrease from the previous year, which obviously things are

82
00:07:09,948 --> 00:07:13,858
accelerating and moving faster. And one particular

83
00:07:14,044 --> 00:07:17,530
area that I was concerned to see as well is the

84
00:07:17,600 --> 00:07:21,446
312% increase in remote monitoring and management tools.

85
00:07:21,558 --> 00:07:24,602
And a lot of these are very legitimate tools

86
00:07:24,666 --> 00:07:27,870
and legitimate software that we'll see

87
00:07:27,940 --> 00:07:31,994
and use in the ways that we administer

88
00:07:32,042 --> 00:07:36,482
our networks. So this is things like any desk teamviewer screen

89
00:07:36,536 --> 00:07:39,966
connect things that sysadmins rely

90
00:07:39,998 --> 00:07:43,442
on in order to conduct operations and have us

91
00:07:43,576 --> 00:07:47,346
do work, right? So by

92
00:07:47,448 --> 00:07:50,710
using and leveraging these RMM tools,

93
00:07:51,210 --> 00:07:55,042
threats, actors start to blend in and they start to hide

94
00:07:55,106 --> 00:07:58,402
among the known good activity.

95
00:07:58,546 --> 00:08:02,374
So that's kind of what my view

96
00:08:02,412 --> 00:08:05,740
of the problem is and how fast this stuff is moving. Now,

97
00:08:06,830 --> 00:08:10,406
along with this, I really like to talk about the knowns

98
00:08:10,438 --> 00:08:13,686
matrix. And if you're not familiar, Donald Rumsfeld,

99
00:08:13,718 --> 00:08:17,338
when he was Secdef, created this knowns matrix.

100
00:08:17,514 --> 00:08:20,874
As he was talking about things that are known

101
00:08:20,922 --> 00:08:24,206
knowns and known unknowns. The whole idea is we want to

102
00:08:24,228 --> 00:08:28,174
try to understand what are the things we know that

103
00:08:28,212 --> 00:08:32,046
we're aware of. And we understand. We have the known unknowns,

104
00:08:32,078 --> 00:08:36,002
which are things that we are aware of but don't really understand. So the things

105
00:08:36,056 --> 00:08:39,630
that we know, we don't know. There are the unknown

106
00:08:39,710 --> 00:08:43,474
knowns, which are the things that we understand but are not exactly aware

107
00:08:43,522 --> 00:08:47,638
of, kind of like an intrinsic understanding of something.

108
00:08:47,804 --> 00:08:51,754
And then we have the unknown unknowns. These are the things that

109
00:08:51,792 --> 00:08:55,900
we neither are aware of or understand.

110
00:08:56,270 --> 00:08:59,626
And that's where a lot of this risk really comes from.

111
00:08:59,648 --> 00:09:03,926
And that's where hackers absolutely love exploiting

112
00:09:04,038 --> 00:09:08,014
the unknown unknowns, right? Because these are things that

113
00:09:08,052 --> 00:09:11,182
we don't even know are a threat to us.

114
00:09:11,236 --> 00:09:14,974
And if we don't know that they're a threat, it's immensely more

115
00:09:15,012 --> 00:09:17,860
difficult for us to be able to defend against it.

116
00:09:18,310 --> 00:09:22,354
Whereas the known unknowns, we can understand

117
00:09:22,472 --> 00:09:25,906
that. We don't fully understand what

118
00:09:25,928 --> 00:09:29,414
the impact is, but at least we are aware of that

119
00:09:29,532 --> 00:09:33,110
threat vector. The unknown unknowns are the ones that

120
00:09:33,260 --> 00:09:36,918
really keep me up at night, right? We don't understand or

121
00:09:37,004 --> 00:09:39,430
are aware of those threat vectors.

122
00:09:42,090 --> 00:09:45,206
So we want to try to look through solutions,

123
00:09:45,238 --> 00:09:47,500
right? We want to try to solve these problems.

124
00:09:48,190 --> 00:09:52,250
So one way I've been looking and trying to understand is

125
00:09:52,400 --> 00:09:55,946
let's emulate the known attacks and measure our response

126
00:09:55,978 --> 00:09:59,546
effectiveness. This is pretty standard pen testing,

127
00:09:59,578 --> 00:10:02,000
red teaming, all that kind of stuff, right?

128
00:10:03,330 --> 00:10:06,670
Not everyone can necessarily afford the red team.

129
00:10:06,740 --> 00:10:10,194
Or if you want to look through one specific area

130
00:10:10,392 --> 00:10:13,618
of activity that we want to defend against,

131
00:10:13,784 --> 00:10:16,866
do we really want to pay for a full pen test if we're trying

132
00:10:16,888 --> 00:10:19,778
to evaluate one specific item?

133
00:10:19,954 --> 00:10:23,334
So when we're looking at this, the threat actor actions are well

134
00:10:23,372 --> 00:10:27,062
documented. The three letter agencies are

135
00:10:27,116 --> 00:10:30,374
very good at writing down

136
00:10:30,412 --> 00:10:34,178
and documenting exactly how they move through a network and the tools

137
00:10:34,194 --> 00:10:38,358
they leverage and how they did it. The tactics are consistent

138
00:10:38,454 --> 00:10:41,914
throughout environments, and these are going to be things like the

139
00:10:41,952 --> 00:10:46,430
initial access, and then they're going to try to escalate across

140
00:10:46,500 --> 00:10:50,362
the network. And then from the network, once they gain admin permissions,

141
00:10:50,426 --> 00:10:54,234
they'll try to dump the hashes and get administrative

142
00:10:54,282 --> 00:10:57,874
permissions, and then they'll look through and try to find the

143
00:10:57,912 --> 00:11:02,274
most sensitive data in the organization. So these

144
00:11:02,312 --> 00:11:06,594
tactics are very consistent, as well as the

145
00:11:06,632 --> 00:11:10,246
actual procedures that the threat actors do and how

146
00:11:10,268 --> 00:11:13,670
they run those procedures within the tactics.

147
00:11:14,250 --> 00:11:17,462
So there's always indications of compromise which

148
00:11:17,516 --> 00:11:20,226
three letter agencies are very good at reporting.

149
00:11:20,338 --> 00:11:23,626
And one thing that really keeps me

150
00:11:23,648 --> 00:11:27,270
up at night too, is do our established EDR

151
00:11:27,350 --> 00:11:31,014
MDR tools actually alert and prevent

152
00:11:31,062 --> 00:11:34,750
this activity? We don't get alerts.

153
00:11:35,650 --> 00:11:39,760
That either means that nothing bad has happened or

154
00:11:40,290 --> 00:11:43,038
nothing bad has been detected, right?

155
00:11:43,204 --> 00:11:47,282
So the false negative kind of aspect of that is always

156
00:11:47,336 --> 00:11:51,534
a concern and we don't really know unless

157
00:11:51,582 --> 00:11:55,794
we check, right? So we want to try to find the gap between

158
00:11:55,912 --> 00:11:59,910
the known threats actor procedures and what our tools will

159
00:11:59,980 --> 00:12:02,726
either alert or protect against from.

160
00:12:02,828 --> 00:12:06,246
So we want to find that gap and understand how we can

161
00:12:06,268 --> 00:12:09,400
tune our tools to protect against it.

162
00:12:10,570 --> 00:12:13,734
So this really revolves a lot around

163
00:12:13,772 --> 00:12:17,530
the mitreattack framework. So if you're not familiar with the attack

164
00:12:17,600 --> 00:12:21,290
framework, this is adversarial tactics, techniques and common

165
00:12:21,360 --> 00:12:24,606
knowledge. And the whole idea of this

166
00:12:24,708 --> 00:12:28,046
framework is that Mitre put it together so that we as

167
00:12:28,068 --> 00:12:31,902
defenders have a comprehensive knowledge base of the

168
00:12:31,956 --> 00:12:35,402
actual specific things that a threat actor

169
00:12:35,466 --> 00:12:38,978
does during a cyberattack. And these are

170
00:12:39,144 --> 00:12:42,946
the very specific and standardized framework for us to

171
00:12:42,968 --> 00:12:47,282
also be able to talk to others and discuss this

172
00:12:47,336 --> 00:12:50,834
specific dancing panda threat actors is known to be

173
00:12:50,872 --> 00:12:56,006
using miterattack? Id 10030

174
00:12:56,188 --> 00:13:00,194
zero three or something along those lines. So anytime

175
00:13:00,242 --> 00:13:04,410
we're talking about password spraying, password cracking,

176
00:13:05,390 --> 00:13:09,434
different types of access, or gaining information, we can

177
00:13:09,472 --> 00:13:13,510
all understand and agree on that specific type

178
00:13:13,600 --> 00:13:17,806
of description and how that activities occurs inside

179
00:13:17,908 --> 00:13:21,514
of a cyberattack. So if you're not familiar

180
00:13:21,562 --> 00:13:25,226
with the attack framework, I really recommend taking a closer

181
00:13:25,258 --> 00:13:28,386
look at it and understanding it and studying it. It's a

182
00:13:28,408 --> 00:13:31,940
phenomenal tool and I read it every day.

183
00:13:33,030 --> 00:13:37,122
So these procedures are the actual real

184
00:13:37,176 --> 00:13:40,870
world implementations of how these techniques actually

185
00:13:41,020 --> 00:13:44,562
happen. So these are the actual hands on keyboard,

186
00:13:44,706 --> 00:13:48,582
the commands and the way they're running those commands and running

187
00:13:48,636 --> 00:13:52,934
the attacks inside of the actual cyberattack.

188
00:13:52,982 --> 00:13:56,986
Right? So we do want to talk about these procedures and

189
00:13:57,168 --> 00:14:00,186
we want to try to understand how can we model these,

190
00:14:00,368 --> 00:14:03,706
because again, as defenders, if our

191
00:14:03,728 --> 00:14:07,006
tools are not alerting us or telling us something bad has happened,

192
00:14:07,028 --> 00:14:10,394
that either means nothing bad has happened or they didn't

193
00:14:10,442 --> 00:14:13,694
catch anything bad that has happened. And if

194
00:14:13,732 --> 00:14:17,274
we have the actual procedures that the threat actors

195
00:14:17,322 --> 00:14:20,674
have been known to use, we can try to run those on

196
00:14:20,712 --> 00:14:25,170
our system and then that'll actually give us an indication of

197
00:14:25,320 --> 00:14:28,898
either, hey, our tools found this activity and stopped

198
00:14:28,914 --> 00:14:32,098
it, or they did not stop this activity.

199
00:14:32,194 --> 00:14:35,640
Now how do we fix that gap and allow us to

200
00:14:36,250 --> 00:14:39,560
stop that and understand or alert on it?

201
00:14:41,230 --> 00:14:44,890
So the atomic red team is a pretty fantastic project,

202
00:14:44,960 --> 00:14:48,186
which is done from Red Canary. What they

203
00:14:48,208 --> 00:14:51,514
have done is they've actually created individual

204
00:14:51,632 --> 00:14:55,914
tests for each of these specific miter attack ids.

205
00:14:56,042 --> 00:14:59,678
So what that means is that for a specific attack

206
00:14:59,764 --> 00:15:03,680
id we can actually find the individual

207
00:15:04,770 --> 00:15:08,634
smallest unit of testing for that very specific

208
00:15:08,772 --> 00:15:12,610
attack id. And when we're talking the smallest unit, that's where

209
00:15:12,680 --> 00:15:16,306
the atomic kind of comes from, right. We're looking at the

210
00:15:16,328 --> 00:15:19,730
smallest piece for us to be able to test just that one

211
00:15:19,800 --> 00:15:23,286
very specific thing. That way we can control and understand

212
00:15:23,388 --> 00:15:27,542
how our systems are reacting to it. So 294

213
00:15:27,596 --> 00:15:31,122
of the 750 attack ids are covered right now.

214
00:15:31,196 --> 00:15:35,702
It is an open source project so anyone is able to contribute

215
00:15:35,766 --> 00:15:37,850
or modify any of the tests.

216
00:15:38,750 --> 00:15:41,962
There are over 1500 tests available right

217
00:15:42,016 --> 00:15:45,722
now and that does sound a little weird, right?

218
00:15:45,856 --> 00:15:49,146
Why are there one 5000 hundred tests for 294 attack ids?

219
00:15:49,258 --> 00:15:53,386
The reason is because the attack ids, they're not necessarily

220
00:15:53,578 --> 00:15:56,894
specific to an operating system where the

221
00:15:56,932 --> 00:16:00,562
actual individual tests, they can test for many

222
00:16:00,616 --> 00:16:04,158
different ways that an attack id can be leveraged

223
00:16:04,174 --> 00:16:07,506
by a threat actor, as well as many different ways that the

224
00:16:07,528 --> 00:16:11,614
attack ids are covered throughout different operating

225
00:16:11,662 --> 00:16:15,380
systems. So there's a lot of very interesting ways for

226
00:16:15,830 --> 00:16:19,442
us to be able to review how to test these and see

227
00:16:19,496 --> 00:16:22,966
exactly how this activity meets

228
00:16:22,998 --> 00:16:26,650
up and is working inside of the miter attack framework.

229
00:16:28,190 --> 00:16:31,786
So when we go to the atomic red team website we can

230
00:16:31,808 --> 00:16:35,774
actually see that they have a huge list of the atomics, the 1500

231
00:16:35,812 --> 00:16:39,390
that we were talking about. Lots of really fun stuff,

232
00:16:39,460 --> 00:16:42,906
right? Like stealing application access tokens or clearing

233
00:16:42,938 --> 00:16:46,142
mailbox data, right? So all these cool things

234
00:16:46,196 --> 00:16:50,098
and then when we actually click on them we can see how we can actually

235
00:16:50,184 --> 00:16:53,902
test that activity as well. So really exciting

236
00:16:53,966 --> 00:16:57,538
stuff. There's a lot of very interesting ones.

237
00:16:57,704 --> 00:17:01,430
So I really highly recommend taking your time

238
00:17:01,580 --> 00:17:06,098
looking through these, trying to understand which ones are interesting, which ones aren't,

239
00:17:06,274 --> 00:17:09,686
and then all of these are available on GitHub as well.

240
00:17:09,788 --> 00:17:13,334
And they are available in Powershell so we can actually download

241
00:17:13,382 --> 00:17:16,906
them and launch them interactively via Powershell as well

242
00:17:16,928 --> 00:17:20,620
as always just copy pasting them directly from this website.

243
00:17:21,390 --> 00:17:25,214
Please note that if you do download the Powershell that

244
00:17:25,412 --> 00:17:28,634
your windows defender or edrs will very likely

245
00:17:28,682 --> 00:17:32,366
start lighting them up because it's legitimately trying to

246
00:17:32,388 --> 00:17:35,166
do actions that threat actors are taking,

247
00:17:35,348 --> 00:17:38,986
right? So we would expect that our EDR finds

248
00:17:39,018 --> 00:17:41,540
it and stops it, which is a good thing.

249
00:17:41,910 --> 00:17:44,754
If you do want to test these, then we're going to need to be able

250
00:17:44,792 --> 00:17:48,434
to do things like allow list those

251
00:17:48,472 --> 00:17:51,894
specific Powershell scripts or the scripts that are being

252
00:17:51,932 --> 00:17:55,766
used to test this activity. And then we can launch those

253
00:17:55,788 --> 00:17:59,942
tests and see how the environment reacts and

254
00:17:59,996 --> 00:18:02,300
what we can see in our detections or not.

255
00:18:03,390 --> 00:18:06,666
So this also gets into how can

256
00:18:06,688 --> 00:18:09,542
we do breach attack simulation on a budget,

257
00:18:09,606 --> 00:18:13,066
right? And going back to what we were saying

258
00:18:13,088 --> 00:18:16,960
at the start of this presentation, there's a lot of

259
00:18:17,810 --> 00:18:21,598
ways that we can try to test

260
00:18:21,684 --> 00:18:25,294
this activity. And a lot of organizations may not have either

261
00:18:25,332 --> 00:18:28,914
the expertise, the time or the funding to be able to pay

262
00:18:28,952 --> 00:18:32,462
for a full red team and penetration testing assessment,

263
00:18:32,526 --> 00:18:36,114
all this fun stuff. So what we can do is

264
00:18:36,232 --> 00:18:40,182
use the atomic Red team and actually read

265
00:18:40,236 --> 00:18:43,270
intelligence reports and find out where these things

266
00:18:43,340 --> 00:18:47,474
map up with each other and how we can effectively

267
00:18:47,522 --> 00:18:51,782
emulate threat actors based on intelligence reporting.

268
00:18:51,926 --> 00:18:55,914
So if you've never read a joint cyber advisory or these

269
00:18:55,952 --> 00:18:59,386
other types of advisories posted by the

270
00:18:59,408 --> 00:19:04,074
NSA, scissor, all these huge cyber

271
00:19:04,122 --> 00:19:08,158
agencies, I really do highly recommend it. It's some pretty interesting

272
00:19:08,244 --> 00:19:11,358
stuff where we can actually read through exactly

273
00:19:11,444 --> 00:19:15,040
how state sponsored cyber actors are

274
00:19:15,650 --> 00:19:19,682
moving throughout an environment and leveraging live off the land

275
00:19:19,736 --> 00:19:24,062
tools or different types of malware and how they leverage

276
00:19:24,126 --> 00:19:27,620
that activity. So I really recommend taking a look through there

277
00:19:28,230 --> 00:19:31,846
inside of the reports, they actually do reference the specific

278
00:19:31,948 --> 00:19:35,462
miter attack ids that are used throughout the

279
00:19:35,596 --> 00:19:39,286
actual attacks. And then we can take

280
00:19:39,308 --> 00:19:42,978
a look and see hey, these attack ids,

281
00:19:43,154 --> 00:19:46,474
let's look them up in the atomic red team. I want to make sure

282
00:19:46,512 --> 00:19:49,626
that we can defend against it, right?

283
00:19:49,728 --> 00:19:52,860
So we open up the atomic red team and then we can see hey,

284
00:19:53,550 --> 00:19:57,466
there is a specific atomic test which allows

285
00:19:57,498 --> 00:20:00,974
us to look and see if Seatbelt will be run.

286
00:20:01,092 --> 00:20:04,766
And if you're not familiar, Seatbelt is a c sharp project

287
00:20:04,868 --> 00:20:08,754
which does a bunch of kind of safety checks on a

288
00:20:08,792 --> 00:20:13,262
machine. And I enjoy using this from the offensive perspective

289
00:20:13,406 --> 00:20:17,090
and I do recommend that people use it on the defensive side because

290
00:20:17,160 --> 00:20:20,246
it helps look for specific vulnerabilities or

291
00:20:20,268 --> 00:20:24,166
misconfigurations. So what we can see is at the

292
00:20:24,188 --> 00:20:27,526
bottom of this specific slide we do have some

293
00:20:27,548 --> 00:20:31,160
powershell where it'll try to download the specific

294
00:20:31,710 --> 00:20:35,734
seatbelt from GitHub

295
00:20:35,862 --> 00:20:39,494
and then it'll try to import it and then execute

296
00:20:39,542 --> 00:20:43,514
it. So what we can see though, I did run

297
00:20:43,552 --> 00:20:46,734
this on a test machine and I can see that,

298
00:20:46,772 --> 00:20:50,014
hey, when I download this and run it, invoke the

299
00:20:50,052 --> 00:20:53,854
expression that it does give an error which says this

300
00:20:53,892 --> 00:20:57,886
script contains malicious content and has been blocked by your antivirus software.

301
00:20:57,998 --> 00:21:01,486
And this was just Windows defender, pretty vanilla

302
00:21:01,518 --> 00:21:04,706
stuff on an endpoint. This is good,

303
00:21:04,808 --> 00:21:08,698
right? We want to make sure that, hey, if a threat actor got onto

304
00:21:08,734 --> 00:21:12,082
my asset and tried to specifically

305
00:21:12,146 --> 00:21:16,946
download and run this PS

306
00:21:16,978 --> 00:21:20,886
one script inside of memory, that it would be stopped. So that is

307
00:21:20,908 --> 00:21:24,682
one way for us to be able to see this and make sure that,

308
00:21:24,816 --> 00:21:28,540
hey, this is how we can stop that, right?

309
00:21:28,910 --> 00:21:32,426
And then there's always things like dumping the

310
00:21:32,448 --> 00:21:36,080
active directory database with NTDs util and

311
00:21:36,450 --> 00:21:39,966
going back to the joint cyber advisory. These are live off the

312
00:21:39,988 --> 00:21:44,058
land binaries. These are legitimate binaries through Microsoft

313
00:21:44,154 --> 00:21:48,450
that we use to administer and conduct operations.

314
00:21:49,030 --> 00:21:52,594
So what we don't want to do or see

315
00:21:52,632 --> 00:21:57,086
is having people dump the NTDS database.

316
00:21:57,198 --> 00:22:01,002
Very often that's something that we want to be able to specifically

317
00:22:01,086 --> 00:22:04,534
understand and make sure that we can account for every time it

318
00:22:04,572 --> 00:22:07,858
happens. Because if you're not familiar the NTDs,

319
00:22:08,034 --> 00:22:11,714
it contains all of the password hashes for the entire active directory

320
00:22:11,762 --> 00:22:14,698
domain. And if you have all of those, you can do quite a bit of

321
00:22:14,704 --> 00:22:18,202
damage and lock people

322
00:22:18,256 --> 00:22:21,002
out or gain access to the sensitive data,

323
00:22:21,136 --> 00:22:25,134
launch the ransomware, you name it. So anytime that

324
00:22:25,172 --> 00:22:28,894
we are gathering a copy of this activity, we always

325
00:22:28,932 --> 00:22:32,606
want to make sure that we get alerted and we can identify it.

326
00:22:32,788 --> 00:22:35,674
So running the NTDs util,

327
00:22:35,722 --> 00:22:39,506
ACI, TDs, that whole string at the bottom,

328
00:22:39,688 --> 00:22:43,154
that allows us to actually run

329
00:22:43,192 --> 00:22:46,638
that and see, okay, do our detections tools

330
00:22:46,734 --> 00:22:49,774
find this and do they stop it? And if they don't,

331
00:22:49,902 --> 00:22:53,654
how do we change that and make sure that we

332
00:22:53,692 --> 00:22:56,626
do get alerts or it does stop it on purpose?

333
00:22:56,738 --> 00:23:00,470
Because again, this is a very critical action that threat actors take.

334
00:23:00,620 --> 00:23:04,634
And if we can get alerted or stop it anytime it

335
00:23:04,672 --> 00:23:08,682
happens, even if it does happen in a legitimate sense, we can create

336
00:23:08,736 --> 00:23:12,538
those individual detections, especially for something like this,

337
00:23:12,704 --> 00:23:16,286
to make sure that we have that positive control over these

338
00:23:16,308 --> 00:23:17,470
types of attacks.

339
00:23:19,570 --> 00:23:23,070
So as far as in conclusion, we definitely want to

340
00:23:23,140 --> 00:23:26,538
embrace that intelligence. The NSA,

341
00:23:26,634 --> 00:23:29,342
scissor, all those joint cyber advisories,

342
00:23:29,486 --> 00:23:33,586
really highly recommend taking a read through them and understanding them.

343
00:23:33,768 --> 00:23:37,586
That way we can find out exactly what the threat actors are doing

344
00:23:37,688 --> 00:23:42,222
and how they are leveraging different tactics

345
00:23:42,286 --> 00:23:45,878
and procedures within the Mitre attack framework. And then

346
00:23:45,964 --> 00:23:49,510
we can identify the gaps inside of our own organization.

347
00:23:49,850 --> 00:23:53,562
When we can find those gaps, we can tune our

348
00:23:53,696 --> 00:23:56,954
detections and preventions. That way we can make sure

349
00:23:56,992 --> 00:24:00,438
that, hey, this actually stops this malicious activity.

350
00:24:00,534 --> 00:24:04,634
And we can feel confident that based on the cyber

351
00:24:04,682 --> 00:24:08,800
threat reporting through the NSA that

352
00:24:09,250 --> 00:24:12,890
the specific tactics that Volt Typhoon

353
00:24:12,970 --> 00:24:16,346
was doing that was reported on, we would be able to be alerted

354
00:24:16,378 --> 00:24:19,250
on or prevented based on that activity.

355
00:24:19,670 --> 00:24:23,806
So we can do that iterative process of tuning

356
00:24:23,838 --> 00:24:27,234
the detections and then rerunning it. That way we can keep

357
00:24:27,272 --> 00:24:31,138
using those atomics over and over until we feel confident that we have

358
00:24:31,304 --> 00:24:35,170
our detections and preventions in a much better spot.

359
00:24:36,950 --> 00:24:40,242
So if you have any questions, please reach

360
00:24:40,296 --> 00:24:43,354
out. Let me know if you have them. I love talking with people. This is

361
00:24:43,472 --> 00:24:46,966
a lot of fun. Again, I am the offensive security practice

362
00:24:46,998 --> 00:24:50,554
lead at strongcrypto. That's my email. You can shoot me an email if you have

363
00:24:50,592 --> 00:24:54,554
questions. I'm on LinkedIn. Love chatting about this stuff. And then I

364
00:24:54,592 --> 00:24:58,426
do have some references as well. So again,

365
00:24:58,528 --> 00:25:01,386
thank you for your time. I hope you learned a lot. Please let me know

366
00:25:01,408 --> 00:25:04,742
if you have any questions and enjoy the rest of the conference.

367
00:25:04,886 --> 00:25:05,080
Thanks.

