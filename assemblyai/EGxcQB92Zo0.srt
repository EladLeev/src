1
00:00:23,290 --> 00:00:26,646
Hello and welcome. My name is Gareth and I'm pleased to be here today to

2
00:00:26,668 --> 00:00:30,390
talk about exploring Chat GPT for improved observability.

3
00:00:31,210 --> 00:00:35,378
So why do we care about observability? Well, Werner Fogels,

4
00:00:35,394 --> 00:00:38,598
the CTO of Amazon, famously said everything

5
00:00:38,684 --> 00:00:41,874
fails all the time. He was emphasizing

6
00:00:41,922 --> 00:00:45,110
the importance of designing systems that can handle failures.

7
00:00:45,450 --> 00:00:49,250
With this in mind, it's critical to plan and deploy a comprehensive

8
00:00:49,410 --> 00:00:52,602
observability. The solution when designing,

9
00:00:52,666 --> 00:00:56,254
building and operating our software solutions, we need to take into account the fact that

10
00:00:56,292 --> 00:00:59,770
modern platforms are largely ephemeral in nature.

11
00:00:59,930 --> 00:01:03,990
They are highly dynamic and constantly evolving. Modern platforms

12
00:01:04,010 --> 00:01:07,534
like the hyperscalers make customers responsible for ensuring

13
00:01:07,582 --> 00:01:11,470
their solutions are architected in a way that achieves their required

14
00:01:11,550 --> 00:01:14,850
reliability. Let's take a look at some of the major outages

15
00:01:15,190 --> 00:01:18,360
which occurred in 2022 which may have affected customers.

16
00:01:20,490 --> 00:01:24,166
In January 2022, Google Cloud performed a

17
00:01:24,188 --> 00:01:28,186
routine maintenance event which in the end went wrong

18
00:01:28,288 --> 00:01:31,654
in the US west region. It caused increased

19
00:01:31,702 --> 00:01:34,922
latency for 3 hours and 22 minutes. This affected Google

20
00:01:34,976 --> 00:01:38,806
Cloud networking, DNS cloud run spanner

21
00:01:38,838 --> 00:01:41,982
and compute engine. In March 2022,

22
00:01:42,036 --> 00:01:44,910
Google Cloud again experienced an outage.

23
00:01:45,410 --> 00:01:49,402
This time it was Google's traffic director which experienced

24
00:01:49,466 --> 00:01:52,782
elevated service errors for 2 hours and 35 minutes.

25
00:01:52,916 --> 00:01:56,142
This was caused by a change in the traffic director code that processes

26
00:01:56,206 --> 00:02:00,194
the configuration. It also impacted a number of large customers like

27
00:02:00,232 --> 00:02:03,106
Spotify and Discord amongst others.

28
00:02:03,288 --> 00:02:06,818
In June 2022, Azure had an outage

29
00:02:06,914 --> 00:02:10,598
where customers had trouble connecting to resources hosted in

30
00:02:10,684 --> 00:02:14,006
east US two. According to Microsoft, this was due to

31
00:02:14,028 --> 00:02:17,958
an unplanned power oscillation. The issue lasted

32
00:02:17,974 --> 00:02:21,414
for around 12 hours. It affected application insights,

33
00:02:21,462 --> 00:02:25,002
log analytics manager, identity service media services

34
00:02:25,136 --> 00:02:29,126
and NetApp files. In July, a heat

35
00:02:29,158 --> 00:02:32,606
wave caused cooling systems to malfunction at data centers in

36
00:02:32,628 --> 00:02:35,902
London. This affected both Google Cloud and

37
00:02:35,956 --> 00:02:39,678
Oracle. Also in July, AWS suffered a

38
00:02:39,684 --> 00:02:42,854
power failure in its eastern zone,

39
00:02:43,002 --> 00:02:46,542
US east one, the outage affected connectivity

40
00:02:46,606 --> 00:02:50,254
to and from the region and brought down Amazon's EC.

41
00:02:50,302 --> 00:02:53,474
Two instances this impacted applications of

42
00:02:53,512 --> 00:02:56,274
customers such as Webex,

43
00:02:56,402 --> 00:03:00,294
Okta, Splunk and Bamboo HR amongst others.

44
00:03:00,492 --> 00:03:04,166
In September, Google Cloud again suffered an

45
00:03:04,188 --> 00:03:07,542
outage, this time with its cloud file store list

46
00:03:07,596 --> 00:03:10,998
instances API which started to fail with an error

47
00:03:11,014 --> 00:03:14,294
code four to nine globally. Apparently,

48
00:03:14,342 --> 00:03:17,786
this outage was triggered by an internal Google service which

49
00:03:17,808 --> 00:03:21,962
was managing a large number of Google projects. It malfunctioned

50
00:03:22,026 --> 00:03:25,518
and overloaded the file store API with requests. These are

51
00:03:25,524 --> 00:03:30,126
just some of the major outages, but every day

52
00:03:30,308 --> 00:03:33,838
there are minor outages occurring on the hyperscalers,

53
00:03:33,934 --> 00:03:37,262
so keep in mind that you need to architect your solution.

54
00:03:37,326 --> 00:03:40,974
You're responsible for architecting your solution to achieve

55
00:03:41,102 --> 00:03:44,450
your required reliability goals.

56
00:03:45,270 --> 00:03:48,850
Gartner estimated the average cost

57
00:03:48,920 --> 00:03:52,870
of downtime RT downtime per minute was $5,600

58
00:03:52,940 --> 00:03:55,270
in 2014.

59
00:03:57,050 --> 00:04:01,066
Over the years, this number has been steadily rising. According to

60
00:04:01,088 --> 00:04:05,386
Pingdom, today it can cost as much as $260,000

61
00:04:05,408 --> 00:04:08,662
an hour in the manufacturing

62
00:04:08,726 --> 00:04:12,810
industry, $450,000 in the it industry,

63
00:04:12,970 --> 00:04:16,270
$3 million in the auto industry,

64
00:04:16,610 --> 00:04:20,250
and up to $5 million in enterprise industries.

65
00:04:20,410 --> 00:04:23,490
So a number of factors play a role in these costs,

66
00:04:24,070 --> 00:04:27,906
those being the size of the business, the industry vertical, as well

67
00:04:27,928 --> 00:04:32,580
as the business model. Today's observability challenges are

68
00:04:33,110 --> 00:04:37,042
complexity. So we've introduced multicloud environments,

69
00:04:37,106 --> 00:04:40,790
which are increasingly complex, and many

70
00:04:40,860 --> 00:04:44,438
legacy observability platforms are not able to keep up.

71
00:04:44,524 --> 00:04:47,902
The volume of data and subsequent alerts has also exploded

72
00:04:47,986 --> 00:04:51,690
in recent years. It's resulting in lost signals

73
00:04:52,270 --> 00:04:55,350
as well as alert fatigue for operations teams.

74
00:04:55,510 --> 00:04:59,574
We also have challenges around silos within organizations where infra,

75
00:04:59,622 --> 00:05:03,566
dev Ops, and business teams cause many

76
00:05:03,668 --> 00:05:06,894
key insights to become lost or surfaced too late because

77
00:05:06,932 --> 00:05:10,382
they don't talk to each other. Correlation is also a challenge for many

78
00:05:10,436 --> 00:05:13,598
customers. So we need to realize what actions,

79
00:05:13,694 --> 00:05:17,486
features, apps and experiences actually drive business impact.

80
00:05:17,598 --> 00:05:20,850
For most customers, this is a very challenging thing to do.

81
00:05:21,000 --> 00:05:24,514
Unfortunately, risks of iT outages are expected to

82
00:05:24,552 --> 00:05:28,018
increase in 2023. This is largely due

83
00:05:28,034 --> 00:05:31,666
to the fact of the current economic

84
00:05:31,698 --> 00:05:34,870
climate as well as tech layoffs which are occurring.

85
00:05:35,530 --> 00:05:38,158
So in 2023 alone,

86
00:05:38,354 --> 00:05:42,170
715 companies have laid off around

87
00:05:42,240 --> 00:05:45,302
200,000 employees. This results

88
00:05:45,366 --> 00:05:48,662
in a loss of institutional knowledge and expertise

89
00:05:48,726 --> 00:05:52,414
for these companies and other challenges due to

90
00:05:52,452 --> 00:05:56,650
economic concerns and cost reductions.

91
00:05:56,810 --> 00:06:00,170
So what do customers actually look for in their modern observability

92
00:06:00,250 --> 00:06:04,194
solutions? Customers are increasingly looking for cost effective and

93
00:06:04,232 --> 00:06:08,162
unified observability platforms that can help them monitor and manage

94
00:06:08,216 --> 00:06:12,206
their complex it environments. They also expect their monitoring

95
00:06:12,318 --> 00:06:15,782
solution to not only provide

96
00:06:15,916 --> 00:06:18,770
real time visibility into their systems,

97
00:06:18,850 --> 00:06:22,566
but also to leverage machine learning and AI to

98
00:06:22,588 --> 00:06:25,810
predict potential issues before they occur.

99
00:06:25,970 --> 00:06:29,562
AI alerting is also something that businesses are looking

100
00:06:29,616 --> 00:06:32,730
for, essentially to reduce

101
00:06:35,390 --> 00:06:39,194
alert fatigue, and this also allows them to

102
00:06:39,312 --> 00:06:43,406
proactively address potential issues before they become major problems.

103
00:06:43,588 --> 00:06:47,514
Correlation to causation analysis also helps customers to identify

104
00:06:47,562 --> 00:06:51,134
the root cause of issues and incidents, allowing them to quickly resolve problems

105
00:06:51,252 --> 00:06:55,074
and minimize downtime. So there's a lot of innovation happening

106
00:06:55,112 --> 00:06:58,420
in the AI and large language model space.

107
00:06:59,270 --> 00:07:02,494
So what are large language models? So large language

108
00:07:02,542 --> 00:07:06,038
models are a type of AI that can process and understand

109
00:07:06,124 --> 00:07:09,734
human language. These models are trained on massive amounts of text

110
00:07:09,772 --> 00:07:13,014
data, such as books, articles, and websites. They use

111
00:07:13,052 --> 00:07:17,286
complex algorithms and neural networks to learn the

112
00:07:17,308 --> 00:07:21,318
patterns and structures of the language, allowing them to generate humanlike

113
00:07:21,334 --> 00:07:24,742
responses essentially to text based queries.

114
00:07:24,886 --> 00:07:28,454
Large language models have a wide range of applications, including natural language

115
00:07:28,502 --> 00:07:32,826
processing, chat bots, and language translation,

116
00:07:33,018 --> 00:07:36,602
amongst others. Some of the most well known language models

117
00:07:36,666 --> 00:07:40,894
include GPT-3 Bert, and some

118
00:07:40,932 --> 00:07:44,754
others. Like Chat GPT. These models have been used to create

119
00:07:44,792 --> 00:07:48,302
chat bots that can hold conversations with humans,

120
00:07:48,366 --> 00:07:52,180
generate realistic text, and even write news articles. However,

121
00:07:52,710 --> 00:07:56,838
there are some concerns around the ethical implications of large

122
00:07:57,004 --> 00:08:01,042
language models, such as their potential to perpetuate biases

123
00:08:01,106 --> 00:08:05,382
and misinformation. Okay, so large

124
00:08:05,436 --> 00:08:09,558
language models leverage deep neural networks.

125
00:08:09,734 --> 00:08:13,334
Deep neural networks attempt to imitate brainlike functionality.

126
00:08:13,462 --> 00:08:16,698
Now, neural networks have been around for some time.

127
00:08:16,864 --> 00:08:20,026
They are algorithms which are essentially modeled after the

128
00:08:20,048 --> 00:08:22,762
brain that are designed to recognize patterns.

129
00:08:22,906 --> 00:08:26,410
They interpret sensory data through machine perception.

130
00:08:26,570 --> 00:08:29,882
The patterns they recognize are numerical in nature.

131
00:08:30,026 --> 00:08:33,778
This is what all real world data must be translated into.

132
00:08:33,944 --> 00:08:37,070
In the diagram on the left hand side, you can see a deep neural network.

133
00:08:37,150 --> 00:08:41,506
So deep learning occurs when you use

134
00:08:41,688 --> 00:08:45,534
stacked neural networks, that is, networks composed

135
00:08:45,582 --> 00:08:49,314
of several layers. The layers are made of nodes,

136
00:08:49,442 --> 00:08:53,154
and on the right hand side, we can see one of those nodes magnified.

137
00:08:53,282 --> 00:08:56,486
A node is a place where computation happens.

138
00:08:56,668 --> 00:09:00,680
It's loosely patterned, and it fires when it

139
00:09:01,050 --> 00:09:05,222
encounters sufficient stimuli. A node combines input

140
00:09:05,366 --> 00:09:08,874
from the data with a set of weights that

141
00:09:08,912 --> 00:09:12,270
either amplify or dampen that input,

142
00:09:12,930 --> 00:09:17,002
therefore assigning significance to inputs.

143
00:09:17,146 --> 00:09:19,760
So we can see that we feed it an image of a dog.

144
00:09:20,370 --> 00:09:24,034
It runs through the neural network and it

145
00:09:24,072 --> 00:09:27,950
detects it's a dog. Large deep

146
00:09:28,030 --> 00:09:31,570
neural network models are pretrained from the whole Internet.

147
00:09:32,550 --> 00:09:35,910
This requires a significant amount of effort and engineering.

148
00:09:37,210 --> 00:09:41,202
Initially, you need to prepare the data. This includes

149
00:09:41,266 --> 00:09:44,360
actually selecting the data that you would use, filtering it,

150
00:09:44,890 --> 00:09:47,720
deduplication of the data,

151
00:09:48,990 --> 00:09:53,190
redaction. So essentially removing PII,

152
00:09:53,350 --> 00:09:57,126
and finally tokenization. We then adjust the billions

153
00:09:57,158 --> 00:10:00,406
of parameters to ensure

154
00:10:00,518 --> 00:10:04,046
that our model returns the expected results. As you can

155
00:10:04,068 --> 00:10:08,702
see, for GPD one, it had 117,000,000

156
00:10:08,756 --> 00:10:11,966
parameters, but GPD three, which is a fairly new

157
00:10:11,988 --> 00:10:16,130
model, has 175,000,000,000 parameters.

158
00:10:16,470 --> 00:10:20,530
Finally, we need to actually reinforce the learning with human feedback.

159
00:10:21,590 --> 00:10:26,402
So we see in the diagram on the left hand side that outputs

160
00:10:26,466 --> 00:10:30,866
from a neural network are awarded by human labeler. So this incentivizes

161
00:10:30,898 --> 00:10:34,726
the model or the neural network to

162
00:10:34,748 --> 00:10:38,438
favor those outputs over others. These models

163
00:10:38,454 --> 00:10:42,634
are extremely expensive in energy costs to

164
00:10:42,672 --> 00:10:46,218
train, so it can cost in excess of $20 million

165
00:10:46,384 --> 00:10:51,530
in energy costs. This is an important caveat.

166
00:10:51,690 --> 00:10:54,906
Okay, here we can see some of the data sets

167
00:10:54,938 --> 00:10:58,746
which were used to train the various open AI models

168
00:10:58,778 --> 00:11:03,138
right in the family. So GPT one took around

169
00:11:03,304 --> 00:11:06,542
4.8gb of unfiltered data, GPT,

170
00:11:06,606 --> 00:11:09,746
240 gigabytes of human filtered data.

171
00:11:09,928 --> 00:11:13,886
And finally, GPT-3 has 570gb

172
00:11:13,918 --> 00:11:17,320
of filtered data from 45 terabytes of raw data.

173
00:11:18,170 --> 00:11:21,590
Chat GPT, which is the focus of this session,

174
00:11:22,090 --> 00:11:25,894
is a version of GPT 3.5. It's fine

175
00:11:25,932 --> 00:11:30,230
tuned on dialogue, using 175,000,000,000 parameters,

176
00:11:30,390 --> 00:11:33,674
so Chat GPT can understand and respond to a wide range of

177
00:11:33,712 --> 00:11:37,606
user queries, from simple questions to complex conversations.

178
00:11:37,718 --> 00:11:40,974
It can also generate humanlike responses and

179
00:11:41,012 --> 00:11:44,782
adapt to the human's language and

180
00:11:44,836 --> 00:11:48,462
tone as well. Chat GPT has been used in various applications, such as

181
00:11:48,516 --> 00:11:52,122
customer service, education, and entertainment.

182
00:11:52,266 --> 00:11:56,222
So typical language models use next token

183
00:11:56,366 --> 00:12:00,254
prediction, or mast language modeling,

184
00:12:00,382 --> 00:12:04,370
to predict the next word in a sequence. There are limitations

185
00:12:04,970 --> 00:12:09,206
to these two approaches. So limitations are they

186
00:12:09,228 --> 00:12:13,014
are unable to fully understand the context. Another is

187
00:12:13,132 --> 00:12:17,390
inputs are processed sequentially on an individual basis.

188
00:12:17,570 --> 00:12:22,086
What OpenAI and GPT essentially

189
00:12:22,278 --> 00:12:26,346
brought to the table was that they

190
00:12:26,368 --> 00:12:30,006
were designed as an

191
00:12:30,048 --> 00:12:32,400
autoregressive language model.

192
00:12:33,650 --> 00:12:37,486
So this uses previous words to predict the next word

193
00:12:37,508 --> 00:12:41,514
in the sequence. This means they use previous words to predict

194
00:12:41,562 --> 00:12:45,806
the next word in the sequence. They also leverage the transformer

195
00:12:45,838 --> 00:12:48,914
architecture, which is a deep learning model that

196
00:12:48,952 --> 00:12:51,330
adopts the mechanism of self attention,

197
00:12:51,670 --> 00:12:55,206
so differentially weighting the significance of

198
00:12:55,228 --> 00:12:56,760
each part of the input data.

199
00:12:58,730 --> 00:13:02,806
In fact, Chat GPT is able to process

200
00:13:02,908 --> 00:13:06,482
all input data simultaneously. So Chat GPT

201
00:13:06,546 --> 00:13:09,786
is a generative AI that uses the ability to

202
00:13:09,808 --> 00:13:14,330
learn, which has the ability to learn, sorry, and make decisions.

203
00:13:14,830 --> 00:13:18,406
But this does not mean that it's Skynet.

204
00:13:18,518 --> 00:13:21,898
There are some key differences between the two. Skynet is

205
00:13:21,904 --> 00:13:25,690
a fictional AI system that was created to control military, weapons and defense systems.

206
00:13:25,770 --> 00:13:29,786
It became self aware and decided that humans were a threat to existence.

207
00:13:29,898 --> 00:13:33,358
This led to a war between humans and machines. Skynet is often

208
00:13:33,524 --> 00:13:37,498
portrayed as a malevant force that seeks to destroy humanity.

209
00:13:37,594 --> 00:13:41,614
So chatgpt and generated AI models. They're used in a variety

210
00:13:41,662 --> 00:13:45,374
of applications, such as image and text generation, a far

211
00:13:45,432 --> 00:13:49,446
cry from what Skynet supposedly could do in

212
00:13:49,548 --> 00:13:52,834
Terminator. They are trained on large data sets

213
00:13:52,882 --> 00:13:57,042
and can generate new content that is similar to the original data. Generative AI

214
00:13:57,186 --> 00:14:00,502
models are not inherently good or evil,

215
00:14:00,646 --> 00:14:04,330
but their use can have ethical implications.

216
00:14:05,150 --> 00:14:08,694
While there are some similarities between the two, they are fundamentally

217
00:14:08,742 --> 00:14:12,606
different, and we

218
00:14:12,628 --> 00:14:15,520
still have a way to go to reach Skynet level.

219
00:14:17,490 --> 00:14:21,338
It's always important to consider ethical implications when leveraging AI

220
00:14:21,434 --> 00:14:25,102
in any application, including with generative AI

221
00:14:25,246 --> 00:14:29,380
models. So luckily, chat GPD is not perfect. As I mentioned,

222
00:14:31,430 --> 00:14:35,810
it can on occasions return nonsensical responses.

223
00:14:35,970 --> 00:14:38,710
It's sensitive to minor changes in prompting,

224
00:14:39,290 --> 00:14:42,754
it's excessively verbose and overuses

225
00:14:42,802 --> 00:14:45,670
phrases, and it's challenged by ambiguity.

226
00:14:47,210 --> 00:14:50,646
Another issue is that it's susceptible to prompt hacking

227
00:14:50,678 --> 00:14:54,586
or injection, so we have to take care when

228
00:14:54,608 --> 00:14:55,850
designing our prompts.

229
00:14:58,990 --> 00:15:02,974
Okay, so how can we use Chat GPT in our

230
00:15:03,012 --> 00:15:05,600
observability solutions? Well,

231
00:15:06,210 --> 00:15:09,360
there are many things that we could use it for,

232
00:15:09,810 --> 00:15:13,154
for instance, conversational UI. So using

233
00:15:13,192 --> 00:15:16,660
natural language is a very comfortable way for users to query data.

234
00:15:17,670 --> 00:15:21,310
Also code generation. So Chat GPT

235
00:15:21,390 --> 00:15:25,380
could support developers and operation engineers when writing scripts in code.

236
00:15:27,850 --> 00:15:31,282
Another area which is very interesting for us is intelligent

237
00:15:31,346 --> 00:15:34,658
problem remediation. So Chat

238
00:15:34,674 --> 00:15:38,410
GPT essentially is suggesting ways to resolve problems in custom

239
00:15:38,480 --> 00:15:42,070
code. Finally, we could look at enriching

240
00:15:42,150 --> 00:15:46,278
observability context using Chat GPT. So this means we will enrich

241
00:15:46,374 --> 00:15:50,926
problem tickets or alerts using Chat GPT to

242
00:15:50,948 --> 00:15:54,922
provide additional context and essentially driving more effective

243
00:15:55,066 --> 00:15:56,110
remediation.

244
00:15:59,810 --> 00:16:03,898
Keep in mind that Chat GPT's responses are non deterministic.

245
00:16:04,074 --> 00:16:06,980
You can see on the left hand side,

246
00:16:08,310 --> 00:16:11,460
I prompted Chat GPT with a question,

247
00:16:12,790 --> 00:16:15,880
and then I prompted it again with the same question.

248
00:16:17,610 --> 00:16:21,606
We can see a number of differences. Although at first glance it looks like

249
00:16:21,628 --> 00:16:23,270
it produced the same output,

250
00:16:28,830 --> 00:16:33,418
I would say that humans expect it,

251
00:16:33,504 --> 00:16:37,270
systems or computers, to be deterministic.

252
00:16:37,430 --> 00:16:40,410
Now, if we had to integrate this into our solutions,

253
00:16:41,810 --> 00:16:45,290
operations engineers might be thrown

254
00:16:45,370 --> 00:16:49,070
off by the fact that it produces different guidance

255
00:16:50,210 --> 00:16:53,586
based on the same input. We need to do

256
00:16:53,608 --> 00:16:57,330
some work to make sure that users of our systems

257
00:16:58,310 --> 00:17:01,890
understand and receive the correct

258
00:17:01,960 --> 00:17:03,860
output every time.

259
00:17:07,830 --> 00:17:11,366
Also, to make informed decisions, Chat GPT needs to

260
00:17:11,388 --> 00:17:15,590
build up a lot of context, and that's in the form of essentially

261
00:17:16,170 --> 00:17:19,818
prompt and completion or question and answer. You'll see this

262
00:17:19,984 --> 00:17:23,050
thread, this chat thread that I has with Chat GPT,

263
00:17:23,470 --> 00:17:27,478
where I asked it why I was experiencing

264
00:17:27,574 --> 00:17:30,960
additional latency between layers in my application.

265
00:17:31,650 --> 00:17:34,110
Now, it was very verbose initially,

266
00:17:34,770 --> 00:17:38,266
and as I drilled down into specific areas,

267
00:17:38,298 --> 00:17:41,326
it asked more and more questions, right? Eventually you would get to the

268
00:17:41,348 --> 00:17:45,402
answer, but you can't expect engineers

269
00:17:45,546 --> 00:17:49,154
or operations teams to do this every single time to solve every

270
00:17:49,192 --> 00:17:52,450
problem. It just takes too long. And this

271
00:17:52,600 --> 00:17:55,650
basically means that, well, as a result,

272
00:17:55,800 --> 00:17:59,574
we need to ensure that we engineer our prompts very

273
00:17:59,612 --> 00:18:04,166
well using guidance. You'll see later in the next slide to

274
00:18:04,188 --> 00:18:07,560
ensure that we get the right answers as quickly as possible.

275
00:18:10,830 --> 00:18:13,770
So as I mentioned, prompt engineering is important. So this is,

276
00:18:13,840 --> 00:18:16,938
in my mind a new discipline, and there are a

277
00:18:16,944 --> 00:18:19,260
number of things that you should keep in mind.

278
00:18:20,110 --> 00:18:23,694
There's a lot of guidance out there. In this case, I'm looking at

279
00:18:23,732 --> 00:18:25,390
guidance from Microsoft.

280
00:18:27,410 --> 00:18:31,454
But top off of the screen, we can see some basics for

281
00:18:31,492 --> 00:18:34,580
designing your prompts, right? So be specific.

282
00:18:35,910 --> 00:18:39,060
Leave as little to the imagination as possible.

283
00:18:40,470 --> 00:18:43,714
Also use analogies, so be as descriptive as possible.

284
00:18:43,832 --> 00:18:47,446
Provide samples, double down. You may need to

285
00:18:47,548 --> 00:18:50,982
remind the model what you actually

286
00:18:51,036 --> 00:18:54,678
want, because that may

287
00:18:54,684 --> 00:18:58,218
be lost as you proceed in

288
00:18:58,384 --> 00:18:59,770
your chat thread.

289
00:19:02,030 --> 00:19:05,786
Make sure the

290
00:19:05,808 --> 00:19:11,082
order of the prompts prioritize

291
00:19:11,146 --> 00:19:13,470
what you actually want. So order matters.

292
00:19:14,610 --> 00:19:18,094
Give the model an alternative, right? So give

293
00:19:18,132 --> 00:19:23,218
it an option to say that I don't know or I

294
00:19:23,224 --> 00:19:26,420
don't have enough information to do that,

295
00:19:26,950 --> 00:19:28,340
those kinds of things.

296
00:19:30,230 --> 00:19:33,582
And that translates into essentially a number of different implementation

297
00:19:33,646 --> 00:19:36,898
techniques. So priming the model, for example,

298
00:19:37,064 --> 00:19:40,374
you make sure that the model has sufficient context, instructions and other

299
00:19:40,412 --> 00:19:43,442
information which is relevant to what you're trying to achieve,

300
00:19:43,586 --> 00:19:46,520
and you use a system prompt to prime the model.

301
00:19:48,570 --> 00:19:51,942
Providing examples is a very good

302
00:19:52,076 --> 00:19:55,666
technique, and this also provides

303
00:19:55,698 --> 00:19:58,754
additional context to the model. It's called fusod.

304
00:19:58,802 --> 00:20:04,026
Learning excels

305
00:20:04,058 --> 00:20:07,614
can be susceptible to recency bias, so make

306
00:20:07,652 --> 00:20:10,814
sure that you repeat yourself with the most

307
00:20:10,852 --> 00:20:14,590
important points at the end of your prompt.

308
00:20:16,530 --> 00:20:19,570
So a few words or phrases at the end of the prompt.

309
00:20:20,070 --> 00:20:23,374
So use a few words or phrases at the end of the prompt to obtain

310
00:20:23,422 --> 00:20:27,240
the model response that you want in the format that you want.

311
00:20:28,410 --> 00:20:31,894
So if you want JSON, you can tell the model that yes,

312
00:20:31,932 --> 00:20:36,614
I want JSON in this particular format, or CSV or whatever

313
00:20:36,652 --> 00:20:40,106
you want. Keep in mind that

314
00:20:40,128 --> 00:20:43,526
large language models often perform better if the task

315
00:20:43,558 --> 00:20:46,250
is broken down into smaller steps.

316
00:20:50,850 --> 00:20:55,434
In recent months, we've seen a very big push by the hyperscalers

317
00:20:55,482 --> 00:20:58,666
to incorporate generative AI into their platforms,

318
00:20:58,778 --> 00:21:02,454
so Azure has invested heavily in OpenAI,

319
00:21:02,522 --> 00:21:03,940
so $10 billion.

320
00:21:05,510 --> 00:21:09,220
They have also announced a number of different services like

321
00:21:09,990 --> 00:21:13,534
prompt flow and support for various foundation

322
00:21:13,582 --> 00:21:17,062
models. They also announced that they will be

323
00:21:17,196 --> 00:21:20,726
adopting the Chat GPT plugin standard

324
00:21:20,908 --> 00:21:24,294
by OpenAI. AWS also

325
00:21:24,332 --> 00:21:28,566
announced a number of different models. They also announced

326
00:21:28,758 --> 00:21:32,438
new hardware and infrastructure for training models

327
00:21:32,454 --> 00:21:35,546
to make it more effective, more efficient to

328
00:21:35,568 --> 00:21:39,450
reduce those costs for training models. They also

329
00:21:39,520 --> 00:21:43,470
recently gaed code Whisperer, Google Cloud,

330
00:21:43,540 --> 00:21:47,854
in their Google I O conference, announced more than 25 products which

331
00:21:47,892 --> 00:21:51,034
featured Palm two and Gemini

332
00:21:51,082 --> 00:21:54,434
models which powered them they

333
00:21:54,472 --> 00:21:58,850
also announced next generation a three gpus

334
00:21:59,190 --> 00:22:01,860
for training models as well.

335
00:22:03,910 --> 00:22:07,430
So I want to leave you with some thoughts.

336
00:22:08,890 --> 00:22:12,226
Do I think that large language models are a panacea?

337
00:22:12,418 --> 00:22:15,878
No, I don't. I think we need to use them in

338
00:22:15,884 --> 00:22:19,478
the right way. I think prompt engineering is critical.

339
00:22:19,654 --> 00:22:23,434
We need this new discipline, which may

340
00:22:23,472 --> 00:22:26,986
require reskilling, and also correct tooling, which may

341
00:22:27,008 --> 00:22:30,570
not even exist today, to support engineers

342
00:22:31,970 --> 00:22:34,766
protecting intellectual property and data.

343
00:22:34,948 --> 00:22:38,414
Also security. Their security concerns can be difficult.

344
00:22:38,532 --> 00:22:42,270
We need to think carefully about how we do that when we engineer our prompts,

345
00:22:43,170 --> 00:22:47,326
and we need to understand in general the risks of the

346
00:22:47,348 --> 00:22:51,294
GPT family of models, as well as generative AI before

347
00:22:51,332 --> 00:22:53,230
we actually use it in our systems.

348
00:22:54,970 --> 00:22:59,154
Thank you for joining my session. I really enjoyed presenting

349
00:22:59,202 --> 00:23:02,438
to you. Please feel free to reach out to

350
00:23:02,444 --> 00:23:05,570
me anytime for further discussions.

