1
00:00:23,290 --> 00:00:27,206
Hello everyone, I hope you have a good day. And now

2
00:00:27,308 --> 00:00:30,370
we will talk about observability for serverless.

3
00:00:30,530 --> 00:00:34,338
But before I will talk about how to do it with serverless

4
00:00:34,434 --> 00:00:38,422
in AWS, I need to, let's say,

5
00:00:38,476 --> 00:00:41,650
introduce you to you my approach to observability,

6
00:00:41,730 --> 00:00:45,254
what observability really is, and what we still kind of

7
00:00:45,292 --> 00:00:49,030
miss in observability. And before we will go

8
00:00:49,100 --> 00:00:53,198
there, let me ask you very small question,

9
00:00:53,364 --> 00:00:56,938
but important one, how good is your monitoring?

10
00:00:57,114 --> 00:01:00,746
Are you happy with it? Do you know how to improve

11
00:01:00,778 --> 00:01:04,100
it? Do you know what you miss there?

12
00:01:04,630 --> 00:01:08,226
Are you sure that your monitoring is aligned with

13
00:01:08,248 --> 00:01:12,306
your business needs? That's the questions we

14
00:01:12,328 --> 00:01:16,018
need to answer, right? So, my name is Pawel Piwosz and I've

15
00:01:16,034 --> 00:01:20,146
been working for Spacelift as developer advocate

16
00:01:20,258 --> 00:01:23,494
for a couple of days today. So this is quite

17
00:01:23,532 --> 00:01:26,706
new for me. And also I am DevOps

18
00:01:26,738 --> 00:01:30,742
Institute ambassador, AWS community builder and CD

19
00:01:30,806 --> 00:01:34,490
foundation ambassador. So now you'll know why

20
00:01:34,560 --> 00:01:36,780
I will talk about AWS, right?

21
00:01:38,030 --> 00:01:41,920
Okay, so what is the problem today

22
00:01:42,450 --> 00:01:45,918
we have less visibility, right? How I understand

23
00:01:46,004 --> 00:01:49,310
it, how we should understand it. So, first of all,

24
00:01:49,380 --> 00:01:53,374
when we had barmetal, these rock and some

25
00:01:53,412 --> 00:01:57,378
servers in this rock in the data center, we could

26
00:01:57,464 --> 00:01:59,140
observe everything,

27
00:01:59,990 --> 00:02:04,302
starting from air conditioning,

28
00:02:04,446 --> 00:02:08,242
through these power flow to the end behavior

29
00:02:08,306 --> 00:02:11,320
of the application by every single user, right?

30
00:02:12,250 --> 00:02:15,670
Then we went to virtual machines.

31
00:02:16,170 --> 00:02:19,722
And as long as we are not

32
00:02:19,776 --> 00:02:23,238
responsible for this virtualization

33
00:02:23,334 --> 00:02:23,980
platform,

34
00:02:26,670 --> 00:02:30,390
we do not have the visibility there.

35
00:02:30,560 --> 00:02:34,350
So we can see everything what is above, not below,

36
00:02:34,500 --> 00:02:38,526
right? Then we have containers and we

37
00:02:38,548 --> 00:02:43,838
can see even less. For example, if you think about ecs,

38
00:02:43,934 --> 00:02:47,246
especially Fargate, ecs, just ecs,

39
00:02:47,438 --> 00:02:50,642
we have less

40
00:02:50,696 --> 00:02:54,562
and less places where we can observe and understand

41
00:02:54,696 --> 00:02:57,942
what our system is doing, especially if we talk about

42
00:02:57,996 --> 00:03:01,800
Fargate, we don't know almost nothing.

43
00:03:02,410 --> 00:03:04,550
And finally, we have serverless,

44
00:03:05,210 --> 00:03:09,362
and in serverless we deliver the code, we deliver

45
00:03:09,426 --> 00:03:13,030
the information, what is the endpoint of the API and

46
00:03:13,180 --> 00:03:16,866
what it should do. And that's all. We don't

47
00:03:16,898 --> 00:03:19,160
see anything else, right?

48
00:03:20,210 --> 00:03:23,854
And why is that? Because we have less

49
00:03:23,892 --> 00:03:27,710
interactions with the systems through the whole

50
00:03:27,860 --> 00:03:31,166
scope of the system, we have less accessibility to the

51
00:03:31,188 --> 00:03:34,210
system, we have more and more tools.

52
00:03:34,870 --> 00:03:38,462
We start to think that central logging is passe.

53
00:03:38,606 --> 00:03:42,782
And this is the problem which came with agile

54
00:03:42,846 --> 00:03:46,354
in my opinion. Especially when we say that all teams

55
00:03:46,402 --> 00:03:50,134
should be self organizing and they know

56
00:03:50,172 --> 00:03:52,920
what they do and that's it, right?

57
00:03:53,690 --> 00:03:57,206
Yes, but on the end of the

58
00:03:57,228 --> 00:04:00,906
day, it's the company who sell the product,

59
00:04:01,088 --> 00:04:04,774
not the team. And if you have multiple teams

60
00:04:04,822 --> 00:04:08,794
working together you

61
00:04:08,832 --> 00:04:12,254
see the problem if you have

62
00:04:12,292 --> 00:04:17,630
monitoring only of your own component without

63
00:04:17,700 --> 00:04:21,086
caring about anything else, because it's not

64
00:04:21,108 --> 00:04:23,650
your responsibility, it's other team responsibility.

65
00:04:24,630 --> 00:04:28,674
What can go wrong, right? I saw examples of this

66
00:04:28,872 --> 00:04:32,706
and believe me today I

67
00:04:32,728 --> 00:04:36,002
can laugh from it, but it wasn't

68
00:04:36,066 --> 00:04:39,654
funny that day. Okay, and finally

69
00:04:39,772 --> 00:04:43,622
we have decoupling, and this decoupling of the system

70
00:04:43,756 --> 00:04:47,366
microservices, serverless, et cetera, et cetera, is bringing more

71
00:04:47,388 --> 00:04:50,902
and more complexity, at least in the communications

72
00:04:50,966 --> 00:04:54,474
pattern, right? And here we also need to

73
00:04:54,512 --> 00:04:58,074
think not only about the communication between the components themselves, but also

74
00:04:58,112 --> 00:05:01,566
between the teams. So convey's law. I don't want to

75
00:05:01,588 --> 00:05:04,958
go deeper into this topic, but this is really interesting

76
00:05:05,044 --> 00:05:08,286
one. So what does less visibility means?

77
00:05:08,468 --> 00:05:11,822
Well, exactly this, right? So we have different

78
00:05:11,876 --> 00:05:15,266
computing models. And on this picture you can

79
00:05:15,288 --> 00:05:19,266
see that the greens are the elements which we control

80
00:05:19,368 --> 00:05:22,786
and the reds what we do not control in any

81
00:05:22,888 --> 00:05:26,386
of these computing models. So we have

82
00:05:26,408 --> 00:05:30,182
a couple of approaches here. We have on premise simple. We control everything.

83
00:05:30,316 --> 00:05:33,720
We have infrastructure as a service, platform as a service,

84
00:05:35,210 --> 00:05:38,890
software as a service, on these end, right, where the serverless lies.

85
00:05:39,470 --> 00:05:43,980
And here, as you can see, in this approach with

86
00:05:44,430 --> 00:05:48,154
software as a service, we do not control anything except code.

87
00:05:48,352 --> 00:05:51,966
And this brings this

88
00:05:51,988 --> 00:05:54,640
complexity, right? However it sounds.

89
00:05:55,170 --> 00:05:59,066
Okay. So first of all, we need to have luke a cultural

90
00:05:59,098 --> 00:06:02,974
shift. Why this is important because we cannot catch

91
00:06:03,022 --> 00:06:07,346
logs as we used to do. So we need to create new,

92
00:06:07,528 --> 00:06:11,666
sometimes even more complex, more responsive ways to

93
00:06:11,688 --> 00:06:15,334
do that. And first element, which I need

94
00:06:15,372 --> 00:06:18,566
to present before we go

95
00:06:18,588 --> 00:06:22,642
to the observability, is something what is called structured logs.

96
00:06:22,706 --> 00:06:26,646
Okay, and what is structured logging? This is

97
00:06:26,668 --> 00:06:30,566
the definition from samologic. And structured logging is the practice

98
00:06:30,598 --> 00:06:34,250
of implementing a consistent predetermined message format for application,

99
00:06:34,320 --> 00:06:38,314
blah, blah, blah, blah, right? So generally what it means that

100
00:06:38,432 --> 00:06:42,430
our message from all the systems should

101
00:06:42,500 --> 00:06:45,534
be as much informative as possible,

102
00:06:45,732 --> 00:06:49,054
as much organized as possible,

103
00:06:49,252 --> 00:06:52,800
and following the standard as much as possible.

104
00:06:53,830 --> 00:06:56,978
This message also has these standard, right?

105
00:06:57,064 --> 00:07:01,474
So how it looks in these

106
00:07:01,512 --> 00:07:06,934
example, we will see it. But please remember one thing, that structured message is

107
00:07:06,972 --> 00:07:10,902
not the structure log. Structure log is

108
00:07:10,956 --> 00:07:15,270
a little bit more. So we have structured message and

109
00:07:15,340 --> 00:07:18,220
around these we have structured information.

110
00:07:19,230 --> 00:07:22,170
Why we have this message, what happened in the system,

111
00:07:22,320 --> 00:07:25,660
right? What is system is doing at this point?

112
00:07:27,150 --> 00:07:31,086
So standard lock line example, especially from sysadmins, this is

113
00:07:31,108 --> 00:07:35,246
very common and very thing which

114
00:07:35,268 --> 00:07:39,226
is very familiar, right? When we want to structurize

115
00:07:39,258 --> 00:07:43,106
the message, we can do something like that. And this is the hint how

116
00:07:43,128 --> 00:07:46,738
to become senior, you just put your message

117
00:07:46,824 --> 00:07:51,650
into the JSON and that's. It sounds

118
00:07:51,720 --> 00:07:55,578
silly, but believe me, it's already a huge upgrade.

119
00:07:55,694 --> 00:07:59,542
Why? Because your systems, which are working

120
00:07:59,596 --> 00:08:03,960
with your locks, doesn't need to process

121
00:08:04,330 --> 00:08:07,574
the message as heavily. Okay?

122
00:08:07,692 --> 00:08:11,174
Because with JSon it is very simple. You have fields,

123
00:08:11,222 --> 00:08:14,700
you have values of those fields, and that's it.

124
00:08:15,070 --> 00:08:18,614
You don't need to look, you don't need to create these patterns

125
00:08:18,662 --> 00:08:22,350
to search through the locks, et cetera, et cetera, et cetera.

126
00:08:22,690 --> 00:08:26,682
It makes things easier. Then we have structurized

127
00:08:26,746 --> 00:08:30,606
lock example. It's not fully structurized yet.

128
00:08:30,708 --> 00:08:34,450
I mean, it's not the structure lock itself, but the line is

129
00:08:34,600 --> 00:08:38,260
pretty nice, right? So we have information about the

130
00:08:40,230 --> 00:08:44,034
message and also, for example, who from

131
00:08:44,072 --> 00:08:47,158
these, et cetera, et cetera, et cetera. It's a lot better,

132
00:08:47,244 --> 00:08:50,326
right? But still, this is a good start.

133
00:08:50,428 --> 00:08:53,414
But this is not a structure lock yet. Okay?

134
00:08:53,612 --> 00:08:57,062
And to have full structure log, we need to go

135
00:08:57,116 --> 00:09:00,890
into observability. But please remember one

136
00:09:00,960 --> 00:09:04,490
thing, observability is not

137
00:09:04,640 --> 00:09:08,346
Grafana on kubernetes. If you have Grafana on

138
00:09:08,368 --> 00:09:12,442
kubernetes, you don't have observability. You have Grafana on kubernetes,

139
00:09:12,586 --> 00:09:15,918
period. Yes,

140
00:09:16,084 --> 00:09:19,838
this is the tool, very nice tool, which we can

141
00:09:20,004 --> 00:09:22,834
use in order to, let's say,

142
00:09:22,872 --> 00:09:27,122
complete the whole approach to observability. But this is only

143
00:09:27,176 --> 00:09:30,020
the tool, nothing more. Okay,

144
00:09:30,710 --> 00:09:33,490
so what are the elements of the observability?

145
00:09:34,070 --> 00:09:37,326
Three of them, logs, traces and metrics.

146
00:09:37,518 --> 00:09:40,706
So what we

147
00:09:40,728 --> 00:09:44,498
can tell about locks? So this is very common scenario,

148
00:09:44,594 --> 00:09:46,760
we write everything to logs, right?

149
00:09:47,550 --> 00:09:51,594
But we write errors only because

150
00:09:51,632 --> 00:09:55,930
we must save money. How many of you are

151
00:09:56,000 --> 00:09:59,660
or was in this situation?

152
00:10:02,130 --> 00:10:05,774
So the problem is that if

153
00:10:05,812 --> 00:10:08,814
we write errors only,

154
00:10:09,012 --> 00:10:12,786
we can forget about everything. Honestly speaking, and I know that it

155
00:10:12,808 --> 00:10:16,686
sounds tough, but this is really the truth

156
00:10:16,798 --> 00:10:20,702
in terms of observability. Right? So what are these locks

157
00:10:20,766 --> 00:10:24,462
here? First of all, they need to be structurized.

158
00:10:24,526 --> 00:10:28,200
We mentioned that they need to be consistent throughout the whole system.

159
00:10:28,570 --> 00:10:32,200
They need to cover all information needed.

160
00:10:32,650 --> 00:10:36,454
They need to be constructed for automated systems, because on these

161
00:10:36,492 --> 00:10:40,118
end, we want all of these elements,

162
00:10:40,214 --> 00:10:44,566
all of these components here to be managed and let's

163
00:10:44,598 --> 00:10:47,958
say, processed by automation,

164
00:10:48,134 --> 00:10:51,440
not us. We want to sleep at night,

165
00:10:51,970 --> 00:10:55,390
right? They need to be collected consistently.

166
00:10:56,130 --> 00:10:59,034
What about the performance and the metrics?

167
00:10:59,162 --> 00:11:02,026
The metrics generally?

168
00:11:02,138 --> 00:11:05,506
So how many of you, again, were in

169
00:11:05,528 --> 00:11:09,234
the situation when you were asked about the performance metrics and

170
00:11:09,272 --> 00:11:13,074
you said, that's great, because in fact,

171
00:11:13,112 --> 00:11:16,280
you don't know, really. Right.

172
00:11:17,530 --> 00:11:21,830
Because for example, you have only collected errors from Njax.

173
00:11:24,090 --> 00:11:27,654
Right? So what about the metrics then?

174
00:11:27,772 --> 00:11:31,258
They need to be structurized, they need to be consistent, they need to

175
00:11:31,344 --> 00:11:34,794
have context, they need to have full information.

176
00:11:34,992 --> 00:11:38,202
And as you already probably start to think,

177
00:11:38,256 --> 00:11:41,454
hey, this is almost the same slide like the one before.

178
00:11:41,652 --> 00:11:45,470
Yes, you're right, it is. I'm lead.

179
00:11:45,540 --> 00:11:49,482
Right. They should be constructed again for automated

180
00:11:49,546 --> 00:11:52,602
systems and collected consistently.

181
00:11:52,746 --> 00:11:56,638
Okay. And very important element,

182
00:11:56,734 --> 00:12:00,066
they need to be relevant for the business, because on

183
00:12:00,088 --> 00:12:03,074
the end of the day, the business is the one who is paying for your

184
00:12:03,112 --> 00:12:03,970
systems.

185
00:12:06,410 --> 00:12:10,390
Right? Okay. Of course

186
00:12:10,460 --> 00:12:13,814
we can collect them directly as a metrics, or we

187
00:12:13,852 --> 00:12:17,926
can, let's say, convert logs

188
00:12:17,958 --> 00:12:19,500
to metrics as well.

189
00:12:21,950 --> 00:12:25,498
What about traces? Traces are

190
00:12:25,664 --> 00:12:28,380
the elements which we,

191
00:12:29,230 --> 00:12:32,478
let's say, use not that often,

192
00:12:32,564 --> 00:12:34,960
right? So logs, it is quite obvious,

193
00:12:35,810 --> 00:12:37,920
metrics, we collect them,

194
00:12:38,850 --> 00:12:40,350
but what about traces?

195
00:12:42,850 --> 00:12:45,874
So if your business will come to you and will say, hey,

196
00:12:45,912 --> 00:12:49,374
I have this John Doe who is claiming

197
00:12:49,422 --> 00:12:52,754
that the request took too long for him

198
00:12:52,792 --> 00:12:56,086
and he is annoying and he is paying a lot of money to us,

199
00:12:56,188 --> 00:12:58,680
please tell me if he is right with this,

200
00:13:01,130 --> 00:13:05,302
what you will do in order to prove or

201
00:13:05,356 --> 00:13:09,274
disprove that everything is okay with

202
00:13:09,312 --> 00:13:12,620
your system, with your complicated microservices system,

203
00:13:14,110 --> 00:13:18,042
for this specific request, probably you

204
00:13:18,096 --> 00:13:19,420
have these problem.

205
00:13:20,690 --> 00:13:23,534
So what about races then?

206
00:13:23,732 --> 00:13:27,754
Of course they need to be consistent, they need to be collected consistently

207
00:13:27,882 --> 00:13:31,822
throughout the whole system. They allow

208
00:13:31,956 --> 00:13:35,314
to track the request through the whole

209
00:13:35,352 --> 00:13:38,866
system. Really? Right. And we can

210
00:13:38,888 --> 00:13:42,654
use them as a performance measures. And we have a zooming

211
00:13:42,702 --> 00:13:45,846
option. If we are very closely, very close

212
00:13:45,868 --> 00:13:49,394
to the system, we can observe one request for one specific user.

213
00:13:49,522 --> 00:13:53,480
If we zoom out, we can see the whole system

214
00:13:54,650 --> 00:13:58,294
in general. And now what about the context?

215
00:13:58,342 --> 00:14:02,054
I mentioned this context and I believe for the observability,

216
00:14:02,182 --> 00:14:05,210
for monitoring, for all of these aspects here.

217
00:14:05,360 --> 00:14:08,794
Context is a clue, right?

218
00:14:08,832 --> 00:14:13,166
It's the heart of everything. So tell

219
00:14:13,188 --> 00:14:15,200
me please, what it is.

220
00:14:16,770 --> 00:14:19,950
I give you like 5 seconds to think about this.

221
00:14:20,100 --> 00:14:24,082
Five, four, these two, 10. That was very

222
00:14:24,216 --> 00:14:27,666
quick seconds. So some of you

223
00:14:27,688 --> 00:14:31,140
will think probably stone or,

224
00:14:32,070 --> 00:14:35,526
I don't know, maybe something else, right? But how

225
00:14:35,548 --> 00:14:39,666
many of you thought that can be a planet fragment

226
00:14:39,698 --> 00:14:43,670
of the planet? So without context you just guessed

227
00:14:44,410 --> 00:14:47,586
correctly or not, but it was only the

228
00:14:47,628 --> 00:14:50,662
guess. And without context,

229
00:14:50,806 --> 00:14:54,186
you lose something, right?

230
00:14:54,368 --> 00:14:57,866
So what is the context in the observability? So first

231
00:14:57,888 --> 00:15:01,274
of all, logs allows us to understand the surroundings,

232
00:15:01,402 --> 00:15:05,470
these traces allows us to understand the path, the journey.

233
00:15:06,050 --> 00:15:09,550
And finally, metrics allows us to understand

234
00:15:09,620 --> 00:15:11,760
the scale, okay?

235
00:15:12,390 --> 00:15:16,098
So please don't tell

236
00:15:16,184 --> 00:15:18,690
that there's something in the locks,

237
00:15:19,030 --> 00:15:22,194
because if there is something in the locks, you should do something.

238
00:15:22,392 --> 00:15:26,550
And the important is what those somethings are,

239
00:15:26,700 --> 00:15:30,550
okay? So please avoid this

240
00:15:30,620 --> 00:15:33,686
headache. Just know what

241
00:15:33,708 --> 00:15:37,442
you have there around this. I built

242
00:15:37,516 --> 00:15:41,894
something, what I called very creatively, meal. And honestly

243
00:15:41,942 --> 00:15:45,514
speaking, I build this before the observability becomes a

244
00:15:45,712 --> 00:15:49,610
buzzword. So, meal contains four elements,

245
00:15:50,450 --> 00:15:53,274
not free, like observability logs, events,

246
00:15:53,322 --> 00:15:57,134
metrics, and also actions. And generally what it

247
00:15:57,172 --> 00:16:01,146
means that in this framework, mine framework,

248
00:16:01,258 --> 00:16:04,546
we don't only collect stuff,

249
00:16:04,648 --> 00:16:07,122
but we also want to automatically act on it,

250
00:16:07,176 --> 00:16:11,550
right? Well, it is in the observability somehow,

251
00:16:11,630 --> 00:16:14,260
but I was the first.

252
00:16:15,350 --> 00:16:18,286
So generally what we have, we have metrics,

253
00:16:18,318 --> 00:16:22,614
events and logs, right? And we collect them together and

254
00:16:22,652 --> 00:16:25,986
based on it, we take action. And these action

255
00:16:26,018 --> 00:16:30,022
can be automated. So enough

256
00:16:30,076 --> 00:16:33,674
for the theory. Now, we have a little bit more than ten

257
00:16:33,712 --> 00:16:37,146
minutes, so let's go through the tech stack, which I

258
00:16:37,168 --> 00:16:40,570
want to show you. So first of all, we have lambda,

259
00:16:40,650 --> 00:16:44,638
right? Aws lambda. This is the serverless compute engine from

260
00:16:44,724 --> 00:16:47,902
AWS. And we have one issue here,

261
00:16:47,956 --> 00:16:52,090
which we can very nicely observe

262
00:16:52,250 --> 00:16:55,426
with the proper approach to observability, which is not

263
00:16:55,448 --> 00:16:59,298
possible without it. So if we are experienced enough,

264
00:16:59,384 --> 00:17:03,698
we can see this issue,

265
00:17:03,864 --> 00:17:06,520
but we are not able really to measure it.

266
00:17:07,130 --> 00:17:10,502
And what I mean by that is cold start, right?

267
00:17:10,636 --> 00:17:14,546
So we can measure cold start with lambda

268
00:17:14,578 --> 00:17:18,898
insights. And these we will see how many invocations

269
00:17:19,074 --> 00:17:21,000
suffer from this cold start.

270
00:17:23,210 --> 00:17:26,586
And using x ray, excuse me,

271
00:17:26,768 --> 00:17:30,362
we can see what is the impact of this cold start

272
00:17:30,416 --> 00:17:33,910
on each invocation. So generally,

273
00:17:33,990 --> 00:17:38,846
cold start looks like this. This is the time when

274
00:17:39,028 --> 00:17:42,782
AWS needs to prepare everything for

275
00:17:42,836 --> 00:17:45,986
us to execute our runtime. And also there

276
00:17:46,008 --> 00:17:49,314
is another type of call start. But this

277
00:17:49,352 --> 00:17:52,962
is not the talk about cold start. So we can have

278
00:17:53,016 --> 00:17:56,614
shortened call start. And when the lambda is

279
00:17:56,732 --> 00:18:00,262
how we call it, warm, there is no call start at all.

280
00:18:00,316 --> 00:18:02,470
We just go to the execution.

281
00:18:03,690 --> 00:18:06,850
In order to deploy the environment,

282
00:18:06,930 --> 00:18:10,540
I used AWS serverless application model,

283
00:18:11,070 --> 00:18:14,826
this kind of framework, which is

284
00:18:15,008 --> 00:18:18,140
in fact cloudformation. So infrastructure as code.

285
00:18:18,750 --> 00:18:22,826
This is the extension to cloud formation. And with that I've

286
00:18:22,858 --> 00:18:26,046
created something, what I call standard example,

287
00:18:26,148 --> 00:18:29,646
with standard logging from AWS. And this

288
00:18:29,668 --> 00:18:32,970
is the code of this Sam template.

289
00:18:33,050 --> 00:18:35,986
So what we have here, we have here a couple of elements. So first of

290
00:18:36,008 --> 00:18:39,742
all, I define the resource, which is the serverless

291
00:18:39,806 --> 00:18:43,394
function, lambda function. I say, where is

292
00:18:43,432 --> 00:18:46,578
the code here, right from

293
00:18:46,664 --> 00:18:51,010
where it needs to be deployed, what is the handler

294
00:18:51,090 --> 00:18:54,502
to my function. So what will be executed first when

295
00:18:54,556 --> 00:18:57,350
the request came, what is the runtime,

296
00:18:58,570 --> 00:19:02,074
memory size, timeout and the event here?

297
00:19:02,192 --> 00:19:06,234
It means that I assign somehow the

298
00:19:06,272 --> 00:19:09,260
API to my function.

299
00:19:09,890 --> 00:19:13,614
And in order to reach my function, I need

300
00:19:13,652 --> 00:19:17,806
to go to these simple path with

301
00:19:17,828 --> 00:19:21,342
methodget. Simple like that. So what we have after

302
00:19:21,396 --> 00:19:24,898
that, and this is 20 lines, right?

303
00:19:25,064 --> 00:19:29,060
So we have lambda function, which is created in AWS. Very nice.

304
00:19:30,550 --> 00:19:33,886
I'm sorry, that was the API gateway. It was created

305
00:19:33,918 --> 00:19:37,234
for us also with the proper endpoint slash,

306
00:19:37,282 --> 00:19:40,770
like I said. Then we have our lambda functions.

307
00:19:40,930 --> 00:19:44,486
And when we execute these, and I want to go into

308
00:19:44,588 --> 00:19:48,374
the metrics,

309
00:19:48,422 --> 00:19:52,042
measurements, logs, et cetera, et cetera, I will see

310
00:19:52,176 --> 00:19:55,100
something like that. Nice.

311
00:19:55,710 --> 00:19:58,730
I see that my API gateway was triggered.

312
00:19:59,230 --> 00:20:02,158
Good. All right, what more,

313
00:20:02,324 --> 00:20:05,726
I see that my lambda function was triggered and I

314
00:20:05,748 --> 00:20:09,562
have some information here. So how many invocations,

315
00:20:09,706 --> 00:20:13,010
what is the duration? But why here is like

316
00:20:13,080 --> 00:20:17,218
2.2

317
00:20:17,304 --> 00:20:20,980
and here is a little bit more than 1.5.

318
00:20:22,070 --> 00:20:25,602
Why it's not

319
00:20:25,656 --> 00:20:29,622
saying anything about that. Right. So maybe locks and

320
00:20:29,676 --> 00:20:33,190
those three elements here

321
00:20:33,260 --> 00:20:36,758
opened shows us all the

322
00:20:36,764 --> 00:20:40,426
information which we have by default from

323
00:20:40,608 --> 00:20:42,330
lambda execution.

324
00:20:44,510 --> 00:20:48,140
Very informative. All right,

325
00:20:49,150 --> 00:20:52,590
all right, so we can agree, I believe,

326
00:20:52,660 --> 00:20:55,902
that it's useless, or almost very

327
00:20:55,956 --> 00:20:59,806
close to be useless, right next to be useless. So how we

328
00:20:59,828 --> 00:21:03,502
can improve this? So first of all, we will enable

329
00:21:03,566 --> 00:21:07,762
x ray for our

330
00:21:07,816 --> 00:21:11,966
lambda. So we need to go into configurations,

331
00:21:12,158 --> 00:21:14,370
monitoring and operation tools,

332
00:21:15,990 --> 00:21:19,102
click edit and just enable

333
00:21:19,166 --> 00:21:22,374
x ray tracing. And by one

334
00:21:22,412 --> 00:21:26,310
click we can become regular engineer.

335
00:21:27,470 --> 00:21:30,742
Then we can do the same thing for API.

336
00:21:30,806 --> 00:21:35,046
Right? So we go into our API stage logs,

337
00:21:35,078 --> 00:21:37,370
tracing, and enable x ray tracing,

338
00:21:38,350 --> 00:21:42,254
two clicks and we are regular engineer and

339
00:21:42,292 --> 00:21:45,614
we have something like that. So we can see here

340
00:21:45,652 --> 00:21:49,834
the request path response

341
00:21:49,882 --> 00:21:53,182
distributions, et cetera, et cetera. Nice, very nice.

342
00:21:53,236 --> 00:21:56,482
And also we have information like that. So we have

343
00:21:56,536 --> 00:22:00,162
the traces, we have the information about all

344
00:22:00,216 --> 00:22:04,034
our executions. Please don't look on this last one here,

345
00:22:04,072 --> 00:22:07,606
because as you can see, there is no get, that means that

346
00:22:07,708 --> 00:22:11,350
this execution was done without API.

347
00:22:12,490 --> 00:22:15,974
We are interested in all of those which

348
00:22:16,012 --> 00:22:19,846
were run through API. So we have the fastest

349
00:22:19,958 --> 00:22:23,306
execution around 60 milliseconds, and the

350
00:22:23,328 --> 00:22:25,290
slowest 28 milliseconds.

351
00:22:26,670 --> 00:22:29,718
Why the same execution?

352
00:22:29,814 --> 00:22:32,000
I mean the same function?

353
00:22:33,330 --> 00:22:36,490
Let's try to find out. So we go to the traces,

354
00:22:36,650 --> 00:22:40,094
now we are in the trace, which is the longest, and we

355
00:22:40,132 --> 00:22:44,302
see kind of gap

356
00:22:44,366 --> 00:22:48,062
here. And when we go into the shortest

357
00:22:48,126 --> 00:22:51,970
one, we see this gap here as well. It's a little bit shorter,

358
00:22:52,310 --> 00:22:56,114
but again, it doesn't say anything, right? We have

359
00:22:56,152 --> 00:22:57,700
invocation somewhere here.

360
00:23:00,950 --> 00:23:04,934
Is this called start or not? What happened here? I know,

361
00:23:05,052 --> 00:23:08,298
because I work with lambda for, I don't know, eight years or something.

362
00:23:08,464 --> 00:23:12,410
I know, right? But not

363
00:23:12,480 --> 00:23:15,814
everyone knows. So what we can do, we can enable

364
00:23:15,862 --> 00:23:19,446
lambda insights. So again we go into the same configuration

365
00:23:19,478 --> 00:23:22,746
for the lambda, we enable enhanced monitoring,

366
00:23:22,858 --> 00:23:26,910
and after some time, some time we will

367
00:23:26,980 --> 00:23:30,800
receive another screen, another,

368
00:23:31,330 --> 00:23:35,634
let's say board these we can see also the information,

369
00:23:35,752 --> 00:23:39,282
like a more detailed information, what was the memory used,

370
00:23:39,336 --> 00:23:42,866
the CPU time used, the network iOS, but also we have the

371
00:23:42,888 --> 00:23:46,934
duration and init duration. And here we can see that

372
00:23:46,972 --> 00:23:50,470
the init duration, we can understand it as a cold start.

373
00:23:50,540 --> 00:23:55,240
Okay, so these invocation suffered from the cold start, those not.

374
00:23:57,550 --> 00:24:01,718
We can also enable tracing and logging

375
00:24:01,894 --> 00:24:05,626
in the API, right? So we go again to

376
00:24:05,648 --> 00:24:09,874
the same position, the same config

377
00:24:10,022 --> 00:24:13,946
screen in the API, and we enable all of them, enable cloudwatch

378
00:24:13,978 --> 00:24:16,320
logs, et cetera, et cetera, et cetera. So these,

379
00:24:17,650 --> 00:24:21,818
and additionally what I suggest

380
00:24:21,994 --> 00:24:26,626
is to add a log format for

381
00:24:26,648 --> 00:24:28,130
your logs from API.

382
00:24:29,750 --> 00:24:33,826
It's called custom. We enable it by clicking this

383
00:24:33,928 --> 00:24:37,800
tick here, and we put this, and now

384
00:24:39,050 --> 00:24:42,150
the hint how to become senior engineer.

385
00:24:43,050 --> 00:24:46,966
This was filled by clicking the JSON button

386
00:24:47,068 --> 00:24:47,720
here.

387
00:24:50,010 --> 00:24:53,734
Nice one, right? So I added here

388
00:24:53,772 --> 00:24:57,080
only one, it one thing, trace id,

389
00:24:57,610 --> 00:25:01,022
just to have the trace id see throughout the

390
00:25:01,076 --> 00:25:04,478
whole system. Okay? And of course we remember

391
00:25:04,564 --> 00:25:08,190
about keeping this tracing enabled. And after that

392
00:25:08,260 --> 00:25:10,670
we have information from API.

393
00:25:12,390 --> 00:25:14,900
So good progress, right?

394
00:25:15,430 --> 00:25:19,614
We can use something what is called contributor

395
00:25:19,662 --> 00:25:23,134
insights to have different boards,

396
00:25:23,182 --> 00:25:26,920
different view, different understandings on what's going on in our system.

397
00:25:27,530 --> 00:25:31,954
But all of these was only about the exteriors,

398
00:25:32,082 --> 00:25:36,246
what about things which happening inside the

399
00:25:36,268 --> 00:25:39,478
function. So here we have AWS lambda

400
00:25:39,494 --> 00:25:44,140
power tools. So it's open,

401
00:25:45,630 --> 00:25:50,446
oh my, I forgot, open source project from

402
00:25:50,468 --> 00:25:54,762
AWS, which is very close to the open telemetry.

403
00:25:54,906 --> 00:25:58,670
And we have multiple ways of implementation. It is ready for

404
00:25:58,740 --> 00:26:01,358
Python, typescript, Java and. Net.

405
00:26:01,524 --> 00:26:04,770
And we can build the observability

406
00:26:05,110 --> 00:26:08,530
almost out from the box, right? And the best

407
00:26:08,600 --> 00:26:11,650
use of it is using AWS lambda.

408
00:26:13,190 --> 00:26:16,786
Finally with that we can start implementing

409
00:26:16,978 --> 00:26:20,566
the code. So what we will have is

410
00:26:20,668 --> 00:26:24,198
that after the implementation we have full

411
00:26:24,284 --> 00:26:27,602
information what's going on in our functionality, right?

412
00:26:27,676 --> 00:26:31,366
Even going into specific sub functions,

413
00:26:31,558 --> 00:26:34,966
information about the initialization time, et cetera, et cetera,

414
00:26:34,998 --> 00:26:38,540
et cetera. It's much, much more rich than it was before.

415
00:26:39,230 --> 00:26:43,086
We can have additional metrics, like a

416
00:26:43,108 --> 00:26:46,720
custom metrics. So those metrics are created by

417
00:26:47,250 --> 00:26:50,654
power tools, of course, by instrumenting it by

418
00:26:50,692 --> 00:26:53,460
me, so I can, for example,

419
00:26:53,990 --> 00:26:57,794
a simple example, these, I can count how many times

420
00:26:57,912 --> 00:27:00,420
the sub functions were called, right?

421
00:27:01,350 --> 00:27:05,954
For the logs, this is the information which

422
00:27:05,992 --> 00:27:09,762
we have so much richer,

423
00:27:09,906 --> 00:27:13,590
we have all the surroundings, we have very,

424
00:27:13,740 --> 00:27:17,582
very, let's say organized

425
00:27:17,666 --> 00:27:20,620
output, which is always the same,

426
00:27:21,230 --> 00:27:25,094
right? And for the Sam

427
00:27:25,142 --> 00:27:28,730
model, I know that is quite small,

428
00:27:28,880 --> 00:27:32,046
but the change for the

429
00:27:32,068 --> 00:27:35,898
infrastructure as code, which I've done, is by adding

430
00:27:35,994 --> 00:27:40,894
67 lines, right? Because it

431
00:27:40,932 --> 00:27:44,302
can be less. But I have this format

432
00:27:44,366 --> 00:27:47,634
described here as well, right? So I didn't do that in one line,

433
00:27:47,672 --> 00:27:51,586
but in multiple lines. So if

434
00:27:51,608 --> 00:27:55,140
you want to, let's say, implement it by yourself

435
00:27:56,410 --> 00:28:00,374
with Python, you can try with these article and

436
00:28:00,492 --> 00:28:04,374
what we can do with that, a lot of things really, because we have

437
00:28:04,412 --> 00:28:07,490
Cloudwatch, we have a possibility to

438
00:28:07,580 --> 00:28:11,562
analyze this through Athena, we can go

439
00:28:11,616 --> 00:28:15,290
into quicksight through open search and kinesis,

440
00:28:15,790 --> 00:28:19,434
we can put it into time stream and publish data

441
00:28:19,632 --> 00:28:23,722
through Grafana, right? Or send it to Prometheus,

442
00:28:23,786 --> 00:28:27,342
whatever. We can build alerts and alarms on it and

443
00:28:27,396 --> 00:28:31,360
act on it using, for example, lambdas, right? So there is a lot.

444
00:28:31,810 --> 00:28:34,802
So for the instrumentation itself,

445
00:28:34,936 --> 00:28:38,530
except power tools, what we can use for,

446
00:28:38,600 --> 00:28:42,350
of course, power tools, right? But also Jaeger has the possibility,

447
00:28:42,430 --> 00:28:45,650
Prometheus has the possibility to instrument your functions.

448
00:28:46,090 --> 00:28:49,510
Opentelemetry has also the possibility to do that.

449
00:28:49,660 --> 00:28:52,866
For visualization, we can use Grafana,

450
00:28:52,898 --> 00:28:56,082
we can use Prometheus, we can use many, many other tools,

451
00:28:56,146 --> 00:29:00,006
right? For the databases, we should use NoSQL

452
00:29:00,038 --> 00:29:02,460
databases, it's, I believe, obvious,

453
00:29:03,390 --> 00:29:06,810
mainly time series, especially for metrics,

454
00:29:07,230 --> 00:29:10,282
but for logs, for example,

455
00:29:10,336 --> 00:29:14,046
open search. And we have also all in

456
00:29:14,068 --> 00:29:18,474
one tools like Prometheus, like Jaeger, like Hanakomp

457
00:29:18,522 --> 00:29:22,298
IO, very nice tool which allows you to

458
00:29:22,404 --> 00:29:24,946
control the whole process,

459
00:29:25,048 --> 00:29:27,922
right? Dynatrace for example, as well.

460
00:29:27,976 --> 00:29:31,154
And Splunk is quite new, but Splunk also

461
00:29:31,192 --> 00:29:33,650
allows us to build the observability.

462
00:29:35,110 --> 00:29:39,220
And finally, the question for you on the end,

463
00:29:40,710 --> 00:29:44,742
who is monitor your monitoring server is a quote from

464
00:29:44,796 --> 00:29:48,120
DevOps Borat. If you have questions,

465
00:29:48,650 --> 00:29:51,894
I'll be happy to discuss it with you.

466
00:29:52,012 --> 00:29:55,282
You can contact me and connecting with me through the LinkedIn

467
00:29:55,346 --> 00:29:57,960
or on my webpage. And also,

468
00:30:00,050 --> 00:30:04,030
ah, strongly recommend. Well, strongly recommend

469
00:30:04,180 --> 00:30:07,934
I ask you to subscribe to the podcast which

470
00:30:07,972 --> 00:30:11,742
I host with my two friends. We talk there about

471
00:30:11,796 --> 00:30:15,838
it with different aspects of it. Thank you very much for your time.

472
00:30:16,004 --> 00:30:20,026
Enjoy rest of the day and I hope this talk was useful

473
00:30:20,058 --> 00:30:20,860
for you. Thank you.

