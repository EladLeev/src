1
00:00:41,410 --> 00:00:44,946
Folks, welcome to Con 42 Cloud Native.

2
00:00:45,058 --> 00:00:48,322
I'm Uma Mukara, CEO, founder and CEO

3
00:00:48,386 --> 00:00:52,154
of Chaos Native, and I'm also the co creator

4
00:00:52,282 --> 00:00:56,126
and maintainer on Litmus Chaos, which is a

5
00:00:56,148 --> 00:01:00,298
CNCF project for Chaos Engineering. Today in this session

6
00:01:00,394 --> 00:01:04,418
I'm going to talk about what is chaos engineering means

7
00:01:04,584 --> 00:01:07,902
in cloud native environments. How can cloud native

8
00:01:07,966 --> 00:01:11,614
developers and sres can take control of reliability?

9
00:01:11,742 --> 00:01:15,122
So in this session we're going to touch upon what is

10
00:01:15,176 --> 00:01:19,122
reliability and what it means to achieve reliability

11
00:01:19,186 --> 00:01:22,626
in cloud native environments. And we will see chaos engineering

12
00:01:22,658 --> 00:01:26,610
as a way to achieve reliability in cloud native environments.

13
00:01:26,770 --> 00:01:30,118
What are the good practices for both sres and developers?

14
00:01:30,214 --> 00:01:33,894
And I will also touch upon Litmus chaos, which is the Chaos

15
00:01:33,942 --> 00:01:37,958
engineering project for achieving reliability in cloud native

16
00:01:38,054 --> 00:01:41,454
what is reliability and what it means in cloud

17
00:01:41,492 --> 00:01:46,222
native environments? Generally, reliability means you

18
00:01:46,356 --> 00:01:49,310
run your services without any outage.

19
00:01:50,130 --> 00:01:53,746
Then you are called as very reliable, but it

20
00:01:53,768 --> 00:01:57,890
does not end with that. It also means that you

21
00:01:58,040 --> 00:02:02,146
need to have some slos or business slas met

22
00:02:02,328 --> 00:02:06,758
even though you are running without an outage, for example, latency for service

23
00:02:06,924 --> 00:02:10,854
performance under scale, et cetera. So you

24
00:02:10,972 --> 00:02:14,326
sometimes need to measure reliability when you

25
00:02:14,348 --> 00:02:17,702
are asked to ramp up your services. There are certain

26
00:02:17,756 --> 00:02:21,626
days in which you are going to scale your services to

27
00:02:21,648 --> 00:02:25,402
a high degree and your slos need to be met on

28
00:02:25,456 --> 00:02:28,966
such days. So that's also a measure of reliability.

29
00:02:29,078 --> 00:02:32,574
So there is also the upgrade scenario. You will end

30
00:02:32,612 --> 00:02:35,870
up upgrading the services in production and

31
00:02:35,940 --> 00:02:39,614
they need to be continuously adhering to your

32
00:02:39,652 --> 00:02:42,890
slos. So you put all these things together.

33
00:02:43,060 --> 00:02:46,514
You call that as a measure of

34
00:02:46,552 --> 00:02:50,062
reliability? If you're satisfying all this criteria,

35
00:02:50,126 --> 00:02:53,442
your services are set to be reliable. Why are

36
00:02:53,496 --> 00:02:56,114
they important in cloud native?

37
00:02:56,242 --> 00:03:00,342
Primarily in cloud native, your application is

38
00:03:00,476 --> 00:03:04,402
now split into multiple microservices.

39
00:03:04,546 --> 00:03:08,426
That means you have more services to manage or more applications to

40
00:03:08,448 --> 00:03:12,538
manage in your larger service. And those

41
00:03:12,704 --> 00:03:16,502
applications are changing very fast in your environment,

42
00:03:16,646 --> 00:03:20,774
primarily because of the advances in your CACD

43
00:03:20,822 --> 00:03:24,846
pipelines and the CACD pipelines of the applications that

44
00:03:24,868 --> 00:03:28,206
you're using as just a service. It could

45
00:03:28,228 --> 00:03:32,238
be some other cloud native service, for example. Those changes are coming fast

46
00:03:32,324 --> 00:03:35,874
into your environments earlier. It's very common

47
00:03:35,992 --> 00:03:39,134
to see big changes happen in production

48
00:03:39,182 --> 00:03:42,882
environments every quarter or two, but in cloud

49
00:03:42,936 --> 00:03:46,450
native they are happening almost every

50
00:03:46,520 --> 00:03:50,562
week. Because you've got so many changes, you don't want to schedule

51
00:03:50,626 --> 00:03:54,614
them for all a fixed state, and you want to automate them in such

52
00:03:54,652 --> 00:03:58,066
a way that the upgrades do happen as soon as possible.

53
00:03:58,188 --> 00:04:01,914
And then you have a system to make sure that irrespective of these

54
00:04:01,952 --> 00:04:05,482
upgrades, your systems are reliable. So that's your

55
00:04:05,616 --> 00:04:09,046
target. And that's what brings us the topic

56
00:04:09,078 --> 00:04:13,114
of how to achieve that reliability in cloud native. In summary,

57
00:04:13,242 --> 00:04:17,226
reliability is very important because there are many applications

58
00:04:17,258 --> 00:04:20,654
that you're dealing with in cloud native and the changes to them are coming

59
00:04:20,692 --> 00:04:24,258
too fast. How do you achieve such a reliability? Or how do

60
00:04:24,264 --> 00:04:27,854
you plan to strategize in achieving such a reliability

61
00:04:27,902 --> 00:04:31,438
for your cloud native? One answer is you implement

62
00:04:31,534 --> 00:04:35,214
the practice of chaos engineering from beginning and

63
00:04:35,352 --> 00:04:39,126
you do it at scale. Then you have at least a

64
00:04:39,148 --> 00:04:42,806
good proven way of achieving reliability. Let's look

65
00:04:42,828 --> 00:04:46,562
at what is chaos engineering? What is chaos engineering?

66
00:04:46,626 --> 00:04:49,974
Why chaos engineering and how do you practice chaos

67
00:04:50,022 --> 00:04:53,818
engineering in the what part? It's about

68
00:04:53,984 --> 00:04:58,026
breaking things on purpose. Or you can also say don't wait for

69
00:04:58,048 --> 00:05:01,622
the failure to happen, you inject. You can also say it's

70
00:05:01,686 --> 00:05:05,310
practices resilience engineering and it's about

71
00:05:05,460 --> 00:05:08,778
being better prepared for disasters.

72
00:05:08,874 --> 00:05:12,474
When some launch failure or an outage happens, how are

73
00:05:12,532 --> 00:05:16,322
you really prepared to bring your services back online?

74
00:05:16,456 --> 00:05:20,562
Right. If you have chaos engineering, we would have dealt with

75
00:05:20,696 --> 00:05:24,402
such an option and you are now better

76
00:05:24,456 --> 00:05:27,378
prepared. So why chaos engineering?

77
00:05:27,474 --> 00:05:31,346
Because big outages are expensive, sometimes smaller.

78
00:05:31,378 --> 00:05:35,318
Outage also can be expensive depending on your

79
00:05:35,404 --> 00:05:38,826
slas to your end users. And you

80
00:05:38,848 --> 00:05:42,122
cannot really prevent outages. No matter how well

81
00:05:42,176 --> 00:05:45,914
you are prepared and tested, outages will happen.

82
00:05:46,032 --> 00:05:49,514
So you better be prepared for that. And there

83
00:05:49,552 --> 00:05:53,054
are too many unknown, too many changes happening. We just

84
00:05:53,092 --> 00:05:56,746
discussed why is reliability important in cloud native?

85
00:05:56,858 --> 00:06:00,766
So chaos engineering is needed because you don't know

86
00:06:00,868 --> 00:06:04,458
everything about your entire knowns and unknowns, right?

87
00:06:04,564 --> 00:06:08,626
So chaos engineering, why you should do because there

88
00:06:08,648 --> 00:06:13,134
are tools in place now. There is so much knowledge

89
00:06:13,182 --> 00:06:17,234
available in chaos engineering space, especially in cloud native,

90
00:06:17,362 --> 00:06:20,566
that you can actually easily do it and you

91
00:06:20,588 --> 00:06:24,134
can avert bigger financial losses and be

92
00:06:24,172 --> 00:06:27,722
in control of your reliability. And that's one reason why

93
00:06:27,776 --> 00:06:30,666
you need to do chaos engineering. How do you do it?

94
00:06:30,768 --> 00:06:35,114
Primarily it is a culture. Still, many people are

95
00:06:35,232 --> 00:06:39,180
grasping the need for chaos engineering and

96
00:06:39,550 --> 00:06:42,702
starting from developers, sres and all the way

97
00:06:42,756 --> 00:06:46,350
to the management who are responsible for

98
00:06:46,420 --> 00:06:50,110
operational reliability. So you start

99
00:06:50,180 --> 00:06:53,134
with advocating or learning chaos engineering.

100
00:06:53,182 --> 00:06:56,850
That's really how you start with and you create a strategy and

101
00:06:56,920 --> 00:07:00,002
choose a platform that suits your needs

102
00:07:00,136 --> 00:07:04,370
and really build a service within

103
00:07:04,440 --> 00:07:08,114
your environment rather than just a set of chaos engineering

104
00:07:08,162 --> 00:07:12,118
experiments or chaos experiments. So you need to look at it

105
00:07:12,204 --> 00:07:15,686
at bigger picture. Chaos engineering has to

106
00:07:15,708 --> 00:07:19,170
have goals of increasing reliability over a

107
00:07:19,180 --> 00:07:22,570
period of time. And one way you can start or keep

108
00:07:22,640 --> 00:07:25,926
repeating is doing game days. These are proven

109
00:07:26,038 --> 00:07:29,594
very helpful to build a culture as well as to build

110
00:07:29,792 --> 00:07:33,278
a practice around your chaos engineering is working well or not,

111
00:07:33,364 --> 00:07:37,200
and it's always difficult to go and break things

112
00:07:37,570 --> 00:07:41,406
in production. So you start small and

113
00:07:41,588 --> 00:07:45,186
you keep fixing things and then you slowly move

114
00:07:45,208 --> 00:07:48,930
on to pre production in production. I'll talk about it later

115
00:07:49,000 --> 00:07:52,338
in this session. So what are the business benefits?

116
00:07:52,504 --> 00:07:56,546
Right? So you cannot avoid outages. So you shorten

117
00:07:56,578 --> 00:08:00,278
your outages. That means you are better prepared and you can really

118
00:08:00,364 --> 00:08:03,734
prevent large revenue losses by finding them

119
00:08:03,772 --> 00:08:07,318
early in pre production and fixing them.

120
00:08:07,404 --> 00:08:10,874
And your overall customer satisfaction will

121
00:08:10,912 --> 00:08:14,694
either go up or your customers are happy. You'll be able to retain

122
00:08:14,742 --> 00:08:18,090
them because you already fixed something before they actually

123
00:08:18,160 --> 00:08:21,934
cause losses to your customers. This is like on the

124
00:08:21,972 --> 00:08:25,178
business side, but your end users

125
00:08:25,274 --> 00:08:28,906
can also move to this new architecture,

126
00:08:29,018 --> 00:08:32,914
or you move to your bigger and better new

127
00:08:32,952 --> 00:08:36,974
architecture fast because now you have a way of finding

128
00:08:37,022 --> 00:08:40,670
how resilient your systems are. That's definitely a good benefit.

129
00:08:40,750 --> 00:08:44,574
And scaling your services, you implement your larger

130
00:08:44,622 --> 00:08:48,206
service for the optimal size and you scale

131
00:08:48,238 --> 00:08:51,842
up as you need it. And you can test that with chaos engineering.

132
00:08:51,906 --> 00:08:55,126
And you know that you're going to scale well when

133
00:08:55,148 --> 00:08:59,286
the need arises. So you don't need to really run them at scale bigger

134
00:08:59,318 --> 00:09:02,790
than what's needed, right? So that's definitely a benefit.

135
00:09:02,870 --> 00:09:06,234
The other benefit is how well your team

136
00:09:06,272 --> 00:09:09,430
is prepared for a given fault,

137
00:09:09,510 --> 00:09:13,182
right? So you don't need to guess. You knew that

138
00:09:13,236 --> 00:09:17,514
your team can respond well because you just experienced

139
00:09:17,562 --> 00:09:20,926
it by injecting a similar. So what are the

140
00:09:20,948 --> 00:09:24,466
business use cases where chaos engineering can

141
00:09:24,488 --> 00:09:28,114
be considered? Now we know the benefits. What are the business use

142
00:09:28,152 --> 00:09:31,778
case? As the digital transformation is happening,

143
00:09:31,864 --> 00:09:35,346
we are all moving to microservices. So you would want to

144
00:09:35,368 --> 00:09:38,966
see what is the reliability today and what is the benchmark that

145
00:09:38,988 --> 00:09:42,482
you need after you move to this microservices architecture.

146
00:09:42,546 --> 00:09:46,070
Chaos engineering has to be put in place or can be put in place

147
00:09:46,220 --> 00:09:50,406
to benchmark that. And you can also accelerate

148
00:09:50,518 --> 00:09:54,634
because now you have confident way of measuring the

149
00:09:54,672 --> 00:09:58,570
reliability. So you can accelerate the journey to containerization.

150
00:09:58,990 --> 00:10:03,038
You can benchmark and measure and scale your service. There are

151
00:10:03,124 --> 00:10:06,702
many sectors where chaos engineering is

152
00:10:06,756 --> 00:10:10,650
proven helpful, especially when they are a large scale

153
00:10:10,730 --> 00:10:14,622
and they are critical. For example, banking sector, retail sector,

154
00:10:14,686 --> 00:10:18,450
ecommerce sectors, these are all already in production. They are

155
00:10:18,520 --> 00:10:22,542
very critical as far as the user experience is concerned. Any losses

156
00:10:22,606 --> 00:10:26,130
or outages will cause bigger financial losses.

157
00:10:26,210 --> 00:10:30,386
So chaos engineering will really help in these sectors

158
00:10:30,578 --> 00:10:34,326
and also the edge computing, you are moving there very fast

159
00:10:34,428 --> 00:10:37,766
and there are many of such services that are in

160
00:10:37,788 --> 00:10:41,030
place. So you want to automate your failure testing

161
00:10:41,190 --> 00:10:44,634
in edge computing. So that's another area where you can

162
00:10:44,672 --> 00:10:48,714
find chaos engineering as very helpful. Generally where

163
00:10:48,752 --> 00:10:52,562
do you do chaos engineering is in many places,

164
00:10:52,726 --> 00:10:56,302
so you could find them in game days. You can find

165
00:10:56,356 --> 00:10:59,674
them the developers using in CA pipelines or SRS

166
00:10:59,722 --> 00:11:03,890
using as a way to trigger your continuous deployments, or after

167
00:11:03,960 --> 00:11:07,634
you did continuous deployment, how do you measure things are okay or

168
00:11:07,672 --> 00:11:11,154
not? And there are various temps where

169
00:11:11,192 --> 00:11:14,766
your failure testing in your pipelines or staged

170
00:11:14,798 --> 00:11:18,482
environments are not good enough. You want to automate more corner

171
00:11:18,546 --> 00:11:22,114
scenarios for failure. And there is another advanced

172
00:11:22,162 --> 00:11:25,494
use case where an application has been upgraded in

173
00:11:25,532 --> 00:11:28,746
your production and you want to trigger some failure testing in

174
00:11:28,768 --> 00:11:33,030
a random way onto that. So that's triggering chaos

175
00:11:33,190 --> 00:11:36,330
on the trigger of application change.

176
00:11:36,480 --> 00:11:40,074
So these are various ways, various reasons, various use

177
00:11:40,112 --> 00:11:44,126
cases in which chaos engineering can be very helpful. Let's look

178
00:11:44,148 --> 00:11:48,094
at what is cloud native chaos engineering? We talked about why

179
00:11:48,132 --> 00:11:51,658
chaos engineering is important in cloud native.

180
00:11:51,754 --> 00:11:55,550
When you are doing chaos engineering in cloud native, you can generally

181
00:11:55,630 --> 00:11:59,138
consider certain principles and cloud native is a

182
00:11:59,144 --> 00:12:02,926
reality right now where kubernetes has crossed the chaos.

183
00:12:03,038 --> 00:12:06,806
And whereas chaos engineering is in the early

184
00:12:06,908 --> 00:12:10,598
days of implementation or being considered as a

185
00:12:10,604 --> 00:12:14,086
must for reliability, there are a lot of options available

186
00:12:14,188 --> 00:12:17,834
today to do chaos engineering in cloud native at

187
00:12:17,872 --> 00:12:21,270
scale. And generally you can follow these principles

188
00:12:21,350 --> 00:12:24,902
while choosing the implementation of chaos engineering.

189
00:12:24,966 --> 00:12:29,826
It's always good to go with a technology that is open source proven

190
00:12:29,958 --> 00:12:32,698
and that's community collaborated.

191
00:12:32,874 --> 00:12:36,506
So the chaos experiments that are developed

192
00:12:36,618 --> 00:12:40,906
through community collaborations will have less chance of false positives

193
00:12:40,938 --> 00:12:44,226
or false negatives because they're well tested. You are in

194
00:12:44,248 --> 00:12:47,298
control of what exactly is the fault that is getting in.

195
00:12:47,384 --> 00:12:51,486
And these chaos experiments or chaos workflows

196
00:12:51,518 --> 00:12:55,006
or chaos scenarios, whatever you call them, they also go

197
00:12:55,048 --> 00:12:58,454
through changes, they need to be maintained. So it's better to

198
00:12:58,492 --> 00:13:02,006
have good API or operators to do

199
00:13:02,028 --> 00:13:06,082
the lifecycle management of such chaos experiments.

200
00:13:06,146 --> 00:13:09,770
And scaling is very important. When you scale your

201
00:13:09,840 --> 00:13:13,882
services. Chaos engineering has to scale as well. Think of

202
00:13:13,936 --> 00:13:17,894
killing container where there are thousands of containers

203
00:13:18,022 --> 00:13:21,742
and then you want to bring off of them down for whatever

204
00:13:21,796 --> 00:13:25,774
reason, right? So you need to scale well. Your infrastructure should

205
00:13:25,812 --> 00:13:28,906
scale well to induce chaos and observability

206
00:13:29,098 --> 00:13:32,602
should be an open one. It's very important

207
00:13:32,756 --> 00:13:36,258
to be able to observe what exactly is happening.

208
00:13:36,344 --> 00:13:39,822
When chaos was introduced. You are most likely

209
00:13:39,886 --> 00:13:43,122
following observability platforms that are based

210
00:13:43,176 --> 00:13:46,722
on Prometheus. So your chaos interleaving

211
00:13:46,866 --> 00:13:50,550
also should be open in nature. You should be having

212
00:13:50,620 --> 00:13:54,230
clear idea on when was chaos injected and

213
00:13:54,300 --> 00:13:58,138
what was that chaos and how it was injected. So consider

214
00:13:58,224 --> 00:14:02,426
all these principles while choosing your platform

215
00:14:02,528 --> 00:14:06,074
for chaos engineering. In cloud native. Let's generally talk

216
00:14:06,112 --> 00:14:10,074
about what it means for sres and

217
00:14:10,112 --> 00:14:13,982
developers later on. So for sres there are many ways

218
00:14:14,036 --> 00:14:17,562
to start, and primarily it starts in staging,

219
00:14:17,626 --> 00:14:21,326
right? And then you move on to pre production and then you move

220
00:14:21,348 --> 00:14:25,170
on to production. As an SRE, you have to start believing

221
00:14:25,590 --> 00:14:29,554
in chaos engineering is a helper tool and

222
00:14:29,752 --> 00:14:32,530
there is going to be a lot of business benefits,

223
00:14:32,680 --> 00:14:35,838
operational benefits that we talked about earlier in

224
00:14:35,864 --> 00:14:40,210
this session. And you need to be able to convince this benefit

225
00:14:40,290 --> 00:14:43,734
to your teammates, to your management. And how

226
00:14:43,772 --> 00:14:47,574
you do that is by doing some simple chaos experiments in

227
00:14:47,612 --> 00:14:50,854
staging, and also try to inject values and

228
00:14:50,892 --> 00:14:54,198
see whether your auto scale works or not on kubernetes,

229
00:14:54,294 --> 00:14:58,362
et cetera. And you also generally do a simple game

230
00:14:58,416 --> 00:15:02,090
day as a way to express confidence

231
00:15:02,250 --> 00:15:06,570
in culture implementation of chaos engineering.

232
00:15:06,650 --> 00:15:09,934
In summary, you start in staging or as

233
00:15:09,972 --> 00:15:13,542
a trigger to your CD with some simple experiment,

234
00:15:13,626 --> 00:15:17,282
and that can go on for a quarter and you can

235
00:15:17,336 --> 00:15:21,310
increase the complexity of such experiments slowly.

236
00:15:21,390 --> 00:15:24,494
You need to gain confidence as well as your team's confidence,

237
00:15:24,622 --> 00:15:28,006
and you do that and then slowly move

238
00:15:28,028 --> 00:15:31,766
on to the other areas. After a quarter move

239
00:15:31,788 --> 00:15:35,330
to pre production. And generally it takes more than a couple of quarters

240
00:15:35,410 --> 00:15:39,802
to do any real failure testing in production because

241
00:15:39,936 --> 00:15:43,654
you should really convince yourself and your fellow

242
00:15:43,702 --> 00:15:46,966
team members that your infrastructure

243
00:15:47,078 --> 00:15:50,462
of chaos engineering is stable. You are not doing any

244
00:15:50,516 --> 00:15:54,094
false positives or negatives, and you have seen some good benefits

245
00:15:54,292 --> 00:15:58,638
of injecting faults and you are able to respond to

246
00:15:58,724 --> 00:16:02,814
such small outages or big outages and you

247
00:16:02,852 --> 00:16:06,254
plan and then move on. So that's more into production.

248
00:16:06,302 --> 00:16:09,602
That's really about being better prepared. Do you really need

249
00:16:09,736 --> 00:16:13,294
chaos engineering? For developers in cloud native environment,

250
00:16:13,422 --> 00:16:16,854
we've been seeing a lot of positive response from

251
00:16:16,892 --> 00:16:20,374
developer community to chaos engineering, and it

252
00:16:20,412 --> 00:16:23,782
is not really tied to whether your

253
00:16:23,836 --> 00:16:27,302
sres are practicing chaos engineering or not. It's really

254
00:16:27,356 --> 00:16:31,126
about an extension to your existing CA pipelines.

255
00:16:31,238 --> 00:16:35,226
So why do you need chaos engineering? In your

256
00:16:35,248 --> 00:16:39,354
CA pipelines? Primarily the changes are happening fast.

257
00:16:39,472 --> 00:16:43,002
You are supposed to be developing and shipping

258
00:16:43,066 --> 00:16:46,474
your services fast. At the same time, in your CI pipelines

259
00:16:46,522 --> 00:16:50,014
there are a lot of other microservices which are not developed by you.

260
00:16:50,052 --> 00:16:53,906
You depend on them, and there are many

261
00:16:54,008 --> 00:16:57,874
of such microservices which are making your pipelines more

262
00:16:57,912 --> 00:17:01,358
dynamic and more complex and bigger,

263
00:17:01,454 --> 00:17:05,210
right? You need to have a defined

264
00:17:05,310 --> 00:17:09,334
strategy not only to test your code,

265
00:17:09,452 --> 00:17:13,330
but also to test the other microservices

266
00:17:13,490 --> 00:17:17,058
and other platform changes inside your pipelines.

267
00:17:17,154 --> 00:17:20,874
So typically this is your regular pipeline, you're trying

268
00:17:20,912 --> 00:17:24,666
to take care of your code. And in addition you

269
00:17:24,688 --> 00:17:28,166
need to consider continuous verification of the underlying

270
00:17:28,198 --> 00:17:32,194
platform. It may be a good idea to run your pipelines

271
00:17:32,262 --> 00:17:35,886
on multiple platforms, right? Different cloud platforms or

272
00:17:35,908 --> 00:17:38,842
on Prem. Because it is a microservice,

273
00:17:38,906 --> 00:17:42,446
you don't know where it all is going to run. And it is better to

274
00:17:42,468 --> 00:17:45,794
inject failures in the pipeline in such platforms and

275
00:17:45,832 --> 00:17:49,474
see whether your code is behaving well. And similarly other

276
00:17:49,512 --> 00:17:53,122
microservices, they can fail and then you better test

277
00:17:53,176 --> 00:17:56,626
them right inside the pipeline how your code responds

278
00:17:56,658 --> 00:18:00,710
to such a failure. So this is really about this continuous verification

279
00:18:01,050 --> 00:18:04,870
of either the platform failures or the

280
00:18:04,940 --> 00:18:08,714
services. Your dependent microservices failures is

281
00:18:08,752 --> 00:18:12,794
really called as chaos engineering for developers, primarily in

282
00:18:12,832 --> 00:18:16,534
cloud native. So with that introduction to why chaos

283
00:18:16,582 --> 00:18:20,210
engineering and why chaos engineering for cloud native,

284
00:18:20,310 --> 00:18:23,774
let me introduce Litmus Chaos, which is a project

285
00:18:23,892 --> 00:18:27,082
that we started a few years ago with the core

286
00:18:27,146 --> 00:18:29,578
goal of this Chaos engineering principles.

287
00:18:29,674 --> 00:18:33,466
And Litmus supports all these principles

288
00:18:33,578 --> 00:18:37,306
very well. The latest release of Litmus supports

289
00:18:37,338 --> 00:18:40,000
Gitops and open observability as well.

290
00:18:40,390 --> 00:18:43,714
So it is a CNCF project which is

291
00:18:43,752 --> 00:18:47,174
currently at Sandbox state and we

292
00:18:47,212 --> 00:18:51,382
are hoping that we'll be moving to incubation very soon.

293
00:18:51,516 --> 00:18:54,646
And it has got a great adoption in

294
00:18:54,668 --> 00:18:58,246
terms of more than 50,000 installations or operators

295
00:18:58,278 --> 00:19:01,722
running. And we built a good community around

296
00:19:01,856 --> 00:19:05,334
the usage of litmus and primarily

297
00:19:05,382 --> 00:19:09,334
around Kubernetes chaos engineering.

298
00:19:09,462 --> 00:19:12,794
So at the outset, litmus is really a

299
00:19:12,832 --> 00:19:16,302
simple helm shot, either for

300
00:19:16,356 --> 00:19:19,998
one developer or one SRE, or for

301
00:19:20,084 --> 00:19:23,906
the entire team or an enterprise. Litmus is a Kubernetes application

302
00:19:24,008 --> 00:19:27,554
that scales very well. And all the experiments or

303
00:19:27,672 --> 00:19:31,758
chaos workflows are published in Chaos Hub,

304
00:19:31,934 --> 00:19:35,514
public Chaos Hub, and you can pull them into your private environments

305
00:19:35,582 --> 00:19:38,978
and set them in a completely air capped

306
00:19:38,994 --> 00:19:43,122
environment. So when you install Litmus, you get a centralized chaos

307
00:19:43,186 --> 00:19:46,678
control plane called Litmus portal and you can start

308
00:19:46,764 --> 00:19:50,882
either running a predefined chaos workflows or you can construct chaos

309
00:19:50,946 --> 00:19:54,618
workloads very seamlessly and you target them against

310
00:19:54,704 --> 00:19:58,822
any other Kubernetes resource. Or you can also target

311
00:19:58,886 --> 00:20:02,330
them towards non Kubernetes resources such as vms,

312
00:20:02,410 --> 00:20:05,866
bare metals and also other cloud platforms.

313
00:20:05,978 --> 00:20:09,754
And all of this you can do it with integrated Gitops

314
00:20:09,882 --> 00:20:12,822
such as Argo CD or plug CD.

315
00:20:12,986 --> 00:20:16,078
When integrated, this chaos can be triggered

316
00:20:16,174 --> 00:20:19,362
as a way as a change happens to your

317
00:20:19,416 --> 00:20:23,506
application. So in a nutshell, litmus has

318
00:20:23,608 --> 00:20:27,230
a control plane, chaos control plane, actual chaos plane.

319
00:20:27,310 --> 00:20:30,838
Target your chaos from the centralized portal or through

320
00:20:30,924 --> 00:20:34,614
GitHub's controlled infrastructure. This chaos workflows can

321
00:20:34,652 --> 00:20:38,010
be directed towards any Kubernetes resource or any

322
00:20:38,080 --> 00:20:41,978
non Kubernetes resource as well. Highly declarative and

323
00:20:42,144 --> 00:20:45,594
API scalable API is there and it is

324
00:20:45,632 --> 00:20:49,114
obviously open source and you are in control of your

325
00:20:49,152 --> 00:20:52,574
chaos. There are a lot of good examples of how

326
00:20:52,612 --> 00:20:56,430
you can use Litmus in CI pipelines can use

327
00:20:56,580 --> 00:21:00,202
them. There are known examples of GitLab GitHub actions,

328
00:21:00,266 --> 00:21:04,174
spinnaker or captain using Litmus to introduce

329
00:21:04,222 --> 00:21:07,518
a chaos stage. And at the outset

330
00:21:07,614 --> 00:21:11,586
all this chaos logic is bundled into a

331
00:21:11,608 --> 00:21:15,198
library and with simple API calling of

332
00:21:15,224 --> 00:21:18,838
that library you'll be able to inject chaos and then

333
00:21:18,924 --> 00:21:22,114
get a result of that chaos experiment.

334
00:21:22,242 --> 00:21:25,570
And litmus is not just only for Kubernetes,

335
00:21:25,650 --> 00:21:29,318
it is a Kubernetes application, but it can inject failures

336
00:21:29,414 --> 00:21:32,874
into non Kubernetes platforms and

337
00:21:32,912 --> 00:21:36,506
it can scale very easily and to

338
00:21:36,528 --> 00:21:39,866
a large scale as well. We do have certain examples of how you

339
00:21:39,888 --> 00:21:43,006
can inject failures into this cloud platform such

340
00:21:43,028 --> 00:21:46,510
as AWS, GCP or Azure. And we also have some

341
00:21:46,580 --> 00:21:50,474
experiments, initial experiments of how you can inject

342
00:21:50,602 --> 00:21:54,094
chaos into VMware platform. These are expected

343
00:21:54,142 --> 00:21:57,618
to grow very heavily, months or quarters to come.

344
00:21:57,704 --> 00:22:01,474
Litmus is well adopted, stable, but also

345
00:22:01,592 --> 00:22:05,394
ready for enterprise adoption. I am part of chaos

346
00:22:05,442 --> 00:22:09,158
native team and we provide enterprise support for

347
00:22:09,244 --> 00:22:12,694
enterprises who are deploying litmus in

348
00:22:12,732 --> 00:22:16,514
production environments or non production environments.

349
00:22:16,642 --> 00:22:20,882
So with that, I would like to thank you for watching this session

350
00:22:21,026 --> 00:22:24,854
and you can reach me on Twitter or on

351
00:22:24,892 --> 00:22:27,160
kubernetes. Slack thank you very much.

352
00:22:30,370 --> 00:22:40,060
Our channel.

