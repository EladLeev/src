1
00:00:00,410 --> 00:00:06,174
Jamaica make a real

2
00:00:06,212 --> 00:00:09,934
time feedback into the behavior of your distributed systems and

3
00:00:09,972 --> 00:00:13,374
observing changes exceptions errors in

4
00:00:13,412 --> 00:00:16,746
real time allows youve to not only experiment with confidence,

5
00:00:16,858 --> 00:00:20,560
but respond instantly to get things working again.

6
00:00:24,610 --> 00:00:50,478
Close event

7
00:00:50,564 --> 00:00:54,126
driven applications with NestJs, which is a

8
00:00:54,148 --> 00:00:58,798
modern framework for building back end node JS applications today

9
00:00:58,884 --> 00:01:02,106
I will talk briefly about what is Nest JS?

10
00:01:02,298 --> 00:01:05,250
How does it help build scalable applications?

11
00:01:05,670 --> 00:01:09,426
I have a demo ready for you and we'll describe the

12
00:01:09,448 --> 00:01:12,866
overall architecture and the tools used and

13
00:01:12,888 --> 00:01:16,690
then we will run and see this demo in action.

14
00:01:17,430 --> 00:01:21,490
So what is NestJs? It's a framework for building

15
00:01:21,560 --> 00:01:25,042
node JS applications. It was inspired

16
00:01:25,106 --> 00:01:28,570
by angular and relies heavily on typescript,

17
00:01:29,150 --> 00:01:33,100
so it provides a somewhat typesafe development experience.

18
00:01:34,030 --> 00:01:37,626
It's still a javascript after transpiling, so you

19
00:01:37,648 --> 00:01:40,650
should cases when dealing with common security risks.

20
00:01:41,490 --> 00:01:44,942
It's popular framework already and youve probably heard

21
00:01:44,996 --> 00:01:48,382
about it. Let's quickly

22
00:01:48,436 --> 00:01:52,174
recap what the framework offers us one

23
00:01:52,212 --> 00:01:55,682
of the main advantages of using a framework is having

24
00:01:55,736 --> 00:01:59,186
a dependency injection. It removes the

25
00:01:59,208 --> 00:02:03,250
overhead of creating and supporting a class dependency tree.

26
00:02:03,830 --> 00:02:07,030
It has abstracted integration with most

27
00:02:07,100 --> 00:02:10,840
databases, so you don't have to think about it.

28
00:02:11,530 --> 00:02:15,638
It has abstracted common use cases for web development like

29
00:02:15,724 --> 00:02:20,518
caching, configuration API, versioning and documentation

30
00:02:20,694 --> 00:02:24,934
queues and so on. For the HTTP server

31
00:02:24,982 --> 00:02:27,610
youve can choose between exprs or fastify.

32
00:02:29,470 --> 00:02:33,290
Yeah, it uses typescript and decorators. I think it simplifies

33
00:02:33,370 --> 00:02:36,750
reading the code, especially in bigger projects,

34
00:02:37,410 --> 00:02:41,358
and it allows the team of developers to be on the same page

35
00:02:41,524 --> 00:02:43,810
when reasoning about components.

36
00:02:44,950 --> 00:02:47,598
Also, of course, as with any framework,

37
00:02:47,694 --> 00:02:52,238
it provides other application design elements like middleware,

38
00:02:52,334 --> 00:02:56,054
exception filters, guards, pipes and so on.

39
00:02:56,252 --> 00:03:00,162
And finally, we'll talk later about some other features

40
00:03:00,226 --> 00:03:02,230
that are specific to scalability.

41
00:03:03,450 --> 00:03:07,830
So how does Nest JS help us build scalable applications?

42
00:03:08,430 --> 00:03:12,650
Let's first recap the main strategies for building such applications.

43
00:03:13,550 --> 00:03:17,750
The common approaches are building the monolith

44
00:03:17,830 --> 00:03:19,500
with a modular design,

45
00:03:20,370 --> 00:03:24,126
microservices, event driven application,

46
00:03:24,308 --> 00:03:27,566
or a mixed approach. And I think this is

47
00:03:27,588 --> 00:03:30,350
the most common in long living projects.

48
00:03:31,490 --> 00:03:35,730
For the first approach I want to talk about is monolith.

49
00:03:36,070 --> 00:03:39,182
It's a single application that has components

50
00:03:39,246 --> 00:03:43,214
tightly coupled. They are deployed together, they are supported

51
00:03:43,262 --> 00:03:47,000
together, and usually they can't leave one without another.

52
00:03:47,690 --> 00:03:51,442
If you write your application that way, it's best to use a modular

53
00:03:51,506 --> 00:03:54,200
approach, which by the way,

54
00:03:54,570 --> 00:03:56,600
NestJs is very good at.

55
00:03:57,930 --> 00:04:02,026
When using modular approach, you can effectively have one code base,

56
00:04:02,208 --> 00:04:05,782
but components of your system act as somewhat

57
00:04:05,846 --> 00:04:09,034
independent entities and can be

58
00:04:09,072 --> 00:04:12,874
worked on by different teams. This becomes harder

59
00:04:12,922 --> 00:04:16,494
as your team and project grows. That's why we

60
00:04:16,532 --> 00:04:18,750
have other models for development.

61
00:04:19,890 --> 00:04:24,100
Microservices are when you have separate deployers for each service.

62
00:04:24,950 --> 00:04:28,606
Usually each service is only responsible for a small unit

63
00:04:28,638 --> 00:04:32,020
of work and will have its own store.

64
00:04:32,710 --> 00:04:37,346
It will communicate with other services via HTTP

65
00:04:37,378 --> 00:04:41,510
request or messaging. Next the

66
00:04:41,580 --> 00:04:45,030
event driven approach is similar to microservices,

67
00:04:45,690 --> 00:04:49,662
but usually you don't have direct communications

68
00:04:49,746 --> 00:04:53,674
between them. Instead, each service will

69
00:04:53,712 --> 00:04:57,334
emit an event, and then it simply doesn't

70
00:04:57,382 --> 00:05:01,326
care. There can be listeners to this event, but there can

71
00:05:01,348 --> 00:05:04,814
be no listeners. If the event is

72
00:05:04,852 --> 00:05:08,560
consumed by someone, it can again produce another event

73
00:05:09,090 --> 00:05:12,410
that can be again consumed by another service,

74
00:05:12,580 --> 00:05:16,020
and so on. So every service

75
00:05:16,710 --> 00:05:21,022
is independent of one another. They only listen and produce

76
00:05:21,086 --> 00:05:24,862
events. Eventually someone will produce

77
00:05:24,926 --> 00:05:28,834
a response for the client waiting. It could be a websocket

78
00:05:28,882 --> 00:05:32,280
response, for example, or a webhook or whatever.

79
00:05:33,050 --> 00:05:36,978
Usually our larger projects are a mix of all designs.

80
00:05:37,154 --> 00:05:41,020
You have components that are tightly coupled and deployed together.

81
00:05:41,870 --> 00:05:45,900
Some components are deployed separately and

82
00:05:46,350 --> 00:05:50,250
some are communicating exclusively via event messaging.

83
00:05:51,230 --> 00:05:54,822
Let's think about why NestJs simplifies

84
00:05:54,886 --> 00:05:58,478
event driven development. First of all,

85
00:05:58,564 --> 00:06:02,202
it allows really fast and simple integration of a popular

86
00:06:02,266 --> 00:06:06,434
bulb package for queues for

87
00:06:06,472 --> 00:06:10,290
microservices developing and communication.

88
00:06:10,790 --> 00:06:15,274
It has integrations with the most popular messaging brokers

89
00:06:15,342 --> 00:06:18,546
like Redis, Kafka,

90
00:06:18,738 --> 00:06:22,114
RabbitMQ, MQTT, Nuts,

91
00:06:22,162 --> 00:06:23,400
and so on.

92
00:06:25,450 --> 00:06:29,222
Third, it promotes modular development, so it's naturally

93
00:06:29,286 --> 00:06:32,666
easy for you to extract single units of work later in

94
00:06:32,688 --> 00:06:36,314
the project's lifecycle, even if you start your project as

95
00:06:36,352 --> 00:06:40,054
a monolith. My next point is it has

96
00:06:40,112 --> 00:06:43,726
great documentation and examples, which is always nice to

97
00:06:43,748 --> 00:06:47,374
have. You can be running your first distributed app

98
00:06:47,412 --> 00:06:51,294
in minutes with Nest Js and

99
00:06:51,332 --> 00:06:55,214
another thing I want to note is unit and integration testing

100
00:06:55,262 --> 00:06:58,590
is bootstrapped for you. It has dependency

101
00:06:58,670 --> 00:07:02,766
injection for testing and all other powerful features

102
00:07:02,798 --> 00:07:06,706
of a jest testing framework. Now let's see how

103
00:07:06,728 --> 00:07:09,970
a simple queue can be created in sjs.

104
00:07:10,330 --> 00:07:13,030
First you install the required dependencies,

105
00:07:13,930 --> 00:07:17,882
then you create a connection to redis and

106
00:07:17,936 --> 00:07:21,660
finally register a queue and that's it.

107
00:07:23,470 --> 00:07:26,822
Next, somewhere else in a service constructor,

108
00:07:26,886 --> 00:07:30,286
you type hint your queue and it

109
00:07:30,308 --> 00:07:34,190
gets injected by the dependency ejection container.

110
00:07:35,010 --> 00:07:39,310
You now have full access to the queue and can start emitting events

111
00:07:40,290 --> 00:07:44,340
some way. In another module youve decorate your processor class

112
00:07:44,710 --> 00:07:47,986
and that is a minimal setup to have a queue system

113
00:07:48,088 --> 00:07:52,142
working. You can have both producer and consumers

114
00:07:52,206 --> 00:07:56,214
exist in one application separately. It's whatever up

115
00:07:56,252 --> 00:08:00,722
to you and they will be communicating via your redis

116
00:08:00,866 --> 00:08:05,042
instance, messaging provider connection

117
00:08:05,106 --> 00:08:09,114
starts with adding a client model connection. In this

118
00:08:09,152 --> 00:08:13,398
example we have redis transport and should provide redispecific

119
00:08:13,494 --> 00:08:17,414
connection options. Next step is to inject the client

120
00:08:17,462 --> 00:08:20,902
proxy interface. Our options further

121
00:08:20,966 --> 00:08:25,134
are either send method or emit. Send is

122
00:08:25,172 --> 00:08:29,290
usually a synchronous section similar to HTTP request,

123
00:08:29,450 --> 00:08:33,810
but is abstracted by the framework to act via selected transport.

124
00:08:34,710 --> 00:08:38,574
In the given example, the accumulate method response

125
00:08:38,622 --> 00:08:41,986
will not be sent to the client until message is processed by the

126
00:08:42,008 --> 00:08:46,002
listener. Application Emit command is can asynchronous

127
00:08:46,066 --> 00:08:49,670
workflow start? It will act as fire and forget

128
00:08:50,090 --> 00:08:53,586
or in some transports this will act as a durable queue

129
00:08:53,618 --> 00:08:57,806
event. This will depend on the transport chosen

130
00:08:57,858 --> 00:09:01,434
and its configuration. Send and

131
00:09:01,472 --> 00:09:05,740
emit partners have a slightly different use case on the consumer side,

132
00:09:06,190 --> 00:09:09,878
message pattern decorator is only for synchronous like

133
00:09:09,984 --> 00:09:14,090
methods and can only be used inside a controller decorated

134
00:09:14,170 --> 00:09:17,626
class, so we expect some kind of response

135
00:09:17,658 --> 00:09:20,990
to the request received via our messaging protocol.

136
00:09:21,890 --> 00:09:25,186
On the other hand, event pattern decorator can be

137
00:09:25,208 --> 00:09:28,706
used in any custom class of your application and

138
00:09:28,728 --> 00:09:32,162
will listen to events produced on the same queue or event

139
00:09:32,216 --> 00:09:35,814
bus, and it does not expect our application to

140
00:09:35,852 --> 00:09:39,494
return something. This setup is similar with

141
00:09:39,532 --> 00:09:43,350
other messaging brokers and if it's something custom,

142
00:09:43,420 --> 00:09:47,094
you can still use a dependency injection container and

143
00:09:47,132 --> 00:09:51,290
create a custom event subsystem provider with NestJs interfaces.

144
00:09:52,430 --> 00:09:55,818
And this is how easy it is to integrate with most common

145
00:09:55,904 --> 00:09:57,850
messaging brokers in NestJs.

146
00:09:59,470 --> 00:10:03,294
In this section I will review a part of real application which

147
00:10:03,332 --> 00:10:06,958
is simplified. Of course you can get the source cases at

148
00:10:06,964 --> 00:10:10,494
my GitHub page to follow along or try it out later.

149
00:10:10,692 --> 00:10:14,126
I will demonstrate how a properly designed event driven

150
00:10:14,158 --> 00:10:18,082
application can face challenges and

151
00:10:18,136 --> 00:10:22,020
how we can quickly resolve them with the tools that framework has.

152
00:10:22,790 --> 00:10:25,090
Let's first do a quick overview.

153
00:10:26,730 --> 00:10:30,374
Our expected workflow is like this. We have

154
00:10:30,412 --> 00:10:34,262
an action that has happened in our API gateway and

155
00:10:34,316 --> 00:10:38,060
detaches the trade service which emits an event.

156
00:10:38,590 --> 00:10:43,226
This event goes to the queue or event bus and

157
00:10:43,248 --> 00:10:47,340
then we have four other services listening to it and processing it.

158
00:10:48,350 --> 00:10:52,446
To observe how this application performs, I use a side application which

159
00:10:52,468 --> 00:10:56,474
is my channel monitor. This is a very powerful pattern

160
00:10:56,522 --> 00:11:00,010
to improve observability and can help automation

161
00:11:00,090 --> 00:11:03,950
for scaling up and down based on channel metrics.

162
00:11:04,370 --> 00:11:06,740
I'll show you how it works in a bit.

163
00:11:08,470 --> 00:11:11,220
I prepared the make file so you can follow along.

164
00:11:11,910 --> 00:11:15,446
First, run a make start command and this will start

165
00:11:15,548 --> 00:11:17,720
docker with all required services.

166
00:11:18,570 --> 00:11:22,662
Next you run a make monitor command to pick into

167
00:11:22,716 --> 00:11:26,102
application metrics. The monitor shows

168
00:11:26,156 --> 00:11:30,698
me the queue name and count of jobs that are waiting process

169
00:11:30,784 --> 00:11:34,060
jobs and amount of worker instances online.

170
00:11:35,390 --> 00:11:39,340
As you can see, under normal conditions the job waiting count is zero,

171
00:11:40,290 --> 00:11:44,000
event flow is slow and we don't have any jobs piling up.

172
00:11:45,170 --> 00:11:48,720
This application works fine with a low event count,

173
00:11:49,090 --> 00:11:51,790
but what happens if traffic suddenly increases?

174
00:11:53,190 --> 00:11:57,074
You can start next demo by running make start issue one

175
00:11:57,112 --> 00:12:00,574
command and restarting the monitor. With make monitor

176
00:12:00,622 --> 00:12:04,194
command, our event flow is

177
00:12:04,232 --> 00:12:07,374
increased by three times. You will notice eventually

178
00:12:07,422 --> 00:12:11,190
that the jobs waiting count will start to increase and

179
00:12:11,340 --> 00:12:15,334
while we still are processing jobs with one worker, the queue has

180
00:12:15,372 --> 00:12:18,330
already slowed down compared to the increased traffic.

181
00:12:19,550 --> 00:12:23,062
Now we can see that our mission critical trade service confirmation

182
00:12:23,126 --> 00:12:26,618
is throttled by this the worker would process

183
00:12:26,704 --> 00:12:29,834
all events without any priority. So each

184
00:12:29,872 --> 00:12:33,214
new trade confirmation must first wait for

185
00:12:33,252 --> 00:12:35,120
some other events to complete.

186
00:12:36,130 --> 00:12:39,566
And you can imagine this creating slow response times on your

187
00:12:39,588 --> 00:12:43,150
front end. Applications for trade processing

188
00:12:44,930 --> 00:12:48,800
let's explore the options that we have to fix this.

189
00:12:49,670 --> 00:12:53,314
The first and most obvious is to scale the worker instance so

190
00:12:53,352 --> 00:12:56,950
it will go faster. In the node js world,

191
00:12:57,020 --> 00:13:01,042
this is rarely a good solution unless you are processing high cpu

192
00:13:01,106 --> 00:13:05,270
intensive tasks such as video audio cryptography.

193
00:13:06,330 --> 00:13:09,866
The second is to increase the worker instance count. This is

194
00:13:09,888 --> 00:13:13,242
a valid option, but sometimes not very cost

195
00:13:13,296 --> 00:13:17,274
effective. Next, we can think about application

196
00:13:17,392 --> 00:13:20,954
applications that would include profiling,

197
00:13:21,002 --> 00:13:24,750
investigating database queries and similar activities.

198
00:13:26,130 --> 00:13:30,254
This can be very time consuming and can render no result

199
00:13:30,452 --> 00:13:32,590
or very limited improvements.

200
00:13:33,830 --> 00:13:37,026
And our last two options are where NestJs can

201
00:13:37,048 --> 00:13:40,862
help us with it's to separate the queues

202
00:13:41,006 --> 00:13:43,330
and prioritize some events.

203
00:13:44,890 --> 00:13:48,710
I will start by applying a queue separation method.

204
00:13:49,450 --> 00:13:53,154
The trade queue will only be responsible for processing

205
00:13:53,202 --> 00:13:55,190
trade confirmation events.

206
00:13:56,010 --> 00:14:00,394
My code for this will look like will

207
00:14:00,432 --> 00:14:04,042
look like this. The first step is to ask our

208
00:14:04,096 --> 00:14:07,226
producer to meet a trade confirm event to

209
00:14:07,248 --> 00:14:08,330
a new queue.

210
00:14:10,430 --> 00:14:13,722
On the consumer side, I extracted a new class called

211
00:14:13,776 --> 00:14:16,798
Trades service and assign it as a

212
00:14:16,804 --> 00:14:18,590
listener to the trades queue.

213
00:14:21,410 --> 00:14:24,946
The queue default listener service stays the same.

214
00:14:25,128 --> 00:14:29,906
I don't have to do any changes here now.

215
00:14:30,008 --> 00:14:34,450
Whatever happens, whatever spike we have, the trades will never stop processing.

216
00:14:34,870 --> 00:14:38,918
You can run the next example by starting

217
00:14:39,004 --> 00:14:43,094
the start step one command and restarting the monitor with make

218
00:14:43,132 --> 00:14:46,866
monitor command. You will notice that the trace queue

219
00:14:46,898 --> 00:14:50,986
has a jobs waiting count of zero and the

220
00:14:51,008 --> 00:14:53,740
default queue is still experiencing problems.

221
00:14:54,830 --> 00:14:58,246
So now I will apply our second step for scaling.

222
00:14:58,358 --> 00:15:02,266
Based on the information I have, I increase the worker

223
00:15:02,298 --> 00:15:06,350
instance count to three for the default queue.

224
00:15:07,490 --> 00:15:11,578
Youve can start this demo by running the start step two common and restarting

225
00:15:11,594 --> 00:15:14,930
the monitor and over time

226
00:15:15,000 --> 00:15:18,414
this application goes to zero jobs

227
00:15:18,462 --> 00:15:21,860
waiting on both queues. So good job.

228
00:15:23,110 --> 00:15:26,374
Let's recap. I applied two solutions here from

229
00:15:26,412 --> 00:15:29,766
my list. I increased worker instance count for

230
00:15:29,788 --> 00:15:33,394
the default queue. I created a separate trades

231
00:15:33,442 --> 00:15:36,726
queue, and this was majorly done for

232
00:15:36,748 --> 00:15:39,610
me by Docker and the Nestjs framework.

233
00:15:41,630 --> 00:15:45,034
Next step you can implement by just using tools that

234
00:15:45,072 --> 00:15:48,406
the framework has is to prioritize some events

235
00:15:48,438 --> 00:15:51,962
over the hours. For example, anything related

236
00:15:52,026 --> 00:15:55,806
to login or internal metrics can

237
00:15:55,828 --> 00:15:59,210
be delayed in favor of more mission critical events

238
00:15:59,290 --> 00:16:03,600
like database integrations, notifications, and so on.

239
00:16:04,130 --> 00:16:07,786
You can get the demo application repository at my GitHub

240
00:16:07,978 --> 00:16:11,886
with a link specified here. Feel free to connect at

241
00:16:11,908 --> 00:16:14,890
LinkedIn. Thanks for watching and goodbye.

