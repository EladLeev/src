1
00:00:23,050 --> 00:00:26,662
Hey, everyone, thank you for coming to stock. In the next like 40

2
00:00:26,716 --> 00:00:30,370
minutes, we are going to track a little bit about CI CD pipelines

3
00:00:30,450 --> 00:00:34,354
and how to make sure that we prevent the bad code from reaching

4
00:00:34,402 --> 00:00:38,226
production. We are going to see how to improve the monitoring

5
00:00:38,258 --> 00:00:41,414
and observability of our databases and why we

6
00:00:41,452 --> 00:00:44,902
actually need a thing that we call database guardrails very

7
00:00:44,956 --> 00:00:48,870
early in our pipelines. So let's go. So the very first

8
00:00:48,940 --> 00:00:52,794
thing we would like to discuss is whenever

9
00:00:52,842 --> 00:00:56,574
there is an issue, we would like to catch it before we actually go

10
00:00:56,612 --> 00:01:00,394
to production, right. We would like to have some automation checks,

11
00:01:00,442 --> 00:01:03,822
some guardrails, some safety nets that will

12
00:01:03,876 --> 00:01:06,814
prevent the bad code from reaching production.

13
00:01:06,942 --> 00:01:10,658
Important part here is that we would like to have these checks as early

14
00:01:10,744 --> 00:01:13,794
in our pipeline as possible. We would like to

15
00:01:13,832 --> 00:01:17,462
push them to the left so they get executed as

16
00:01:17,516 --> 00:01:20,258
early during the early development stage,

17
00:01:20,354 --> 00:01:24,134
not very late during the load tests or

18
00:01:24,172 --> 00:01:27,766
even after we deploy to production. This is super important

19
00:01:27,868 --> 00:01:31,878
because in today's world, we just can't let ourselves

20
00:01:31,974 --> 00:01:35,734
to identify issues after we deploy to production.

21
00:01:35,782 --> 00:01:38,950
We need to catch all these issues before going to prod.

22
00:01:39,030 --> 00:01:42,442
And in order to do that, we need to do that automation.

23
00:01:42,506 --> 00:01:46,222
Right. We don't want to have this process like manual and

24
00:01:46,276 --> 00:01:50,254
handcrafted. We want to get it fully automated and work like

25
00:01:50,292 --> 00:01:53,774
a charm before even we go to load

26
00:01:53,822 --> 00:01:57,330
tests to pre production environments as early as possible.

27
00:01:57,480 --> 00:02:01,218
That's very first thing. But the second thing is whenever something

28
00:02:01,304 --> 00:02:05,326
breaks, we need to be able to automatically

29
00:02:05,438 --> 00:02:08,870
troubleshoot the issue. We need to know the context. We need to

30
00:02:08,940 --> 00:02:12,502
know everything that is around those things in our

31
00:02:12,556 --> 00:02:16,054
cluster, in our environment. And we need to basically be able

32
00:02:16,092 --> 00:02:19,306
to monitor and observe what's going on there. We would

33
00:02:19,328 --> 00:02:23,194
like to have a good tooling that is going to

34
00:02:23,232 --> 00:02:27,494
pinpoint the issues directly and let us know very precisely

35
00:02:27,622 --> 00:02:31,050
what happened and what the reason is.

36
00:02:31,200 --> 00:02:35,050
So this is what we are going to discuss during the upcoming

37
00:02:35,130 --> 00:02:38,286
minutes. So you might ask a

38
00:02:38,308 --> 00:02:42,414
very good question, right. How do you know that the code you deploy to

39
00:02:42,452 --> 00:02:45,426
production is actually going to work well? Right.

40
00:02:45,528 --> 00:02:49,326
They tell you deploy every time, deploy constantly,

41
00:02:49,518 --> 00:02:52,866
deploy on Friday night, everything is going to be good.

42
00:02:52,968 --> 00:02:56,414
But how do you make sure that you are not going to take your production

43
00:02:56,462 --> 00:02:59,830
down and that everything that you deploy is going to work well.

44
00:02:59,900 --> 00:03:03,846
Right. And before answering the question, we need to actually understand

45
00:03:04,028 --> 00:03:07,794
what may go wrong. And there are various areas

46
00:03:07,842 --> 00:03:11,226
that may break during our deployment. And when dealing with

47
00:03:11,248 --> 00:03:14,906
production environment, the very first area is the deployment may

48
00:03:14,928 --> 00:03:18,614
go wrong. So, you know, there are multiple operating systems.

49
00:03:18,662 --> 00:03:23,210
There is windows, there are Linux, macOS and other operating systems

50
00:03:23,290 --> 00:03:27,290
and there are differences between them, right? Like characters

51
00:03:27,370 --> 00:03:30,846
indicating the end of line, right. Different ways of

52
00:03:30,948 --> 00:03:34,910
setting permissions, right? Docker with different parameters and

53
00:03:35,060 --> 00:03:38,674
net host that works on Linux but doesn't work somewhere else.

54
00:03:38,792 --> 00:03:42,770
And other things that may break along the way. Not to mention that

55
00:03:42,840 --> 00:03:46,094
during the deployment you also need to propagate

56
00:03:46,142 --> 00:03:50,086
the changes from your local environment, from your staging environment to the

57
00:03:50,108 --> 00:03:53,526
production environment. And you may simply get that wrong or

58
00:03:53,548 --> 00:03:56,854
just forget to do so. For instance, how many times it

59
00:03:56,892 --> 00:04:00,342
happened that everything worked well in pre production environment

60
00:04:00,406 --> 00:04:04,074
when we deployed it to the cloud, but once we went to production it

61
00:04:04,112 --> 00:04:07,974
simply stopped working, right, because we forgot to propagate.

62
00:04:08,022 --> 00:04:12,138
Like IM roles, permissions, settings for databases,

63
00:04:12,234 --> 00:04:15,614
connection strings and other stuff, right? Just getting the

64
00:04:15,652 --> 00:04:19,182
software deployed is not as straightforward as

65
00:04:19,236 --> 00:04:22,734
possible. And your unit test may capture that.

66
00:04:22,772 --> 00:04:25,986
Your logic is flawed, but they won't capture whether you got

67
00:04:26,008 --> 00:04:29,442
the deployment right. Okay, so that is the very first thing

68
00:04:29,496 --> 00:04:33,442
that may break. The other thing that may go wrong is like your code

69
00:04:33,576 --> 00:04:37,398
may just start failing in production. This is because of

70
00:04:37,484 --> 00:04:40,834
various things you basically got wrong. For instance

71
00:04:40,882 --> 00:04:44,434
bugs in your application, but also because of different assumptions

72
00:04:44,482 --> 00:04:48,386
and different environment that you are now running in your locale

73
00:04:48,418 --> 00:04:52,426
may be different. The country you deploy to may be different like

74
00:04:52,528 --> 00:04:57,142
already mentioned, things like different end of line characters

75
00:04:57,206 --> 00:05:01,066
may be completely different. And all that stuff that affects that. Your application

76
00:05:01,168 --> 00:05:05,586
that worked well in local environment or in testing pre production

77
00:05:05,638 --> 00:05:09,438
environment doesn't work well when you go to production, right?

78
00:05:09,524 --> 00:05:13,354
And those things we can capture again to some extent

79
00:05:13,402 --> 00:05:16,798
using automated tests, unit test integration tests or whatnot.

80
00:05:16,894 --> 00:05:20,434
But generally what we need is we need to be able to tell

81
00:05:20,552 --> 00:05:24,254
very early that things that we are checking in our local environment

82
00:05:24,382 --> 00:05:28,066
will not break when deployed to production. Another thingy

83
00:05:28,098 --> 00:05:32,294
is the third area we'd like to discuss is

84
00:05:32,412 --> 00:05:36,546
completely different context and completely different workload

85
00:05:36,658 --> 00:05:40,330
when we run in production. This may be that like obviously

86
00:05:40,480 --> 00:05:44,374
different country, different data patterns, different data distribution.

87
00:05:44,502 --> 00:05:48,026
You tested things in Europe, but then you deploy to the US and

88
00:05:48,048 --> 00:05:52,090
you just get completely different input to your application because

89
00:05:52,240 --> 00:05:55,982
you have different clients working over there, right? Another thing

90
00:05:56,036 --> 00:06:00,046
is different data load. You tested stuff on very small database with

91
00:06:00,068 --> 00:06:04,062
like 100 rows in it. But when you go to the production you get

92
00:06:04,116 --> 00:06:07,474
millions of rows, right? And your application just can't keep

93
00:06:07,512 --> 00:06:10,562
up with the load, with the pace that you observe in

94
00:06:10,616 --> 00:06:14,510
completely living environment. Last thing is like edge cases,

95
00:06:14,590 --> 00:06:17,746
right? You have completely different situation when you deploy

96
00:06:17,778 --> 00:06:21,634
to big country versus to small country, right? You may lack

97
00:06:21,682 --> 00:06:25,122
some content, pre populated content like of your ecommerce,

98
00:06:25,186 --> 00:06:28,614
eshop or whatnot. You may get different distribution, you may get

99
00:06:28,652 --> 00:06:32,362
different characters, different encoding. Things may just break because

100
00:06:32,416 --> 00:06:35,786
you did not expect them to break because you didn't foresee how they

101
00:06:35,808 --> 00:06:39,290
may break. That's because there's completely different country,

102
00:06:39,360 --> 00:06:42,654
different environment you're running in. So now the question is, okay,

103
00:06:42,692 --> 00:06:46,750
so how can we make sure that on Friday afternoon we can

104
00:06:46,820 --> 00:06:50,174
safely deploy to production? And the very first thing they

105
00:06:50,212 --> 00:06:53,614
tell you is go with CI CD, right? If you

106
00:06:53,652 --> 00:06:56,930
know CI CD, everything is going to work well, right?

107
00:06:57,000 --> 00:07:00,162
So just to set things straight, CI CD stands for various things.

108
00:07:00,216 --> 00:07:03,742
CI stands for continuous integration. Continuous integration

109
00:07:03,806 --> 00:07:07,554
is basically when, after we merge or after

110
00:07:07,592 --> 00:07:11,382
we commit to the repository, we merge all the changes into one

111
00:07:11,436 --> 00:07:15,058
branch and then we build the package that we would like to deploy.

112
00:07:15,154 --> 00:07:18,802
We build the package, we run all the unit tests, all the automated

113
00:07:18,866 --> 00:07:22,442
tests, we run everything, we prepare all of that so

114
00:07:22,496 --> 00:07:26,122
that we are pretty sure that the package we have is going

115
00:07:26,176 --> 00:07:29,974
to work well. Okay, then we have another thingy, which is continuous

116
00:07:30,022 --> 00:07:33,326
delivery. In continuous delivery, what we do is we take the

117
00:07:33,348 --> 00:07:36,922
package and we deploy it to all non production

118
00:07:36,986 --> 00:07:40,286
environments. We deploy this package, we install all

119
00:07:40,308 --> 00:07:44,154
the dependencies, configure everything, and start testing whether the package

120
00:07:44,202 --> 00:07:48,062
worked correctly. Also, we make sure that all our teammates

121
00:07:48,126 --> 00:07:52,194
and all the teams around are using exactly the same code if

122
00:07:52,232 --> 00:07:55,570
they, for instance, don't deploy things locally, but instead use

123
00:07:55,640 --> 00:07:59,206
some developer or team environments deployed in the

124
00:07:59,228 --> 00:08:03,682
cloud, right? And finally, we have continuous deployment. And continuous deployment

125
00:08:03,746 --> 00:08:07,526
is when you get the package that you have just built and you deploy it

126
00:08:07,548 --> 00:08:11,370
to the production environment directly. Right? And this is cool.

127
00:08:11,440 --> 00:08:15,126
You take the package, you already tested it in like non

128
00:08:15,158 --> 00:08:18,662
production environments, and then you go and deploy into production,

129
00:08:18,726 --> 00:08:21,978
right? And this is when things may break.

130
00:08:22,144 --> 00:08:25,566
Obviously they tell you CI CD is going to protect you from all the

131
00:08:25,588 --> 00:08:29,166
issues, but is it? Right. What kind of issues can

132
00:08:29,188 --> 00:08:32,842
you capture when running unit tests or when running integration

133
00:08:32,906 --> 00:08:36,734
tests, what things you may see, what things you may spot,

134
00:08:36,782 --> 00:08:40,354
and what issues may just go unnoticed and appear in

135
00:08:40,392 --> 00:08:43,700
production. So what we are going to do over the

136
00:08:44,150 --> 00:08:47,558
next minutes of this talk is we will see some specific

137
00:08:47,644 --> 00:08:51,234
issues that may actually happen because you can't catch

138
00:08:51,282 --> 00:08:54,950
them easily in your CI CD pipeline. So we will cover

139
00:08:55,020 --> 00:08:58,774
databases, we will cover orm libraries, and we'll

140
00:08:58,822 --> 00:09:02,694
finally cover lack of context and lack of understanding

141
00:09:02,742 --> 00:09:06,246
of all the moving pieces around. So let's jump

142
00:09:06,278 --> 00:09:09,606
straight to it. So the very first thing with database

143
00:09:09,718 --> 00:09:13,322
is like we do deploy them, but they consist of multiple

144
00:09:13,386 --> 00:09:17,210
parts. First thing is when we change, we typically

145
00:09:17,290 --> 00:09:20,974
change the code that is talking to the database. So we change the

146
00:09:21,012 --> 00:09:24,826
queries that we send to the database. And this may result in

147
00:09:24,868 --> 00:09:28,814
various things. For instance, the query may now just be inherently slower.

148
00:09:28,942 --> 00:09:32,686
For instance, if you restructure your query of if you extract

149
00:09:32,718 --> 00:09:36,450
more data or if you change columns, you may change

150
00:09:36,600 --> 00:09:40,514
how your query executes and you may for instance get lower performance

151
00:09:40,562 --> 00:09:44,406
or just bugs, right? So that's first thing. The other thing we

152
00:09:44,428 --> 00:09:47,382
may get is schema changes. So in schema changes,

153
00:09:47,516 --> 00:09:50,938
whenever we deploy something to database, we may end up in

154
00:09:50,944 --> 00:09:54,474
a situation that this schema modification is going

155
00:09:54,512 --> 00:09:58,282
to work for a very long time. If you run

156
00:09:58,336 --> 00:10:02,330
things locally with small tables, then adding new column

157
00:10:02,410 --> 00:10:06,506
or changing the column type, or doing something with your schema

158
00:10:06,698 --> 00:10:10,302
in your database is going to run really really fast.

159
00:10:10,436 --> 00:10:13,918
But once you go to production and you have millions of rows,

160
00:10:14,014 --> 00:10:17,742
then simply innocent schema migration

161
00:10:17,886 --> 00:10:21,666
may literally takes minutes or even hours to get

162
00:10:21,688 --> 00:10:25,506
deployed. Your table may need to be rewritten, meaning that your

163
00:10:25,528 --> 00:10:28,786
SQL engine may need to copy the data from the table on

164
00:10:28,808 --> 00:10:32,422
the site, recreate the table, and then restore the data

165
00:10:32,476 --> 00:10:35,782
back. And this is not something you can do in a split second.

166
00:10:35,836 --> 00:10:39,494
This is something that is going to take minutes. So this will

167
00:10:39,532 --> 00:10:43,482
take your application down. And another thing is

168
00:10:43,616 --> 00:10:47,498
query changes. It may be the case that something

169
00:10:47,584 --> 00:10:51,178
in your database have changed for whatever reason,

170
00:10:51,344 --> 00:10:55,306
indexes changed, configuration, installed extensions,

171
00:10:55,418 --> 00:10:58,234
views, stored procedures, triggers,

172
00:10:58,282 --> 00:11:02,158
whatnot. Multiple things may just change which will result

173
00:11:02,244 --> 00:11:05,966
in your query now being executed completely differently.

174
00:11:06,078 --> 00:11:09,426
For instance, previously it was using index to

175
00:11:09,448 --> 00:11:13,822
scan your table. Now it can't use this index because of whatnot.

176
00:11:13,966 --> 00:11:17,630
Or maybe it was doing like hash join or merge join.

177
00:11:17,710 --> 00:11:21,762
Now statistics are out of date and it just goes with nested loop join

178
00:11:21,826 --> 00:11:25,366
which will just be slower. There are other things that may

179
00:11:25,388 --> 00:11:28,614
change in the database like statistics, bugs,

180
00:11:28,662 --> 00:11:32,250
missing indexes, data quality, configuration locks,

181
00:11:32,830 --> 00:11:36,554
partitioning, other stuff that is in your

182
00:11:36,592 --> 00:11:40,234
database and your unit tests will just not catch that.

183
00:11:40,352 --> 00:11:43,934
Your unit test will test your code and assume how

184
00:11:43,972 --> 00:11:47,882
it's going to work in your database. But those tests

185
00:11:47,946 --> 00:11:51,294
do not work how you configured your database. Especially they

186
00:11:51,332 --> 00:11:54,842
have no idea how you configured your production environment.

187
00:11:54,986 --> 00:11:59,166
So let's see what else may go wrong. For instance, we may get slow queries

188
00:11:59,278 --> 00:12:02,430
that work pretty well on your testing environment

189
00:12:02,510 --> 00:12:06,482
but do not work in when you go to production. So imagine that we have

190
00:12:06,536 --> 00:12:10,626
this application code right. In this application code we have an aggregate root

191
00:12:10,658 --> 00:12:14,374
of the user and what we do is we would like to also query for

192
00:12:14,412 --> 00:12:17,270
some details of the user, like location pages, text,

193
00:12:17,340 --> 00:12:21,718
whatnot. Right? And this in turn because we use orm library,

194
00:12:21,814 --> 00:12:25,738
this could create some query like this one when we basically

195
00:12:25,904 --> 00:12:29,786
join multiple tables. And this is the example of the actual

196
00:12:29,888 --> 00:12:33,386
production environment I had. And this is the code I was debugging

197
00:12:33,418 --> 00:12:37,790
once. And this code resulted in just when getting one

198
00:12:37,860 --> 00:12:41,918
entity to our application. Because this entity had

199
00:12:42,084 --> 00:12:45,170
so much of this data,

200
00:12:45,320 --> 00:12:48,718
these details of like questions, text reports and other tables

201
00:12:48,734 --> 00:12:53,314
that we joined together, this resulted in getting 300,000

202
00:12:53,432 --> 00:12:56,646
rows to the application. And then the

203
00:12:56,668 --> 00:13:00,898
application RM worked hard for nearly 25 seconds

204
00:13:00,994 --> 00:13:05,042
to deduplicate everything and to construct the final aggregate

205
00:13:05,106 --> 00:13:09,078
object, the aggregate root of this user.

206
00:13:09,254 --> 00:13:12,890
So this is what may happen. You won't catch this issue

207
00:13:13,040 --> 00:13:17,462
when you run your tests against like very small database

208
00:13:17,526 --> 00:13:21,518
available locally, right? You won't catch that when you have 100

209
00:13:21,604 --> 00:13:25,230
rows in your database. You can catch that if and

210
00:13:25,300 --> 00:13:28,746
only if you have literally thousands or millions

211
00:13:28,778 --> 00:13:32,254
of rows in your database. So because only then

212
00:13:32,372 --> 00:13:35,554
you see the cross join product of all

213
00:13:35,592 --> 00:13:39,250
those tables. How can we fix that in that case? Well,

214
00:13:39,320 --> 00:13:43,410
once we identify what the issue is, the fix was pretty straightforward.

215
00:13:44,470 --> 00:13:47,846
Instead of getting like the aggregate roots in one go,

216
00:13:47,948 --> 00:13:51,874
I was basically getting it with multiple queries, with multiple

217
00:13:51,922 --> 00:13:55,426
objects. This resulted in sending multiple SQL

218
00:13:55,458 --> 00:13:58,818
statements to the database and then joining all

219
00:13:58,844 --> 00:14:02,618
the results in the application code. One might say, okay,

220
00:14:02,704 --> 00:14:06,406
but now this sends more SQL queries to the database.

221
00:14:06,518 --> 00:14:10,442
And yes, you'd be right. But the only thing that is worth

222
00:14:10,496 --> 00:14:14,906
noticing here is that those queries run way faster

223
00:14:15,018 --> 00:14:19,070
now. They execute in like split second, and because they do not

224
00:14:19,140 --> 00:14:23,154
extract 300,000 rows. So all of that is now much,

225
00:14:23,192 --> 00:14:26,702
much faster. And just because we split one query

226
00:14:26,766 --> 00:14:31,010
into multiple ones, that's not a problem at all, because this

227
00:14:31,080 --> 00:14:34,722
ultimately leads to a better performance. So we can

228
00:14:34,776 --> 00:14:38,422
see something that, hey, your unit test probably

229
00:14:38,476 --> 00:14:42,386
won't tell you. You could capture that with some load tests and we'll

230
00:14:42,418 --> 00:14:45,990
get to that a little bit later on. But generally

231
00:14:46,330 --> 00:14:50,278
by testing things locally in your CI CD pipeline,

232
00:14:50,374 --> 00:14:53,818
you won't spot an issue like this one because it will just work

233
00:14:53,904 --> 00:14:57,542
fast enough. Moving on, your libraries

234
00:14:57,606 --> 00:15:01,878
and your tools, or even you may write queries

235
00:15:01,974 --> 00:15:05,214
that are equivalent in terms of what they do,

236
00:15:05,332 --> 00:15:08,906
but are completely different in terms of performance. So let's

237
00:15:08,938 --> 00:15:13,134
say we have this table that we call boarding passes. It has something like 8

238
00:15:13,172 --> 00:15:16,626
million rows. And what we would like to do now is we have a

239
00:15:16,648 --> 00:15:20,350
handcrafted query that is getting all the boating passes

240
00:15:20,430 --> 00:15:24,354
and just calculating a checksum of the ticket number and

241
00:15:24,392 --> 00:15:27,314
doing it twice using like MD five algorithm.

242
00:15:27,362 --> 00:15:30,598
Right. What we do next is we basically

243
00:15:30,684 --> 00:15:34,262
join this CTE three times and we filter for

244
00:15:34,316 --> 00:15:37,474
some specific like double hash of the ticket number.

245
00:15:37,612 --> 00:15:41,078
And this query, this query at the top that uses

246
00:15:41,174 --> 00:15:44,314
CTE, which is common table expression, which is

247
00:15:44,352 --> 00:15:47,706
kind of like temporary table used only for this

248
00:15:47,728 --> 00:15:51,326
query. This statement is equivalent to

249
00:15:51,348 --> 00:15:55,182
the one down below, meaning that the one

250
00:15:55,236 --> 00:15:59,274
down below does not use CTE, but instead extracts

251
00:15:59,322 --> 00:16:03,054
from the boarding passes three times directly and then does the

252
00:16:03,092 --> 00:16:06,882
filtering in the work condition. So those two queries are

253
00:16:06,936 --> 00:16:10,194
equivalent in terms of what the logical output they

254
00:16:10,232 --> 00:16:14,130
produce. The only difference is the query at the top runs in

255
00:16:14,200 --> 00:16:17,814
13 seconds total, whereas the query down below

256
00:16:17,932 --> 00:16:21,606
runs in 8 seconds. So there's nearly half of

257
00:16:21,628 --> 00:16:25,478
the time of the query above. Right? So again,

258
00:16:25,644 --> 00:16:29,606
this is something you can't check with your unit

259
00:16:29,638 --> 00:16:32,730
tests because hey, those queries just give you the proper

260
00:16:32,800 --> 00:16:36,518
answer. And unit tests, they check whether your code works correctly,

261
00:16:36,614 --> 00:16:39,674
checks whether the code production, the expected result,

262
00:16:39,792 --> 00:16:43,262
right? But unit tests will not capture, and especially

263
00:16:43,316 --> 00:16:47,834
your CI CD pipeline may not capture the performance characteristics.

264
00:16:47,962 --> 00:16:51,866
And one spot that those two queries, even though they are equivalent,

265
00:16:51,978 --> 00:16:55,610
they work completely differently. Another thing we

266
00:16:55,620 --> 00:16:59,058
may hit is incompatible changes in schemas, right?

267
00:16:59,144 --> 00:17:02,242
Adding a column seems like something that will not break

268
00:17:02,296 --> 00:17:05,666
your database production at all, but this may

269
00:17:05,688 --> 00:17:09,186
take a lot of time to apply. If you add a column,

270
00:17:09,298 --> 00:17:12,274
then your table may need to be rewritten.

271
00:17:12,322 --> 00:17:15,622
So data may need to be copied from the table on the site.

272
00:17:15,756 --> 00:17:18,994
Table must be recreated and then the data is restored

273
00:17:19,042 --> 00:17:22,298
back to the original table. And this is something you won't do in a

274
00:17:22,304 --> 00:17:26,042
second. It will take you minutes. Dropping a column seems like

275
00:17:26,096 --> 00:17:29,882
something that should be easy enough, but the problem is

276
00:17:30,016 --> 00:17:33,434
if you do deploy to a really big fleet of your machines,

277
00:17:33,562 --> 00:17:37,614
then you may end up with split brain, meaning that half of your

278
00:17:37,652 --> 00:17:40,782
machines are already running with the new code,

279
00:17:40,916 --> 00:17:44,674
whereas the other half of the machines run with the

280
00:17:44,712 --> 00:17:47,954
old version of code. That still does expect

281
00:17:48,072 --> 00:17:51,906
that column being there. Another scenario is when

282
00:17:51,928 --> 00:17:55,574
you have heterogeneous application, meaning that you have

283
00:17:55,612 --> 00:17:59,330
one database that is accessed from multiple applications

284
00:17:59,410 --> 00:18:03,266
being written in various different technologies,

285
00:18:03,378 --> 00:18:06,274
one in JavaScript, the other one in Python, in Java,

286
00:18:06,322 --> 00:18:09,770
in. Net, in rust, you name it. And those different

287
00:18:09,840 --> 00:18:13,318
technologies do not control the schema.

288
00:18:13,414 --> 00:18:17,206
So if you change the table schema

289
00:18:17,238 --> 00:18:20,698
in your database, then all those applications need to

290
00:18:20,704 --> 00:18:24,202
be updated. If you do not keep the backwards

291
00:18:24,266 --> 00:18:27,358
compatibility then you may end up with issues.

292
00:18:27,524 --> 00:18:30,894
Another thing is just changing the column type. If you

293
00:18:30,932 --> 00:18:34,434
change the column type, you may get your table rewritten. But this

294
00:18:34,472 --> 00:18:38,002
may also lead to some problems that hey, now you lose like

295
00:18:38,056 --> 00:18:41,810
precision, you lost some data quality, or maybe

296
00:18:41,880 --> 00:18:45,758
your application cannot read the column anymore

297
00:18:45,854 --> 00:18:49,526
because the internal representation has changed, right? So those are

298
00:18:49,548 --> 00:18:53,778
the things that may go wrong when we are playing with or changing

299
00:18:53,874 --> 00:18:56,562
the table schema when deploying to production.

300
00:18:56,706 --> 00:18:59,834
Another thing is about indexes, right?

301
00:18:59,952 --> 00:19:03,162
If you track an index in production, then your

302
00:19:03,216 --> 00:19:06,874
query may just be very, very slow, and your

303
00:19:06,912 --> 00:19:10,746
unit test is not going to catch that. So how can

304
00:19:10,768 --> 00:19:14,590
you fix that? You just need to configure a proper index index of proper

305
00:19:14,660 --> 00:19:18,474
type, whether it's Btree, hash, index, gen index, or whatnot.

306
00:19:18,602 --> 00:19:21,726
If you configure a proper index, your application is going to

307
00:19:21,748 --> 00:19:25,226
work faster. Right? But what happens if we tell some developer

308
00:19:25,258 --> 00:19:28,206
that hey, if your query is slow, configure the index.

309
00:19:28,238 --> 00:19:31,186
Then we end up, obviously with index all the things.

310
00:19:31,288 --> 00:19:35,430
So you have too many indexes configured in your database. And while

311
00:19:35,500 --> 00:19:38,802
index can help speed up the querying,

312
00:19:38,946 --> 00:19:42,950
it will slow down the data modification. Because now

313
00:19:43,020 --> 00:19:46,914
not only you need to just modify

314
00:19:46,962 --> 00:19:50,842
the entity, but you also need to update all the

315
00:19:50,896 --> 00:19:54,838
indexes around, meaning you need to update indexes

316
00:19:55,014 --> 00:19:58,186
on every single entity and every single column that

317
00:19:58,208 --> 00:20:02,062
you just configured. So one data modification may now lead to

318
00:20:02,196 --> 00:20:06,010
multiple indexes being modified, which may be slower,

319
00:20:06,170 --> 00:20:10,666
again, something you won't catch with your CI CD pipeline.

320
00:20:10,858 --> 00:20:14,002
And we also get to this situation of like

321
00:20:14,056 --> 00:20:17,422
we do modify, we do deploy our code to production,

322
00:20:17,486 --> 00:20:20,866
and this code is buggy. There are different kind

323
00:20:20,888 --> 00:20:24,894
of bugs. It may be buggy just because we didn't

324
00:20:25,022 --> 00:20:28,726
implement it properly. This is something our unit tests will be

325
00:20:28,748 --> 00:20:31,654
able to spot most of the times, obviously,

326
00:20:31,852 --> 00:20:35,814
but there may be also bugs in the engine we

327
00:20:35,852 --> 00:20:39,354
use in the database we use. One of the examples is

328
00:20:39,392 --> 00:20:42,746
the Halloween problem. Halloween problem was a

329
00:20:42,768 --> 00:20:46,186
case like back a couple of decades, back when if

330
00:20:46,208 --> 00:20:50,098
you tried to update the salary of all the employees,

331
00:20:50,134 --> 00:20:54,170
just as you can see on the screen, the database

332
00:20:54,250 --> 00:20:58,078
engine updated the same row multiple times

333
00:20:58,164 --> 00:21:01,726
because it was still meeting the condition. So here on

334
00:21:01,748 --> 00:21:05,742
the screen, we want to update the salary when it's below 10,000.

335
00:21:05,876 --> 00:21:09,746
So imagine that we start with 1000 salary and we want to increase it

336
00:21:09,768 --> 00:21:13,186
by 10%. So we end up with 1100

337
00:21:13,288 --> 00:21:16,294
and this is still below 10,000.

338
00:21:16,412 --> 00:21:20,214
So the database engine kept updating this row over and

339
00:21:20,252 --> 00:21:23,826
over again until it finally stopped

340
00:21:23,858 --> 00:21:27,702
meeting the filtering condition. So until

341
00:21:27,836 --> 00:21:31,546
everyone was earning at least 10,000. So this

342
00:21:31,568 --> 00:21:35,066
is what happened now? Your databases protect themselves

343
00:21:35,168 --> 00:21:38,742
from the Halloween problem, but you may end up hitting

344
00:21:38,806 --> 00:21:42,714
some other edge cases. Did you even know that in your SQL

345
00:21:42,762 --> 00:21:46,142
database when you have read committed isolation level,

346
00:21:46,276 --> 00:21:50,366
then according to the standard and implementation details of

347
00:21:50,388 --> 00:21:54,354
the databases, your application is allowed to

348
00:21:54,392 --> 00:21:58,082
read the same rows twice or to

349
00:21:58,136 --> 00:22:01,490
skip a row using read committed isolation level.

350
00:22:01,560 --> 00:22:05,194
And read committed is most of the times the default isolation

351
00:22:05,262 --> 00:22:08,806
level you use. But that's it.

352
00:22:08,988 --> 00:22:12,822
Those are the big areas when we are talking about databases. But we

353
00:22:12,956 --> 00:22:16,978
often interact with databases using orms.

354
00:22:17,154 --> 00:22:21,050
Orms. So object relational mappers are libraries that help

355
00:22:21,120 --> 00:22:24,182
us simplify querying the database,

356
00:22:24,246 --> 00:22:27,660
mapping data back and forth between our application

357
00:22:28,190 --> 00:22:31,322
and the SQL engine. So let's see what may go wrong.

358
00:22:31,376 --> 00:22:34,654
The very first thing that breaks often is the n

359
00:22:34,692 --> 00:22:38,362
plus one select problem. Imagine that we start with the aircraft

360
00:22:38,426 --> 00:22:42,426
stable, which is in one too many relationship with seat

361
00:22:42,458 --> 00:22:45,906
stable. So what happens now is we would like to get all

362
00:22:45,928 --> 00:22:49,394
the aircraft and then for every single aircraft we would

363
00:22:49,432 --> 00:22:52,674
like to get the number of seats. What may happen

364
00:22:52,792 --> 00:22:56,510
behind the scenes is this will generate n plus one queries.

365
00:22:56,590 --> 00:22:59,686
Why? Because first it will go to the database to

366
00:22:59,708 --> 00:23:03,510
get all the aircraft from the database. And then for

367
00:23:03,580 --> 00:23:07,734
every single aircraft, just as we are looping over all of them,

368
00:23:07,852 --> 00:23:11,146
we get a query going to the database to

369
00:23:11,168 --> 00:23:15,194
get one particular aircraft from the seats table. So this

370
00:23:15,232 --> 00:23:19,050
results in one query sent to get all the aircraft and

371
00:23:19,120 --> 00:23:22,974
an additional queries to get like seats for

372
00:23:23,012 --> 00:23:27,066
every single aircraft. And this can be improved.

373
00:23:27,178 --> 00:23:30,446
This problem is easy to solve. Instead of just going with n

374
00:23:30,468 --> 00:23:34,266
plus one queries, we can just join two tables together in one

375
00:23:34,308 --> 00:23:36,882
query and bank. We are good to go.

376
00:23:37,016 --> 00:23:40,062
However, in order to generate this query,

377
00:23:40,126 --> 00:23:43,378
this eager query that will eagerly get all the data.

378
00:23:43,464 --> 00:23:46,370
Instead of doing that in a lazy mode fashion,

379
00:23:46,530 --> 00:23:49,830
what we need to do is we need to reconfigure our

380
00:23:49,900 --> 00:23:53,446
Orm. Do we see with this application code

381
00:23:53,548 --> 00:23:57,046
whether it's going to send like lazy queries and

382
00:23:57,148 --> 00:24:00,614
n plus one queries, or whether it's going to go with eager

383
00:24:00,662 --> 00:24:03,930
mode? We don't see that and ORM doesn't show that

384
00:24:04,000 --> 00:24:08,150
to us easily because the configuration is obscured and stored

385
00:24:08,230 --> 00:24:11,514
somewhere else. However, even if

386
00:24:11,552 --> 00:24:14,970
we reconfigure our OrM to always go eagerly,

387
00:24:15,050 --> 00:24:18,686
which may not be the best idea, but even if we did that,

388
00:24:18,788 --> 00:24:22,574
then we end up with different issues. Just the query. We already seen

389
00:24:22,612 --> 00:24:26,574
a couple of slides back, right? We now get multiple

390
00:24:26,622 --> 00:24:30,722
tables joined together. That slows down the performance and

391
00:24:30,776 --> 00:24:33,934
the solution for that is just to split that into multiple

392
00:24:33,982 --> 00:24:37,422
queries. So do you know how your RM

393
00:24:37,486 --> 00:24:40,742
is going to work behind the scenes and what it's going to do?

394
00:24:40,876 --> 00:24:44,854
And more importantly, can you catch that automatically with

395
00:24:44,892 --> 00:24:47,790
your unit tests and with your CI CD pipeline?

396
00:24:47,890 --> 00:24:50,970
And the answer is, most of the times you just cannot.

397
00:24:51,390 --> 00:24:55,286
Moving on. Another issues that ORM introduce

398
00:24:55,398 --> 00:24:59,078
are like issues related to impedance mismatch.

399
00:24:59,174 --> 00:25:03,166
Impedance mismatch is like generic term, meaning that the model

400
00:25:03,268 --> 00:25:06,842
we store in our object oriented applications

401
00:25:06,986 --> 00:25:10,074
is different than the model in our SQL

402
00:25:10,122 --> 00:25:14,154
databases. In general different because in all the applications

403
00:25:14,202 --> 00:25:16,942
what we do is we for instance, have polymorphism,

404
00:25:17,086 --> 00:25:20,626
so we can inherit from one class, can inherit from

405
00:25:20,648 --> 00:25:24,254
another. And the question is how do we represent that in our SQL

406
00:25:24,302 --> 00:25:27,506
database to not lose data and to not lose performance?

407
00:25:27,618 --> 00:25:30,994
There are obviously a couple of different approaches to do so, for instance,

408
00:25:31,042 --> 00:25:34,326
table per hierarchy or table per type.

409
00:25:34,428 --> 00:25:37,942
But generally this is something that may lead to

410
00:25:37,996 --> 00:25:41,290
issues in terms of the performance or in terms of

411
00:25:41,360 --> 00:25:45,098
the data quality. Another thing that we may end up with

412
00:25:45,184 --> 00:25:48,746
is the data types to be used. It sounds simple

413
00:25:48,848 --> 00:25:52,314
enough to store data in the SQL database,

414
00:25:52,362 --> 00:25:56,094
right? But how do you for instance, store the spatial data?

415
00:25:56,212 --> 00:25:59,290
Spatial data is basically geographic location,

416
00:25:59,450 --> 00:26:03,018
like longitude and latitude that we store somewhere around the

417
00:26:03,044 --> 00:26:07,006
globe, right? We can store that in our database. And typically

418
00:26:07,118 --> 00:26:10,274
SQL engines have dedicated data type to

419
00:26:10,312 --> 00:26:13,954
store that. But how is our orm going to deal with

420
00:26:13,992 --> 00:26:17,570
that? Isn't going to store this thing as like pair of numbers

421
00:26:17,720 --> 00:26:21,494
or maybe as a string or maybe as something different. And you may

422
00:26:21,532 --> 00:26:24,786
think, okay, I don't use spatial data, this is some weird edge

423
00:26:24,818 --> 00:26:28,570
case I'm not interested in. But even strings is

424
00:26:28,640 --> 00:26:32,486
something that may be very prone to the impedance mismatch.

425
00:26:32,598 --> 00:26:36,342
Because in our applications, in JavaScript,

426
00:26:36,486 --> 00:26:39,802
net, Java, whatever, we have just one

427
00:26:39,936 --> 00:26:43,998
string type. But in SQL engine what we can often

428
00:26:44,084 --> 00:26:47,690
do is we can configure a thing that is called collation.

429
00:26:47,850 --> 00:26:51,130
Collation is basically the order of characters,

430
00:26:51,210 --> 00:26:55,534
whether like lowercase letters are less than uppercase

431
00:26:55,582 --> 00:26:58,814
ones, or maybe we have some national characters,

432
00:26:58,942 --> 00:27:02,862
how to order basically, how to compare those characters

433
00:27:02,926 --> 00:27:06,966
and what to do with the encoding and whatnot. And you can configure that

434
00:27:07,068 --> 00:27:10,550
per database in your SQL engine,

435
00:27:10,700 --> 00:27:14,402
meaning that you can reconfigure that dynamically

436
00:27:14,546 --> 00:27:18,154
and your application should reflect that. But because

437
00:27:18,192 --> 00:27:21,514
you have just one string type in your application,

438
00:27:21,712 --> 00:27:25,322
then everything you have will not work well in that

439
00:27:25,376 --> 00:27:28,938
case. So this is another thingy that

440
00:27:29,024 --> 00:27:33,278
is caused by the impedance mismatch. Yet another thingy is like

441
00:27:33,444 --> 00:27:37,214
precision, right? In our applications we have floats and

442
00:27:37,252 --> 00:27:40,686
we have doubles and that's typically all we can use.

443
00:27:40,788 --> 00:27:44,530
But in SQL engine you can use decimal on numeric with

444
00:27:44,600 --> 00:27:48,638
the precision you can specify. You can basically configure

445
00:27:48,734 --> 00:27:52,050
the precision of your numbers to not lose the data.

446
00:27:52,120 --> 00:27:56,066
But once you go to your application, you may basically decrease the quality

447
00:27:56,248 --> 00:28:00,410
of your entities. Another thing with RMS

448
00:28:00,510 --> 00:28:04,118
is they lack the visibility, meaning that there are so

449
00:28:04,204 --> 00:28:07,794
many moving pieces that rms do take

450
00:28:07,852 --> 00:28:11,434
care of. Starting with transaction isolation devrel or

451
00:28:11,472 --> 00:28:15,158
transaction in general transaction scope. Who starts the transaction?

452
00:28:15,254 --> 00:28:18,826
Who rolls it back when it goes wrong? How is it

453
00:28:18,848 --> 00:28:22,334
rolled back? Can you nest transactions together? Is the

454
00:28:22,372 --> 00:28:26,222
data cached for your transaction or not? What is

455
00:28:26,276 --> 00:28:30,094
your pooling for your database connections or query hints or

456
00:28:30,132 --> 00:28:34,110
stored procedures and whatnot? All those things your RM

457
00:28:34,190 --> 00:28:37,986
is taking care of. But the problem is, do you

458
00:28:38,008 --> 00:28:41,378
see this configuration? This configuration is not

459
00:28:41,464 --> 00:28:44,974
stored very close to your application code. It's basically

460
00:28:45,112 --> 00:28:47,986
hidden somewhere in your app config,

461
00:28:48,098 --> 00:28:51,862
and it may differ between your environments. So again,

462
00:28:51,996 --> 00:28:55,206
your unit tests are not going to catch that.

463
00:28:55,388 --> 00:28:59,350
Moving on. Migrations. Is your Orm handling

464
00:28:59,430 --> 00:29:04,010
migrations or is it some set of SQL scripts

465
00:29:04,350 --> 00:29:07,926
doing all of that? Is even your application dealing

466
00:29:07,958 --> 00:29:11,530
with schema migrations and with the schema of your database?

467
00:29:11,610 --> 00:29:15,230
Or maybe it's some other application doing that. What happens

468
00:29:15,300 --> 00:29:18,906
if your Orm recognizes there is a schema drift?

469
00:29:19,018 --> 00:29:22,094
So it recognizes that some differences in

470
00:29:22,132 --> 00:29:25,762
columns or in data types? Is your Orm going

471
00:29:25,816 --> 00:29:28,738
to come step in and fix those changes,

472
00:29:28,824 --> 00:29:31,954
those differences automatically because some orms do

473
00:29:31,992 --> 00:29:35,182
that? How do you deal with heterogeneous scenario

474
00:29:35,246 --> 00:29:38,722
when you have multiple applications talking to the same database?

475
00:29:38,786 --> 00:29:42,774
Right? Those are the things that are very hard to see

476
00:29:42,892 --> 00:29:46,406
just because they are not very clear from our application code.

477
00:29:46,508 --> 00:29:49,946
Not to mention that how do you test whether your migration is

478
00:29:49,968 --> 00:29:53,750
going to run fast enough? So generally

479
00:29:53,910 --> 00:29:57,674
your Orm hides tons of

480
00:29:57,712 --> 00:30:01,322
various configurations behind the scenes. It starts with

481
00:30:01,376 --> 00:30:05,006
like the application code that you have no idea whether it's going

482
00:30:05,028 --> 00:30:09,914
to produce n plus one queries or whether it's going to download

483
00:30:09,962 --> 00:30:13,546
the data in eager mode. We can carry

484
00:30:13,578 --> 00:30:17,566
on with like models, migrations, configuration of

485
00:30:17,588 --> 00:30:20,734
the RM, stored procedures, functions,

486
00:30:20,862 --> 00:30:24,370
triggers and other stuff. And generally all those

487
00:30:24,440 --> 00:30:28,466
pieces are there, but are very hidden very deeply,

488
00:30:28,578 --> 00:30:32,454
very deep inside your application. So how

489
00:30:32,492 --> 00:30:36,086
do you capture all of that? How do you verify whether what

490
00:30:36,108 --> 00:30:39,446
you actually ultimately implemented, whether it's

491
00:30:39,478 --> 00:30:43,686
going to work well in production or not? How is your CI CD pipeline

492
00:30:43,798 --> 00:30:47,370
going to help you with that? And the thing

493
00:30:47,440 --> 00:30:50,938
that we lack is the context. We do not

494
00:30:51,024 --> 00:30:54,894
see how things that we implemented are going to work in

495
00:30:54,932 --> 00:30:58,702
production. We do not see the performance, we do not see

496
00:30:58,756 --> 00:31:02,442
what they actually do behind the scenes. And we lack this

497
00:31:02,516 --> 00:31:05,746
context. And we need to have this context in

498
00:31:05,768 --> 00:31:09,726
order to build a proper database guardrails.

499
00:31:09,838 --> 00:31:14,242
What we need to do is we need to have

500
00:31:14,296 --> 00:31:18,422
this ability to understand everything that

501
00:31:18,476 --> 00:31:22,166
happens in our database, in our environment, right? What the

502
00:31:22,188 --> 00:31:26,290
running configuration is, what the query is, what's the execution

503
00:31:26,370 --> 00:31:30,006
plan and other stuff. And with the typical CI

504
00:31:30,038 --> 00:31:33,450
CD pipeline with no database guardrails,

505
00:31:33,950 --> 00:31:37,818
we have no idea how it's working. What we need to do is we need

506
00:31:37,824 --> 00:31:41,034
to build database guardrails. So we need to build elements that

507
00:31:41,072 --> 00:31:44,814
are going to protect us from deploying bedcode to

508
00:31:44,852 --> 00:31:48,830
production and the elements that are going to observe how things

509
00:31:48,900 --> 00:31:52,302
work in your production SQL to let you know

510
00:31:52,356 --> 00:31:55,646
right when you are typing the code that these things are not going to

511
00:31:55,668 --> 00:31:58,766
work well in your local database. So let's

512
00:31:58,798 --> 00:32:02,146
see how we can do that. So in order to do that, first we would

513
00:32:02,168 --> 00:32:05,086
like to understand how SQL queries are executed,

514
00:32:05,198 --> 00:32:08,518
right? In order to do that, we need to understand SQL engine a

515
00:32:08,524 --> 00:32:12,150
little bit. So nearly every single

516
00:32:12,220 --> 00:32:16,374
database, when it executes the query, the query goes through

517
00:32:16,492 --> 00:32:20,294
multiple stages. The very first stage is parser. So the query

518
00:32:20,342 --> 00:32:23,914
is being parsed, meaning its textual representation is

519
00:32:23,952 --> 00:32:27,510
parsed into a thing that we call abstract syntax tree

520
00:32:27,590 --> 00:32:31,562
Ast for short. AST is basically a representation

521
00:32:31,626 --> 00:32:34,862
of what the query is trying to do. Then this

522
00:32:34,916 --> 00:32:38,462
query is getting rewritten using the rewriter because

523
00:32:38,596 --> 00:32:42,014
you can write the same query like

524
00:32:42,132 --> 00:32:46,014
there are multiple queries that are equivalent but are just written

525
00:32:46,062 --> 00:32:49,726
differently. You use different aliases, you number columns

526
00:32:49,758 --> 00:32:52,974
instead of naming them and whatnot. And those queries

527
00:32:53,022 --> 00:32:56,418
are doing the same. But still we would like to be able to reason

528
00:32:56,504 --> 00:32:59,846
about that in the same way. So that's why they need to be

529
00:32:59,868 --> 00:33:03,746
rewritten into some standardized form that is just easier

530
00:33:03,778 --> 00:33:08,230
to process. Then is the third step, which is called planning.

531
00:33:08,390 --> 00:33:11,894
SQL engine plans how to execute

532
00:33:11,942 --> 00:33:15,254
the query so it goes through the database and figures

533
00:33:15,302 --> 00:33:18,634
out what indexes there are, what tables there are,

534
00:33:18,672 --> 00:33:21,974
how it can join tables, how it can extract the data,

535
00:33:22,032 --> 00:33:25,214
whether it can use indexes, whether it should cache the

536
00:33:25,252 --> 00:33:28,794
data, hash it, sort it, and whatnot. This planning

537
00:33:28,842 --> 00:33:32,458
is a process that is actually crucial to executing the query

538
00:33:32,554 --> 00:33:36,402
because it provides the plan, the actual idea,

539
00:33:36,536 --> 00:33:40,530
how the query is going to be executed by the database. And finally,

540
00:33:40,680 --> 00:33:45,170
the executor is going to just get the plan and start doing

541
00:33:45,240 --> 00:33:49,250
that. So let's see the execution plans

542
00:33:49,410 --> 00:33:52,534
in action. So whenever we send a query like

543
00:33:52,572 --> 00:33:56,326
the one on the left. What we get is we can always ask the

544
00:33:56,348 --> 00:33:59,554
database to explain the query

545
00:33:59,602 --> 00:34:03,354
for us, how it's going to execute it. For instance, this is example from

546
00:34:03,392 --> 00:34:07,386
PostgreSQL and what we can see here is it generates a

547
00:34:07,408 --> 00:34:11,262
very nice plan for us. Let's dive deep into this plan.

548
00:34:11,396 --> 00:34:15,578
So every single plan consists of nodes. Basically every row

549
00:34:15,674 --> 00:34:19,006
you see in this plan is a

550
00:34:19,028 --> 00:34:22,846
code that represents some operation executed by

551
00:34:22,868 --> 00:34:26,046
the database. And every node has type,

552
00:34:26,148 --> 00:34:29,662
meaning that the type of automation it does, for instance

553
00:34:29,726 --> 00:34:33,486
sequential scan or bitmap, heat scan or nested loop

554
00:34:33,518 --> 00:34:37,234
join or whatever else. So generally operations that the SQL

555
00:34:37,282 --> 00:34:41,094
engine is going to execute. But apart from the type of

556
00:34:41,132 --> 00:34:44,360
the node, we also have the thing that is called cost.

557
00:34:44,730 --> 00:34:48,586
Cost is basically an arbitrary measure of

558
00:34:48,688 --> 00:34:52,390
how hard it is to execute

559
00:34:52,550 --> 00:34:55,866
given operation. How hard? Mostly in

560
00:34:55,888 --> 00:34:59,610
terms of like I o operations, how much data needs to be read

561
00:34:59,680 --> 00:35:03,486
from the drive, how much data needs to be spilled over to

562
00:35:03,508 --> 00:35:07,802
the hard drive and whatnot. But generally this represents the complexity

563
00:35:07,866 --> 00:35:11,166
of the operation. The higher the cost, obviously the

564
00:35:11,188 --> 00:35:14,866
slower the operation is. So what we can do now is

565
00:35:14,968 --> 00:35:18,498
if we could ask our SQL engine,

566
00:35:18,584 --> 00:35:21,630
hey, this is the query that my orm generated.

567
00:35:21,790 --> 00:35:25,234
Please tell me how you are going to execute that.

568
00:35:25,352 --> 00:35:28,694
Then we would end up with the query plan just like the

569
00:35:28,732 --> 00:35:32,310
one on the right. And based on this query plan we could

570
00:35:32,380 --> 00:35:36,422
tell how expensive it is. Obviously your

571
00:35:36,476 --> 00:35:39,638
SQL database is going to generate

572
00:35:39,734 --> 00:35:43,914
multiple plans and compare them based on the cost to

573
00:35:43,952 --> 00:35:47,434
pick the cheapest one. But for us, what is important is

574
00:35:47,472 --> 00:35:51,254
we can take this plan and see how the database

575
00:35:51,302 --> 00:35:54,686
decided to execute the query, which indexes it decided to

576
00:35:54,708 --> 00:35:58,362
use and why it decided to use these indexes and whatnot.

577
00:35:58,426 --> 00:36:01,790
So this is the first thing we could do to start building

578
00:36:01,860 --> 00:36:05,678
our database guardrails. The other thing we need to do is

579
00:36:05,764 --> 00:36:09,294
how are we going to do that? How are we going to extract

580
00:36:09,342 --> 00:36:12,622
all of these pieces? And to do that we can use the modern

581
00:36:12,686 --> 00:36:16,386
observability tooling, which is called open telemetry.

582
00:36:16,498 --> 00:36:19,890
Open telemetry allows us to capture logs,

583
00:36:19,970 --> 00:36:23,826
track metrics from our applications

584
00:36:23,938 --> 00:36:27,834
to provide better observability. Open telemetry, Otel for

585
00:36:27,872 --> 00:36:31,514
short, is basically a standard provided by CNCF cloud

586
00:36:31,552 --> 00:36:35,654
Native Computing foundation standard defining and providing

587
00:36:35,702 --> 00:36:39,594
a set of sdks for the instrumentation. Sdks for

588
00:36:39,632 --> 00:36:42,746
every single language you can think of modern languages that

589
00:36:42,768 --> 00:36:46,106
support it and whatnot. So you generally drop an SDK

590
00:36:46,138 --> 00:36:50,174
to your application. And now open telemetry is going to process things

591
00:36:50,212 --> 00:36:54,830
that are called signals. Signals are track our metrics,

592
00:36:54,990 --> 00:36:58,946
our logs, and other stuff that we can combine together

593
00:36:59,128 --> 00:37:02,786
to understand what's going on behind the scenes in

594
00:37:02,808 --> 00:37:05,966
our application and how things are actually executed.

595
00:37:06,078 --> 00:37:09,942
And with Autel, what we can do is we can create spans and

596
00:37:09,996 --> 00:37:13,862
traces. So imagine that we have an application that is

597
00:37:13,916 --> 00:37:17,506
processing some workflow that could be like a checkout workflow

598
00:37:17,538 --> 00:37:21,542
in our ecommerce app. So imagine that user clicked a checkout

599
00:37:21,606 --> 00:37:25,370
button and wants to start processing the payment, right? So our

600
00:37:25,440 --> 00:37:28,726
application, like our node a, this could be like web server,

601
00:37:28,758 --> 00:37:32,126
load balancer or whatever, gets this request. And then it

602
00:37:32,148 --> 00:37:35,930
needs to call some other microservices, like some queries,

603
00:37:36,010 --> 00:37:39,502
some database, some log storage or whatever.

604
00:37:39,636 --> 00:37:43,998
So we can see that this request coming from the node a is propagated

605
00:37:44,094 --> 00:37:47,682
down the line to other services, right? And this is

606
00:37:47,736 --> 00:37:51,502
what opentelemetry can capture for us. So we can capture

607
00:37:51,566 --> 00:37:55,086
the whole view of what's going on, the whole

608
00:37:55,128 --> 00:37:59,298
view that we basically call track. And track represents

609
00:37:59,394 --> 00:38:02,822
one particular workflow in our application and

610
00:38:02,876 --> 00:38:06,598
consists of spans. Spans are basically those single

611
00:38:06,684 --> 00:38:10,230
pieces representing how a particular code

612
00:38:10,390 --> 00:38:14,074
executed given stuff. So how there was a call

613
00:38:14,192 --> 00:38:18,138
to some other node like Node C, how long it took, what was

614
00:38:18,224 --> 00:38:21,426
the parameters and stuff and whatnot,

615
00:38:21,558 --> 00:38:25,054
showing exactly what's going on. So we can see what details we can

616
00:38:25,092 --> 00:38:28,254
capture using open telemetry, for instance, friendly name,

617
00:38:28,292 --> 00:38:32,202
for instance, timestamps, for instance, some attributes and whatnot.

618
00:38:32,346 --> 00:38:36,114
So this is what we can use to instrument our

619
00:38:36,152 --> 00:38:40,194
application and capture all the stuff. And now if we

620
00:38:40,232 --> 00:38:44,494
combine both of these things together, like the execution plans

621
00:38:44,542 --> 00:38:48,294
we already considered and open telemetry, what we

622
00:38:48,332 --> 00:38:51,926
could do is we could capture the true

623
00:38:52,108 --> 00:38:55,750
behavior of our application. The only

624
00:38:55,820 --> 00:38:58,986
problem is when do we capture that?

625
00:38:59,168 --> 00:39:02,726
And obviously we could go with load tests,

626
00:39:02,838 --> 00:39:06,086
get our application deployed, start load testing

627
00:39:06,118 --> 00:39:10,074
it, to get all the execution plans, to get all

628
00:39:10,112 --> 00:39:14,094
the statistics, all the metrics and whatnot, to see how it

629
00:39:14,132 --> 00:39:17,390
works. The problem with load tests is though that

630
00:39:17,460 --> 00:39:20,894
first they are super expensive in terms

631
00:39:20,932 --> 00:39:24,926
of time and money. It takes hours to execute proper

632
00:39:25,028 --> 00:39:28,546
load tests. It also takes lot of money to

633
00:39:28,568 --> 00:39:31,874
basically pay for the fleet, for the generated traffic, for the

634
00:39:31,912 --> 00:39:35,746
hardware. If we are doing load tests for ML based application, then we

635
00:39:35,768 --> 00:39:39,282
need to have GPU, which is also crazy expensive and whatnot.

636
00:39:39,426 --> 00:39:43,366
Second thing is we need to reproduce the traffic properly. So we

637
00:39:43,388 --> 00:39:46,482
need to get the proper cardinality data distribution,

638
00:39:46,546 --> 00:39:50,294
we need to anonymize the data, we need to be GDPR compliant

639
00:39:50,342 --> 00:39:53,658
and whatnot. It's not as straightforward as possible.

640
00:39:53,824 --> 00:39:57,738
And finally, those load tests happen very,

641
00:39:57,824 --> 00:40:00,874
very late in our CI CD pipeline.

642
00:40:01,002 --> 00:40:04,682
They happen after we merge the branch,

643
00:40:04,826 --> 00:40:08,686
after we run unit tests and integration tests, after we do

644
00:40:08,708 --> 00:40:11,882
the code review, after we deploy to pre production

645
00:40:11,946 --> 00:40:16,062
environment, they happen at the very end of this pipeline.

646
00:40:16,126 --> 00:40:19,490
And this is typically too late for us to

647
00:40:19,640 --> 00:40:23,394
get a meaningful and actionable feedback because when we

648
00:40:23,432 --> 00:40:26,674
implemented our stuff and we realize how

649
00:40:26,712 --> 00:40:30,214
we did that and then load tests tell us, hey,

650
00:40:30,252 --> 00:40:34,166
this thing is not going to work in production, then we are already probably

651
00:40:34,268 --> 00:40:37,834
like hours, if not days after we had the

652
00:40:37,872 --> 00:40:41,446
implementation phase of given particular feature, right? So load

653
00:40:41,478 --> 00:40:45,274
tests are expensive, are slow, and are way too

654
00:40:45,312 --> 00:40:49,242
late in our pipeline. So what we need to do

655
00:40:49,376 --> 00:40:52,074
is we need to be proactive.

656
00:40:52,202 --> 00:40:55,866
We can't let issues to appear in production.

657
00:40:55,978 --> 00:40:59,978
We need to find the issues during our CI CD pipeline

658
00:41:00,074 --> 00:41:03,950
as early as possible. We need to push all those checks

659
00:41:04,030 --> 00:41:09,038
to the left and find the issues automatically

660
00:41:09,134 --> 00:41:13,266
and monitor and observe our applications constantly to

661
00:41:13,288 --> 00:41:16,566
get better troubleshooting and better root causing. And we need

662
00:41:16,588 --> 00:41:20,134
that now. No matter what our application is, whether it's small

663
00:41:20,172 --> 00:41:24,102
application or big Fortune 500 corporate with

664
00:41:24,156 --> 00:41:26,920
enterprise application, we need that now.

665
00:41:27,710 --> 00:41:31,494
We need a completely new modern approach

666
00:41:31,622 --> 00:41:34,570
for getting proper database guild rows.

667
00:41:34,990 --> 00:41:38,554
And Mattis does exactly that. Matis is the

668
00:41:38,592 --> 00:41:42,602
solution that prevents the bad code from reaching

669
00:41:42,666 --> 00:41:46,714
production, that can monitor and observe all your databases

670
00:41:46,842 --> 00:41:50,078
and that can automatically troubleshoot them for you.

671
00:41:50,164 --> 00:41:54,862
And this uses all the principles, all the things that we've just discussed, open telemetry,

672
00:41:54,926 --> 00:41:58,334
execution plans and whatnot, and can improve

673
00:41:58,382 --> 00:42:02,782
your CI CD pipeline by providing a proper database

674
00:42:02,846 --> 00:42:05,850
guardrails. So let's see that a little bit in action.

675
00:42:05,950 --> 00:42:09,874
So Matis prevents your database code from breaking production.

676
00:42:09,922 --> 00:42:13,334
Once you register into the application, what you end up with is

677
00:42:13,372 --> 00:42:17,634
you have a project. Project basically represents, let's say one

678
00:42:17,692 --> 00:42:21,366
of your application with interacting with database.

679
00:42:21,478 --> 00:42:25,334
Right? What we can do is you drop one independency

680
00:42:25,462 --> 00:42:28,922
to your application dependency that uses open

681
00:42:28,976 --> 00:42:32,906
telemetry and does all that we discussed behind the scenes. And what

682
00:42:32,928 --> 00:42:36,686
we can do then is we can show you the recent activity. So for

683
00:42:36,708 --> 00:42:40,074
instance, we can tell you, hey, your application is exposing

684
00:42:40,122 --> 00:42:43,682
like those rest endpoints. And when you did call the rest

685
00:42:43,736 --> 00:42:47,394
endpoint, you get like 200 HTTP code

686
00:42:47,432 --> 00:42:50,754
as a response. But more importantly, those are the

687
00:42:50,792 --> 00:42:54,350
SQL queries that were generated behind the scenes

688
00:42:54,430 --> 00:42:57,702
by your orm, by your SQL driver, whatever.

689
00:42:57,836 --> 00:43:01,522
We are developer centric. So we want to have a very straight

690
00:43:01,586 --> 00:43:05,126
and very direct information, whether it's going to

691
00:43:05,148 --> 00:43:08,282
work well or whether it's going to fail. And what

692
00:43:08,336 --> 00:43:11,594
the impact is and how to fix a

693
00:43:11,632 --> 00:43:14,858
particular query. So Matis does exactly that,

694
00:43:14,944 --> 00:43:18,794
shows you all of that, and gives you very straight, very direct

695
00:43:18,912 --> 00:43:23,046
signal whether the things you have are going to work well in production

696
00:43:23,158 --> 00:43:26,286
or not. But if you want to dig deeper, then feel

697
00:43:26,308 --> 00:43:29,962
free to do so. You can, for instance, get all the SQL statements

698
00:43:30,026 --> 00:43:33,658
with all the tables listed, how they were accessed and executed.

699
00:43:33,754 --> 00:43:37,042
You can get metrics of your queries, so you can see

700
00:43:37,096 --> 00:43:40,930
exactly what the cost was, what the execution plans was

701
00:43:41,000 --> 00:43:44,674
and whatnot. You can get like a nice visualization of

702
00:43:44,712 --> 00:43:48,594
all the operations, how your SQL engine actually executed

703
00:43:48,642 --> 00:43:52,802
the stuff right. If you want, you can get the raw

704
00:43:52,866 --> 00:43:56,086
execution plan for you to process it further. And you

705
00:43:56,108 --> 00:43:59,574
can also see for instance all the tables and metrics and

706
00:43:59,612 --> 00:44:03,002
timings and other stuff that you have in your application,

707
00:44:03,136 --> 00:44:07,366
right? So this is what you can do. And this gives you the observability

708
00:44:07,478 --> 00:44:10,746
that you need to have during your CI CD

709
00:44:10,778 --> 00:44:14,222
pipeline more. We can also integrate that

710
00:44:14,276 --> 00:44:16,990
with your CI CD actions. So for instance,

711
00:44:17,330 --> 00:44:21,102
if you use GitHub actions that you can configure your pull

712
00:44:21,156 --> 00:44:24,382
request to basically have Matis

713
00:44:24,446 --> 00:44:28,082
interact with you with the pull request to

714
00:44:28,136 --> 00:44:32,114
analyze all the queries and all the schema migrations from

715
00:44:32,152 --> 00:44:36,210
your application automatically, for instance, we can also analyze that hey,

716
00:44:36,280 --> 00:44:40,006
you tried to migrate this schema. Those are the indexes you try to

717
00:44:40,028 --> 00:44:43,186
configure. Maybe this is not going to work and whatnot.

718
00:44:43,298 --> 00:44:47,094
So this is how you build a proper database guardrails into

719
00:44:47,132 --> 00:44:51,014
your CI CD pipeline. You can get the immediate feedback

720
00:44:51,062 --> 00:44:54,810
just when you are typing things down as a developer. But also

721
00:44:54,880 --> 00:44:59,242
you can get this kind of like database review for

722
00:44:59,296 --> 00:45:02,906
your SQL database interactions during CI CD

723
00:45:02,938 --> 00:45:07,434
pipeline. But it's not the end of the story. Also after deploying

724
00:45:07,482 --> 00:45:11,130
stuff, Matis can monitor and observe your databases.

725
00:45:11,210 --> 00:45:14,778
For instance, it can automatically analyze the schema

726
00:45:14,794 --> 00:45:18,574
of your database and suggest that hey, you do not have indexes

727
00:45:18,622 --> 00:45:21,794
configured on that. Maybe you should do that in order

728
00:45:21,832 --> 00:45:25,758
to improve the performance. But you also get a very nice observability

729
00:45:25,854 --> 00:45:30,034
dashboard dashboard showing you like slowest queries. So for instance

730
00:45:30,082 --> 00:45:34,226
you can see hey, this is the query that has been executed recently and bank,

731
00:45:34,258 --> 00:45:37,654
this is its performance. And you can get anomaly detection with like

732
00:45:37,692 --> 00:45:41,478
details of the deployments of running configuration and whatnot.

733
00:45:41,574 --> 00:45:45,862
You can get statistics of your tables like number of dead rows, auto vacuum

734
00:45:45,926 --> 00:45:49,514
and other stuff. You can get index usage hey, you do have

735
00:45:49,552 --> 00:45:53,374
indexes configured in your database, but maybe this index hasn't been

736
00:45:53,412 --> 00:45:56,894
used for like last two weeks and it's going to break,

737
00:45:57,012 --> 00:46:00,702
you can get extension, you can get database config and all

738
00:46:00,756 --> 00:46:04,686
of that stuff just by dropping one open source docker container

739
00:46:04,718 --> 00:46:08,622
that runs alongside your database. So generally

740
00:46:08,686 --> 00:46:12,434
this is what you can get with Mattis, and this is exactly what

741
00:46:12,472 --> 00:46:17,062
we would like to have. We would like to have basically all

742
00:46:17,116 --> 00:46:21,090
our stuff covered. We would like to have covered the source code integration,

743
00:46:21,170 --> 00:46:24,626
pull request analysis. We would like to have constant monitoring

744
00:46:24,658 --> 00:46:28,310
on observability and other stuff running 24/7

745
00:46:28,380 --> 00:46:31,786
left full cycle, preventing the bad code from

746
00:46:31,808 --> 00:46:34,982
reaching production and automatically troubleshooting

747
00:46:35,046 --> 00:46:38,906
the stuff if something breaks in the production. So metis integrates with

748
00:46:38,928 --> 00:46:42,122
your source code with various languages, various orms,

749
00:46:42,186 --> 00:46:46,190
various databases, no matter whether you host them on premise

750
00:46:46,530 --> 00:46:50,046
or in the cloud. It integrates with

751
00:46:50,068 --> 00:46:53,066
your CI CD pipeline, analyzes your pull requests,

752
00:46:53,098 --> 00:46:56,546
merge requests, for instance in GitHub actions. It can also give you

753
00:46:56,568 --> 00:47:00,574
the observability using like ad hoc analysis, web interface,

754
00:47:00,702 --> 00:47:04,642
CI tools and whatnot. So you get all of that at

755
00:47:04,696 --> 00:47:08,006
your hand with the modern open telemetry standard

756
00:47:08,108 --> 00:47:11,810
and modern approach to build the proper database

757
00:47:11,890 --> 00:47:14,834
guardrails into your CI CD pipeline.

758
00:47:14,962 --> 00:47:18,490
And that's the idea. Because databases, they may break,

759
00:47:18,640 --> 00:47:22,838
you may get slow queries, you may get wrong SQl

760
00:47:22,934 --> 00:47:26,742
schema migration, you may break the configuration by dropping,

761
00:47:26,806 --> 00:47:30,374
removing or stopping using the index right. And you can't

762
00:47:30,422 --> 00:47:34,142
wait for these issues to pop up in production. You need to catch them as

763
00:47:34,196 --> 00:47:35,680
early as possible.

764
00:47:37,250 --> 00:47:40,138
You can't rely on load tests. They are way too late,

765
00:47:40,234 --> 00:47:43,326
way too slow, and super expensive. You need to

766
00:47:43,348 --> 00:47:47,294
be proactive and push things to the left. And to all of that you can

767
00:47:47,332 --> 00:47:50,750
use Matis. Matis covers all of that and makes

768
00:47:50,820 --> 00:47:54,702
sure you do not fly blind and don't deploy bad

769
00:47:54,756 --> 00:47:58,246
code to your production. And being that said,

770
00:47:58,348 --> 00:48:01,606
I'd like to thank you for tuning in and coming to this talk.

771
00:48:01,708 --> 00:48:05,430
Hope you enjoyed. Hope you liked it, and please enjoy the rest

772
00:48:05,500 --> 00:48:07,380
of your conference. Thank you.

