1
00:00:24,250 --> 00:00:28,600
Hi everyone. Hello. Welcome to Chaos Engineering 2024.

2
00:00:28,970 --> 00:00:32,454
My name is Indika Wimalasuriya and part

3
00:00:32,492 --> 00:00:36,034
of my presentation I will walk you through smart Chaos,

4
00:00:36,162 --> 00:00:39,478
which is about leveraging generative AI to build

5
00:00:39,564 --> 00:00:44,034
autonomous chaos engineering workflows. During my presentation

6
00:00:44,162 --> 00:00:47,810
I will talk about distributed systems and mainly

7
00:00:47,890 --> 00:00:51,982
its importance when it comes to resilience. So why we have to make

8
00:00:52,036 --> 00:00:55,454
our distributed systems resilient? And then we will

9
00:00:55,492 --> 00:01:00,000
discuss high level what is chaos engineering and generative AI as well.

10
00:01:01,090 --> 00:01:04,590
Important part of my presentation is discuss about methodology

11
00:01:04,670 --> 00:01:08,082
of chaos engineering and then how we can apply

12
00:01:08,216 --> 00:01:12,082
generative AI solutions into the different aspects of

13
00:01:12,136 --> 00:01:15,374
or the life stages of the chaos

14
00:01:15,422 --> 00:01:18,774
engineering workflows. We will discuss about quite a lot of

15
00:01:18,812 --> 00:01:22,726
use cases, and I have used AWS Partyrock to implement some

16
00:01:22,748 --> 00:01:26,342
of these use cases as well. And then we will check

17
00:01:26,476 --> 00:01:30,730
how we can build an autonomous chaos engineering workflow

18
00:01:31,230 --> 00:01:35,210
which can learn and which can act, and we can generate

19
00:01:37,150 --> 00:01:40,714
the chaos solutions using generative AI

20
00:01:40,762 --> 00:01:44,110
without human intervention. Finally, I'll wrap it up with

21
00:01:44,180 --> 00:01:48,000
some of the best practices and pitfalls based on my experience.

22
00:01:48,850 --> 00:01:53,200
So, moving on, I hope you all understand,

23
00:01:53,570 --> 00:01:57,330
the distributed systems are very complex. One of the main reason

24
00:01:57,400 --> 00:02:02,142
why they are very complex is we have layers of architectures,

25
00:02:02,286 --> 00:02:05,534
right? We have the hardware layers. It can be your serverless,

26
00:02:05,582 --> 00:02:09,142
or the computing layer or the front end layers as well.

27
00:02:09,276 --> 00:02:13,174
What these layers has done is in case if there's an issue in any

28
00:02:13,212 --> 00:02:16,854
of these layers, it will have a ripple effect on other

29
00:02:16,892 --> 00:02:20,154
layers as well. And one other challenge is in case

30
00:02:20,192 --> 00:02:24,154
of a bug in one of the layer, again, it can cause

31
00:02:24,352 --> 00:02:27,562
different behaviors to the impact or ripple effect

32
00:02:27,616 --> 00:02:30,974
to the other layers. And what we also know

33
00:02:31,012 --> 00:02:34,334
is bugs can appear anytime, right? It can be that

34
00:02:34,372 --> 00:02:38,480
you did a deployment last week, but maybe bug might appear today.

35
00:02:38,930 --> 00:02:42,634
So managing these complexity distributed

36
00:02:42,682 --> 00:02:46,366
systems is a challenge because there are a lot of unknowns.

37
00:02:46,478 --> 00:02:50,194
And even though we think that we are knowing everything and we are

38
00:02:50,312 --> 00:02:53,602
on top of the development rigor, the test

39
00:02:53,656 --> 00:02:57,574
rigor and the CI CD pipelines and all the

40
00:02:57,612 --> 00:03:01,234
automations we are bringing in, we still tend to encounter

41
00:03:01,282 --> 00:03:04,438
issues. And that is one of the challenge. And that is something

42
00:03:04,524 --> 00:03:08,614
probably you will ask why? Like why are we not able

43
00:03:08,652 --> 00:03:12,346
to make management of distributed systems easy? Or is

44
00:03:12,368 --> 00:03:16,154
it something down to the skill level? Or is it something down

45
00:03:16,192 --> 00:03:19,818
to the people aspect? Or what is it? That's something

46
00:03:19,904 --> 00:03:22,942
probably you want to find

47
00:03:22,996 --> 00:03:26,846
out, and probably you want to answer. And if you are

48
00:03:26,868 --> 00:03:30,286
thinking that these issues are only bound to

49
00:03:30,308 --> 00:03:33,806
a certain level of size of the company or size of the

50
00:03:33,908 --> 00:03:37,474
engagement. But I think you are wrong. Why?

51
00:03:37,592 --> 00:03:40,706
Because I am giving you a couple of examples here. If you

52
00:03:40,728 --> 00:03:43,586
look at it, during 2021,

53
00:03:43,688 --> 00:03:46,802
Facebook had a massive outage which impacted Instagram

54
00:03:46,866 --> 00:03:51,026
and WhatsApp and it outage lasted around 5 hours. This has impacted

55
00:03:51,058 --> 00:03:54,262
Facebook badly and it had an impact on their

56
00:03:54,316 --> 00:03:58,514
stocks as well. And same here, one of the leading

57
00:03:58,562 --> 00:04:02,214
content delivery network, the fastly had the outage

58
00:04:02,342 --> 00:04:05,706
which lasted around 1 hour again and it had

59
00:04:05,728 --> 00:04:09,350
the impact on series of other applications or systems.

60
00:04:09,510 --> 00:04:12,746
Mainly this is down to fastly being one of the leading

61
00:04:12,778 --> 00:04:16,026
CDN. It has been used widely across the industry.

62
00:04:16,138 --> 00:04:18,890
So this impacted Amazon, eBay,

63
00:04:18,970 --> 00:04:22,126
Reddit and Twitch, Guardian and

64
00:04:22,148 --> 00:04:26,206
even the New York Times and even some of the uk government websites.

65
00:04:26,318 --> 00:04:29,634
This was identified that there was a bug in the software and

66
00:04:29,752 --> 00:04:32,798
which has got move into production

67
00:04:32,894 --> 00:04:36,614
and which has resulted this outage. So this is again one

68
00:04:36,652 --> 00:04:39,906
classic example, one issue impacting multiple systems.

69
00:04:39,938 --> 00:04:43,570
And this is kind of a classic example of the complexities

70
00:04:43,650 --> 00:04:48,038
distributed systems are bringing. And last year

71
00:04:48,204 --> 00:04:52,294
we have seen Datadoc, one of the leading observability tools

72
00:04:52,342 --> 00:04:55,674
and it's kind of like probably number two

73
00:04:55,712 --> 00:05:00,018
in the gardener observability magic quadrant. So Datadog experienced

74
00:05:00,054 --> 00:05:04,090
a substantial outage which resulted in impacting

75
00:05:04,170 --> 00:05:08,154
almost like most of their customers. Because Datadog,

76
00:05:08,202 --> 00:05:11,918
as a SaaS solution, people are dependent on the

77
00:05:12,004 --> 00:05:16,002
systems being up and running to enable their

78
00:05:16,056 --> 00:05:19,710
systems, getting the alerts and other observability

79
00:05:19,790 --> 00:05:23,262
related work. So this is again identified

80
00:05:23,326 --> 00:05:26,914
that there was a route and there's a restart

81
00:05:26,962 --> 00:05:30,838
required. So this is again a classic example. Like even

82
00:05:30,924 --> 00:05:34,534
with companies which has money, which has

83
00:05:34,572 --> 00:05:38,314
able to invest money on the proper tools, processes and

84
00:05:38,352 --> 00:05:41,558
even people is not immune

85
00:05:41,574 --> 00:05:45,194
to outages. So again, now you will

86
00:05:45,232 --> 00:05:48,486
question this, right? Why? Because if you are spending

87
00:05:48,518 --> 00:05:52,078
money, if you are bringing in the right tool, right people, and we are building

88
00:05:52,244 --> 00:05:55,982
the right processes, then why are we every

89
00:05:56,036 --> 00:05:59,370
day like ending up with these kind of situations?

90
00:05:59,530 --> 00:06:03,140
And one of the key thing, what you have to understand is

91
00:06:03,670 --> 00:06:07,442
we are doing lot of testing. And you might even ask that these

92
00:06:07,496 --> 00:06:10,850
systems are going through a rigorous testing cycle.

93
00:06:11,510 --> 00:06:14,834
It can be the developer testing, it can

94
00:06:14,872 --> 00:06:19,150
be the regression testing, it can be performance testing,

95
00:06:19,230 --> 00:06:23,414
it can be loud testing, it can be security testing. And once even

96
00:06:23,452 --> 00:06:27,390
you deploy your code to production, you will do a post deployment testing.

97
00:06:27,490 --> 00:06:30,806
So there are a lot of testing happening in these systems

98
00:06:30,918 --> 00:06:34,042
and even with this testing, and we have using

99
00:06:34,096 --> 00:06:37,914
lot of tools and automations to

100
00:06:38,112 --> 00:06:41,326
improve our testing capability, why are we still

101
00:06:41,428 --> 00:06:45,182
encountering major issues? And one of the answer is

102
00:06:45,316 --> 00:06:48,718
we are only testing what we know. So example,

103
00:06:48,804 --> 00:06:52,326
if I take example, if a customer gives a requirement,

104
00:06:52,458 --> 00:06:55,806
developer go through the requirement, probably, and the developer

105
00:06:55,838 --> 00:06:59,298
and the business analyst is converted to these stories. And then

106
00:06:59,384 --> 00:07:03,998
these stories, developers will start building parallel.

107
00:07:04,094 --> 00:07:08,130
The QA team, the quality assurance team will go through these requirements as well.

108
00:07:08,200 --> 00:07:11,302
And they will come up with their test cases. And this is a very

109
00:07:11,356 --> 00:07:15,366
important point to remember. So when the QA team is coming up with

110
00:07:15,548 --> 00:07:19,126
the test cases, what they are doing is they are referring to the

111
00:07:19,148 --> 00:07:22,554
requirements and they are putting their thought and they are coming up with those

112
00:07:22,592 --> 00:07:26,006
test cases. So what we have to understand is the QA

113
00:07:26,038 --> 00:07:28,666
team is coming up with what they know,

114
00:07:28,848 --> 00:07:32,106
right? So we are good at testing what we know. So that

115
00:07:32,128 --> 00:07:35,774
is one of the main thing. And most of the time when we are coming

116
00:07:35,812 --> 00:07:39,418
up with issues, what we have seen is it's the unknowns

117
00:07:39,514 --> 00:07:43,226
distributed system, because they are very complex

118
00:07:43,338 --> 00:07:46,754
and because it's like vast and it's difficult to manage,

119
00:07:46,872 --> 00:07:50,286
there are a lot of unknowns. And these unknowns are getting missed

120
00:07:50,318 --> 00:07:52,850
out when we are doing testing,

121
00:07:53,670 --> 00:07:57,186
because we test what is known to us.

122
00:07:57,288 --> 00:08:00,854
So this resulted in these issues getting creeped into our

123
00:08:00,892 --> 00:08:04,242
production systems regularly. And this is one of the challenge,

124
00:08:04,306 --> 00:08:07,874
and this is a challenge where we are planning to address using chaos

125
00:08:07,922 --> 00:08:10,902
engineering. So if you look at chaos engineering,

126
00:08:10,966 --> 00:08:14,266
chaos engineering is pretty much trying to understand what are

127
00:08:14,288 --> 00:08:16,954
the unknowns, right. As I said,

128
00:08:17,072 --> 00:08:20,662
when our quality assurance teams going and doing testing,

129
00:08:20,726 --> 00:08:24,334
they are only doing testing on knowns, what is known to them.

130
00:08:24,452 --> 00:08:28,750
But assuming a distributed system deployed in a data

131
00:08:28,820 --> 00:08:32,826
center, are we thinking of like someone in the data center pulling

132
00:08:32,858 --> 00:08:36,514
a cable or someone is switching off the machine accidentally or

133
00:08:36,552 --> 00:08:40,066
some router is enabling and which has resulted in traffic is

134
00:08:40,088 --> 00:08:43,538
getting failed. So those are the scenarios usually

135
00:08:43,704 --> 00:08:47,602
are not being conscious or covered. Part of our typical,

136
00:08:47,746 --> 00:08:51,746
the quality assurance testing. And one of the main reason is there's

137
00:08:51,778 --> 00:08:55,878
a lot of unknown here. So why chaos engineering is

138
00:08:55,964 --> 00:08:59,642
we want to develop a

139
00:08:59,696 --> 00:09:03,642
mechanism where we can test unknown. So this is nothing new.

140
00:09:03,696 --> 00:09:07,258
Chaos engineering is here in industry for some time now.

141
00:09:07,344 --> 00:09:10,650
So this was pioneered by Netflix. Especially when they are moving

142
00:09:10,720 --> 00:09:13,966
out, they are on premise to the

143
00:09:13,988 --> 00:09:17,998
cloud. They developed this chaos monkey, which is used to

144
00:09:18,084 --> 00:09:21,594
go and do some chaos in their production environment.

145
00:09:21,722 --> 00:09:25,214
So this allowed them to understand what are the issues

146
00:09:25,332 --> 00:09:28,978
and what are the reliability issues and the resilience issues in their system,

147
00:09:29,064 --> 00:09:32,338
so that they were able to develop a world class streaming media

148
00:09:32,424 --> 00:09:36,618
platform. So one of the reason chaos engineering

149
00:09:36,654 --> 00:09:40,530
is very important is it is able to test your resilience

150
00:09:40,690 --> 00:09:44,086
and it is able to do sometimes some things which

151
00:09:44,108 --> 00:09:48,130
we are not even thinking. So that is the advantage.

152
00:09:48,210 --> 00:09:51,834
So chaos engineering is allowing us to improve our reliability and

153
00:09:51,872 --> 00:09:54,922
build our systems with resilience in mind,

154
00:09:55,056 --> 00:09:58,726
and it's allowing us to achieve our service level objectives,

155
00:09:58,838 --> 00:10:02,110
and even it's allowing us to achieve our meantime to result

156
00:10:02,180 --> 00:10:06,094
and other targets. So this is very important for

157
00:10:06,132 --> 00:10:10,270
any of the distributed system to look at chaos engineering seriously.

158
00:10:11,090 --> 00:10:14,606
So with this, I'll park the topic of chaos engineering for

159
00:10:14,628 --> 00:10:18,978
a moment, and let's move into generative AI. So I'm probably sure

160
00:10:19,064 --> 00:10:22,942
you all are aware of generative AI. With the hype of chat GBT.

161
00:10:23,006 --> 00:10:26,882
Now, everyone is aware of generative AI, and everyone is using generative

162
00:10:26,946 --> 00:10:30,674
AI. So generative AI is nothing but the ability

163
00:10:30,722 --> 00:10:35,026
of AI models to create new content or create original

164
00:10:35,058 --> 00:10:38,266
content. By looking at the large amount of

165
00:10:38,288 --> 00:10:41,738
data, these large language models are able to come up

166
00:10:41,744 --> 00:10:45,354
with innovative solutions. When comes

167
00:10:45,392 --> 00:10:49,066
to creating new content, it can be either images or

168
00:10:49,088 --> 00:10:52,000
the videos, or it can be in any media form.

169
00:10:52,370 --> 00:10:56,154
So some of these models are really helping

170
00:10:56,202 --> 00:10:59,914
us to make a difference in our operations,

171
00:11:00,042 --> 00:11:04,062
or how we work, or how we approach our day of

172
00:11:04,116 --> 00:11:07,394
life work. So if you look at applications of

173
00:11:07,432 --> 00:11:11,538
generative AI, as I said, one of the top use cases is

174
00:11:11,704 --> 00:11:16,886
the text generation. So it's not just a chatbot or just a

175
00:11:16,988 --> 00:11:20,502
standard bot which you can communicate. So the same text

176
00:11:20,556 --> 00:11:23,570
generation concept, you can apply into your coding,

177
00:11:23,650 --> 00:11:27,062
and you can apply into the writing, you can apply

178
00:11:27,116 --> 00:11:30,806
into the production support, you can apply into manage knowledge

179
00:11:30,838 --> 00:11:35,450
bases. So the opportunities are endless, has good as your imagination,

180
00:11:35,790 --> 00:11:38,970
it has the capability of image generation as well, and video

181
00:11:39,040 --> 00:11:42,954
generation, and so many other things. So this is helping

182
00:11:43,002 --> 00:11:46,606
us to come up with the new innovative solutions for

183
00:11:46,708 --> 00:11:49,840
some of the problems or the challenges we have.

184
00:11:50,770 --> 00:11:54,574
And again, coming back to chaos engineering. So even

185
00:11:54,612 --> 00:11:58,626
though we say chaos, we want to do chaos engineering in

186
00:11:58,648 --> 00:12:02,526
a methodical way. So there's nothing like doing a chaos engineering

187
00:12:02,558 --> 00:12:05,730
a chaos way, and that will not give you any value.

188
00:12:05,880 --> 00:12:09,202
So what we want to do is come up with the proper methodology,

189
00:12:09,346 --> 00:12:13,650
which will allow you to develop your workflows,

190
00:12:13,730 --> 00:12:17,734
and then come up with the proper chaos engineering mechanism. And even

191
00:12:17,772 --> 00:12:21,254
though Netflix has been pioneered and they are able to do this in production

192
00:12:21,302 --> 00:12:25,414
environment, we currently suggest you started in your non production

193
00:12:25,462 --> 00:12:29,354
environments and then expand it later. So what are the

194
00:12:29,392 --> 00:12:32,778
key steps of chaos engineering?

195
00:12:32,874 --> 00:12:35,594
So the first task is discover,

196
00:12:35,722 --> 00:12:39,438
discover your services, what are the components of your application,

197
00:12:39,604 --> 00:12:43,502
where your application is deployed, and what are the dependencies

198
00:12:43,566 --> 00:12:46,930
upstreams and downstreams, those are very important because

199
00:12:47,000 --> 00:12:50,340
those are the places where things can go wrong.

200
00:12:50,870 --> 00:12:54,034
So discovering your service is very important.

201
00:12:54,232 --> 00:12:58,182
Then you have to understand your steady state studies is nothing

202
00:12:58,236 --> 00:13:01,446
but what is good mean for you. It can

203
00:13:01,468 --> 00:13:05,078
be like example,

204
00:13:05,164 --> 00:13:08,726
if it is web application, it's about application has

205
00:13:08,748 --> 00:13:12,426
to be up and running, application has to serve customer request within a

206
00:13:12,448 --> 00:13:16,106
certain time. So that is what goods mean for you.

207
00:13:16,208 --> 00:13:19,846
So every system we have to understand what is the steady state

208
00:13:19,968 --> 00:13:24,238
and that will allow us to understand

209
00:13:24,404 --> 00:13:28,298
and ensure that we have one identification.

210
00:13:28,474 --> 00:13:31,582
When we say good, so good can't be based

211
00:13:31,636 --> 00:13:35,634
on different people's opinion. It has to be something which

212
00:13:35,672 --> 00:13:39,614
is written and something which is acceptable

213
00:13:39,662 --> 00:13:42,974
to everyone. And then we will build our hypothesis,

214
00:13:43,022 --> 00:13:46,574
what are the failure scenarios for this application? And the hypothesis

215
00:13:46,622 --> 00:13:49,814
will help us to come up with experiments and then

216
00:13:49,932 --> 00:13:53,446
to run them. And when we are running we will verify and we

217
00:13:53,468 --> 00:13:56,802
will do an improve and continuous improvement of this cycle.

218
00:13:56,946 --> 00:14:00,518
And we are obviously able to integrate this with CI CD pipelines.

219
00:14:00,614 --> 00:14:04,042
But this is at the moment happening manually. And one

220
00:14:04,096 --> 00:14:07,946
important thing you have to be remember is when you are following this process,

221
00:14:08,128 --> 00:14:11,498
you have to have ability to measure everything.

222
00:14:11,664 --> 00:14:14,810
There's no point you do chaos engineering or chaos testing,

223
00:14:14,890 --> 00:14:18,894
but you are not looking at how your systems are behaving. I'm sure

224
00:14:18,932 --> 00:14:23,394
you have heard of this term called wisdom of production. It's about getting

225
00:14:23,512 --> 00:14:27,630
the knowledge of how your systems are running in production

226
00:14:27,790 --> 00:14:31,934
or production environments, or even some environments

227
00:14:31,982 --> 00:14:35,970
which are identical production. Remember I said you are not supposed

228
00:14:36,040 --> 00:14:39,686
to or encouraged to do chaos engineering testing in production. But what you

229
00:14:39,708 --> 00:14:43,398
can do is you can build an identical environment and you can do where you

230
00:14:43,404 --> 00:14:46,690
can get the experience and the knowledge.

231
00:14:46,850 --> 00:14:50,186
So key things is parallel to your chaos testing. You have

232
00:14:50,208 --> 00:14:53,498
to have your observability in place. So observability is

233
00:14:53,664 --> 00:14:57,414
looking at the external outputs, trying to define the internal

234
00:14:57,462 --> 00:15:01,578
state of your system. So that is very important. When the chaos is happening,

235
00:15:01,664 --> 00:15:05,274
you want to know how your systems are behaving and then you have to have

236
00:15:05,312 --> 00:15:08,750
your SL laws defined and they are in place so that

237
00:15:08,820 --> 00:15:12,478
you will able to understand when these chaos testings are run,

238
00:15:12,564 --> 00:15:16,366
what is the impact on your service level objectives. And that is directly

239
00:15:16,398 --> 00:15:19,698
correlated with what is impact on your customer experience.

240
00:15:19,864 --> 00:15:23,506
So at this moment we are not probably have the ability to understand

241
00:15:23,608 --> 00:15:26,642
what is customers feeling, but we have some service

242
00:15:26,696 --> 00:15:29,862
level objectives which are very aligned to customer experience.

243
00:15:29,996 --> 00:15:33,426
So this is allowing us to understand how this is impacting

244
00:15:33,458 --> 00:15:36,822
to our customer. And finally you can look at

245
00:15:36,956 --> 00:15:40,714
the latency traffic error and saturation. So combination of

246
00:15:40,752 --> 00:15:44,970
all of this will allow you to measure everything. So this is very important.

247
00:15:45,120 --> 00:15:49,030
When you are going through the chaos engineering process, you have to measure

248
00:15:49,110 --> 00:15:52,080
everything, otherwise that is a waste of time.

249
00:15:53,010 --> 00:15:56,478
So now let's look at part of each

250
00:15:56,564 --> 00:16:00,986
different stage of chaos engineering, how we can bring generative AI.

251
00:16:01,178 --> 00:16:04,690
So that is the key. So here I'm looking at ten

252
00:16:04,760 --> 00:16:08,222
stages, ten step into the chaos engineering workflow,

253
00:16:08,286 --> 00:16:11,634
and we'll try to go and see how we can actually

254
00:16:11,752 --> 00:16:14,926
leverage generative AI to

255
00:16:15,048 --> 00:16:18,406
provide solutions to this area. So one is

256
00:16:18,508 --> 00:16:22,342
discovery. So we are able, like the traditional way

257
00:16:22,396 --> 00:16:26,322
is people will use manual

258
00:16:26,386 --> 00:16:30,074
approach or something very close to manual to

259
00:16:30,112 --> 00:16:33,786
discover things. But we have the option, like we have sometimes the

260
00:16:33,808 --> 00:16:38,102
observability tools and our apms application performance supporting tools

261
00:16:38,166 --> 00:16:41,846
where it can create service maps, but that again will

262
00:16:41,888 --> 00:16:45,822
help us to do discovery. But sometimes, most of the time this is happening

263
00:16:45,876 --> 00:16:49,566
in manually and dependency identification. So this is

264
00:16:49,588 --> 00:16:52,686
again something which is currently happening manually and we

265
00:16:52,708 --> 00:16:56,562
are able to bringing in generative AI solutions which we will look at

266
00:16:56,616 --> 00:16:59,790
in future. And steady state defined.

267
00:16:59,870 --> 00:17:03,374
So steady state defined is you are looking at your architecture,

268
00:17:03,422 --> 00:17:07,174
the services and everything, and you are defining what is good

269
00:17:07,212 --> 00:17:10,914
mean to you. So this is at the moment pretty much happening manually.

270
00:17:11,042 --> 00:17:15,762
And this is something, again you can leverage generative AI solutions,

271
00:17:15,906 --> 00:17:18,838
hypothesis is nothing but your failure scenarios.

272
00:17:18,934 --> 00:17:23,514
And this is again at the moment what's happening is your

273
00:17:23,552 --> 00:17:27,366
entire team will start looking at the services, the architecture

274
00:17:27,398 --> 00:17:31,210
diagrams, system dependencies, bottlenecks and probable

275
00:17:31,370 --> 00:17:35,194
causes, and then come up with the failure

276
00:17:35,242 --> 00:17:39,630
scenarios or the hypothesis. But then again there's a human intervention

277
00:17:40,050 --> 00:17:44,698
required. And you all understand, if there's a human intervention means

278
00:17:44,884 --> 00:17:48,306
there's always humans will do what is known. So we are missing out the

279
00:17:48,328 --> 00:17:52,930
unknowns. So that is the area where again we can leverage generative AI,

280
00:17:53,670 --> 00:17:56,882
an experiment design, again something which is happening

281
00:17:56,936 --> 00:18:00,534
manually, or we can do it in a partial automation, but with this

282
00:18:00,572 --> 00:18:04,006
generative AI, we are able to full fledged automate this,

283
00:18:04,108 --> 00:18:07,318
like we can full fledged use generative AI and its

284
00:18:07,404 --> 00:18:10,794
content creation capabilities. And to come up with these

285
00:18:10,832 --> 00:18:14,186
experiments, and once you have the experiments, you will have

286
00:18:14,208 --> 00:18:17,418
to understand the blast radius. I mean once you

287
00:18:17,504 --> 00:18:21,418
come up with the chaos engineering test, you will not go and just execute it.

288
00:18:21,504 --> 00:18:25,498
You want to understand what is the impact it's going to cause upfront,

289
00:18:25,594 --> 00:18:29,310
right? So that we call blast radius. So once you are

290
00:18:29,380 --> 00:18:32,798
doing that experiment, you can understand your blast radius is correct,

291
00:18:32,884 --> 00:18:36,226
or whether it was less or whether it had a wider impact. That is

292
00:18:36,248 --> 00:18:39,566
again a learning. So understanding

293
00:18:39,598 --> 00:18:42,818
blast radiance, which is usually happening in a manual way

294
00:18:42,904 --> 00:18:46,406
where you can leverage generative AI solutions to

295
00:18:46,428 --> 00:18:49,906
do it in an automated fashion. And there's

296
00:18:49,938 --> 00:18:53,650
something called Rumsfield metrics, which is about known knowns,

297
00:18:53,730 --> 00:18:57,766
known unknowns and unknown knowns, so which we will cover in

298
00:18:57,788 --> 00:19:01,640
a subsequent slide. Here's again about

299
00:19:02,330 --> 00:19:05,846
coming up with a hypothesis for known knowns,

300
00:19:05,878 --> 00:19:09,158
what you know in your area, likewise.

301
00:19:09,254 --> 00:19:12,682
So this is again a place where we can use Geni, and then

302
00:19:12,736 --> 00:19:16,494
about monitoring and analysis. We can plug our geni solutions with

303
00:19:16,532 --> 00:19:20,014
observability tools, and then we can bring in

304
00:19:20,212 --> 00:19:23,642
the capabilities large language model is bringing to the table,

305
00:19:23,706 --> 00:19:27,314
and we can leverage that documentation and reporting is something

306
00:19:27,352 --> 00:19:31,090
a bread and butter for generative AI, because it's kind of like

307
00:19:31,160 --> 00:19:35,346
what is supposed to do or the basics. And then obviously we

308
00:19:35,368 --> 00:19:38,946
can go through this in an iterative way. We can share all the learnings,

309
00:19:38,978 --> 00:19:42,934
the observability data, service level objective data and other

310
00:19:43,052 --> 00:19:46,018
the latency, traffic saturation and error rates,

311
00:19:46,034 --> 00:19:49,354
and all those four golden signal data and feed them into

312
00:19:49,392 --> 00:19:53,414
generative AI, where it can come up with the holistic approach

313
00:19:53,462 --> 00:19:57,094
and to improve your systems or the workflows of chaos

314
00:19:57,142 --> 00:20:00,746
engineering. So, moving on

315
00:20:00,848 --> 00:20:04,046
now, I will go to the stages which

316
00:20:04,068 --> 00:20:07,914
we have discussed and discuss about how we can leverage generative

317
00:20:07,962 --> 00:20:11,802
AI for this. I am at the moment using one of the architecture diagram.

318
00:20:11,866 --> 00:20:15,594
So these architecture diagrams, I have pulled it up from Amazon.com website,

319
00:20:15,732 --> 00:20:19,166
one of their case studies. So probably one glass,

320
00:20:19,198 --> 00:20:22,882
you might have an understanding of what this architecture diagram, or probably

321
00:20:23,016 --> 00:20:26,462
it will take a little bit of time for you. And the idea is that

322
00:20:26,536 --> 00:20:29,958
that is why we need generative AI. So we don't need

323
00:20:30,044 --> 00:20:33,494
really SMEs to be involved all the time.

324
00:20:33,612 --> 00:20:37,606
So this is the architecture diagram of an electronic vehicle charging system.

325
00:20:37,708 --> 00:20:41,206
So it's hosted in AWS, it has components

326
00:20:41,238 --> 00:20:44,678
like Route 53, you have your network load balancer,

327
00:20:44,774 --> 00:20:48,534
it's using Fargate, and it's using some of the IoT

328
00:20:48,662 --> 00:20:51,306
components, and it has lambda SQS,

329
00:20:51,418 --> 00:20:53,930
step functions, and it has the Aetna,

330
00:20:54,010 --> 00:20:57,770
DynamoDB, S three, and other visualization

331
00:20:57,850 --> 00:21:00,910
tools as well. So this is again a very comprehensive,

332
00:21:01,810 --> 00:21:05,298
probably a highly complex distributed system.

333
00:21:05,464 --> 00:21:10,114
And what we are going to do is we are going to use this as

334
00:21:10,152 --> 00:21:14,446
our base and see how we can automate some of the stage

335
00:21:14,558 --> 00:21:17,270
just which I discussed earlier.

336
00:21:18,010 --> 00:21:21,894
So, moving on, one of our first task is,

337
00:21:22,012 --> 00:21:25,542
can we identify the dependencies here?

338
00:21:25,596 --> 00:21:29,174
What I'm doing is. So all those examples I have tested

339
00:21:29,222 --> 00:21:32,700
using AWS, party Rock AWS party rock is one of

340
00:21:33,550 --> 00:21:37,578
innovative the AI play pen

341
00:21:37,664 --> 00:21:40,874
which AWS has released. So if you are aware, AWS has

342
00:21:40,912 --> 00:21:44,926
the search maker which is about hard way of deploying and

343
00:21:45,028 --> 00:21:48,702
managing your AI models. And then you have bedrock where

344
00:21:48,756 --> 00:21:52,558
it's API based so that it's more of a serverless kind of experience.

345
00:21:52,724 --> 00:21:56,386
And party rock is where you kind of like plug and

346
00:21:56,408 --> 00:22:00,398
play and start using models. So if you want go to AWS party

347
00:22:00,414 --> 00:22:03,934
rock where you can experiment and create all those things which I'm

348
00:22:03,982 --> 00:22:07,042
discussing here. So here what I have done, I used

349
00:22:07,096 --> 00:22:10,822
that architecture diagram I showed you earlier. I created a

350
00:22:10,876 --> 00:22:14,018
small app where I have given the architecture diagram

351
00:22:14,114 --> 00:22:18,294
and I asked generative AI to come up with system dependencies.

352
00:22:18,422 --> 00:22:22,086
As you can see it says based on the architecture

353
00:22:22,118 --> 00:22:26,374
diagram, here are some of the key dependencies. So it's identifying

354
00:22:26,422 --> 00:22:30,530
EV charging station, OCPP protocol handler

355
00:22:30,710 --> 00:22:34,666
charging station management system, payment provider notification

356
00:22:34,778 --> 00:22:38,634
component, telemetry induction, billing system authentication

357
00:22:38,682 --> 00:22:43,140
has the key system dependencies. So this is good without

358
00:22:43,590 --> 00:22:47,090
us looking at this, without someone

359
00:22:47,160 --> 00:22:51,230
from the team or the SME looking at this generative AI,

360
00:22:51,310 --> 00:22:54,866
just by looking at architecture diagram, it's able to derive this.

361
00:22:54,968 --> 00:22:58,626
So what you have to understand is this is not just image

362
00:22:58,658 --> 00:23:01,538
reading. So this is about just image reading.

363
00:23:01,634 --> 00:23:05,462
Then understand those components using the

364
00:23:05,516 --> 00:23:09,530
massive amount of learning or the data it's have make a

365
00:23:09,600 --> 00:23:13,354
story which makes sense. So that is the beauty of

366
00:23:13,392 --> 00:23:16,614
large language models. So here it's able to easily

367
00:23:16,662 --> 00:23:20,218
come up with the dependency list. So here's the example.

368
00:23:20,304 --> 00:23:23,982
Like when you are coming up with the dependency list, like you can change

369
00:23:24,036 --> 00:23:27,454
the model types. Now here if I'm not mistaken, I am

370
00:23:27,572 --> 00:23:31,534
using the model call command. So here my

371
00:23:31,572 --> 00:23:34,030
output is more accurate,

372
00:23:34,610 --> 00:23:38,994
or I would say it's kind of like very clear

373
00:23:39,112 --> 00:23:42,178
compared to the previous one. So it's a pro tip. So if you

374
00:23:42,184 --> 00:23:45,358
are using large language model, like ensure that you are using the

375
00:23:45,384 --> 00:23:48,520
right model and that will give you more accurate data.

376
00:23:49,530 --> 00:23:52,866
So moving on, next aspect is understanding

377
00:23:52,898 --> 00:23:56,278
the steady state of this application or the system.

378
00:23:56,444 --> 00:24:00,414
Here again, I'm using party rock. I have given the architecture diagram

379
00:24:00,482 --> 00:24:04,358
link and then I have asked to come up with the steady state definition.

380
00:24:04,454 --> 00:24:08,214
So what the party rock or the large language model is producing

381
00:24:08,262 --> 00:24:11,706
is it's providing the steady state definitions.

382
00:24:11,818 --> 00:24:15,486
So it's saying API gateway. The API gateway is available

383
00:24:15,588 --> 00:24:19,006
and return the correct response code, 200 code

384
00:24:19,108 --> 00:24:22,342
when OICP requests are sent to API.

385
00:24:22,506 --> 00:24:26,050
And likewise it's able to list all the steady state

386
00:24:26,120 --> 00:24:29,966
definitions. Example payment gateway, it says the payment gateway

387
00:24:29,998 --> 00:24:33,154
is available and successfully processing payment for

388
00:24:33,192 --> 00:24:36,774
charging sessions. So this is the steady state.

389
00:24:36,892 --> 00:24:40,898
So our generative AI is able to look at the architecture diagram

390
00:24:40,994 --> 00:24:44,150
and then define what is good mean without

391
00:24:44,220 --> 00:24:46,070
even human involved.

392
00:24:47,050 --> 00:24:50,150
So moving on, this is about hypothesis creation.

393
00:24:50,230 --> 00:24:53,686
So creation of what are the failure scenarios? Again, what I'm

394
00:24:53,718 --> 00:24:57,626
doing, I have given the architecture diagram link and I

395
00:24:57,648 --> 00:25:01,386
have asked generative AI model to generate the hypothesis

396
00:25:01,498 --> 00:25:05,594
so it's able to come up with a meaningful and relevant

397
00:25:05,722 --> 00:25:09,214
accurate hypothesis. So first one,

398
00:25:09,252 --> 00:25:12,506
it says if the OCPP handle goes down,

399
00:25:12,628 --> 00:25:16,370
electric vehicle charging station will not be able to start stop

400
00:25:16,440 --> 00:25:20,670
charging sessions, leading to inability to charge the vehicles.

401
00:25:20,830 --> 00:25:24,018
So likewise, if the billing system goes down,

402
00:25:24,104 --> 00:25:27,730
new charging sessions cannot be started, has authorization,

403
00:25:27,810 --> 00:25:31,474
and payments cannot be processed. So it's coming up with the failure

404
00:25:31,522 --> 00:25:34,534
scenarios and also potential impact. So as you

405
00:25:34,572 --> 00:25:38,722
see here, again, I am simply giving generative AI

406
00:25:38,786 --> 00:25:42,902
the architecture diagram and asking it to come up with this hypothesis.

407
00:25:43,046 --> 00:25:47,734
But probably you might already understood

408
00:25:47,782 --> 00:25:52,006
it. Now, I can improve this massively, not only architecture

409
00:25:52,038 --> 00:25:55,406
diagram, I can give the observability data,

410
00:25:55,508 --> 00:25:59,230
I can give the other services, I can give a live service map taken

411
00:25:59,300 --> 00:26:02,366
from an observability tool, and I can give a

412
00:26:02,388 --> 00:26:06,530
lot of data so that generative AI can improve its answers

413
00:26:07,350 --> 00:26:09,860
and then experiment design. So again,

414
00:26:10,630 --> 00:26:14,034
as I discussed, I'm giving the architecture diagram. I'm just

415
00:26:14,072 --> 00:26:17,150
asking generative AI to come up with the experiments.

416
00:26:17,230 --> 00:26:20,338
So if you can see, it's able to come up with hypothesis

417
00:26:20,434 --> 00:26:23,734
and steady state and even list the test case.

418
00:26:23,852 --> 00:26:27,990
So here it states test case, simulate a failure of CPP

419
00:26:28,070 --> 00:26:31,622
handle by powering off the server or disrupting the network

420
00:26:31,686 --> 00:26:35,514
connection to the OCPP handler. Observe the behavior of

421
00:26:35,552 --> 00:26:39,642
system and impact on EV charging process. So again,

422
00:26:39,696 --> 00:26:42,842
another test case, simulate a database

423
00:26:42,906 --> 00:26:47,162
disruption by stopping the database service or corrupting the database files.

424
00:26:47,306 --> 00:26:51,006
Observe if the charging stations can continue charging and if the

425
00:26:51,028 --> 00:26:54,558
charging stations data is accurately recorded and updated.

426
00:26:54,734 --> 00:26:58,114
Likewise, I mentioned to you, so generative AI is able

427
00:26:58,152 --> 00:27:02,286
to smartly come up with these experiments. So this is again helping

428
00:27:02,318 --> 00:27:07,974
us massively to cut down human involvement and

429
00:27:08,012 --> 00:27:11,986
moving on. Once you have the experiments, it's about understanding blast

430
00:27:12,018 --> 00:27:15,426
radius. I mentioned to you, when you are executing your chaos testing

431
00:27:15,458 --> 00:27:19,366
or experiments, you have to understand or have some understanding of

432
00:27:19,388 --> 00:27:23,126
the impact. So here again what I'm doing, I'm giving the architecture

433
00:27:23,158 --> 00:27:26,394
diagram so that generative AI can have a big

434
00:27:26,432 --> 00:27:30,298
picture. And then I'm giving a test case. Then I'm asking it

435
00:27:30,304 --> 00:27:33,914
to come up with the blast radius. So here it says this is a blast

436
00:27:33,962 --> 00:27:37,178
radius for the test case. So here we know it's going to impact

437
00:27:37,274 --> 00:27:39,934
OCPP handler, EV charging state,

438
00:27:40,052 --> 00:27:43,474
back end services and users. So this is

439
00:27:43,672 --> 00:27:47,090
massively advantage. So generative AI without

440
00:27:47,160 --> 00:27:50,500
even us involving able to come up with this kind of data.

441
00:27:51,510 --> 00:27:55,266
And as I said, now if you remember I used

442
00:27:55,448 --> 00:27:58,374
architecture diagram to get all this data.

443
00:27:58,492 --> 00:28:02,258
And probably you might think architecture diagrams are sometimes outdated

444
00:28:02,354 --> 00:28:05,798
and can we improve this? Of course, this is

445
00:28:05,804 --> 00:28:09,546
an example of a very simple application where

446
00:28:09,728 --> 00:28:13,718
service map was generated by Cloudwatch x ray

447
00:28:13,814 --> 00:28:17,130
where once the application is being used, so I know the client is there,

448
00:28:17,200 --> 00:28:20,066
API gates, microservices, my databases.

449
00:28:20,198 --> 00:28:25,054
So I can just feed in this diagram with

450
00:28:25,092 --> 00:28:28,462
the architecture diagram so that generative AI solution can

451
00:28:28,516 --> 00:28:32,142
compare what is in the architecture diagram and what are the services

452
00:28:32,276 --> 00:28:35,854
it in live or operations or in whatever the environments

453
00:28:35,902 --> 00:28:39,554
you have deployed this. So this will allow it to. So the

454
00:28:39,592 --> 00:28:42,946
more data, more accurate data, more information we

455
00:28:42,968 --> 00:28:46,726
are feeding into the chaos engineering or the generative AI tool which

456
00:28:46,748 --> 00:28:50,246
is going to do this. This will allow it to come up with more

457
00:28:50,268 --> 00:28:53,398
accurate answers. So next,

458
00:28:53,484 --> 00:28:56,930
so we quickly touch about this Ramsfield metrics.

459
00:28:57,010 --> 00:29:00,426
So this is about known known. So when you say non known, it's about

460
00:29:00,528 --> 00:29:04,294
evaluating components of your system that are familiar and thoroughly

461
00:29:04,342 --> 00:29:07,846
understood, such as system architecture, infrastructure,

462
00:29:07,958 --> 00:29:11,726
identified failure points, CI CD test, and then we have

463
00:29:11,748 --> 00:29:15,646
the known unknowns. And this is about investigating potential issues

464
00:29:15,748 --> 00:29:19,374
and vulnerabilities in your system that are known but

465
00:29:19,412 --> 00:29:22,470
haven't undergone rigorous testing or validation,

466
00:29:22,650 --> 00:29:26,350
such as theoretical vulnerabilities or unverified

467
00:29:26,430 --> 00:29:30,434
failure scenarios. So that is again a known unknown. And then

468
00:29:30,472 --> 00:29:34,514
we have the unknown knowns reviewing issues that are

469
00:29:34,712 --> 00:29:38,194
considered but may have been forgotten or overlooked

470
00:29:38,242 --> 00:29:41,842
with passing of time, such as adherent to best practices,

471
00:29:41,986 --> 00:29:45,810
documented procedures, or insights from historical incidents.

472
00:29:45,890 --> 00:29:49,794
So this is known as known unknowns, known unknown

473
00:29:49,842 --> 00:29:53,814
knowns. And finally, it's about unknown unknowns conducting

474
00:29:53,862 --> 00:29:58,422
comprehensive chaos testing to discover, foresee and anticipated vulnerabilities

475
00:29:58,486 --> 00:30:01,898
that may emerge unexpectedly, leading to

476
00:30:01,984 --> 00:30:05,722
surpassed or often unpleasant nature. So Ramsville field

477
00:30:05,776 --> 00:30:09,594
just gives kind of an approach where you can plan your chaos

478
00:30:09,642 --> 00:30:13,182
testing or when you are coming up. So what we can do is we

479
00:30:13,236 --> 00:30:17,234
can feed this data or approach or the framework of

480
00:30:17,272 --> 00:30:21,326
Ramsville metrics into our generative AI here. What I'm

481
00:30:21,358 --> 00:30:24,722
doing is I have given the architecture diagram, then I'm just saying,

482
00:30:24,776 --> 00:30:28,262
come up with the known known. Or I could have improved this thing by looking

483
00:30:28,316 --> 00:30:31,366
at this, come up with test cases or hypothesis to map to

484
00:30:31,388 --> 00:30:35,126
known known and moving on. I was able to do

485
00:30:35,148 --> 00:30:39,286
the same thing for known unknown as well. So I'm

486
00:30:39,318 --> 00:30:43,114
sure now you have that understood. We are able

487
00:30:43,152 --> 00:30:46,598
to use generative AI, every aspects

488
00:30:46,614 --> 00:30:49,866
of our chaos engineering workflow. We are able to

489
00:30:49,888 --> 00:30:53,318
use generative AI to discover our services, we can able

490
00:30:53,344 --> 00:30:57,482
to use it to understand the dependencies, we are able to use it to define

491
00:30:57,546 --> 00:31:00,846
steady state, we are able to use it to come

492
00:31:00,868 --> 00:31:04,146
up with our hypothesis, we are able to use it to come up with

493
00:31:04,248 --> 00:31:07,506
our test cases or the experiments. And then

494
00:31:07,528 --> 00:31:11,426
we are able to use it to come up with, what do

495
00:31:11,448 --> 00:31:15,010
you call after test cases? The blast radius.

496
00:31:16,630 --> 00:31:20,434
So those are the ingredients or the pieces of our chaos

497
00:31:20,482 --> 00:31:24,626
engineering workflow. So if you are looking at a typical CI CD

498
00:31:24,658 --> 00:31:28,662
pipeline, you have the developers coding and committing code, you will build it

499
00:31:28,716 --> 00:31:32,586
and you will deploy it for testing and probably you will do the deploy as

500
00:31:32,608 --> 00:31:36,202
well. And then you have the observability tools which if you are using

501
00:31:36,256 --> 00:31:38,774
AWS, you can leverage cloud matrix,

502
00:31:38,822 --> 00:31:42,766
cloud logs or x rays. And here we

503
00:31:42,788 --> 00:31:46,318
can plug our chaos engineering pipeline to here as well.

504
00:31:46,404 --> 00:31:49,946
So what this does is part of this pipeline, our chaos engineering

505
00:31:49,978 --> 00:31:53,886
pipeline can get invoked and then it will start triggering

506
00:31:53,918 --> 00:31:57,474
a workflow. So what this workflow is, this is

507
00:31:57,512 --> 00:32:01,438
what I call the smart chaos. This is about autonomous

508
00:32:01,534 --> 00:32:05,060
chaos Engineering. So what we are doing is first

509
00:32:06,070 --> 00:32:09,718
our generator AI will have access to the training data set.

510
00:32:09,804 --> 00:32:13,206
This about your architecture diagrams, this about your service

511
00:32:13,388 --> 00:32:17,442
maps, this about observability data, this about all the

512
00:32:17,516 --> 00:32:21,738
inputs which we can give it to generative AI to come up with the proper

513
00:32:21,824 --> 00:32:25,498
solution. Then it's able to

514
00:32:25,664 --> 00:32:29,354
come up with, I mean it will obviously come up with

515
00:32:29,392 --> 00:32:32,538
the defined steady state. It's able to come up understand

516
00:32:32,624 --> 00:32:36,010
the dependencies and it will come up with a hypothesis.

517
00:32:36,090 --> 00:32:39,258
And then based on that it will try to come up with some experiments.

518
00:32:39,354 --> 00:32:42,846
So what we want is when we are creating experiments, we want to

519
00:32:42,868 --> 00:32:46,354
create templates, small experiment templates, so that

520
00:32:46,392 --> 00:32:49,906
we can make it as a collection and reuse. So that is

521
00:32:50,008 --> 00:32:53,714
probably we can give already some of the templates like

522
00:32:53,752 --> 00:32:57,030
API failures or instance termination or system

523
00:32:57,100 --> 00:33:00,694
resource filling up and those things as

524
00:33:00,892 --> 00:33:04,600
the templates so that this workflow can use.

525
00:33:05,370 --> 00:33:09,194
Then this workflow can create these experiments and

526
00:33:09,232 --> 00:33:12,700
then start executing it. And then once

527
00:33:13,790 --> 00:33:17,766
the experiments have been executed, we are able to monitor

528
00:33:17,878 --> 00:33:21,962
using our observability tools, like we are able to monitor the observability

529
00:33:22,026 --> 00:33:25,742
data or the telemetry data. And we will start monitoring our service level

530
00:33:25,796 --> 00:33:29,374
objectives and the traffic saturation error and other

531
00:33:29,412 --> 00:33:33,102
things. So that is again will give more data

532
00:33:33,156 --> 00:33:36,674
points to this workflow. So what we have to do is

533
00:33:36,712 --> 00:33:40,494
we'll come up with a small blast radius and we'll ask the generative

534
00:33:40,542 --> 00:33:43,806
AI to use a small blast radius and then increase

535
00:33:43,838 --> 00:33:48,354
it in subsequent runs. So this is more of a very automated workflow

536
00:33:48,402 --> 00:33:52,338
where we are leveraging what I mentioned to you, right? Each stage

537
00:33:52,434 --> 00:33:55,938
I have shown you how we can use generative AI

538
00:33:56,034 --> 00:34:00,330
and now we are bringing it all together to come up with a proper workflow.

539
00:34:01,230 --> 00:34:05,114
And if you look at it how this can be actually look at

540
00:34:05,152 --> 00:34:08,726
in an actual production environment or a typical other environment.

541
00:34:08,838 --> 00:34:12,254
So you will have your DevOps and sres which are doing your

542
00:34:12,292 --> 00:34:16,106
changes. They will ship these changes using CI CD

543
00:34:16,138 --> 00:34:19,706
pipeline which will go and deploying into your different environments

544
00:34:19,818 --> 00:34:23,466
and parallel that we can trigger your smart chaos. And smart

545
00:34:23,498 --> 00:34:27,930
chaos is also integrated with observability, service level objectives, error budgets.

546
00:34:28,010 --> 00:34:31,298
And what smart chaos will do is it will try to pull up

547
00:34:31,384 --> 00:34:36,418
the observability tool and get the actual service

548
00:34:36,504 --> 00:34:40,194
maps, and then it can refer the knowledge it's having about the architecture

549
00:34:40,242 --> 00:34:44,066
diagrams and all the other diagrams, the logs and the metrics

550
00:34:44,098 --> 00:34:47,286
and traces and everything based on that, it will try to come

551
00:34:47,308 --> 00:34:51,094
up with what are the steady states, what are the dependencies?

552
00:34:51,222 --> 00:34:54,742
It will come up with hypothesis and it will design experiments.

553
00:34:54,806 --> 00:34:58,394
And based on after it design experiments, it will look

554
00:34:58,432 --> 00:35:02,202
at a library of templates, which we call experiment

555
00:35:02,266 --> 00:35:05,482
templates, and then combine those templates scripts.

556
00:35:05,546 --> 00:35:08,894
It can create the actual chaos workflows and then

557
00:35:08,932 --> 00:35:12,654
it will start pushing this into the relevant environments to run.

558
00:35:12,772 --> 00:35:16,194
While doing that it can start monitoring it and look at

559
00:35:16,312 --> 00:35:20,274
the telemetry data and improve, right? Obviously it will look at

560
00:35:20,472 --> 00:35:24,510
controlling the blast radius and then increasing in subsequent runs.

561
00:35:24,590 --> 00:35:28,246
So this is happening fully autonomous where we don't have to spend time,

562
00:35:28,348 --> 00:35:32,454
we don't have to get our peoples involved. We can let the

563
00:35:32,492 --> 00:35:35,894
generative AI learn about our application setup and

564
00:35:36,012 --> 00:35:39,674
everything and then build smart chaos or

565
00:35:39,712 --> 00:35:43,114
the chaos engineering automations for us. This I like

566
00:35:43,152 --> 00:35:46,906
to call autonomous chaos workflows. So with

567
00:35:46,928 --> 00:35:50,890
this, before I wrap up, so if you are seriously trying to get into this,

568
00:35:50,960 --> 00:35:54,862
I have a couple of best practices you have to consider. One thing is

569
00:35:54,996 --> 00:35:57,898
as like any other generative solutions,

570
00:35:57,994 --> 00:36:01,182
this smart chaos is depend on providing good

571
00:36:01,236 --> 00:36:05,218
quality data to our generative AI models. If you provide

572
00:36:05,304 --> 00:36:09,358
unclean data or data which might not be relevant,

573
00:36:09,454 --> 00:36:13,106
then your model will struggle. And then one

574
00:36:13,128 --> 00:36:17,154
of the best practices have a big template

575
00:36:17,202 --> 00:36:21,106
library ready with some of the small subunit

576
00:36:21,138 --> 00:36:24,950
of experiments. So this will allow our workflows to quickly

577
00:36:25,020 --> 00:36:28,710
use these templates, bundle it up and create one template.

578
00:36:28,870 --> 00:36:32,218
And other thing is that let the

579
00:36:32,384 --> 00:36:36,394
smart chaos expand gradually. Don't go into in a big

580
00:36:36,432 --> 00:36:40,646
bang way. I mean, that is always not the best or advisable thing.

581
00:36:40,768 --> 00:36:44,080
Let's do it in more of the control

582
00:36:44,450 --> 00:36:48,490
and way that we can expand.

583
00:36:48,650 --> 00:36:51,966
And one other thing is have the feedback loop, right? You can introduce some

584
00:36:51,988 --> 00:36:55,630
of these feedback loops so that generative AI can provide

585
00:36:55,700 --> 00:36:59,186
notifications and all those insights and runtime, you can look

586
00:36:59,208 --> 00:37:02,146
at how things are happening and then also based on that,

587
00:37:02,168 --> 00:37:04,980
you can fine tune some of these workflows as well.

588
00:37:05,990 --> 00:37:10,114
And what are the pitfalls to look at it? So one of the big pitfall

589
00:37:10,162 --> 00:37:13,846
is when you are looking at generative AI, sometimes we

590
00:37:13,868 --> 00:37:17,158
have seen there's a data bias. So you have to ensure that

591
00:37:17,244 --> 00:37:21,058
when you are providing this data, so the model will not

592
00:37:21,084 --> 00:37:24,662
go into a data bias situation. So here, when I say data bias,

593
00:37:24,726 --> 00:37:28,314
so example, it's about balancing the flaws, right? So it can

594
00:37:28,352 --> 00:37:32,150
identify some of the critical workflows and non critical workflows.

595
00:37:32,230 --> 00:37:35,754
So what we don't want the model to be is biased to the critical

596
00:37:35,802 --> 00:37:39,370
workflow where it will go and only look at the critical workflows.

597
00:37:39,450 --> 00:37:43,090
But then we want to have some kind of good

598
00:37:43,160 --> 00:37:46,306
cover of non critical workflows as well. And then

599
00:37:46,328 --> 00:37:49,534
we want this approach to expand

600
00:37:49,582 --> 00:37:53,022
in a controlled fashion, not avoid rapid chaos expansion,

601
00:37:53,086 --> 00:37:56,946
because that is

602
00:37:56,968 --> 00:38:00,386
not a recommended thing. And we want it to feed all the

603
00:38:00,408 --> 00:38:03,810
observable telemetry data and everything, so that experiments,

604
00:38:03,890 --> 00:38:07,654
monitoring, measuring, everything can be comprehensive, and then it can learn

605
00:38:07,692 --> 00:38:10,610
and iterative in a nice fashion. And finally,

606
00:38:10,700 --> 00:38:14,246
what I want to tell you is, even though this is a very good approach,

607
00:38:14,278 --> 00:38:18,780
and I'm pretty sure we are going to see this in happening real time,

608
00:38:21,470 --> 00:38:25,770
there's a need of human expertise. Don't eliminate your human

609
00:38:25,920 --> 00:38:29,086
completely, still roping him in.

610
00:38:29,268 --> 00:38:32,698
Start looking at the areas, try to look at the bigger picture,

611
00:38:32,794 --> 00:38:36,926
look at things from holistically, and then try to see how we can improve

612
00:38:36,958 --> 00:38:40,226
this in a holistic way with this.

613
00:38:40,328 --> 00:38:44,222
I'd like to finish my session. It was wonderful being part of Chaos

614
00:38:44,286 --> 00:38:48,430
Engineering 2024. I hope you enjoy my presentation

615
00:38:48,590 --> 00:38:52,518
and there are a lot of other presentations. Please go and check them as well.

616
00:38:52,604 --> 00:38:55,894
And I'm very much happy if you are still in and

617
00:38:55,932 --> 00:38:59,334
if you are listening, I'm privileged to be part of this.

618
00:38:59,452 --> 00:39:03,286
And I'm wishing and hoping that you have

619
00:39:03,308 --> 00:39:06,982
learned something which you can go back and used in your

620
00:39:07,036 --> 00:39:11,134
day to day work with that. This is nice, us doing this

621
00:39:11,172 --> 00:39:14,700
presentation. Thank you very much. Have a nice day.

