1
00:00:23,130 --> 00:00:26,742
Welcome to this session. Hope that you're enjoying the

2
00:00:26,796 --> 00:00:30,306
42 conference dedicated to observability.

3
00:00:30,498 --> 00:00:34,038
And thanks for joining my session. So what are

4
00:00:34,044 --> 00:00:37,654
we going to talk about? This session is all

5
00:00:37,692 --> 00:00:41,666
about open telemetry, but in a specific context,

6
00:00:41,858 --> 00:00:46,118
the even driven architecture. My name is

7
00:00:46,204 --> 00:00:51,226
Henrik Rexed. I'm a cloud native advocate within Dynatrace.

8
00:00:51,418 --> 00:00:55,246
And prior to Dynatrace I've been working 50 plus

9
00:00:55,348 --> 00:00:59,246
years as a performance engineer. Performance is pretty

10
00:00:59,268 --> 00:01:02,766
much still in my heart. So that's why I'm producing content for a

11
00:01:02,788 --> 00:01:06,494
YouTube channel podcast called Perf Bytes. So this is the icon

12
00:01:06,542 --> 00:01:10,226
with the red is perf bytes. And then one year, less than two years,

13
00:01:10,248 --> 00:01:14,158
I would say I've started a YouTube channel called is it observable?

14
00:01:14,254 --> 00:01:18,038
Where I try to provide content for anyone who

15
00:01:18,124 --> 00:01:21,400
wants to get started in the observery world.

16
00:01:21,930 --> 00:01:25,302
All right, so we're going to talk about in the next 20 or 30 minutes

17
00:01:25,356 --> 00:01:28,358
or so, a couple of things. So first,

18
00:01:28,444 --> 00:01:31,958
obviously you heard entitled opentelemetry. So we're

19
00:01:31,974 --> 00:01:35,894
going to obviously talk about opentelemetry. We look at the various components

20
00:01:35,942 --> 00:01:39,722
involved in open telemetry, how to produce traces, because today

21
00:01:39,776 --> 00:01:42,190
we're going to focus mainly on tracing.

22
00:01:42,770 --> 00:01:46,142
Then we're going to jump into our topic of today,

23
00:01:46,196 --> 00:01:50,014
which is event driven architecture, and see the various way

24
00:01:50,052 --> 00:01:53,082
of instrumenting your event driven architecture

25
00:01:53,146 --> 00:01:56,910
application. And of course you will see that we'll have some disadvantage.

26
00:01:56,990 --> 00:02:00,626
So that's why we're going to jump into spanlinks. We'll explain what is

27
00:02:00,648 --> 00:02:03,780
span links and how you can utilize them.

28
00:02:04,550 --> 00:02:08,262
So before we start, let me tell you a story.

29
00:02:08,396 --> 00:02:12,546
So when I was a kid, I really love to draw, to paint,

30
00:02:12,658 --> 00:02:16,626
to create basically content, and because my grandma

31
00:02:16,658 --> 00:02:20,714
and my mother teach me how to draw things. And it was pretty

32
00:02:20,752 --> 00:02:24,298
funny because when I started my first job,

33
00:02:24,384 --> 00:02:27,482
when I started in the industry, I was

34
00:02:27,536 --> 00:02:31,550
assigned into an engagement as a consultant.

35
00:02:32,210 --> 00:02:35,674
And at that time, in that technical environment,

36
00:02:35,802 --> 00:02:38,922
my manager, we were basically managing different servers,

37
00:02:38,986 --> 00:02:42,446
different applications. And my manager said, hey, we need

38
00:02:42,468 --> 00:02:45,710
to draw or we need to visualize the current behavior

39
00:02:45,790 --> 00:02:49,966
of our application. And that time we were having a couple of tools

40
00:02:49,998 --> 00:02:54,286
like top and mon and so on. Those tools

41
00:02:54,398 --> 00:02:58,114
are pretty much precise, but give you points. So with the help

42
00:02:58,152 --> 00:03:01,670
of those points, the only thing that was able to draw was this.

43
00:03:01,740 --> 00:03:05,046
So basically like a list of points so you can think

44
00:03:05,068 --> 00:03:08,780
about, it's very zoomed in, so like a pixel. So it's very hard to understand

45
00:03:09,550 --> 00:03:12,986
the entire context of our application. But with

46
00:03:13,008 --> 00:03:17,242
the tooling, I was able to do that. Then 20

47
00:03:17,296 --> 00:03:20,674
years ago we had improved our solution,

48
00:03:20,742 --> 00:03:24,400
so we were able to store data, so we have history,

49
00:03:25,010 --> 00:03:28,430
we were attaching the data that we were collecting with

50
00:03:28,500 --> 00:03:32,910
metadata coming from CMDB, for example. So we had more

51
00:03:32,980 --> 00:03:36,578
context. And because I was having stored points,

52
00:03:36,664 --> 00:03:39,906
I was able to draw lines. That's why I started to

53
00:03:39,928 --> 00:03:43,090
have a shape of the health of my web server.

54
00:03:43,430 --> 00:03:47,386
Then 13 years ago, the industry

55
00:03:47,438 --> 00:03:51,410
provided a couple of great product called APM application performance monitoring

56
00:03:51,490 --> 00:03:54,962
that was allowing us to provide other box. Distribute traces.

57
00:03:55,026 --> 00:03:57,942
Yes, distribute traces was there out there at that time,

58
00:03:58,076 --> 00:04:01,622
metrics. It was also having some synthetic monitoring,

59
00:04:01,686 --> 00:04:05,066
some real user monitoring and so on. So with this at least we

60
00:04:05,088 --> 00:04:08,620
had a better understanding. And so I was able to start

61
00:04:08,990 --> 00:04:12,134
drawing the eyes, the nose,

62
00:04:12,262 --> 00:04:16,094
the mouth of the actual server that I was trying to

63
00:04:16,132 --> 00:04:20,126
represent so much better. At least we still understand what

64
00:04:20,228 --> 00:04:23,966
we have here. Then ten years ago, because we

65
00:04:23,988 --> 00:04:27,202
were producing so much logs in our environment, we thought

66
00:04:27,256 --> 00:04:30,654
why don't we start utilizing them? So we were parsing the logs,

67
00:04:30,702 --> 00:04:33,826
indexing them, and try to get even more

68
00:04:33,928 --> 00:04:37,558
value out of all the effort that we were doing in

69
00:04:37,564 --> 00:04:40,886
terms of producing logs. So at the end we were

70
00:04:40,988 --> 00:04:44,198
better. That's why I'm having the arms now on the

71
00:04:44,204 --> 00:04:47,926
server. But still it's not perfect. Let me show

72
00:04:47,948 --> 00:04:51,562
you what I thought to draw

73
00:04:51,696 --> 00:04:55,814
and to show to the project. This is the actual drawing.

74
00:04:55,942 --> 00:04:59,434
So you can see that at least I had kid and

75
00:04:59,472 --> 00:05:03,114
the shape of the kid better, like a draft.

76
00:05:03,242 --> 00:05:06,446
And then the kid was basically in

77
00:05:06,468 --> 00:05:10,110
a forest or in a park or in a garden. So there was something

78
00:05:10,180 --> 00:05:14,062
surrounding the kid. So unfortunately

79
00:05:14,126 --> 00:05:17,586
with the toolings that I had, I was not able to basically

80
00:05:17,688 --> 00:05:21,506
draw what the current situations. So at

81
00:05:21,528 --> 00:05:25,266
the end, why I'm telling you that is because observability is not

82
00:05:25,288 --> 00:05:28,534
a science. Observability is like an art.

83
00:05:28,652 --> 00:05:32,518
You basically see things and then you start visualizing this.

84
00:05:32,604 --> 00:05:35,458
So you need a couple of tools like pencils,

85
00:05:35,634 --> 00:05:39,366
you need to have pastels, you need various colors. So let's

86
00:05:39,398 --> 00:05:43,322
jump into the various toolings that we have to basically build

87
00:05:43,376 --> 00:05:46,838
the art of observability. So what are the artistic

88
00:05:46,854 --> 00:05:50,662
tools? Well, as you know, observability is about understanding

89
00:05:50,726 --> 00:05:54,102
our current environment. So for that we need logs.

90
00:05:54,246 --> 00:05:57,706
We talked about it this couple of minutes ago. We need events. So events

91
00:05:57,738 --> 00:06:01,578
could be basically a system like kubernetes generates tons

92
00:06:01,594 --> 00:06:05,298
of events, but you also have events from

93
00:06:05,384 --> 00:06:08,466
your building, your pipelines, all the solution that

94
00:06:08,488 --> 00:06:12,098
basically make your solution going to production. So you have a lot of

95
00:06:12,184 --> 00:06:16,178
rich information that give even more context to the current situation.

96
00:06:16,344 --> 00:06:19,862
Then we have metrics, we used to that traces, we talked about it,

97
00:06:19,916 --> 00:06:23,526
and now you see that traces is becoming very popular. And then we

98
00:06:23,548 --> 00:06:27,094
have producing. So profiling is basically one of the signals, which is very

99
00:06:27,132 --> 00:06:30,826
powerful, because when you look at traces, you obviously want to go down to the

100
00:06:30,848 --> 00:06:33,180
code and profiling will help you to do so.

101
00:06:33,550 --> 00:06:36,554
But those pillars, those toolings are great,

102
00:06:36,672 --> 00:06:40,378
but you need to add context, because without

103
00:06:40,464 --> 00:06:43,966
context it doesn't make sense at all. So what are

104
00:06:43,988 --> 00:06:47,834
the context? We need the technology where it's been deployed,

105
00:06:47,882 --> 00:06:51,514
which server, the service, if it's a Kubernetes environment.

106
00:06:51,562 --> 00:06:55,714
So, deployment file, the namespace, the pod, the version number,

107
00:06:55,832 --> 00:06:59,166
very important, the geo, where is that server located,

108
00:06:59,198 --> 00:07:02,686
if you have multicloud deployments, maybe also the geo

109
00:07:02,718 --> 00:07:06,538
where this server is coming from. So at the end, the context is rich,

110
00:07:06,574 --> 00:07:10,946
because it will help you to correlate the data that you have been ingesting

111
00:07:10,978 --> 00:07:14,550
in your back end. But again,

112
00:07:14,700 --> 00:07:18,166
a natural reaction from the market. If you look around you,

113
00:07:18,268 --> 00:07:22,182
a lot of organizations and a lot of engineers

114
00:07:22,326 --> 00:07:26,054
have started to implement observability, but if you pay attention,

115
00:07:26,182 --> 00:07:29,942
they were using dedicated tools that were very specific for each signal.

116
00:07:30,006 --> 00:07:33,642
So for example, metrics, I'm going to store it in Prometheus for traces,

117
00:07:33,706 --> 00:07:37,178
probably Jaeger for logs, I want to use elasticsearch.

118
00:07:37,354 --> 00:07:40,798
So at the end we have observity, but everything

119
00:07:40,884 --> 00:07:44,726
is disconnected, so pretty much separated. So we are not efficient.

120
00:07:44,778 --> 00:07:48,066
So we need to stop doing this and

121
00:07:48,088 --> 00:07:51,726
we need to keep everything together. So then we are more efficient,

122
00:07:51,838 --> 00:07:54,980
especially when we need to troubleshoot, understand a given situation.

123
00:07:56,070 --> 00:07:59,190
So that's the purpose of the Opentelemetry project.

124
00:07:59,340 --> 00:08:02,790
The Opentelemetry project, for those who never heard, but it,

125
00:08:02,940 --> 00:08:06,694
Opentelemetry is an open standard, so it doesn't provide any

126
00:08:06,732 --> 00:08:10,502
storage, it doesn't provide you any software.

127
00:08:10,566 --> 00:08:14,858
It basically provides you libraries on helping you to build

128
00:08:15,024 --> 00:08:19,398
a standard format observatory. So standard format for distributed

129
00:08:19,414 --> 00:08:22,874
traces, standard format for metrics, for logs and so on.

130
00:08:22,912 --> 00:08:26,222
So at the end we will put something in our code,

131
00:08:26,276 --> 00:08:29,326
like an SDK. There's another component we'll talk about

132
00:08:29,348 --> 00:08:32,954
in a few seconds. And then with those SDK, we'll be able to produce auxiliary

133
00:08:33,002 --> 00:08:36,674
data. And that framework will add on top of that the

134
00:08:36,712 --> 00:08:40,334
metadata that we're looking for. So the semantic convention, so the server,

135
00:08:40,382 --> 00:08:43,940
the HP request, anything that we are related to our data.

136
00:08:44,470 --> 00:08:48,098
So if we want to summarize the Opentimi project in

137
00:08:48,104 --> 00:08:52,114
a very simple way, you have two things. You have the instruments of the SDK.

138
00:08:52,242 --> 00:08:56,246
So at the end I've got a guitar, I'm going to produce logs, metrics and

139
00:08:56,268 --> 00:08:59,686
traces, but I can play my guitar like this.

140
00:08:59,788 --> 00:09:03,594
But if I want to propagate my could or

141
00:09:03,632 --> 00:09:06,838
change the sound on the fly, I'm probably going to use an amplifier. So that's

142
00:09:06,854 --> 00:09:10,202
the collector. I will send my sound to

143
00:09:10,256 --> 00:09:14,042
the collector, I will be able to add some effects like chorus

144
00:09:14,106 --> 00:09:17,966
eventdriven, and then with the collector I'll be able to amplify the

145
00:09:17,988 --> 00:09:21,694
data to send it to any observer backend of our choice. And as

146
00:09:21,732 --> 00:09:25,326
you know, any amplifier you can have a second output, so you can send the

147
00:09:25,348 --> 00:09:28,370
data to several observed backend of our choice.

148
00:09:29,190 --> 00:09:32,734
At the moment, opentelemetry supports several type of signals,

149
00:09:32,782 --> 00:09:36,510
so the first one that has been initially supported was traces.

150
00:09:36,590 --> 00:09:40,758
So now it's stable in most of the language that we use today.

151
00:09:40,924 --> 00:09:44,966
Metrics is also stable for most of the language, except two of them,

152
00:09:45,148 --> 00:09:48,522
PHP and I don't remember the other one to be honest. And last,

153
00:09:48,576 --> 00:09:52,102
we have logs where it's under construction,

154
00:09:52,166 --> 00:09:55,402
so we should expect it probably in Q

155
00:09:55,456 --> 00:09:59,526
three or Q four of this year. Then we have continuous

156
00:09:59,558 --> 00:10:03,102
profiling, the specification is on the way, so we should not expect it until

157
00:10:03,156 --> 00:10:06,682
next year. So how do we produce traces?

158
00:10:06,746 --> 00:10:10,094
Because today we're going to focus mainly on traces, a couple

159
00:10:10,132 --> 00:10:13,662
of things. So first traces for this you

160
00:10:13,716 --> 00:10:17,258
will produce traces, you can do it in various way, but we

161
00:10:17,284 --> 00:10:21,026
will still need to add an SDK in our code. And there is

162
00:10:21,048 --> 00:10:24,434
two ways. The first approach is manual, so you can say, oh, manual sounds quite

163
00:10:24,472 --> 00:10:27,774
expensive, but if it's a fresh new application, it's similar to logging

164
00:10:27,822 --> 00:10:31,078
if you've been used to do logs, logging produced logs from

165
00:10:31,084 --> 00:10:34,166
out of the code, why don't you start producing traces out of your

166
00:10:34,188 --> 00:10:37,990
code? Similar journey, but we never start from there.

167
00:10:38,060 --> 00:10:41,654
Usually we start using the automatic and semi automatic

168
00:10:41,702 --> 00:10:44,934
instrumentation that will instrument our well known

169
00:10:44,982 --> 00:10:48,714
framework of the market. So for example, spring in Java will be

170
00:10:48,752 --> 00:10:52,126
fully instrumented. If you use Python, there is a

171
00:10:52,128 --> 00:10:56,234
lot of popular framework like Django that will be also instrumented.

172
00:10:56,282 --> 00:10:59,646
There is plenty of various examples for every language. So at

173
00:10:59,668 --> 00:11:03,194
the end, if you rely on a framework, there's a good chance that the traces

174
00:11:03,242 --> 00:11:06,946
that will be produced will be quite accurate for your use case. And at

175
00:11:06,968 --> 00:11:10,018
the end it will only produce data, but you will still need to send to

176
00:11:10,024 --> 00:11:12,690
an obliterate back end to store the data that you produce.

177
00:11:13,110 --> 00:11:16,674
So what is a trace? Good question. A traces is

178
00:11:16,712 --> 00:11:20,566
a transaction, so I'm making an action, I will save, for example,

179
00:11:20,668 --> 00:11:24,706
an order. So the save order will go through different components

180
00:11:24,738 --> 00:11:28,506
in my architecture and that will be the trace. So to make this saving

181
00:11:28,608 --> 00:11:32,326
order, it will go through different subtasks

182
00:11:32,438 --> 00:11:35,894
within my architecture, within my microservices.

183
00:11:36,022 --> 00:11:40,058
So I will have subtasks and those subtasks will be same

184
00:11:40,224 --> 00:11:43,694
spans. So at the end of traces, very simple,

185
00:11:43,812 --> 00:11:47,082
it's a big JSON array of spans.

186
00:11:47,146 --> 00:11:50,842
So it's a list of spans and everything. To make the traces,

187
00:11:50,906 --> 00:11:54,030
we will need a context. Context have the trace id

188
00:11:54,100 --> 00:11:57,346
and a span id. And basically with the help of the trace id, this is

189
00:11:57,368 --> 00:12:00,590
how we attach all the spans together to make a trace.

190
00:12:00,750 --> 00:12:03,938
So a span has different information, so the name,

191
00:12:04,104 --> 00:12:07,990
the attributes and so on. But we're not going to go too much into details.

192
00:12:08,650 --> 00:12:12,054
So if I want to build my traces in

193
00:12:12,092 --> 00:12:15,538
go or Java or node or whatever language,

194
00:12:15,634 --> 00:12:19,190
I will have a couple of objects that will be common

195
00:12:19,260 --> 00:12:23,210
to all of the SDK of opentelemetry. So first,

196
00:12:23,280 --> 00:12:27,402
if I want to build traces, I will add the opentelemetry API, no problem.

197
00:12:27,536 --> 00:12:30,694
From there I will be able to create one trace provider. So the trace

198
00:12:30,742 --> 00:12:33,738
provider is basically the component that will help me to build my traces.

199
00:12:33,834 --> 00:12:37,114
And you can see that there is various objects involved. So they have the span

200
00:12:37,162 --> 00:12:40,794
processor, the sampler, the exporter,

201
00:12:40,922 --> 00:12:44,186
opensource. So we will see those in details,

202
00:12:44,218 --> 00:12:47,458
but the span processor will help you to determine how you're going to

203
00:12:47,464 --> 00:12:50,546
send the data. Sampling is how much details we want to

204
00:12:50,568 --> 00:12:53,906
send, Explorer is where you're going to send the data and resource is

205
00:12:53,928 --> 00:12:57,374
the identity of service. And then we have a progator.

206
00:12:57,422 --> 00:13:00,646
We'll talk about it in a few seconds. Once we have defined this, we will

207
00:13:00,668 --> 00:13:04,310
be able to definitely create our spans and our child spans.

208
00:13:04,730 --> 00:13:08,422
So what is a resource mentioned? It's the identity of the service.

209
00:13:08,556 --> 00:13:12,230
So the resource is very critical because at the end,

210
00:13:12,300 --> 00:13:15,466
if you have a service cart service order, each of those services needs

211
00:13:15,488 --> 00:13:19,046
to have an identity. So then they will be basically displayed in the observy

212
00:13:19,078 --> 00:13:22,526
solution. So at the end you need a service name, you need

213
00:13:22,548 --> 00:13:26,074
service version. So a couple of things are required, but at least minimum

214
00:13:26,122 --> 00:13:28,922
is a service name tracing,

215
00:13:28,986 --> 00:13:33,246
sampling what it is? Well, we want to determine how

216
00:13:33,268 --> 00:13:36,510
much data we want to send to observe backet. Of course we can send 100%,

217
00:13:36,580 --> 00:13:40,350
but that will be quite expensive at the end. So we need to sample

218
00:13:40,430 --> 00:13:44,018
and decide how we want to sample. At the moment the opening project gives back,

219
00:13:44,104 --> 00:13:47,710
you have to configure the sampling decision by your own. So you have several

220
00:13:47,790 --> 00:13:50,982
sampling decisions available. You have always on. So 100%

221
00:13:51,116 --> 00:13:54,614
of the terms of data produced will be sent to the back end.

222
00:13:54,732 --> 00:13:58,258
You have always off, which is the opposite, nothing. Then you

223
00:13:58,284 --> 00:14:01,674
have parent base. Parent base is perfect when you are a dependency, like service b.

224
00:14:01,712 --> 00:14:05,580
For example, in this slide where I will define that

225
00:14:06,990 --> 00:14:10,618
only the information from service b coming

226
00:14:10,784 --> 00:14:14,234
involved in a global transaction will be sent to the user back

227
00:14:14,272 --> 00:14:17,678
end. Then you have trace id based ratio, where you define basically a

228
00:14:17,684 --> 00:14:20,894
ratio, how many percentage? I say 20%. 10% of my data

229
00:14:20,932 --> 00:14:23,934
will be sent to the back end. And then you have combination of both.

230
00:14:23,972 --> 00:14:27,250
So parent based, always on, parent based trace id

231
00:14:27,320 --> 00:14:30,946
ratio, parent based, always off and so on.

232
00:14:31,048 --> 00:14:34,674
So here in this example I have series A-B-C-D and e.

233
00:14:34,712 --> 00:14:38,218
And we're looking for an end to end trace. So the a have been configured

234
00:14:38,254 --> 00:14:41,638
with trace id ratio because it's the first endpoint and the other one,

235
00:14:41,724 --> 00:14:44,822
we configured it with the parent based trace id

236
00:14:44,876 --> 00:14:48,374
ratio. So it will send the data from a global transaction where

237
00:14:48,412 --> 00:14:52,154
they involved as a dependency. And we see that I've defined 20%

238
00:14:52,192 --> 00:14:55,546
for the service b, 50% of service c and so on. But you can see

239
00:14:55,568 --> 00:14:58,700
that the numbers here, it's very important

240
00:15:00,190 --> 00:15:04,042
how you configure the sampling decision because you can have more or less details.

241
00:15:04,106 --> 00:15:08,142
So in this example, if I take 1000 requests, out of these 1000

242
00:15:08,196 --> 00:15:12,026
requests I will have only one end to end trace

243
00:15:12,138 --> 00:15:15,586
from a to e, which is quite low. So you

244
00:15:15,608 --> 00:15:18,958
have to tweak and configure it properly to get the right details

245
00:15:18,974 --> 00:15:22,414
that you need. What is trace propagation? Trace propagation,

246
00:15:22,462 --> 00:15:26,174
very simple. It's basically how the context

247
00:15:26,222 --> 00:15:29,502
will be sent to our architecture.

248
00:15:29,566 --> 00:15:32,338
So if I'm the first service a, I'm starting the trace.

249
00:15:32,434 --> 00:15:35,526
So I have the context very easy, so I can push it to

250
00:15:35,548 --> 00:15:38,662
all the various code, because at the end it's the same code.

251
00:15:38,796 --> 00:15:41,926
I can keep the right context. But how can I make sure that the context

252
00:15:41,958 --> 00:15:45,386
will be sent over to service b and the trace will continue? Well,

253
00:15:45,408 --> 00:15:49,178
this is called propagation where basically we will inject the

254
00:15:49,264 --> 00:15:52,986
trace context into before in our HTTP request, for example

255
00:15:53,088 --> 00:15:56,506
in the case of an HTTP communication, and then we will extract

256
00:15:56,538 --> 00:15:59,520
in a service b. And then once we have the trace context, we can continue

257
00:15:59,970 --> 00:16:03,614
our trace. So now you know everything, let's have

258
00:16:03,652 --> 00:16:07,586
an example. So in a traditional microservice architecture, distribute traces is

259
00:16:07,608 --> 00:16:11,006
just fantastic because here you can see that I have an ingress controller,

260
00:16:11,038 --> 00:16:14,738
I got server services. So with this I will be able to keep track

261
00:16:14,824 --> 00:16:18,018
on all the tasks of a given transaction. And you have

262
00:16:18,024 --> 00:16:21,746
a very easy way to visualize this data. For example, here I have an HTTP

263
00:16:21,778 --> 00:16:25,282
request going through various services in architecture.

264
00:16:25,346 --> 00:16:29,218
So here I see that I have 25 milliseconds of this transaction.

265
00:16:29,314 --> 00:16:32,614
And if I want to optimize this transaction, I can clearly

266
00:16:32,662 --> 00:16:36,518
see that. Okay, so we can see that list recommendation takes 20 milliseconds.

267
00:16:36,614 --> 00:16:39,914
So if I want to optimize, I may probably want to

268
00:16:39,952 --> 00:16:43,210
optimize that specific functions. And also what I discover here,

269
00:16:43,280 --> 00:16:47,246
I could get product that is called 1234 times. So maybe there

270
00:16:47,268 --> 00:16:50,606
is a more efficient way of doing it to reduce again the footprint of

271
00:16:50,628 --> 00:16:53,070
this transaction. So fantastic.

272
00:16:53,830 --> 00:16:57,918
But you say, okay, great, but you're talking about microservices.

273
00:16:58,014 --> 00:17:01,198
What's the relationship with event driven architecture?

274
00:17:01,374 --> 00:17:05,534
Okay, be patient, I'm coming there. Well, for distributed

275
00:17:05,582 --> 00:17:09,366
tracing it's a but different, for example, you had a service, then I

276
00:17:09,388 --> 00:17:12,694
send my data to a broker or to a pub sub whatever, and then

277
00:17:12,732 --> 00:17:16,614
based on that pub sub, based on that event,

278
00:17:16,732 --> 00:17:20,506
a couple of different services will start. So there's two different ways of

279
00:17:20,528 --> 00:17:24,086
doing it. The first way is oh, let's do a big trace.

280
00:17:24,198 --> 00:17:28,106
So from the service close to the ingress, to all the services

281
00:17:28,208 --> 00:17:30,780
that is being triggered through that event.

282
00:17:31,790 --> 00:17:34,958
So I will have a big traces, and you will see that sometimes based on

283
00:17:34,964 --> 00:17:38,654
your architecture it makes sense, and sometimes it doesn't make sense.

284
00:17:38,852 --> 00:17:42,526
So let's have a look at the first example, the end

285
00:17:42,548 --> 00:17:46,114
to end trace I just referred, very simple. So here I

286
00:17:46,152 --> 00:17:49,934
prepared for this event a GitHub

287
00:17:49,982 --> 00:17:53,618
repo. So here's the link, so you can play around. So here I'm using a

288
00:17:53,624 --> 00:17:57,154
pub sub architecture hosted on

289
00:17:57,192 --> 00:18:00,786
solace, and I have the hotel demo, just to produce

290
00:18:00,818 --> 00:18:03,778
traces on the side. And then I have a demo, I have a publisher,

291
00:18:03,874 --> 00:18:07,158
and I have two consumers. One is on the

292
00:18:07,164 --> 00:18:10,746
rest and the other one in database. So let's have a look at how we

293
00:18:10,768 --> 00:18:14,490
can do that. What does it means in terms of coding?

294
00:18:15,070 --> 00:18:18,634
So first let's bring me the code of the

295
00:18:18,672 --> 00:18:22,682
publisher. So the publisher, nothing special. I'm going to look at the code here.

296
00:18:22,816 --> 00:18:26,586
So here you can see that we're using the Opentelemetry SDK like expected.

297
00:18:26,618 --> 00:18:30,570
We have a batch band processor. So every single things that I explained, the sampling

298
00:18:30,650 --> 00:18:33,886
is defined. So first here I can see that I'm defining an

299
00:18:33,908 --> 00:18:37,374
exporter. So it's going to use the standard exporter of opentelemetry.

300
00:18:37,502 --> 00:18:41,058
I'm using a batch band processor to determine how I'm going to send the

301
00:18:41,064 --> 00:18:44,286
data. So this basically with that I have a trace

302
00:18:44,318 --> 00:18:47,670
provider now, and with that traces provider I'm able to start

303
00:18:47,740 --> 00:18:51,794
creating spans, which I'm doing here, create span, start span.

304
00:18:51,922 --> 00:18:55,158
And as you can see here, I'm adding some attributes to

305
00:18:55,164 --> 00:18:58,534
give some details about this specific function,

306
00:18:58,652 --> 00:19:02,380
and then I will be able to attach the context. In the case of

307
00:19:02,750 --> 00:19:06,406
messaging, a couple of technologies support and the trace context

308
00:19:06,438 --> 00:19:09,642
will be passed properly. And in this particular example I'm using

309
00:19:09,696 --> 00:19:13,014
pub sub, so I don't have necessarily the SDK

310
00:19:13,062 --> 00:19:16,958
that does it automatically. So what I'm doing is I have a trace, once I

311
00:19:16,964 --> 00:19:19,870
have the trace, I'm getting the trace id and the span id.

312
00:19:19,940 --> 00:19:24,378
So then I'm sending it as a property of the message, which means the consumer

313
00:19:24,554 --> 00:19:27,986
will have to extract it as well. So now if we look at one of

314
00:19:28,008 --> 00:19:32,002
the example of the consumer, like the distressed consumer, same thing,

315
00:19:32,056 --> 00:19:35,634
we defined the traces provider, nothing special.

316
00:19:35,752 --> 00:19:39,714
And here you can see that from the message, I'm extracting the trace

317
00:19:39,762 --> 00:19:43,382
id and I'm extracting the span id. So once I have

318
00:19:43,436 --> 00:19:47,142
those, I am defining a new span context and

319
00:19:47,196 --> 00:19:50,426
I'm linking it and I'm restarting the child spans from

320
00:19:50,448 --> 00:19:54,090
there. So that's from the code perspective, but what does it represent

321
00:19:55,310 --> 00:19:59,100
in an actual traces example? So if I open

322
00:19:59,710 --> 00:20:03,214
my browser, I have

323
00:20:03,252 --> 00:20:06,510
it already displayed here. So first let me bring me

324
00:20:06,580 --> 00:20:09,790
to the services. So which means here I got a dynatrace services,

325
00:20:09,860 --> 00:20:13,326
I have different application running. And here you can see that I

326
00:20:13,348 --> 00:20:17,026
have first of all the consumer database, the consumer rests, those are the two things

327
00:20:17,128 --> 00:20:19,380
and the publisher. So those are the information.

328
00:20:20,230 --> 00:20:23,406
The three services I'm running. In my example, if I click on the publisher,

329
00:20:23,438 --> 00:20:27,410
I will have details about the actual services. But what I

330
00:20:27,480 --> 00:20:31,142
want to show you is the actual end to end traces. Remember I started

331
00:20:31,196 --> 00:20:34,406
traces, I send the context to the message and then the

332
00:20:34,428 --> 00:20:38,070
consumer extract the context and continue their task as well.

333
00:20:38,140 --> 00:20:41,862
So I can see here, now I have a big trace with the publisher

334
00:20:41,926 --> 00:20:45,962
sending the data, and then I get every single

335
00:20:46,016 --> 00:20:49,334
details, have the consumer rest and the consumer database.

336
00:20:49,462 --> 00:20:52,762
But the problem is, as you can see here, we have a four

337
00:20:52,816 --> 00:20:56,494
minutes transaction and four minutes in terms of open

338
00:20:56,532 --> 00:21:00,378
to me distribute trace is very difficult. So if I want to optimize the publisher,

339
00:21:00,394 --> 00:21:03,806
I have no idea because here it traces, then a

340
00:21:03,828 --> 00:21:06,846
couple of hundred milliseconds. So if I want to reduce the publisher,

341
00:21:06,878 --> 00:21:10,110
I'm not able to have the details because technically it's not visible.

342
00:21:10,270 --> 00:21:13,666
So it's not perfect. So that's why I think we

343
00:21:13,688 --> 00:21:15,540
should improve in a way,

344
00:21:18,150 --> 00:21:22,006
because it's not well designed for our example. So you can see this is

345
00:21:22,028 --> 00:21:25,538
what I was showing you. Is it a useful trace?

346
00:21:25,634 --> 00:21:28,774
The answer is, of course no. I may need to change

347
00:21:28,812 --> 00:21:32,298
the way we're doing it. And the great examples is my second example,

348
00:21:32,384 --> 00:21:36,134
using span links. So before we start with these second examples,

349
00:21:36,262 --> 00:21:39,386
what is a span link? Well, in the case where you

350
00:21:39,408 --> 00:21:43,440
have a long transaction, in our case was not two minutes, but four minutes,

351
00:21:43,810 --> 00:21:46,942
you can see that the black span, which is in the first one,

352
00:21:46,996 --> 00:21:50,446
is mainly not visible. So if

353
00:21:50,468 --> 00:21:54,058
I have this, I can basically start a traces and

354
00:21:54,084 --> 00:21:57,186
then use a span link. So then

355
00:21:57,288 --> 00:22:00,674
the consumer will start a new trace and

356
00:22:00,712 --> 00:22:04,942
link that trace to the publisher. So at the end I will have three traces

357
00:22:05,086 --> 00:22:08,230
with this implementation, one for the publisher,

358
00:22:08,570 --> 00:22:12,262
one for one of the consumers, and last

359
00:22:12,316 --> 00:22:15,634
one for the other consumers. So at the end I have three traces,

360
00:22:15,762 --> 00:22:18,886
much more easier to consume, much more easier to understand what's going

361
00:22:18,908 --> 00:22:22,890
on. So again, let's jump into the information. So I did a second

362
00:22:22,960 --> 00:22:26,490
version of this implementation where I changed slightly the code.

363
00:22:26,560 --> 00:22:30,202
So let me show you what I mean. So if we look at the code

364
00:22:30,256 --> 00:22:33,642
here, let me go back here I go to the other

365
00:22:33,696 --> 00:22:36,826
example where it's the same rest that I showed you. So the publisher,

366
00:22:36,858 --> 00:22:40,254
I didn't change it, it's still sending the trace context in the message. I still

367
00:22:40,292 --> 00:22:44,050
need to extract my trace context. So, trace id and spin id.

368
00:22:44,120 --> 00:22:47,620
And here I'm starting a traces, and here you can see that

369
00:22:49,590 --> 00:22:53,230
I'm tracing a link to the actual context

370
00:22:53,310 --> 00:22:56,866
of the publisher, and then I'm starting a new span, and here I'm

371
00:22:56,898 --> 00:23:00,326
attaching a link. So it means that the code is

372
00:23:00,348 --> 00:23:03,846
slightly different. But what does it mean in

373
00:23:03,868 --> 00:23:07,634
terms of ui, in your observable backend of your choice?

374
00:23:07,762 --> 00:23:11,226
Well, let's jump into dynatrace now I have another example

375
00:23:11,408 --> 00:23:15,306
where here, this is one of

376
00:23:15,328 --> 00:23:18,106
the example of the rest that I was showing you. And you can see that

377
00:23:18,128 --> 00:23:21,914
I have three steps, much more simpler to use it. But what is interesting here,

378
00:23:21,952 --> 00:23:24,574
if I pay attention to the first one,

379
00:23:24,772 --> 00:23:28,670
I have here links, and then with that link

380
00:23:28,820 --> 00:23:32,954
I can click on it and it will bring me back to the publisher

381
00:23:33,082 --> 00:23:37,402
trace. And you can see that I have 100 millisecond trace,

382
00:23:37,466 --> 00:23:41,010
much more easier. And here I can see that if I want to optimize it,

383
00:23:41,080 --> 00:23:44,786
obviously I need to optimize the connect pub sub, which could be very difficult,

384
00:23:44,888 --> 00:23:48,422
but at least I know where I'm spending most of my time

385
00:23:48,476 --> 00:23:51,174
on that specific steps. Okay,

386
00:23:51,292 --> 00:23:54,934
so now that we've seen that very

387
00:23:54,972 --> 00:23:58,618
important, let's jump into the conclusion. So first, pros and

388
00:23:58,624 --> 00:24:03,050
cons. So first, I would say using

389
00:24:03,120 --> 00:24:07,210
spannings is great because at least it keep track

390
00:24:07,280 --> 00:24:08,970
properly on the consumers.

391
00:24:12,210 --> 00:24:14,400
It's easier to visualize these things.

392
00:24:14,930 --> 00:24:18,090
But the major disadvantage that you lose,

393
00:24:18,170 --> 00:24:21,450
basically the connection between the consumer and the publisher, from the consumer

394
00:24:21,530 --> 00:24:25,486
to the publisher, it's very easy. I know that this consumer comes from that

395
00:24:25,508 --> 00:24:28,994
trace, no problem. But from the publisher, I have no idea how many

396
00:24:29,112 --> 00:24:32,514
consumers has been triggered through that message. So it's more

397
00:24:32,552 --> 00:24:36,050
difficult to get a better vision, a broader vision of these

398
00:24:36,120 --> 00:24:39,906
things. The other disadvantage I would say is sampling

399
00:24:39,938 --> 00:24:43,426
decisions. We mentioned of sampling here I got a publisher

400
00:24:43,458 --> 00:24:47,426
trace and then I have a consumer trace. If those are two different sampling decisions,

401
00:24:47,458 --> 00:24:51,286
I may lose details. Maybe I won't have the publisher trace

402
00:24:51,318 --> 00:24:55,130
anymore. Or maybe I won't have the consumer trace anymore. So again,

403
00:24:55,280 --> 00:24:58,998
it's not perfect, but it's easier to consume. So depending

404
00:24:59,014 --> 00:25:02,446
on, on your implementation, you will have to decide if you need an

405
00:25:02,468 --> 00:25:05,982
end to end trace or the user of spannings. That's why it's an art

406
00:25:06,036 --> 00:25:10,126
to do observability. So first,

407
00:25:10,308 --> 00:25:13,822
as a takeaway, make sure your code is agnostic because

408
00:25:13,876 --> 00:25:17,054
again, the idea, we don't want to use any vendor locked in. That's the concept

409
00:25:17,102 --> 00:25:20,386
and the culture of opentelemetry. Second thing, if you start

410
00:25:20,408 --> 00:25:24,306
doing observability with using opentelemetry, make sure you add the right context in your

411
00:25:24,328 --> 00:25:28,086
metrics, in your logs, in your traces. Otherwise you

412
00:25:28,108 --> 00:25:31,766
won't be efficient and again, be creative. Understand your

413
00:25:31,788 --> 00:25:35,906
system, design the right observability technique

414
00:25:36,098 --> 00:25:39,734
based on your application. All right, so just

415
00:25:39,772 --> 00:25:43,426
a small teaser of the YouTube channel isn't

416
00:25:43,458 --> 00:25:46,822
observable. There's plenty of content covering opentelemetry and other

417
00:25:46,876 --> 00:25:50,398
observability framework or agents. So check it out. It's a

418
00:25:50,404 --> 00:25:54,206
quite young channel, so by looking at it, it will help me to

419
00:25:54,228 --> 00:25:57,566
be more efficient in the way I'm producing new content.

420
00:25:57,748 --> 00:26:01,214
All right, so I hope you enjoyed that session that you learned some

421
00:26:01,252 --> 00:26:05,200
stuff, but if you have any questions, I will be very

422
00:26:05,810 --> 00:26:09,006
delighted and honored to answer to any of your questions.

423
00:26:09,188 --> 00:26:10,940
Thanks for watching, see you soon.

