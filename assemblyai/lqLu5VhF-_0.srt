1
00:00:27,250 --> 00:00:30,546
Hi everyone. Today we're going to talk about debugging node

2
00:00:30,578 --> 00:00:34,070
js applications in production with Lightrun.

3
00:00:35,050 --> 00:00:39,014
But first, a few things about me I was a consultant for over

4
00:00:39,052 --> 00:00:42,710
a decade. I worked at sun, founded a couple of companies,

5
00:00:42,860 --> 00:00:46,226
wrote a couple of books. I wrote a lot of open source

6
00:00:46,258 --> 00:00:50,150
code, and currently work as developer advocate for Lightrun.

7
00:00:50,530 --> 00:00:54,286
My email and Twitter accounts are listed here, so feel free to

8
00:00:54,308 --> 00:00:57,774
write to me. I have a new blog that talks about

9
00:00:57,812 --> 00:01:02,254
debugging and production issues at talktotheduck dev.

10
00:01:02,452 --> 00:01:06,114
It would be great if you check it out and let me know what you

11
00:01:06,152 --> 00:01:09,698
think. I want to put my heart out there.

12
00:01:09,784 --> 00:01:13,150
I love apms. They are absolutely wonderful.

13
00:01:13,310 --> 00:01:16,566
I'm old enough to remember a time where

14
00:01:16,668 --> 00:01:20,694
they weren't and weren't around and I'm just

15
00:01:20,732 --> 00:01:23,480
so happy that we moved past that.

16
00:01:24,890 --> 00:01:28,902
These is absolutely amazing. The dashboards

17
00:01:28,966 --> 00:01:32,810
and the details. You get these

18
00:01:32,880 --> 00:01:35,914
great dashboard with just everything you need.

19
00:01:36,032 --> 00:01:40,034
Amazing. We're truly at the golden age of monitoring

20
00:01:40,182 --> 00:01:43,534
hell. When I started, we used

21
00:01:43,572 --> 00:01:47,342
to literally monitor the server by kicking it and listening to see if the hard

22
00:01:47,396 --> 00:01:51,114
drive was spinning properly. These vendors

23
00:01:51,162 --> 00:01:54,606
provide amazing dashboards that let you see every stat

24
00:01:54,638 --> 00:01:58,066
that matters in your app. Monitoring is absolutely

25
00:01:58,168 --> 00:02:02,702
amazing. And if you don't use these tools on your production servers,

26
00:02:02,846 --> 00:02:07,026
well, you're missing out and you might have issues you're

27
00:02:07,058 --> 00:02:10,454
unaware of. In fact, a lot of these issues we run

28
00:02:10,492 --> 00:02:14,210
into start when we notice an anomaly in the dashboard.

29
00:02:14,370 --> 00:02:17,590
We see a spike in failures or something

30
00:02:17,660 --> 00:02:21,270
that performs a bit too slow. The APM

31
00:02:21,350 --> 00:02:25,146
is amazing in showing those hiccups, but this is where

32
00:02:25,168 --> 00:02:28,406
it stops. It can tell us that a web service performed

33
00:02:28,438 --> 00:02:32,446
badly or failed. It can't tell us why.

34
00:02:32,628 --> 00:02:36,286
It can't point at a line of code that

35
00:02:36,308 --> 00:02:39,934
we need. So let's stop for a second and talk about a

36
00:02:39,972 --> 00:02:44,226
different line altogether. This line on

37
00:02:44,248 --> 00:02:47,090
one side we have developers,

38
00:02:47,910 --> 00:02:51,810
on the other we have ops or DevOps.

39
00:02:52,230 --> 00:02:55,310
This is a line we've had for a long time.

40
00:02:55,480 --> 00:02:58,914
It's something we drew out of necessity because when developers

41
00:02:58,962 --> 00:03:02,520
were given access to production, well,

42
00:03:03,130 --> 00:03:06,354
I don't want to be too dramatic, but when developers

43
00:03:06,402 --> 00:03:10,380
got access to production, it didn't end well.

44
00:03:10,990 --> 00:03:14,380
This was literally the situation not too long ago.

45
00:03:14,990 --> 00:03:18,522
Yes, we had sysadmins, but the whole

46
00:03:18,576 --> 00:03:22,320
process used to be a mess. That was no good.

47
00:03:22,770 --> 00:03:26,842
But we need a better solution than this hard separation

48
00:03:26,906 --> 00:03:30,286
because the ops guys don't necessarily know how

49
00:03:30,308 --> 00:03:33,070
to solve the problems made by the developers.

50
00:03:33,910 --> 00:03:38,002
These know how to solve ops problems because

51
00:03:38,056 --> 00:03:41,060
this is really what those monitoring tools are all about.

52
00:03:41,430 --> 00:03:44,626
They're the bat signal. They come up and

53
00:03:44,728 --> 00:03:48,280
we're Batman or Batwoman or Bat person.

54
00:03:48,890 --> 00:03:52,230
All of us damn heroes in these cases,

55
00:03:52,730 --> 00:03:56,454
we step up to deal with the bugs and we're the last

56
00:03:56,492 --> 00:03:59,370
line of defense against their villainy.

57
00:04:00,110 --> 00:04:04,026
DevOps have enough of villains of their own

58
00:04:04,208 --> 00:04:07,962
that they need to deal with for this case.

59
00:04:08,096 --> 00:04:12,106
They need us, but, well, we're coder.

60
00:04:12,138 --> 00:04:15,822
But people, it's kind of the same thing, just without the six pack

61
00:04:15,876 --> 00:04:20,654
abs, too much baked goods. And in the company kitchen over

62
00:04:20,692 --> 00:04:24,378
here, coder Batman needs to know these the

63
00:04:24,404 --> 00:04:27,220
crime or bugs are happening in the code.

64
00:04:27,670 --> 00:04:32,370
So those dashboards, these point us in the general direction

65
00:04:34,230 --> 00:04:37,526
these the crime is, but not at

66
00:04:37,548 --> 00:04:41,350
the exact specific location where we need to fight crime.

67
00:04:42,090 --> 00:04:45,814
And here's where things get hard. We start digging into

68
00:04:45,852 --> 00:04:49,126
logs, trying to find the problem. The dashboard sent us into a

69
00:04:49,148 --> 00:04:53,238
general direction like performance problem or high error rates.

70
00:04:53,414 --> 00:04:56,762
But now we need to jump into logs and hope that we can

71
00:04:56,816 --> 00:05:00,306
find something there that will somehow explain the problem we're

72
00:05:00,358 --> 00:05:04,026
seeing. That's like going from a jet

73
00:05:04,058 --> 00:05:07,198
engine back to the Stone age tools. Now there are

74
00:05:07,204 --> 00:05:10,942
many log processing platforms that do amazing job at

75
00:05:10,996 --> 00:05:14,578
processing these logs and finding these gold within these.

76
00:05:14,744 --> 00:05:18,366
But even then it's a needle in a haystack. And that's

77
00:05:18,398 --> 00:05:22,082
the good outcome where a log is already

78
00:05:22,136 --> 00:05:26,034
there waiting for us. But obviously we can't have logging

79
00:05:26,082 --> 00:05:30,150
all over the place. Our billing would go through the roof and our performance will.

80
00:05:30,300 --> 00:05:34,290
Well, you know, we're stuck

81
00:05:34,450 --> 00:05:38,126
in these loop. Add a new log, go through CI

82
00:05:38,178 --> 00:05:42,186
CD which includes the QA cycle and everything. This can

83
00:05:42,208 --> 00:05:45,526
take hours. Then reproduce the issue in production

84
00:05:45,558 --> 00:05:49,046
server with your fingers crossed and try to analyze

85
00:05:49,078 --> 00:05:52,318
what went on. Hopefully you found the issue because

86
00:05:52,404 --> 00:05:55,822
if not, it's effectively rinse, repeat for the whole

87
00:05:55,876 --> 00:05:59,822
process. In the meantime, you still have a bug in production and

88
00:05:59,876 --> 00:06:03,122
developers are crashing their time. This is so

89
00:06:03,176 --> 00:06:06,702
bad. Some developers even advocate extreme solutions.

90
00:06:06,846 --> 00:06:10,354
Just build everything in these cloud as servers functions to

91
00:06:10,392 --> 00:06:14,130
avoid that inconsistency between local and remote environments.

92
00:06:14,710 --> 00:06:17,846
Gareth, who quoted this

93
00:06:18,028 --> 00:06:22,658
but a lot of faith in isolated unit tests for his functions.

94
00:06:22,834 --> 00:06:26,146
Having written a lot of code, I have very limited faith

95
00:06:26,178 --> 00:06:29,754
in my tests. Then there's the other

96
00:06:29,792 --> 00:06:32,874
extreme that sees even microservices as

97
00:06:32,912 --> 00:06:36,906
a way to get more money. I dont even need to ask Vlad what

98
00:06:36,928 --> 00:06:40,554
he thinks about lambda. My personal opinion on this is

99
00:06:40,592 --> 00:06:44,880
somewhere in the middle, but closer to Vlad, probably because I'm old.

100
00:06:45,250 --> 00:06:49,194
I do think we need microservices and serverless in the right circumstances,

101
00:06:49,242 --> 00:06:53,130
though. But regardless of your opinions here,

102
00:06:53,300 --> 00:06:57,454
debugging in production is a hard and risky

103
00:06:57,502 --> 00:06:59,970
process, even with fast deployments,

104
00:07:00,310 --> 00:07:03,780
especially if you have a team larger than one person.

105
00:07:04,150 --> 00:07:08,598
And Garth is correct when he says that production and local

106
00:07:08,764 --> 00:07:11,640
development can never be quite the same.

107
00:07:12,170 --> 00:07:16,274
There are just too many variables and too much noise. We can't

108
00:07:16,322 --> 00:07:19,750
possibly avoid production only bugs.

109
00:07:20,330 --> 00:07:23,594
There just has to be a better way. It's 2020

110
00:07:23,632 --> 00:07:26,986
ones, and logs are the way we solve bugs in these day

111
00:07:27,008 --> 00:07:30,978
and age. Don't get me wrong, I love logs, and today's

112
00:07:31,014 --> 00:07:35,360
logs are totally different from what we had even ten years ago.

113
00:07:36,050 --> 00:07:40,142
But you need to know about your problems in advance for a log to

114
00:07:40,196 --> 00:07:43,738
work. The problem is, I'm not clairvoyant.

115
00:07:43,914 --> 00:07:47,154
When I write code, I can't tell what bugs or

116
00:07:47,192 --> 00:07:51,006
problems the code will have before the code is written.

117
00:07:51,198 --> 00:07:54,494
I'm in the same boat as you are. The bug doesn't

118
00:07:54,542 --> 00:07:57,782
exist yet, so I'm faced with the dilemma of whether

119
00:07:57,836 --> 00:08:01,206
to log something. This is a bit like the

120
00:08:01,228 --> 00:08:04,854
dilemma of writing comments. Does it make the code look

121
00:08:04,892 --> 00:08:08,214
noisy and stupid, or will I find this

122
00:08:08,252 --> 00:08:12,202
useful at 02:00 a.m. When everything isn't working and I want to rip out

123
00:08:12,256 --> 00:08:16,246
a few strands of hair I still have left because of this damn

124
00:08:16,278 --> 00:08:20,254
production problem? I'm sure you've all been in that

125
00:08:20,292 --> 00:08:23,694
situation. I've been through it quite a lot.

126
00:08:23,732 --> 00:08:25,280
As you can see on my head.

127
00:08:26,450 --> 00:08:29,854
Debuggers are amazing. They let

128
00:08:29,892 --> 00:08:33,054
us set breakpoints, see callbacks, inspect variables,

129
00:08:33,102 --> 00:08:37,294
and more. If only we could do the same for production

130
00:08:37,342 --> 00:08:40,866
systems. But debuggers weren't designed for this.

131
00:08:41,048 --> 00:08:44,242
They're very insecure when debugging remotely. They can

132
00:08:44,296 --> 00:08:47,634
block your server while sending debug commands remotely.

133
00:08:47,762 --> 00:08:51,474
A small mistake, such as an expensive condition can literally

134
00:08:51,522 --> 00:08:55,346
destroy your server. I might be repeating an urban legend

135
00:08:55,378 --> 00:08:58,970
here, but 20 or so years ago I heard a story about a guy

136
00:08:59,120 --> 00:09:03,050
who was debugging a railed system located on a cliff.

137
00:09:03,390 --> 00:09:07,574
He stopped at a breakpoint during debugging, and the multimillion

138
00:09:07,622 --> 00:09:11,034
dollar hardware fell into the sea because it didn't

139
00:09:11,082 --> 00:09:14,782
receive the stop command. Again, I don't know if it's a true

140
00:09:14,836 --> 00:09:19,322
story, but it's plausible. Debuggers weren't

141
00:09:19,386 --> 00:09:21,870
really designed for those situations.

142
00:09:22,530 --> 00:09:26,226
Worse, debuggers are limited to one server. If you

143
00:09:26,248 --> 00:09:29,826
have a cluster with multiple machines, the problem can manifest on one

144
00:09:29,848 --> 00:09:32,862
machine always or might manifest on a random machine.

145
00:09:33,006 --> 00:09:35,010
We can't rely on pure luck.

146
00:09:36,010 --> 00:09:39,234
If I have multiple servers with multiple languages,

147
00:09:39,362 --> 00:09:42,834
platforms crossing from one to another with these debugger?

148
00:09:42,962 --> 00:09:45,910
Well it's possible in theory,

149
00:09:46,570 --> 00:09:49,370
but I can't even imagine it in reality.

150
00:09:50,270 --> 00:09:53,786
Let's take the Batman metaphor all the way. We need

151
00:09:53,808 --> 00:09:57,030
a team up. We need some help on the servers,

152
00:09:57,110 --> 00:10:01,354
especially in a clustered polyglot environment where the issues

153
00:10:01,552 --> 00:10:04,490
can appear on one server, move to the next, etc.

154
00:10:05,090 --> 00:10:08,606
So you remember these slide. We need some way to get

155
00:10:08,628 --> 00:10:12,190
through that line. We need a way to connect the server

156
00:10:12,530 --> 00:10:16,514
with these server and debug it. What if you could

157
00:10:16,552 --> 00:10:19,458
connect your servers to a debugger agent?

158
00:10:19,624 --> 00:10:23,250
That would make sure you dont overload the server and don't make

159
00:10:23,320 --> 00:10:27,158
a mistake, like setting a breakpoint or something like that.

160
00:10:27,324 --> 00:10:31,202
That's what Lightrun does. It lets you connect securely

161
00:10:31,266 --> 00:10:34,626
through your own server so you physically don't

162
00:10:34,658 --> 00:10:38,514
have access to production. That means that lovely

163
00:10:38,562 --> 00:10:41,698
line we have with DevOps is maintained.

164
00:10:41,874 --> 00:10:45,174
DevOps have their control and know you can't

165
00:10:45,222 --> 00:10:49,366
break production. Developers still get insight and can investigate

166
00:10:49,398 --> 00:10:52,350
an issue to avoid the redeploy cycle.

167
00:10:52,930 --> 00:10:57,002
There's a safety net in place protecting production

168
00:10:57,066 --> 00:11:00,510
from harm, intentional or otherwise.

169
00:11:01,410 --> 00:11:05,326
So how does this thing work? Well, we install the plugin

170
00:11:05,358 --> 00:11:08,478
in our IDE and it lets us interact

171
00:11:08,574 --> 00:11:12,318
with the lightrun server. We can insert an action

172
00:11:12,494 --> 00:11:16,274
which can be a log or a snapshot, which I'll show

173
00:11:16,312 --> 00:11:20,450
soon enough. Right now Lightrun supports Webstorm,

174
00:11:20,610 --> 00:11:24,386
intellij idea, etc. But there's a visual studio

175
00:11:24,418 --> 00:11:28,666
code plugin that will look very similar to what you're seeing here.

176
00:11:28,848 --> 00:11:32,586
It will launch soon. Notice there's also a

177
00:11:32,608 --> 00:11:36,854
command line option which I won't discuss here. The management

178
00:11:36,902 --> 00:11:40,366
server sends everything to the agent which is

179
00:11:40,388 --> 00:11:44,874
installed on your server. That means there's clean separation

180
00:11:45,002 --> 00:11:47,946
between developer and production.

181
00:11:48,138 --> 00:11:52,240
DevOps still has that guarding line we're talking about,

182
00:11:52,630 --> 00:11:56,594
and we don't have direct access to production. That means

183
00:11:56,712 --> 00:12:00,782
no danger to the running production servers from careless developers.

184
00:12:00,926 --> 00:12:05,140
Well, like myself. The agent

185
00:12:05,770 --> 00:12:09,414
is just a small runtime you add

186
00:12:09,452 --> 00:12:13,282
to your servers. It's very low overhead and it implements

187
00:12:13,346 --> 00:12:17,126
the debugging logic. Finally, everything is piped through

188
00:12:17,148 --> 00:12:20,714
the server back to your ide directly. So as a

189
00:12:20,752 --> 00:12:24,490
developer you can keep working in the IDE without

190
00:12:24,560 --> 00:12:27,882
leaving your comfort zone. So let's go over a simple

191
00:12:27,936 --> 00:12:31,100
hello world demo so we're all on the same page.

192
00:12:32,030 --> 00:12:35,854
This is a simple express typescript hello world app.

193
00:12:36,052 --> 00:12:38,910
It should be very familiar to anyone using nodejs.

194
00:12:39,570 --> 00:12:43,082
I opened it here in webstorm and I want to debug

195
00:12:43,226 --> 00:12:46,882
that app in the same way I would debug a real world app

196
00:12:46,936 --> 00:12:50,882
in production. To do that, we need to sign

197
00:12:50,936 --> 00:12:54,738
up on Lightrun.com and set up an agent and

198
00:12:54,904 --> 00:12:58,500
IDE plugin which will let us debug this application.

199
00:12:59,510 --> 00:13:03,158
Integrating lightrun requires two steps. The first

200
00:13:03,244 --> 00:13:06,630
is very easy. Just run NPM install

201
00:13:06,700 --> 00:13:10,170
Lightrun to add lightrun from NPM.

202
00:13:10,750 --> 00:13:14,218
The second stage is adding this code

203
00:13:14,384 --> 00:13:18,026
to the top of your main file. Notice that you

204
00:13:18,048 --> 00:13:21,750
need these custom code from Lightrun, which includes the correct lightrun

205
00:13:21,840 --> 00:13:26,014
secret value. Now we just log in from the

206
00:13:26,052 --> 00:13:29,680
Lightrun id plugin and we're in business.

207
00:13:31,010 --> 00:13:33,970
Back in Express TypeScript hello World app,

208
00:13:34,120 --> 00:13:38,002
we can add the code snippet to the top of the file and

209
00:13:38,056 --> 00:13:41,986
run the server. Here's the hello world

210
00:13:42,088 --> 00:13:45,474
demo running. Let's go to the code and add a

211
00:13:45,512 --> 00:13:49,314
snapshot for the main page request. These snapshot

212
00:13:49,362 --> 00:13:52,760
will be hit when we load the main page.

213
00:13:54,170 --> 00:13:57,774
Now let's add a log to the method covering

214
00:13:57,842 --> 00:14:01,530
the hello URL. This is injected without

215
00:14:01,600 --> 00:14:04,634
restarting the server or anything like that.

216
00:14:04,832 --> 00:14:08,346
A snapshot is like a breakpoint. It gives us the

217
00:14:08,368 --> 00:14:11,966
stacks, traces and variable values, but it doesn't stop the

218
00:14:11,988 --> 00:14:15,498
debugger in place. So a production server

219
00:14:15,594 --> 00:14:19,694
dont block on snapshot. The camera icon we

220
00:14:19,732 --> 00:14:23,362
see on the left is the line on which

221
00:14:23,416 --> 00:14:25,410
we set up the snapshot.

222
00:14:27,030 --> 00:14:30,354
Let's reload now back in the ide I

223
00:14:30,392 --> 00:14:32,740
can see the stacks trace popped up.

224
00:14:33,110 --> 00:14:36,426
We only have one method on these course stack, which isn't

225
00:14:36,478 --> 00:14:40,406
as valuable as usual, but we can see the variables and we

226
00:14:40,428 --> 00:14:43,080
can see that the stacks was hit.

227
00:14:44,010 --> 00:14:47,510
Let's go back to the browser and check the hello URL.

228
00:14:48,030 --> 00:14:50,620
Notice it printed world.

229
00:14:52,110 --> 00:14:56,006
Now in the ide we can see these new log we injected

230
00:14:56,118 --> 00:14:59,446
is instantly these. Notice the response

231
00:14:59,478 --> 00:15:03,534
in the code for world which is what we indeed saw

232
00:15:03,652 --> 00:15:07,630
in the browser. I want a better demo,

233
00:15:07,780 --> 00:15:11,354
but trying to run and explain a truly complex environment

234
00:15:11,402 --> 00:15:14,706
in a conference session will probably confuse all

235
00:15:14,728 --> 00:15:17,650
of us more than it will teach, myself included.

236
00:15:18,070 --> 00:15:21,300
So I'm doing a relatively simple demo

237
00:15:22,070 --> 00:15:26,180
in this app. All the front end logic is handled from the web

238
00:15:27,110 --> 00:15:30,674
to these start of the back end with node js

239
00:15:30,722 --> 00:15:34,390
and JavaScript. In the previous sample I showed off support

240
00:15:34,460 --> 00:15:38,140
for typescript, so using JavaScript here makes sense.

241
00:15:38,750 --> 00:15:42,474
Java is pretty common in the enterprise backend, so in this scenario that

242
00:15:42,512 --> 00:15:47,606
makes sense. We're storing the data using spring

243
00:15:47,638 --> 00:15:50,902
boot and the front end and the portion

244
00:15:50,966 --> 00:15:53,310
of the backend is done in node JS.

245
00:15:55,730 --> 00:15:59,582
So now that we got this out of the way, let's go to

246
00:15:59,636 --> 00:16:02,926
the simple to do app used by so many demos in the

247
00:16:02,948 --> 00:16:06,626
past. Now the funny thing is that I was going to

248
00:16:06,648 --> 00:16:10,594
demonstrate something completely different and ran into this

249
00:16:10,632 --> 00:16:13,170
bug by accident as I was working on the code.

250
00:16:13,320 --> 00:16:17,026
Well, opportunity knocks. I can't clear completed

251
00:16:17,058 --> 00:16:20,262
to do items in the app. Well,

252
00:16:20,396 --> 00:16:24,214
it's time to pull out the debugger and figure out what's going

253
00:16:24,252 --> 00:16:27,346
on. The only problem is that these

254
00:16:27,468 --> 00:16:31,526
are two servers running on remote containers in production.

255
00:16:31,718 --> 00:16:35,226
I can't just debug them. So let's look at

256
00:16:35,248 --> 00:16:38,700
the code and see if I can spot some problem.

257
00:16:39,950 --> 00:16:43,994
This is the method that implements clearcompleted in the node

258
00:16:44,042 --> 00:16:47,546
servers. I assume you all know how to debug the client,

259
00:16:47,578 --> 00:16:51,338
so I didn't really show that part. But even if we don't,

260
00:16:51,434 --> 00:16:54,802
the technique would instantly show if the problem

261
00:16:54,856 --> 00:16:58,638
is in these client or not. You'll notice

262
00:16:58,814 --> 00:17:02,530
that we don't have any logging here. That would have been really nice,

263
00:17:02,600 --> 00:17:05,570
but obviously we can put logs everywhere.

264
00:17:06,010 --> 00:17:09,174
Besides the huge cost of

265
00:17:09,212 --> 00:17:12,758
log at scale, these also costs and performance in the individual

266
00:17:12,844 --> 00:17:16,034
machine. So I'm not a huge fan

267
00:17:16,082 --> 00:17:20,086
of overlogging. So I already installed Lightrun

268
00:17:20,118 --> 00:17:23,446
on both servers here. I also have Lightrun

269
00:17:23,478 --> 00:17:27,142
installed in my IDE, so I can just add a snapshot

270
00:17:27,206 --> 00:17:30,170
to the method to see if it's even reached.

271
00:17:30,610 --> 00:17:34,122
As you may recall, a snapshot is like a breakpoint.

272
00:17:34,266 --> 00:17:37,742
It gives us stack track and these variable values, but it

273
00:17:37,796 --> 00:17:40,560
doesn't stop the debugger in place.

274
00:17:41,890 --> 00:17:45,042
But we also want to see the end

275
00:17:45,096 --> 00:17:49,026
of the method was if the end of the method was reached, did we

276
00:17:49,048 --> 00:17:52,820
return from this method? If only there was a log.

277
00:17:53,270 --> 00:17:56,390
Well, we can inject new logs in runtime.

278
00:17:56,810 --> 00:18:00,614
We can just add a new log and type in the details we want in

279
00:18:00,652 --> 00:18:04,678
that log and bam, we can see that log

280
00:18:04,844 --> 00:18:08,406
right here. The cool thing is that if you

281
00:18:08,428 --> 00:18:12,118
have built in logs, these log will be integrated

282
00:18:12,214 --> 00:18:16,010
with the rest of those logs so you can see it in context.

283
00:18:16,430 --> 00:18:20,102
In this case, I selected that the log will pipe

284
00:18:20,166 --> 00:18:23,614
into the IDE console too, which is more convenient for

285
00:18:23,652 --> 00:18:27,680
demos and quick tests. But when you do this in real life,

286
00:18:28,130 --> 00:18:31,166
viewing the log as if it was written in

287
00:18:31,188 --> 00:18:34,526
the code is a game changer

288
00:18:34,638 --> 00:18:38,146
that can literally save you millions. I know

289
00:18:38,248 --> 00:18:41,714
we say that about a lot of features, but the ability to

290
00:18:41,752 --> 00:18:45,686
see these things in context can seriously shorten the amount of

291
00:18:45,708 --> 00:18:48,962
time spent debugging. It also means you can eliminate

292
00:18:49,026 --> 00:18:52,662
a lot of your redundant debugging overhead and

293
00:18:52,716 --> 00:18:57,030
reduce your logs cloud storage cases significantly.

294
00:18:57,550 --> 00:19:01,274
The savings in a large company can be very

295
00:19:01,392 --> 00:19:05,526
significant. Now let's go back into the browser

296
00:19:05,638 --> 00:19:09,434
and press that dysfunctional button. Then go back into

297
00:19:09,472 --> 00:19:13,006
the ide and wait a couple of seconds for the

298
00:19:13,028 --> 00:19:15,440
whole loopback of events to reach us.

299
00:19:15,890 --> 00:19:19,534
Now we can see the snapshot was hit.

300
00:19:19,732 --> 00:19:22,826
That means the calls reached that method,

301
00:19:22,938 --> 00:19:26,100
which already eliminates a lot of potential problem.

302
00:19:26,950 --> 00:19:30,386
Now we can look in the stack trace on the

303
00:19:30,408 --> 00:19:34,002
left to see who invoked that method, or look within

304
00:19:34,056 --> 00:19:37,586
variables on the right to see if there is an interesting variable

305
00:19:37,698 --> 00:19:41,954
we missed. We should also check out the log console

306
00:19:42,082 --> 00:19:45,240
where we can see that the method reached the log line,

307
00:19:46,010 --> 00:19:49,306
so we didn't get an exception or some

308
00:19:49,328 --> 00:19:53,990
other problem. This is odd. Let's check the springboot

309
00:19:54,070 --> 00:19:57,814
servers. This is the Springboot

310
00:19:57,862 --> 00:20:01,982
server code. Notice this is Java code representing a

311
00:20:02,036 --> 00:20:05,546
rest request for the clear completed API.

312
00:20:05,738 --> 00:20:09,626
It deletes all the elements that are marked completed, then returns

313
00:20:09,658 --> 00:20:13,310
the to do items that remain. I want to add a log

314
00:20:13,380 --> 00:20:16,986
here just like I did in the node JS code, but in this case

315
00:20:17,028 --> 00:20:20,034
I'm going to do something a bit different. I'm going to add

316
00:20:20,072 --> 00:20:24,014
an expression to the log. I'm going to print out the number of items

317
00:20:24,062 --> 00:20:27,446
in the response variable, which is of type list.

318
00:20:27,548 --> 00:20:31,494
That means I'll literally invoke the size method on

319
00:20:31,532 --> 00:20:35,320
that object within the curly braces here.

320
00:20:36,090 --> 00:20:39,946
Notice you could do the same exact thing in these node JS project

321
00:20:40,048 --> 00:20:42,970
using JavaScript code for the expression.

322
00:20:43,550 --> 00:20:46,794
Now you might be thinking why not print the whole

323
00:20:46,832 --> 00:20:50,140
thing? Why not print the response object?

324
00:20:50,610 --> 00:20:53,360
Well, it won't work. Well,

325
00:20:53,810 --> 00:20:57,278
there are two reasons. First, it might output tools much text

326
00:20:57,364 --> 00:21:01,530
and get cropped. But the more important aspect is evaluation

327
00:21:01,610 --> 00:21:05,330
speed. When we're running in production environments,

328
00:21:05,990 --> 00:21:09,474
changes can be very dangerous. If we

329
00:21:09,512 --> 00:21:12,962
evaluate these expressions dynamically, it might take too much

330
00:21:13,016 --> 00:21:16,798
cpu and crashing our server. So lightrun limits the

331
00:21:16,824 --> 00:21:19,750
amount of operations you can do in an expression.

332
00:21:20,090 --> 00:21:24,182
If I'll print that list, Lightrun might just eliminate my log because

333
00:21:24,236 --> 00:21:27,866
of cpu usage. So the code here needs to

334
00:21:27,888 --> 00:21:29,690
be very efficient.

335
00:21:30,830 --> 00:21:34,074
So let's press ok to add the new

336
00:21:34,112 --> 00:21:37,702
log. We'll then go to the browser to trigger

337
00:21:37,766 --> 00:21:41,854
the event. I'll press clear completed again and

338
00:21:41,892 --> 00:21:45,486
then we'll go back to the server. Back in

339
00:21:45,508 --> 00:21:49,498
the servers we can see the log showing and that's weird.

340
00:21:49,674 --> 00:21:53,330
The API is showing that we're returning two elements.

341
00:21:53,670 --> 00:21:57,426
That doesn't make sense, but this is the core idea of

342
00:21:57,448 --> 00:22:01,010
debugging. Validate your assumptions.

343
00:22:02,310 --> 00:22:05,454
I don't get that. I want to check the values,

344
00:22:05,582 --> 00:22:09,414
so for that I need to edit the log entry and instead of

345
00:22:09,452 --> 00:22:12,966
listing the size of the list. I want to print out these content of the

346
00:22:12,988 --> 00:22:17,000
first element in the list using the got zero method call

347
00:22:17,850 --> 00:22:21,722
pressing ok deletes the current log and creates a new log

348
00:22:21,776 --> 00:22:25,034
object in its place. We now need

349
00:22:25,072 --> 00:22:29,020
to go back to the web and clear the completed elements again,

350
00:22:29,550 --> 00:22:33,440
and after a short wait the log prints out the result.

351
00:22:33,970 --> 00:22:36,830
It seems that this is the bug.

352
00:22:37,650 --> 00:22:41,386
Looking at the values for the object, it's obvious that the completed

353
00:22:41,418 --> 00:22:44,770
field is false on the servers. That's why

354
00:22:44,840 --> 00:22:48,178
it wasn't cleared. With that in hand,

355
00:22:48,344 --> 00:22:52,446
I looked at the code that toggles the completed field on the nodejs

356
00:22:52,558 --> 00:22:56,790
server and oops. It seems that

357
00:22:56,860 --> 00:23:00,726
code was never written. These completed field

358
00:23:00,828 --> 00:23:04,818
was only set on initialization. So that's

359
00:23:04,834 --> 00:23:08,566
the bug. That's very cool, but that's

360
00:23:08,598 --> 00:23:12,374
just one type of production problem. For a different production

361
00:23:12,422 --> 00:23:15,866
problem. Let's go back to the slides and look at ones

362
00:23:15,888 --> 00:23:19,178
of my first slides. This is

363
00:23:19,184 --> 00:23:22,954
the dashboard I found off of Google. It isn't mine,

364
00:23:23,082 --> 00:23:25,840
but you probably see a couple of interesting things here.

365
00:23:26,370 --> 00:23:29,486
I mean, what's this? What the

366
00:23:29,508 --> 00:23:33,374
hell happened here? If you use a dashboard, you probably see

367
00:23:33,412 --> 00:23:36,738
stuff like that all the time and ask yourself the exact

368
00:23:36,824 --> 00:23:40,206
same question. Now apms are pretty sweet.

369
00:23:40,318 --> 00:23:44,242
These will usually tell you which entry point caused a performance issue,

370
00:23:44,376 --> 00:23:47,814
which cpu worked too hard, where memory was used up,

371
00:23:47,932 --> 00:23:51,334
and all of those things. But what they won't tell

372
00:23:51,372 --> 00:23:55,000
you is which block of code took too long.

373
00:23:55,370 --> 00:23:59,034
Let's say we have an entry point that takes too long to

374
00:23:59,072 --> 00:24:01,500
perform. Now what?

375
00:24:02,430 --> 00:24:06,154
We need to review deep calls all over the place to

376
00:24:06,192 --> 00:24:09,610
try and pinpoint a specific operation.

377
00:24:10,130 --> 00:24:13,470
This might be something we can't reproduce locally.

378
00:24:13,970 --> 00:24:17,342
Let's go back into the IDE briefly and go over

379
00:24:17,396 --> 00:24:21,150
the options here in the metrics menu.

380
00:24:21,650 --> 00:24:25,578
We can add measurements that give us fine grained benchmarks

381
00:24:25,674 --> 00:24:29,426
on the code level. We can count the amount of time line of

382
00:24:29,448 --> 00:24:33,186
code times a line of code was hit. We can measure the duration of

383
00:24:33,208 --> 00:24:37,102
a block of code or a method. We can even add more complex

384
00:24:37,166 --> 00:24:40,886
metrics based on customer evaluation. The result

385
00:24:40,988 --> 00:24:44,386
of metrics can be periodically logged or piped

386
00:24:44,418 --> 00:24:48,178
into Prometheus statsD, etc. This provides

387
00:24:48,274 --> 00:24:51,942
that missing piece that we need to see beyond what the APM

388
00:24:52,006 --> 00:24:56,074
provides us. That way we won't spend ages optimizing the

389
00:24:56,112 --> 00:24:59,574
wrong area because the production information didn't include

390
00:24:59,622 --> 00:25:03,274
all of the lower level information. Please notice

391
00:25:03,322 --> 00:25:07,258
that at this moment measurements are only available for JVM languages,

392
00:25:07,434 --> 00:25:11,130
but they will be coming to nodejs and Python in the update.

393
00:25:11,210 --> 00:25:14,862
That's coming soon. In closing,

394
00:25:15,006 --> 00:25:18,626
I'd like to go over what we discussed here and a few things we

395
00:25:18,648 --> 00:25:22,046
didn't have time for. Lightrun supports JVM

396
00:25:22,078 --> 00:25:25,794
languages like Java, Kotlin, Scala, etc. It supports

397
00:25:25,842 --> 00:25:30,982
nodejs for both Javascript and typescript and

398
00:25:31,036 --> 00:25:34,470
Python, even complex stuff like airflow.

399
00:25:34,970 --> 00:25:38,950
When we add actions, conditions run within a sandbox

400
00:25:39,030 --> 00:25:42,586
so they don't take up cpu or crash the system.

401
00:25:42,768 --> 00:25:47,014
This all happens without networking, so something like a networking

402
00:25:47,062 --> 00:25:50,862
hiccup won't crash the server. Security is

403
00:25:50,916 --> 00:25:53,920
especially crucial with solutions like this.

404
00:25:54,370 --> 00:25:58,074
One of the core concepts is that the server

405
00:25:58,122 --> 00:26:01,454
queries information, not the other way around as

406
00:26:01,492 --> 00:26:04,850
you would see with solutions such as JDWP etc.

407
00:26:05,190 --> 00:26:08,546
This means operations are atomic and these server can

408
00:26:08,568 --> 00:26:12,530
be hidden behind firewalls even from the rest of the organization.

409
00:26:13,350 --> 00:26:16,894
PIi production lets us define conditions

410
00:26:16,942 --> 00:26:20,774
that would obscure patterns in the logs. So if a user could

411
00:26:20,812 --> 00:26:24,486
print out a credit card number by mistake, you can define a

412
00:26:24,508 --> 00:26:27,962
rule that would block that. This way the bad

413
00:26:28,016 --> 00:26:31,626
data won't make it into your logs and won't expose you

414
00:26:31,648 --> 00:26:34,934
to liability. Blacklisting bets us block

415
00:26:34,982 --> 00:26:38,570
specific classes, methods or files. This means

416
00:26:38,640 --> 00:26:42,074
you can block developers in your organization from debugging

417
00:26:42,122 --> 00:26:45,694
specific files. This means a developer won't be able

418
00:26:45,732 --> 00:26:48,910
to put a snapshot or a log

419
00:26:49,060 --> 00:26:52,606
in a place where a password, for instance, might be

420
00:26:52,628 --> 00:26:56,260
available to steal user credentials or stuff like that.

421
00:26:56,950 --> 00:27:00,814
Besides these sandbox, I'd also like to mention that Lightrun

422
00:27:00,862 --> 00:27:04,654
is very efficient and in our benchmarks has almost no runtime

423
00:27:04,702 --> 00:27:08,182
impact. When it isn't used, it has very small

424
00:27:08,236 --> 00:27:11,320
impact even with the multiple actions in place.

425
00:27:11,850 --> 00:27:15,846
Finally, Lightrun can be used from the cloud or using

426
00:27:15,948 --> 00:27:19,954
an on premise install. It works with any deployment

427
00:27:20,002 --> 00:27:24,082
you might have, whether cloud based, container based on premise,

428
00:27:24,146 --> 00:27:27,190
microservices, serverless, etc.

429
00:27:28,650 --> 00:27:32,750
Thanks for bearing with me. I hope you enjoyed the presentation.

430
00:27:33,170 --> 00:27:36,766
Please feel free to ask questions and also feel free to write to

431
00:27:36,788 --> 00:27:40,478
me. Also, please check out talktothoduct dev

432
00:27:40,564 --> 00:27:43,678
where I talk about debugging in depth. And check out

433
00:27:43,764 --> 00:27:47,486
lightrun.com which I think you guys will like a lot.

434
00:27:47,668 --> 00:27:51,454
If you have any questions, my email is listed here and I'll be happy

435
00:27:51,492 --> 00:27:53,100
to help. Thank you.

