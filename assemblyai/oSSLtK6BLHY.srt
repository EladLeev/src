1
00:00:27,490 --> 00:00:30,726
Hello, my name is Maria and I'm the developer advocate at

2
00:00:30,748 --> 00:00:34,722
Botkube. In today's session we'll be talking about Kubernetes

3
00:00:34,786 --> 00:00:38,214
troubleshooting demystified, and I'll be presenting your five best

4
00:00:38,252 --> 00:00:41,666
practices to level up your Kubernetes troubleshooting workflow.

5
00:00:41,858 --> 00:00:45,334
Just a little bit. About me my name is Maria, as I said

6
00:00:45,372 --> 00:00:49,046
before, and I'm a developer advocate at Cube shop and I work on

7
00:00:49,068 --> 00:00:52,506
the Botkube project. It I have a background in industrial

8
00:00:52,538 --> 00:00:56,186
systems engineering and I've also been working in developer

9
00:00:56,218 --> 00:00:59,200
relations in software and engineering for the past few years.

10
00:00:59,570 --> 00:01:02,030
I also have a really cute dog named Malcolm.

11
00:01:03,010 --> 00:01:06,782
To say that the Kubernetes space is complex is an understatement.

12
00:01:06,846 --> 00:01:09,906
There's a steep learning curve and on the left you

13
00:01:09,928 --> 00:01:13,218
can see that there are lots of

14
00:01:13,224 --> 00:01:16,962
tools to learn. So here is the map of the CNCF landscape

15
00:01:17,106 --> 00:01:20,614
and there are probably more tools that have been added since this

16
00:01:20,652 --> 00:01:24,760
picture has been created. But with Kubernetes you have to know about

17
00:01:25,770 --> 00:01:29,286
container orchestration, you have to know about configuration management,

18
00:01:29,398 --> 00:01:32,986
deployments and networking, all just to get your kubernetes up

19
00:01:33,008 --> 00:01:36,742
and running. Additionally, troubleshooting is challenges,

20
00:01:36,886 --> 00:01:40,534
especially in this hybrid world that we're living in.

21
00:01:40,672 --> 00:01:43,966
Being able to communicate effectively with your teammates is

22
00:01:43,988 --> 00:01:47,630
more difficult than ever, especially when you have teams across different

23
00:01:47,700 --> 00:01:51,722
time zones with different levels of Kubernetes expertise.

24
00:01:51,866 --> 00:01:55,140
And just being able to share context is very difficult.

25
00:01:55,670 --> 00:01:59,330
So what is Kubernetes troubleshooting? So in short,

26
00:01:59,400 --> 00:02:02,802
Kubernetes troubleshooting is a process of identifying and resolving issues

27
00:02:02,856 --> 00:02:06,274
in a Kubernetes cluster. So this means solving

28
00:02:06,322 --> 00:02:08,610
problems related to deployment,

29
00:02:08,770 --> 00:02:12,406
networking challenges, resource allocation and more in a

30
00:02:12,428 --> 00:02:16,002
timely manner. So here's an example of a Kubernetes

31
00:02:16,066 --> 00:02:19,686
troubleshooting scenario. This is the Ohm killed

32
00:02:19,718 --> 00:02:23,446
error, and this occurs when there's excess memory

33
00:02:23,558 --> 00:02:27,594
and Kubernetes will automatically terminate their

34
00:02:27,632 --> 00:02:30,954
pods. So first you need to identify the

35
00:02:30,992 --> 00:02:34,122
container or pod that was terminated. Secondly,

36
00:02:34,186 --> 00:02:38,426
you need to check memory usage of the container or pod.

37
00:02:38,618 --> 00:02:42,234
Then you have to look for any errors in the container or pod

38
00:02:42,282 --> 00:02:45,454
logs. Fourth, you need to update the container and pod

39
00:02:45,502 --> 00:02:49,326
image, and fifth, increase the memory limit for the container

40
00:02:49,358 --> 00:02:52,914
or the pod. So this is a five step process.

41
00:02:53,032 --> 00:02:56,354
And you might say, Maria, this is five steps. It's not that complicated.

42
00:02:56,482 --> 00:03:00,326
However, when you're finding the root cause of the issue, you have

43
00:03:00,348 --> 00:03:04,038
to go through multiple substeps in this five step process.

44
00:03:04,124 --> 00:03:08,826
So these five steps can take minutes

45
00:03:08,928 --> 00:03:12,202
or even hours or even days to solve if you don't have

46
00:03:12,256 --> 00:03:15,962
an efficient troubleshooting workflow and

47
00:03:16,016 --> 00:03:19,974
it gets even more challenges than when you add in multiple clusters.

48
00:03:20,102 --> 00:03:23,626
So in a large scale production environment, it's very difficult to identify

49
00:03:23,658 --> 00:03:26,782
the root cause of the issue. So if one cluster is having

50
00:03:26,836 --> 00:03:30,398
issues, how can you tell what is going on with

51
00:03:30,484 --> 00:03:33,966
each cluster? So how can you identify and diagnose

52
00:03:33,998 --> 00:03:38,414
your problems when your problems are distributed across multiple systems?

53
00:03:38,542 --> 00:03:41,714
Additionally, with multiple clusters, you're going to have multiple tools that you

54
00:03:41,752 --> 00:03:45,670
use for your observability, your monitoring and

55
00:03:45,820 --> 00:03:49,682
your resolution. And then being able to collaborate

56
00:03:49,746 --> 00:03:53,382
and assign responsibility just becomes more difficult the more

57
00:03:53,436 --> 00:03:56,920
complexity that you add in. So here are my five

58
00:03:57,450 --> 00:04:00,762
kubernetes troubleshooting best practices number one,

59
00:04:00,896 --> 00:04:03,770
you want to centralize your monitoring and observability.

60
00:04:04,430 --> 00:04:08,154
This means you want to put all of your information into one place

61
00:04:08,272 --> 00:04:12,206
where everybody can have a shared context and a source of

62
00:04:12,228 --> 00:04:15,390
truth to be able to act on the error.

63
00:04:15,810 --> 00:04:19,018
Second, you want to have proper incident response

64
00:04:19,034 --> 00:04:22,814
and collaboration. So what you need to do is have some

65
00:04:22,852 --> 00:04:26,382
sort of avenue

66
00:04:26,446 --> 00:04:30,674
to be able to have your incident response and collaboration in one place so

67
00:04:30,712 --> 00:04:34,526
they're not in two separate channels and you can have everything in one streamlined

68
00:04:34,558 --> 00:04:37,682
place. Third, you want to have establish a feedback loop.

69
00:04:37,746 --> 00:04:41,542
So this means keeping track of all of your insights from

70
00:04:41,596 --> 00:04:45,602
previous incidents and errors so you can have more insights

71
00:04:45,666 --> 00:04:49,178
on what's going on in your system. Fourth, you want to be able

72
00:04:49,184 --> 00:04:53,638
to streamline your command execution so as you scale to avoid redundancy,

73
00:04:53,734 --> 00:04:57,146
you want to be able to make a

74
00:04:57,168 --> 00:04:59,690
single command across multiple clusters.

75
00:05:00,350 --> 00:05:04,462
And fifth, we want to be able to automate your observability and

76
00:05:04,516 --> 00:05:08,238
delivery process. So automation is key when it covers to

77
00:05:08,404 --> 00:05:12,078
efficiency. So what is Botkube and

78
00:05:12,084 --> 00:05:15,070
how does it help teams follow troubleshooting best practices?

79
00:05:15,650 --> 00:05:19,700
Botcube is an open source collaboration Kubernetes troubleshooting tool.

80
00:05:20,070 --> 00:05:23,780
This means you're able to monitor and troubleshoot your events in the same platform.

81
00:05:24,390 --> 00:05:27,750
So this means instead of having to screen,

82
00:05:27,820 --> 00:05:31,602
share or hop on a meeting to solve an error,

83
00:05:31,666 --> 00:05:35,158
you're able to solve everything in your

84
00:05:35,324 --> 00:05:39,542
chosen platform. And today we'll be talking about how Botkube works well with

85
00:05:39,596 --> 00:05:43,334
Microsoft Teams and Azure. And then with

86
00:05:43,372 --> 00:05:48,134
Botkube you're able to improve your developer experience, because nowadays

87
00:05:48,182 --> 00:05:51,994
if you're a developer working with kubernetes, you're almost forced to be kubernetes

88
00:05:52,042 --> 00:05:55,786
expert just to know the status of your applications.

89
00:05:55,818 --> 00:06:00,240
But with Botcube you're able to get self service access to your resources without

90
00:06:00,770 --> 00:06:04,190
having to deal with the knowledge gap. And finally,

91
00:06:04,260 --> 00:06:08,350
because Botkube can easily connect in with any of your communication platform tools,

92
00:06:08,430 --> 00:06:11,698
you're able to use Botkube from a mobile device, meaning that

93
00:06:11,704 --> 00:06:15,730
you can use Botkube on the go. So just a quick overview.

94
00:06:15,890 --> 00:06:18,834
Botcube works with Slack, Microsoft Teams,

95
00:06:18,882 --> 00:06:22,162
Discord and Mattermost and currently you can monitor

96
00:06:22,226 --> 00:06:25,714
your kubernetes events via

97
00:06:25,762 --> 00:06:28,954
kubernetes events and Prometheus. And we

98
00:06:28,992 --> 00:06:32,826
also have more plugin system where we

99
00:06:32,848 --> 00:06:36,262
have more sources

100
00:06:36,326 --> 00:06:39,846
where you can link Botcube to. Additionally,

101
00:06:39,878 --> 00:06:43,034
you can control your kubernetes, so act on those events

102
00:06:43,082 --> 00:06:46,986
with Kubectl and hem. And secondly,

103
00:06:47,178 --> 00:06:50,298
you can automate your event responses with Botcube's

104
00:06:50,314 --> 00:06:53,678
actions and you can extend Botcube to

105
00:06:53,684 --> 00:06:57,326
any source executor via the plugin system I mentioned before. And via

106
00:06:57,358 --> 00:07:01,486
the BotKube web hosted app, you're able to audit your events and commands

107
00:07:01,678 --> 00:07:05,006
from all of your clusters. And in that web hosted app it's

108
00:07:05,038 --> 00:07:09,110
easier to manage your botkube installation and configuration for all of your clusters.

109
00:07:09,530 --> 00:07:11,910
So back to our best practices.

110
00:07:12,490 --> 00:07:16,086
So empowering observability with Bachube and

111
00:07:16,108 --> 00:07:19,466
you see an example right here. You're able to receive your

112
00:07:19,488 --> 00:07:22,860
real time updates in your communication platform

113
00:07:23,550 --> 00:07:26,986
and you can get your changes about your

114
00:07:27,008 --> 00:07:29,980
new resources or updates that happen to your system.

115
00:07:30,430 --> 00:07:34,750
And with Bachube it's very easy to create channels

116
00:07:35,650 --> 00:07:39,280
and separate the information that you get. So for example,

117
00:07:39,810 --> 00:07:42,846
the front end developer channel does not

118
00:07:42,868 --> 00:07:46,530
need to have all of the Kubernetes alerts that you get

119
00:07:46,680 --> 00:07:50,034
versus a platform engineering channel that should have all the

120
00:07:50,072 --> 00:07:53,570
access to the need to everything that's going on in the cluster.

121
00:07:53,990 --> 00:07:57,030
Secondly, incident response and collaboration.

122
00:07:57,370 --> 00:08:00,790
So you can see this GIF, the team is

123
00:08:00,860 --> 00:08:04,614
reacting to an error that occurs and they're able

124
00:08:04,652 --> 00:08:08,678
to run a command right in the communication platform

125
00:08:08,764 --> 00:08:13,558
that they're using. So you're able to not only receive alerts,

126
00:08:13,574 --> 00:08:16,714
but you're also getting context about what's happening. You get logs of what you're doing,

127
00:08:16,752 --> 00:08:19,974
you're able to filter those logs and you're also able just

128
00:08:20,032 --> 00:08:23,854
to have a history of events that is right in your

129
00:08:23,892 --> 00:08:25,630
communication platform of choice.

130
00:08:27,090 --> 00:08:30,506
And third, establishing a feedback loop.

131
00:08:30,538 --> 00:08:34,066
So this is an example of audit log that you'd be able to access with

132
00:08:34,088 --> 00:08:37,570
the Botcube web hosted app. So you're able to

133
00:08:37,640 --> 00:08:41,374
get insights about your team's performance

134
00:08:41,422 --> 00:08:45,774
and potential issues. So if you notice that certain developers

135
00:08:45,822 --> 00:08:49,254
on your team are the ones who ran the last

136
00:08:49,292 --> 00:08:52,854
command before something goes down, you're able to get performance insights on what's going on

137
00:08:52,892 --> 00:08:56,530
with your team. And as an industrial engineer,

138
00:08:56,610 --> 00:09:00,214
I believe in continuous improvement, and you can't have continuous improvement

139
00:09:00,262 --> 00:09:04,026
without having data to back it up. So this autolog is

140
00:09:04,048 --> 00:09:08,154
your source of truth to be able to make changes to

141
00:09:08,192 --> 00:09:12,174
improve your system. And next

142
00:09:12,212 --> 00:09:15,840
we have streamlining command execution. So here you see

143
00:09:16,690 --> 00:09:20,750
the botkube. You're able to change

144
00:09:20,820 --> 00:09:24,882
your namespace, you're able to change the cluster and be able

145
00:09:24,936 --> 00:09:28,094
to run commands across multiple clusters.

146
00:09:28,222 --> 00:09:31,970
So this allows you to scale

147
00:09:32,470 --> 00:09:35,640
fairly easy, fairly easily and fairly quickly.

148
00:09:36,090 --> 00:09:40,242
And you're also able to give non Kubernetes

149
00:09:40,306 --> 00:09:44,214
experts access to the ability to run

150
00:09:44,332 --> 00:09:48,534
Kubernetes commands or helm commands or any executor

151
00:09:48,582 --> 00:09:52,538
that you choose fairly easily and

152
00:09:52,624 --> 00:09:54,940
very quickly within the communication platform.

153
00:09:56,270 --> 00:09:59,786
And finally, you want to be able to streamline your automation and

154
00:09:59,808 --> 00:10:03,354
developer empowerment. So here's an example of an automation

155
00:10:03,402 --> 00:10:07,706
with Botkube. So this automation runs automatically

156
00:10:07,738 --> 00:10:10,990
every time there's an error. So this automation is to run

157
00:10:11,060 --> 00:10:14,786
the Kubecontrol logs function.

158
00:10:14,888 --> 00:10:18,942
So instead of having to repeatedly write kubectl

159
00:10:19,006 --> 00:10:22,386
logs over and over again when you receive an

160
00:10:22,408 --> 00:10:26,214
error, Bachube does that for you. And you're able to

161
00:10:26,412 --> 00:10:30,146
reduce the amount of time in your troubleshooting workflow.

162
00:10:30,338 --> 00:10:33,558
So this scales really well. So you're able to

163
00:10:33,724 --> 00:10:36,630
work with different tools across the cloud,

164
00:10:36,700 --> 00:10:41,222
native landscape. So you can use this with Prometheus,

165
00:10:41,286 --> 00:10:45,274
you can use this with Argo CD, Flux CD and

166
00:10:45,312 --> 00:10:49,740
many more, and you can reduce your time well

167
00:10:50,210 --> 00:10:54,234
in your troubleshooting workflow. So here is a new improved

168
00:10:54,282 --> 00:10:57,338
Kubernetes troubleshooting workflow with BAQ.

169
00:10:57,514 --> 00:11:01,118
So with the automations in place

170
00:11:01,284 --> 00:11:05,410
and the alerting in place, you're able to reduce your

171
00:11:05,480 --> 00:11:08,420
five step process into a two step process.

172
00:11:09,190 --> 00:11:12,690
So as you know, with scale,

173
00:11:13,110 --> 00:11:16,806
this will scale really well. So imagine you being able to

174
00:11:16,828 --> 00:11:20,022
reduce your troubleshooting time by 30

175
00:11:20,076 --> 00:11:23,254
40% and then scaling that across all of your

176
00:11:23,292 --> 00:11:27,142
clusters that you work with. So this will allow

177
00:11:27,196 --> 00:11:30,358
your teams to work more efficiently and quicker

178
00:11:30,454 --> 00:11:33,642
and be able to work on the more important stuff

179
00:11:33,696 --> 00:11:37,370
besides debugging errors. So in conclusion,

180
00:11:37,790 --> 00:11:41,094
a strategic approach to Kubernetes troubleshooting is vital

181
00:11:41,142 --> 00:11:44,814
for multiculture environments. And as we

182
00:11:44,852 --> 00:11:48,094
know, complexity and scale is becoming more and

183
00:11:48,132 --> 00:11:52,046
more important as we go on. So it's very important to have

184
00:11:52,068 --> 00:11:55,694
a very calculated and targeted approach to kubernetes

185
00:11:55,742 --> 00:11:59,026
troubleshooting, and not just sort of have an ad

186
00:11:59,048 --> 00:12:02,414
hoc way of dealing with errors. And by following

187
00:12:02,462 --> 00:12:07,526
the best practices aligned that

188
00:12:07,548 --> 00:12:11,526
I've talked about before. You will be able to take

189
00:12:11,548 --> 00:12:15,270
your kubernetes troubleshooting to the next level, and finally,

190
00:12:15,420 --> 00:12:19,062
integrating solutions like Botkube will be able to enhance your efficiency

191
00:12:19,126 --> 00:12:22,090
and reliability across all your kubernetes clusters.

192
00:12:22,910 --> 00:12:26,154
So just quickly, how to get started with Bachube it's very

193
00:12:26,192 --> 00:12:29,690
easy. You can either install

194
00:12:29,760 --> 00:12:33,726
Bachube via the web hosted app, or you can go

195
00:12:33,748 --> 00:12:37,786
to our GitHub and install the manual way in your cluster

196
00:12:37,818 --> 00:12:42,106
with helm. And it's very easy to configure

197
00:12:42,138 --> 00:12:46,126
it to whatever you're working with via

198
00:12:46,158 --> 00:12:49,790
our web hosted app. And I will show you how to get configured

199
00:12:49,870 --> 00:12:53,230
with Botkube and teams and aks

200
00:12:53,390 --> 00:12:56,820
in a moment. So here is the demo,

201
00:12:57,270 --> 00:13:01,254
the botkube dashboard. But first you would just get

202
00:13:01,292 --> 00:13:04,742
here by just going to the botcube website, and then next you'd click sign

203
00:13:04,796 --> 00:13:08,150
in, get all your login information, et cetera, et cetera.

204
00:13:08,730 --> 00:13:11,626
So I'm just going to make a new instance. I would do this the same

205
00:13:11,648 --> 00:13:15,290
way that I would do all of my botkube instances.

206
00:13:16,830 --> 00:13:20,774
So here we're going to go to the official Botkube Slack

207
00:13:20,822 --> 00:13:24,142
app, and this requires starting a free tutorial. So we have a

208
00:13:24,196 --> 00:13:28,042
30 day free trial to be able to support multi cluster management.

209
00:13:28,106 --> 00:13:32,014
And then after that it's $25 per node per month. So here

210
00:13:32,052 --> 00:13:35,778
you would just connect your slack workspace, click add to slack, then you

211
00:13:35,784 --> 00:13:38,914
would just select whatever Slack workspace you'd be working in.

212
00:13:39,032 --> 00:13:42,194
I have my own debrel demo one, and I'm already

213
00:13:42,232 --> 00:13:44,900
connected, so I can just continue.

214
00:13:45,290 --> 00:13:49,510
I'll call this instance botkube demo production.

215
00:13:49,930 --> 00:13:53,398
Then next, since I already have this pre configured, I'm going to

216
00:13:53,404 --> 00:13:57,218
call this cube tomorrow production.

217
00:13:57,394 --> 00:14:00,586
And because this is going to be just for my production, I'm going to put

218
00:14:00,608 --> 00:14:04,346
it in my production channel, in my dev prod channel, which is

219
00:14:04,368 --> 00:14:08,038
going to host my cluster dedicated for production and my cluster

220
00:14:08,134 --> 00:14:12,234
dedicated to staging. And I'm just going to show you how

221
00:14:12,272 --> 00:14:15,614
easy it is to add baku cloud to a channel. Just an example.

222
00:14:15,732 --> 00:14:19,134
So click that open slack. Then I

223
00:14:19,172 --> 00:14:22,446
would go to integrations add up

224
00:14:22,628 --> 00:14:26,160
and then click on this. And then basically you're good to go.

225
00:14:26,550 --> 00:14:29,986
So now if I want to, I can add or

226
00:14:30,088 --> 00:14:33,714
remove as many channels as I'd like. So for this purpose of this

227
00:14:33,752 --> 00:14:37,190
demo, I'm just going to be using helm Kubectl Kubernetes.

228
00:14:37,770 --> 00:14:41,720
So it's just the same standard process. And then I'm going to go,

229
00:14:42,090 --> 00:14:46,534
I'm going to make this bigger. Hopefully everybody can see that and

230
00:14:46,572 --> 00:14:50,330
it's the same installation process that you would use for single cluster,

231
00:14:50,670 --> 00:14:53,420
just very copy and paste. Great.

232
00:14:53,950 --> 00:14:57,626
He'll, let's hop into slack and see what top

233
00:14:57,648 --> 00:15:00,250
it is. I was playing around with this earlier.

234
00:15:00,750 --> 00:15:04,282
All right, perfect. So we have Botkube activated

235
00:15:04,346 --> 00:15:08,000
in our production channel, in our dev prod channel.

236
00:15:08,450 --> 00:15:12,174
So I'm just going to do a few botcube commands just so you

237
00:15:12,212 --> 00:15:16,194
can see botkube up and running in some real world

238
00:15:16,232 --> 00:15:19,054
scenarios. So first I always do the botcube ping,

239
00:15:19,182 --> 00:15:22,786
just so I know that my botkube instance is

240
00:15:22,808 --> 00:15:26,582
up and running. Then I'm going to be running the help command which

241
00:15:26,636 --> 00:15:30,360
will show you a guide of all of the

242
00:15:31,050 --> 00:15:34,600
commands and plugins that we work with and just give you

243
00:15:34,970 --> 00:15:38,506
just more detail of what's going on. So I'm going to

244
00:15:38,688 --> 00:15:42,006
find out our list of executors.

245
00:15:42,038 --> 00:15:45,478
So today we'll be working with Doctor, which is our chat

246
00:15:45,494 --> 00:15:49,130
GBT plugin, helm and Kubectl.

247
00:15:49,630 --> 00:15:53,754
So next we're going to run some simple Kubectl

248
00:15:53,802 --> 00:15:57,258
functions in Bachube and I'm

249
00:15:57,274 --> 00:16:01,582
going to be using the slack interactivity feature which

250
00:16:01,636 --> 00:16:05,806
basically allows you to build out commands using buttons

251
00:16:05,838 --> 00:16:09,634
instead of having to manually type them out. So we're just going to run a

252
00:16:09,672 --> 00:16:14,126
quick get and then we're going to do a get pods

253
00:16:14,318 --> 00:16:17,990
just so we can see what's happening in our cluster.

254
00:16:18,730 --> 00:16:22,150
And you can add or remove

255
00:16:22,890 --> 00:16:26,774
functionalities like this in the Botkube cloud web

256
00:16:26,812 --> 00:16:30,026
hosted app. So if you want it to be read only you can

257
00:16:30,048 --> 00:16:33,846
take this out and you can see we have three pods

258
00:16:33,878 --> 00:16:37,846
going, so we have one that's failing. And then we're

259
00:16:37,878 --> 00:16:41,374
able to have our notification come in

260
00:16:41,492 --> 00:16:45,498
that there's an error. Then I can run a quick describe

261
00:16:45,674 --> 00:16:49,630
and see what else is going on. And then with this log

262
00:16:49,700 --> 00:16:53,182
that you get, you're able to also

263
00:16:53,236 --> 00:16:56,914
filter out the input, the output, excuse me,

264
00:16:57,112 --> 00:17:00,686
and filter out just what you want to see because sometimes those logs

265
00:17:00,718 --> 00:17:04,034
can be hundreds of lines long. So it's really great

266
00:17:04,072 --> 00:17:07,654
to get more information. So then we have some

267
00:17:07,692 --> 00:17:11,078
more things coming. So we have an ingress that

268
00:17:11,084 --> 00:17:15,394
was created. So we have an automation that I just inputted

269
00:17:15,522 --> 00:17:18,658
to have an automation where you do a describe every time you have a created

270
00:17:18,674 --> 00:17:22,940
resource. And then I'm just going to do a quick helm list.

271
00:17:23,550 --> 00:17:26,806
So then I'll be able to see everything that's

272
00:17:26,838 --> 00:17:30,406
going on on the helm chart that I have. So I have just bought Cube

273
00:17:30,438 --> 00:17:34,202
on there right now. But if I had a more complex cluster,

274
00:17:34,266 --> 00:17:37,120
I'd be able to see more of what's going on.

275
00:17:37,730 --> 00:17:41,002
And then we're just going to see the doctor plugin. So we had an ingress

276
00:17:41,066 --> 00:17:44,160
being created. What if I don't remember what an ingress is?

277
00:17:45,170 --> 00:17:48,814
And I'm just going to ask doctor really quickly. And doctor almost

278
00:17:48,852 --> 00:17:52,538
serves as having docs inside of your platform so you don't

279
00:17:52,554 --> 00:17:55,618
have to navigate to another window. So going to tell me what's

280
00:17:55,634 --> 00:17:59,222
a Kubernetes ingress? And I can be able to take that information

281
00:17:59,356 --> 00:18:03,254
and be able to act on that alert that I just got

282
00:18:03,292 --> 00:18:06,040
and that automation that I just got. So here's the demo,

283
00:18:06,730 --> 00:18:10,146
and thank you so much for joining my presentation.

284
00:18:10,338 --> 00:18:13,526
And right here, you can scan the QR code to get started with

285
00:18:13,548 --> 00:18:16,200
Bachube. And thank you so much for having me.

