1
00:00:26,290 --> 00:00:29,942
Security, chaos, engineering, how to fix

2
00:00:29,996 --> 00:00:34,054
things you didn't know were broken and make friends while doing it. The things

3
00:00:34,092 --> 00:00:37,654
I'll be talking about while sounding like a job for offsec people is not really

4
00:00:37,692 --> 00:00:41,478
an offset role. I'm not particularly interested in knowing something doesn't work.

5
00:00:41,564 --> 00:00:44,486
We all know that there is more than enough people out there to tell you

6
00:00:44,508 --> 00:00:48,006
that the goal is to not find all the broken things. The goal is to

7
00:00:48,028 --> 00:00:52,350
understand how things work before you a team to break things part

8
00:00:52,420 --> 00:00:55,680
one nothing works how we think it works.

9
00:00:57,330 --> 00:01:00,686
Maybe it's me. If you're looking for the smartest person in

10
00:01:00,708 --> 00:01:03,934
the room, just shut this off. Just go watch a different one

11
00:01:04,052 --> 00:01:07,394
because you're looking at the wrong person. But if you want to feel better about

12
00:01:07,432 --> 00:01:10,882
yourself, let's hang out. I don't really know how everything

13
00:01:10,936 --> 00:01:15,410
works all the time and you might and that's really awesome. But individuals don't scale.

14
00:01:15,990 --> 00:01:19,826
The outside world's a scary, scary place. And the people pulling the big decision

15
00:01:19,858 --> 00:01:23,190
levers are constantly being fed information about the horrors of the outside

16
00:01:23,260 --> 00:01:25,590
world and the threats looming on the horizon.

17
00:01:26,250 --> 00:01:29,670
They're hearing about the magic dust that solves the world's problems

18
00:01:29,740 --> 00:01:33,514
that they didn't know that they had. They protect the business from the next big

19
00:01:33,552 --> 00:01:37,126
nasty thing. They're going to ask their teams, are we safe from that threat?

20
00:01:37,158 --> 00:01:40,662
And then they're going to hear, we've got signatures in place and configurations

21
00:01:40,726 --> 00:01:44,558
made to stop those threats. But that doesn't really answer that question.

22
00:01:44,644 --> 00:01:48,286
The answer should be, yeah, we've modeled it. Here are the results. We arent

23
00:01:48,308 --> 00:01:51,520
tracking the resolution of those gaps or like,

24
00:01:51,890 --> 00:01:55,714
I don't know. But here's how we're going to find out. Everyone working

25
00:01:55,752 --> 00:01:58,926
in this industry, they're constantly bombarded with ads meant

26
00:01:58,958 --> 00:02:02,606
to terrify them into buying whatever jalapeno nacho cheese

27
00:02:02,638 --> 00:02:05,742
flavored security tool that says it's the only real way to prevent

28
00:02:05,806 --> 00:02:10,370
all the cutting edge quantum AI threats that arent continuously

29
00:02:10,530 --> 00:02:14,246
trying to eat their lunch. Vendors make us worry about

30
00:02:14,268 --> 00:02:17,654
the hypothetical next gen problems while the core of the business still

31
00:02:17,692 --> 00:02:21,238
struggles with fundamentals that have been placed since 19

32
00:02:21,334 --> 00:02:24,794
eight know where your assets are, where the data lives,

33
00:02:24,912 --> 00:02:28,614
who can access the data? Taking backups, validating the backups

34
00:02:28,662 --> 00:02:32,318
work, protecting information and keeping the nasties out

35
00:02:32,484 --> 00:02:35,946
should really most of us be worrying about quantum

36
00:02:35,978 --> 00:02:39,966
ransomware while we're struggling with managing role based access control.

37
00:02:40,148 --> 00:02:43,454
My mind is still blown from hearing about vendors talking about

38
00:02:43,492 --> 00:02:47,722
bloodhound and how they can detect bloodhound. It's like great I'm glad

39
00:02:47,786 --> 00:02:50,770
it's super noisy. It's like, I hope you can pick it up.

40
00:02:50,920 --> 00:02:54,850
Maybe next we'll talk about detecting Mimi Captain's default configuration

41
00:02:56,310 --> 00:02:59,366
I was having trouble sleeping a few nights ago and I decided to look up

42
00:02:59,388 --> 00:03:02,738
vulnerability trending information. So I took one look at the trending chart

43
00:03:02,754 --> 00:03:07,062
and said, wow, I'm glad I'm not involved management saying

44
00:03:07,116 --> 00:03:10,550
that it's probably going to be gifted with a project

45
00:03:10,620 --> 00:03:14,790
around in vulnerability soon for cyber karma.

46
00:03:14,950 --> 00:03:18,710
So going back on topic, it makes me wonder if we're actually improving

47
00:03:18,790 --> 00:03:22,326
as an industry. And based on those vulnerability numbers, we're clearly

48
00:03:22,358 --> 00:03:26,110
good at identifying these issues, especially in 2017.

49
00:03:26,450 --> 00:03:29,982
Minor change, their assignment process made cves easier to get.

50
00:03:30,036 --> 00:03:33,070
It's like a nice birthday gift to vulnerable management teams.

51
00:03:33,990 --> 00:03:37,134
Verizon Dvir regularly shows misconfigurations

52
00:03:37,182 --> 00:03:40,366
as the primary cause of breaches, not vulnerabilities.

53
00:03:40,558 --> 00:03:44,286
Is the time that we're spending on patching improving our ability to defend?

54
00:03:44,398 --> 00:03:48,126
Probably. But it's also true that misconfigurations contribute

55
00:03:48,158 --> 00:03:51,094
greatly to the security issues that plague us today.

56
00:03:51,292 --> 00:03:54,280
When you've got all these issues just dumped in front of you,

57
00:03:54,810 --> 00:03:58,434
it's really easy to buy a tool and say, okay, I've got the industry

58
00:03:58,482 --> 00:04:02,002
standard tools, so I don't have to worry about this. This is covered.

59
00:04:02,066 --> 00:04:05,610
I don't have to think about this anymore. Then you only find out later

60
00:04:05,680 --> 00:04:08,620
that it might not be working the way that you thought it worked.

61
00:04:08,990 --> 00:04:12,394
As we buzzily declare that we're shifting left to

62
00:04:12,432 --> 00:04:16,650
embed security in all the platforms at the beginning, trouble is kind of brewing.

63
00:04:16,730 --> 00:04:19,918
Like how do we know that the developers are making secure code? How do we

64
00:04:19,924 --> 00:04:23,706
know that the libraries that we rely on aren't actually held together with tinfoil

65
00:04:23,738 --> 00:04:26,974
and bubblegum, we get more tools to tell us it's

66
00:04:27,022 --> 00:04:31,026
extremely complicated and none of it's easy. As we do

67
00:04:31,048 --> 00:04:34,958
our work, these systems constantly change and constant changes the chaos experienced in

68
00:04:34,984 --> 00:04:38,738
day to day work. Chaos engineering security chaos engineering

69
00:04:38,834 --> 00:04:42,722
help design, build, operate, and protect these complex

70
00:04:42,786 --> 00:04:46,390
systems that are more resilient to attacks and failures.

71
00:04:46,810 --> 00:04:50,114
A lot of these tools exist because it's kind of hard to afford the folks

72
00:04:50,162 --> 00:04:53,642
that have time to dig into the root cause and make real change.

73
00:04:53,776 --> 00:04:57,334
Arent you afraid of malware? Buy Av a lot of these successful

74
00:04:57,382 --> 00:05:01,162
attacks are broken down, can be broken down to the basics like

75
00:05:01,216 --> 00:05:04,746
don't let untrusted code execute. Don't let folks run untrusted

76
00:05:04,778 --> 00:05:08,510
macros from excel docs. But if you do, make sure the one time it happens

77
00:05:08,580 --> 00:05:10,590
isn't going to bring down your whole environment.

78
00:05:12,050 --> 00:05:15,386
Arent vendors where we should be focusing our efforts to secure

79
00:05:15,418 --> 00:05:19,758
things, or should it be in people? While I'm somewhat excited about AI,

80
00:05:19,854 --> 00:05:23,406
I'm not really excited as being trained on the same thing humans are being trained

81
00:05:23,438 --> 00:05:27,234
on. Probably stack exchange or outdated Reddit

82
00:05:27,282 --> 00:05:31,506
posts or materials that help you get what you want, but it's not done securely,

83
00:05:31,618 --> 00:05:35,078
which will probably result in creating broken or

84
00:05:35,164 --> 00:05:38,600
insecure applications at a faster scale than a human can.

85
00:05:39,850 --> 00:05:43,098
And even the fundamentals are simple, but they're not easy.

86
00:05:43,264 --> 00:05:46,458
Even paid for tooling is complicated, like how does it

87
00:05:46,464 --> 00:05:50,026
work with deployment pipelines? Can it work at scale? Can you get your

88
00:05:50,048 --> 00:05:53,166
data out of it? Or are you essentially stuck with them for life?

89
00:05:53,348 --> 00:05:56,586
Token management, like things that are considered table stakes and basic

90
00:05:56,618 --> 00:06:00,510
fundamentals are still difficult even without the smug jerks clumsily saying

91
00:06:00,580 --> 00:06:04,366
just turn it on. So what makes things thing challenging?

92
00:06:04,478 --> 00:06:08,114
Like in some cases we don't know why we're doing it outside of third

93
00:06:08,152 --> 00:06:11,650
parties saying it's best practice, follow best practice.

94
00:06:12,230 --> 00:06:15,666
These basics arent really basic, they are kind of

95
00:06:15,688 --> 00:06:19,126
hard. If you don't believe it, you can ask yourself like why

96
00:06:19,148 --> 00:06:23,362
are there so many companies struggling with implementing native

97
00:06:23,426 --> 00:06:27,126
endpoint controls like a firewall, and instead rely on vendors to

98
00:06:27,148 --> 00:06:30,746
cover that gap for them? It's easier with the resources that are available to

99
00:06:30,768 --> 00:06:34,540
them to just manage a portal and not the entire platform.

100
00:06:34,910 --> 00:06:38,054
Have you ever really tried managing something like an app locker

101
00:06:38,102 --> 00:06:41,286
or Windows defender app control? It's got poor

102
00:06:41,318 --> 00:06:44,750
usability, poor user experience, and that makes it

103
00:06:44,820 --> 00:06:48,558
far more challenging than it should be. If you need to be certified to

104
00:06:48,564 --> 00:06:52,654
use a product or go through 40 plus hours of training, it's probably

105
00:06:52,772 --> 00:06:56,218
not well designed. And things that aren't well designed are

106
00:06:56,244 --> 00:06:59,586
prone to failure. Good security should not just

107
00:06:59,608 --> 00:07:02,626
be for those who can pay to play, it should be the built into the

108
00:07:02,648 --> 00:07:06,594
foundation. But regardless of who runs it, we need to understand how the tools

109
00:07:06,642 --> 00:07:10,962
work, if they work, and ensure they continue to work. And importantly,

110
00:07:11,026 --> 00:07:14,594
do they work as expected and to accomplish things, to accomplish

111
00:07:14,642 --> 00:07:17,906
things, we need foundational work. We need to understand what we're

112
00:07:17,938 --> 00:07:20,906
trying to protect. We need to know what is the goal that we want to

113
00:07:20,928 --> 00:07:24,326
achieve? Is it top ten adversaries? Is it opportunistics?

114
00:07:24,438 --> 00:07:27,674
How the tools work doesn't necessarily have

115
00:07:27,712 --> 00:07:31,054
to be deep weighted knowledge, but in general were are the weak points

116
00:07:31,092 --> 00:07:35,066
in your detection? What does it not cover? Like, what can't

117
00:07:35,098 --> 00:07:38,734
it see? Are they being used for their intended purpose? If they

118
00:07:38,772 --> 00:07:42,666
work, sometimes things are secretly a beta

119
00:07:42,698 --> 00:07:46,910
with pretend machine learning and AI that only work under certain conditions.

120
00:07:47,070 --> 00:07:51,442
We need to make sure they continue to work. So whatever

121
00:07:51,496 --> 00:07:55,054
value is being taken from these tools, that's the baseline of what's expected.

122
00:07:55,102 --> 00:07:57,720
It needs to continue doing that thing always.

123
00:07:58,490 --> 00:08:02,134
I would argue that so few know how things

124
00:08:02,172 --> 00:08:05,526
work that it's more scalable and acceptable to say we manage that

125
00:08:05,548 --> 00:08:09,574
a part of our portfolio with Vendorx. And the more

126
00:08:09,612 --> 00:08:13,222
I learn about something and how things work, the more I'm amazed

127
00:08:13,286 --> 00:08:16,794
that anything works fix things world at all. So we

128
00:08:16,832 --> 00:08:20,234
need to understand how these tools work. If they work, ensure they work.

129
00:08:20,272 --> 00:08:23,070
And importantly, do they work as expected?

130
00:08:24,690 --> 00:08:28,314
Because using security incidents as a way to measure this detection,

131
00:08:28,442 --> 00:08:32,126
while it is a method, it's not a great method to measure the ability to

132
00:08:32,148 --> 00:08:34,942
detect. People are stressed. There's a lot going on.

133
00:08:35,076 --> 00:08:38,158
Researching gaps during this time isn't really recommended.

134
00:08:38,254 --> 00:08:41,602
Obviously you can do it in retrospective, but these are still stressful times,

135
00:08:41,656 --> 00:08:45,234
and a bad retrospective can end up being a game of blame the human,

136
00:08:45,432 --> 00:08:49,266
don't blame the human, blame the system. Security awareness already puts

137
00:08:49,298 --> 00:08:52,578
enough responsibility on the person. Let's build resilient systems

138
00:08:52,594 --> 00:08:56,178
that can withstand an attacker. It's like shaming people for clicking

139
00:08:56,194 --> 00:09:00,042
on phishing. Like if clicking on a link just ruins everything for you,

140
00:09:00,096 --> 00:09:02,460
it's not the victim, it's the system.

141
00:09:03,550 --> 00:09:06,986
Stop shaming user for clicking on things. When things break in

142
00:09:07,008 --> 00:09:09,802
real life, we generally analyze. When we're wrong,

143
00:09:09,936 --> 00:09:13,086
we redesign it, we model it and we build it better.

144
00:09:13,268 --> 00:09:16,798
But when we think people are the cause, we just typically blame them.

145
00:09:16,884 --> 00:09:20,910
Like cybersecurity awareness, we're well were of cybersecurity.

146
00:09:21,250 --> 00:09:24,306
So let's build platforms and environments that are resilient enough to

147
00:09:24,328 --> 00:09:28,494
withstand a user clicking on a link. Part two secure

148
00:09:28,542 --> 00:09:32,194
today does not mean secure tomorrow. In real

149
00:09:32,232 --> 00:09:35,890
life, you only know how the systems work. The moment you deploy it,

150
00:09:35,960 --> 00:09:39,198
it gets presumably been tested, documented, everyone signed

151
00:09:39,214 --> 00:09:42,646
off for deployment, and chaos been set free to run through the fields of

152
00:09:42,668 --> 00:09:46,950
cybersecurity. But then tuning happens, patching happens,

153
00:09:47,100 --> 00:09:50,618
priorities change, humans get reassigned work, people leave.

154
00:09:50,784 --> 00:09:53,798
This is where the chaos comes in. Chaos engineering.

155
00:09:53,894 --> 00:09:57,450
We arent not making the chaos everyday. Work is the chaos,

156
00:09:57,790 --> 00:10:01,166
and we're working to make sense of how things change and why

157
00:10:01,268 --> 00:10:04,430
planned and approved changes can fundamentally change how a system

158
00:10:04,500 --> 00:10:07,710
operates. An example,

159
00:10:07,780 --> 00:10:11,118
software development constantly invents new ways to

160
00:10:11,124 --> 00:10:14,810
change. How systems work usually features performance,

161
00:10:14,890 --> 00:10:18,390
usability, so on. Oftentimes, vendor platforms aren't equipped

162
00:10:18,410 --> 00:10:21,314
to move things quickly. So in these cases, what do you do, do you hold

163
00:10:21,352 --> 00:10:24,926
back their releases? Do you stick with older versions of things? Sticking back with older

164
00:10:24,958 --> 00:10:28,130
versions of things means you could have more vulnerable software.

165
00:10:28,950 --> 00:10:32,566
So when we're looking for reliability, we know how it operates, we know

166
00:10:32,588 --> 00:10:36,166
what failure looks like, and we can validate multiple layers of defense to

167
00:10:36,188 --> 00:10:39,238
cover the gaps generated by the failure. Trying to

168
00:10:39,244 --> 00:10:42,602
prevent failure doesn't work, and it's likely never going to work.

169
00:10:42,656 --> 00:10:46,026
You cannot prevent all failure. Everything's going to

170
00:10:46,048 --> 00:10:49,462
fail at some point. So it's our jobs to understand how they'll fail

171
00:10:49,526 --> 00:10:53,066
and plan accordingly. And these experiments help us understand how

172
00:10:53,088 --> 00:10:56,046
something's going to fail so we can learn from it, and it will enable us

173
00:10:56,068 --> 00:10:59,070
to build systems resilient to cybersecurity failures.

174
00:10:59,490 --> 00:11:03,226
You get something dumping lsas and you have got a whole slew of controls

175
00:11:03,258 --> 00:11:06,498
that have failed and questions that come along with it. How did it get there?

176
00:11:06,584 --> 00:11:10,226
Why did it run? Was privilege escalation needed?

177
00:11:10,328 --> 00:11:13,934
If so, why did that work? How did it get through our network defenses?

178
00:11:13,982 --> 00:11:17,654
Does that mean we need to revisit configurations to do this?

179
00:11:17,692 --> 00:11:21,446
I enjoy building attack trees that help model these scenarios and

180
00:11:21,468 --> 00:11:24,822
guide me in creating new experiments with visual aids to help

181
00:11:24,876 --> 00:11:28,554
with telling the story to other humans and help

182
00:11:28,592 --> 00:11:30,780
me not look insane while I'm doing it.

183
00:11:32,430 --> 00:11:37,926
Part three experiments in madness KPIs

184
00:11:38,118 --> 00:11:41,226
super hot. Key performance indicators

185
00:11:41,258 --> 00:11:44,938
help set benchmarks, measure progress, set business goals.

186
00:11:45,034 --> 00:11:48,894
There are nearly unlimited numbers of terrible KPIs floating around,

187
00:11:48,932 --> 00:11:52,206
or floating around around there based on things

188
00:11:52,228 --> 00:11:56,030
that you can't control, like KPIs on intrusion attempts,

189
00:11:56,190 --> 00:11:59,746
numbers of incidents. Time to resolve. These can be gamed or just

190
00:11:59,768 --> 00:12:02,866
inaccurate. You can't control how many external entities are

191
00:12:02,888 --> 00:12:06,882
trying to ruin your parade. Something like a meantime between

192
00:12:06,936 --> 00:12:10,194
failure, those I can get behind. Every successful

193
00:12:10,242 --> 00:12:14,038
event on the endpoint is a failure. App control stops something. There's a

194
00:12:14,044 --> 00:12:17,442
failure at every previous layer, and that's just where the work begins.

195
00:12:17,506 --> 00:12:21,526
It's where we need skilled humans. Anybody can push the go button, but you need

196
00:12:21,548 --> 00:12:25,818
folks in place who understand what the button does and what it all means together

197
00:12:25,984 --> 00:12:29,098
to understand it. We need to tie it back to what we care about.

198
00:12:29,264 --> 00:12:32,614
What are the customer concerns? Are they worried about threat coverage?

199
00:12:32,742 --> 00:12:36,000
Defensive resilience? Needlessly duplicative technology?

200
00:12:36,370 --> 00:12:39,534
You're going to want to take the time to figure out their goals, especially if

201
00:12:39,572 --> 00:12:43,146
they aren't sure what they need. So when you're looking at it, what concerns

202
00:12:43,178 --> 00:12:47,060
you? What threats concern you? What does your coverage look like?

203
00:12:47,430 --> 00:12:51,266
Can you safely withstand the attacks from these groups? How much failure can

204
00:12:51,288 --> 00:12:54,020
you safely withstand before you have a really bad day.

205
00:12:54,630 --> 00:12:58,402
Testing versus experimentation. Testing implies a

206
00:12:58,456 --> 00:13:01,974
right or wrong answer, and we're not looking for right or wrong. We're looking for

207
00:13:02,012 --> 00:13:05,382
new information to help us make better decisions. I want to know what

208
00:13:05,436 --> 00:13:09,058
works, what doesn't work, why it works, how it does, and what cost

209
00:13:09,084 --> 00:13:13,370
effective improvements we can make that will make other teams work harder.

210
00:13:14,350 --> 00:13:17,542
I'd like to know that the money we're spending is providing value beyond

211
00:13:17,606 --> 00:13:21,066
compliance. Checkboxes. Starting with design, what do

212
00:13:21,088 --> 00:13:24,394
we think will happen? Assuming there's a documented expectation,

213
00:13:24,442 --> 00:13:27,386
we can safely wager that the platform will do what's promised.

214
00:13:27,498 --> 00:13:31,230
Tons of people will say truly and verify, but I don't really trust

215
00:13:31,300 --> 00:13:34,770
claims. I want to test the claims and gather evidence.

216
00:13:35,350 --> 00:13:40,066
It's admittedly a lesser exciting part, but we

217
00:13:40,088 --> 00:13:43,982
don't want to eat the dry ramen and then just drink the water afterwards.

218
00:13:44,126 --> 00:13:48,370
We just want to tie it back to business goals. So in building an experiment,

219
00:13:49,030 --> 00:13:52,326
we want to start with a nice, reputable source to use.

220
00:13:52,428 --> 00:13:56,006
I generally go with either intel sources or map it out in

221
00:13:56,028 --> 00:13:59,786
front of me. But if I'm not emulating a specific threat, I'm looking at

222
00:13:59,808 --> 00:14:03,306
each stage and finding out what's available to me at

223
00:14:03,328 --> 00:14:06,934
every single part. Odds are soon you're going to find that most adversaries

224
00:14:06,982 --> 00:14:10,854
look extremely similar to each other. Maybe they'll deploy

225
00:14:10,902 --> 00:14:14,506
something differently, but in the end, it's just untrusted code executing.

226
00:14:14,618 --> 00:14:18,442
It's like 22 Jump street. You infiltrate the dealer, you find the supplier.

227
00:14:18,506 --> 00:14:20,080
Just do the same thing.

228
00:14:21,570 --> 00:14:24,958
Mostly. Obviously there are edge cases.

229
00:14:25,134 --> 00:14:29,294
So DFIR report usually has great breakdowns of adversarial

230
00:14:29,342 --> 00:14:33,490
actions that you can take to plan your experiment. But don't use actual

231
00:14:33,560 --> 00:14:36,646
malware because that can ruin your day. You can

232
00:14:36,668 --> 00:14:39,970
use icar or mimicats, things that aren't inherently

233
00:14:40,050 --> 00:14:43,734
destructive and won't get out of your control. Like,

234
00:14:43,772 --> 00:14:48,002
you can even make AV flip out by appending mimicats commands after calc exe,

235
00:14:48,066 --> 00:14:52,006
because next gen AV likes to pretend it's learning everything, but it's going to trigger

236
00:14:52,038 --> 00:14:56,090
on those words. I wonder why. This is just a visual example

237
00:14:56,160 --> 00:14:59,414
of a couple different tests where we expect to see some observables,

238
00:14:59,462 --> 00:15:03,006
sort of a scorecard, if you will, about what you think you

239
00:15:03,028 --> 00:15:06,734
should see and where. And doing things is noisy. In this

240
00:15:06,772 --> 00:15:10,266
example, we're running a couple of atomic tests. In this scenario,

241
00:15:10,298 --> 00:15:13,530
were seeing a file download, execution,

242
00:15:13,610 --> 00:15:17,262
and local discovery. And when these typically run, you're looking for endpoint events,

243
00:15:17,326 --> 00:15:21,060
which makes sense because that's the easiest place to look for indicators of attack.

244
00:15:21,430 --> 00:15:24,514
In reality, downloading a file should provide no less

245
00:15:24,552 --> 00:15:28,214
than two to four pieces of telemetry through your

246
00:15:28,252 --> 00:15:31,830
stack, or even nothing, depending on how your organization is

247
00:15:31,900 --> 00:15:35,238
running. Point being, when you do things, you should be

248
00:15:35,244 --> 00:15:37,590
able to see layers of defense in action.

249
00:15:38,090 --> 00:15:41,466
So questions that I have from above would be why are these

250
00:15:41,488 --> 00:15:45,334
files allowed to be downloaded? Is that normal for that user's Persona?

251
00:15:45,382 --> 00:15:48,602
Do people typically download things out of band? Do they use

252
00:15:48,656 --> 00:15:52,178
Powershell to do it? Why are they able to launch setup

253
00:15:52,214 --> 00:15:55,978
from the desktop? Is that normal? Like pretend it's malware?

254
00:15:56,074 --> 00:15:59,514
Shouldn't the proxy handle malware at that layer? Do people normally

255
00:15:59,562 --> 00:16:03,166
start services in the command line? The answer to all that could

256
00:16:03,188 --> 00:16:06,606
be yes. But if you don't know that, it's difficult to say whether your tools

257
00:16:06,638 --> 00:16:10,146
and platforms are working as expected. We're going to be filling this

258
00:16:10,168 --> 00:16:14,046
out later. It's a quick, high level overview of what the experiment

259
00:16:14,158 --> 00:16:17,366
ultimately looks like. At its conclusion, we'll have

260
00:16:17,388 --> 00:16:20,566
an easy to understand view of the overall status of the

261
00:16:20,588 --> 00:16:23,622
cybersecurity tooling. So this one

262
00:16:23,676 --> 00:16:26,610
is relatively straightforward. Take your outcome,

263
00:16:26,690 --> 00:16:30,138
your goals, validate your position. If you deploy a thing,

264
00:16:30,224 --> 00:16:33,466
does it do what it's supposed to do? You don't want to just assume the

265
00:16:33,488 --> 00:16:37,210
outcome. You need to exercise, it needs to be exercised.

266
00:16:37,870 --> 00:16:40,938
And getting started is probably

267
00:16:41,024 --> 00:16:44,330
one of the hardest parts. So in order to

268
00:16:44,400 --> 00:16:47,886
sort of guide this like mitre defend framework, it's going to help if you're

269
00:16:47,908 --> 00:16:51,066
unsure how your defenses measure up. Attack helps if you've

270
00:16:51,098 --> 00:16:54,514
got absolutely no idea how to get started or what an attack looks like.

271
00:16:54,632 --> 00:16:58,146
If everything is super awesome, you've just created a baseline to

272
00:16:58,168 --> 00:17:01,874
measure future changes against patching, tuning whole

273
00:17:01,912 --> 00:17:05,486
platform replacements. It can all be measured against that baseline.

274
00:17:05,678 --> 00:17:09,094
One key note, this baseline should be changed over

275
00:17:09,132 --> 00:17:12,886
time to reflect positive changes. Otherwise, you'll be

276
00:17:12,908 --> 00:17:16,134
measuring the wrong thing, and you won't really know if you're improving from

277
00:17:16,172 --> 00:17:19,834
the previous iteration. If everything's not super awesome,

278
00:17:19,952 --> 00:17:23,180
well, you now know where you've got to start.

279
00:17:24,750 --> 00:17:28,794
Part four measuring stuff the

280
00:17:28,832 --> 00:17:32,906
phrase we don't know what we don't know is an traditional

281
00:17:33,018 --> 00:17:36,334
annoyance of mine. It's like you're throwing up your hands and

282
00:17:36,372 --> 00:17:40,046
giving up. Presumably there are things that have

283
00:17:40,068 --> 00:17:43,434
been done outlining what you know about your environment. Even a bone

284
00:17:43,482 --> 00:17:46,946
scan is a start. Whatever that is, that's what you know.

285
00:17:47,048 --> 00:17:51,038
Everything else needs to be tested, identified and measured.

286
00:17:51,214 --> 00:17:54,674
Whatever you know, that's your current baseline. So to put

287
00:17:54,712 --> 00:17:58,530
visibility in, expect to put visibility into perspective.

288
00:17:58,690 --> 00:18:02,738
What if they could only guarantee that 80 or 90% of the time your cheerios

289
00:18:02,754 --> 00:18:05,990
weren't poisoned or contained bits of rock and glass?

290
00:18:06,410 --> 00:18:09,994
There'd probably be a big investigation. So we

291
00:18:10,032 --> 00:18:13,578
should not settle for 80 or 90% visibility. We don't want

292
00:18:13,584 --> 00:18:17,386
to be eating glass. Cyberglass. I don't think cyberglass is

293
00:18:17,408 --> 00:18:21,254
a thing yet. And the view of experiments and practice.

294
00:18:21,302 --> 00:18:25,386
This is currently my favorite view of the world. It tells me exactly what defenses

295
00:18:25,418 --> 00:18:29,242
are working for the given technique. Now, this example is purely fictional,

296
00:18:29,306 --> 00:18:32,334
but the idea is that you take a view like this and guide it to

297
00:18:32,372 --> 00:18:35,758
where you're going in the delivery stage. You can see the payload was blocked at

298
00:18:35,764 --> 00:18:39,506
the endpoint. Arent mission accomplished. But why did it get to the

299
00:18:39,528 --> 00:18:42,926
endpoint? That means there were failures at the other layers coming earlier

300
00:18:42,958 --> 00:18:46,626
in the chain. Why didn't it get stopped earlier? Was it a misconfiguration?

301
00:18:46,738 --> 00:18:49,750
If nothing's wrong and everything is working and expected,

302
00:18:51,370 --> 00:18:54,950
is that normal? We don't know. That's what we're going to find out.

303
00:18:55,100 --> 00:18:58,246
And that's the beauty. In experimentation. You're learning about

304
00:18:58,268 --> 00:19:01,922
how things actually work rather than guessing based on a configuration.

305
00:19:02,066 --> 00:19:05,466
And once you can do it that first time, you automate it. And now you

306
00:19:05,488 --> 00:19:09,174
have ways to identify drift. Over time, you're able to measure the impact

307
00:19:09,222 --> 00:19:12,830
of changes and avoid mistakes later on that are more expensive to fix,

308
00:19:12,980 --> 00:19:16,442
like PG and E. Fixing the infrastructure

309
00:19:16,506 --> 00:19:20,426
50 years ago would have been way less expensive than making it for deferred

310
00:19:20,458 --> 00:19:24,594
maintenance. Buyers homes lost and eventually rate

311
00:19:24,632 --> 00:19:28,338
raises that we have today. And it helps you make friends.

312
00:19:28,504 --> 00:19:32,194
Friends like these. So this was AI's attempt to

313
00:19:32,232 --> 00:19:36,020
make five half human, half ravioli people.

314
00:19:36,390 --> 00:19:39,842
There are six here. I had some free tokens that were expiring,

315
00:19:39,906 --> 00:19:42,310
and I needed to make some art for this presentation.

316
00:19:44,730 --> 00:19:48,146
Security chaos. Engineering should not just be limited to engineering.

317
00:19:48,178 --> 00:19:52,060
Teams don't think they're the only ones that can have all of the fun.

318
00:19:52,750 --> 00:19:56,534
Hunt teams. Hunt teams can validate

319
00:19:56,582 --> 00:20:00,166
analytics to let them know that in lieu of an active compromise, that their analytic

320
00:20:00,198 --> 00:20:03,534
is still functioning. Parsing results can let groups zero

321
00:20:03,572 --> 00:20:07,598
in on where detection is missing and guide hunt activities to where the gaps live.

322
00:20:07,764 --> 00:20:11,354
Architecture teams or groups can be looking for duplicative

323
00:20:11,402 --> 00:20:14,670
technologies, maybe reduce tech tech debt.

324
00:20:15,570 --> 00:20:19,106
If you don't know where things overlap, then when you make changes, you might

325
00:20:19,128 --> 00:20:22,654
be losing critical tooling. You could also find that you've got too much emphasis

326
00:20:22,702 --> 00:20:26,114
in one place and not enough someplace else. And this is how you can find

327
00:20:26,152 --> 00:20:29,598
out without waiting for an adversary. Operations teams want to note

328
00:20:29,614 --> 00:20:32,966
that the tools they rely on to work through all the nonsense of maintenance of

329
00:20:32,988 --> 00:20:36,774
updates. They want to make sure their alerts still work. They want to know where

330
00:20:36,812 --> 00:20:40,090
the holes are that they need to worry about. And our product

331
00:20:40,160 --> 00:20:43,686
teams everywhere. They want to know how their portfolios

332
00:20:43,718 --> 00:20:46,620
perform, whether they provide actual value to their customers.

333
00:20:46,990 --> 00:20:50,566
Knowing that your product works enables

334
00:20:50,598 --> 00:20:53,706
better decisions when it comes to the renew replace cycles, and will

335
00:20:53,728 --> 00:20:57,226
help give you a baseline to measure against. It also helps validate

336
00:20:57,258 --> 00:20:59,854
that a new product will do what it claims, and you don't have to take

337
00:20:59,892 --> 00:21:03,930
their word for it. Or if they say, just look at the minor attack evaluation

338
00:21:04,010 --> 00:21:07,834
results. You could see we saw everything. Yeah,

339
00:21:07,892 --> 00:21:11,266
sure you did. I don't want to know what the best tool is.

340
00:21:11,368 --> 00:21:14,098
I want to know the best way that we can reduce the impact of a

341
00:21:14,104 --> 00:21:18,134
malicious entity getting into an environment. And that is what

342
00:21:18,332 --> 00:21:20,710
we can do with the experimentation.

343
00:21:21,850 --> 00:21:25,560
Part five making friends along the way

344
00:21:26,810 --> 00:21:29,690
and I will wholeheartedly,

345
00:21:30,030 --> 00:21:33,786
wholeheartedly attest to making friends.

346
00:21:33,968 --> 00:21:37,514
Director director director director director of security chaos engineering

347
00:21:37,552 --> 00:21:41,370
become popular like popular with audit

348
00:21:41,530 --> 00:21:44,874
second line functions, which you might not want unless

349
00:21:44,922 --> 00:21:47,642
you really like writing responses to their requests.

350
00:21:47,706 --> 00:21:51,326
Because talking to them and giving information means you'll be

351
00:21:51,348 --> 00:21:55,246
writing responses all the time, because you're bringing real life views into what's

352
00:21:55,278 --> 00:21:58,978
typically a box checking exercise and

353
00:21:59,064 --> 00:22:02,260
making other programs better. It helps you make friends,

354
00:22:03,590 --> 00:22:07,170
and that's really what working is about, isn't it? Work is really

355
00:22:07,240 --> 00:22:10,486
all about making friends in the right places to help you get the things you

356
00:22:10,508 --> 00:22:14,514
want done, actually done. So in the example, I'm going with compliance

357
00:22:14,562 --> 00:22:18,134
now, everybody loves compliance. And many times when

358
00:22:18,172 --> 00:22:22,006
asked about the security program of their business, they'll answer, we're HIPAA

359
00:22:22,038 --> 00:22:25,846
certified were PCI compliant, which, if you're listening

360
00:22:25,878 --> 00:22:29,974
to this, you know exactly what that means. But it doesn't have to mean that

361
00:22:30,112 --> 00:22:33,594
compliance can be made mostly painless. And director of security

362
00:22:33,642 --> 00:22:37,290
chaos engineering support measuring

363
00:22:37,450 --> 00:22:40,734
those tools it helps measure the effectiveness of your

364
00:22:40,772 --> 00:22:44,018
program. Effectiveness of your program opportunities to

365
00:22:44,024 --> 00:22:48,014
improve your program communicate recent achievements demonstrate

366
00:22:48,062 --> 00:22:51,614
stewardship of your resources show how your team supported objectives

367
00:22:51,662 --> 00:22:54,994
of your organization, possible actions that you want others to take

368
00:22:55,032 --> 00:22:58,786
to improve. And by doing it all the time, it's not an exercise in finding

369
00:22:58,818 --> 00:23:02,198
the right evidence at the right time to show compliance. It enables you to

370
00:23:02,204 --> 00:23:06,066
be compliant because you're secure, not secure because you're compliant.

371
00:23:06,258 --> 00:23:09,820
Security chaos engineering helps you ask better questions.

372
00:23:10,590 --> 00:23:14,166
Questions like, does our endpoint security stack proactively reduce

373
00:23:14,198 --> 00:23:17,126
the impact of unwanted activity by malicious actors.

374
00:23:17,238 --> 00:23:20,890
How do we minimize the impact of ransomware? Do our network security

375
00:23:20,960 --> 00:23:25,226
tools effectively provide defenders with data necessary to investigate

376
00:23:25,258 --> 00:23:28,826
and or mitigate unwanted activity? So we're reframing

377
00:23:28,858 --> 00:23:32,014
the question to ask what the most effective use of resources would be,

378
00:23:32,052 --> 00:23:35,954
whether it's tuning implementation build versus buy instead of just

379
00:23:35,992 --> 00:23:40,260
asking what's the best av we can buy?

380
00:23:41,030 --> 00:23:44,174
Making things palatable for others will make your life easier,

381
00:23:44,302 --> 00:23:47,462
and it takes patience to do this kind of work because it's not as common

382
00:23:47,516 --> 00:23:51,334
as it should be, or hopefully in the future will be. You may get

383
00:23:51,372 --> 00:23:55,174
empathy from any sres out there when you explain

384
00:23:55,292 --> 00:23:59,082
hey, here are my challenges, how do you solve this?

385
00:23:59,136 --> 00:24:02,794
And they'll smile, they'll nod and

386
00:24:02,832 --> 00:24:05,420
maybe smuggly chuckle first time.

387
00:24:05,870 --> 00:24:09,402
So get started. Start small with business

388
00:24:09,456 --> 00:24:13,126
goals and use examples they'll care about. Start by experimenting against

389
00:24:13,168 --> 00:24:16,206
controlled endpoints to validate they function the way the owners think.

390
00:24:16,308 --> 00:24:19,726
Give them data to build KPIs to show how awesome they are.

391
00:24:19,828 --> 00:24:23,566
Be nice. If you're not nice, nobody's going to want to help you

392
00:24:23,668 --> 00:24:27,266
trace back why something doesn't work if you're mean, it's really easy

393
00:24:27,288 --> 00:24:30,846
to get sidetracked by finding oddities. Don't go chasing waterfalls

394
00:24:30,878 --> 00:24:34,594
and beware. It's work that people don't even know they need

395
00:24:34,632 --> 00:24:38,482
until it's done. And success means more work because that's

396
00:24:38,546 --> 00:24:42,646
really what life's all about. Life's about succeeding and

397
00:24:42,748 --> 00:24:46,466
generating more work for yourself. Our ultimate

398
00:24:46,498 --> 00:24:49,858
goal is making things better with proven, well designed functional systems

399
00:24:49,874 --> 00:24:53,954
that provide depth. It increases the cost of attack and it's resistant

400
00:24:54,002 --> 00:24:57,462
or resilient to failures. And I believe

401
00:24:57,516 --> 00:25:01,214
in you, so thank you for listening and or watching,

402
00:25:01,332 --> 00:25:05,022
and I hope you learned something from this. And if not, I made a

403
00:25:05,076 --> 00:25:06,590
terrible mistake.

