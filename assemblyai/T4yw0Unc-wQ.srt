1
00:01:28,690 --> 00:01:32,246
Hi, today I will be talking about fault tolerance and how

2
00:01:32,268 --> 00:01:35,160
to migrate service to multiregion in the cloud.

3
00:01:35,690 --> 00:01:39,414
Services and resources are located in an availability zone inside

4
00:01:39,452 --> 00:01:42,698
a region like us east or us west.

5
00:01:42,874 --> 00:01:46,106
We can have multiple availability zones in a region.

6
00:01:46,218 --> 00:01:49,790
Sometimes a whole region can fail, causing a whole service

7
00:01:49,860 --> 00:01:53,178
to die. But if we have a fault tolerance setup

8
00:01:53,274 --> 00:01:57,022
with a multi region approach, disaster can be avoided.

9
00:01:57,166 --> 00:02:00,862
I am currently working at Globant as a DevOps engineer.

10
00:02:01,006 --> 00:02:04,062
We are a digitally native company that helps organizations

11
00:02:04,126 --> 00:02:07,526
reinvent themselves and unleash their potential. We are

12
00:02:07,548 --> 00:02:11,670
the place where reinnovation, design and engineering met scale.

13
00:02:12,650 --> 00:02:16,294
Since I started working in the cloud, I've noticed that

14
00:02:16,332 --> 00:02:20,326
even with high availability, there is a chance that a whole region fails

15
00:02:20,438 --> 00:02:24,074
and critical services that need 100% uptime are not

16
00:02:24,112 --> 00:02:27,414
available, generating massive loss to the clients.

17
00:02:27,542 --> 00:02:31,082
The process not only to modernize these services, but also

18
00:02:31,136 --> 00:02:34,974
migrating them to be multiregion can be quite taxing, but if

19
00:02:35,012 --> 00:02:38,650
done correctly, it will generate a peace of mind to stakeholders,

20
00:02:38,730 --> 00:02:42,174
clients and end users. I will explain the

21
00:02:42,212 --> 00:02:45,646
difference between high availability versus fault tolerance,

22
00:02:45,758 --> 00:02:49,742
and then provide some pointers to go with multiregion in a complex

23
00:02:49,806 --> 00:02:50,420
service.

24
00:02:55,130 --> 00:02:57,830
So first, what is high availability?

25
00:02:58,410 --> 00:03:02,098
High availability is the ability of a service to remain operational

26
00:03:02,194 --> 00:03:05,110
with minimal downtime in the event of disruption.

27
00:03:05,770 --> 00:03:09,306
Disruptions include hardware failure, networking problems,

28
00:03:09,408 --> 00:03:13,254
or security events like a DDoS attack. In a highly

29
00:03:13,302 --> 00:03:17,242
available system, the infrastructure services are spread across

30
00:03:17,296 --> 00:03:20,550
a cluster of instances. If one of these instance

31
00:03:20,630 --> 00:03:24,606
fails, the warlocks running on it are automatically moved to other servers or

32
00:03:24,628 --> 00:03:28,174
instances. These clusters are normally set up

33
00:03:28,212 --> 00:03:32,026
across different availability zones, but all in the same region.

34
00:03:32,218 --> 00:03:35,810
The main advantages are the easier maintenance,

35
00:03:36,790 --> 00:03:40,910
even if the design is more complex, because the scalability

36
00:03:41,070 --> 00:03:44,434
that it provides and almost no service disruption with

37
00:03:44,472 --> 00:03:48,466
a load balancing solution that will automatically divert the traffic

38
00:03:48,578 --> 00:03:52,886
to a functioning cluster. Things means that we

39
00:03:52,908 --> 00:03:56,086
will need to set up double the components to provide this

40
00:03:56,108 --> 00:03:59,546
balancing solution, which can raise the cost even if we

41
00:03:59,568 --> 00:04:03,322
are spending to prevent disruption. There is also a chance of data

42
00:04:03,376 --> 00:04:07,834
loss if there is data being transferred while

43
00:04:07,872 --> 00:04:09,580
the change of authority happens.

44
00:04:12,800 --> 00:04:15,820
And finally, there is still a chance of disruption.

45
00:04:16,160 --> 00:04:19,832
There's like a percentage of disruption

46
00:04:19,976 --> 00:04:23,324
that can cause several loss in some services. Have we always seen

47
00:04:23,362 --> 00:04:26,240
a full service failure over a regional disaster?

48
00:04:29,300 --> 00:04:33,824
Then we have fault tolerance where

49
00:04:33,862 --> 00:04:37,844
there's no interruptional service. So it's a design concept when

50
00:04:37,882 --> 00:04:41,424
a service will continue working normally after experiencing expected

51
00:04:41,472 --> 00:04:44,980
failure or malfunctioning with zero service interruption.

52
00:04:46,360 --> 00:04:50,356
So in this seamless transition, when there's

53
00:04:50,388 --> 00:04:54,696
a failure is

54
00:04:54,798 --> 00:04:58,664
the problem, but also not

55
00:04:58,702 --> 00:05:02,332
only with failures, but when there's a need to upgrade to

56
00:05:02,386 --> 00:05:06,140
change or perform maintenance on the service or hardware.

57
00:05:06,880 --> 00:05:10,648
Now, regarding data loss that was applied

58
00:05:10,664 --> 00:05:15,904
in high availability, here is if

59
00:05:15,942 --> 00:05:19,388
well implemented, there shouldn't be none

60
00:05:19,564 --> 00:05:22,736
because we have set up redundancy and we

61
00:05:22,758 --> 00:05:26,096
do not have that crossover component between active and

62
00:05:26,118 --> 00:05:29,940
passive systems and will write and receive all of the requests.

63
00:05:30,360 --> 00:05:33,956
Obviously, the design concept that will assure that the service will continue to

64
00:05:33,978 --> 00:05:37,856
work if a whole region fails has some more costly and complex

65
00:05:37,888 --> 00:05:41,652
setup. But sometimes you have to wait those things and decide

66
00:05:41,716 --> 00:05:48,000
what is better for the situation now.

67
00:05:48,070 --> 00:05:51,936
So both designs reduce the risk of service disruption and

68
00:05:51,958 --> 00:05:55,280
downtime, but they do so in different ways.

69
00:05:55,430 --> 00:05:59,220
Additionally, the two models tend to differ in terms of cost.

70
00:05:59,290 --> 00:06:02,788
When we choose which one to adopt, you have to take into account the

71
00:06:02,794 --> 00:06:06,612
level of disruption, the infrastructure requirements and management

72
00:06:06,676 --> 00:06:09,720
effort in the design setup and operational maintenance.

73
00:06:10,780 --> 00:06:13,960
As I've been working with some sensitive projects that needed

74
00:06:14,030 --> 00:06:18,036
zero downtime and no downloads, I had to implement multi

75
00:06:18,068 --> 00:06:21,390
region, and I like to provide some insight on how to implement it

76
00:06:22,320 --> 00:06:24,940
using a multi region in AWS.

77
00:06:27,680 --> 00:06:31,744
So first of all that we have to make

78
00:06:31,782 --> 00:06:35,788
sure is that we have a good cross

79
00:06:35,884 --> 00:06:40,080
account replication on the security resources

80
00:06:40,820 --> 00:06:44,112
and cross region replication on the security resources too.

81
00:06:44,246 --> 00:06:47,876
Authorization, encryption, auditing and observability need

82
00:06:47,898 --> 00:06:51,284
to be replicated, and the data logs should be stored in an s three

83
00:06:51,322 --> 00:06:55,300
bucket with multiregion replication, as we can see in this graphic

84
00:06:58,120 --> 00:07:01,400
snuckly AWS IAM,

85
00:07:01,740 --> 00:07:06,772
that's the users roles groups provider

86
00:07:06,836 --> 00:07:10,728
for AWS has multi region availability

87
00:07:10,824 --> 00:07:14,190
automatically has no configuration required on your part.

88
00:07:14,720 --> 00:07:18,236
Then we have the AWS secret manager that can store secrets with

89
00:07:18,258 --> 00:07:21,440
KMS encryption, which can be replicated

90
00:07:22,500 --> 00:07:26,284
over secondary regions to ensure they can be retrieved in the closest

91
00:07:26,332 --> 00:07:29,552
and available region. Some services like

92
00:07:29,606 --> 00:07:33,516
s three package and Aurora databases have cross region

93
00:07:33,548 --> 00:07:37,444
replication, which makes the encryption decryption steps more

94
00:07:37,482 --> 00:07:41,156
agile. But for those applications that run multiregion, there's an

95
00:07:41,178 --> 00:07:45,124
option to set up TMS multiregion keys, which will make your life

96
00:07:45,162 --> 00:07:47,320
easier on the encryption operations.

97
00:07:49,020 --> 00:07:52,324
As stated before, you can save all the clothes

98
00:07:52,372 --> 00:07:55,928
right logs in a replicated s three storage, but keep in mind that

99
00:07:55,934 --> 00:07:59,964
you can also enable security hub to send all the findings from both

100
00:08:00,002 --> 00:08:02,540
regions to a single navigation pane.

101
00:08:06,720 --> 00:08:10,264
Second, but not less important, is networking.

102
00:08:10,312 --> 00:08:14,012
Because we have to analyze and be aware of the networking infrastructure.

103
00:08:14,076 --> 00:08:17,420
We are going to need to set up a global network

104
00:08:17,580 --> 00:08:21,440
to communicate between the regions. We can use BPC peering.

105
00:08:22,020 --> 00:08:25,792
These resources can communicate using private ip addresses

106
00:08:25,856 --> 00:08:30,112
and do not require an Internet gateway, a VPN

107
00:08:30,176 --> 00:08:34,740
or separate network appliances, and by the way, it's cheaper

108
00:08:35,240 --> 00:08:39,076
than other options using a private private

109
00:08:39,108 --> 00:08:42,772
cloud for on premise communication

110
00:08:42,836 --> 00:08:46,548
we have transit Gateway is a networking transit hub

111
00:08:46,644 --> 00:08:50,540
that connects your vpcs and on premises networks.

112
00:08:51,040 --> 00:08:54,396
Things can be chance to expand the

113
00:08:54,418 --> 00:08:58,664
additional regions with transit gateway interregion peering

114
00:08:58,712 --> 00:09:03,020
to create a globally distributed private network for your resources.

115
00:09:03,680 --> 00:09:07,164
Now we have route 53, that's the DNS

116
00:09:07,212 --> 00:09:10,860
solution to route the users to those distributed

117
00:09:10,940 --> 00:09:14,560
Internet applications and offers a comprehensive

118
00:09:14,640 --> 00:09:17,700
available solution that has minimal dependencies.

119
00:09:19,800 --> 00:09:23,536
Then we have close one is a content delivery

120
00:09:23,568 --> 00:09:27,924
network like for websites which

121
00:09:27,962 --> 00:09:31,600
allow us to manage our content closer to the end users

122
00:09:31,760 --> 00:09:35,160
with apps locations. But it's also possible

123
00:09:35,230 --> 00:09:38,600
to set it up with an origin failover.

124
00:09:40,400 --> 00:09:44,696
If the primary origin is unavailable or returns

125
00:09:44,728 --> 00:09:48,812
a specific HTTP response status code that

126
00:09:48,866 --> 00:09:50,140
indicates a failure,

127
00:09:52,100 --> 00:09:55,730
Cloudfront will automatically switch to the secondary origin.

128
00:09:56,500 --> 00:10:00,364
And then for Internet facing apps

129
00:10:00,492 --> 00:10:04,224
you can set up a global accelerator which automatically

130
00:10:04,272 --> 00:10:08,180
switches with two static Anikas ips

131
00:10:08,520 --> 00:10:12,144
with one single entry point as you can seamlessly

132
00:10:12,192 --> 00:10:15,552
add or remove origins and redirect traffic within

133
00:10:15,626 --> 00:10:19,112
6 seconds. It also allow

134
00:10:19,166 --> 00:10:22,040
us to ask traffic waves to test deployments.

135
00:10:27,180 --> 00:10:31,720
I've used global accelerators and it's really useful

136
00:10:31,800 --> 00:10:34,408
for devs,

137
00:10:34,504 --> 00:10:38,204
not cloud engineers because they

138
00:10:38,242 --> 00:10:41,440
have only to switch the weights and

139
00:10:41,510 --> 00:10:45,472
traffic all the workload and it's a

140
00:10:45,526 --> 00:10:49,250
really good solution. It also help with

141
00:10:50,980 --> 00:10:54,612
live fixes to production when some

142
00:10:54,666 --> 00:10:56,310
scenarios require it.

143
00:10:58,520 --> 00:11:02,896
Now next we have compute

144
00:11:02,928 --> 00:11:06,504
depending on your infrastructure, there are different things to consider.

145
00:11:06,622 --> 00:11:10,376
For example, if you use EC two instances, they have

146
00:11:10,398 --> 00:11:13,780
their corresponding EDS volumes.

147
00:11:13,940 --> 00:11:18,304
They are storing one availability zone, but we have data lifecycle

148
00:11:18,372 --> 00:11:22,056
manager to automate the replication to those volumes

149
00:11:22,088 --> 00:11:26,664
to another region. And if we use amas,

150
00:11:26,792 --> 00:11:30,040
we have replication of our regions

151
00:11:30,120 --> 00:11:33,888
with EC two image builder. So we don't need to

152
00:11:33,894 --> 00:11:36,976
do this manually. If our

153
00:11:36,998 --> 00:11:40,972
service or application is based on microservices,

154
00:11:41,036 --> 00:11:45,184
which is a really good idea, we can use Amazon

155
00:11:45,232 --> 00:11:49,056
elastic container registry which has private image

156
00:11:49,088 --> 00:11:53,350
replication which can be cross region or cross account.

157
00:11:53,800 --> 00:11:57,876
I use third party container registry tools

158
00:11:58,068 --> 00:12:01,796
that generates the call from my pipelines and deploy

159
00:12:01,828 --> 00:12:05,032
them into my AWS infrastructure in both regions at the same

160
00:12:05,086 --> 00:12:11,230
time. So that's another option for

161
00:12:11,840 --> 00:12:15,880
data replication. This is also a complicated topic

162
00:12:16,040 --> 00:12:19,996
because we have heard about this things

163
00:12:20,018 --> 00:12:23,696
is the cap theorem that states that we can have the three we

164
00:12:23,718 --> 00:12:27,324
can have consistency, availability and partition tolerance

165
00:12:27,372 --> 00:12:31,936
at the same time and we need to choose two only and

166
00:12:31,958 --> 00:12:35,604
decide which we select depending on our

167
00:12:35,642 --> 00:12:38,496
needs. So when we go for multiregion,

168
00:12:38,688 --> 00:12:42,208
the one that's harder to achieve is consistency due

169
00:12:42,224 --> 00:12:45,300
to the long distance between the services I have

170
00:12:45,370 --> 00:12:49,604
already mentioned that S

171
00:12:49,642 --> 00:12:54,120
three has multiregion replication. That's the simple storage service

172
00:12:54,270 --> 00:12:59,128
or buckets or that usually call them. This replication

173
00:12:59,304 --> 00:13:02,700
is one way or two way, continuous and

174
00:13:02,770 --> 00:13:05,964
things replication can also be applied as subset of

175
00:13:06,002 --> 00:13:07,980
items inside the bucket.

176
00:13:10,580 --> 00:13:14,652
For non relational databases like DynamoDB,

177
00:13:14,796 --> 00:13:18,540
it has a global structure, has multi writer capabilities,

178
00:13:18,620 --> 00:13:22,144
will detect the changes and replicate them in other

179
00:13:22,182 --> 00:13:25,816
regions. For cachet, we have elastic cachet.

180
00:13:25,868 --> 00:13:29,284
For Redis, it offers a global data store to

181
00:13:29,322 --> 00:13:33,504
create fully managed, fast, reliable and secure cross

182
00:13:33,552 --> 00:13:36,920
region replica. For redis caches and databases,

183
00:13:37,980 --> 00:13:41,592
and for relational databases such

184
00:13:41,646 --> 00:13:45,400
as Aurora,

185
00:13:48,000 --> 00:13:51,196
the cluster is in one region is designated as the

186
00:13:51,218 --> 00:13:54,344
writer, and then we have secondary

187
00:13:54,392 --> 00:13:58,524
regions that are designated as read copies or

188
00:13:58,562 --> 00:14:01,964
read replicas. While only one instance can process the writers,

189
00:14:02,012 --> 00:14:05,388
our MySQL supports write forwarding.

190
00:14:05,484 --> 00:14:09,356
That's a feature that will forward write queries from a secondary region endpoint

191
00:14:09,388 --> 00:14:13,036
to the primary region. To simplify the logic in application

192
00:14:13,158 --> 00:14:17,392
code, logical replication, which utilizes

193
00:14:17,456 --> 00:14:21,364
a database engine built in replication technology,

194
00:14:21,482 --> 00:14:25,104
can be set up for Amazon RDS for Mariadebe,

195
00:14:25,152 --> 00:14:28,464
MySQL, Oracle PostgreSQL

196
00:14:28,512 --> 00:14:32,644
and Aurora database. This means that a cross vision red replica

197
00:14:32,692 --> 00:14:36,692
will receive and process chance from the writer in the primary

198
00:14:36,756 --> 00:14:40,444
region. This will make local reads faster and

199
00:14:40,482 --> 00:14:44,124
can reduce data loss and recovery times in the case of a disaster by being

200
00:14:44,162 --> 00:14:46,380
promoted to a standalone instance.

201
00:14:47,440 --> 00:14:50,876
This technology can also be used to replicate data to

202
00:14:50,898 --> 00:14:55,068
a resource outside an Amazon RDS, like an EC two instance,

203
00:14:55,244 --> 00:14:58,080
an on premise server, or even a data lake.

204
00:14:59,780 --> 00:15:03,184
Third, but not last, we have

205
00:15:03,222 --> 00:15:07,200
application management. This means that that

206
00:15:07,270 --> 00:15:10,756
bigger part side of the service that has to be

207
00:15:10,778 --> 00:15:15,584
taken into account. For example DevOps.

208
00:15:15,712 --> 00:15:19,816
I think it's important to plan what CI CD tools are we going to

209
00:15:19,838 --> 00:15:23,000
use in order to deploy all of this infrastructure,

210
00:15:23,740 --> 00:15:27,284
whether it's AWS core pipeline, GitLab CI

211
00:15:27,332 --> 00:15:30,744
or Jenkins pipelines will need to be configured

212
00:15:30,792 --> 00:15:34,156
to assure this double deployment, but at

213
00:15:34,178 --> 00:15:37,740
the same time deploying first to one region and then to other

214
00:15:37,890 --> 00:15:41,116
to the other while the primary

215
00:15:41,148 --> 00:15:44,896
is working isn't as complicated as it seems.

216
00:15:45,078 --> 00:15:48,300
Working with variable files for each region and environment

217
00:15:48,380 --> 00:15:51,932
is a really good idea. I mostly use terraform,

218
00:15:52,076 --> 00:15:55,940
which is really solid and allow us to review before we apply

219
00:15:56,010 --> 00:15:59,156
changes to

220
00:15:59,178 --> 00:16:03,936
the infrastructure. But AWS has cloudformation

221
00:16:04,048 --> 00:16:07,496
that's also really solid and allow us to

222
00:16:07,518 --> 00:16:10,840
create and delete stacks and update them across

223
00:16:10,910 --> 00:16:14,552
multiple regions and multiple accounts with one simple

224
00:16:14,686 --> 00:16:18,856
template obviously providing the corresponding

225
00:16:18,888 --> 00:16:22,190
variables. Now,

226
00:16:22,720 --> 00:16:25,950
depending on the architecture of our service,

227
00:16:26,560 --> 00:16:29,752
if we use the coupled applications,

228
00:16:29,816 --> 00:16:34,400
we will need an event manager we have Eventbridge.

229
00:16:35,300 --> 00:16:39,040
This will help us provide a notification service across regions.

230
00:16:39,780 --> 00:16:43,904
Eventbridge is serverless and we can use cross region

231
00:16:43,952 --> 00:16:47,968
routing to interconnect messages between the resources.

232
00:16:48,144 --> 00:16:51,510
If you rely on pubsoft messaging like

233
00:16:53,000 --> 00:16:56,888
it can work with multiple destinations, so you can send messages to

234
00:16:56,894 --> 00:17:00,840
a central SQSQ that process

235
00:17:00,910 --> 00:17:05,800
orders going multi region application finally,

236
00:17:05,950 --> 00:17:09,500
to maintain visibility and observability

237
00:17:09,840 --> 00:17:12,952
over an application deployed across multiple regions

238
00:17:13,096 --> 00:17:16,600
and accounts that can generate a lot of resources,

239
00:17:16,760 --> 00:17:20,484
you can create a trusted advisor dashboard, an operation

240
00:17:20,552 --> 00:17:24,412
dashboard that can be done with system manager

241
00:17:24,476 --> 00:17:27,776
Explorer. This operation dashboard offer a unified view

242
00:17:27,798 --> 00:17:31,072
of resources like easy to cloud

243
00:17:31,126 --> 00:17:35,196
watch AWS config data, and you can combine

244
00:17:35,228 --> 00:17:39,216
the metadata with a master latina to create a

245
00:17:39,238 --> 00:17:43,396
multiregion and multi account inventory with

246
00:17:43,418 --> 00:17:46,100
a good view of all of the resources.

247
00:17:50,460 --> 00:17:54,196
So you have heard me talk about all of these resources,

248
00:17:54,388 --> 00:17:57,700
and while I don't want to sound like an AWS evangelist,

249
00:17:57,780 --> 00:18:01,420
I think it's important to know that these options exist.

250
00:18:01,760 --> 00:18:05,372
Each cloud has similar resources and alternatives to build

251
00:18:05,506 --> 00:18:07,790
a fault tolerant multiregion service.

252
00:18:08,560 --> 00:18:12,160
It's hard, but it's possible, and the outcome

253
00:18:12,500 --> 00:18:15,772
of the peace of mind it brings when disaster

254
00:18:15,836 --> 00:18:19,724
happens is something to take into consideration when designing

255
00:18:19,772 --> 00:18:22,210
or updating a service or an application.

256
00:18:24,040 --> 00:18:29,312
It has bring me a lot of solutions

257
00:18:29,376 --> 00:18:34,388
and help me to provide

258
00:18:34,474 --> 00:18:38,372
better architecture for my projects so

259
00:18:38,426 --> 00:18:41,510
well. Thank you for listening and I hope this information

260
00:18:42,040 --> 00:18:45,380
allows you to reinvent and think

261
00:18:45,530 --> 00:18:48,890
for better architecture for better solutions. Ask me. Thank you.

