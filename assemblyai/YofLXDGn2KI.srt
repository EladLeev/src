1
00:00:23,770 --> 00:00:27,602
Everyone. I'm Shakar from ground cover and I'll be talking about cloud native

2
00:00:27,666 --> 00:00:29,720
observability at scale today.

3
00:00:31,050 --> 00:00:34,594
A little about me I am the co founder and CEO

4
00:00:34,642 --> 00:00:37,926
of ground Cover. I have many years of experience as an

5
00:00:37,948 --> 00:00:41,574
engineer and an R D leader and during the different

6
00:00:41,612 --> 00:00:45,174
positions I've being in, I've also been responsible many

7
00:00:45,212 --> 00:00:48,438
times for creating and maintaining the observability stack at the

8
00:00:48,444 --> 00:00:52,394
companies I've worked with, which is part of the motivation for setting

9
00:00:52,442 --> 00:00:56,490
up and creating ground cover, which is a company that reinvents

10
00:00:56,650 --> 00:01:00,302
Kubernetes application monitoring before

11
00:01:00,356 --> 00:01:04,386
talking about anything, I just wanted to set the ground about the

12
00:01:04,408 --> 00:01:08,082
three pillars of observability. They start out with

13
00:01:08,216 --> 00:01:11,102
the most bottom layer of logs or log management,

14
00:01:11,166 --> 00:01:14,050
which most these know and use today in production.

15
00:01:14,470 --> 00:01:18,210
The layer on top is infrastructure monitoring. Basically figuring

16
00:01:18,290 --> 00:01:22,578
out is your infrastructure healthy and is it healthy enough to host your applications

17
00:01:22,674 --> 00:01:27,014
in production? And the upper layer, and perhaps the most

18
00:01:27,132 --> 00:01:30,858
intricate one and most related to the business you're trying to create,

19
00:01:30,944 --> 00:01:34,294
is the application monitoring or APM application performance

20
00:01:34,342 --> 00:01:37,514
monitoring solutions. APM is super

21
00:01:37,552 --> 00:01:40,694
critical to monitoring what your business is trying to achieve,

22
00:01:40,742 --> 00:01:44,206
since it correlates really deeply with the targets you

23
00:01:44,228 --> 00:01:46,640
set for yourself and for your customers.

24
00:01:47,330 --> 00:01:51,386
Just to describe two of the critical missions APM usually performs.

25
00:01:51,498 --> 00:01:55,246
One of them is trace captures, actually capturing the behavior of the

26
00:01:55,268 --> 00:01:58,770
API driven system. You're actually burdening production. Most companies

27
00:01:58,840 --> 00:02:02,626
today are based on a microservices architecture which is

28
00:02:02,728 --> 00:02:06,006
heavily app driven, and by capturing the

29
00:02:06,028 --> 00:02:08,978
different traces between these microservices,

30
00:02:09,154 --> 00:02:13,142
teams can troubleshoot, figure out where things starting to break or

31
00:02:13,196 --> 00:02:16,834
behave differently than expected. And the other one is highly

32
00:02:16,882 --> 00:02:20,230
related to the SLOS the business is trying to maintain.

33
00:02:20,390 --> 00:02:23,606
And that's application metrics or golden signals.

34
00:02:23,798 --> 00:02:27,514
In these application metrics you will find things like throughput or

35
00:02:27,552 --> 00:02:31,434
requests per second, or error rates or latencies

36
00:02:31,482 --> 00:02:34,906
of the different APIs which measure how fast or slow

37
00:02:34,938 --> 00:02:38,810
your application is actually doing its task

38
00:02:38,890 --> 00:02:42,746
facing your users I'm not going to dive

39
00:02:42,778 --> 00:02:46,378
in too deeply about why APM is so important, but this

40
00:02:46,404 --> 00:02:50,030
is a quote from the Google SRE book just saying that if you could measure

41
00:02:50,110 --> 00:02:53,486
only four metrics about what your user facing

42
00:02:53,518 --> 00:02:57,122
system is actually doing, you should focus on those four golden signals,

43
00:02:57,266 --> 00:03:00,486
since they can highly predict if something is starting to

44
00:03:00,508 --> 00:03:04,022
drift or break in your production. And that only

45
00:03:04,076 --> 00:03:07,946
goes to say how important an APM is in the

46
00:03:07,968 --> 00:03:12,410
stack that you're maintaining inside the company with regards to observability.

47
00:03:13,470 --> 00:03:16,698
So if APM is so important,

48
00:03:16,784 --> 00:03:19,974
it must be adopted really well in the industry,

49
00:03:20,022 --> 00:03:23,162
right? But reality actually says completely different.

50
00:03:23,216 --> 00:03:26,890
I mean, looking at statistics, slug management solutions

51
00:03:26,970 --> 00:03:30,926
are highly adopted in the industry. I mean,

52
00:03:31,028 --> 00:03:34,974
with almost 70% of teams actually using some kind of log management

53
00:03:35,022 --> 00:03:38,402
solution. Infrastructure monitoring not following too far

54
00:03:38,456 --> 00:03:41,970
behind, with almost 60% of teams using

55
00:03:42,120 --> 00:03:45,906
some ways to monitor their infrastructure. Yet application monitoring,

56
00:03:45,938 --> 00:03:49,270
or APM, is clearly under adopted with only

57
00:03:49,340 --> 00:03:53,446
22% of the population actually using an

58
00:03:53,468 --> 00:03:58,726
APM solution of some kind. And it

59
00:03:58,748 --> 00:04:02,794
raises the question of why this is happening. I mean, if APM is so

60
00:04:02,832 --> 00:04:06,294
important, why is it so under adopted in the industry

61
00:04:06,342 --> 00:04:10,538
as we know it? And to understand the

62
00:04:10,704 --> 00:04:13,914
answer to this specific question, we have to dig much deeper

63
00:04:13,962 --> 00:04:17,582
into what an APM is and how it is built. There's many

64
00:04:17,636 --> 00:04:21,498
reasons behind why apms today are under adopted.

65
00:04:21,594 --> 00:04:25,870
But in this talk we're going to focus on one, one specific and painful

66
00:04:26,030 --> 00:04:30,290
answer to this question. And it is the final actual

67
00:04:30,440 --> 00:04:34,014
understanding that apms don't scale well with modern

68
00:04:34,062 --> 00:04:37,800
architectures. The reason that they don't scale well, just to

69
00:04:38,730 --> 00:04:42,038
jump for a second all the way through to the final understanding of

70
00:04:42,044 --> 00:04:45,826
what we're trying to say, is that they stored tons

71
00:04:45,858 --> 00:04:49,062
of irrelevant data just to get you the little

72
00:04:49,116 --> 00:04:52,006
insight you need about what's actually going on in production.

73
00:04:52,198 --> 00:04:55,322
Monitoring so much data basically turns cost to be

74
00:04:55,376 --> 00:04:58,666
unbearable. So teams can't really scale as their business is

75
00:04:58,688 --> 00:05:01,886
growing and their customer base is growing. Can't really scale with

76
00:05:01,908 --> 00:05:05,230
the APM solutions and maintain them and use them in production.

77
00:05:05,970 --> 00:05:09,022
But another question is starting

78
00:05:09,076 --> 00:05:10,720
to emerge here.

79
00:05:12,130 --> 00:05:15,854
How did we get here? How did we get into a state where an APM

80
00:05:15,902 --> 00:05:19,266
solution is storing tons of irrelevant data just to give me the

81
00:05:19,288 --> 00:05:22,962
little information I need to monitor my production and

82
00:05:23,016 --> 00:05:26,770
to understand that we have to kind of go back in time,

83
00:05:26,840 --> 00:05:29,910
ten or 15 years, back to when apms started

84
00:05:29,980 --> 00:05:34,022
as they are today. The solutions dominating the APM industry today

85
00:05:34,156 --> 00:05:38,338
have been formed over a decade ago, and these are based on

86
00:05:38,364 --> 00:05:41,820
a centralized architecture, which we're going to talk about in a second.

87
00:05:42,430 --> 00:05:46,650
And the tale of these centralized architectures and the architectures

88
00:05:47,230 --> 00:05:50,614
decisions the APM vendors made over a decade ago

89
00:05:50,752 --> 00:05:54,750
have led us to the point where we are today, where apms just don't fit

90
00:05:54,820 --> 00:05:58,270
to the current modern scale of microservices architectures.

91
00:05:59,730 --> 00:06:03,262
When things started out basically in observability, you had

92
00:06:03,316 --> 00:06:06,994
an infrastructure agent, which is usually an external problems of

93
00:06:07,032 --> 00:06:10,722
some sort, monitoring the infrastructure as these bedding of

94
00:06:10,776 --> 00:06:14,194
your running applications in production, figuring out what the infrastructure is

95
00:06:14,232 --> 00:06:18,786
doing, provider metrics about the infrastructure. But when APM

96
00:06:18,898 --> 00:06:22,706
providers started to try and monitor applications of what these applications

97
00:06:22,738 --> 00:06:26,470
are doing, they had to turn into a different solution, which was

98
00:06:26,620 --> 00:06:30,438
much more heavily based on instrumentation

99
00:06:30,534 --> 00:06:34,374
inside the code. And instrumentation means that to monitor

100
00:06:34,422 --> 00:06:37,514
the application I gave, to monitor it from within,

101
00:06:37,632 --> 00:06:41,610
I have to give the R and D teams or the developers

102
00:06:42,030 --> 00:06:45,470
some kind of SDK that they can instrument into their code,

103
00:06:45,540 --> 00:06:48,762
basically integrate into their code. And this SDK

104
00:06:48,826 --> 00:06:52,286
would allow me to monitor the application from within, running as part of the

105
00:06:52,308 --> 00:06:56,126
application, giving me the opportunity to suddenly

106
00:06:56,158 --> 00:06:59,886
measure things like a latency of a specific API or the error

107
00:06:59,918 --> 00:07:03,346
rate on a specific API, things that I couldn't have done with

108
00:07:03,368 --> 00:07:06,200
an external agent up until that point.

109
00:07:07,130 --> 00:07:11,954
But what exactly is instrumentation?

110
00:07:12,002 --> 00:07:15,810
I mean, what does it actually mean? This is a sketch of a typical microservice

111
00:07:15,890 --> 00:07:19,426
kind of behavior. A production

112
00:07:19,458 --> 00:07:23,034
system based on this architectures would be very API driven. You would get some

113
00:07:23,072 --> 00:07:25,930
kind of request from the outside world, from the user,

114
00:07:26,350 --> 00:07:30,490
some microservice would handle it and pass it on down into

115
00:07:30,640 --> 00:07:33,886
these different microservices inside your production, taking care of

116
00:07:33,908 --> 00:07:38,014
the different business logics you're trying to create, eventually returning some

117
00:07:38,052 --> 00:07:41,498
kind of response to the actual user that triggered

118
00:07:41,514 --> 00:07:45,602
this entire flow. But instrumentation means that you're actually

119
00:07:45,656 --> 00:07:50,146
injecting or inserting a

120
00:07:50,168 --> 00:07:53,790
small monitoring code that wraps this entire API handling

121
00:07:53,870 --> 00:07:57,346
behavior inside each of the microservices. For example, to monitor

122
00:07:57,378 --> 00:08:00,726
the latency of a specific API, I would have to wrap it with

123
00:08:00,748 --> 00:08:04,982
an external monitoring code given to me by the observability vendor to

124
00:08:05,036 --> 00:08:08,874
actually time the start and the end of

125
00:08:08,912 --> 00:08:12,026
the handling of, say, an HTTP request flowing into my

126
00:08:12,048 --> 00:08:16,010
web server. But this specific

127
00:08:16,160 --> 00:08:19,866
choice of actually using instrumentation is part of the reason we

128
00:08:19,888 --> 00:08:22,574
got to the point we are at today. I mean,

129
00:08:22,612 --> 00:08:26,202
when APM vendors chose to invest in SDK

130
00:08:26,266 --> 00:08:29,066
and instrumentation of code by the developer teams,

131
00:08:29,178 --> 00:08:32,678
basically they did it since this was the best technology to achieve

132
00:08:32,714 --> 00:08:36,340
their task over a decade ago. This also

133
00:08:37,350 --> 00:08:41,826
creates a lot of different meanings into

134
00:08:41,848 --> 00:08:45,822
what the architecture actually looks like. If I'm using an instrumentation

135
00:08:45,966 --> 00:08:49,446
and I'm inserting my own code into my

136
00:08:49,468 --> 00:08:53,014
user's application code, it has to be very simple and

137
00:08:53,052 --> 00:08:56,760
has to be very fast. And the reason for it is that, for example,

138
00:08:57,470 --> 00:09:01,418
you wouldn't expect your web server efficiency to decrease by 50%

139
00:09:01,504 --> 00:09:04,454
just because you're starting to monitoring it with an APM,

140
00:09:04,502 --> 00:09:07,754
right. It means that the

141
00:09:07,792 --> 00:09:11,258
code I'm wrapping my

142
00:09:11,344 --> 00:09:14,686
actual application with this instrumentation code, has to be very

143
00:09:14,788 --> 00:09:18,750
fast to not create bottlenecks or slow down my applications.

144
00:09:19,250 --> 00:09:23,694
This means it has to be very simple and create very simple decisions

145
00:09:23,822 --> 00:09:27,282
and run very simple algorithms that basically make it

146
00:09:27,336 --> 00:09:30,802
efficient, fast, not error prone, to not create

147
00:09:30,856 --> 00:09:34,686
any bugs or crashes that can also endanger

148
00:09:34,718 --> 00:09:38,630
my application. And this means that

149
00:09:38,700 --> 00:09:42,034
eventually, instead of putting a lot of weight

150
00:09:42,082 --> 00:09:45,314
into the sophistication of this instrumentation

151
00:09:45,362 --> 00:09:48,826
code, I'm basically taking all the responsibility back to

152
00:09:48,848 --> 00:09:53,126
the APM vendor. This is the basic architectures behind the centralized approach

153
00:09:53,158 --> 00:09:56,540
that APM vendors chose over a decade ago, which means

154
00:09:57,230 --> 00:10:00,426
let's make the SDK as simple as

155
00:10:00,448 --> 00:10:05,326
possible. It will be fast, it will be free

156
00:10:05,348 --> 00:10:09,386
of errors, it will be very simple to understand and let it sample raw

157
00:10:09,418 --> 00:10:13,038
data and just send it back to the APM vendor. And all the crunching and

158
00:10:13,044 --> 00:10:16,974
all the complex algorithms and all the intricate

159
00:10:17,022 --> 00:10:20,706
decisions we have to make as an APM provider would happen on

160
00:10:20,728 --> 00:10:24,610
the backend side of the APM vendor. Things like capturing specific

161
00:10:24,680 --> 00:10:28,386
traces, things like creating span based metrics, these golden

162
00:10:28,418 --> 00:10:31,990
signals we're talking about, we're going to create them from the actual raw data

163
00:10:32,060 --> 00:10:35,394
sampled from the customer side on the AMPM vendors

164
00:10:35,442 --> 00:10:38,330
backend side. But this decision,

165
00:10:39,470 --> 00:10:43,370
even though very logical at the time, created a major

166
00:10:43,440 --> 00:10:47,306
depth towards scale, and this is part of what is starting to

167
00:10:47,328 --> 00:10:50,842
shift currently in the industry. Basically what it says.

168
00:10:50,976 --> 00:10:54,686
It says you have to store raw data to get insights. So if

169
00:10:54,708 --> 00:10:58,334
we look at all the green rectangles here as healthy request and

170
00:10:58,372 --> 00:11:02,154
the red one as a faulty request, you would actually store these spans

171
00:11:02,202 --> 00:11:05,474
of the different requests when you wanted most

172
00:11:05,512 --> 00:11:08,754
of the time, just these digested insights around

173
00:11:08,792 --> 00:11:12,082
them, like the golden signals, the metrics that depict their

174
00:11:12,136 --> 00:11:15,998
behavior in production. You can imagine that if you have a million requests

175
00:11:16,014 --> 00:11:18,774
per second on a Kubernetes cluster, for example,

176
00:11:18,972 --> 00:11:22,198
if you're a company working at high scale, you wouldn't want

177
00:11:22,204 --> 00:11:25,766
to store too many spans and pay for their storage just to

178
00:11:25,868 --> 00:11:29,862
get things like the latency on your different microservices

179
00:11:29,926 --> 00:11:33,354
and things like that. That would be the entry point to

180
00:11:33,392 --> 00:11:37,020
figuring out if your production is doing okay or not.

181
00:11:37,390 --> 00:11:41,094
And the other one is that by making simple decisions

182
00:11:41,142 --> 00:11:44,574
at the instrumentation code at the SDK side, it will also mean

183
00:11:44,612 --> 00:11:48,142
you would store data at equal depth. Meaning that, for example,

184
00:11:48,196 --> 00:11:52,490
if I want to make a decision of what should I store in different cases,

185
00:11:52,650 --> 00:11:56,314
this wouldn't happen with a common APM today. So for example,

186
00:11:56,372 --> 00:12:00,450
imagine I want to get the payload of the faulty red request here.

187
00:12:00,600 --> 00:12:04,322
Since I want to troubleshoot with this payload, it will usually mean that

188
00:12:04,376 --> 00:12:08,514
I would have to store payloads for all requests or for none of the requests.

189
00:12:08,642 --> 00:12:11,878
But clearly that's not reality, right? I mean, not everything

190
00:12:11,964 --> 00:12:16,070
is equally important. If that faulty request comes

191
00:12:16,140 --> 00:12:19,482
one in 10,000 requests you would gave wanted to get as much

192
00:12:19,536 --> 00:12:24,314
information as you could on this specific request. Like know

193
00:12:24,352 --> 00:12:28,362
logs from the different pods communicating around this request or

194
00:12:28,416 --> 00:12:31,546
other requests flowing through the system at the time to figure out if there's some

195
00:12:31,568 --> 00:12:35,194
kind of interdependency. But on the green healthy requests,

196
00:12:35,242 --> 00:12:38,862
you probably want to capture much less and pay much less

197
00:12:38,916 --> 00:12:42,400
for all this data being stored at the APM vendor side.

198
00:12:43,970 --> 00:12:47,690
And this trade off is exactly what we define as the visibility indepth

199
00:12:47,770 --> 00:12:51,486
cost tradeoff. It means that if you want to go deeper in the cases

200
00:12:51,518 --> 00:12:54,594
you care about, like for example getting as much

201
00:12:54,632 --> 00:12:57,686
information as you can about that faulty request, you would

202
00:12:57,708 --> 00:13:01,062
have to pay increasingly high

203
00:13:01,116 --> 00:13:04,322
amount of pay by storing

204
00:13:04,466 --> 00:13:08,562
increasing amount of data across your system. Since you can't really decide

205
00:13:08,626 --> 00:13:12,198
what to store and what not to store given the different cases

206
00:13:12,374 --> 00:13:16,134
you care about in production. And we all know that from intuitively.

207
00:13:16,182 --> 00:13:19,610
Every developer knows that from the different experiences

208
00:13:20,050 --> 00:13:24,042
he or she had in handling

209
00:13:24,106 --> 00:13:27,610
some kind of observability stack in their production environment.

210
00:13:27,690 --> 00:13:31,038
We know it very well from logs, right? We store,

211
00:13:31,124 --> 00:13:34,414
say warning logs level and up. Since we couldn't

212
00:13:34,462 --> 00:13:38,158
store every trace, debug or info messages flowing

213
00:13:38,174 --> 00:13:41,698
through the production, it doesn't make sense, right? But imagine that you could

214
00:13:41,784 --> 00:13:45,314
get the info or traces logs from the web

215
00:13:45,352 --> 00:13:48,830
server on 10 seconds around any faulty request.

216
00:13:48,910 --> 00:13:53,478
Wouldn't you want to do that? I mean, clearly there's different depth of information

217
00:13:53,564 --> 00:13:57,014
you would want to get in different cases. We also know it from traces really

218
00:13:57,052 --> 00:14:01,006
well. I mean, observability vendors or APM vendors allow us to randomly

219
00:14:01,058 --> 00:14:04,630
sample our production to reduce the volume of data we capture.

220
00:14:04,790 --> 00:14:08,294
That would mean we would capture, say one in 100 traces,

221
00:14:08,422 --> 00:14:12,206
but that's not exactly what we want. We want to capture the specific traces we

222
00:14:12,228 --> 00:14:16,106
care about, like the ones that take ten x the time of other traces,

223
00:14:16,218 --> 00:14:19,630
and not just randomly sampling the production.

224
00:14:21,490 --> 00:14:25,166
So centralized architectures is being replaced

225
00:14:25,198 --> 00:14:28,526
today by something which we call edge

226
00:14:28,558 --> 00:14:32,530
observability. It's a terminology that's starting to

227
00:14:32,680 --> 00:14:35,810
be very common in modern solutions today.

228
00:14:35,960 --> 00:14:39,954
Basically it says that the centralized architecture

229
00:14:40,002 --> 00:14:43,718
has reached a point where it doesn't make sense anymore, it can't scale well.

230
00:14:43,884 --> 00:14:47,674
It doesn't make sense to maintain and pay for the data being stored by this

231
00:14:47,712 --> 00:14:51,782
approach. And basically the weight

232
00:14:51,846 --> 00:14:55,446
of the decision making and the sophistication is being moved

233
00:14:55,478 --> 00:14:58,986
from these observability vendor side to the actual agent

234
00:14:59,088 --> 00:15:02,590
or SDK, running at the edge, close to where the data

235
00:15:02,660 --> 00:15:06,782
is. And that's the future as we see it. And before trying

236
00:15:06,836 --> 00:15:14,142
to kind of describe what ground cover does in this specific approach

237
00:15:14,206 --> 00:15:18,210
of how to actually monitor with edge observability,

238
00:15:18,550 --> 00:15:22,340
I want to talk a bit about EVPF as an enabler to all that.

239
00:15:22,870 --> 00:15:26,834
EVPF is a technology that's basically a revolutionary

240
00:15:26,882 --> 00:15:30,534
technology, being more and

241
00:15:30,572 --> 00:15:34,198
more prominent in the last couple of years.

242
00:15:34,364 --> 00:15:37,814
It's a very interesting technology for many different

243
00:15:37,852 --> 00:15:41,766
use cases, from networking to security, to monitoring and observability.

244
00:15:41,958 --> 00:15:45,322
Basically what it says, without going too deep, is that you can run

245
00:15:45,376 --> 00:15:49,434
complex business logs inside the Linux kernel, and that

246
00:15:49,472 --> 00:15:53,390
allows you for monitoring, for example, to monitor all the user space,

247
00:15:53,460 --> 00:15:57,582
all the applications running at the user space, without actually

248
00:15:57,636 --> 00:16:01,962
being part of the code. You can, for example, get things like golden signals

249
00:16:02,026 --> 00:16:05,474
or things that you would expect from an APM that had to be very

250
00:16:05,512 --> 00:16:09,374
tightly integrated into the code itself by just running an external

251
00:16:09,422 --> 00:16:13,380
agent at the kernel level and capturing the same data.

252
00:16:13,830 --> 00:16:16,600
So EVPF is a really interesting technology.

253
00:16:16,970 --> 00:16:20,850
But these reason it's so interesting to edge observability

254
00:16:21,010 --> 00:16:25,126
is that it's suddenly allowed to achieve what an APM would

255
00:16:25,148 --> 00:16:28,726
have achieved only with instrumentation deeply

256
00:16:28,758 --> 00:16:32,282
into the code. Suddenly with an out of band agent that

257
00:16:32,336 --> 00:16:36,026
just runs alongside the application without being part

258
00:16:36,048 --> 00:16:39,740
of it, that suddenly opens up two interesting

259
00:16:40,750 --> 00:16:44,814
use cases or ways to think about what we can do. It means

260
00:16:44,852 --> 00:16:48,558
that everything we do inside this agent wouldn't create an overhead on

261
00:16:48,564 --> 00:16:52,314
the application. So for example, if we make some kind of complex decision

262
00:16:52,442 --> 00:16:55,714
or run some kind of complex algorithm inside this agent,

263
00:16:55,832 --> 00:17:00,014
it wouldn't necessarily mean directly that we may slow

264
00:17:00,062 --> 00:17:03,794
down the performance of these application we're trying to monitor. And that

265
00:17:03,832 --> 00:17:07,238
means that we can make distributed decision making

266
00:17:07,404 --> 00:17:10,520
in this agent, which is much more complicated than before.

267
00:17:10,970 --> 00:17:15,206
If before we had to keep that SDK as simple as possible,

268
00:17:15,388 --> 00:17:19,122
suddenly we can put much more sophistication

269
00:17:19,186 --> 00:17:22,506
into this agent, since it's running completely out of

270
00:17:22,528 --> 00:17:26,438
band and not impacting the application it's trying to monitor.

271
00:17:26,614 --> 00:17:29,946
And this is exactly where things started to get really interesting and

272
00:17:29,968 --> 00:17:33,438
what you can do. So if the

273
00:17:33,444 --> 00:17:37,054
first thing we talked about was I don't want to store

274
00:17:37,092 --> 00:17:40,494
raw data and pay for so much raw data, to get

275
00:17:40,692 --> 00:17:44,210
a simple ingested metric like latency on my specific

276
00:17:44,280 --> 00:17:47,938
APIs, we can suddenly move all these sophistication into the

277
00:17:47,944 --> 00:17:51,202
EBPF agent. Imagine an API flowing into

278
00:17:51,256 --> 00:17:53,300
your application at a very high rate.

279
00:17:53,990 --> 00:17:58,066
Instead of storing or sampling these spans and sending them back to the APM

280
00:17:58,098 --> 00:18:01,222
vendor. We can now create the metrics inside

281
00:18:01,356 --> 00:18:04,866
the EBPF agent on the fly without storing the spans

282
00:18:05,058 --> 00:18:08,310
or tracking them out of the node or the actual host

283
00:18:09,150 --> 00:18:12,362
at any time. And that allows us to store so much less

284
00:18:12,416 --> 00:18:16,534
data. To create the actual insights, teams need to monitor production

285
00:18:16,582 --> 00:18:19,210
like golden signals and application metrics.

286
00:18:19,790 --> 00:18:23,514
Another interesting approach allows us also to create variant depth

287
00:18:23,562 --> 00:18:27,226
capturing. So imagine I have again this API flowing

288
00:18:27,258 --> 00:18:30,686
in at these high throughput into these application. I can

289
00:18:30,708 --> 00:18:34,074
decide to do very different stuff in different scenarios.

290
00:18:34,122 --> 00:18:37,854
For example, if there's a bad status code, let's imagine it's an HTTP

291
00:18:37,902 --> 00:18:41,298
API for a second. So if I get a had status code returning from the

292
00:18:41,304 --> 00:18:45,234
server like a 500, I may want to decide to capture these

293
00:18:45,272 --> 00:18:49,126
full payload of this specific request so I can troubleshoot and store the

294
00:18:49,148 --> 00:18:52,882
logs a few seconds around that request from the different participants

295
00:18:53,026 --> 00:18:57,618
that participated in this API call. But perhaps

296
00:18:57,714 --> 00:19:01,174
if it's a high latency event like an HTTP span suddenly

297
00:19:01,222 --> 00:19:05,386
taking ten x the usual time, I may decide to do

298
00:19:05,488 --> 00:19:10,074
different stuff. For example, I may want to stored other

299
00:19:10,112 --> 00:19:13,760
requests flowing to the server at the same time to figure out if there's specific

300
00:19:14,690 --> 00:19:18,186
API load from different other APIs on the server.

301
00:19:18,218 --> 00:19:21,966
At the same time, I may want to store the cpu usage of this specific

302
00:19:22,068 --> 00:19:26,334
HTTP server at a very high resolution at the time of the request

303
00:19:26,382 --> 00:19:30,926
to figure out if there was some kind of cpu spike that eventually caused

304
00:19:31,118 --> 00:19:34,766
this slow response. And it also opens

305
00:19:34,798 --> 00:19:38,246
up different behavior for the normal flow, right?

306
00:19:38,348 --> 00:19:41,586
In usual APIs in a common production

307
00:19:41,618 --> 00:19:45,734
environment, the normal flow is clearly very prominent and most

308
00:19:45,772 --> 00:19:49,142
spans are healthy and describe the normal case.

309
00:19:49,276 --> 00:19:52,554
So I may want to do something completely different. I may not

310
00:19:52,592 --> 00:19:55,914
want to store even payloads or logs or whatever

311
00:19:56,032 --> 00:19:59,386
at this specific situation and just sample 1%,

312
00:19:59,488 --> 00:20:02,890
say of the normal flow to just allow the users

313
00:20:02,970 --> 00:20:07,486
to see actual healthy spans and how they look in

314
00:20:07,508 --> 00:20:11,226
a normal flow. This variation opens

315
00:20:11,258 --> 00:20:14,882
up a lot of different ways to store

316
00:20:14,936 --> 00:20:18,354
data based on the different scenarios the user would care

317
00:20:18,392 --> 00:20:21,106
about or the development team will care about.

318
00:20:21,208 --> 00:20:25,138
And that breaks the trade off of storing too much information

319
00:20:25,224 --> 00:20:29,254
to create the little insights you need. You can figure out what

320
00:20:29,372 --> 00:20:32,774
scenarios you care about and store much more information about them,

321
00:20:32,812 --> 00:20:36,680
while storing much less information about other cases which are not that

322
00:20:37,050 --> 00:20:41,180
interested in figuring out the details about them.

323
00:20:42,030 --> 00:20:46,746
This may sound like theory of trying to take the

324
00:20:46,768 --> 00:20:50,394
centralized approach into the edge observability approach and

325
00:20:50,432 --> 00:20:53,598
do things differently to reduce costs and to make things much more

326
00:20:53,604 --> 00:20:56,814
scalable. But this is current reality and this is the current

327
00:20:56,852 --> 00:21:00,990
reality of ground cover and how we're built. As an APM vendor,

328
00:21:01,330 --> 00:21:05,902
we're based on exactly these two assumptions

329
00:21:05,966 --> 00:21:09,890
or approaches that kind of bothcentralized the way an APM is built.

330
00:21:09,960 --> 00:21:13,806
One is that we use an EVPF instrumentation instead of an SDK

331
00:21:13,838 --> 00:21:17,730
instrumentation inside the code. Basically what it means is that first we allow

332
00:21:17,880 --> 00:21:21,094
at can immediate time to value because we don't require any r and D

333
00:21:21,132 --> 00:21:24,680
efforts in the process integrating our solution into their code.

334
00:21:25,530 --> 00:21:29,046
But we also support this out of band deployment, which we

335
00:21:29,068 --> 00:21:32,822
just talked about, which allows us to take complex

336
00:21:32,886 --> 00:21:36,650
decision and create a sophisticated EBPF agent that can

337
00:21:36,800 --> 00:21:40,362
carry most of the load of these observability at the edge side where the data

338
00:21:40,416 --> 00:21:43,646
is actually at. And the other one is that

339
00:21:43,668 --> 00:21:47,310
we're creating these edge based algorithms to create

340
00:21:47,380 --> 00:21:50,686
metrics to sample the data smartly so they can be

341
00:21:50,708 --> 00:21:54,546
built for scale. So we can scale very well with production environments as

342
00:21:54,568 --> 00:21:57,998
they grow into hundreds and hundreds of microservices,

343
00:21:58,174 --> 00:22:02,114
breaking the trade offs of how deep we want to

344
00:22:02,152 --> 00:22:06,030
get these data in specific cases compared to the overall

345
00:22:06,190 --> 00:22:09,590
volume of raw data that would be captured to kind of

346
00:22:09,740 --> 00:22:13,106
describe the production and let users figure out if their production

347
00:22:13,138 --> 00:22:16,438
is doing well. This is a really interesting

348
00:22:16,524 --> 00:22:20,662
discussion, and we think the industry is definitely shifting

349
00:22:20,726 --> 00:22:24,022
from one approach to a completely new modern approach.

350
00:22:24,166 --> 00:22:29,034
We would love to answer any questions or keep

351
00:22:29,072 --> 00:22:32,830
talking about it in different discussions. We find this topic really interesting and important

352
00:22:32,900 --> 00:22:36,634
for the entire observability community. Feel free to join our slack

353
00:22:36,682 --> 00:22:40,558
and ping us at any time with questions or ideas you have

354
00:22:40,644 --> 00:22:45,534
or experiences you have from monitoring your production with

355
00:22:45,652 --> 00:22:49,086
the scale you're used to today. Also,

356
00:22:49,188 --> 00:22:52,894
feel free to contact me directly and thank

357
00:22:52,932 --> 00:22:55,990
you. It was a great, it, it was great to

358
00:22:56,060 --> 00:22:59,060
talk about this topic and share our thoughts with you. Thanks guys.

