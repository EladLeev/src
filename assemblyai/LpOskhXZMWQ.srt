1
00:00:27,010 --> 00:00:30,422
Hi, I'm Joe. Welcome to don't get out of bed

2
00:00:30,476 --> 00:00:33,986
for anything less than an SLO. I'm a software

3
00:00:34,018 --> 00:00:37,874
engineer at Grafana. I've been building and operating large distributed

4
00:00:37,922 --> 00:00:41,446
systems for nearly my whole career. I've been on call for

5
00:00:41,468 --> 00:00:45,030
those systems. I think there's great things about being on call.

6
00:00:45,100 --> 00:00:48,534
The people who are operating and fixing things usually

7
00:00:48,652 --> 00:00:51,920
know what to do because they've built the system.

8
00:00:52,370 --> 00:00:55,966
But some companies have things more together than others. I've been in

9
00:00:55,988 --> 00:00:59,226
some organizations where things are incredibly noisy

10
00:00:59,258 --> 00:01:03,474
and stressful, and I want to talk about a tool today that

11
00:01:03,512 --> 00:01:06,850
can help us improve that situation markedly.

12
00:01:07,590 --> 00:01:10,962
We're going to talk about what makes an on call situation

13
00:01:11,096 --> 00:01:14,514
bad and what sort of knobs we have to

14
00:01:14,552 --> 00:01:18,102
improve it. We'll talk about a particular tool called a service

15
00:01:18,156 --> 00:01:21,574
level objective, which helps you understand what really

16
00:01:21,612 --> 00:01:25,046
matters in your system and how to

17
00:01:25,148 --> 00:01:28,234
alert on that, so that the alerts that you're sending to people

18
00:01:28,272 --> 00:01:31,370
at three in the morning are really meaningful.

19
00:01:31,950 --> 00:01:36,682
They point to things that really have to be done and they

20
00:01:36,736 --> 00:01:40,842
explain sort of what's going on. What problems are people

21
00:01:40,896 --> 00:01:43,040
having that caused this alert to happen?

22
00:01:44,210 --> 00:01:47,434
Burnout is a big topic in software

23
00:01:47,482 --> 00:01:51,210
engineering these days. Tons of people in the industry

24
00:01:51,290 --> 00:01:55,620
experience burnout at some point in their career, and right now

25
00:01:56,070 --> 00:01:59,854
huge numbers of people are experiencing some symptoms of burnout.

26
00:01:59,982 --> 00:02:03,362
It kills careers. People go out to the woods to build log

27
00:02:03,416 --> 00:02:07,094
cabins when they leave, choose jobs. It really

28
00:02:07,132 --> 00:02:11,014
kills their teams and their organizations. Too much

29
00:02:11,052 --> 00:02:14,466
turnover leads to institutional knowledge walking out the door.

30
00:02:14,578 --> 00:02:17,726
No matter how good your system documentation is, you can't

31
00:02:17,858 --> 00:02:21,350
recover from huge turnover. So mitigating,

32
00:02:21,510 --> 00:02:24,982
preventing and curing

33
00:02:25,046 --> 00:02:29,142
to some degree, burnout is really important to software

34
00:02:29,206 --> 00:02:32,634
companies. Burnout comes from a lot of places,

35
00:02:32,682 --> 00:02:36,046
but some big external factors, factors that

36
00:02:36,068 --> 00:02:39,550
come from your job are unclear expectations,

37
00:02:40,130 --> 00:02:43,902
a lack of autonomy and direction, an inability

38
00:02:43,966 --> 00:02:47,138
to unplug from work and an inability to

39
00:02:47,224 --> 00:02:51,122
deliver meaningful work. And bad

40
00:02:51,176 --> 00:02:54,830
on call can affect all of those. There are unclear expectations

41
00:02:54,910 --> 00:02:58,422
about what am I supposed to do with an alert? Who's supposed to handle this?

42
00:02:58,476 --> 00:03:02,134
Is it meaningful if you're repeatedly getting paged at three

43
00:03:02,172 --> 00:03:06,002
in the morning, especially for minor things, you really can't relax

44
00:03:06,066 --> 00:03:09,526
and let go of work when it's time to be done. And if you're

45
00:03:09,558 --> 00:03:13,274
spending all day responding to especially

46
00:03:13,392 --> 00:03:17,094
useless things, youll don't ship anything, you don't commit

47
00:03:17,142 --> 00:03:20,734
code, you feel like you're just running around putting

48
00:03:20,772 --> 00:03:24,750
out fires and it's very frustrating and draining so

49
00:03:24,900 --> 00:03:28,778
bad alerts, poorly defined alerts, things that people don't

50
00:03:28,794 --> 00:03:32,158
understanding what to do about are huge contributors to

51
00:03:32,244 --> 00:03:36,194
burnout. And to improve that situation. We need to understand our

52
00:03:36,232 --> 00:03:40,034
systems better, understand what's important about them, and make sure

53
00:03:40,072 --> 00:03:43,940
that we're responding to those important things and not to

54
00:03:44,310 --> 00:03:47,926
minor things, underlying things that can be addressed as

55
00:03:47,948 --> 00:03:50,930
part of a normal work routine. A useful,

56
00:03:51,010 --> 00:03:54,454
good on call shift looks like having the right people on

57
00:03:54,492 --> 00:03:58,074
call for the right systems. When alerts happen,

58
00:03:58,192 --> 00:04:01,706
they're meaningful and they're actionable. They are

59
00:04:01,728 --> 00:04:05,114
for a real problem in the system, and there's something someone can do

60
00:04:05,152 --> 00:04:08,986
to address it. There's a great

61
00:04:09,088 --> 00:04:12,366
tool in the DevOps world that we can use to help make

62
00:04:12,388 --> 00:04:15,546
all of that happen, called service level objectives,

63
00:04:15,738 --> 00:04:19,550
and they help you define what's actually important about the system.

64
00:04:19,620 --> 00:04:22,958
You operations understand how to measure, choose important

65
00:04:23,044 --> 00:04:26,546
behaviors, and help youll make decisions based on

66
00:04:26,568 --> 00:04:31,010
those measurements. Is there a problem we need to respond to right now?

67
00:04:31,160 --> 00:04:34,594
Is there something we need to look at in the morning? Or is there something

68
00:04:34,632 --> 00:04:38,102
over time where we need to prioritize work to

69
00:04:38,156 --> 00:04:41,990
improve things sort of long term? How can we assess what problems

70
00:04:42,060 --> 00:04:44,200
we have and how serious they are?

71
00:04:46,090 --> 00:04:50,266
We split that into sort of two things here. There's a service level

72
00:04:50,368 --> 00:04:54,266
which is not about a microservice or a given set of little

73
00:04:54,368 --> 00:04:58,090
computers. It's about a system and

74
00:04:58,160 --> 00:05:02,350
the services that it provides to its users. What's the quality of service

75
00:05:02,420 --> 00:05:06,094
that we're giving people? And then an objective which

76
00:05:06,132 --> 00:05:09,790
says, what level of quality is good enough for this system,

77
00:05:09,940 --> 00:05:12,160
for our customers, for my team.

78
00:05:13,890 --> 00:05:17,566
So a service level is all about the quality of service you're

79
00:05:17,598 --> 00:05:21,474
providing to users and clients. To do that, you need to understand what

80
00:05:21,512 --> 00:05:25,154
users really want from that system and how

81
00:05:25,192 --> 00:05:28,040
you can measure whether they're getting what they want.

82
00:05:28,970 --> 00:05:32,402
So we use something called a service level indicator

83
00:05:32,546 --> 00:05:35,586
to help us identify what people want and whether they're

84
00:05:35,618 --> 00:05:39,322
getting it. We start with sort of a prose description. Can users sign

85
00:05:39,376 --> 00:05:43,366
in? Are they able to check out with the socks in their shopping

86
00:05:43,398 --> 00:05:47,142
cares? Are they able to run analytics queries

87
00:05:47,206 --> 00:05:50,666
that let our data scientists decide what we need to

88
00:05:50,688 --> 00:05:54,726
do next? Is the catalog popping

89
00:05:54,758 --> 00:05:57,546
up? Do we start with that?

90
00:05:57,568 --> 00:06:00,814
Pros. Then we figure out what metrics we have, or maybe that we need

91
00:06:00,852 --> 00:06:03,906
to generate that. Let us measure that,

92
00:06:04,088 --> 00:06:08,030
and then we do some math. It's not terribly complicated

93
00:06:08,110 --> 00:06:12,162
math to give us a number between zero and one,

94
00:06:12,296 --> 00:06:15,958
one being sort of the best quality output we could expect for a

95
00:06:15,964 --> 00:06:19,430
given measurement, and zero being everything is broken.

96
00:06:20,090 --> 00:06:23,894
Nothing is working right. Some really common

97
00:06:24,012 --> 00:06:27,922
indicators that you might choose are the ratio of successful

98
00:06:27,986 --> 00:06:31,674
requests to all requests that a service is receiving over some

99
00:06:31,712 --> 00:06:35,370
time. This is useful for an ecommerce application,

100
00:06:35,520 --> 00:06:39,890
a database query kind of system. You might have like a threshold

101
00:06:39,990 --> 00:06:43,166
measurement about data throughput being

102
00:06:43,268 --> 00:06:46,842
over some rate. You may know you're generating

103
00:06:46,906 --> 00:06:50,506
data at a certain rate and youll need to be processing

104
00:06:50,538 --> 00:06:53,966
it fast enough to keep up with that. And so you need

105
00:06:53,988 --> 00:06:57,586
to measure throughput to know if something's falling apart. Or you may want to

106
00:06:57,608 --> 00:07:00,914
use a percentile kind of threshold to say,

107
00:07:00,952 --> 00:07:05,034
for a given set of requests, the 99th percentile latency

108
00:07:05,102 --> 00:07:08,678
needs to be below some value, or my average latency needs to

109
00:07:08,684 --> 00:07:12,562
be above some value, some statistical threshold.

110
00:07:12,706 --> 00:07:17,154
These are all really common indicators. They're relatively easy to compute,

111
00:07:17,282 --> 00:07:19,918
relatively cheap to collect.

112
00:07:20,034 --> 00:07:23,782
Next, you need to set an objective. What level of quality is acceptable?

113
00:07:23,846 --> 00:07:27,210
And of course, only the highest quality will do,

114
00:07:27,280 --> 00:07:30,618
right? That's what we all want to provide, but we

115
00:07:30,624 --> 00:07:35,130
have to be a little more realistic about our target. To measure an objective,

116
00:07:35,290 --> 00:07:38,734
you choose two things. You choose a time range over which

117
00:07:38,772 --> 00:07:42,782
you want to measure. It's better to have a sort of moderate to long time

118
00:07:42,836 --> 00:07:45,358
range, like 28 days,

119
00:07:45,524 --> 00:07:49,410
seven days, than a really short one, like a day or a few minutes.

120
00:07:49,560 --> 00:07:52,834
You're getting too fine grained if you're trying to measure something like that.

121
00:07:52,952 --> 00:07:56,514
And then a percentage of your

122
00:07:56,552 --> 00:07:59,874
indicator that would be acceptable over that time range,

123
00:08:00,002 --> 00:08:03,174
90% is sort of a comically low number. But are

124
00:08:03,212 --> 00:08:06,518
90% of login requests succeeding over the last week?

125
00:08:06,604 --> 00:08:09,590
If so, we've met our objective,

126
00:08:10,250 --> 00:08:13,450
and if not, then we know we need to be paying attention.

127
00:08:14,590 --> 00:08:18,678
Youll want to set a really high quality bar, right? Everybody does. But it's

128
00:08:18,694 --> 00:08:21,886
useful to think about what a really high quality bar

129
00:08:21,988 --> 00:08:25,390
means if you're measuring your objectives over the last seven

130
00:08:25,460 --> 00:08:28,826
days and you want a 99% objective

131
00:08:28,858 --> 00:08:32,686
to be set, we're talking here

132
00:08:32,708 --> 00:08:35,886
about, let's say total system downtime, right? If you're

133
00:08:35,918 --> 00:08:39,074
hitting zero, you've got an hour and 41

134
00:08:39,112 --> 00:08:42,270
minutes every seven days of total downtime

135
00:08:42,350 --> 00:08:45,762
to meet a 99% objective. And if you want five

136
00:08:45,816 --> 00:08:49,654
nines, the sort of magic number that you sometimes hear people say over

137
00:08:49,692 --> 00:08:53,702
a month, that's only 25 seconds of downtime. It's really important

138
00:08:53,756 --> 00:08:57,882
to think these things through when you set objectives, because it's better to start

139
00:08:57,936 --> 00:08:59,930
low and get stricter.

140
00:09:00,830 --> 00:09:04,166
Teams feel better and perform better when they're

141
00:09:04,198 --> 00:09:07,882
able to start at a place that's okay

142
00:09:08,016 --> 00:09:11,574
and get better rather than be failing right out of the gate

143
00:09:11,702 --> 00:09:16,062
and when setting objectives, you want to leave a bit of safety margin for

144
00:09:16,116 --> 00:09:19,774
normal operations. If you're always right up on the line of your

145
00:09:19,812 --> 00:09:23,534
objective, then you either need to do some work to

146
00:09:23,572 --> 00:09:26,978
improve your system's performance and build up some margin or lower the

147
00:09:26,984 --> 00:09:30,494
objectives a bit. Because if you're right up on the line, people are alerts

148
00:09:30,542 --> 00:09:34,354
all the time for things they may not be able to do

149
00:09:34,392 --> 00:09:37,550
much about. So to choose an objective,

150
00:09:37,630 --> 00:09:41,206
once you've defined your indicators, it's a good idea to

151
00:09:41,228 --> 00:09:44,694
look back over the last sort of few time

152
00:09:44,732 --> 00:09:48,114
periods that you want to measure and get a sense for what a good objectives

153
00:09:48,162 --> 00:09:51,434
would look like. Something that doesn't work is

154
00:09:51,472 --> 00:09:55,414
for your vp of engineering to say, look, every service needs to have a minimum

155
00:09:55,462 --> 00:09:59,386
99% SLO target set for their services

156
00:09:59,568 --> 00:10:03,040
and it's not acceptable for there to be anything less.

157
00:10:04,130 --> 00:10:08,266
This doesn't work well, especially when you're

158
00:10:08,298 --> 00:10:11,982
implementing these for the first time in a system and you may not

159
00:10:12,036 --> 00:10:16,126
even know how well things are performing, you're going to be sabotaging

160
00:10:16,158 --> 00:10:19,422
yourself right out of the gate. It's better to find your indicators,

161
00:10:19,486 --> 00:10:23,620
start to measure them and then think about youll objectives after that.

162
00:10:26,810 --> 00:10:30,614
Once we understanding what our indicators and

163
00:10:30,652 --> 00:10:34,898
objectives look like, then we can start to alerts

164
00:10:34,994 --> 00:10:39,074
based on measurements of those indicators. We want to alerts operators

165
00:10:39,202 --> 00:10:42,060
when they need to pay attention to a system now,

166
00:10:42,830 --> 00:10:45,786
not when something kind of looks bad and you should look at it in the

167
00:10:45,808 --> 00:10:49,734
morning. We're going to monitor those indicators

168
00:10:49,782 --> 00:10:54,238
because they're symptoms of what our users actually experience and

169
00:10:54,404 --> 00:10:58,190
we'll prioritize how urgent things are based on how bad

170
00:10:58,260 --> 00:11:01,198
those indicators look. To think about this,

171
00:11:01,284 --> 00:11:05,246
it's useful to think about monitoring the symptoms

172
00:11:05,438 --> 00:11:08,738
of a problem and not the causes. Symptoms of a

173
00:11:08,744 --> 00:11:12,146
problem would be things like checkout is broken, cause of

174
00:11:12,168 --> 00:11:16,214
a problem might be pods are running out of memory and

175
00:11:16,252 --> 00:11:18,710
crashing in my kubernetes cluster.

176
00:11:20,170 --> 00:11:23,446
Alerting is not about maintaining systems. It's not

177
00:11:23,468 --> 00:11:26,582
about looking for underlying causes before something goes

178
00:11:26,636 --> 00:11:30,502
wrong. That's maintenance. Alerting is for dealing with emergencies.

179
00:11:30,566 --> 00:11:34,538
Alerting is for dealing with triage. And so you should be looking at

180
00:11:34,624 --> 00:11:38,026
things that are really broken, really problems for

181
00:11:38,048 --> 00:11:40,918
users. Now youll systems deserve checkups.

182
00:11:41,014 --> 00:11:44,394
You should be understanding and looking at those underlying causes.

183
00:11:44,522 --> 00:11:48,030
But that's part of your normal day to day work.

184
00:11:48,100 --> 00:11:51,374
If your team is operating systems, that should be part of what your

185
00:11:51,412 --> 00:11:54,574
team is measuring and understanding as part of your

186
00:11:54,692 --> 00:11:58,386
general work, not as something that your on call does

187
00:11:58,568 --> 00:12:01,666
just during the time that they're on call. You shouldn't be getting up

188
00:12:01,688 --> 00:12:05,198
at three in the morning for maintenance tasks. You should be getting up at three

189
00:12:05,224 --> 00:12:09,174
in the morning when something is broken. So you

190
00:12:09,212 --> 00:12:12,390
need to be alerted not too early

191
00:12:12,460 --> 00:12:15,746
when there's some problem that's just a little spike,

192
00:12:15,858 --> 00:12:19,900
but definitely not too late to solve your problem either.

193
00:12:20,830 --> 00:12:24,218
So to think about this, it's useful to think of system

194
00:12:24,304 --> 00:12:28,182
performance like cash flow. Once you set an objective,

195
00:12:28,246 --> 00:12:31,674
then you've got a budget. You've got a budget of problems you can

196
00:12:31,712 --> 00:12:35,514
spend, and you're spending that like money. If you've been in the startup

197
00:12:35,562 --> 00:12:39,022
world, you've heard about a company's burn rate, how fast

198
00:12:39,076 --> 00:12:42,654
are they running through their cash? When are they going to need to raise more?

199
00:12:42,772 --> 00:12:46,206
And you can think of this as having an error burn rate

200
00:12:46,388 --> 00:12:49,966
where you're burning through your budget. And so when you start spending

201
00:12:49,998 --> 00:12:53,602
that budget too quickly, you need to stop things, drop things,

202
00:12:53,656 --> 00:12:56,020
look in on it and figure out how to fix that.

203
00:12:57,530 --> 00:13:00,690
So we can think about levels of urgency

204
00:13:00,770 --> 00:13:04,214
associated with measurements of the SLO. There's things that should

205
00:13:04,252 --> 00:13:08,134
wake me up, like a high burn rate that isn't going away or can

206
00:13:08,172 --> 00:13:11,882
extremely high set of errors that cares happening over a short

207
00:13:11,936 --> 00:13:16,006
period of time. Now, if there's a sort of sustained moderate

208
00:13:16,038 --> 00:13:19,578
rate that's going to cause youll problems over a period of days,

209
00:13:19,664 --> 00:13:22,714
it's something your on call can look at in the morning, but that they must

210
00:13:22,752 --> 00:13:26,074
prioritize. Or if you've got a sort of you're never burning

211
00:13:26,122 --> 00:13:29,726
through your error budget, but you're always kind of using a bit, maybe more than

212
00:13:29,748 --> 00:13:32,826
you're comfortable with, then you should be doing that as part of

213
00:13:32,868 --> 00:13:35,460
your maintenance checkup kind of work on your system.

214
00:13:36,630 --> 00:13:40,238
And if you have sort of just transient moderate burn

215
00:13:40,254 --> 00:13:43,380
rate kind of problems, small spikes here and there,

216
00:13:44,310 --> 00:13:47,686
you almost shouldn't worry about these. There are always going to be,

217
00:13:47,788 --> 00:13:49,830
especially in larger systems,

218
00:13:50,250 --> 00:13:54,082
transient issues. As other services deploy,

219
00:13:54,146 --> 00:13:56,630
a network switch gets replaced.

220
00:13:57,390 --> 00:14:00,486
SLO. This is why we set our objectives

221
00:14:00,518 --> 00:14:04,742
at a reasonable level, because we shouldn't be spending teams

222
00:14:04,806 --> 00:14:08,150
valuable time on minor things like that that can

223
00:14:08,230 --> 00:14:11,806
really be addressed in

224
00:14:11,828 --> 00:14:13,920
order to get alerted soon enough,

225
00:14:15,010 --> 00:14:19,034
but not too soon. To avoid choose sort of transient

226
00:14:19,162 --> 00:14:22,758
moderate problems causing sending alerts

227
00:14:22,794 --> 00:14:25,700
that cares resolved by the time somebody wakes up.

228
00:14:26,310 --> 00:14:30,530
We can measure our indicators over two time operations,

229
00:14:31,110 --> 00:14:34,546
which helps us handle that too early, too late kind

230
00:14:34,568 --> 00:14:37,654
of problem. So by taking

231
00:14:37,692 --> 00:14:40,982
those two time operations and comparing the burn rate

232
00:14:41,036 --> 00:14:44,854
to a threshold, we can decide how serious a

233
00:14:44,892 --> 00:14:48,870
problem is. The idea here is over

234
00:14:48,940 --> 00:14:52,378
short time periods the burn rate needs to be very, very high

235
00:14:52,464 --> 00:14:56,294
to get somebody out of bed. And over longer time operations,

236
00:14:56,422 --> 00:14:59,846
a lower burn rate will still cause you problems. If you've

237
00:14:59,878 --> 00:15:02,940
got a low burn rate all day every day,

238
00:15:03,470 --> 00:15:07,040
you're going to run out of error budget well before the end of the month.

239
00:15:07,570 --> 00:15:11,118
If you have a high burn rate, you'll run out of the

240
00:15:11,124 --> 00:15:14,458
error budget in a matter of hours. And so somebody really needs to get up

241
00:15:14,484 --> 00:15:18,610
and look at it. So for a rating of urgency here,

242
00:15:18,680 --> 00:15:22,834
you can have, like, a short time window of 5 minutes and

243
00:15:22,872 --> 00:15:26,686
a longer time window of an hour. And if the average burn

244
00:15:26,718 --> 00:15:29,954
rate over that time are both above this relatively

245
00:15:30,002 --> 00:15:33,586
high threshold of 14 times your error budget,

246
00:15:33,698 --> 00:15:37,666
then you know youll need to pay attention. And what these two windows buy you

247
00:15:37,788 --> 00:15:41,114
is the long window helps make sure you're not alerted too

248
00:15:41,152 --> 00:15:44,998
early. And the short window helps

249
00:15:45,014 --> 00:15:49,382
you make sure that when things are resolved, the alert resolves

250
00:15:49,446 --> 00:15:54,942
relatively quickly. And so higher

251
00:15:54,996 --> 00:15:58,350
urgency levels means shorter measurement windows, but a higher

252
00:15:58,420 --> 00:16:01,982
threshold for alerting and lower

253
00:16:02,036 --> 00:16:04,640
urgency levels, things you can look at in the morning,

254
00:16:05,330 --> 00:16:09,178
take measurements over longer periods of time, but have a much more relaxed

255
00:16:09,274 --> 00:16:13,454
threshold for alerting. And this is a way to

256
00:16:13,492 --> 00:16:17,782
really make sure that getting out of bed when something is really going

257
00:16:17,836 --> 00:16:21,686
wrong at a pretty severe level. Thanks for, thanks for

258
00:16:21,708 --> 00:16:21,780
coming.

