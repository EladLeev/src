1
00:00:22,330 --> 00:00:26,226
Everyone. My name is Gajendra Deshpande and today I will be presenting

2
00:00:26,258 --> 00:00:29,750
a talk on multilingual natural language processing using

3
00:00:29,820 --> 00:00:33,990
Python. So in today's tasks we will be discussing in brief

4
00:00:34,490 --> 00:00:38,722
about natural language processing and its concepts, then challenges

5
00:00:38,786 --> 00:00:42,626
in multisource multilingual natural language processing tools

6
00:00:42,658 --> 00:00:45,426
for extracting information from various file formats,

7
00:00:45,538 --> 00:00:48,358
extracting information from web pages and source code.

8
00:00:48,524 --> 00:00:51,914
Then finally methods convert information into common language

9
00:00:51,962 --> 00:00:55,534
format. Let us first look at the few

10
00:00:55,572 --> 00:00:58,894
of the basic concepts of natural language processing. So first

11
00:00:58,932 --> 00:01:02,506
one is tokenization. So in tokenization, what we do is we

12
00:01:02,548 --> 00:01:05,330
tokenize a paragraph into words and sentences.

13
00:01:05,910 --> 00:01:09,778
So basically you will be given huge text. So it

14
00:01:09,784 --> 00:01:13,822
is not possible to perform computation or processing

15
00:01:13,966 --> 00:01:17,894
the entire text at once. So we need to tokenize it say

16
00:01:17,932 --> 00:01:21,302
for example, we may have to compute the word

17
00:01:21,356 --> 00:01:24,774
frequency and sentence frequency, and we also

18
00:01:24,812 --> 00:01:28,650
need to perform ngram analysis. The next is

19
00:01:28,800 --> 00:01:33,142
word embeddings. So here we represent words into vectors,

20
00:01:33,286 --> 00:01:37,094
that is we convert words into some numeric

21
00:01:37,142 --> 00:01:39,850
formats for computation,

22
00:01:40,210 --> 00:01:43,454
then text completion. So here we try to

23
00:01:43,492 --> 00:01:46,842
predict next few words in a sentence,

24
00:01:46,986 --> 00:01:49,390
then sentence similarity,

25
00:01:50,690 --> 00:01:54,334
where we will try to find out the similarity score

26
00:01:54,382 --> 00:01:57,922
between two sentences. So here the scale will be from

27
00:01:57,976 --> 00:02:01,502
zero to one, then normalization.

28
00:02:01,646 --> 00:02:04,750
So here we transform the text into its

29
00:02:04,920 --> 00:02:07,746
canonical form, then transliteration.

30
00:02:07,858 --> 00:02:11,734
So write the text in language a,

31
00:02:11,772 --> 00:02:15,350
script using language b script say for example,

32
00:02:15,420 --> 00:02:19,734
you can write Korean using english script,

33
00:02:19,862 --> 00:02:23,306
then translation. Convert the text in language a to

34
00:02:23,328 --> 00:02:27,446
language b. That is, you are directly converting korean

35
00:02:27,478 --> 00:02:31,194
text into english language. So there is a difference between transliteration

36
00:02:31,242 --> 00:02:35,226
and translation, so both are totally different. Then phonetic

37
00:02:35,258 --> 00:02:38,734
analysis. So here we try to determine how two

38
00:02:38,772 --> 00:02:43,074
characters sound when we speak

39
00:02:43,192 --> 00:02:46,478
those characters. The next is syllabification.

40
00:02:46,654 --> 00:02:51,230
Convert text into syllables, then lamatization.

41
00:02:51,390 --> 00:02:54,930
Here we convert words into their root form.

42
00:02:55,080 --> 00:02:58,294
Say for example, if there is a word called as running,

43
00:02:58,412 --> 00:03:01,942
then the root form of running will be just

44
00:03:01,996 --> 00:03:05,426
run. Then next concept is stemming.

45
00:03:05,538 --> 00:03:08,390
It is bit similar to lamatization,

46
00:03:08,730 --> 00:03:12,326
but what we do in stemming is we just remove last few characters

47
00:03:12,438 --> 00:03:16,486
from the word. So sometimes it may be similar to lamatization,

48
00:03:16,598 --> 00:03:20,346
but the results are not accurate when you use

49
00:03:20,448 --> 00:03:23,982
stemming, so you will not be able to convert the words into their

50
00:03:24,036 --> 00:03:26,922
root form always. Then language detection.

51
00:03:27,066 --> 00:03:30,398
Detect the language of the text or words,

52
00:03:30,564 --> 00:03:33,886
then dependency parsing. Analyze the grammatical

53
00:03:33,918 --> 00:03:37,854
structure of a sentence, then named entity speechrecognition

54
00:03:37,982 --> 00:03:41,746
recognize the entities in the text,

55
00:03:41,928 --> 00:03:46,306
for example names, pages, et cetera. Then part of speech.

56
00:03:46,418 --> 00:03:50,806
Tag a part of speech in a text, then challenges in

57
00:03:50,908 --> 00:03:54,454
multilingual NLP so first challenge is that language is

58
00:03:54,492 --> 00:03:57,954
ambiguous. So same sentence may mean different in different

59
00:03:58,012 --> 00:04:01,594
languages. So even in the same language, we need to

60
00:04:01,632 --> 00:04:05,050
identify the context of the words. Then languages have

61
00:04:05,120 --> 00:04:08,940
different structure, grammar and order. Say, for example, we have

62
00:04:09,390 --> 00:04:13,502
western languages, we have indian languages, and we have some other

63
00:04:13,556 --> 00:04:17,034
languages. So each language has got their own grammar

64
00:04:17,082 --> 00:04:20,398
and syntaxes different. Some languages are

65
00:04:20,484 --> 00:04:24,242
read left to right and some languages are read right to left.

66
00:04:24,376 --> 00:04:28,674
Then hard to deal with missed languages information. Now we

67
00:04:28,712 --> 00:04:32,894
know that due to globalization, people speak multiple

68
00:04:32,942 --> 00:04:36,694
languages. And when they speak multiple languages, it's a general tendency that

69
00:04:36,732 --> 00:04:39,938
they mix the words of different languages.

70
00:04:40,034 --> 00:04:43,238
So when we have a data of such a

71
00:04:43,244 --> 00:04:46,854
kind, and when we need to process such data, then it may

72
00:04:46,892 --> 00:04:50,378
create a problem in processing that kind of

73
00:04:50,464 --> 00:04:53,962
information. Because our libraries may not

74
00:04:54,016 --> 00:04:57,514
be able to detect or may not be able to identify the

75
00:04:57,632 --> 00:05:01,594
words of other languages. The next translation from one language

76
00:05:01,642 --> 00:05:05,402
to another language is not accurate. So translation

77
00:05:05,466 --> 00:05:09,034
is not always word to word translation. So the meaning

78
00:05:09,082 --> 00:05:12,858
needs to be taken into account. Then language semantics

79
00:05:12,954 --> 00:05:17,074
need to be taken into account. Right. So that's what

80
00:05:17,272 --> 00:05:20,834
I was discussing just now. That is, translation is not word

81
00:05:20,872 --> 00:05:24,142
to word, so we need to take into account the context

82
00:05:24,286 --> 00:05:27,458
for more accurate translation. Then lack

83
00:05:27,474 --> 00:05:31,126
of libraries and features of

84
00:05:31,148 --> 00:05:34,450
course there are many libraries in Python,

85
00:05:34,530 --> 00:05:38,278
but these libraries may not support all languages

86
00:05:38,374 --> 00:05:41,626
and they may be limited by the features. So in

87
00:05:41,648 --> 00:05:44,806
this case we may have to use multiple

88
00:05:44,838 --> 00:05:48,202
libraries or we may have to hard code

89
00:05:48,336 --> 00:05:53,306
many features. Then let us consider a scenario of multi

90
00:05:53,338 --> 00:05:56,846
source, multilingual information processing. Say,

91
00:05:56,948 --> 00:05:59,920
for example, we need to generate a summary. In that case,

92
00:06:00,850 --> 00:06:05,534
these are the steps. So the first step is information source,

93
00:06:05,662 --> 00:06:09,214
which is there in different format, then extract the text, then identify

94
00:06:09,262 --> 00:06:12,770
the language, translation to source language, then processing

95
00:06:12,840 --> 00:06:15,870
the text, and finally translate to target language.

96
00:06:15,950 --> 00:06:20,014
So let us discuss these steps in detail. So, information source,

97
00:06:20,062 --> 00:06:23,862
our information may be present in various formats, it may be present in text,

98
00:06:23,916 --> 00:06:27,046
it may be present in audio, it may be present in video, it may be

99
00:06:27,068 --> 00:06:30,586
present in image. But for processing we need the

100
00:06:30,608 --> 00:06:33,626
information in textual format. So if the information is

101
00:06:33,648 --> 00:06:36,410
available in text format, then it's not a problem.

102
00:06:36,480 --> 00:06:40,006
But if the information is available in audio, video or image,

103
00:06:40,038 --> 00:06:43,918
then we need to extract the text from audio, video and

104
00:06:44,004 --> 00:06:47,322
image. And we know that there are various formats for audio,

105
00:06:47,386 --> 00:06:50,958
video as well as image. So we need to try to

106
00:06:51,044 --> 00:06:55,326
extract the information from maximum possible formats.

107
00:06:55,438 --> 00:06:59,202
So in second step, we are going to extract the text using the

108
00:06:59,256 --> 00:07:03,106
libraries available in Python. The next, identify the

109
00:07:03,128 --> 00:07:07,010
languages. So here we try to detect the language

110
00:07:07,090 --> 00:07:10,770
of the text. So here it is bit challenging

111
00:07:10,850 --> 00:07:14,166
because all the text may not be available in

112
00:07:14,348 --> 00:07:17,874
single source language. So some words

113
00:07:18,012 --> 00:07:22,502
may not be identified because of the feature limitations.

114
00:07:22,646 --> 00:07:25,670
So in this case we may have to hard code some features.

115
00:07:25,750 --> 00:07:29,366
The next is translate to source language.

116
00:07:29,478 --> 00:07:33,322
So here one important step we need to perform. We need to translate

117
00:07:33,386 --> 00:07:37,440
the entire text into one single language so that we can perform

118
00:07:38,370 --> 00:07:41,918
processing over the text. So this is very very important

119
00:07:42,004 --> 00:07:45,874
step. So once we translate the information to one language then

120
00:07:45,912 --> 00:07:49,346
we can process the text, say for example, if we have to

121
00:07:49,368 --> 00:07:53,390
generate the summary, then in this case we can perform tokenization,

122
00:07:53,470 --> 00:07:57,542
we can perform lambdization, we can calculate word

123
00:07:57,596 --> 00:08:01,014
frequency and sentence frequency and we can also

124
00:08:01,052 --> 00:08:05,158
perform Engram analysis. And based on these steps we can

125
00:08:05,324 --> 00:08:09,306
pick top n sentences for the generation of

126
00:08:09,328 --> 00:08:12,822
the summary, then finally translate to a target

127
00:08:12,886 --> 00:08:15,978
language. So you can generate a summary in

128
00:08:15,984 --> 00:08:19,910
the source language or you can generate the summary in the

129
00:08:20,000 --> 00:08:22,826
specified language or a destination language.

130
00:08:22,938 --> 00:08:26,410
Now let us look at few python packages

131
00:08:26,570 --> 00:08:30,366
which will help us to achieve our task. So first one is

132
00:08:30,468 --> 00:08:34,222
Google Trans 3.00.

133
00:08:34,356 --> 00:08:38,094
So it's a free and unlimited Python library that

134
00:08:38,132 --> 00:08:41,786
implemented Google translation API. This uses Google translate

135
00:08:41,818 --> 00:08:45,106
ajax API to make calls to such methods

136
00:08:45,258 --> 00:08:49,094
as detect and translate. So it is compatible with Python 3.6

137
00:08:49,212 --> 00:08:52,146
and higher versions. It is fast and reliable.

138
00:08:52,258 --> 00:08:56,134
That's because it uses the same servers that translate google.com

139
00:08:56,172 --> 00:08:59,750
uses. Then auto language detection feature is supported,

140
00:08:59,830 --> 00:09:04,166
then bulk translations are possible. Then customizable service URL

141
00:09:04,278 --> 00:09:08,022
is supported and it also supports HTTP version

142
00:09:08,166 --> 00:09:11,626
two. Then you can install it using Pip command, so you

143
00:09:11,648 --> 00:09:15,882
can say pil install Google Trans, then it will be installed on your machine.

144
00:09:16,026 --> 00:09:19,658
So if the source language is not given, then Google translate attempts

145
00:09:19,674 --> 00:09:22,914
to direct the source language. So you can see here the

146
00:09:22,952 --> 00:09:27,230
source code. So first we are importing translator

147
00:09:27,310 --> 00:09:31,374
from Google Trans, then we are using the translate

148
00:09:31,502 --> 00:09:34,986
function. So note here that we have just specified source

149
00:09:35,038 --> 00:09:38,662
language, that is Korean, but we have not

150
00:09:38,716 --> 00:09:42,674
mentioned the language. So it tries to detect

151
00:09:42,722 --> 00:09:46,706
that it's a korean language and destination is not specified.

152
00:09:46,898 --> 00:09:50,810
So by default it will be converted to English. Then next

153
00:09:50,960 --> 00:09:54,986
in the next case we have not specified the source language, but we have

154
00:09:55,008 --> 00:09:58,934
specified the destination language. So here the source

155
00:09:59,062 --> 00:10:02,698
language will be korean and destination language will be japanese.

156
00:10:02,794 --> 00:10:05,978
So that is the korean language. Text will be converted

157
00:10:05,994 --> 00:10:09,806
to japanese language text. Then in the next example we

158
00:10:09,828 --> 00:10:13,306
have specified some text and we have specified that the source language

159
00:10:13,338 --> 00:10:17,134
is Latin. In this case we have not specified the destination language,

160
00:10:17,262 --> 00:10:20,530
so the latin text will be converted to English.

161
00:10:20,870 --> 00:10:24,354
Now you can use under Google translate domain for

162
00:10:24,392 --> 00:10:27,906
translation. Say for example if multiple URLs are

163
00:10:27,928 --> 00:10:31,410
provided then it randomly chooses a domain.

164
00:10:32,170 --> 00:10:35,874
So you can specify either one domain or you can specify multi

165
00:10:35,922 --> 00:10:39,514
domains. If you specify multiple domains then it will select one

166
00:10:39,552 --> 00:10:43,034
domain randomly. Then the

167
00:10:43,072 --> 00:10:46,746
detect methods, as its name implies identifies the

168
00:10:46,768 --> 00:10:50,414
language used in the given sentence so

169
00:10:50,452 --> 00:10:54,494
you can use detect method to identify the

170
00:10:54,612 --> 00:10:58,206
language of the given text. Important point here

171
00:10:58,228 --> 00:11:02,266
is that it is unofficial, unstable and maximum character

172
00:11:02,298 --> 00:11:05,210
limit on a single text is 15k characters.

173
00:11:05,370 --> 00:11:09,434
So the solution is use Google's official translate

174
00:11:09,482 --> 00:11:12,510
API for your requirements.

175
00:11:12,930 --> 00:11:17,126
The next is speechrecognition. Here we

176
00:11:17,148 --> 00:11:20,146
try to extract text from an audio file.

177
00:11:20,338 --> 00:11:24,050
So it's a library for performing speechrecognition

178
00:11:24,210 --> 00:11:28,282
with support for several engines and APIs and

179
00:11:28,336 --> 00:11:31,558
also it's available online as well as offline.

180
00:11:31,654 --> 00:11:35,606
So speech recognition engines or API supported

181
00:11:35,638 --> 00:11:39,762
by speechrecognition packages are CMU sphinx, it works offline

182
00:11:39,926 --> 00:11:43,454
and also snow by hot word

183
00:11:43,492 --> 00:11:46,894
detection also works offline. Apart from that

184
00:11:47,092 --> 00:11:50,874
Google speech recognition, then Google cloud speech API width AI,

185
00:11:50,922 --> 00:11:53,990
Microsoft Bing voice recognition, hindi fi

186
00:11:54,090 --> 00:11:57,726
API, then IBM speech to text engines

187
00:11:57,758 --> 00:12:01,698
are supported. Then this is how we write the code.

188
00:12:01,784 --> 00:12:05,274
First we import the speech recognition package,

189
00:12:05,422 --> 00:12:08,758
then we specify the file name from which

190
00:12:08,844 --> 00:12:11,974
we want to extract the text.

191
00:12:12,172 --> 00:12:16,374
Then we use a recognizer function to

192
00:12:16,412 --> 00:12:18,230
initialize the recognizer.

193
00:12:18,910 --> 00:12:22,058
Then we use record

194
00:12:22,144 --> 00:12:25,606
function and there we specify the source file

195
00:12:25,638 --> 00:12:29,674
name. And finally we use recognize Google function

196
00:12:29,872 --> 00:12:33,758
and this function will convert the speech to text and store

197
00:12:33,844 --> 00:12:37,662
the information in the text variable. And finally we

198
00:12:37,796 --> 00:12:41,402
can print the text or you can store it in a variable

199
00:12:41,466 --> 00:12:45,694
for further processing. The next is pytessaract

200
00:12:45,742 --> 00:12:48,862
package, so it is used to extract

201
00:12:48,926 --> 00:12:52,766
text from an image file. So Python

202
00:12:52,958 --> 00:12:56,326
Pytessaract is an optical character recognition tool

203
00:12:56,428 --> 00:13:00,294
for Python. That is, it will recognize and read the

204
00:13:00,332 --> 00:13:02,870
text embedded in images.

205
00:13:03,450 --> 00:13:07,390
Python Pytessaract is a wrapper for Google's pytessaract

206
00:13:07,490 --> 00:13:11,094
OCR engine. It is also useful as a standalone

207
00:13:11,142 --> 00:13:14,970
invocation script to Pytessaract as it can read

208
00:13:15,120 --> 00:13:19,126
all image types supported by the pillow and leptonica

209
00:13:19,158 --> 00:13:22,234
imaging libraries including JPeg,

210
00:13:22,362 --> 00:13:25,680
png, GiF, BMP, TIFF and others.

211
00:13:26,050 --> 00:13:29,294
Additionally, if used as a script, Python test

212
00:13:29,332 --> 00:13:33,202
track will print the recognized text instead of

213
00:13:33,336 --> 00:13:36,882
writing it to a files. So just three

214
00:13:36,936 --> 00:13:40,722
lines are enough to extracting the text

215
00:13:40,776 --> 00:13:44,418
from an image file. So first import

216
00:13:44,504 --> 00:13:48,662
the pytessaract package, then initialize the

217
00:13:48,716 --> 00:13:52,390
pytessaract command and then specify

218
00:13:52,810 --> 00:13:55,778
the images path.

219
00:13:55,954 --> 00:13:59,766
So we use image to string methods

220
00:13:59,878 --> 00:14:03,340
so which will read the image and convert the

221
00:14:04,590 --> 00:14:08,346
data in the image to a string. The next is

222
00:14:08,448 --> 00:14:12,542
beautiful soup four. Then it is used to

223
00:14:12,596 --> 00:14:16,186
extracting the information from a web page. So if you have performed

224
00:14:16,218 --> 00:14:19,898
web page scraping then you are familiar with this package.

225
00:14:19,994 --> 00:14:23,234
So that is beautiful soup four.

226
00:14:23,352 --> 00:14:27,234
So it's a library that makes it easy to scrape information from web

227
00:14:27,272 --> 00:14:31,358
pages. It sits atop an HTML

228
00:14:31,374 --> 00:14:34,542
or XML parser providing pythonic idioms

229
00:14:34,606 --> 00:14:38,274
for extracting, searching and modifying the parse

230
00:14:38,322 --> 00:14:41,430
tree. So this is how we write the code

231
00:14:41,500 --> 00:14:44,930
here. So we first import requests package,

232
00:14:45,010 --> 00:14:48,982
then we import beautiful soup package.

233
00:14:49,126 --> 00:14:52,940
Then we specify the URL from which we want to extracting the

234
00:14:53,310 --> 00:14:57,830
information. Then next we specify the parser.

235
00:14:57,910 --> 00:15:01,454
So here HTML parser has been specified. Now the thing

236
00:15:01,492 --> 00:15:05,120
here is that when you use beautiful soup it extracts the

237
00:15:05,970 --> 00:15:09,614
source code. Also it's not the

238
00:15:09,652 --> 00:15:13,326
server side source code, but it is the code which is rendered

239
00:15:13,358 --> 00:15:16,994
by the web browser. So the

240
00:15:17,032 --> 00:15:21,422
next task will be to remove

241
00:15:21,486 --> 00:15:25,394
all the unwanted code and also to navigate

242
00:15:25,442 --> 00:15:28,774
to appropriate location in the web

243
00:15:28,812 --> 00:15:32,070
page. Maybe if you are using XML then you can

244
00:15:32,140 --> 00:15:35,942
use xPath queries to navigate to a

245
00:15:35,996 --> 00:15:39,702
particular location on the web pages to extracting

246
00:15:39,766 --> 00:15:43,322
its content. The next library which we will

247
00:15:43,376 --> 00:15:48,086
see is the stanza. So it is Python NLP

248
00:15:48,118 --> 00:15:52,234
package for many human languages. So stanza

249
00:15:52,282 --> 00:15:55,914
is by Stanford. So earlier it was known as Stanford

250
00:15:55,962 --> 00:15:59,294
NLP, but now they have challenges its name

251
00:15:59,332 --> 00:16:02,582
so now it is known as stanza. So it's a collection

252
00:16:02,666 --> 00:16:06,194
of accurate and efficient tools for many

253
00:16:06,232 --> 00:16:09,570
human languages in one place. So starting

254
00:16:09,640 --> 00:16:13,550
from raw text to syntactic analysis and entity recognition,

255
00:16:13,710 --> 00:16:17,266
stanza bring state of the art NLP models

256
00:16:17,298 --> 00:16:21,042
to languages of your choosing. So native

257
00:16:21,106 --> 00:16:24,914
Python implementation requiring minimal efforts

258
00:16:24,962 --> 00:16:29,510
to set up so full neural network pipeline for robust text

259
00:16:29,580 --> 00:16:33,042
analytics including tokenization, multi word

260
00:16:33,196 --> 00:16:36,374
token expansion, lamatization part of speech

261
00:16:36,422 --> 00:16:40,394
tagging and morphological feature,

262
00:16:40,442 --> 00:16:44,494
staging, dependency parsing and named entry speechrecognition are

263
00:16:44,532 --> 00:16:48,298
supported. Then pretrained neural models

264
00:16:48,474 --> 00:16:52,254
supporting 66 human languages. Then it's a

265
00:16:52,292 --> 00:16:56,798
stable, officially maintained Python interface to core NLP.

266
00:16:56,894 --> 00:17:00,850
So you can refer GitHub repo for more information.

267
00:17:01,000 --> 00:17:04,322
Then you can also visit stanza run

268
00:17:04,376 --> 00:17:07,014
website for live demo.

269
00:17:07,212 --> 00:17:11,026
Then on this slide you can see the output

270
00:17:11,058 --> 00:17:14,854
of stanza. So here I had pasted one story,

271
00:17:15,052 --> 00:17:19,306
so you all know about the story.

272
00:17:19,488 --> 00:17:23,206
That's a race between tortoise and rabbit.

273
00:17:23,318 --> 00:17:26,860
So you can see here that it is showing the

274
00:17:27,390 --> 00:17:31,006
part of speech output, then it is

275
00:17:31,028 --> 00:17:34,030
also showing the lemmas.

276
00:17:34,610 --> 00:17:38,426
Then it's also showing the named entity recognition.

277
00:17:38,538 --> 00:17:41,822
So you can say that in named entity recognition it's saying that

278
00:17:41,876 --> 00:17:45,234
two is a cardinal, then it is showing the

279
00:17:45,272 --> 00:17:49,010
universal dependency between different words

280
00:17:49,080 --> 00:17:52,594
in a sentence. The next, what I did

281
00:17:52,632 --> 00:17:56,246
was the same text, same story was

282
00:17:56,268 --> 00:18:00,994
converted to another language. So that's Hindi.

283
00:18:01,122 --> 00:18:04,690
So you can see here that part of speech

284
00:18:04,770 --> 00:18:08,226
is working fine. It has successfully identified

285
00:18:08,418 --> 00:18:11,898
part of speech. Then lemmas also working

286
00:18:11,984 --> 00:18:15,674
fine. But if you see the named entity recognition, this feature is

287
00:18:15,712 --> 00:18:19,260
not yet supported. So those who want to contribute, they can

288
00:18:19,630 --> 00:18:23,566
think of contributing here in this particular area for

289
00:18:23,588 --> 00:18:27,034
Hindi language. So likewise if you consider some other languages,

290
00:18:27,162 --> 00:18:30,926
so features are lacking. So this is what I

291
00:18:30,948 --> 00:18:35,022
was speaking earlier. So libraries are limited

292
00:18:35,086 --> 00:18:38,750
by features. We may have to hard code some features

293
00:18:38,830 --> 00:18:42,658
now it also shows universal dependencies. So that's fine,

294
00:18:42,824 --> 00:18:47,050
that's not a problem. Then next is inLtk.

295
00:18:47,150 --> 00:18:51,074
So it's a natural language toolkit for indic languages.

296
00:18:51,202 --> 00:18:54,966
It's created by Gaurav Aurora. It aims to provide out

297
00:18:54,988 --> 00:18:58,346
of the box support for various NLP tasks that an application

298
00:18:58,448 --> 00:19:02,282
developer might need for indic languages. So indic languages means

299
00:19:02,336 --> 00:19:05,910
the languages which are used in India.

300
00:19:05,990 --> 00:19:10,258
So India is very rich in terms of languages.

301
00:19:10,454 --> 00:19:14,186
So it has got around 22 official

302
00:19:14,298 --> 00:19:18,138
languages. Then it supports native languages and code missed

303
00:19:18,234 --> 00:19:21,422
languages. So native languages means the text

304
00:19:21,476 --> 00:19:25,742
in a single language. Maybe the Canada Hindi or Marathi,

305
00:19:25,806 --> 00:19:29,154
Tamil, Telugu or some other language code.

306
00:19:29,192 --> 00:19:32,894
Mixed languages means the words from two or more languages

307
00:19:33,022 --> 00:19:36,706
is mixed. Say for example we can say English which is combination

308
00:19:36,738 --> 00:19:39,858
of Hindi and English. We can say English

309
00:19:39,954 --> 00:19:43,814
which is consideration of Canada and English. That means the

310
00:19:43,852 --> 00:19:47,554
script will be in Canada, but in between some english language

311
00:19:47,602 --> 00:19:51,622
words are used. InTK is currently supported

312
00:19:51,686 --> 00:19:55,542
only on Linux and Windows ten with Python version

313
00:19:55,606 --> 00:19:59,034
greater than or equal to 3.6. The next

314
00:19:59,072 --> 00:20:03,214
library is indic NLP library. So you can see here that

315
00:20:03,332 --> 00:20:07,306
the language support there are different classifications,

316
00:20:07,338 --> 00:20:10,080
that is Indo Aryan, dravidian and others.

317
00:20:10,530 --> 00:20:14,206
Then it also shows that the features

318
00:20:14,238 --> 00:20:18,190
supported by the various languages in India.

319
00:20:18,270 --> 00:20:21,826
So if you see dravidian languages, most of

320
00:20:21,848 --> 00:20:26,158
the features are supported in Indo RN category, Hindi and Bengali,

321
00:20:26,334 --> 00:20:29,718
Gujarati, Marathi and Kokane. They support

322
00:20:29,804 --> 00:20:33,490
all the features. Even Punjabi supports

323
00:20:33,650 --> 00:20:37,058
the features like script information normalization,

324
00:20:37,154 --> 00:20:39,130
tokenization, word segmentation,

325
00:20:39,550 --> 00:20:42,106
romanization and so on.

326
00:20:42,208 --> 00:20:45,990
Then there are some languages which support bilingual

327
00:20:46,070 --> 00:20:49,706
features. That is, script conclusion is possible among the

328
00:20:49,728 --> 00:20:53,214
above mentioned languages, but except Urdu and English it is not

329
00:20:53,252 --> 00:20:56,910
possible. Then transliteration is possible.

330
00:20:57,060 --> 00:21:00,240
Then also the translation is possible.

331
00:21:00,610 --> 00:21:05,006
Then this library was created by Anup Konchukutans.

332
00:21:05,198 --> 00:21:08,354
The goal of the Indian LP library is

333
00:21:08,392 --> 00:21:11,966
to build Python based libraries for common text processing

334
00:21:11,998 --> 00:21:16,050
and multilingual natural language processing. Indian languages indian languages

335
00:21:16,130 --> 00:21:19,394
share a lot of similarity in terms of script, phonology,

336
00:21:19,522 --> 00:21:22,934
language syntax, et cetera. And this library is

337
00:21:22,972 --> 00:21:26,626
an attempt to provide general conclusion to very common

338
00:21:26,658 --> 00:21:30,138
required tool sets for indian language text.

339
00:21:30,304 --> 00:21:33,734
Then polyclot is another interesting library.

340
00:21:33,862 --> 00:21:37,674
It's a very vast library and it

341
00:21:37,712 --> 00:21:41,086
supports most of the human languages in the

342
00:21:41,108 --> 00:21:44,762
world. It's really a massive library.

343
00:21:44,906 --> 00:21:48,346
It's developed by Rami al Rafu.

344
00:21:48,538 --> 00:21:51,950
It supports various features, and you can see here

345
00:21:52,020 --> 00:21:54,994
in bracket how many languages it supports. Say for example,

346
00:21:55,032 --> 00:21:59,646
tokenization is supported by 165 languages, language detection

347
00:21:59,758 --> 00:22:03,042
for 196 languages, name recognition for 40

348
00:22:03,096 --> 00:22:06,430
languages, part of speech tagging for 16 languages,

349
00:22:06,510 --> 00:22:10,402
sentiment analysis for 136 languages, word embeddings

350
00:22:10,466 --> 00:22:14,722
for 137 languages, morphological analysis for 135 languages.

351
00:22:14,866 --> 00:22:18,102
Then similarly transliteration for 69 languages.

352
00:22:18,246 --> 00:22:21,386
Again, note here that the features are limited for

353
00:22:21,408 --> 00:22:25,290
few of the languages. So again, there is a scope

354
00:22:25,870 --> 00:22:29,878
for contribution here. Then finally,

355
00:22:29,984 --> 00:22:33,422
summary. So, performing NLP tasks on multiple human

356
00:22:33,476 --> 00:22:36,654
languages at a time is hard, especially when

357
00:22:36,692 --> 00:22:39,790
the text includes mixed languages.

358
00:22:40,130 --> 00:22:43,746
The information need to be extracted from multiple sources and

359
00:22:43,768 --> 00:22:47,758
multiple languages, and should be converted to a common language.

360
00:22:47,854 --> 00:22:50,866
Multilingual NLP helps to generate output in

361
00:22:50,888 --> 00:22:54,882
a target language. So one feature what

362
00:22:54,936 --> 00:22:58,614
we are doing here is we are converting the information to

363
00:22:58,652 --> 00:23:02,086
a source language, and then we are converting the information to a

364
00:23:02,108 --> 00:23:05,894
specific target language. So there are various libraries offering different

365
00:23:05,932 --> 00:23:09,910
features, but not a single library offers all features. So that means

366
00:23:09,980 --> 00:23:14,086
that there's a lot of scope for contribution and also a

367
00:23:14,108 --> 00:23:18,374
lot of features needs to be hard coded. Thank you everyone

368
00:23:18,572 --> 00:23:21,500
for attend my talk.

