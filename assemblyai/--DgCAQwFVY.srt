1
00:00:42,540 --> 00:00:46,124
Hi everyone, and welcome to this talk about infrastructure

2
00:00:46,172 --> 00:00:49,760
drift. Infrastructure as code, devsecops and, well,

3
00:00:49,830 --> 00:00:52,660
drift control. All right, the agenda.

4
00:00:52,740 --> 00:00:56,120
So in this talk I will briefly define what is

5
00:00:56,190 --> 00:00:59,656
infrastructure drift, what we learned the hard way, and then it

6
00:00:59,678 --> 00:01:03,652
will be fun. Live demos and stories from the trenches.

7
00:01:03,716 --> 00:01:07,496
This will be a very hands on talk. Thank you for attending.

8
00:01:07,608 --> 00:01:11,052
So basically last year we were working on

9
00:01:11,106 --> 00:01:14,540
GitHub's platform to support infrastructure as code and

10
00:01:14,610 --> 00:01:18,000
all the tooling, the best practices, et cetera. And at some point

11
00:01:18,070 --> 00:01:21,344
we looked for feedback to build the next features and

12
00:01:21,382 --> 00:01:24,572
we interviewed our users and other DevOps,

13
00:01:24,636 --> 00:01:28,748
Sres, ctos, et cetera. And the most important pain those people

14
00:01:28,854 --> 00:01:31,776
reported was around infrastructure drift,

15
00:01:31,888 --> 00:01:35,920
visibility of what's living outside of your terraform

16
00:01:36,000 --> 00:01:39,844
configuration. So if you have only one thing to remember from

17
00:01:39,882 --> 00:01:44,084
this talk, it's that almost everyone experienced infrastructure

18
00:01:44,132 --> 00:01:48,164
drift recently, and that drifts can have major consequences,

19
00:01:48,292 --> 00:01:51,992
including security. In the end, that's the reason

20
00:01:52,126 --> 00:01:55,688
why we built this open source tool called drift control.

21
00:01:55,774 --> 00:01:59,576
Drift cutl drift TTL. It's up to you causes your poison

22
00:01:59,688 --> 00:02:03,528
so I'm Stephane Jourdan as Jordan pretty much everywhere

23
00:02:03,704 --> 00:02:07,196
on the Internet, I've been around infrastructures for

24
00:02:07,298 --> 00:02:10,624
the past 20 years. I cofounded a bunch of companies in

25
00:02:10,662 --> 00:02:14,064
Canada and Europe, and well, many years ago I

26
00:02:14,102 --> 00:02:17,420
cohort this book infrastructure as Code cookbook,

27
00:02:17,500 --> 00:02:21,456
and more recently I'm the happy cofounder of the open source tool Drift

28
00:02:21,488 --> 00:02:25,156
control with a wonderful team. So after talking to hundreds of

29
00:02:25,178 --> 00:02:28,896
people, we had to come up with a common definition of infrastructure

30
00:02:28,928 --> 00:02:32,432
drift. And basically it's what happens when the reality

31
00:02:32,496 --> 00:02:36,232
and the expectations don't match. It's also known as oh my

32
00:02:36,286 --> 00:02:39,416
God when things go wrong, while they really should not.

33
00:02:39,518 --> 00:02:43,144
So according to this definition, your ediber's account has

34
00:02:43,182 --> 00:02:46,844
a ton of actual resources that's on the right, and maybe

35
00:02:46,882 --> 00:02:50,268
only part of it is correctly managed by terraform that's on

36
00:02:50,274 --> 00:02:53,608
the left. And the diff is the drift.

37
00:02:53,784 --> 00:02:57,720
So what are the causes of the drift? There are many,

38
00:02:57,810 --> 00:03:01,212
but the major ones are the manual changes directly

39
00:03:01,276 --> 00:03:05,308
on the AWS console, the authenticated lambdas or microservices.

40
00:03:05,404 --> 00:03:08,496
You know, the scripts that you run every night, I don't know,

41
00:03:08,518 --> 00:03:12,320
to snapshot those disks on AWS, or can for certain

42
00:03:12,390 --> 00:03:15,588
tags, etc. It can be also this other team

43
00:03:15,754 --> 00:03:19,508
working with this other tool or that AWS service

44
00:03:19,594 --> 00:03:23,424
not yet available in the current terraform provider version

45
00:03:23,472 --> 00:03:27,496
that you are using. Maybe it's just that new project starting on

46
00:03:27,518 --> 00:03:31,512
this new cloud provider. It's different from the current one and no time

47
00:03:31,566 --> 00:03:34,648
to automate it properly. All those activities

48
00:03:34,744 --> 00:03:38,632
and others are authenticated and are sources

49
00:03:38,776 --> 00:03:42,668
causes of drift. So it could be no big deal and

50
00:03:42,754 --> 00:03:45,688
maybe we could all live with those drifts.

51
00:03:45,784 --> 00:03:49,856
Problem is, misconfiguration can lead to security issues you

52
00:03:49,878 --> 00:03:53,424
don't even know about. And we see here on this picture that

53
00:03:53,462 --> 00:03:56,640
the NSA recently leveled poor access

54
00:03:56,710 --> 00:03:59,824
control and misconfiguration stop issues.

55
00:03:59,942 --> 00:04:03,764
And definitely you want to know about the unknown stuff running in your

56
00:04:03,802 --> 00:04:07,716
cloud provider accounts. As we just said, we definitely need

57
00:04:07,738 --> 00:04:11,072
to shed some light on the unknown resources of your accounts,

58
00:04:11,136 --> 00:04:14,820
those that are not under control with terraform.

59
00:04:14,900 --> 00:04:18,068
And only then you'll know about misconfiguration.

60
00:04:18,164 --> 00:04:22,328
Only then you will be able to address or fix the issues.

61
00:04:22,494 --> 00:04:26,076
Now it's time for the stories, for the fun part, the live part.

62
00:04:26,178 --> 00:04:29,756
I will share a few stories. They are simplified for the

63
00:04:29,778 --> 00:04:32,984
talk. They are from our closed environment.

64
00:04:33,112 --> 00:04:36,672
And I'll show as well how our open

65
00:04:36,726 --> 00:04:39,984
source answer drift control helped in this

66
00:04:40,022 --> 00:04:44,080
case to find vulnerabilities in a configuration.

67
00:04:44,420 --> 00:04:47,964
So the first story is about this authenticated

68
00:04:48,012 --> 00:04:51,332
microservice for the lambda actually. And basically

69
00:04:51,466 --> 00:04:55,284
during the weekend there was a problem, it was just

70
00:04:55,322 --> 00:04:59,568
deployed, things like that. And basically, let me switch.

71
00:04:59,664 --> 00:05:03,608
Here we are. And basically what the on call guys

72
00:05:03,694 --> 00:05:07,492
did that weekend was going to the microservice

73
00:05:07,556 --> 00:05:10,712
im user and basically they said, oh,

74
00:05:10,766 --> 00:05:14,592
maybe it's a problem with the credentials, so let's

75
00:05:14,676 --> 00:05:18,540
deactivate the first one and create a new access key.

76
00:05:18,610 --> 00:05:22,476
So at last we will try that. Unfortunately it

77
00:05:22,498 --> 00:05:25,660
did not help. So they said okay, maybe it's this

78
00:05:25,730 --> 00:05:29,660
policy read only is not enough. Let's try again and attach

79
00:05:29,740 --> 00:05:33,404
a larger one policy. So it wasn't administrative

80
00:05:33,452 --> 00:05:36,572
access actually, but it's quicker.

81
00:05:36,636 --> 00:05:40,064
Imagine what can go wrong. And basically we

82
00:05:40,102 --> 00:05:43,636
don't know what happened, but a few minutes later it

83
00:05:43,658 --> 00:05:47,364
started to work again and they said okay, we're good

84
00:05:47,402 --> 00:05:50,756
with that. We will report it back on Monday to the

85
00:05:50,778 --> 00:05:54,504
team and we'll be good. So what happened

86
00:05:54,622 --> 00:05:58,216
is that they forgot to report it back on Monday, as you

87
00:05:58,238 --> 00:06:01,656
can imagine. And it stood that way for a long time.

88
00:06:01,758 --> 00:06:05,596
But it was cool. They had everything on terraform. So as

89
00:06:05,618 --> 00:06:10,236
you can see here on

90
00:06:10,258 --> 00:06:13,672
the code, it's working. So this is basic

91
00:06:13,736 --> 00:06:17,628
terraform code. If you're not used to it, it basically means that

92
00:06:17,714 --> 00:06:21,104
you create free resources. One is a user, one is an access key,

93
00:06:21,142 --> 00:06:24,672
and the other one is an attachment for policy, a managed policy

94
00:06:24,726 --> 00:06:28,876
or read only one. So basically it will create a

95
00:06:28,918 --> 00:06:32,852
user, a microservice user, an IM user with a dedicated access

96
00:06:32,906 --> 00:06:37,168
key for this specific user, and a policy attachment,

97
00:06:37,264 --> 00:06:40,710
which is the read only access you wanted. And basically,

98
00:06:42,460 --> 00:06:46,456
this configuration was perfectly well working

99
00:06:46,558 --> 00:06:50,500
on terraform. And if you applied terraform

100
00:06:50,580 --> 00:06:52,170
here, terraform apply.

101
00:06:53,260 --> 00:06:57,160
Well, it didn't see the change because terraform is cant.

102
00:06:57,240 --> 00:07:00,732
CTo see only changes for its

103
00:07:00,786 --> 00:07:03,996
scope. And basically, a new attachment in

104
00:07:04,018 --> 00:07:07,840
this case is seen as a new resource, as a new object.

105
00:07:07,910 --> 00:07:11,644
It cannot see that there is a new attachment. It's not meant

106
00:07:11,692 --> 00:07:16,688
for that. So had our

107
00:07:16,854 --> 00:07:20,868
team used drift control here, it would have

108
00:07:21,034 --> 00:07:25,140
done the following result. It's scanning

109
00:07:26,280 --> 00:07:29,924
the AWS account and

110
00:07:29,962 --> 00:07:33,092
comparing the results with the terraform state.

111
00:07:33,226 --> 00:07:36,936
So in this case, we have. For the free stories I'm going to tell

112
00:07:36,958 --> 00:07:40,388
you, we have free states for IAC users,

113
00:07:40,484 --> 00:07:44,460
VPC security groups and S three buckets. We can see here

114
00:07:44,530 --> 00:07:47,996
that we scanned 59 resources on

115
00:07:48,018 --> 00:07:52,184
the account and that drift control found resources

116
00:07:52,232 --> 00:07:55,756
not covered by terraform, like this access key that

117
00:07:55,778 --> 00:07:59,710
we just created. And it belongs to

118
00:08:00,160 --> 00:08:03,012
the IM user, microservice, LHz,

119
00:08:03,096 --> 00:08:06,592
something. We also display some information,

120
00:08:06,726 --> 00:08:10,740
like the number of resources, percentage coverage of your

121
00:08:10,810 --> 00:08:14,868
terraform code compared to what's on your AWS account,

122
00:08:14,954 --> 00:08:18,470
et cetera. So that's the kind of things terraform can

123
00:08:18,840 --> 00:08:22,172
miss by design on CI.

124
00:08:22,256 --> 00:08:26,600
And that's the kind of things drift control can show you live

125
00:08:26,750 --> 00:08:30,856
if you cause it. So this is the first story for

126
00:08:31,038 --> 00:08:35,124
this example. The second one is about security groups.

127
00:08:35,252 --> 00:08:38,972
At the beginning of the pandemic, people started working from home.

128
00:08:39,106 --> 00:08:42,956
And in this team, a couple of people couldn't connect

129
00:08:43,058 --> 00:08:46,220
to the company network and they didn't want CTO wait for it

130
00:08:46,290 --> 00:08:49,568
to solve the issue. They asked some managers to do something.

131
00:08:49,654 --> 00:08:53,168
And one of them had enough credentials to open up everything

132
00:08:53,254 --> 00:08:56,464
to everyone. And basically it solved the issue

133
00:08:56,582 --> 00:09:01,860
and you'll see. So how does it look like VPC?

134
00:09:02,200 --> 00:09:05,030
No, here we are,

135
00:09:06,920 --> 00:09:10,560
Main. So this is a security group. It's called super secure

136
00:09:10,640 --> 00:09:14,264
because it only allows port 22 ssh for the

137
00:09:14,302 --> 00:09:18,570
local network on AWS. So basically it's completely locked down.

138
00:09:20,700 --> 00:09:24,636
So if

139
00:09:24,658 --> 00:09:25,550
you go there,

140
00:09:28,990 --> 00:09:33,180
definitely we are good.

141
00:09:33,710 --> 00:09:37,018
So what did the team do in this case?

142
00:09:37,184 --> 00:09:41,146
The guy went to the security group in the console,

143
00:09:41,338 --> 00:09:43,710
he edited inbound rules.

144
00:09:44,370 --> 00:09:47,870
And basically what he did was adding a rule,

145
00:09:49,090 --> 00:09:52,154
all traffic from anywhere

146
00:09:52,282 --> 00:09:55,586
on IPV six, I-P-V. Four, and called it

147
00:09:55,688 --> 00:09:59,586
temp. So that it was sure it's going to remember it.

148
00:09:59,688 --> 00:10:03,414
All right, so now you have all your rules here.

149
00:10:03,612 --> 00:10:07,414
And the terraform was on

150
00:10:07,452 --> 00:10:11,730
CI. It was running every hour or so, and at the next terraform

151
00:10:11,810 --> 00:10:15,480
apply maybe 2 hours later. What happened?

152
00:10:20,350 --> 00:10:23,706
Do you think it would be reported as a

153
00:10:23,728 --> 00:10:27,338
new rule in the managed security group?

154
00:10:27,424 --> 00:10:31,178
Unfortunately not, because same story,

155
00:10:31,344 --> 00:10:35,770
it's not the same thing as seen on AWS.

156
00:10:35,850 --> 00:10:39,434
A rule seems like to be two objects,

157
00:10:39,482 --> 00:10:43,198
CTO, two elements of a single table array, but it's

158
00:10:43,214 --> 00:10:46,626
not the case at all on terraform. The way it

159
00:10:46,648 --> 00:10:50,354
was written here on terraform, it means that basically

160
00:10:50,472 --> 00:10:54,486
here, if we look again this

161
00:10:54,668 --> 00:10:58,082
here, it doesn't mean that adding an element to the array

162
00:10:58,146 --> 00:11:01,750
would be seen by terraform. It's a different object once again.

163
00:11:01,900 --> 00:11:06,550
So basically we needed a tool like Driftctl

164
00:11:07,950 --> 00:11:11,546
to show this team the

165
00:11:11,568 --> 00:11:15,450
drifts they had on their account. So here,

166
00:11:15,520 --> 00:11:19,390
now this team would have a security

167
00:11:19,460 --> 00:11:23,306
group rule discovered as unmanaged, not covered

168
00:11:23,338 --> 00:11:27,486
by terraform, and they would have had the whole information like the

169
00:11:27,508 --> 00:11:30,910
IPV, six addresses, source addresses, I-P-V four,

170
00:11:30,980 --> 00:11:33,790
the name, the id of the security group, the type.

171
00:11:33,940 --> 00:11:37,602
And they would have seen as well that their coverage went down. It went

172
00:11:37,656 --> 00:11:40,786
from how many it was,

173
00:11:40,888 --> 00:11:45,030
how much it was, it was 85% and now it's 66%.

174
00:11:45,100 --> 00:11:48,614
So it went down heavily. So basically that's about

175
00:11:48,652 --> 00:11:52,738
it for the security group story. If you add rules

176
00:11:52,834 --> 00:11:55,766
manually on the web console for AWS,

177
00:11:55,878 --> 00:11:59,034
and you wrote your rules that

178
00:11:59,072 --> 00:12:02,346
way on terraform, you will never

179
00:12:02,448 --> 00:12:06,394
see added rules using terraform. You need to use

180
00:12:06,512 --> 00:12:09,726
a specific tool for that. So unfortunately for them,

181
00:12:09,828 --> 00:12:13,470
nobody reported the change on the weeks after that.

182
00:12:13,540 --> 00:12:17,326
And the security group stood open for a

183
00:12:17,348 --> 00:12:21,122
very long time. So the third and final story

184
00:12:21,176 --> 00:12:24,274
for this talk is the AWS s

185
00:12:24,312 --> 00:12:28,146
free terrible story that a team in

186
00:12:28,168 --> 00:12:31,554
the UK in London, reported to me a few months ago.

187
00:12:31,672 --> 00:12:36,034
They were building a plugin, there were like 100 developers,

188
00:12:36,162 --> 00:12:39,542
and every hour or so they were uploading to s free

189
00:12:39,596 --> 00:12:42,610
a build of this temporary build of this plugin.

190
00:12:42,690 --> 00:12:45,990
And it was then processed by QA test,

191
00:12:46,060 --> 00:12:49,414
et cetera, and then dropped because it was useless

192
00:12:49,462 --> 00:12:53,194
at the time, just holy testing of everything. So it was

193
00:12:53,312 --> 00:12:57,530
hundreds of gigabytes every day, uploaded and processed and dropped.

194
00:12:57,950 --> 00:13:00,990
At some point there was another team in another country.

195
00:13:01,140 --> 00:13:04,846
They wanted to improve security and compliance in

196
00:13:04,868 --> 00:13:08,062
a company. And they went to see them and tell them,

197
00:13:08,116 --> 00:13:12,186
well, we will enable redundancy in versioning,

198
00:13:12,218 --> 00:13:15,586
sorry, in s three, so we will do it on

199
00:13:15,608 --> 00:13:19,282
your bucket as well. So the team I was talking to

200
00:13:19,416 --> 00:13:22,930
told them, well, it's perfectly useless in our case. It's cool

201
00:13:23,000 --> 00:13:26,710
for the others, but it's useless in our case because we'll cost a lot,

202
00:13:26,780 --> 00:13:30,454
because we definitely don't care about what we upload on s three.

203
00:13:30,572 --> 00:13:33,926
If it burns we don't care. We will have lost 1 hour of

204
00:13:33,948 --> 00:13:37,514
work, it's not can issue. So the other team said okay, cool,

205
00:13:37,552 --> 00:13:41,190
you mentioned that. So we will not enable s three versioning

206
00:13:41,270 --> 00:13:45,258
on your bucket. They went home, everybody was happy because

207
00:13:45,424 --> 00:13:48,906
the first team thought well anyway, if they make

208
00:13:48,928 --> 00:13:52,558
a mistake we have everything on terraform. And if they change

209
00:13:52,644 --> 00:13:56,606
a setting we will know about it, cause as you can see

210
00:13:56,708 --> 00:14:00,446
here, the resource is pretty simple and the bucket is declared, so we

211
00:14:00,468 --> 00:14:03,986
will know if they change something. So no problem with that. And the

212
00:14:04,008 --> 00:14:08,066
other team was happy as well because they scripted a wonderful script with

213
00:14:08,088 --> 00:14:11,394
a lot of exceptions for all the buckets, et cetera. And if

214
00:14:11,432 --> 00:14:14,726
it failed they will know about it as well. They executed the

215
00:14:14,748 --> 00:14:17,942
script, it enabled versioning everywhere and

216
00:14:17,996 --> 00:14:21,686
absolutely everywhere, because their exception didn't work, but they didn't know

217
00:14:21,708 --> 00:14:25,430
about it and they went on with their lives. And guess

218
00:14:25,500 --> 00:14:29,174
what happens at the first week of every month?

219
00:14:29,292 --> 00:14:33,082
It's the Edibaria's bill. So what happened in their case?

220
00:14:33,216 --> 00:14:36,586
So this is the bucket. And basically the

221
00:14:36,608 --> 00:14:41,200
script did something like enable here

222
00:14:41,890 --> 00:14:45,246
versioning. So it was not on the web console, but it's the

223
00:14:45,268 --> 00:14:49,470
same id. So the enabled versioning

224
00:14:50,550 --> 00:14:55,886
and now drift

225
00:14:55,918 --> 00:14:59,780
control would see

226
00:15:02,230 --> 00:15:06,434
here a change resource. So the AWS

227
00:15:06,482 --> 00:15:09,766
S three bucket conf 42 demo, whatever,

228
00:15:09,948 --> 00:15:13,282
has versioning enabled from false

229
00:15:13,346 --> 00:15:18,054
to true. If we go to s three folder,

230
00:15:18,182 --> 00:15:22,220
can see here and we terraform apply,

231
00:15:24,350 --> 00:15:28,046
it refreshes from AWS, it will

232
00:15:28,148 --> 00:15:31,706
not report the change. And even worse,

233
00:15:31,898 --> 00:15:35,534
some way it's not worse, it's meant for

234
00:15:35,572 --> 00:15:39,406
that. But if we look for the

235
00:15:39,428 --> 00:15:42,498
s free bucket here, we will see

236
00:15:42,664 --> 00:15:46,174
that versioning is enabled

237
00:15:46,222 --> 00:15:50,974
directly on the state. So that's something that was written

238
00:15:51,022 --> 00:15:52,980
on the state while not,

239
00:15:56,550 --> 00:16:00,930
while not expressed directly on the resource.

240
00:16:01,930 --> 00:16:05,446
Basically this kind of mistake can cost a lot

241
00:16:05,548 --> 00:16:08,746
as well. It's not a security issue in this case, but it can cost a

242
00:16:08,768 --> 00:16:12,666
lot to the company, cause it was definitely not cant to

243
00:16:12,688 --> 00:16:16,266
be enabled for weeks. This is a

244
00:16:16,288 --> 00:16:20,426
few examples from real life, but real life also includes

245
00:16:20,618 --> 00:16:23,786
different ways of managing that kind of drift.

246
00:16:23,898 --> 00:16:27,680
And if you want to integrate the data drift control

247
00:16:28,370 --> 00:16:31,486
reports with another tool, maybe you

248
00:16:31,508 --> 00:16:34,942
want to tour the data in a database for dashboards,

249
00:16:35,086 --> 00:16:38,334
for tracking, for integration in reports,

250
00:16:38,462 --> 00:16:42,094
et cetera. So you can use the JSON output

251
00:16:42,222 --> 00:16:45,510
from drift control. Let me show that

252
00:16:45,660 --> 00:16:49,430
to you. You can just add the output here.

253
00:16:49,580 --> 00:16:53,160
JSON output JSon, sorry.

254
00:16:53,530 --> 00:16:56,378
And basically, oh yeah,

255
00:16:56,464 --> 00:17:00,762
I'm not on the right folder and

256
00:17:00,816 --> 00:17:01,900
here we are.

257
00:17:03,870 --> 00:17:07,370
Okay, same output. And now if we take a look at

258
00:17:07,440 --> 00:17:10,606
output JSON, we have

259
00:17:10,628 --> 00:17:13,818
the same output that we had previously,

260
00:17:13,994 --> 00:17:17,198
but now as JSON. What's the use

261
00:17:17,284 --> 00:17:21,394
for that? Maybe you want to only keep the

262
00:17:21,432 --> 00:17:25,614
coverage output so you can just graph percentage

263
00:17:25,742 --> 00:17:29,746
directly on your directly, I don't know, on the dashboard or something,

264
00:17:29,928 --> 00:17:33,474
maybe on a pull request kind of things. So you can

265
00:17:33,512 --> 00:17:36,870
use JQ to parse the output and well,

266
00:17:36,940 --> 00:17:40,454
do whatever you want with it after that. That's it for the

267
00:17:40,492 --> 00:17:44,550
JSON output. There is a lot of filters. If you want to report

268
00:17:44,700 --> 00:17:48,358
only a certain type resources, only a certain tag,

269
00:17:48,454 --> 00:17:52,086
anything specific to your case, you can do it with drift

270
00:17:52,118 --> 00:17:55,734
control filters. It's using the gemspath query

271
00:17:55,782 --> 00:18:00,222
language. It's very useful to analyze and report on

272
00:18:00,276 --> 00:18:04,080
specific cases. This example here is about

273
00:18:05,010 --> 00:18:08,160
security group rules. It's not bad.

274
00:18:09,490 --> 00:18:13,090
It's a good example in our case. So it's

275
00:18:13,750 --> 00:18:18,270
filter type equal AWS

276
00:18:18,430 --> 00:18:22,660
security group rule and

277
00:18:23,610 --> 00:18:27,142
let's go. So the tool will report

278
00:18:27,276 --> 00:18:31,446
only on AWS security group rules and not

279
00:18:31,628 --> 00:18:35,198
the other resources. You can see here that the coverage

280
00:18:35,314 --> 00:18:39,542
dropped dramatically because we have so many drifts

281
00:18:39,606 --> 00:18:43,834
in security group rules that the coverage is now very very low.

282
00:18:44,032 --> 00:18:48,142
So yeah, filters are really, really useful on

283
00:18:48,196 --> 00:18:51,610
drift control to control to report on specific areas,

284
00:18:51,690 --> 00:18:55,646
even for enumeration or regular audits as

285
00:18:55,668 --> 00:18:59,006
well. So there is also this

286
00:18:59,108 --> 00:19:02,778
drift ignore file because you will probably start with

287
00:19:02,804 --> 00:19:06,290
a lot of unmanaged resources in your AWS account.

288
00:19:06,440 --> 00:19:09,634
I have a lot of mess, a lot of test files, and you

289
00:19:09,672 --> 00:19:13,346
probably do as well. Even by just testing things

290
00:19:13,448 --> 00:19:16,774
on AWS, it creates a lot of sub resources that

291
00:19:16,812 --> 00:19:20,214
are not clean afterwards. So drift control has

292
00:19:20,252 --> 00:19:23,186
support for this file, drift ignore.

293
00:19:23,298 --> 00:19:26,582
It's pretty much like the git ignore file that you already know.

294
00:19:26,636 --> 00:19:29,402
It takes a resource type. So like in this case,

295
00:19:29,456 --> 00:19:33,174
AWS im user and a name or an id. So it's

296
00:19:33,222 --> 00:19:36,998
terraform in this case because it's the first user that I created manually

297
00:19:37,094 --> 00:19:40,922
on the AWS console. So it's AWS imuser terraform,

298
00:19:40,986 --> 00:19:44,010
but it can be an id as well for a security group, et cetera.

299
00:19:44,090 --> 00:19:47,742
So you can ignore specific resources while

300
00:19:47,876 --> 00:19:51,218
you work on it, while you, I don't know,

301
00:19:51,304 --> 00:19:54,882
you import it on your terraform code,

302
00:19:55,016 --> 00:19:58,866
while you maybe will remove it from

303
00:19:58,968 --> 00:20:02,498
your account. At least you can start fresh or you can

304
00:20:02,584 --> 00:20:06,594
work on it at your pace. So when it's included

305
00:20:06,642 --> 00:20:10,054
in your drift ignore file, it will be ignored. That's the name

306
00:20:10,092 --> 00:20:13,734
of the file and you can also add this file to

307
00:20:13,772 --> 00:20:17,046
your own docker image. So if you include if you work with

308
00:20:17,068 --> 00:20:20,434
your own docker image, we have a cloud drift

309
00:20:20,482 --> 00:20:24,394
CTO image available, official image and you can start

310
00:20:24,432 --> 00:20:28,454
from there to add your own drift ignore so you are perfectly

311
00:20:28,582 --> 00:20:32,138
ready. CTO launch drift control with the ignore file.

312
00:20:32,234 --> 00:20:36,654
I don't know, as a scheduled job on

313
00:20:36,692 --> 00:20:40,186
Kubernetes for example. Finally, once you

314
00:20:40,228 --> 00:20:43,566
have your initial reports cleaned, you can deploy drift

315
00:20:43,598 --> 00:20:47,266
control in your CI pipeline, at least as

316
00:20:47,288 --> 00:20:50,290
a recurring task, cron job, et cetera,

317
00:20:50,870 --> 00:20:54,034
like well, every hour or so if your infrastructure

318
00:20:54,082 --> 00:20:57,218
is not too big so you can get alerts

319
00:20:57,314 --> 00:20:59,830
when something goes wrong in the hover.

320
00:21:00,570 --> 00:21:03,702
I've seen different use cases using drift control.

321
00:21:03,836 --> 00:21:08,022
So one of them is that after terraform

322
00:21:08,086 --> 00:21:11,094
apply is executed on the pipeline,

323
00:21:11,222 --> 00:21:15,386
a lot of other scripts are executed, stuff are done

324
00:21:15,488 --> 00:21:20,042
after terraform apply in the pipeline. And to ensure those scripts

325
00:21:20,106 --> 00:21:24,106
and stuff don't create a mess, people execute drift

326
00:21:24,138 --> 00:21:27,582
control after terraform apply and

327
00:21:27,636 --> 00:21:31,730
the rest of the pipeline. In the end, that's one use cause another

328
00:21:31,800 --> 00:21:35,954
use case is the exact opposite, the other way around. People want

329
00:21:35,992 --> 00:21:39,682
to ensure that the situation is perfectly under control before doing

330
00:21:39,736 --> 00:21:43,170
anything with terraform involving applied.

331
00:21:43,770 --> 00:21:47,842
Like using drift control, like a safety check before terraform

332
00:21:47,906 --> 00:21:53,046
apply can change anything on the state. Remember the

333
00:21:53,068 --> 00:21:56,642
TF state a few minutes ago that was modified

334
00:21:56,786 --> 00:22:00,182
because of the terraform refresh. It's the job of terraform

335
00:22:00,246 --> 00:22:04,202
refresh to do this. But if you do not want this to happen

336
00:22:04,256 --> 00:22:07,866
in your case, well put drift control first

337
00:22:07,968 --> 00:22:11,406
in your pipeline so you can put it at the end if

338
00:22:11,428 --> 00:22:13,600
you want to ensure things are okay.

339
00:22:14,530 --> 00:22:18,334
Or at the beginning if you want to ensure things

340
00:22:18,372 --> 00:22:21,938
are under control. Before executing terraform apply, you can use it

341
00:22:22,024 --> 00:22:25,522
in parallel with terraform plan as well because they do different

342
00:22:25,576 --> 00:22:28,834
things, one from the terraform scope and the other from

343
00:22:28,872 --> 00:22:31,966
outside the scope of terraform.

344
00:22:32,078 --> 00:22:35,446
In any case, I strongly advise you to

345
00:22:35,468 --> 00:22:38,966
deploy drift control like can how they check so you can

346
00:22:38,988 --> 00:22:42,040
get reports if anything changes.

347
00:22:42,730 --> 00:22:46,150
So yeah, basically that's about it.

348
00:22:46,300 --> 00:22:49,754
Drift control is written in Go. It's a brand new

349
00:22:49,792 --> 00:22:53,686
tool. It was released last December, early January. It's written

350
00:22:53,718 --> 00:22:57,814
in Go, the license Apache two, it has support for AWS

351
00:22:57,862 --> 00:23:01,754
and GitHub. More is to come. You can go on GitHub discussion

352
00:23:01,882 --> 00:23:05,914
upvote for the next cloud provider because we are really community driven.

353
00:23:05,962 --> 00:23:09,610
So if you cant Azure or digitalocean or GCP

354
00:23:09,690 --> 00:23:13,170
or I don't know what cloud provider go vote for it because

355
00:23:13,240 --> 00:23:17,282
that's where we're going CTO decide what's the next cloud

356
00:23:17,336 --> 00:23:20,702
provider to support. We support today the terraform

357
00:23:20,766 --> 00:23:24,722
state locally s free HTTP cloud terraform

358
00:23:24,786 --> 00:23:28,358
cloud is coming very soon. Basically same way,

359
00:23:28,444 --> 00:23:31,894
same situation. If you want to vote for other features like

360
00:23:31,932 --> 00:23:36,226
reading the terraform states, go vote on GitHub GitHub

361
00:23:36,258 --> 00:23:40,122
discussion there's a lot of discussions about that filtering ignore. I showed them

362
00:23:40,176 --> 00:23:43,866
in the slides. We are also very present,

363
00:23:44,048 --> 00:23:48,606
very active on Discord. You can go to drift control driftl.com

364
00:23:48,708 --> 00:23:52,560
d. It's a shortcut that redirects you

365
00:23:54,050 --> 00:23:57,726
to our discord community discord. We are there. We can answer all your

366
00:23:57,748 --> 00:24:00,878
questions live. We can help you live there as well.

367
00:24:01,044 --> 00:24:03,998
So if you joined during the talk,

368
00:24:04,164 --> 00:24:09,130
what CTO remember is that almost everyone is experiencing

369
00:24:09,290 --> 00:24:12,886
infrastructure drift and that we basically built

370
00:24:13,028 --> 00:24:16,440
drift control as an open source tool to

371
00:24:16,890 --> 00:24:20,470
increase the knowledge and security of

372
00:24:20,540 --> 00:24:23,990
automated cloud infrastructure drift. Yeah, thanks for watching

373
00:24:24,060 --> 00:24:27,414
and see you soon on Discord and on GitHub. Thank you.

374
00:24:27,452 --> 00:24:27,650
Bye.

