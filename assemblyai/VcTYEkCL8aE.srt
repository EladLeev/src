1
00:00:24,010 --> 00:00:27,318
Welcome everybody, and thank you very much for joining this talk.

2
00:00:27,484 --> 00:00:31,282
These is Kaus Engineering in the fast lane, accelerating resilience

3
00:00:31,346 --> 00:00:34,914
with AI and EBPF. I'm Francesco Sbaraglia.

4
00:00:34,962 --> 00:00:38,854
I'm SRE tech lead at Accenture in ISG and

5
00:00:38,892 --> 00:00:42,054
observability lead for EMEA. I have the pleasure to

6
00:00:42,092 --> 00:00:44,950
have with me today Michaela hi,

7
00:00:45,020 --> 00:00:49,590
my name is Michaela and I'm a site reliability engineer and SME at Accenture.

8
00:00:49,970 --> 00:00:53,642
The past years I've been focusing on various essay related topics

9
00:00:53,706 --> 00:00:58,042
such as aiops, observability and chaos engineering topics

10
00:00:58,106 --> 00:01:01,742
which I also presented on various other occasions as a public

11
00:01:01,796 --> 00:01:05,646
speaker. So I'm also very excited to present our new topic

12
00:01:05,678 --> 00:01:09,326
to you. Therefore, I suggest we don't waste time and kick

13
00:01:09,358 --> 00:01:13,262
off right away with the agenda. We will start off by provide

14
00:01:13,326 --> 00:01:16,514
an overview of today's burning challenges and trends in the world

15
00:01:16,552 --> 00:01:19,734
of chaos engineering. We will start with a list of

16
00:01:19,772 --> 00:01:23,746
pain points that we observe in the industry and then start to provide solutions

17
00:01:23,778 --> 00:01:26,440
for each one of these step by step.

18
00:01:26,970 --> 00:01:29,706
We will then introduce an interesting technology,

19
00:01:29,888 --> 00:01:33,114
EBPF, and we will show to you how we can

20
00:01:33,152 --> 00:01:36,330
leverage it to enhance our chaos engineering practices,

21
00:01:36,750 --> 00:01:39,914
especially when it's combined with the power

22
00:01:39,952 --> 00:01:42,540
of OpenAI or AI in general.

23
00:01:43,090 --> 00:01:46,366
As always, we will be presenting a custom demo in

24
00:01:46,388 --> 00:01:49,950
order to put into action everything that we've learned so far before

25
00:01:50,020 --> 00:01:52,990
finally wrapping up with the conclusion and takeaways.

26
00:01:53,510 --> 00:01:57,282
Furthermore, keep in mind that in this talk, the focus is rather

27
00:01:57,336 --> 00:02:01,380
on security observability rather than security itself.

28
00:02:01,990 --> 00:02:05,458
Here is an overview of the overall benefits that chaos engineering brings

29
00:02:05,474 --> 00:02:08,226
to the table. As mentioned in the beginning,

30
00:02:08,338 --> 00:02:11,762
both Francesco and I are site reliability engineers

31
00:02:11,906 --> 00:02:16,274
and therefore, it's only natural for us to try and formulate

32
00:02:16,322 --> 00:02:20,250
everything and all these statements from an SRE perspective.

33
00:02:20,750 --> 00:02:24,282
Having said that, the first point is more

34
00:02:24,416 --> 00:02:27,862
of a cultural one. Without the knowledge and best practices

35
00:02:27,926 --> 00:02:31,342
of chaos engineering, there is little anyone can do.

36
00:02:31,476 --> 00:02:35,706
Therefore, the first step is to bring awareness and upskill

37
00:02:35,738 --> 00:02:40,026
your SRE resources based on the latest trends and best practices.

38
00:02:40,218 --> 00:02:43,330
So as it says, bring them up to speed.

39
00:02:43,750 --> 00:02:46,674
Okay, so you're asking yourself,

40
00:02:46,792 --> 00:02:50,494
what is the ultimate goal of chaos engineering? What is the purpose

41
00:02:50,542 --> 00:02:53,140
of running a chaos experiment several times?

42
00:02:53,590 --> 00:02:57,522
I'm quite sure it's not just an attempt to destroy

43
00:02:57,666 --> 00:03:01,414
our system, but rather to test and discover its

44
00:03:01,452 --> 00:03:04,950
blind spots, which are revealed via chaos experiments.

45
00:03:05,530 --> 00:03:08,902
Once the vulnerabilities are revealed, we can start

46
00:03:08,956 --> 00:03:13,190
implementing approaches that will reduce unknown behavior or anomalies.

47
00:03:13,350 --> 00:03:16,986
So the goal here is to predict the unexpected and

48
00:03:17,008 --> 00:03:21,310
in order to do that, we first need to make our system observable.

49
00:03:21,890 --> 00:03:25,162
Obviously, once we have implemented mechanisms to discover

50
00:03:25,226 --> 00:03:28,506
and resolve potential failures, we implicitly reduce

51
00:03:28,538 --> 00:03:31,550
mean time to detect and mean time to resolve.

52
00:03:31,970 --> 00:03:35,378
Once a chaos experiment has detected a blind spot in

53
00:03:35,384 --> 00:03:39,314
our system which could lead to a potential failure, we are

54
00:03:39,352 --> 00:03:43,182
able then to determine its root cause and therefore

55
00:03:43,326 --> 00:03:47,102
we reduce also finger pointing issues that often

56
00:03:47,176 --> 00:03:50,834
occur between various teams in various organizations.

57
00:03:50,962 --> 00:03:54,962
And in such case the root cause is clear and so is the responsible

58
00:03:55,026 --> 00:03:58,138
team in the organization that needs to take care of it.

59
00:03:58,224 --> 00:04:01,334
Therefore, with chaos engineering, we also introduce

60
00:04:01,382 --> 00:04:04,886
better visibility and improve the overall communication

61
00:04:04,998 --> 00:04:06,810
between s three teams.

62
00:04:07,870 --> 00:04:10,742
Okay, that was a high level overview.

63
00:04:10,886 --> 00:04:14,554
We will now deep dive into the various challenges and provide a solution

64
00:04:14,602 --> 00:04:18,334
for each one of these. Let's start with the first one.

65
00:04:18,532 --> 00:04:22,394
As already preempted, without observability, I am unable

66
00:04:22,442 --> 00:04:25,394
to identify the issues that are impacting my system.

67
00:04:25,592 --> 00:04:29,746
Basically, I'm blind, especially in the case of connectivity issues.

68
00:04:29,848 --> 00:04:33,582
The question is, how can I then troubleshoot my Kubernetes

69
00:04:33,646 --> 00:04:36,802
clusters if I don't have the proper level of visibility,

70
00:04:36,946 --> 00:04:40,674
if I don't have the tools to look into my Kubernetes

71
00:04:40,722 --> 00:04:44,002
cluster? Think in general about containerized

72
00:04:44,066 --> 00:04:47,846
applications. What is really going on inside a container? There could

73
00:04:47,868 --> 00:04:51,114
be vulnerabilities. For instance, a container trying

74
00:04:51,152 --> 00:04:54,538
to read something that it shouldn't have access to. In that case,

75
00:04:54,624 --> 00:04:58,106
how do we conduct a risk assessment? That's the

76
00:04:58,128 --> 00:05:01,390
question that we want to answer with these challenge.

77
00:05:01,730 --> 00:05:05,070
In order to answer this question, we first need to introduce an interesting

78
00:05:05,140 --> 00:05:09,470
piece of technology. So let's start talking about EBPF.

79
00:05:09,970 --> 00:05:13,934
What is EBPF? EBPF stands for extended

80
00:05:13,982 --> 00:05:17,486
Berkeley packet filter. It can run sandbox programs

81
00:05:17,518 --> 00:05:21,026
in a privileged context. What does that mean? It means it

82
00:05:21,048 --> 00:05:23,090
can make the kernel programmable.

83
00:05:23,750 --> 00:05:27,334
Furthermore, EBPF comes from the open source community.

84
00:05:27,532 --> 00:05:31,382
There are a lot of enterprise companies interested and

85
00:05:31,436 --> 00:05:34,642
actively using EBPF, such as Meta,

86
00:05:34,706 --> 00:05:37,910
Google, Netflix and other big names.

87
00:05:38,410 --> 00:05:41,866
Also, keep in mind that EBPF is not really the

88
00:05:41,888 --> 00:05:45,578
new kid on the block. It already existed before, but with a

89
00:05:45,584 --> 00:05:49,354
different focus. So EBPF originally had its

90
00:05:49,392 --> 00:05:51,200
roots in the network area.

91
00:05:53,330 --> 00:05:57,098
It was used as a performance analyzer for networks,

92
00:05:57,274 --> 00:06:00,778
for example, used to detect malware and whatnot.

93
00:06:00,954 --> 00:06:04,562
But as we will see throughout these session, EBPF can

94
00:06:04,616 --> 00:06:07,570
be extended to much, much more. So basically,

95
00:06:07,640 --> 00:06:11,294
EBPF extends the OS kernel without changing

96
00:06:11,342 --> 00:06:15,054
the kernel source, without requiring a reboot, and without

97
00:06:15,192 --> 00:06:19,122
causing any crashes. Let's now see how EBPF

98
00:06:19,186 --> 00:06:22,840
actually work. I suggest we start from the user space

99
00:06:23,450 --> 00:06:27,074
where we attached our application, microservice networking

100
00:06:27,122 --> 00:06:30,886
components and various other processes. Then we

101
00:06:30,908 --> 00:06:35,446
have the chrono space at this current point in time entirely decoupled

102
00:06:35,478 --> 00:06:38,826
from the application. While the application process will

103
00:06:38,848 --> 00:06:42,586
at some point have a system call, for instance

104
00:06:42,698 --> 00:06:46,174
execute, the system call will create an event

105
00:06:46,292 --> 00:06:50,762
which is then calling the EBPF program that we have injected.

106
00:06:50,906 --> 00:06:54,286
This way, every time the process executes something on

107
00:06:54,308 --> 00:06:57,986
the kernel side, it will run the EBPF program.

108
00:06:58,168 --> 00:07:01,970
These is a great feature as we can use EBPF to understand the system

109
00:07:02,040 --> 00:07:06,034
calls exactly as they are triggered in prod. Meaning with

110
00:07:06,072 --> 00:07:09,474
EBPF we can replicate and detect a real incident

111
00:07:09,602 --> 00:07:13,234
as if it would have occurred in Prod. This is super helpful

112
00:07:13,282 --> 00:07:16,662
because when an incident in prod occurs, I can then

113
00:07:16,716 --> 00:07:20,406
track and understand all system calls and replicate

114
00:07:20,438 --> 00:07:23,398
them more accurately into a chaos engineering experiment.

115
00:07:23,574 --> 00:07:27,242
Basically every time we have something, anything happening

116
00:07:27,296 --> 00:07:30,330
in our program, it will run these system call inside

117
00:07:30,400 --> 00:07:33,374
the kernel, which then called these EBPF program,

118
00:07:33,492 --> 00:07:37,680
and which will then run on the scheduler and will start our application.

119
00:07:38,530 --> 00:07:42,566
This is why we say that EBPF programs are event reading

120
00:07:42,698 --> 00:07:46,420
and this is how we increase awareness from the kernel side.

121
00:07:47,030 --> 00:07:51,106
Overall, EBPF tools have the ability to instrument these system

122
00:07:51,208 --> 00:07:54,178
without requiring any prior configuration changes.

123
00:07:54,344 --> 00:07:57,846
And in this way we sort of strengthen the

124
00:07:57,868 --> 00:08:01,350
coupling and context awareness between the kernel and

125
00:08:01,420 --> 00:08:04,982
our application sitting in the user space. And remember,

126
00:08:05,116 --> 00:08:09,126
the kernel becomes a sort of big brother because from this point onwards

127
00:08:09,238 --> 00:08:11,740
it is able to see basically everything.

128
00:08:12,670 --> 00:08:15,946
Okay, so we learned about the basics of EBPF and

129
00:08:15,968 --> 00:08:18,982
its benefits, but the question remains,

130
00:08:19,126 --> 00:08:22,318
what is actually an EBPF program and

131
00:08:22,484 --> 00:08:25,726
what does it look like? So the question we

132
00:08:25,748 --> 00:08:29,146
want to ask ourselves now, from a technical perspective,

133
00:08:29,258 --> 00:08:32,910
how do we load our EBPF program into the kernel?

134
00:08:33,270 --> 00:08:36,866
Let's start, for example, by taking a look at this python code

135
00:08:36,968 --> 00:08:40,434
that compiles our EBPF program.

136
00:08:40,632 --> 00:08:44,430
First thing we need is to load the EBPF library,

137
00:08:44,590 --> 00:08:47,510
which we need to move the program inside the kernel.

138
00:08:47,930 --> 00:08:50,600
I then have my hello world program.

139
00:08:50,970 --> 00:08:54,662
So I load EBPF and attach it to the kernel via our

140
00:08:54,716 --> 00:08:57,398
execve system call. Remember,

141
00:08:57,564 --> 00:09:00,994
this system call will invoke the hello function.

142
00:09:01,132 --> 00:09:04,490
And this is how we get our program into the kernel.

143
00:09:04,910 --> 00:09:09,046
So if we look at the right hand side, every time a new program runs

144
00:09:09,078 --> 00:09:12,894
in this virtual machine, my hello EBPF program will be

145
00:09:12,932 --> 00:09:16,810
triggered from inside the kernel. And this is how we increase awareness

146
00:09:16,890 --> 00:09:20,554
from the kernel side. Now that we introduced

147
00:09:20,602 --> 00:09:24,558
EBPF, let's see how we can use it to improve

148
00:09:24,734 --> 00:09:27,330
our overall chaos engineering practice.

149
00:09:27,830 --> 00:09:31,726
Consider a classic deployment structure, CI CD

150
00:09:31,758 --> 00:09:35,702
pipeline running on a Kubernetes and or cloud

151
00:09:35,756 --> 00:09:39,206
native. Then we have an application that we

152
00:09:39,228 --> 00:09:42,806
want to deploy, and the application is running

153
00:09:42,988 --> 00:09:46,150
on a pod with possibly many containers.

154
00:09:46,730 --> 00:09:50,746
And let's say that we don't know what's happening in

155
00:09:50,768 --> 00:09:54,074
the containers as of now. Let's say

156
00:09:54,112 --> 00:09:57,254
that we now use a chaos engineering platform to inject

157
00:09:57,302 --> 00:10:00,300
a chaos experiment into our user space.

158
00:10:00,610 --> 00:10:04,094
So the question is, what about

159
00:10:04,212 --> 00:10:07,962
security vulnerabilities? How can we detect

160
00:10:08,026 --> 00:10:11,630
these? How can we detect that dacaos experiment is running

161
00:10:11,700 --> 00:10:14,946
in my Kubernetes cluster? I believe you

162
00:10:14,968 --> 00:10:18,734
can already anticipate the answer. With EBPF,

163
00:10:18,782 --> 00:10:22,514
we have visibility into what is happening and what these

164
00:10:22,552 --> 00:10:27,026
vulnerabilities might be, therefore also visibility

165
00:10:27,138 --> 00:10:30,230
into the chaos experiment we just injected.

166
00:10:30,650 --> 00:10:33,800
Keep in mind that on the left hand side,

167
00:10:34,730 --> 00:10:38,934
we just have one singular app. We want to deploy one

168
00:10:38,972 --> 00:10:43,046
user space and one pod. That is something that we can monitor relatively

169
00:10:43,078 --> 00:10:46,874
easily. As I can see what is happening with my app, thanks to

170
00:10:46,912 --> 00:10:50,606
EBPF, which also feeds my information to my end

171
00:10:50,628 --> 00:10:54,206
to end mission control. These mission control

172
00:10:54,308 --> 00:10:57,950
launches a trigger in case of any issues detected.

173
00:10:58,370 --> 00:11:01,760
However, if we look on the right hand side,

174
00:11:02,130 --> 00:11:05,870
we have a much more complex environment.

175
00:11:05,950 --> 00:11:08,926
We have much more than just one deployment.

176
00:11:09,038 --> 00:11:12,290
Imagine a huge and complex microservice deployment.

177
00:11:12,870 --> 00:11:15,220
So what does it change?

178
00:11:16,090 --> 00:11:20,258
Not much, really, because when creating a container,

179
00:11:20,354 --> 00:11:24,390
accessing any file or network, pay attention to the

180
00:11:24,460 --> 00:11:28,706
little EBPF icons next

181
00:11:28,748 --> 00:11:32,746
to these squares. As you can see, EBPF is

182
00:11:32,768 --> 00:11:35,974
attached to all of these, and EBPF is able to scare

183
00:11:36,022 --> 00:11:39,850
and sre all of this. EBPF is aware of everything

184
00:11:39,920 --> 00:11:43,294
that is going on on the node and can help us reproduce any

185
00:11:43,332 --> 00:11:46,574
disruptive application and platform behavior. This is why

186
00:11:46,612 --> 00:11:50,238
we say that EBPF enables context awareness on a

187
00:11:50,244 --> 00:11:53,746
more cloud native level. Now that

188
00:11:53,768 --> 00:11:56,978
we have thoroughly analyzed the role of EBPF, let's move on to

189
00:11:56,984 --> 00:12:00,386
the next challenge. Now we

190
00:12:00,408 --> 00:12:03,922
can leverage EBPF to gain even better visibility into

191
00:12:03,976 --> 00:12:08,538
our system. How do we do that? We can use EBPF

192
00:12:08,654 --> 00:12:11,602
to collect even more events and metrics,

193
00:12:11,746 --> 00:12:15,320
which we can use to trigger the big red stop button.

194
00:12:15,930 --> 00:12:19,434
For those who are unfamiliar with the concept of big

195
00:12:19,472 --> 00:12:23,450
red stop button, it is basically a metaphorical,

196
00:12:23,790 --> 00:12:27,306
it's a metaphorical term used in chaos engineering to indicate an

197
00:12:27,328 --> 00:12:31,002
imaginary stop button, which sort of aborts the chaos

198
00:12:31,066 --> 00:12:34,814
experiments. If we observe that things start to go wrong and we

199
00:12:34,852 --> 00:12:38,590
want to prevent it from further damaging our system for instance.

200
00:12:38,930 --> 00:12:42,518
Interestingly, this term

201
00:12:42,554 --> 00:12:46,130
is inspired from an actual red stop button which

202
00:12:46,280 --> 00:12:49,618
is used in machine production. So they always have

203
00:12:49,704 --> 00:12:54,194
a sort of big physical red button there to

204
00:12:54,232 --> 00:12:57,640
abort any operations if they see things start going wrong.

205
00:12:58,410 --> 00:13:01,894
Nevertheless, going back to our approach, the goal is to

206
00:13:01,932 --> 00:13:05,830
make use of EBPF insights to generate some automation actions.

207
00:13:06,410 --> 00:13:10,282
Let's take a good look at what EBPF and what

208
00:13:10,336 --> 00:13:13,674
benefits we can get from EBPF, which can be used

209
00:13:13,712 --> 00:13:16,170
to enhance our chaos engineering approach.

210
00:13:16,830 --> 00:13:20,822
Firstly, no application changes, and this also means

211
00:13:20,896 --> 00:13:24,766
no prior configuration changes and no need to change the kernel space,

212
00:13:24,868 --> 00:13:28,350
no need to reboot, and it doesn't cause any crashes.

213
00:13:29,010 --> 00:13:32,126
Secondly, EBPF sees all activities on the

214
00:13:32,148 --> 00:13:35,646
node, whether it's one deployment or more deployments,

215
00:13:35,758 --> 00:13:39,182
as we previously saw one or more container.

216
00:13:39,246 --> 00:13:42,050
The point is, EBPF always scales.

217
00:13:42,710 --> 00:13:45,990
Then we have the basis for security observability.

218
00:13:46,410 --> 00:13:49,042
EBPF increases context awareness,

219
00:13:49,106 --> 00:13:52,470
provides a deeper and more cloud native level of visibility,

220
00:13:52,890 --> 00:13:56,454
and makes it easier to detect and respond to

221
00:13:56,492 --> 00:13:59,770
security threats and vulnerabilities, which obviously

222
00:13:59,840 --> 00:14:03,126
without EBPF we wouldn't be able to do on such a deep

223
00:14:03,158 --> 00:14:07,002
level, for example seeing what is happening on a container level.

224
00:14:07,136 --> 00:14:09,686
Otherwise we would be totally blunt.

225
00:14:09,878 --> 00:14:13,370
Finally, this data can be used to generate metrics and events,

226
00:14:13,450 --> 00:14:17,374
which are then used as an input to our AI prediction in order

227
00:14:17,412 --> 00:14:21,102
to generate actionable insights. I mean, in the end,

228
00:14:21,156 --> 00:14:25,154
that's the whole point. Why are we collecting all of this data with

229
00:14:25,192 --> 00:14:28,466
or without EBPF, if we're not going to make use of

230
00:14:28,488 --> 00:14:31,666
it to generate some predictions? So,

231
00:14:31,688 --> 00:14:35,342
to summarize this slide, with EBPF, we don't need dozens

232
00:14:35,406 --> 00:14:38,530
or hundreds of tools to have a better control of our experiments.

233
00:14:38,610 --> 00:14:42,198
EBPF does it all. And with this

234
00:14:42,284 --> 00:14:45,606
we conclude our second challenge. Thank you so

235
00:14:45,628 --> 00:14:49,138
much Mikhaila. Let's have a look and move over on the next challenge.

236
00:14:49,234 --> 00:14:53,066
Design an inset security clouds experiments within kubernetes how

237
00:14:53,088 --> 00:14:56,822
we are going to solve this? Yes, we can use a BPF.

238
00:14:56,886 --> 00:15:00,474
APF will help us to design new security cows experiment will

239
00:15:00,512 --> 00:15:04,286
help us to understand the behavior of an application under security

240
00:15:04,388 --> 00:15:08,270
attack. And we can also try to understand what are the steps

241
00:15:09,170 --> 00:15:13,054
in the different levels and what sre these sequence of

242
00:15:13,092 --> 00:15:16,274
the steps to try to breach and gather data from

243
00:15:16,312 --> 00:15:20,254
our cluster. But as well use our cluster maybe to do other faber

244
00:15:20,302 --> 00:15:24,062
attack. What we can see here is the classical

245
00:15:24,206 --> 00:15:28,254
attack integrated of a Kubernetes cluster. We know in Kubernetes cluster

246
00:15:28,302 --> 00:15:31,362
we have a master node, maybe they have component like FTCD.

247
00:15:31,426 --> 00:15:34,546
We have a control plane, we have a worker nodes

248
00:15:34,578 --> 00:15:38,418
where they have maybe a Kubernetes that can be accessed via API.

249
00:15:38,514 --> 00:15:42,586
And then last but not least, we have our pod where our application will run.

250
00:15:42,688 --> 00:15:46,646
Of course if you see in a different level, we can have a different vulnerability

251
00:15:46,758 --> 00:15:50,346
of different attack interface. On these right hand

252
00:15:50,368 --> 00:15:53,886
side, what you can see there are these typical cyber attack can example can

253
00:15:53,908 --> 00:15:57,946
be I can run my kubernetes on the same node,

254
00:15:58,138 --> 00:16:02,094
I can have maybe a privileged pod that can run,

255
00:16:02,132 --> 00:16:05,886
I can escape the pod, maybe we reach other pod or we'll

256
00:16:05,918 --> 00:16:09,854
try kind of to inject any malicious

257
00:16:09,902 --> 00:16:13,234
code. We can have also malicious web book. So this

258
00:16:13,272 --> 00:16:17,460
will call maybe outside of our cluster and we'll try to get these other information.

259
00:16:17,910 --> 00:16:21,526
And maybe another example can be to gather token from outside

260
00:16:21,628 --> 00:16:24,806
or to read the other token that we are actually we are not allowed to

261
00:16:24,828 --> 00:16:28,422
do. And in these case we need to try to understand how we can

262
00:16:28,556 --> 00:16:32,074
catch a lot of data. Of course we have already our security,

263
00:16:32,192 --> 00:16:35,754
our CM, we are monitoring this behavior, so we

264
00:16:35,792 --> 00:16:39,578
know exactly what can happen and that can be really bad.

265
00:16:39,744 --> 00:16:43,086
And then what we see like on the right side down.

266
00:16:43,188 --> 00:16:47,002
So we have these top three vulnerabilities for Kubernetes

267
00:16:47,146 --> 00:16:50,750
attacks. Let's get only three of them. So maybe I can

268
00:16:50,900 --> 00:16:54,666
misconfigure my container, maybe I can have a malicious container

269
00:16:54,698 --> 00:16:58,306
image that we run and this will try to escape or

270
00:16:58,328 --> 00:17:01,794
to gather data from someone else. But what we will see and what we will

271
00:17:01,832 --> 00:17:05,302
focus also later, it's especially on

272
00:17:05,356 --> 00:17:09,074
unintentional cluster misconfiguration. So we have a misconfiguration

273
00:17:09,122 --> 00:17:13,202
inside our cluster. One of the pod will enable

274
00:17:13,266 --> 00:17:16,918
us to do other attacks or maybe to get other information.

275
00:17:17,084 --> 00:17:20,854
And these we are trying to understand how a BPF is helping

276
00:17:20,902 --> 00:17:24,026
us to do the discovery, but also to try to understand what are

277
00:17:24,048 --> 00:17:27,370
the sequence and maybe replicate in another experiment.

278
00:17:27,870 --> 00:17:31,066
What you see here, in fact what we can do is

279
00:17:31,168 --> 00:17:34,874
to use a capability of a BPF of creating network

280
00:17:34,922 --> 00:17:38,282
policy. So in this case we use psyllium, EBPF,

281
00:17:38,346 --> 00:17:41,614
what are the benefit that will give us at the end. So the first thing

282
00:17:41,652 --> 00:17:45,086
is create a better network experiment, because now

283
00:17:45,108 --> 00:17:48,914
I don't need to use any other software outside,

284
00:17:49,032 --> 00:17:53,074
but I can use the model from EBPF to create

285
00:17:53,192 --> 00:17:56,318
this network experiment. I can isolate my pod,

286
00:17:56,414 --> 00:18:00,214
of course I can create some rules. We will see also later I have also

287
00:18:00,332 --> 00:18:03,894
apple that will tell me what are the internal connection or

288
00:18:03,932 --> 00:18:07,286
the connection to outside. And I can have a look on

289
00:18:07,308 --> 00:18:10,746
this case to kind of troubleshoot. If I have this problem I

290
00:18:10,768 --> 00:18:14,186
can do also experiment in a service mesh. This will help me of

291
00:18:14,208 --> 00:18:17,318
course to do other experiments that are a bit more complex,

292
00:18:17,494 --> 00:18:21,034
maybe crossing different cloud or different Kubernetes

293
00:18:21,082 --> 00:18:24,366
cluster and the multicluster. In fact experiments is

294
00:18:24,388 --> 00:18:28,314
the fact when we have designed our architectures

295
00:18:28,362 --> 00:18:31,838
to have different automation of kubernetes cluster and then in

296
00:18:31,844 --> 00:18:34,466
this case what I can do is to try to understand if I have an

297
00:18:34,488 --> 00:18:37,906
isolation of this region, what will happen in the

298
00:18:37,928 --> 00:18:41,154
end. And we always start with these fact with the question of

299
00:18:41,192 --> 00:18:44,962
what if it's also pusher proof because as

300
00:18:45,016 --> 00:18:48,194
you will see also in the live demo later wherever when I will do

301
00:18:48,232 --> 00:18:51,366
like a node I o resource exhaustion. What I can do

302
00:18:51,468 --> 00:18:55,382
is that I can use now MVPF and we were already using

303
00:18:55,436 --> 00:18:59,062
before because we were already using for the classical network

304
00:18:59,126 --> 00:19:02,586
performance or for network observability. But in this

305
00:19:02,608 --> 00:19:05,834
case we will use a more active way and we can

306
00:19:05,872 --> 00:19:10,554
create our VPF model and we can inject these

307
00:19:10,592 --> 00:19:13,790
resources. Of course a bit more like affecting than before,

308
00:19:13,860 --> 00:19:17,134
because with the BBF, as was explained before also

309
00:19:17,172 --> 00:19:21,246
by Mikira, we move away from our user space and we are

310
00:19:21,268 --> 00:19:24,994
running in the kernel space network resources option. Of course now

311
00:19:25,032 --> 00:19:28,962
I can do a bit more, I can use like BGP, I can do other

312
00:19:29,016 --> 00:19:32,980
experiment, a bit more complexity. All they are like

313
00:19:33,590 --> 00:19:36,910
just using like YamL file and you can read there is

314
00:19:36,920 --> 00:19:40,822
also the source for this network policy, how they work and how it's super

315
00:19:40,876 --> 00:19:44,134
easy to apply. We will show later

316
00:19:44,252 --> 00:19:47,510
one of them and how we do this network

317
00:19:47,850 --> 00:19:51,734
troubleshooting. Last but not least is about pod resources

318
00:19:51,782 --> 00:19:56,006
option. So I can run and use the performance testing

319
00:19:56,038 --> 00:19:59,322
from MVPF. And here I can understand what will happen

320
00:19:59,376 --> 00:20:03,166
when a pod will consume the old

321
00:20:03,188 --> 00:20:06,670
cpu, all the memory, all the disk. And in this case

322
00:20:06,820 --> 00:20:10,446
I can prevent because I can also act in blocking something.

323
00:20:10,548 --> 00:20:13,902
So at the end a VPF removes the need to kill

324
00:20:13,956 --> 00:20:17,534
or delete the pod and to deploy any other new tools.

325
00:20:17,582 --> 00:20:21,074
I'm running already because I have a PPF installed and it's running

326
00:20:21,112 --> 00:20:24,798
already on my kernel, so I can trigger whatever I want and I don't

327
00:20:24,814 --> 00:20:28,546
need to restart nothing at the end. Okay, now let's move on.

328
00:20:28,568 --> 00:20:32,342
The next challenge and actually is the last one before our

329
00:20:32,396 --> 00:20:36,258
demo. So getting started with the very first causal

330
00:20:36,274 --> 00:20:40,018
engineering experiments, that's always a question that we have. So where we

331
00:20:40,044 --> 00:20:43,206
start, how we start, how we do reduce this toil

332
00:20:43,238 --> 00:20:46,490
at the end. So what we thought about is to create

333
00:20:46,560 --> 00:20:50,154
a house engineering copilot that's powered by generator Bi.

334
00:20:50,272 --> 00:20:53,450
We'll gather all the data that I have, like my postmortem

335
00:20:53,530 --> 00:20:57,482
data, my incident data, anything, any documentation

336
00:20:57,546 --> 00:21:00,942
that I have architecture and we can use this

337
00:21:00,996 --> 00:21:04,410
to generate our first experiment. So we will see in the

338
00:21:04,420 --> 00:21:07,874
next slide how we do it. First of all,

339
00:21:07,912 --> 00:21:11,314
we do like a bit of architecture. So we have on the left

340
00:21:11,352 --> 00:21:15,198
side our SRE. Our SRE will use our cows.

341
00:21:15,214 --> 00:21:19,090
Engineering copilot okay, let's move on to our last challenge.

342
00:21:19,170 --> 00:21:23,282
So getting started with our first house engineering experiment.

343
00:21:23,346 --> 00:21:27,142
So we always have the challenge. We don't know how to create maybe

344
00:21:27,196 --> 00:21:30,954
the first experiment, the first hypothesis, or maybe

345
00:21:30,992 --> 00:21:34,522
the steps and the one that are most effective for our

346
00:21:34,576 --> 00:21:38,038
usage. How we solve it. We solve it using a causal

347
00:21:38,054 --> 00:21:41,434
engineering copilot powered by generative AI. At these end we will see also

348
00:21:41,472 --> 00:21:44,906
later is a script. In the script it's super easy. We integrate via

349
00:21:44,938 --> 00:21:48,318
our CI CD pipeline. Every time that we deploy something new,

350
00:21:48,404 --> 00:21:51,806
this will start to run. And what we'll do, we'll try to

351
00:21:51,828 --> 00:21:55,458
understand based on various data. Let's have a look on

352
00:21:55,464 --> 00:21:59,506
the architecture. As you can see there's really simple architecture in

353
00:21:59,528 --> 00:22:02,818
the left side. Our SRE will use these copilot. We'll create

354
00:22:02,904 --> 00:22:06,482
maybe manual for the first time and then

355
00:22:06,536 --> 00:22:09,770
later they will move inside CICD pipeline

356
00:22:09,790 --> 00:22:12,838
with just a Python script. We have a look on the Python script also in

357
00:22:12,844 --> 00:22:16,326
the next slide. But it's interesting is that in these case we

358
00:22:16,348 --> 00:22:20,134
can generate an hypothesis and we can also have the

359
00:22:20,172 --> 00:22:23,322
usage of historical data. What are the historical data

360
00:22:23,376 --> 00:22:27,254
at the end? So what you see here, usually with EBPF we extract

361
00:22:27,302 --> 00:22:31,102
a lot of data, this data that we were mentioning before about

362
00:22:31,156 --> 00:22:34,926
the application behavior or platform behavior. And in this case what we

363
00:22:34,948 --> 00:22:38,480
can do is to give this as a context inside

364
00:22:39,090 --> 00:22:42,414
our generative AI. We can also

365
00:22:42,532 --> 00:22:45,662
get data that are automatically

366
00:22:45,806 --> 00:22:49,474
coming like from our observability tool. So those will be real

367
00:22:49,512 --> 00:22:53,570
time data. And these maybe can be used as a stop button

368
00:22:53,720 --> 00:22:56,850
or as a trigger for the next experiments.

369
00:22:57,530 --> 00:23:01,014
In fact, here we see already that we use AI for three different

370
00:23:01,132 --> 00:23:05,074
topology. The first thing is to try to understand unknown

371
00:23:05,122 --> 00:23:08,582
pattern. So not just using generative AI to generate something new,

372
00:23:08,636 --> 00:23:12,138
but also using AI to predict which ones are the pattern that

373
00:23:12,144 --> 00:23:15,882
are most effective but also easy to use without having

374
00:23:15,936 --> 00:23:19,782
a lot of risk. Second, we'll analyze the application behavior

375
00:23:19,926 --> 00:23:24,090
based on this APF data. We can try to understand the different steps

376
00:23:24,250 --> 00:23:27,374
or the different system calls that the application is doing,

377
00:23:27,492 --> 00:23:31,482
and we can simulate and replicate them in a controlled

378
00:23:31,546 --> 00:23:35,506
way. And last but not least, based on our historical attack,

379
00:23:35,608 --> 00:23:39,310
the one that we had before or our postmortem reports,

380
00:23:39,390 --> 00:23:43,266
what we can do is predict the area that where we can OpenAI

381
00:23:43,448 --> 00:23:46,098
these next incident,

382
00:23:46,274 --> 00:23:50,182
but also the area where we can concentrate our experiment. Because maybe

383
00:23:50,236 --> 00:23:53,810
we want to improve the classical mitdmetDr.

384
00:23:53,890 --> 00:23:57,602
So in fact, AI and collection of generative

385
00:23:57,666 --> 00:24:01,094
AI. What we'll do for us is first

386
00:24:01,132 --> 00:24:05,450
of all we'll answer a question, what is the cause, what are the

387
00:24:05,520 --> 00:24:09,542
problem or the application that can be affected or in general component

388
00:24:09,606 --> 00:24:13,790
that can be affected. And if we can predict the behavior.

389
00:24:14,210 --> 00:24:18,094
And if you see here, there is a cycle. So every time that we

390
00:24:18,132 --> 00:24:21,518
finish one of the experiment, this experiment is

391
00:24:21,604 --> 00:24:25,154
used by the next run of generative AI that

392
00:24:25,192 --> 00:24:29,566
will improve and make a better hypothesis or create new hypothesis,

393
00:24:29,678 --> 00:24:33,694
having a look at different area. And in this case, in fact we can automate

394
00:24:33,822 --> 00:24:38,178
completely. Those are not only the classical house experiments,

395
00:24:38,274 --> 00:24:42,418
but of course we can also extend in these security house experimentation.

396
00:24:42,514 --> 00:24:46,390
In fact, with the BPF we are collecting also security and auditing.

397
00:24:46,970 --> 00:24:50,630
Okay, already in fact we also tagulated the last challenges.

398
00:24:50,710 --> 00:24:54,170
But before moving on, we have a look on these small

399
00:24:54,240 --> 00:24:57,846
example that we build from the general DBI.

400
00:24:57,958 --> 00:25:02,042
So this is a small script, we just use the OpenAI service.

401
00:25:02,176 --> 00:25:05,886
And what you can see, it's a bit different than the classical one. But what

402
00:25:05,908 --> 00:25:08,954
we are doing is first of all we are creating a system role.

403
00:25:09,002 --> 00:25:13,186
So this is a classical prompt engineering. You see that we are embodying an

404
00:25:13,208 --> 00:25:16,946
expert on causal experiments. We are also

405
00:25:16,968 --> 00:25:20,974
in these second step bringing more context hunting

406
00:25:21,022 --> 00:25:24,222
like more data. Maybe there are the historical

407
00:25:24,286 --> 00:25:27,922
data, maybe there are past incidents,

408
00:25:28,066 --> 00:25:31,334
maybe we have also available like

409
00:25:31,372 --> 00:25:34,534
some postmortem report. And maybe

410
00:25:34,572 --> 00:25:38,518
we have light data from our observability tool. This will of course create

411
00:25:38,604 --> 00:25:42,234
a bit more context to our generation of these hypothesis. And we see

412
00:25:42,272 --> 00:25:46,026
the last comment is about create can hypothesis for an

413
00:25:46,048 --> 00:25:50,010
experimentation. And I want to have step by step for a specific service.

414
00:25:50,160 --> 00:25:54,418
And the system, what will generate, of course will generate the hypothesis

415
00:25:54,454 --> 00:25:57,920
for us, but will also generate which are the possible

416
00:25:58,450 --> 00:26:02,014
experiment that we can use. We always need to validate before

417
00:26:02,052 --> 00:26:05,602
we run. So we really encourage to do a dry run

418
00:26:05,656 --> 00:26:09,150
before and to validate what is the output.

419
00:26:09,310 --> 00:26:13,170
But this is like a really good starting point

420
00:26:13,320 --> 00:26:17,720
and we can move on these next on the demo for today.

421
00:26:18,090 --> 00:26:21,334
Okay, let's move on on the demo. So what

422
00:26:21,372 --> 00:26:25,190
we will see later in the architectures is the classical

423
00:26:25,770 --> 00:26:28,438
boutique shop. So we have a boutique shop,

424
00:26:28,604 --> 00:26:32,474
we have a front end, we have a couple of services, front end

425
00:26:32,512 --> 00:26:35,898
service, checkout service, payment services and so

426
00:26:35,904 --> 00:26:39,626
on. So we see that 1 hour target in fact is our

427
00:26:39,808 --> 00:26:43,162
checkout service. And the view that you see here

428
00:26:43,296 --> 00:26:46,538
is from Abol Ui.

429
00:26:46,634 --> 00:26:50,682
So in Apple UI we can have a view on what are the connection

430
00:26:50,746 --> 00:26:54,274
inside the cluster. You see there are a lot of tcp connection from

431
00:26:54,312 --> 00:26:58,754
inside, from outside. But also how these different services

432
00:26:58,872 --> 00:27:01,874
they are calling each other. Okay,

433
00:27:01,912 --> 00:27:06,174
here we have a look first of all to our retail

434
00:27:06,222 --> 00:27:09,654
shop. So this is the one that we saw

435
00:27:09,692 --> 00:27:13,334
before as architectures. So it's the classical one where maybe

436
00:27:13,372 --> 00:27:16,742
I can add something on the chart, then I can do maybe

437
00:27:16,796 --> 00:27:20,374
like go shopping again. And last but not

438
00:27:20,412 --> 00:27:23,558
least I will do maybe placeholder and my order is placed.

439
00:27:23,654 --> 00:27:27,402
So what we'll do like under the wood, of course there is the wall

440
00:27:27,456 --> 00:27:31,020
application. These they are called that I done. So I put

441
00:27:31,630 --> 00:27:35,134
something like in the cart. Maybe these is these front end

442
00:27:35,172 --> 00:27:38,830
that is doing a call to shipment service to the cart service.

443
00:27:38,980 --> 00:27:42,558
And lately last to the checkout and payment service.

444
00:27:42,644 --> 00:27:45,934
So super easy like demo. Let's jump

445
00:27:46,062 --> 00:27:49,394
on our experiments in the end. So the first thing that you can sre

446
00:27:49,432 --> 00:27:52,834
here, I want to attach to one

447
00:27:52,872 --> 00:27:56,418
of these pod and service that I'm running. So I

448
00:27:56,424 --> 00:28:00,086
will have a look what I have. So as we said, we want to have

449
00:28:00,108 --> 00:28:03,542
a look on the checkout service. And I put here

450
00:28:03,596 --> 00:28:06,774
on my checkout service. So I want to handle my checkout service before

451
00:28:06,812 --> 00:28:10,218
I handle my checkout service, what I will do. So we deployed in

452
00:28:10,224 --> 00:28:14,266
this case tetragon. Tetragon is listening to any

453
00:28:14,448 --> 00:28:17,786
EBPF events and we

454
00:28:17,808 --> 00:28:21,262
will see what we can achieve. So first of all I'm going

455
00:28:21,316 --> 00:28:25,022
list and in this case and the first thing that what I can do,

456
00:28:25,076 --> 00:28:29,360
I will enter inside my pod. So I'm inside

457
00:28:29,890 --> 00:28:34,114
my container. And what I can do here, for example,

458
00:28:34,312 --> 00:28:37,442
just a clear already message. So in this case, you see

459
00:28:37,576 --> 00:28:40,610
nothing is happening under the tetragon.

460
00:28:40,950 --> 00:28:44,738
But the interesting is coming when I'm applying a tracing policy.

461
00:28:44,824 --> 00:28:48,038
So imagine that I want to understand the behavior and I want to

462
00:28:48,044 --> 00:28:51,734
replicate the same behavior as an experiment. So I

463
00:28:51,772 --> 00:28:54,806
prepared some of them. So I will apply one of

464
00:28:54,828 --> 00:28:58,722
them. That is the EBPF one. So the EBPF

465
00:28:58,786 --> 00:29:02,330
of course will try to catch some of the

466
00:29:02,400 --> 00:29:06,150
library that are loaded. To try to understand if my container

467
00:29:06,230 --> 00:29:10,118
is doing something that is not allowed. The second one

468
00:29:10,224 --> 00:29:11,600
that I want to start,

469
00:29:13,330 --> 00:29:17,210
I created one about the capability.

470
00:29:17,370 --> 00:29:20,670
So if my pod is trying to use any capability,

471
00:29:21,490 --> 00:29:25,054
then of course these will be will create

472
00:29:25,092 --> 00:29:28,946
an event that will be triggered at these end. So if now I run

473
00:29:29,128 --> 00:29:33,426
the message so it's using some of the capability in

474
00:29:33,448 --> 00:29:37,170
the next I would see when these will be catched

475
00:29:37,250 --> 00:29:41,190
by tedragon. So I can do something a bit more.

476
00:29:41,260 --> 00:29:45,366
So I will apply the next one on

477
00:29:45,388 --> 00:29:49,034
the processes. So in fact every process in this

478
00:29:49,072 --> 00:29:52,602
case will be monitored and will create an event

479
00:29:52,656 --> 00:29:56,954
inside VPF. And now imagine here. So I'm attached in

480
00:29:56,992 --> 00:30:00,506
the one that is the load generator. In this

481
00:30:00,528 --> 00:30:04,382
case I see immediately that there is a system call. So if you see

482
00:30:04,436 --> 00:30:07,822
now I can go a bit deeper like I'm having

483
00:30:07,876 --> 00:30:11,166
a look on all system call that this service is

484
00:30:11,188 --> 00:30:14,606
doing and in this case I see also that I have

485
00:30:14,628 --> 00:30:17,860
locos that is running this system call.

486
00:30:19,190 --> 00:30:22,706
Maybe I enter again so I'm a bad guy. So what I

487
00:30:22,728 --> 00:30:26,210
can do is maybe try to understand my password

488
00:30:26,550 --> 00:30:30,006
so the list of the user that we run and to also try

489
00:30:30,028 --> 00:30:33,266
to understand if I can do some privilege escalation

490
00:30:33,378 --> 00:30:36,806
or maybe I can run with a different user that is open.

491
00:30:36,908 --> 00:30:40,810
And in this case you see every event will be automatically

492
00:30:41,310 --> 00:30:44,646
create an event inside tedragon.

493
00:30:44,678 --> 00:30:48,714
So tedragon of course in this case I'm using via command line but

494
00:30:48,752 --> 00:30:53,534
I can also export and use in

495
00:30:53,572 --> 00:30:57,006
another way. We will run one of the experiment that

496
00:30:57,028 --> 00:31:01,120
is super easy one. So that will only just

497
00:31:02,470 --> 00:31:05,906
increase a bit of the cpu of my

498
00:31:05,928 --> 00:31:09,140
pod. So I'm getting one of them.

499
00:31:09,670 --> 00:31:12,946
So we just run one command in this

500
00:31:12,968 --> 00:31:16,274
case and you see immediately that also this

501
00:31:16,312 --> 00:31:19,926
is generating an event and it's a bit different because

502
00:31:20,028 --> 00:31:23,190
it's a process in this case so it's not a real system

503
00:31:23,260 --> 00:31:26,886
call and now I'm generating load. So imagine that this is a

504
00:31:26,908 --> 00:31:30,410
normal experiments, so I understand when it's real

505
00:31:30,480 --> 00:31:34,154
starting my experiment and understand what are the behavior of my

506
00:31:34,192 --> 00:31:38,090
application. So by Sean's these, if I'm attaching and listening

507
00:31:38,430 --> 00:31:42,406
on the basic application that of course is a demo purpose.

508
00:31:42,518 --> 00:31:46,446
But if I know that there is a special process that will need the

509
00:31:46,468 --> 00:31:49,854
resources, what I can do is to attach and listen

510
00:31:49,972 --> 00:31:53,774
and to try to understand if the behavior of this process is changing

511
00:31:53,822 --> 00:31:57,074
based on the load that I'm inserting. So of course

512
00:31:57,112 --> 00:32:00,306
I can do like a bit more so we

513
00:32:00,328 --> 00:32:04,354
can go in security observability where I know

514
00:32:04,392 --> 00:32:08,086
also the steps because of course those steps that are in

515
00:32:08,108 --> 00:32:12,706
this case that I'm running, I have a cycle hands and I can generate

516
00:32:12,898 --> 00:32:16,214
a better experiment now. So I will stop now

517
00:32:16,252 --> 00:32:19,814
this and what I will do is maybe I will run

518
00:32:19,932 --> 00:32:23,538
these message and the message is a bit trying.

519
00:32:23,724 --> 00:32:27,066
You need to have the privileges to run this command at the end. And what

520
00:32:27,088 --> 00:32:30,878
you see here, in fact I have this command that

521
00:32:30,964 --> 00:32:34,558
is first of all running and

522
00:32:34,724 --> 00:32:38,346
starting my VPF program that I loaded.

523
00:32:38,458 --> 00:32:42,554
And these next, what I see is in fact all events

524
00:32:42,602 --> 00:32:46,114
that are getting created by my call. Last but

525
00:32:46,152 --> 00:32:49,426
not least as we provide it, we want to understand how we are

526
00:32:49,448 --> 00:32:52,818
going to kind of understand which

527
00:32:52,904 --> 00:32:55,806
connection we have, if we have problem with connection.

528
00:32:55,918 --> 00:32:59,522
So what I created is a tracing

529
00:32:59,586 --> 00:33:02,930
point. So I can attach these tracing point to a EBPF.

530
00:33:03,010 --> 00:33:06,886
And what will do this will help me to understand the

531
00:33:06,908 --> 00:33:10,442
connections that are done, if the connection, they are successful, but also

532
00:33:10,496 --> 00:33:14,182
which kind of TCP connection that maybe they are broken

533
00:33:14,246 --> 00:33:17,654
and they are not going in the right direction

534
00:33:17,702 --> 00:33:21,134
or maybe they are just low. So let's have a look. So first of all,

535
00:33:21,172 --> 00:33:24,366
I want to see the one that

536
00:33:24,388 --> 00:33:27,774
I already have running in this case. So I see

537
00:33:27,812 --> 00:33:31,098
that I created three tracing policies.

538
00:33:31,274 --> 00:33:35,218
What I want to add is the last one. So that's about

539
00:33:35,384 --> 00:33:38,930
having a list these on all TCP connection.

540
00:33:39,350 --> 00:33:42,930
Let me apply and you will see now that

541
00:33:43,080 --> 00:33:46,534
we'll log all the events about

542
00:33:46,732 --> 00:33:50,134
this TCP connection. Yeah, you see,

543
00:33:50,252 --> 00:33:54,274
so in this case we have a process that is named locust.

544
00:33:54,322 --> 00:33:57,806
So locust, what is doing is opening a TCP

545
00:33:57,858 --> 00:34:01,366
connection to another endpoint.

546
00:34:01,478 --> 00:34:05,082
In this case we know that is our front end and we know

547
00:34:05,136 --> 00:34:08,854
also that is exchanging some called,

548
00:34:08,902 --> 00:34:12,914
because locust for us is used as a load generator,

549
00:34:13,062 --> 00:34:16,430
is trying to kind of test anything

550
00:34:16,500 --> 00:34:19,886
that we have. So it's doing all API calls and we see all the

551
00:34:19,908 --> 00:34:23,502
API calls. But what I see, that's also interesting because I have other

552
00:34:23,556 --> 00:34:27,506
calls that are not the standard one and not the normal one. So now what

553
00:34:27,528 --> 00:34:31,122
you can imagine is that in this case I can script all

554
00:34:31,176 --> 00:34:34,318
these called that I have or DCP connection.

555
00:34:34,414 --> 00:34:38,214
What I can do is replicate an incident. Maybe I can

556
00:34:38,252 --> 00:34:41,734
listen in some of the real

557
00:34:41,852 --> 00:34:45,654
production services and can try to understand

558
00:34:45,852 --> 00:34:49,462
all the events that are getting integrated,

559
00:34:49,526 --> 00:34:52,714
all called that are done. I can try also to

560
00:34:52,752 --> 00:34:57,642
kind of map them and give to

561
00:34:57,696 --> 00:35:01,386
AI to understand the behavior of my application. And I

562
00:35:01,408 --> 00:35:05,358
will know exactly what are the lateral movers that are done and

563
00:35:05,444 --> 00:35:09,422
what I can do now I can replicate and create a better

564
00:35:09,556 --> 00:35:12,880
experiments for the next round. So in fact,

565
00:35:13,190 --> 00:35:17,682
we use here the combination of different

566
00:35:17,736 --> 00:35:20,994
tools as we saw before. So first of all,

567
00:35:21,032 --> 00:35:24,366
we instrumented and we added

568
00:35:24,398 --> 00:35:27,126
CNU. We are using the version 1150.

569
00:35:27,308 --> 00:35:31,138
We also sre using Apple, because we want to observe

570
00:35:31,234 --> 00:35:34,486
all these connection as we saw in the UI before.

571
00:35:34,668 --> 00:35:38,346
I will be able also to run Abol, of course in

572
00:35:38,368 --> 00:35:42,230
a command line where it's giving me like other dimension,

573
00:35:42,390 --> 00:35:45,770
because those data can be used later for

574
00:35:45,920 --> 00:35:49,306
other experimentation. And what I'm using at

575
00:35:49,328 --> 00:35:52,906
the end is tetragon. So Tetragon is creating

576
00:35:52,938 --> 00:35:56,986
of course a JSON file. So I can consume this JSON

577
00:35:57,018 --> 00:36:01,034
file automation, but I can also create metrics

578
00:36:01,162 --> 00:36:04,834
and connect this to an

579
00:36:04,872 --> 00:36:08,834
example to my CI CD pipeline. So imagine that as always we have,

580
00:36:08,872 --> 00:36:12,370
so we have our customer deployment and production system,

581
00:36:12,440 --> 00:36:15,406
or to maybe before an integration environment.

582
00:36:15,518 --> 00:36:18,886
And I want to run an experiment, but I want to know also if the

583
00:36:18,908 --> 00:36:22,966
experiment that I created is exactly doing the

584
00:36:22,988 --> 00:36:26,358
behavior that I want to have. Example that my application will

585
00:36:26,444 --> 00:36:30,406
not respond after maybe three or four calls, or maybe with

586
00:36:30,428 --> 00:36:33,562
the load that I integrated is the right one. And here, in fact,

587
00:36:33,616 --> 00:36:37,100
what I can do, I can be sure 100%

588
00:36:37,470 --> 00:36:40,486
that my cousin experiment is running as expected.

589
00:36:40,598 --> 00:36:44,560
And on the other side, what I can do later. So there will be

590
00:36:45,010 --> 00:36:48,894
a new experimentation that will come directly using

591
00:36:48,932 --> 00:36:53,002
a BPF. So where I don't need to inject nothing

592
00:36:53,076 --> 00:36:57,746
manually anymore, but what I can do, I can use again a

593
00:36:57,768 --> 00:37:01,154
different layer. I can go in a layer of

594
00:37:01,192 --> 00:37:04,670
a kernel space where I can generate an experiment

595
00:37:04,830 --> 00:37:08,694
directly there. That's a bit dangerous. So that's why we are

596
00:37:08,892 --> 00:37:12,806
tuning it. And maybe we can show in the next demo

597
00:37:12,988 --> 00:37:17,110
for the next time. Thank you very much for joining today for

598
00:37:17,180 --> 00:37:21,210
this demo session. If you are interested, you can ping us also after

599
00:37:21,280 --> 00:37:24,826
this talk and I will hand over to

600
00:37:24,848 --> 00:37:29,174
Michaela for the wrap up. Thank you so much. Thanks Francesco,

601
00:37:29,222 --> 00:37:32,720
for the fantastic demo. I suggest we wrap things up now.

602
00:37:33,090 --> 00:37:36,714
Today we saw how we can leverage AI Genai

603
00:37:36,762 --> 00:37:40,202
and EBPF to better detect running chaos experiments.

604
00:37:40,346 --> 00:37:44,106
Remember, EBPF goes beyond classical observability.

605
00:37:44,298 --> 00:37:47,874
EBPF is extremely helpful, as when an

606
00:37:47,912 --> 00:37:51,810
incident in protocols, we can use it to track and understand all

607
00:37:51,880 --> 00:37:55,466
system calls and replicate them more accurately into a chaos

608
00:37:55,518 --> 00:37:59,026
engineering experiments. Additionally, not to forget

609
00:37:59,058 --> 00:38:02,594
the role of AI, which can be used to significantly enhance threat

610
00:38:02,642 --> 00:38:06,338
and anomaly detection. And these final takeaway,

611
00:38:06,434 --> 00:38:09,974
I would like to point out from today's session. Start simple and

612
00:38:10,012 --> 00:38:13,654
scale fast. So you don't know where to start from. Well,

613
00:38:13,772 --> 00:38:17,606
start from a simple experiment, see how the system reacts, see how it

614
00:38:17,628 --> 00:38:21,374
goes, and as you proceed, you can scale, you can basically build more and more

615
00:38:21,412 --> 00:38:24,986
on top of that. Well, it seems it's time to close the curtains.

616
00:38:25,098 --> 00:38:27,340
Thanks a lot for watching. And until next time.

