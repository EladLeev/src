1
00:00:25,410 --> 00:00:28,950
You. Yes. Hello everyone.

2
00:00:29,100 --> 00:00:32,486
Very happy to be here. Very happy. Two join comfort e

3
00:00:32,508 --> 00:00:35,910
two. My name is Long Zhang and today my topic is

4
00:00:35,980 --> 00:00:39,762
maximizing error injection realism for chaos engineering

5
00:00:39,826 --> 00:00:43,522
with system calls. So of course we can replace maximizing

6
00:00:43,586 --> 00:00:47,666
with improving here because I can't see like I have maximizing

7
00:00:47,778 --> 00:00:51,294
the array injection realism, but it still interesting to

8
00:00:51,332 --> 00:00:55,386
explore how to improve the realism for chaos engineering

9
00:00:55,418 --> 00:00:58,894
experiments. So, about myself. Currently I'm doing my

10
00:00:58,932 --> 00:01:02,542
phd study at KTH KTH Royal Institute

11
00:01:02,596 --> 00:01:06,782
of Technology, Sweden. And before that I was a software

12
00:01:06,846 --> 00:01:10,046
engineer at Tencent in China. And I'm very proud

13
00:01:10,078 --> 00:01:14,190
to say that one of my main research topics is chaos

14
00:01:14,350 --> 00:01:18,194
engineering. Exactly. So it's really nice to join a conference

15
00:01:18,242 --> 00:01:21,494
such as conf fourty two and discuss all kinds of

16
00:01:21,532 --> 00:01:24,998
novel findings of chaos engineering with everyone here.

17
00:01:25,084 --> 00:01:29,654
So today. Yes, so during my research work I

18
00:01:29,692 --> 00:01:33,434
find like there are a lot of nice talks, tutorials and also

19
00:01:33,472 --> 00:01:37,386
nice tools. And I find that people also talking about

20
00:01:37,488 --> 00:01:40,998
the challenges of chaos engineering nowadays. So for example,

21
00:01:41,104 --> 00:01:45,390
here are some challenges I find the first one, how to evaluate different

22
00:01:45,460 --> 00:01:48,830
aspects of resilience because chaos engineering can be done

23
00:01:48,900 --> 00:01:52,190
at different levels, like operating system level,

24
00:01:52,260 --> 00:01:55,554
network level or application level. And then we need

25
00:01:55,592 --> 00:01:59,250
to have extra observability of an application

26
00:01:59,400 --> 00:02:02,946
and collect different kinds of metrics so we can

27
00:02:03,048 --> 00:02:07,338
precisely define how our system behaves during AnKLC

28
00:02:07,374 --> 00:02:11,222
engineering experiment. And how to evaluate the resilience of

29
00:02:11,276 --> 00:02:14,806
an application at different level, in different aspects can be

30
00:02:14,828 --> 00:02:18,822
quite challenging. The second one, how to automate the chaos experiments.

31
00:02:18,886 --> 00:02:22,554
Though we have lots of awesome tools today, they do

32
00:02:22,592 --> 00:02:26,134
help, do helps a lot for chaos

33
00:02:26,182 --> 00:02:30,098
engineering experiments, but still based on the applications

34
00:02:30,134 --> 00:02:34,090
concrete scenario, how to make this automation really helpful

35
00:02:34,170 --> 00:02:37,662
and efficient for developers, this can be

36
00:02:37,716 --> 00:02:41,438
quite challenging, like how we automate the flow, how we

37
00:02:41,604 --> 00:02:45,094
learn from the chaos engineering experiments automatically,

38
00:02:45,162 --> 00:02:48,494
and how we use the learned knowledge for our future chaos

39
00:02:48,542 --> 00:02:52,018
engineering. So this deal can be challenging and

40
00:02:52,104 --> 00:02:55,822
need more research work on that. And the third challenge, how to improve

41
00:02:55,886 --> 00:02:59,158
the efficiency of chaos experiments. So for example,

42
00:02:59,244 --> 00:03:03,266
if we are going to explore some really large faulty injection

43
00:03:03,378 --> 00:03:07,014
search space like, we have a lot of different combinations to

44
00:03:07,052 --> 00:03:10,682
inject different kinds of failures in production, but given the

45
00:03:10,736 --> 00:03:15,158
limited experiment time, we can't really explore every possibilities.

46
00:03:15,254 --> 00:03:18,950
So how to improve the efficiency of this chaos experiment,

47
00:03:19,030 --> 00:03:22,538
how to learn as much as we can during an experiment.

48
00:03:22,634 --> 00:03:26,654
This can be challenging and to explore this can be quite helpful for

49
00:03:26,772 --> 00:03:30,574
our future chaos engineering experiments. And today I could

50
00:03:30,612 --> 00:03:34,066
like to only focus on the third challenge, how to

51
00:03:34,088 --> 00:03:37,810
improve the efficiency of the chaos experiments and I believe

52
00:03:37,880 --> 00:03:42,030
that there will be lots of different directions,

53
00:03:42,110 --> 00:03:45,350
different solutions for this challenge. One of the idea

54
00:03:45,420 --> 00:03:49,234
we come up with is to synthesize realistic failure

55
00:03:49,282 --> 00:03:52,694
models for chaos engineering, because let us take an example,

56
00:03:52,812 --> 00:03:56,230
if we have lots of different

57
00:03:56,300 --> 00:03:59,666
failures to explore and the experiment time

58
00:03:59,708 --> 00:04:03,802
is quite limited. Also, this will be done in production, so it's sort of

59
00:04:03,856 --> 00:04:07,670
risky if we inject so many different kinds of failures,

60
00:04:07,750 --> 00:04:11,086
especially some failures, they may not actually happened in

61
00:04:11,108 --> 00:04:14,794
production. So how to synthesize realistic failure models

62
00:04:14,842 --> 00:04:18,506
that actually is possible to see these errors

63
00:04:18,538 --> 00:04:22,522
in production? And then we use chaos in engineering experiments

64
00:04:22,586 --> 00:04:25,890
to explore more. Like to learn more about how your system

65
00:04:25,960 --> 00:04:29,394
behaves under such an error, such a failure. This could be

66
00:04:29,432 --> 00:04:32,862
quite interesting, and then we can learn more in limited

67
00:04:32,926 --> 00:04:36,302
time. So based on this idea, we could like to

68
00:04:36,376 --> 00:04:40,390
do some more research. And to be precise, and to do

69
00:04:40,460 --> 00:04:43,362
deep research, we would like to narrow down the scope.

70
00:04:43,426 --> 00:04:47,358
So we want to focus on system call invocations

71
00:04:47,474 --> 00:04:51,674
at this moment. But of course this idea can be used and

72
00:04:51,792 --> 00:04:55,146
explored at other levels. For example,

73
00:04:55,248 --> 00:04:58,390
at application level we can also synthesize

74
00:04:58,550 --> 00:05:02,694
exception like failure models, failure models with respect

75
00:05:02,742 --> 00:05:06,122
to Java exceptions, and then we try it in chaos

76
00:05:06,186 --> 00:05:09,694
engineering experiments that should also work. But today I would like only to

77
00:05:09,732 --> 00:05:13,694
present our research work at the system come invocations level about how

78
00:05:13,732 --> 00:05:17,870
to synthesize realized failure models for chaos engineering experiments.

79
00:05:17,950 --> 00:05:21,550
Yes. And next, before going into InA details,

80
00:05:21,630 --> 00:05:25,054
I could like to show you a short demonstration so we can

81
00:05:25,112 --> 00:05:28,530
have an overall picture of system call invocations,

82
00:05:28,610 --> 00:05:32,550
and also about this naturally happening errors at the system

83
00:05:32,620 --> 00:05:36,038
calls invocation level. First of all, about system

84
00:05:36,124 --> 00:05:40,138
call. So system call is a fundamental interface between

85
00:05:40,224 --> 00:05:43,642
an application and the operating system, or let's say the

86
00:05:43,696 --> 00:05:47,766
Linux kernel. And usually the critical resources

87
00:05:47,878 --> 00:05:52,006
such as network or disk storage, or maybe like thread

88
00:05:52,038 --> 00:05:55,406
scheduling, et cetera. These resources are controlled by the

89
00:05:55,508 --> 00:05:59,326
operating system kernel. And then when application needs

90
00:05:59,428 --> 00:06:02,994
some resources in these categories, the application

91
00:06:03,112 --> 00:06:07,362
needs to invoke some specific system calls. So the

92
00:06:07,416 --> 00:06:11,410
application invokes system calls. It transforms

93
00:06:11,830 --> 00:06:15,718
the control from the user space to the kernel space,

94
00:06:15,804 --> 00:06:19,926
and then the kernel can arrange the resources for

95
00:06:19,948 --> 00:06:23,318
the application. So in Linux kernel there

96
00:06:23,404 --> 00:06:26,962
are more than 300 different kinds of system calls.

97
00:06:27,026 --> 00:06:30,170
And also Linux provides more than 100 different

98
00:06:30,240 --> 00:06:33,734
kinds of error codes. So the Linux

99
00:06:33,782 --> 00:06:36,922
kernel can precisely report different kinds of

100
00:06:36,976 --> 00:06:41,130
errors when system call invocation fails. So imagine

101
00:06:41,550 --> 00:06:45,466
this is quite like a big combination. Like we have hundreds

102
00:06:45,498 --> 00:06:49,114
of system call types, we also have hundreds of errors codes

103
00:06:49,162 --> 00:06:53,166
if we want two, do some experiments at system call level if

104
00:06:53,188 --> 00:06:56,354
we want to. Inject some system calls errors on

105
00:06:56,392 --> 00:06:59,454
purpose, then it's quite like time consuming.

106
00:06:59,502 --> 00:07:03,042
If we try to combine different system calls types with

107
00:07:03,096 --> 00:07:07,234
different errors codes, and actually some of the combinations are not realistic

108
00:07:07,282 --> 00:07:10,530
and they can never happen in production environment.

109
00:07:10,610 --> 00:07:14,002
So we need a better strategy

110
00:07:14,066 --> 00:07:17,526
to generate some error injection models and

111
00:07:17,548 --> 00:07:21,222
then we can pick up the most interesting errors

112
00:07:21,286 --> 00:07:24,726
to inject in our system and learn about the resilience.

113
00:07:24,838 --> 00:07:28,122
Okay, so about the demo. Now I'm going to

114
00:07:28,256 --> 00:07:31,840
switch to my terminal. Yes. So here

115
00:07:32,210 --> 00:07:35,482
we have mount, we have a script

116
00:07:35,546 --> 00:07:39,242
to monitor all kinds of system calls invocations

117
00:07:39,306 --> 00:07:42,922
for us. Right. Currently I'm using OBS, a software

118
00:07:42,986 --> 00:07:46,802
called OBS, to record this video. And when you watch

119
00:07:46,856 --> 00:07:50,162
this video or listen to this video, I believe that you won't feel

120
00:07:50,216 --> 00:07:53,620
anything abnormal like the pictures, the videos

121
00:07:53,990 --> 00:07:57,606
are good and also the sound is quite good. So this means the

122
00:07:57,628 --> 00:08:01,000
OBS is functioning correctly. And behind this

123
00:08:01,770 --> 00:08:05,526
we can feel like the OBS must interact a lot with

124
00:08:05,548 --> 00:08:09,142
the system and it invokes lots of different system calls.

125
00:08:09,206 --> 00:08:13,322
So let's take a look at this. There is a script called system

126
00:08:13,376 --> 00:08:17,478
call monitor. And then given the process name OBS,

127
00:08:17,574 --> 00:08:20,858
I would like to use milliseconds as a unit,

128
00:08:20,954 --> 00:08:24,606
and I also want to monitor the latency of different system calls,

129
00:08:24,628 --> 00:08:28,526
invocations. And please report, call the

130
00:08:28,548 --> 00:08:30,880
metrics every 1 second.

131
00:08:32,950 --> 00:08:36,802
Okay, so now we can see like yes,

132
00:08:36,856 --> 00:08:40,830
the OBS indeed does lots of system call invocations,

133
00:08:40,990 --> 00:08:43,698
and the type is here, few text read,

134
00:08:43,864 --> 00:08:47,586
write, et cetera, and different counts

135
00:08:47,698 --> 00:08:51,682
of the system call invocations. And also most of the system calls

136
00:08:51,746 --> 00:08:55,190
succeed. But still we can see like some of the system

137
00:08:55,260 --> 00:08:58,874
calls called and we can see the percentage of

138
00:08:58,912 --> 00:09:02,122
these failures. Let's see, so behind this

139
00:09:02,176 --> 00:09:05,882
field tax system calls we also had like field tax e

140
00:09:05,936 --> 00:09:09,340
again. And also let's see,

141
00:09:10,030 --> 00:09:13,694
yes, most of them are field tax, but if

142
00:09:13,732 --> 00:09:17,534
we keep watching this for several, maybe one

143
00:09:17,572 --> 00:09:20,830
or two minutes, I think we will have more

144
00:09:20,980 --> 00:09:25,294
failures to observe. For example, this one execve,

145
00:09:25,422 --> 00:09:28,946
it failed four times in 1 second. And all of

146
00:09:28,968 --> 00:09:32,340
them return an en o ent errors code.

147
00:09:33,190 --> 00:09:36,886
So this is just an idea. Like we can feel the

148
00:09:37,068 --> 00:09:40,760
presence of system call invocations behind one application.

149
00:09:41,770 --> 00:09:45,106
Every application indeed does lots of system calls,

150
00:09:45,138 --> 00:09:47,750
and some of them failed naturally.

151
00:09:48,170 --> 00:09:51,786
So this is the idea first, and if we want to

152
00:09:51,808 --> 00:09:56,454
make it a bit more complex. So for example, we keep monitoring

153
00:09:56,502 --> 00:10:00,462
the application and we keep extracting these metrics and

154
00:10:00,516 --> 00:10:04,526
put them into the database. So in a

155
00:10:04,548 --> 00:10:09,114
long time we can have a series of monitoring

156
00:10:09,242 --> 00:10:12,810
metrics at the system call level and then we can have

157
00:10:12,900 --> 00:10:16,606
really diverse information about the natural

158
00:10:16,638 --> 00:10:19,774
happening errors at this system call invocation

159
00:10:19,822 --> 00:10:23,554
level. So for example, this one is a

160
00:10:23,592 --> 00:10:27,174
dashboard. We deployed an email server into

161
00:10:27,212 --> 00:10:31,042
production and we just keep it running as euro

162
00:10:31,186 --> 00:10:35,286
and we also register different email address,

163
00:10:35,388 --> 00:10:38,434
email accounts into different mailing list.

164
00:10:38,572 --> 00:10:42,342
So we do collect some natural traffic

165
00:10:42,406 --> 00:10:46,250
here. And then by attaching the system calls

166
00:10:46,320 --> 00:10:50,490
invocation monitor, we can collect the metrics like the failure rate,

167
00:10:50,560 --> 00:10:54,278
the total number of system call invocations and also like

168
00:10:54,304 --> 00:10:57,806
the latency of the system call invocations, et cetera. So you

169
00:10:57,828 --> 00:11:01,662
see here there are many different kinds of system

170
00:11:01,716 --> 00:11:05,822
calls failed with different IR codes, e again econary

171
00:11:05,886 --> 00:11:09,694
site, et cetera. And this can be quite helpful

172
00:11:09,742 --> 00:11:13,394
and interesting for us to see. Okay, even though

173
00:11:13,432 --> 00:11:17,218
the email server is functioning and still we have lots

174
00:11:17,234 --> 00:11:21,526
of different errors at the system call level and

175
00:11:21,628 --> 00:11:25,654
they return like different error codes. And also the failure rate are

176
00:11:25,692 --> 00:11:29,018
quite different. Sometimes they called a lot and sometimes

177
00:11:29,104 --> 00:11:33,638
it's really rare to observe one single errors in production.

178
00:11:33,814 --> 00:11:37,290
So this is a question to be discussed here,

179
00:11:37,440 --> 00:11:40,682
because these are errors. So an error

180
00:11:40,746 --> 00:11:43,280
can be handled by the operating system,

181
00:11:43,810 --> 00:11:47,610
it can be remediated, but if the operating

182
00:11:47,690 --> 00:11:50,698
system cannot handle this error, usually it wraps

183
00:11:50,714 --> 00:11:54,066
the error and reports it. Two, the application,

184
00:11:54,248 --> 00:11:57,534
for example, if some system call invocations called

185
00:11:57,582 --> 00:12:01,154
and the Linux kernel cannot handle it, it can

186
00:12:01,192 --> 00:12:04,798
wrap it as a Java exception. And then in our

187
00:12:04,904 --> 00:12:08,226
java application we can write a try catch block to handle

188
00:12:08,258 --> 00:12:12,742
this concrete error scenario. So interesting

189
00:12:12,876 --> 00:12:16,440
question is, we are not sure

190
00:12:18,510 --> 00:12:22,138
if these errors happen more frequently because

191
00:12:22,224 --> 00:12:26,054
sometimes it's rare to observe one errors. But if this errors

192
00:12:26,102 --> 00:12:29,420
happened far more frequently in a

193
00:12:29,970 --> 00:12:33,882
severe scenario, how our application behaves,

194
00:12:34,026 --> 00:12:38,298
then it can be quite interesting to explore

195
00:12:38,394 --> 00:12:41,310
this using chaos engineering experiments.

196
00:12:41,730 --> 00:12:45,778
Okay, let's come back to the slides. So that's why

197
00:12:45,864 --> 00:12:49,986
we could like to do some research at system come level and also

198
00:12:50,168 --> 00:12:54,446
about analyzing the realistic errors and generating

199
00:12:54,558 --> 00:12:57,902
the realistic error models for error invocations.

200
00:12:58,046 --> 00:13:01,554
We call it Fabi as a research type and this is an overall

201
00:13:01,602 --> 00:13:05,350
picture of the design of FAbi. So we can start from here

202
00:13:05,420 --> 00:13:09,514
like we have application in production, we just deploy it

203
00:13:09,712 --> 00:13:13,066
normally and then the application interacts with the

204
00:13:13,088 --> 00:13:16,150
kernel space using different kinds of system calls.

205
00:13:16,230 --> 00:13:19,274
And then Phoebei attaches two different kinds of

206
00:13:19,312 --> 00:13:23,402
monitors here. The first one is natural arrow monitor, so it

207
00:13:23,456 --> 00:13:26,846
uses, I will introduce later like

208
00:13:26,868 --> 00:13:30,526
we have some nice features, we use some nice features provided by

209
00:13:30,548 --> 00:13:34,286
the Linux kernel. So it observes different kinds of

210
00:13:34,468 --> 00:13:37,726
natural errors and then it reports to our

211
00:13:37,748 --> 00:13:41,186
IRO model syzor also there is

212
00:13:41,208 --> 00:13:44,894
another monitor called application behavior monitor, because we do

213
00:13:44,952 --> 00:13:48,710
need some application specific metrics like response come,

214
00:13:48,780 --> 00:13:52,610
or maybe some performance related metrics, the cpu

215
00:13:52,690 --> 00:13:55,858
usage like heap memory usage, et cetera.

216
00:13:55,954 --> 00:13:59,842
Because we could like to compare how the application behaves

217
00:13:59,906 --> 00:14:03,894
when IRO is injected. We need some evidence

218
00:14:03,942 --> 00:14:08,646
about the steady state. So based on this monitor,

219
00:14:08,678 --> 00:14:12,038
the information the IRO model syntax outputs

220
00:14:12,054 --> 00:14:15,354
some realistic IRO models based on the naturally happening errors.

221
00:14:15,402 --> 00:14:19,354
And then our Phoebes orchestrator can conduct some chaos

222
00:14:19,402 --> 00:14:22,694
engineering experiments. It uses a system calls injector.

223
00:14:22,762 --> 00:14:26,606
So this injector intercepts some system call invocations,

224
00:14:26,718 --> 00:14:30,002
and then it replaces the return code with

225
00:14:30,056 --> 00:14:34,370
our predefined error codes. And so finally

226
00:14:34,440 --> 00:14:38,050
we get a resilience report about how the application behaves

227
00:14:38,130 --> 00:14:42,226
when we actively inject some specific errors

228
00:14:42,338 --> 00:14:45,846
at the system call level. And of course we can visualize the

229
00:14:45,868 --> 00:14:49,546
results using a visualizer, just like I showed you before,

230
00:14:49,648 --> 00:14:53,322
the grandfather dashboard, which provides you some information about

231
00:14:53,376 --> 00:14:57,034
system call invocations and error rates. So a

232
00:14:57,072 --> 00:15:00,746
question here is how to synthesize realistic error

233
00:15:00,778 --> 00:15:04,800
models. Now we have got natural errors and

234
00:15:06,290 --> 00:15:09,678
we can also analyze these errors like what's the error rate,

235
00:15:09,764 --> 00:15:13,074
what is error code, et cetera. And then we have

236
00:15:13,112 --> 00:15:17,390
to use different strategies to generate realistic

237
00:15:17,470 --> 00:15:21,506
errors models. And here our idea is to amplify the

238
00:15:21,528 --> 00:15:25,106
errors rate. So because given the limited time, we would like to

239
00:15:25,128 --> 00:15:28,866
learn as much as we can in a chaos engineering experiment.

240
00:15:28,978 --> 00:15:32,982
So we need to somehow amplify the error rate, but we still

241
00:15:33,036 --> 00:15:36,854
keep it realistic. This can be done like we keep the

242
00:15:36,972 --> 00:15:40,410
type of the system calls as the same, and then we

243
00:15:40,480 --> 00:15:44,234
slightly increase the error rate, the happening rate of

244
00:15:44,272 --> 00:15:47,834
this specific error, so we can observe enough data

245
00:15:47,952 --> 00:15:51,806
in the chaos engineering experiments. Before doing that, I would

246
00:15:51,828 --> 00:15:54,602
like to propose some definitions.

247
00:15:54,666 --> 00:15:57,934
So, system call invocation error we define it

248
00:15:57,972 --> 00:16:01,242
as here as follows. An invocation

249
00:16:01,306 --> 00:16:05,134
of a system call is deemed an error if it returns an error

250
00:16:05,182 --> 00:16:08,366
code, and then we need to define the monitoring

251
00:16:08,398 --> 00:16:12,354
interval because we keep reporting this matrix to

252
00:16:12,392 --> 00:16:16,350
our database, and this is based on the monitoring interval.

253
00:16:16,430 --> 00:16:20,714
So a monitoring interval is a period of time along which matrix

254
00:16:20,782 --> 00:16:24,114
of interest are collected. Based on these two definitions,

255
00:16:24,162 --> 00:16:28,394
we can define our error rate. So the error rate means the

256
00:16:28,432 --> 00:16:31,930
percentage of the errors with

257
00:16:32,080 --> 00:16:35,958
respect to the same type, the total number of invocations

258
00:16:36,054 --> 00:16:40,346
in the same type. So for example, in 1 second there

259
00:16:40,368 --> 00:16:44,062
are ten open system calls and one of them

260
00:16:44,196 --> 00:16:47,918
failed with an error code, for example no content

261
00:16:48,004 --> 00:16:51,534
or something like that. Then the error rate can be like 10%,

262
00:16:51,652 --> 00:16:54,834
and then this is some information for us to

263
00:16:54,872 --> 00:16:59,954
generate error models in the future because we can amplify this

264
00:16:59,992 --> 00:17:03,182
errors rate. This error rate was observed in production,

265
00:17:03,246 --> 00:17:07,126
so it can be like a basic information

266
00:17:07,228 --> 00:17:11,122
for us. Yes, and talking about the application strategy,

267
00:17:11,266 --> 00:17:14,870
we have some strategies predefined here.

268
00:17:14,940 --> 00:17:18,630
So if we have a set of error rates with respect to

269
00:17:18,700 --> 00:17:23,350
error, system calls error code e, and then we can calculate the maximum

270
00:17:23,430 --> 00:17:26,906
value of the error rate in this observation phase and

271
00:17:26,928 --> 00:17:30,990
also the variance of the error rate. So if the max value

272
00:17:31,060 --> 00:17:34,590
of error rate is quite low, this means it's pretty

273
00:17:34,660 --> 00:17:37,870
difficult to observe such an error in production.

274
00:17:39,410 --> 00:17:43,058
It's rare to see this errors and it does not happen

275
00:17:43,144 --> 00:17:47,106
so frequently. Then we categorize such errors into

276
00:17:47,208 --> 00:17:50,654
sporadic errors and to observe these errors.

277
00:17:50,702 --> 00:17:54,690
And two, learn more about how our application behaves under

278
00:17:54,760 --> 00:17:58,886
these errors. We would like to use a fixed error rate to

279
00:17:58,908 --> 00:18:02,850
amplify this error rate, so this can be predefined,

280
00:18:02,930 --> 00:18:06,278
of course. And usually we just use a number

281
00:18:06,364 --> 00:18:10,694
that can be large enough for our chaos engineering experiments,

282
00:18:10,742 --> 00:18:14,550
so we can get enough data and we can evaluate

283
00:18:14,630 --> 00:18:18,794
how our applications behaves when this error happens. And also,

284
00:18:18,832 --> 00:18:22,526
there are also different errors. Like these errors are

285
00:18:22,548 --> 00:18:26,158
quite fluctuating because the max value is

286
00:18:26,244 --> 00:18:30,254
relatively large. So we can observe these

287
00:18:30,292 --> 00:18:33,854
errors in production more frequently.

288
00:18:33,982 --> 00:18:37,534
And also the variance of the errors rate is larger

289
00:18:37,582 --> 00:18:41,650
than a certain value. So this means, like sometimes this system

290
00:18:41,720 --> 00:18:44,980
calls invocation errors happened quite a lot, but sometimes

291
00:18:45,290 --> 00:18:49,298
it's difficult to observe them. And by amplifying

292
00:18:49,394 --> 00:18:52,566
this kind of errors, we would like to

293
00:18:52,588 --> 00:18:56,466
keep using the maximum value of the error rate. So this error

294
00:18:56,498 --> 00:18:59,574
rate do exist, does exist in production,

295
00:18:59,622 --> 00:19:03,446
and then we keep using it. So we somehow improve

296
00:19:03,478 --> 00:19:06,874
the frequency of these fluctuating errors. And the last

297
00:19:06,912 --> 00:19:10,070
one, we categorize it as steady errors.

298
00:19:10,150 --> 00:19:13,582
So the maximum value of the error rate

299
00:19:13,636 --> 00:19:17,022
is quite large, but the variance of the error rates is

300
00:19:17,076 --> 00:19:21,482
not that large. So we can always observe these errors

301
00:19:21,546 --> 00:19:25,214
in a relatively steady frequency. So that's

302
00:19:25,262 --> 00:19:29,006
why we would like to multiply the max

303
00:19:29,118 --> 00:19:32,018
value with a factor, because we still,

304
00:19:32,104 --> 00:19:35,410
we feel interested to increase the happening

305
00:19:35,480 --> 00:19:39,670
rate of these errors, just to see if there exists any

306
00:19:39,740 --> 00:19:43,606
threshold for our application. Like in production, this happens in

307
00:19:43,628 --> 00:19:47,486
this frequency. But if we do a Kelsey engineering experiments

308
00:19:47,538 --> 00:19:51,734
and we increase the errors rate, how our application behaves,

309
00:19:51,782 --> 00:19:55,302
is it still resilient to this error, or there exists

310
00:19:55,366 --> 00:20:00,098
a threshold, like after this errors rate, the application behaves

311
00:20:00,214 --> 00:20:03,902
abnormally, et cetera, then we can use experiments to

312
00:20:04,036 --> 00:20:07,882
explore it. Of course, these are sort of like basic

313
00:20:07,946 --> 00:20:12,158
application strategies. We can also define more

314
00:20:12,244 --> 00:20:16,338
complex strategies like we combine different scenarios or

315
00:20:16,424 --> 00:20:20,062
we have maybe injection

316
00:20:20,126 --> 00:20:23,774
chaos, or considering the propagation of errors,

317
00:20:23,822 --> 00:20:28,082
et cetera. And then it's another story. So as a research prototype,

318
00:20:28,146 --> 00:20:32,098
we would like to evaluate how Phoebei functions

319
00:20:32,194 --> 00:20:36,214
when we use Phoebe to monitor system calls and also

320
00:20:36,412 --> 00:20:40,266
inject system calls, invocation errors. So we have different

321
00:20:40,368 --> 00:20:45,046
evaluation targets. For example, this Hedwig

322
00:20:45,078 --> 00:20:48,486
is an email server. So I just show you during my demonstration,

323
00:20:48,598 --> 00:20:51,786
we deploy Hedwig into production and then

324
00:20:51,888 --> 00:20:55,434
we use Hedwig to send and fetch emails in a normal

325
00:20:55,482 --> 00:20:58,714
way so we can calculate the steady

326
00:20:58,762 --> 00:21:02,186
state, of course, and we can also have some realistic traffic

327
00:21:02,218 --> 00:21:05,934
there. And then based on the sending

328
00:21:05,982 --> 00:21:09,634
and fetching emails, the number of failures, et cetera, we can

329
00:21:09,672 --> 00:21:12,814
know how the system behaves without injecting

330
00:21:12,862 --> 00:21:16,454
any errors. But based on our observation, we can

331
00:21:16,492 --> 00:21:19,750
still observe some errors that naturally happened

332
00:21:19,820 --> 00:21:23,720
in production. So for example, the table on your left,

333
00:21:24,170 --> 00:21:28,050
we observed like this almost ten different

334
00:21:28,140 --> 00:21:31,818
kinds of system call errors. And some of them happen

335
00:21:31,904 --> 00:21:35,962
quite a lot. Some of them, the error rate is quite

336
00:21:36,016 --> 00:21:39,974
low. But these are sort of interesting findings for

337
00:21:40,032 --> 00:21:43,786
us and we would like to explore more about how Hedwig

338
00:21:43,818 --> 00:21:47,982
behaves if we inject more failures with

339
00:21:48,036 --> 00:21:51,130
respect to different categories of system calls.

340
00:21:51,210 --> 00:21:54,846
So that's the first phase. Like we observe

341
00:21:54,958 --> 00:21:58,718
the system's behavior and we collect

342
00:21:58,814 --> 00:22:02,494
all kinds of naturally happened errors based on the error

343
00:22:02,542 --> 00:22:06,782
and also based on the application strategies I introduced

344
00:22:06,846 --> 00:22:11,390
just now, or fabi outputs like realistic

345
00:22:11,470 --> 00:22:14,802
hair injection models for our future experiments.

346
00:22:14,866 --> 00:22:18,854
And then we can keep injecting different kinds of invocation

347
00:22:18,902 --> 00:22:22,406
failures. And then we try to send and fetch emails

348
00:22:22,438 --> 00:22:26,138
again to see how Hedwig behaves. And this is the result.

349
00:22:26,304 --> 00:22:29,370
So based on the result table,

350
00:22:29,810 --> 00:22:34,400
Hedwig does have different capabilities about

351
00:22:34,930 --> 00:22:38,890
bearing these injected errors. So some injected

352
00:22:38,970 --> 00:22:42,538
invocations errors, it directly crashed the

353
00:22:42,564 --> 00:22:46,658
server, or it has state corruption. This means

354
00:22:46,744 --> 00:22:50,606
even we turn off the error injection, the email server still behaves

355
00:22:50,638 --> 00:22:54,494
incorrectly. But some of the system calls invocation errors.

356
00:22:54,542 --> 00:22:58,038
Hedwig is quite resilient to them. Even we keep

357
00:22:58,124 --> 00:23:02,162
injecting these errors with a relatively larger

358
00:23:02,226 --> 00:23:06,054
error rate than the original one. Hedwig is

359
00:23:06,092 --> 00:23:09,958
still resilient and provides the correct functionality.

360
00:23:10,054 --> 00:23:13,834
So this is some findings of the experiments on

361
00:23:13,872 --> 00:23:17,254
Hedwig. We also did some experiments on tTorrent.

362
00:23:17,302 --> 00:23:21,182
Ttorrent is a Java client which is

363
00:23:21,236 --> 00:23:25,642
used to downloading files using Bittorrent

364
00:23:25,706 --> 00:23:29,354
protocol. So we still, as a normal user, we use tTorrent

365
00:23:29,402 --> 00:23:33,486
to download files and then we observe ttorrent

366
00:23:33,598 --> 00:23:36,882
like a normal behavior and also collects call

367
00:23:36,936 --> 00:23:40,894
the naturally happening errors and then based on this naturally

368
00:23:40,942 --> 00:23:44,446
happening errors, we generate error injection models

369
00:23:44,478 --> 00:23:48,194
for fabric for our chaos engineering experiments,

370
00:23:48,242 --> 00:23:52,146
and this is the result of the evaluation experiments

371
00:23:52,178 --> 00:23:56,034
on tTorrent. Similarly, we can also find that tTorrent

372
00:23:56,082 --> 00:23:59,974
is resilient to come of the system calls invocation errors

373
00:24:00,022 --> 00:24:04,358
and some of the system call invocation errors are quite critical

374
00:24:04,454 --> 00:24:08,154
to title's functionalities. So based on this

375
00:24:08,192 --> 00:24:13,594
resilience report, we can further explore how

376
00:24:13,632 --> 00:24:17,222
we can improve the application's resilience when such

377
00:24:17,376 --> 00:24:21,546
system call invocation happens. We can also explore what's

378
00:24:21,578 --> 00:24:25,266
the relations between system call invocation failures and

379
00:24:25,368 --> 00:24:28,546
the application's behavior or the exceptions in

380
00:24:28,568 --> 00:24:32,274
this specific application. So there are lots of interesting

381
00:24:32,392 --> 00:24:35,842
topics to see. And another important aspect is the

382
00:24:35,896 --> 00:24:39,762
overhead, thanks to the feature we used in Phoebe.

383
00:24:39,826 --> 00:24:43,542
So now I'm going to introduce it a little bit. The feature is called

384
00:24:43,596 --> 00:24:46,834
EPPF. It's a feature provided

385
00:24:46,882 --> 00:24:50,378
by the Linux kernel. By using EBPF, it's quite

386
00:24:50,544 --> 00:24:54,118
easy to capture the system call invocation

387
00:24:54,294 --> 00:24:58,566
information, and you can also intercept the system calls invocations

388
00:24:58,678 --> 00:25:01,582
to rewrite return code, et cetera. Actually,

389
00:25:01,716 --> 00:25:05,054
EBPF is quite powerful. You can use this

390
00:25:05,092 --> 00:25:08,410
feature to have a really nice observability

391
00:25:08,490 --> 00:25:11,790
of Linux kernel. And an interesting story behind

392
00:25:11,860 --> 00:25:15,794
this is I learned it when I joined Conf 42

393
00:25:15,832 --> 00:25:19,854
last year. There was a workshop which was about the Linux

394
00:25:19,902 --> 00:25:23,886
observability and chaos engineering hosted

395
00:25:23,918 --> 00:25:27,534
by 42. So I learned a lot. And I learned

396
00:25:27,582 --> 00:25:31,142
like EBPF and other the front end

397
00:25:31,196 --> 00:25:35,218
BCC are really helpful to improve the observability

398
00:25:35,314 --> 00:25:38,502
and get really lots of nice insights in our

399
00:25:38,556 --> 00:25:41,626
running system. So we came back to Sweden and

400
00:25:41,648 --> 00:25:44,954
decided to explore more on this. Then we came up with

401
00:25:44,992 --> 00:25:48,794
this research idea and finally we write a paper about it.

402
00:25:48,832 --> 00:25:52,326
So it's really nice. We joined comforted too to

403
00:25:52,368 --> 00:25:56,254
share with each other and we learned a lot, a lot. And finally I

404
00:25:56,292 --> 00:25:59,454
can come back again to tell you. Here is

405
00:25:59,492 --> 00:26:03,486
my findings and here is some extra work we have done in

406
00:26:03,508 --> 00:26:07,290
this year. I think it's quite interesting and I'm very happy to join

407
00:26:07,370 --> 00:26:11,186
comfort two again. But the slide here I would like

408
00:26:11,208 --> 00:26:15,414
to show you is the overhead of Fabi because using these

409
00:26:15,452 --> 00:26:18,790
nice features we actually don't have really

410
00:26:18,860 --> 00:26:22,434
high overhead compared to other research prototypes

411
00:26:22,482 --> 00:26:25,378
even. We ran the experiments in production environment.

412
00:26:25,474 --> 00:26:29,094
Still, the response time, the cpu load and the memory

413
00:26:29,142 --> 00:26:32,662
usage are quite slightly improved,

414
00:26:32,726 --> 00:26:36,870
but not that much. I would say this makes it promising

415
00:26:36,950 --> 00:26:40,394
if we do lots of improvements and then we can

416
00:26:40,432 --> 00:26:44,218
still lower down the overhead and try to

417
00:26:44,304 --> 00:26:48,394
improve, maybe to really learn something more about the system calls

418
00:26:48,442 --> 00:26:52,126
or other useful information at the system calls

419
00:26:52,228 --> 00:26:55,346
level or at the operating system level.

420
00:26:55,448 --> 00:26:59,314
Yes, but as a research prototype, Fabi of course has its

421
00:26:59,352 --> 00:27:02,610
limitations and we need to do lots of future work

422
00:27:02,680 --> 00:27:06,454
to explore this field. For example, Fabi is designed for

423
00:27:06,492 --> 00:27:09,686
Java applications. This is because when

424
00:27:09,708 --> 00:27:12,934
we do some chaos engineering experiment, we would like

425
00:27:12,972 --> 00:27:16,354
to have a multiple layer observability.

426
00:27:16,482 --> 00:27:20,138
So we want to collect the metrics at operating system

427
00:27:20,224 --> 00:27:23,546
level and also the metrics about the GVM and

428
00:27:23,568 --> 00:27:27,082
also some application specific metrics such as

429
00:27:27,136 --> 00:27:31,294
response code, response time, et cetera. That's why we

430
00:27:31,492 --> 00:27:35,386
only evaluate Fibi for Java

431
00:27:35,418 --> 00:27:39,134
applications. But I think the concepts are applicable to other

432
00:27:39,172 --> 00:27:43,382
software stacks. For example, for call kinds of executables

433
00:27:43,466 --> 00:27:47,262
in Linux operating system, we can always use Phoebe

434
00:27:47,326 --> 00:27:50,946
to monitor its system calls invocations and also to

435
00:27:50,968 --> 00:27:55,170
summarize its naturally happened errors about system call invocations.

436
00:27:55,910 --> 00:28:00,130
So this means like some components can be reused with minor applications

437
00:28:00,210 --> 00:28:03,494
such as the monitor, the visualizer, and also the system error

438
00:28:03,532 --> 00:28:06,614
injection. And the second limitation is the

439
00:28:06,652 --> 00:28:10,010
GBM itself, to be honest, may either create

440
00:28:10,080 --> 00:28:14,022
natural system call errors or remediate come errors directly.

441
00:28:14,166 --> 00:28:17,786
So this is only our first step. But in the future I

442
00:28:17,808 --> 00:28:21,722
think it would be interesting to explore the interplay

443
00:28:21,786 --> 00:28:25,482
between the GVM and the application error handling mechanisms

444
00:28:25,546 --> 00:28:28,510
with respect to system call errors. Okay,

445
00:28:28,580 --> 00:28:32,414
so the next page is about the summary of our

446
00:28:32,532 --> 00:28:36,894
research work on Fibi. So basically we proposed some original

447
00:28:36,942 --> 00:28:40,834
insights about the presence of naturally happening system call

448
00:28:40,872 --> 00:28:44,942
errors in software systems. We also contribute

449
00:28:45,006 --> 00:28:48,766
to the concept of synthesizing realistic error injection

450
00:28:48,798 --> 00:28:53,554
models for system calls based on amplification

451
00:28:53,682 --> 00:28:57,574
strategy. So we amplifying naturally happening errors observed in

452
00:28:57,612 --> 00:29:02,010
production. And also we implemented Fabi as a research prototype

453
00:29:02,590 --> 00:29:05,882
about this concept. So the crisp bounding paper

454
00:29:05,936 --> 00:29:09,226
is called realistic average injection for system calls. If you are a

455
00:29:09,248 --> 00:29:13,246
fan of reading papers, you are more than welcome to give us

456
00:29:13,348 --> 00:29:16,894
feedback about how you think of this paper. Okay,

457
00:29:16,932 --> 00:29:21,294
finally, about the Fabi, the framework, we have already

458
00:29:21,492 --> 00:29:25,298
made it open source. So if you feel interested in

459
00:29:25,384 --> 00:29:28,914
Fabi, and also if you feel interested in how

460
00:29:28,952 --> 00:29:32,114
we address the previous two, the first

461
00:29:32,152 --> 00:29:35,602
two challenges I mentioned in the beginning, you can take a look

462
00:29:35,656 --> 00:29:39,494
at our royal chaos GitHub rep because Kth is

463
00:29:39,532 --> 00:29:43,010
Royal Institute of Technology. So we have this royal chaos

464
00:29:43,090 --> 00:29:46,774
repo which contains all kinds of different our research work

465
00:29:46,812 --> 00:29:50,202
in the field of chaos engineering papers, source code and also

466
00:29:50,256 --> 00:29:54,250
experiment. So feel free to take a look and also create

467
00:29:54,320 --> 00:29:58,182
issues if you have further questions. Okay, so as a summary

468
00:29:58,326 --> 00:30:02,062
during this talk I presented a short

469
00:30:02,116 --> 00:30:05,630
demonstration so we had an overall picture about the system

470
00:30:05,700 --> 00:30:08,942
called invocations and the naturally happening errors behind

471
00:30:08,996 --> 00:30:12,858
it. Then we proposed the design of Fabi which

472
00:30:13,044 --> 00:30:17,246
takes the naturally happening errors as input and automatically

473
00:30:17,358 --> 00:30:21,870
synthesize realistic error models for chaos engineering experiments

474
00:30:21,950 --> 00:30:25,800
in the FAbi the most interesting or important idea is

475
00:30:26,970 --> 00:30:31,014
error rate amplification. So we have different strategies and

476
00:30:31,052 --> 00:30:34,838
we have categorized the errors into different types and

477
00:30:34,924 --> 00:30:39,080
also we did some evaluation experiments on FIbi on different

478
00:30:39,450 --> 00:30:42,854
applications so we have some interesting findings and

479
00:30:42,892 --> 00:30:46,162
of course based on the findings we have summarized

480
00:30:46,306 --> 00:30:49,882
the cool ideas and also the limitations of Phoebe.

481
00:30:49,986 --> 00:30:53,406
And the last point is to take a look at

482
00:30:53,428 --> 00:30:56,526
our Royalkowski tab rifle if you feel interested.

483
00:30:56,708 --> 00:31:00,542
Basically that's all of my talk today and I hope you

484
00:31:00,596 --> 00:31:04,158
enjoyed it. If you feel interested please you are welcome

485
00:31:04,244 --> 00:31:08,014
to contact me at any time. I look forward to

486
00:31:08,132 --> 00:31:11,038
discussing more with you and we keep in touch.

487
00:31:11,124 --> 00:31:12,540
Thanks a lot. Have a nice day.

