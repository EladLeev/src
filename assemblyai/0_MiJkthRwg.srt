1
00:00:39,170 --> 00:00:42,706
Hi, and welcome to my talk. Who's going to secure the code?

2
00:00:42,738 --> 00:00:45,030
Army of robots is going to be writing.

3
00:00:45,530 --> 00:00:49,286
So, my name is Arshan Dabirsiaghi. I've been at

4
00:00:49,308 --> 00:00:52,814
the intersect section of code and security my

5
00:00:52,852 --> 00:00:56,686
whole career, around 20 years. And all of

6
00:00:56,708 --> 00:01:00,014
these bullets can be summarized as I've always been

7
00:01:00,052 --> 00:01:03,698
fascinated with the idea of taking over your computer against your will

8
00:01:03,864 --> 00:01:07,410
and all the different aspects that come out of

9
00:01:07,480 --> 00:01:11,326
that, including protecting

10
00:01:11,358 --> 00:01:15,350
your data. And so let's talk about

11
00:01:15,420 --> 00:01:18,886
generative AI and how I see from my

12
00:01:18,908 --> 00:01:22,438
vantage point how that's going to affect the security

13
00:01:22,524 --> 00:01:26,646
of our software. So if

14
00:01:26,668 --> 00:01:30,250
you look at the studies that have been put out by the major

15
00:01:30,320 --> 00:01:33,834
players, you would be

16
00:01:33,872 --> 00:01:37,660
led to believe that the tools we have today

17
00:01:38,030 --> 00:01:41,162
for helping us code largely

18
00:01:41,226 --> 00:01:45,386
and take the form of these fill in the middle models, like GitHub's

19
00:01:45,418 --> 00:01:48,494
copilot, they help us

20
00:01:48,532 --> 00:01:51,802
produce 25 CTO, 60% more coding

21
00:01:51,866 --> 00:01:55,662
throughput. Now, these numbers, really, they depend on how you measure

22
00:01:55,726 --> 00:01:59,090
and what is the activity. I think a lot of people

23
00:01:59,240 --> 00:02:03,540
say that the acceptance rate is between 20% and 30%

24
00:02:04,310 --> 00:02:07,906
for GitHub's copilot. Suggestions? I haven't

25
00:02:07,938 --> 00:02:11,874
had a chance to play with the other tools, but these fill in the models,

26
00:02:11,922 --> 00:02:14,630
really, you can think of them as autocomplete, right?

27
00:02:14,780 --> 00:02:18,620
And just with autocomplete, we have to

28
00:02:19,390 --> 00:02:22,780
acknowledge that throughput is higher.

29
00:02:23,310 --> 00:02:27,514
And now we can argue about the numbers and what they mean, but with

30
00:02:27,552 --> 00:02:31,670
a higher throughput, it'll come downstream consequences,

31
00:02:31,750 --> 00:02:35,306
some good, some bad. But right now, what most people

32
00:02:35,328 --> 00:02:39,118
are using, what's been adopted as of now, has been this

33
00:02:39,204 --> 00:02:41,070
autocomplete kind of feature.

34
00:02:42,210 --> 00:02:46,190
And more recently, we've seen coding assistants

35
00:02:46,350 --> 00:02:49,682
jump into our IDE, things like

36
00:02:49,736 --> 00:02:54,030
magic and GitHub's copilot

37
00:02:54,190 --> 00:02:57,334
in the IDE. And so these things are

38
00:02:57,372 --> 00:03:00,678
pretty new. And so, adoption is not through the

39
00:03:00,684 --> 00:03:04,166
roof yet. And what we

40
00:03:04,188 --> 00:03:08,006
saw on the autocomplete side was this, I don't want to

41
00:03:08,028 --> 00:03:13,754
say modest improvement to throughput, but one

42
00:03:13,792 --> 00:03:17,386
standard deviation away from what we do today. Right now, if we

43
00:03:17,408 --> 00:03:20,794
have an assistant that is drafting whole

44
00:03:20,912 --> 00:03:24,494
sections of code, whole files of code, you can see in this

45
00:03:24,532 --> 00:03:27,946
example, we're asking copilot to create a new button component,

46
00:03:28,058 --> 00:03:31,280
and it's able to do that. And so

47
00:03:31,650 --> 00:03:36,002
if a fill on the middle model can deliver us 25

48
00:03:36,056 --> 00:03:39,358
cto, 60% more throughput, we have to ask ourselves,

49
00:03:39,454 --> 00:03:43,214
what is the throughput that a drafting assistant

50
00:03:43,262 --> 00:03:46,694
like this could do? And the studies haven't been done on

51
00:03:46,732 --> 00:03:50,198
this yet. The studies really are just coming out now for the fill in the

52
00:03:50,204 --> 00:03:51,750
middle models,

53
00:03:53,370 --> 00:03:57,126
we're left to guess here. I'm guessing sort

54
00:03:57,148 --> 00:04:00,998
of out of thin air here, 100%, just for an argument's

55
00:04:01,014 --> 00:04:05,050
sake. And if you watch the GitHub keynote,

56
00:04:05,790 --> 00:04:07,660
just a few weeks ago,

57
00:04:08,670 --> 00:04:12,122
you would have heard that GitHub has said that they're

58
00:04:12,186 --> 00:04:15,562
refounding the company based on Copilot,

59
00:04:15,706 --> 00:04:19,214
and they demoed something at the end with their just one

60
00:04:19,252 --> 00:04:22,542
more thing that was really

61
00:04:22,596 --> 00:04:26,590
impressive. And so they showed essentially

62
00:04:28,070 --> 00:04:31,650
somebody opening up an issue and saying, hey, I want to add this feature.

63
00:04:32,150 --> 00:04:35,814
And the GitHub copilot feature that they were

64
00:04:35,852 --> 00:04:39,320
demoing created a plan, as you can see here,

65
00:04:39,850 --> 00:04:42,550
went through the code and changed files,

66
00:04:45,130 --> 00:04:49,186
and we'll try to auto fix like compilation errors.

67
00:04:49,218 --> 00:04:52,742
Or from the demo, it seemed like it was going to try to solve small

68
00:04:52,796 --> 00:04:56,600
kinds of errors on its own. And so now

69
00:04:57,530 --> 00:05:01,534
this is a tectonic shift from fill

70
00:05:01,572 --> 00:05:04,910
in the middle, right. This is doing requirements,

71
00:05:06,050 --> 00:05:09,098
sort of guessing at the requirements,

72
00:05:09,274 --> 00:05:13,266
guessing at those requirements translate into

73
00:05:13,368 --> 00:05:17,586
code requirements and performing multiple file changes,

74
00:05:17,768 --> 00:05:21,460
and then itering on those changes to get them to a working state.

75
00:05:21,990 --> 00:05:25,494
And so if autocomplete can

76
00:05:25,532 --> 00:05:29,282
give us these modest numbers, what can a feature

77
00:05:29,346 --> 00:05:30,520
like this do?

78
00:05:32,330 --> 00:05:35,640
Were again, left to speculate. Seems like a lot.

79
00:05:36,170 --> 00:05:40,042
So there have also been studies on the

80
00:05:40,096 --> 00:05:43,702
models to help establish that they're

81
00:05:43,846 --> 00:05:46,970
not that good at security. In fact, they're kind of poor.

82
00:05:48,110 --> 00:05:51,754
The models produce, they produce insecure

83
00:05:51,802 --> 00:05:56,158
code, right? The statistics on the right help us understand

84
00:05:56,244 --> 00:05:59,726
that. They've done studies where they

85
00:05:59,748 --> 00:06:03,294
had a control group that didn't use a coding assistant,

86
00:06:03,342 --> 00:06:06,590
and then a group that did use an assistant,

87
00:06:06,670 --> 00:06:10,734
and they found that consistently, the group that used the assistant produced

88
00:06:10,782 --> 00:06:14,194
more insecure code and perhaps more

89
00:06:14,232 --> 00:06:17,426
dangerously, believed that their code was more secure

90
00:06:17,538 --> 00:06:19,080
than the control group.

91
00:06:22,010 --> 00:06:25,782
This also reflects my experience testing the top

92
00:06:25,836 --> 00:06:29,466
commercial offerings. If you

93
00:06:29,488 --> 00:06:32,230
ask the models about SQL injection,

94
00:06:32,390 --> 00:06:36,442
it's fairly competent. SQL injection is super

95
00:06:36,496 --> 00:06:39,546
common issue. There's a ton of literature out on the

96
00:06:39,568 --> 00:06:43,642
Internet about it. But if you ask it about a vulnerability

97
00:06:43,706 --> 00:06:46,510
class that's just slightly less popular,

98
00:06:48,050 --> 00:06:51,486
I have not found it to be competent at all in

99
00:06:51,588 --> 00:06:56,082
delivering fixes, analyzing itself for whether

100
00:06:56,136 --> 00:06:57,330
the code is secure.

101
00:07:00,310 --> 00:07:03,602
It can't reason about these issues with any level

102
00:07:03,656 --> 00:07:07,382
of competency. So what our

103
00:07:07,436 --> 00:07:11,058
experience is that basically the LLMs don't produce

104
00:07:11,154 --> 00:07:14,518
secures code. Now we have

105
00:07:14,524 --> 00:07:18,666
this issue where, and maybe this shouldn't be surprising because the

106
00:07:18,688 --> 00:07:22,490
LLMs are trained on human code, which contains bugs.

107
00:07:22,830 --> 00:07:26,170
And so in fact, they're overtrained, right? I mean,

108
00:07:26,320 --> 00:07:29,994
the data set that they are trained on is

109
00:07:30,112 --> 00:07:34,062
all on insecure code, because that's the code that's in GitHub, that's publicly available.

110
00:07:34,196 --> 00:07:37,802
And so it's not a surprise that the LLM then produces

111
00:07:37,866 --> 00:07:41,914
insecure code. So if you wanted the why or how are they producing

112
00:07:41,962 --> 00:07:45,534
insecure code? That's really, how is that the models are really a mirror

113
00:07:45,582 --> 00:07:49,380
held up to the existing human vulnerable code.

114
00:07:49,750 --> 00:07:53,518
So then the question was posed

115
00:07:53,534 --> 00:07:56,726
to me, can't the models just generate secure code?

116
00:07:56,828 --> 00:07:58,760
Can we teach them to do that? Maybe.

117
00:07:59,450 --> 00:08:03,480
And this is harder than people think.

118
00:08:04,170 --> 00:08:07,906
And to understand why, you need to understand the nature of a vulnerability.

119
00:08:08,018 --> 00:08:11,562
And so if we look at a vulnerability that takes

120
00:08:11,616 --> 00:08:14,940
place, all these blue bubbles are little pieces of code.

121
00:08:15,470 --> 00:08:19,318
User input actually comes into the system here and then it bounces

122
00:08:19,414 --> 00:08:23,466
all around the system. And so the system is not just what's

123
00:08:23,498 --> 00:08:27,614
in your GitHub repo, right? The system, the application is

124
00:08:27,652 --> 00:08:30,554
a combination of your custom code libraries, frameworks,

125
00:08:30,602 --> 00:08:34,354
runtime, third party services, et cetera. And so

126
00:08:34,472 --> 00:08:38,146
as the data, untrusted data kind of flows around your

127
00:08:38,168 --> 00:08:40,930
system, you'll see that eventually,

128
00:08:41,750 --> 00:08:45,082
in this example, it reaches a place in the runtime where it shouldn't.

129
00:08:45,246 --> 00:08:48,454
And so lots of vulnerabilities can be modeled this way.

130
00:08:48,492 --> 00:08:52,470
SQL injection, cross site scripting. Many of the

131
00:08:52,540 --> 00:08:55,320
medium high critical vulnerabilities look this way.

132
00:08:55,930 --> 00:08:59,258
So it's tempting to just say, well, we'll just

133
00:08:59,264 --> 00:09:04,234
take the whole code base and shove it into the context window and

134
00:09:04,352 --> 00:09:08,362
try to reason about the safety, the security of

135
00:09:08,416 --> 00:09:12,190
the code. And you might notice that a lot of this

136
00:09:12,340 --> 00:09:16,160
vulnerability data flow isn't even in your code.

137
00:09:18,610 --> 00:09:21,886
So that's one problem. And then also code bases are

138
00:09:21,908 --> 00:09:24,638
just way too big. The most popular,

139
00:09:24,734 --> 00:09:28,820
biggest context window today,

140
00:09:29,270 --> 00:09:33,202
I'm not even sure if it's available for public offering yet, but there is 100K

141
00:09:33,256 --> 00:09:36,870
context window from anthropic, if I'm remembering that correctly.

142
00:09:37,290 --> 00:09:41,174
But 100K tokens is

143
00:09:41,212 --> 00:09:45,746
not going to be enough. It might be able to fit microservice

144
00:09:45,778 --> 00:09:49,834
with one endpoint in it, but when

145
00:09:49,872 --> 00:09:53,420
you look at the manifest files, the data files, all the code,

146
00:09:54,590 --> 00:09:58,378
we're going to need millions of context window in

147
00:09:58,384 --> 00:10:02,640
the millions in order CTO fit most apps into it.

148
00:10:03,730 --> 00:10:07,550
So the next, maybe most obvious step

149
00:10:07,620 --> 00:10:12,890
would be to take all the code and cram it into embeddings,

150
00:10:12,970 --> 00:10:17,102
which are another way that we augment LLM usage

151
00:10:17,166 --> 00:10:21,410
in order to give it knowledge about other

152
00:10:21,480 --> 00:10:24,786
things that are big. I know that's a very simple way of thinking about

153
00:10:24,808 --> 00:10:28,454
it. But, for instance, you might feed an LLM all

154
00:10:28,492 --> 00:10:31,826
of your docs in order to make a useful chat bot.

155
00:10:31,938 --> 00:10:35,480
And so you would give it the ability to sort of search over that space,

156
00:10:37,130 --> 00:10:40,566
and that works relatively well. But searching

157
00:10:40,598 --> 00:10:44,282
is different from reasoning. And so if

158
00:10:44,336 --> 00:10:47,866
we just were to cram all of the code into an

159
00:10:47,888 --> 00:10:51,454
embeddings and then ask it to connect these

160
00:10:51,492 --> 00:10:54,942
dots for us, that hasn't worked

161
00:10:55,076 --> 00:10:59,226
in my experience, and we haven't seen that anything suggesting

162
00:10:59,258 --> 00:11:03,230
that that is possible yet, either. From the wider marketplace.

163
00:11:03,750 --> 00:11:05,090
And generally,

164
00:11:06,150 --> 00:11:11,858
models are confused by very

165
00:11:12,024 --> 00:11:15,878
long series of events where you have

166
00:11:15,884 --> 00:11:18,550
to reason across many different steps.

167
00:11:20,490 --> 00:11:24,162
And most of these issues involve many steps

168
00:11:24,226 --> 00:11:28,042
and sometimes many variables. So adding those two

169
00:11:28,096 --> 00:11:31,338
dimensions, llms tend to

170
00:11:31,504 --> 00:11:35,066
deliver less, in my experience, on those types of

171
00:11:35,088 --> 00:11:38,746
problems, where it's got to keep track of the history of two

172
00:11:38,768 --> 00:11:41,690
variables across all these different events.

173
00:11:42,030 --> 00:11:45,230
It's quite difficult. I think we need to figure out how to make,

174
00:11:45,300 --> 00:11:47,662
if we wanted to solve this problem, we have to figure out how to make

175
00:11:47,716 --> 00:11:51,214
these problems smaller for the LM. And just as a

176
00:11:51,252 --> 00:11:52,510
point of reference,

177
00:11:54,550 --> 00:11:58,894
we've tried to build static analysis tools, code analysis tools,

178
00:11:59,022 --> 00:12:02,882
that are purpose built for exactly this problem,

179
00:12:03,016 --> 00:12:07,238
and they can't do this fast and accurately. And so

180
00:12:07,324 --> 00:12:11,190
the hope that the very general purpose,

181
00:12:13,930 --> 00:12:16,070
working at the speed of inference,

182
00:12:17,130 --> 00:12:21,498
it feels like we can't even get this right with

183
00:12:21,584 --> 00:12:25,500
really purpose built tools. It feels very far fetched to me.

184
00:12:25,870 --> 00:12:30,714
So I want to show you, this is a

185
00:12:30,912 --> 00:12:34,400
diagram put out by Pedro Tutti to talk about

186
00:12:34,770 --> 00:12:38,798
what is the secure development lifecycle, where does security

187
00:12:38,884 --> 00:12:42,538
fit in? And so what

188
00:12:42,564 --> 00:12:46,066
you see here is this is

189
00:12:46,088 --> 00:12:48,910
a company that takes security very seriously.

190
00:12:49,070 --> 00:12:52,786
Whoever actually works CTO, this diagram, they have a

191
00:12:52,808 --> 00:12:56,340
range of activities that are sort of like things you do

192
00:12:56,970 --> 00:13:01,030
at the front end in terms of things you do once to establish

193
00:13:02,250 --> 00:13:05,974
the context of that app for this lifetime. And there are things that you do

194
00:13:06,092 --> 00:13:08,890
continuously, either during development,

195
00:13:09,630 --> 00:13:13,334
testing, and then in production as well. And so they've

196
00:13:13,382 --> 00:13:17,420
labeled here some of the things that are manually performed with this little m.

197
00:13:17,950 --> 00:13:24,554
And I'm going to tell you that this

198
00:13:24,592 --> 00:13:27,854
graph, this diagram, is way underlabeled, doesn't have nearly enough

199
00:13:27,892 --> 00:13:31,354
M's. And I'll give you an example. So, in the beginning,

200
00:13:31,402 --> 00:13:34,714
yes, you would do threat modeling once. Threat modeling is an exercise.

201
00:13:34,762 --> 00:13:38,660
Were you sort of look at the inputs and outputs to the system,

202
00:13:39,030 --> 00:13:43,042
you look at the third party systems it connects to, and you try

203
00:13:43,096 --> 00:13:46,454
to predict ahead of time what are the different

204
00:13:46,492 --> 00:13:49,254
threats you might want to face? What are the controls you want to make sure

205
00:13:49,292 --> 00:13:53,480
you have. And so this is an expert led human

206
00:13:54,250 --> 00:13:57,446
process, usually looking at a

207
00:13:57,468 --> 00:14:01,260
combination of cloud infrastructure and

208
00:14:01,710 --> 00:14:05,050
literally papers to try to do this process.

209
00:14:05,120 --> 00:14:08,282
So this is obviously very human, very manual. You're asking

210
00:14:08,336 --> 00:14:11,710
a ton of questions when you lead a threat model to try to

211
00:14:11,860 --> 00:14:14,960
enumerate the real world picture of this app.

212
00:14:15,410 --> 00:14:18,862
And so, of course, this is going to happen one

213
00:14:18,916 --> 00:14:22,650
time. Very unlikely it'll happen a lot after that.

214
00:14:22,820 --> 00:14:28,386
But every time you

215
00:14:28,408 --> 00:14:32,094
commit some code, your pipeline runs. You're going to run a static analysis

216
00:14:32,142 --> 00:14:35,506
tool. You're going to need CTO look at the results

217
00:14:35,538 --> 00:14:39,110
of that when it's found. Right. And so now imagine

218
00:14:40,490 --> 00:14:44,082
we have all the generative AI,

219
00:14:44,146 --> 00:14:47,954
all the robots are working, they're cranking out code. What are the robots

220
00:14:48,002 --> 00:14:50,730
going to do when they find a static analysis finding?

221
00:14:51,950 --> 00:14:55,910
Well, let's talk about what the humans do. But first, we're going to put m's

222
00:14:55,990 --> 00:14:59,354
here, because now we've said, look, when we do

223
00:14:59,392 --> 00:15:03,086
static analysis, scanning of the code, and there's a finding, we need to do

224
00:15:03,108 --> 00:15:06,302
something about it, we need to triage it, we need to possibly fix it,

225
00:15:06,436 --> 00:15:10,282
we need to do something. And so all of these activities,

226
00:15:10,426 --> 00:15:13,726
static analysis, software composition analysis, which is

227
00:15:13,748 --> 00:15:17,346
looking at your libraries that you have, especially new

228
00:15:17,368 --> 00:15:21,026
libraries coming in. We have dynamic analysis, which is kind of

229
00:15:21,048 --> 00:15:25,570
like fuzzing your web application from the outside, or your rest API.

230
00:15:26,070 --> 00:15:29,942
We have Iast, which is watching the internals of the system running.

231
00:15:29,996 --> 00:15:33,894
You're scanning any containers that you would have built for vulnerabilities and

232
00:15:33,932 --> 00:15:35,960
sort of the infrastructure of your app.

233
00:15:39,530 --> 00:15:43,142
If you're lucky enough to work in an organization that has penetration

234
00:15:43,206 --> 00:15:46,762
testing, you're also going to have pen testers looking at your app

235
00:15:46,816 --> 00:15:50,346
sort of occasionally. And so through the, hopefully you can

236
00:15:50,368 --> 00:15:53,646
see the through line here is that we have a lot

237
00:15:53,668 --> 00:15:56,878
of security processes and we have a lot of security

238
00:15:56,964 --> 00:16:00,574
technology, and the process for acting on these

239
00:16:00,612 --> 00:16:06,162
results is very manual. And so we

240
00:16:06,216 --> 00:16:09,330
list some of the human interventions here.

241
00:16:09,480 --> 00:16:12,702
And it's interesting to note that also these activities

242
00:16:12,766 --> 00:16:16,038
are not just strictly a developer. There's a lot

243
00:16:16,044 --> 00:16:19,794
of developer stuff that's happening here, but also there's some product management

244
00:16:19,842 --> 00:16:23,046
stuff, talking about trade offs, there's compliance stuff,

245
00:16:23,228 --> 00:16:25,830
there's security engineering.

246
00:16:26,810 --> 00:16:30,886
There's a lot of activities here across a couple of different disciplines

247
00:16:30,998 --> 00:16:34,550
in order CTO make this secure software factory

248
00:16:34,630 --> 00:16:37,738
work. Now, again,

249
00:16:37,824 --> 00:16:40,220
what are we going to do when the robots come?

250
00:16:40,850 --> 00:16:44,654
Because the question is going to be, are we going to slow down the

251
00:16:44,692 --> 00:16:49,274
software factory in order to accommodate inserting

252
00:16:49,322 --> 00:16:53,362
humans in all these places. And typically when somebody

253
00:16:53,416 --> 00:16:56,542
says go fast or go secure,

254
00:16:56,686 --> 00:17:02,226
businesses choose to go fast because they

255
00:17:02,248 --> 00:17:05,880
have to compete. And so they feel like

256
00:17:06,250 --> 00:17:09,634
they can't tie one hand behind their backs

257
00:17:09,682 --> 00:17:13,682
because for a lot of different reasons.

258
00:17:13,826 --> 00:17:17,880
And so just today

259
00:17:18,750 --> 00:17:23,018
I want to talk about how our programs are limited. I think developers often

260
00:17:23,104 --> 00:17:26,300
think that security is somebody else's job,

261
00:17:27,150 --> 00:17:30,220
and to a certain degree that is true.

262
00:17:31,010 --> 00:17:34,926
But I just want to give you a glimpse behind the

263
00:17:34,948 --> 00:17:38,766
wall here. Developers at least, and some

264
00:17:38,788 --> 00:17:42,282
studies say that this developers outnumber security 101.

265
00:17:42,436 --> 00:17:46,146
My experience is if you go to a

266
00:17:46,168 --> 00:17:48,930
giant bank or a giant financial institution,

267
00:17:50,070 --> 00:17:51,890
these ratios are much worse.

268
00:17:53,590 --> 00:17:56,742
And I wouldn't want to speculate on what the numbers are,

269
00:17:56,876 --> 00:18:00,310
but at least maybe an order

270
00:18:00,380 --> 00:18:02,280
of magnitude off of this,

271
00:18:04,170 --> 00:18:08,006
the humans we have aren't cross skilled. So if you think

272
00:18:08,028 --> 00:18:11,158
of just very simply, and we just say there's developers on one side and there's

273
00:18:11,174 --> 00:18:15,702
security on the other, security understands risk

274
00:18:15,766 --> 00:18:19,100
pretty well in such a way that the developers don't, to be honest,

275
00:18:20,610 --> 00:18:24,174
they think about security differently, but they

276
00:18:24,212 --> 00:18:28,170
don't have the skills often to pitch in directly

277
00:18:28,330 --> 00:18:31,630
or CTo, review findings very deeply.

278
00:18:32,930 --> 00:18:35,826
They just don't have that skill set. A lot of times they don't come from

279
00:18:35,848 --> 00:18:39,042
an engineering background. And then on the other side,

280
00:18:39,096 --> 00:18:42,606
developers don't have great security skills.

281
00:18:42,638 --> 00:18:46,440
So they don't understand vulnerability classes that well,

282
00:18:47,210 --> 00:18:50,998
and we shouldn't expect them to because security is a

283
00:18:51,084 --> 00:18:54,854
tough, complex, fast moving field with every

284
00:18:54,892 --> 00:18:58,380
vulnerability class is its own interesting

285
00:18:59,550 --> 00:19:03,002
rabbit hole. And so they don't have that

286
00:19:03,056 --> 00:19:06,746
muscle memory to do a really great job

287
00:19:06,928 --> 00:19:10,586
at working through vulnerabilities. And that's what on their own. And that's

288
00:19:10,618 --> 00:19:13,946
why often we'll see developers struggle

289
00:19:13,978 --> 00:19:17,086
to fix vulnerabilities after one

290
00:19:17,188 --> 00:19:20,954
iteration. So if you read bug

291
00:19:21,002 --> 00:19:24,370
bounty reports, you'll often see like the developer fixes something,

292
00:19:24,440 --> 00:19:27,714
but the attacker is able to get around their

293
00:19:27,752 --> 00:19:31,426
proposed fix right away. And so anyway,

294
00:19:31,608 --> 00:19:34,610
we have people who are good at parts of this,

295
00:19:34,680 --> 00:19:38,054
but we don't have that many people that are really great

296
00:19:38,092 --> 00:19:41,874
at both. And then just from a math

297
00:19:41,922 --> 00:19:45,606
perspective on the number of humans we have, regardless of

298
00:19:45,628 --> 00:19:48,140
how skilled or cross skilled they are,

299
00:19:49,470 --> 00:19:52,730
we just don't have enough people to do the jobs.

300
00:19:53,230 --> 00:19:57,670
And so what ends up happening here? If this is our application portfolio

301
00:19:57,750 --> 00:20:02,678
here, where you're thinking you're

302
00:20:02,694 --> 00:20:06,222
the business owner at a big bank or a big technology company,

303
00:20:06,276 --> 00:20:09,902
and you say, these are all the apps I have, what typically actually

304
00:20:09,956 --> 00:20:13,250
happens is that you label a very small number

305
00:20:13,320 --> 00:20:15,940
of those apps, let's say 10%,

306
00:20:16,950 --> 00:20:20,254
as the most critical. So these are things that might be Internet

307
00:20:20,302 --> 00:20:24,190
facing. They might directly touch some sensitive assets.

308
00:20:24,350 --> 00:20:26,980
And so you might choose to say,

309
00:20:27,590 --> 00:20:31,094
look, we're only going to run

310
00:20:31,132 --> 00:20:34,760
the full barrage of activities and tools on

311
00:20:35,450 --> 00:20:38,518
this 10% of our most critical applications.

312
00:20:38,694 --> 00:20:42,458
And so this is why we have situations like,

313
00:20:42,624 --> 00:20:45,834
there was a major retailer that was broken into a few years

314
00:20:45,872 --> 00:20:50,554
ago that suffered a tremendous

315
00:20:50,602 --> 00:20:53,550
breach and a really painful breach.

316
00:20:53,970 --> 00:20:57,630
And the way they got in was through a

317
00:20:57,700 --> 00:21:00,670
contractor HVAC portal.

318
00:21:01,010 --> 00:21:05,090
And I'm sure that at some point, somebody looked at this

319
00:21:05,240 --> 00:21:09,262
asset of the companies and said, it's just for contractors,

320
00:21:09,326 --> 00:21:10,610
it's just HVAC.

321
00:21:12,630 --> 00:21:16,290
There's just not enough assets here at risk. It's a small

322
00:21:16,360 --> 00:21:20,434
number of people who have access to it, HVAC contractors and

323
00:21:20,472 --> 00:21:23,606
so know to get

324
00:21:23,628 --> 00:21:26,742
in their foot of the door. It all looks the same to them. And so

325
00:21:26,796 --> 00:21:30,620
the attacker in this case breached this system.

326
00:21:31,470 --> 00:21:34,582
I'm not sure if they had insider information or they knew a contractor,

327
00:21:34,646 --> 00:21:38,300
but they found some way to get to this and

328
00:21:38,670 --> 00:21:42,222
they pivoted from were to the soft

329
00:21:42,276 --> 00:21:46,430
underbelly of the systems and

330
00:21:46,500 --> 00:21:50,238
did a lot of damage. And so if were only

331
00:21:50,324 --> 00:21:53,938
doing, let's say, what we want to do

332
00:21:54,104 --> 00:21:58,126
on 5% CTO, 10% of the applications that we have, and we're

333
00:21:58,158 --> 00:22:01,746
about to raise the throughput of our developers by

334
00:22:01,768 --> 00:22:05,574
a lot. Somebody's going to have to explain

335
00:22:05,612 --> 00:22:10,006
to me how

336
00:22:10,028 --> 00:22:13,766
we're going to secure all this code. And so this caused a lot

337
00:22:13,788 --> 00:22:17,046
of soul searching for me, and I'm sure a lot of

338
00:22:17,068 --> 00:22:20,894
other people to say, what are the things that can scale

339
00:22:20,962 --> 00:22:24,394
with the robots? And I'm just choosing three things here

340
00:22:24,432 --> 00:22:27,462
today to talk about. I think there's some more opportunities,

341
00:22:27,606 --> 00:22:31,230
but I think I want to focus on the highest yield

342
00:22:31,570 --> 00:22:36,302
things. And so one

343
00:22:36,356 --> 00:22:40,302
solution, one strategy we can have is to make it hard to be

344
00:22:40,356 --> 00:22:44,610
secures. And so Netflix

345
00:22:46,550 --> 00:22:49,310
has a term for this. They call it paved roads.

346
00:22:49,470 --> 00:22:52,946
So this is the idea where we have a

347
00:22:52,968 --> 00:22:56,694
use case, and we give the developer a

348
00:22:56,732 --> 00:23:00,390
very simple path to follow. We give them a framework,

349
00:23:02,010 --> 00:23:05,494
we give them an abstract type to

350
00:23:05,532 --> 00:23:09,740
work with that automatically enforces authentication for them.

351
00:23:10,110 --> 00:23:13,942
Right? So they don't have to think about authentication anymore.

352
00:23:14,006 --> 00:23:17,942
They don't have to think about identity authentication.

353
00:23:18,006 --> 00:23:21,674
They just add the type, add their feature,

354
00:23:21,802 --> 00:23:24,560
and security comes baked in. In that regard,

355
00:23:26,050 --> 00:23:29,774
you might have another use case where for a developer to

356
00:23:29,812 --> 00:23:33,314
make something for their

357
00:23:33,352 --> 00:23:37,250
code to compile, it forces you to provide

358
00:23:37,400 --> 00:23:41,090
roles for access control, enforcement, and so

359
00:23:41,240 --> 00:23:45,690
this is really forcing the developer to acknowledge

360
00:23:45,870 --> 00:23:48,870
when they make a new feature,

361
00:23:49,610 --> 00:23:53,320
what are the security aspects they should be asking themselves about?

362
00:23:53,690 --> 00:23:57,558
And we don't do this enough. Usually we tell the developer, hey, we need

363
00:23:57,564 --> 00:24:00,438
you to go make an app that does XYZ.

364
00:24:00,614 --> 00:24:04,842
And the product manager, the product owner doesn't really care many

365
00:24:04,896 --> 00:24:08,346
times about the security of it. They just sort of assume that security is

366
00:24:08,368 --> 00:24:11,950
baked in. And so the developer might stand

367
00:24:12,020 --> 00:24:16,094
up a new app with

368
00:24:16,132 --> 00:24:19,674
just the base, let's say exprs

369
00:24:19,722 --> 00:24:22,970
framework. And that's not going to come with any paved roads, right.

370
00:24:23,060 --> 00:24:26,706
The developer is now going to have to reinvent all

371
00:24:26,728 --> 00:24:30,786
the security controls and

372
00:24:30,808 --> 00:24:34,500
they're probably going to get a lot of things wrong along the way. And so

373
00:24:37,270 --> 00:24:40,534
these are some good ideas just to try to force them down a road

374
00:24:40,572 --> 00:24:44,440
that's going to either provide the security or force them to

375
00:24:44,890 --> 00:24:48,986
provide answers themselves. And you

376
00:24:49,008 --> 00:24:51,130
might say, to prevent cross site scripting,

377
00:24:52,350 --> 00:24:55,398
all the apps here have to be rest plus Json,

378
00:24:55,494 --> 00:24:58,998
right? And that makes cross site scripting

379
00:24:59,014 --> 00:25:02,110
patterns a lot harder to create accidentally.

380
00:25:03,170 --> 00:25:07,118
And this doesn't just apply to code or

381
00:25:07,204 --> 00:25:10,878
frameworks or something sort of at compile time,

382
00:25:10,964 --> 00:25:14,014
but maybe if we say, look,

383
00:25:14,052 --> 00:25:17,826
there's only one pipeline to use, or if you want

384
00:25:17,848 --> 00:25:21,346
to run a GitHub action, we're automatically going to add

385
00:25:21,368 --> 00:25:24,574
this in there where were going to force static analysis

386
00:25:24,622 --> 00:25:28,546
on every build, or we're going to add a GitHub app that watches

387
00:25:28,578 --> 00:25:32,390
your dependencies. And so these paved roads,

388
00:25:34,730 --> 00:25:38,314
they really help. And if

389
00:25:38,352 --> 00:25:42,506
a robot is going to take your code

390
00:25:42,688 --> 00:25:44,940
and add something to it,

391
00:25:45,390 --> 00:25:48,678
copilot in my experience has been pretty good about following

392
00:25:48,694 --> 00:25:53,742
the patterns that are there. And so if

393
00:25:53,796 --> 00:25:56,922
all it sees around it are paved roads,

394
00:25:57,066 --> 00:26:01,040
it'll probably use the paved roads. And so

395
00:26:02,390 --> 00:26:06,114
it'll force it to reason about some of these things

396
00:26:06,152 --> 00:26:10,274
that we talked about and provide some good

397
00:26:10,312 --> 00:26:12,660
first draft settings for some of these things.

398
00:26:14,470 --> 00:26:17,430
So what does it take to get this done? Sort of organizationally,

399
00:26:18,010 --> 00:26:22,194
the first thing is we need strong devex and platform teams.

400
00:26:22,242 --> 00:26:25,990
So strong teams who are centralized,

401
00:26:26,410 --> 00:26:29,930
who understand developers, who understand

402
00:26:30,080 --> 00:26:34,022
the requirements from security and can help developers

403
00:26:34,086 --> 00:26:37,786
go down these paved roads. Now the second bullet here is also really

404
00:26:37,808 --> 00:26:41,214
important. If you want to have

405
00:26:41,252 --> 00:26:44,346
paved roads, unfortunately,

406
00:26:44,458 --> 00:26:48,382
you can't say go build whatever you want in whatever language you want with whatever

407
00:26:48,436 --> 00:26:53,140
framework you want. That ends up being really difficult,

408
00:26:53,750 --> 00:26:57,410
because if you want to build

409
00:26:57,480 --> 00:27:01,822
a paved road that like an access control mechanism

410
00:27:01,886 --> 00:27:05,178
for every different language, for every different framework,

411
00:27:05,294 --> 00:27:08,806
it just doesn't scale. And so the fewer technology

412
00:27:08,908 --> 00:27:11,720
stacks you have, the better. And of course,

413
00:27:13,450 --> 00:27:17,158
if express is really big in your organization and you have a

414
00:27:17,164 --> 00:27:21,210
long tail of other technologies, of course it's still worth it to do paved roads

415
00:27:21,630 --> 00:27:24,598
for those technologies that are predominant.

416
00:27:24,774 --> 00:27:28,298
But it's hard to do sort of globally, hard to solve globally unless you're a

417
00:27:28,304 --> 00:27:32,250
little bit more authoritarian about what technology stacks are allowed.

418
00:27:32,410 --> 00:27:35,882
And then we love the developer

419
00:27:35,946 --> 00:27:39,454
security champion model, and this has become a really popular model

420
00:27:39,572 --> 00:27:43,154
in lots of different companies where we have

421
00:27:43,192 --> 00:27:46,770
security cross skilled developers

422
00:27:48,070 --> 00:27:51,598
who can chime in, who think about risk maybe a little bit differently

423
00:27:51,614 --> 00:27:54,814
than your average developers who can help create these paved

424
00:27:54,862 --> 00:27:57,730
roads, help inject security into these paved roads.

425
00:27:57,890 --> 00:28:01,766
And so I added a few vendors and tools here at

426
00:28:01,788 --> 00:28:05,080
the bottom for you to look into more. If this is interesting for you.

427
00:28:05,450 --> 00:28:08,774
One other strategy is to make it so. The first strategy

428
00:28:08,822 --> 00:28:12,134
was make it hard to be secures, right? Give developers

429
00:28:12,182 --> 00:28:15,740
paved roads so that it's difficult to get off those roads and create

430
00:28:16,350 --> 00:28:19,578
accidental vulnerabilities. Another strategy is to make it

431
00:28:19,584 --> 00:28:22,094
hard to exploit your insecure code.

432
00:28:22,292 --> 00:28:26,170
So traditionally, runtime protections

433
00:28:26,250 --> 00:28:30,026
were dominated by these tools called web application firewalls

434
00:28:30,058 --> 00:28:33,426
that watched HTTP traffic and sort of tried to

435
00:28:33,448 --> 00:28:36,126
signature to detect attacks.

436
00:28:36,318 --> 00:28:39,650
And they weren't super accurate, but they did provide

437
00:28:39,800 --> 00:28:43,054
visibility into traffic. You could detect

438
00:28:43,102 --> 00:28:47,038
obvious attacks. It was

439
00:28:47,064 --> 00:28:50,838
hard to rely on them in sort of a blocking code because they had

440
00:28:50,924 --> 00:28:54,358
lots of false positives. It's very difficult to watch

441
00:28:54,444 --> 00:28:59,330
traffic and pick out the bad stuff and

442
00:28:59,420 --> 00:29:02,522
not pick out good stuff accidentally. I've been in a job

443
00:29:02,576 --> 00:29:06,538
like that, and it's quite difficult. And so in

444
00:29:06,544 --> 00:29:09,786
the last few years, we've seen a class of

445
00:29:09,808 --> 00:29:13,882
tools I worked on one called RASp

446
00:29:13,946 --> 00:29:18,190
runtime application security protection. And so whereas traditional

447
00:29:18,850 --> 00:29:22,206
protection tools sat at the network level and

448
00:29:22,228 --> 00:29:25,280
try to protect, build a moat around the app,

449
00:29:26,290 --> 00:29:30,850
these rasp tools are really injecting sensors and actuators

450
00:29:31,430 --> 00:29:34,786
into the application itself, into the

451
00:29:34,808 --> 00:29:38,054
app, the frameworks, the libraries. So these are sort of

452
00:29:38,092 --> 00:29:41,986
language level agents that are putting these sensors

453
00:29:42,018 --> 00:29:45,410
actuators in and acting on behaviors

454
00:29:45,490 --> 00:29:48,530
rather than traffic signatures.

455
00:29:48,690 --> 00:29:52,922
And so this is an example of a rasp tool.

456
00:29:53,056 --> 00:29:56,934
And so the user input that the attackers

457
00:29:56,982 --> 00:30:00,510
sent in, they're trying to exploit a SQL injection. They send in

458
00:30:00,580 --> 00:30:02,880
this tick, or one equals one,

459
00:30:04,210 --> 00:30:07,994
which is a comment in this SQL

460
00:30:08,042 --> 00:30:11,934
dialect. And so they're trying to attack this

461
00:30:11,972 --> 00:30:15,858
line of c sharp code where the

462
00:30:15,864 --> 00:30:20,674
user input is included here. Now a

463
00:30:20,712 --> 00:30:23,874
WAf only sees the input right.

464
00:30:24,072 --> 00:30:27,846
It gets the traffic first. It looks at the input and says, is this an

465
00:30:27,868 --> 00:30:31,414
attack or not? It has to make a decision that's far

466
00:30:31,452 --> 00:30:35,926
too early, far too away from what we call boom to

467
00:30:35,948 --> 00:30:39,690
make that decision. But a rasp

468
00:30:40,350 --> 00:30:44,474
can look at the application behavior, it can look

469
00:30:44,512 --> 00:30:48,026
at the SQL query that's actually being sent, and it

470
00:30:48,048 --> 00:30:51,214
can scan it and it can tokenize it,

471
00:30:51,252 --> 00:30:55,022
and it can semantically analyze it and say, look this

472
00:30:55,076 --> 00:30:58,110
query, some user input came in,

473
00:30:58,260 --> 00:31:02,326
I saw it go into the SQL statement.

474
00:31:02,458 --> 00:31:07,346
And two things about it irritated me. One is it

475
00:31:07,368 --> 00:31:10,434
caused a data context CTO become code.

476
00:31:10,632 --> 00:31:14,002
So the token boundary was crossed here.

477
00:31:14,136 --> 00:31:18,054
This input looks like it became code at this, or one

478
00:31:18,092 --> 00:31:23,334
equals one part. And then there's a

479
00:31:23,372 --> 00:31:26,774
clause that always evaluates to true right. This is something we can

480
00:31:26,812 --> 00:31:30,422
evaluate at the sensor where SQL

481
00:31:30,486 --> 00:31:33,546
is evaluated. And that kind of bugs us

482
00:31:33,568 --> 00:31:37,878
too. And so you have so many more degrees of freedom

483
00:31:38,054 --> 00:31:42,720
with tools like these that sit in the runtime and

484
00:31:44,450 --> 00:31:47,854
can look for malicious behaviors. People who use these

485
00:31:47,892 --> 00:31:51,422
tools, they were protected from

486
00:31:51,556 --> 00:31:54,494
log for j, the exploits,

487
00:31:54,542 --> 00:31:57,874
when the log for J exploit came out because they was

488
00:31:57,912 --> 00:32:01,550
watching for malicious behaviors of the runtime,

489
00:32:01,710 --> 00:32:05,300
not traffic. And so

490
00:32:06,090 --> 00:32:09,830
there's some vendors here that there's not really an open source,

491
00:32:10,330 --> 00:32:14,194
good open source option, but it's

492
00:32:14,242 --> 00:32:17,674
still a relatively new space. And so if you want to make

493
00:32:17,712 --> 00:32:20,330
your code much harder to exploit,

494
00:32:21,070 --> 00:32:26,266
this is a very good option, because now you

495
00:32:26,288 --> 00:32:30,734
have some confidence that even if the

496
00:32:30,772 --> 00:32:34,350
generative AI is producing code that may be secures,

497
00:32:34,850 --> 00:32:39,562
that it still can be protected from a lot of different vulnerability classes.

498
00:32:39,706 --> 00:32:43,690
Now, these vendors and these strategies

499
00:32:43,770 --> 00:32:47,634
work pretty well when it's a vulnerability class that looks the

500
00:32:47,672 --> 00:32:51,406
same from your app to the next app to the next person's

501
00:32:51,438 --> 00:32:55,366
app. So for instance, SQL injection is the same no

502
00:32:55,388 --> 00:32:58,582
matter whose app it is.

503
00:32:58,716 --> 00:33:02,470
But we also have a class of vulnerabilities called business

504
00:33:02,540 --> 00:33:06,966
logic vulnerabilities that do look different. They look very custom

505
00:33:07,148 --> 00:33:10,920
to your app. So you might have business rules that say

506
00:33:11,450 --> 00:33:15,082
Mary is allowed to access this data unless it's Tuesday after

507
00:33:15,136 --> 00:33:18,406
04:00 p.m. And so those types

508
00:33:18,438 --> 00:33:22,314
of weaknesses, the gaps in our security models

509
00:33:22,362 --> 00:33:26,094
there, the misses we create there, those are

510
00:33:26,132 --> 00:33:30,190
different from app to app. And so they're harder for both

511
00:33:30,260 --> 00:33:34,130
static analysis tools or any kind of analysis tools and

512
00:33:34,200 --> 00:33:37,458
for tools like protection tools to understand

513
00:33:37,544 --> 00:33:41,458
that there was an exploit that occurred, because sometimes

514
00:33:41,544 --> 00:33:45,366
that's allowed. And so how can these tools understand the

515
00:33:45,388 --> 00:33:48,646
business requirements being violated here?

516
00:33:48,748 --> 00:33:52,022
So although that these tools can help with

517
00:33:52,076 --> 00:33:55,880
many things, there's still some things that they can't help with.

518
00:33:56,250 --> 00:33:58,730
So if we remember our diagram,

519
00:33:59,470 --> 00:34:03,082
we had all those M's on the board and all those

520
00:34:03,136 --> 00:34:06,746
M's, all those manual activities, most of them were

521
00:34:06,928 --> 00:34:10,940
responding humans that had to respond to

522
00:34:11,470 --> 00:34:14,400
an interruption from a security tool.

523
00:34:15,010 --> 00:34:18,986
And some of those tools were software composition analysis tools.

524
00:34:19,018 --> 00:34:24,914
Some of them were docker tools. But what we found is that most

525
00:34:24,952 --> 00:34:28,222
of the results come from code scanning tools.

526
00:34:28,286 --> 00:34:32,526
So we need to solve this problem for all of them. But it's

527
00:34:32,558 --> 00:34:36,870
interesting that this problem of evaluating the results from security tools

528
00:34:37,290 --> 00:34:40,722
also requires the hardest

529
00:34:40,786 --> 00:34:44,662
collection of skills across

530
00:34:44,796 --> 00:34:48,070
development and secures. So you have to understand

531
00:34:48,140 --> 00:34:52,250
the vulnerability class. You need to understand sort of security concepts

532
00:34:52,670 --> 00:34:55,914
in general, and you need to understand the code in order

533
00:34:55,952 --> 00:34:59,178
to determine is this a real issue?

534
00:34:59,264 --> 00:35:02,734
Is it a false positive? Is it something I need to fix right now?

535
00:35:02,932 --> 00:35:07,278
And so we

536
00:35:07,284 --> 00:35:10,766
can imagine a tool here where we

537
00:35:10,788 --> 00:35:13,858
see sonar here finding something,

538
00:35:14,024 --> 00:35:16,850
sonar finds a SQL injection vulnerability.

539
00:35:17,670 --> 00:35:21,022
We have a security copilot here that's

540
00:35:21,086 --> 00:35:24,194
reviewed the code and said, hey, look,

541
00:35:24,232 --> 00:35:27,238
I noticed you had some vulnerabilities in that code.

542
00:35:27,404 --> 00:35:31,122
I'm going to issue you a pr to try to fix those vulnerabilities.

543
00:35:31,266 --> 00:35:34,210
And then after that PR gets merged,

544
00:35:34,290 --> 00:35:36,360
the scanner doesn't find anything.

545
00:35:38,730 --> 00:35:42,026
We need to be able to do two things to accomplish this reality. We need

546
00:35:42,048 --> 00:35:45,542
to be able to triage results to determine if they should be pixee,

547
00:35:45,686 --> 00:35:48,950
and then we need to be able to fix them confidently.

548
00:35:49,110 --> 00:35:52,766
And so what we see here is a

549
00:35:52,788 --> 00:35:56,462
tool doing that. And so there's still a human

550
00:35:56,516 --> 00:35:59,120
in the loop here to approve this pr,

551
00:35:59,730 --> 00:36:03,946
but the whole job of triaging the vulnerability and creating

552
00:36:03,978 --> 00:36:07,346
a fix and verifying that all the tests pass and all that stuff,

553
00:36:07,448 --> 00:36:12,174
this can be done by what we're calling a security tools copilot.

554
00:36:12,302 --> 00:36:16,326
And so I have an offering in this space, but there's also others that

555
00:36:16,348 --> 00:36:20,182
I've listed here. And so I wanted

556
00:36:20,236 --> 00:36:24,118
CTo especially highlight. At the bottom here we

557
00:36:24,124 --> 00:36:29,730
have this library called code modder, on which we

558
00:36:29,820 --> 00:36:34,410
opensource this technology to help other people perform

559
00:36:34,480 --> 00:36:37,962
this same kind of activity. And so I'm going to spend a little bit of

560
00:36:38,016 --> 00:36:42,330
time on code modder. So code mods are this cool

561
00:36:42,480 --> 00:36:45,674
idea. They came out of the first Python

562
00:36:45,722 --> 00:36:49,534
community from an engineer, Justin at Facebook. Oh my gosh, I can't remember

563
00:36:49,572 --> 00:36:53,674
his last name. And then we saw them

564
00:36:53,732 --> 00:36:57,346
sort of jump to the JavaScript world as

565
00:36:57,368 --> 00:37:00,820
really the primary users of code mods today.

566
00:37:01,190 --> 00:37:05,202
And so the idea is a code mod is a little bit of code that

567
00:37:05,256 --> 00:37:08,870
changes a lot of code. And so the Javascript community

568
00:37:08,940 --> 00:37:12,802
uses code mods today to do things like upgrade your react

569
00:37:12,866 --> 00:37:16,614
four, to react five, update all your code. And so

570
00:37:16,652 --> 00:37:20,650
this is a cool use case, but they never really escaped

571
00:37:21,630 --> 00:37:25,050
that pattern of usage. When I was looking

572
00:37:25,120 --> 00:37:28,570
into how can we automatically secure code on people's behalf?

573
00:37:30,030 --> 00:37:33,566
I wanted CTO do more and I couldn't get them to

574
00:37:33,588 --> 00:37:36,702
do more. And so that's because they were

575
00:37:36,756 --> 00:37:41,034
missing the ability, they weren't very expressive.

576
00:37:41,162 --> 00:37:45,202
I couldn't get them CTo highlight or find

577
00:37:45,336 --> 00:37:49,102
complicated patterns of code. If you just want to change library

578
00:37:49,166 --> 00:37:53,378
a to library b, and you're just replacing APIs, it's not that

579
00:37:53,544 --> 00:37:56,926
difficult. But if you want to automatically refactor

580
00:37:56,958 --> 00:38:00,054
some code to be secures, well,

581
00:38:00,092 --> 00:38:03,778
you need to do a good job of finding the places where it isn't secure.

582
00:38:03,874 --> 00:38:07,766
And so this is why I developed code modder with

583
00:38:07,788 --> 00:38:11,494
some of my friends. So code modder is an open source

584
00:38:11,622 --> 00:38:14,490
code mod library for Java and Python today.

585
00:38:14,560 --> 00:38:18,106
And what makes it different and what's so exciting about it

586
00:38:18,128 --> 00:38:22,206
is it is really an orchestration library. At first

587
00:38:22,228 --> 00:38:25,530
I started to build a library that was very ocean boiling.

588
00:38:25,610 --> 00:38:30,606
It tries to offer query language and

589
00:38:30,788 --> 00:38:34,098
it was too much to do. A lot of languages, CTO support a lot of

590
00:38:34,104 --> 00:38:37,778
languages. And we realized that there's already been so many

591
00:38:37,864 --> 00:38:41,810
hundreds of manures invested in tools like

592
00:38:41,960 --> 00:38:45,370
contrast, Semgrap, code, sonar, fortify,

593
00:38:45,470 --> 00:38:47,990
checkmarks, et cetera. All these tools,

594
00:38:50,570 --> 00:38:54,578
they've invested a ton into identifying vulnerable

595
00:38:54,674 --> 00:39:01,946
or interesting shapes of code. To go change code

596
00:39:01,968 --> 00:39:05,754
mod libraries shouldn't try to replicate that. We should

597
00:39:05,792 --> 00:39:09,862
just take the results from those tools and then pair them with

598
00:39:09,936 --> 00:39:13,978
tools that are great at changing code. And so tools

599
00:39:13,994 --> 00:39:17,146
like Java Parser, Libcst, JS, Codeshift,

600
00:39:17,338 --> 00:39:21,326
Go has refactoring features sort of right out of the

601
00:39:21,508 --> 00:39:26,386
first class feature of the language. And so we

602
00:39:26,408 --> 00:39:29,986
need to create a library that orchestrates these things together. And so this

603
00:39:30,008 --> 00:39:34,222
is an example code mod in the code moderate framework,

604
00:39:34,286 --> 00:39:37,442
which orchestrates a Semgrep rule.

605
00:39:37,586 --> 00:39:40,840
Semgrep is a fun static analysis tool to use.

606
00:39:41,610 --> 00:39:46,498
It's really good at building very expressive, simple rules.

607
00:39:46,594 --> 00:39:50,300
And so in this example we want to find anytime you're using

608
00:39:51,310 --> 00:39:55,126
the random functions and replace the random

609
00:39:55,158 --> 00:39:58,620
dot function with a more secure version of that.

610
00:39:59,950 --> 00:40:03,538
If you don't know most of the time in a language,

611
00:40:03,574 --> 00:40:06,526
when you say give me the next, give me a random number, or give me

612
00:40:06,548 --> 00:40:09,790
a random string of characters, it's actually quite predictable.

613
00:40:10,130 --> 00:40:15,154
You need to use often the secure version of that

614
00:40:15,192 --> 00:40:18,286
library in order to get actually unpredictable,

615
00:40:18,398 --> 00:40:22,562
unguesable entropy, which is very important for

616
00:40:22,616 --> 00:40:26,006
generating passwords and tokens, et cetera. And so if you wanted

617
00:40:26,028 --> 00:40:29,446
CTO write a code mod in

618
00:40:29,468 --> 00:40:32,360
Python, this is what it would look like.

619
00:40:33,130 --> 00:40:36,946
We create a little semgrap rule to help find the shapes

620
00:40:36,978 --> 00:40:40,874
of code we want to change. And then through

621
00:40:40,912 --> 00:40:44,314
our magic, the developers doesn't have to do anything in terms

622
00:40:44,352 --> 00:40:47,718
of understanding how the tool gets invoked

623
00:40:47,734 --> 00:40:51,054
or anything. It'll just jump on the results of that,

624
00:40:51,092 --> 00:40:54,506
and for every result, it changed

625
00:40:54,538 --> 00:40:58,174
to the secure version of that

626
00:40:58,212 --> 00:41:01,706
API. And so what we're trying to do with this open source

627
00:41:01,738 --> 00:41:04,320
project is create,

628
00:41:05,430 --> 00:41:08,914
I'm not sure, have 50 or 100 something like that,

629
00:41:08,952 --> 00:41:12,654
rules or code mods in order to upgrade

630
00:41:12,702 --> 00:41:16,566
code automatically. And so this is obviously a fundamental tool if

631
00:41:16,588 --> 00:41:18,390
we want to keep up with the robots.

632
00:41:20,490 --> 00:41:24,054
If code comes in from a robot and

633
00:41:24,092 --> 00:41:27,990
we can have code that changes that code to be secure,

634
00:41:28,890 --> 00:41:31,946
that's a big deal, because now a lot

635
00:41:31,968 --> 00:41:36,106
of these findings from these security tools won't happen. And the

636
00:41:36,128 --> 00:41:40,342
ones that do get found, we can act on them and fix them automatically.

637
00:41:40,486 --> 00:41:44,846
And so we can help stay on track with

638
00:41:44,868 --> 00:41:49,306
all the code that's coming in. And so here's

639
00:41:49,338 --> 00:41:53,042
some links for you to follow if you want to learn more about the open

640
00:41:53,096 --> 00:41:59,246
source offering. So that's

641
00:41:59,278 --> 00:42:02,322
what I came here to say. I think that there

642
00:42:02,376 --> 00:42:05,510
are a lot of things we can do

643
00:42:05,580 --> 00:42:08,818
to try to keep pace with the robots,

644
00:42:08,994 --> 00:42:12,742
but we have to be realistic and we have to move

645
00:42:12,796 --> 00:42:16,806
right now in

646
00:42:16,828 --> 00:42:20,266
order to keep up. Most of the enterprises I

647
00:42:20,288 --> 00:42:24,102
talk to now are doing PoCs with copilot.

648
00:42:24,246 --> 00:42:27,594
And when copilot code in, when code

649
00:42:27,632 --> 00:42:30,810
whisper comes in, whenever, whatever LLM

650
00:42:30,890 --> 00:42:34,414
is, your preference comes in, we're going to see a lot more

651
00:42:34,452 --> 00:42:36,480
throughput and security.

652
00:42:37,570 --> 00:42:41,310
I've suffered the same staffing challenges

653
00:42:41,890 --> 00:42:45,118
as the general tech industry has. And so

654
00:42:45,204 --> 00:42:47,920
how are we going with fewer people than ever?

655
00:42:48,450 --> 00:42:52,110
We absolutely today need to create

656
00:42:52,180 --> 00:42:55,682
some strategies and start working on people, process knowledge,

657
00:42:55,826 --> 00:42:59,014
CTO keep up, because the LLMs are

658
00:42:59,052 --> 00:43:02,598
not going to produce secure code. We have plenty of evidence of that,

659
00:43:02,764 --> 00:43:06,262
but we're going to own the risk of it as

660
00:43:06,316 --> 00:43:10,470
application makers. So happy to be here,

661
00:43:10,540 --> 00:43:14,070
thanks for having me. And I've got some contact info

662
00:43:14,810 --> 00:43:16,660
if you want to talk further. Take care.

