1
00:00:39,010 --> 00:00:42,802
Hi everyone. I hope everyone is having a fun time at the conference.

2
00:00:42,946 --> 00:00:47,042
My name is Harsh and I'm currently working as an engineer at local stack.

3
00:00:47,186 --> 00:00:50,382
Today I will be presenting my talk on shift left cloud

4
00:00:50,436 --> 00:00:53,662
chaos testing on your local machine. The focus

5
00:00:53,716 --> 00:00:57,246
of the talk would be around local cloud chaos testing and how

6
00:00:57,268 --> 00:01:01,134
you can leverage open source cloud emulators to make this happen.

7
00:01:01,332 --> 00:01:04,514
So without further ado, let's jump directly into

8
00:01:04,552 --> 00:01:05,380
the talk.

9
00:01:07,590 --> 00:01:11,234
So let's check out the agenda for today. We will start with

10
00:01:11,272 --> 00:01:14,574
understanding what do we mean by shift left chaos testing

11
00:01:14,622 --> 00:01:18,246
and how various open source tools can help you get started. With this,

12
00:01:18,428 --> 00:01:21,782
we will uncover how performing chaos testing on public cloud

13
00:01:21,836 --> 00:01:25,046
can be risky, and how cloud emulators can help you in

14
00:01:25,068 --> 00:01:28,730
this regard. We will check out a couple of cool and interesting

15
00:01:28,880 --> 00:01:31,962
demonstrations that will explain how locally running

16
00:01:32,016 --> 00:01:35,754
emulators can help you build a strong test suite for

17
00:01:35,792 --> 00:01:39,430
maintaining conformity and latency both on your local machine

18
00:01:39,510 --> 00:01:42,926
and in your continuous integration pipelines. We will end

19
00:01:42,948 --> 00:01:46,522
this session with a final concluding note that would remark some strategies

20
00:01:46,586 --> 00:01:50,666
around building a test suite for a local chaos testing setup

21
00:01:50,778 --> 00:01:54,910
and how developers can be empowered to build failover mechanisms

22
00:01:54,990 --> 00:01:58,466
right from the start. So let's jump right

23
00:01:58,488 --> 00:02:01,906
into it. What is shift left chaos testing and

24
00:02:01,928 --> 00:02:05,314
what do we exactly mean by that? But before that,

25
00:02:05,352 --> 00:02:08,966
let's do a quick recap around what chaos engineering exactly

26
00:02:09,068 --> 00:02:11,640
is and where do we stand right now?

27
00:02:12,890 --> 00:02:15,926
The idea behind chaos engineering is all about

28
00:02:16,028 --> 00:02:20,010
how you can experiment on a system to uncover behavioral issues

29
00:02:20,160 --> 00:02:23,402
and make your whole application resilient to such

30
00:02:23,456 --> 00:02:27,370
conditions right from the start before you land into the production.

31
00:02:27,790 --> 00:02:31,838
This concept, I guess, emerged around 2010s, maybe early two thousand

32
00:02:31,844 --> 00:02:35,214
and ten s and was heralded, in fact,

33
00:02:35,252 --> 00:02:38,574
due to the outages that have suffered like

34
00:02:38,612 --> 00:02:42,174
that have made the organization suffer a lot of significant cost.

35
00:02:42,372 --> 00:02:46,834
Now these incidents always have highlighted a long standing issue.

36
00:02:47,032 --> 00:02:50,574
Organizations of all sizes have experienced such disruptions,

37
00:02:50,622 --> 00:02:54,162
and some of the times these are the disruptions. We are beyond their

38
00:02:54,216 --> 00:02:57,842
control. Now, these outages not only affect their maintenance

39
00:02:57,906 --> 00:03:01,830
cost and the company revenue, but also have broader consequences

40
00:03:02,330 --> 00:03:06,182
for the development and also the teams that are managing the whole

41
00:03:06,236 --> 00:03:09,898
user experience. Now this is where

42
00:03:10,064 --> 00:03:13,894
chaos testing comes into the picture. With chaos testing,

43
00:03:13,942 --> 00:03:17,782
you can set up a system's baseline or optimal operational

44
00:03:17,846 --> 00:03:21,934
state further. Then you can identify some

45
00:03:21,972 --> 00:03:25,662
of the potential vulnerabilities and

46
00:03:25,716 --> 00:03:29,870
design scenarios, and you can further evaluate their potential impact.

47
00:03:30,210 --> 00:03:33,754
Now, for a lot of developers, injecting these faults or

48
00:03:33,812 --> 00:03:37,874
issues seems almost counterintuitive. Now just imagine this.

49
00:03:37,912 --> 00:03:41,714
You already have unit tests, you already have some sort of an integration test

50
00:03:41,752 --> 00:03:45,666
suite running with every single commit being merged. So why would

51
00:03:45,688 --> 00:03:49,254
I need another layer of testing just to ensure that my application would

52
00:03:49,292 --> 00:03:52,822
work fine? Now this part is particularly important

53
00:03:52,956 --> 00:03:56,854
because of third party services, particularly the public cloud that

54
00:03:56,892 --> 00:04:01,180
has made chaos testing useful. You can

55
00:04:01,550 --> 00:04:04,554
cover up some of the faulty configuration issues,

56
00:04:04,672 --> 00:04:07,994
behaviors, outages and other interruptions that might

57
00:04:08,032 --> 00:04:11,638
not necessarily be due to your code, but just something that's going wrong with just

58
00:04:11,664 --> 00:04:15,086
your provider. Standard testing can fix some of the

59
00:04:15,108 --> 00:04:18,714
usual issues that might have a net end user negative

60
00:04:18,762 --> 00:04:22,206
reaction, but chaos testing can help you introduce issues into

61
00:04:22,228 --> 00:04:25,422
your system and just build some solutions around it about

62
00:04:25,476 --> 00:04:28,946
how you can react to such kind of issues at the end.

63
00:04:29,128 --> 00:04:32,094
And one of the core tenet of this is that I would like to highlight

64
00:04:32,142 --> 00:04:35,262
is that developers should value the chaos,

65
00:04:35,406 --> 00:04:38,534
and once they value that, they need to build the solutions around

66
00:04:38,572 --> 00:04:42,114
it with a predefined plan that allows you to introduce

67
00:04:42,162 --> 00:04:45,526
errors and also help you build kind of a swift response to

68
00:04:45,548 --> 00:04:48,822
that. This allows you to handle any sort of unexpected

69
00:04:48,886 --> 00:04:52,826
behavior and also maintains the balance between thorough testing and

70
00:04:52,848 --> 00:04:54,460
the stability for your application.

71
00:04:55,790 --> 00:04:59,894
And this of course could not be possible without a steady DevOps culture.

72
00:05:00,022 --> 00:05:03,374
Chaos testing is essentially a DevOps practice at the end

73
00:05:03,412 --> 00:05:06,634
where you can define various testing scenarios, you can handle various

74
00:05:06,682 --> 00:05:10,778
kind of executions, you can track the results in varying outcomes

75
00:05:10,874 --> 00:05:14,718
and ensure that your end customers do not suffer any impact.

76
00:05:14,894 --> 00:05:18,274
Resilience is a pretty important aspect for any

77
00:05:18,312 --> 00:05:21,454
deployment process, and a strong DevOps pipeline

78
00:05:21,502 --> 00:05:25,406
should ensure that your application should remain robust. It should remain reliable

79
00:05:25,438 --> 00:05:28,258
in a cloud environment where factors like scalability,

80
00:05:28,354 --> 00:05:31,730
availability, fault tolerance are all of critical aspects,

81
00:05:31,810 --> 00:05:34,360
some of which might not be even in your control.

82
00:05:35,530 --> 00:05:39,366
Now there are various chaos testing tools, both open source and commercial in

83
00:05:39,388 --> 00:05:42,806
nature, and teams have been using them to build reliable solutions

84
00:05:42,838 --> 00:05:46,410
for quite some time. There was an interesting keynote session at

85
00:05:46,480 --> 00:05:49,866
Conf 42 Chaos engineering conference by Pablo I

86
00:05:49,888 --> 00:05:53,690
guess the last year, and he talked about like shifting

87
00:05:53,770 --> 00:05:57,310
left chaos testing with Grafana K six. So you can definitely

88
00:05:57,380 --> 00:06:00,874
check that out. We have some of the key innovators over here like Chaos

89
00:06:00,922 --> 00:06:04,514
Monkey from Netflix, which started as a test tool to evaluate the

90
00:06:04,552 --> 00:06:08,562
resiliency of AWS resources and simulate failures for

91
00:06:08,616 --> 00:06:11,378
services running within an auto scaling group.

92
00:06:11,544 --> 00:06:15,646
Litmus Chaos is another interesting project by CNCF

93
00:06:15,758 --> 00:06:19,334
that uses a chaos management tool called as Chaos center where

94
00:06:19,372 --> 00:06:22,662
you can basically create, manage and monitor your chaos using

95
00:06:22,716 --> 00:06:26,162
Kubernetes custom resources in a pretty much a cloud native manner.

96
00:06:26,306 --> 00:06:29,718
Other projects include, I guess Chaos blade, chaos Mesh,

97
00:06:29,814 --> 00:06:33,786
Chaos Toolkit and more, which can provide you various features to

98
00:06:33,808 --> 00:06:36,330
enable your cloud testing workflows.

99
00:06:37,550 --> 00:06:40,326
But one of the things that I would like to highlight, and I guess it's

100
00:06:40,358 --> 00:06:43,546
one of the persistent issues with chaos testing cloud components,

101
00:06:43,578 --> 00:06:47,194
is that they are often proprietary in nature,

102
00:06:47,322 --> 00:06:50,286
and the only way that you can test them is running them directly in the

103
00:06:50,308 --> 00:06:53,966
production. Now you can imagine this testing things such

104
00:06:53,988 --> 00:06:58,030
as missing error handlers, or missing health checks or missing fallbacks

105
00:06:58,110 --> 00:07:01,566
cannot be done without actually deploying to a staging or a production

106
00:07:01,598 --> 00:07:05,202
environment. Though you will have the comfort of running everything

107
00:07:05,256 --> 00:07:09,554
directly onto the cloud, you will miss out on two significant

108
00:07:09,602 --> 00:07:13,254
aspects. The first one is that since you're running on the cloud,

109
00:07:13,372 --> 00:07:16,914
it will cost you significantly, especially deploying all your resources,

110
00:07:16,962 --> 00:07:19,506
including databases, message queues,

111
00:07:19,698 --> 00:07:22,778
kafka clusters, kubernetes clusters, and more of them.

112
00:07:22,944 --> 00:07:26,234
Second, some of these tests can take you hours, if not

113
00:07:26,272 --> 00:07:30,374
days or weeks, to test reliably, and you will miss out on the agility aspect

114
00:07:30,422 --> 00:07:34,442
of the DevOps culture. So how do you shift left your chaos

115
00:07:34,506 --> 00:07:38,494
testing early in the development process as closely to the developer machine as

116
00:07:38,532 --> 00:07:41,886
possible? Few years back this would happen, implausible to

117
00:07:41,908 --> 00:07:46,034
think of, but now we have a certain solution and

118
00:07:46,072 --> 00:07:49,502
the answer is cloud emulators. Cloud emulators

119
00:07:49,566 --> 00:07:53,086
are powerful developer tools because they can counter the friction

120
00:07:53,118 --> 00:07:56,914
between cloud native paradigm and also the local development paradigm.

121
00:07:57,042 --> 00:08:00,806
Now, there are two certain aspects of cloud emulators. The first one

122
00:08:00,828 --> 00:08:04,754
is that they almost remove the need for provisioning

123
00:08:04,802 --> 00:08:08,198
a completely dedicated development environment like sandbox and all of

124
00:08:08,204 --> 00:08:11,686
these things which mirrors your production setup. And the

125
00:08:11,708 --> 00:08:15,546
second is that every change that you do to your application or to your code

126
00:08:15,648 --> 00:08:19,066
do not need to be packaged and uploaded to the cloud needs to be

127
00:08:19,088 --> 00:08:21,850
deployed so that you can run your tests against it.

128
00:08:22,000 --> 00:08:25,182
So with the help of these emulators, you now have a replica of a cloud

129
00:08:25,236 --> 00:08:28,766
service that's running fully local on your machine or in an

130
00:08:28,788 --> 00:08:32,542
automated test environment. And this makes chaos testing so easy

131
00:08:32,596 --> 00:08:36,242
and helpful. So how do you go about building

132
00:08:36,296 --> 00:08:39,220
a chaos test suite for your cloud application?

133
00:08:39,670 --> 00:08:43,602
The answer to this almost lies in the testability of your cloud

134
00:08:43,656 --> 00:08:47,198
application deployments. As you can see at the top

135
00:08:47,224 --> 00:08:51,282
of this pyramid, we have the classic strategy of using mock libraries.

136
00:08:51,426 --> 00:08:54,978
With mocking, you can scope the tested component in unit

137
00:08:54,994 --> 00:08:58,342
tests, and you can implement the same interface as the real

138
00:08:58,396 --> 00:09:02,470
class to allow the predefined behavior to be invoked.

139
00:09:02,630 --> 00:09:05,962
Second, we have the service emulation, which means that we now have

140
00:09:06,016 --> 00:09:10,170
local stripped down versions of the managed service, where each individual service

141
00:09:10,240 --> 00:09:13,694
requires its own implementation as a follow up to that,

142
00:09:13,732 --> 00:09:17,018
we now have cloud emulation, which enables a superset

143
00:09:17,034 --> 00:09:20,366
of cloud resources that can interact with each other and run on

144
00:09:20,388 --> 00:09:23,934
your local machine. And finally, we have real staging environment

145
00:09:23,982 --> 00:09:26,450
which uses real cloud resources.

146
00:09:27,750 --> 00:09:31,074
An example for this that I would like to showcase is of

147
00:09:31,112 --> 00:09:35,502
course moto. It's a pretty popular mocking library for AWS,

148
00:09:35,646 --> 00:09:39,590
and with Moto you can basically add decorators to your test

149
00:09:39,660 --> 00:09:43,106
cases and redirect all of the AWS API calls

150
00:09:43,138 --> 00:09:46,440
to a mock resource and not to the real AWS services.

151
00:09:46,890 --> 00:09:50,950
Now, mock libraries are excellent tools for local cloud development,

152
00:09:51,030 --> 00:09:52,810
but they are often limited.

153
00:09:54,670 --> 00:09:58,506
The very first and the foremost reason for this is that mocking these services

154
00:09:58,608 --> 00:10:02,174
do not correctly replicate the behavior of remote cloud

155
00:10:02,212 --> 00:10:05,840
services that are often interacting with each other, and also the application.

156
00:10:06,770 --> 00:10:10,826
You can definitely build a chaos testing suite around just plain mocking,

157
00:10:10,938 --> 00:10:14,174
but it might often lead to unsatisfactory results

158
00:10:14,222 --> 00:10:17,970
because the behavior of your locally executed test always

159
00:10:18,040 --> 00:10:20,770
diverges from the behavior that you see in the production.

160
00:10:22,470 --> 00:10:25,726
Now, with the limitations of mocking, we now have progressed

161
00:10:25,758 --> 00:10:29,066
further and we have local development servers that provide an emulation

162
00:10:29,118 --> 00:10:32,946
layer. The difference between mocking and emulation often lies in the degree

163
00:10:32,978 --> 00:10:35,778
to which the behavior of the service is reverse engineered.

164
00:10:35,874 --> 00:10:39,586
Now, as an example here, if we pick up DynamoDB

165
00:10:39,618 --> 00:10:43,514
local to create a new database, the mock will return us a

166
00:10:43,552 --> 00:10:47,274
parsable API lessons, but it does not necessarily carry any

167
00:10:47,312 --> 00:10:51,190
state, and it will just give you some random attributes that do not reflect

168
00:10:51,270 --> 00:10:55,086
the request context. In comparison, the emulator will

169
00:10:55,108 --> 00:10:58,318
correctly store and retrieve the state for you. However,

170
00:10:58,404 --> 00:11:02,206
there are always some issues with the service emulators. The first one is that there

171
00:11:02,228 --> 00:11:05,442
is no sort of an integration between different services, which means that

172
00:11:05,496 --> 00:11:09,262
you cannot hook your dynamodb with appsync or with lambdas or whatsoever.

173
00:11:09,406 --> 00:11:12,942
You cannot use them with a fully fledged ise script,

174
00:11:13,086 --> 00:11:16,738
and there are often API compatibility issues, and they are also not up

175
00:11:16,744 --> 00:11:20,262
to date with the latest API enhancements that might be happening in real

176
00:11:20,316 --> 00:11:23,558
time. So as the best example of a

177
00:11:23,564 --> 00:11:27,266
cloud emulator, we have local stack. Local stack is an open source

178
00:11:27,298 --> 00:11:31,366
service emulator that runs in a single container on your laptop

179
00:11:31,478 --> 00:11:34,774
or your continuous integration environment. For the end user,

180
00:11:34,822 --> 00:11:38,154
it means that it allows them to run these AWS services pretty much

181
00:11:38,192 --> 00:11:41,326
on their local machine. The entire purpose of a project like

182
00:11:41,348 --> 00:11:44,410
local stack is to basically drive local cloud development,

183
00:11:44,490 --> 00:11:48,174
and also to make sure that engineers can collaborate and

184
00:11:48,212 --> 00:11:52,026
just do away with inefficient development and testing loops.

185
00:11:52,218 --> 00:11:55,742
But now the question starts is how do you enable chaos

186
00:11:55,806 --> 00:11:59,394
testing with local stack? As a first step you can

187
00:11:59,432 --> 00:12:03,362
basically use local stack as a drop in replacement for AWS on

188
00:12:03,416 --> 00:12:06,898
your developer machine and your CI environment, and you

189
00:12:06,904 --> 00:12:10,434
can use them with services such as Amazon fault injection simulator,

190
00:12:10,482 --> 00:12:13,718
which is fis, and you can perform resilient testing for your

191
00:12:13,724 --> 00:12:17,174
cloud apps running locally. Now the benefits of this

192
00:12:17,212 --> 00:12:21,098
are paramount. This means that you can not just deploy your application

193
00:12:21,184 --> 00:12:24,630
locally, but also run experiments that can inject errors

194
00:12:24,710 --> 00:12:30,230
at the infrastructure level which was not possible to replicate beforehand.

195
00:12:30,390 --> 00:12:34,026
And you can do this only once you deploy to the production,

196
00:12:34,058 --> 00:12:37,486
so it makes it even hard. But with a solution like local stack, you can

197
00:12:37,508 --> 00:12:41,166
basically shift left your chaos experiments and tests right on

198
00:12:41,188 --> 00:12:44,818
the developer machine. And you can use this to basically tackle some of the

199
00:12:44,824 --> 00:12:47,906
low hanging fruits to redesign your cloud architecture so

200
00:12:47,928 --> 00:12:51,810
that you can trigger some failover mechanisms and just observe locally about

201
00:12:51,880 --> 00:12:54,420
how your system starts responding to that.

202
00:12:55,350 --> 00:12:58,994
Now that we have done, I guess, enough talking. So let's

203
00:12:59,042 --> 00:13:02,534
move on and explore some cool demos. I'm going to showcase two

204
00:13:02,572 --> 00:13:05,762
examples. The first one is to demonstrate the feasibility

205
00:13:05,826 --> 00:13:09,414
of using cloud emulators like local stack for testing

206
00:13:09,462 --> 00:13:12,602
RDS failovers. And the second one is to actually

207
00:13:12,656 --> 00:13:16,314
show you how you can inject chaos experiments in your

208
00:13:16,352 --> 00:13:20,206
locally running applications. So in this

209
00:13:20,228 --> 00:13:24,046
sample we will locally run and test a

210
00:13:24,068 --> 00:13:28,110
local RDS database failover. During this failover process,

211
00:13:28,180 --> 00:13:32,142
the standby RDS instance is basically promoted as the new

212
00:13:32,196 --> 00:13:35,422
primary instance. Thus it allows you to resume

213
00:13:35,486 --> 00:13:38,574
your database activities in the shortest

214
00:13:38,622 --> 00:13:42,146
amount of time. Now if you are trying to set up this

215
00:13:42,168 --> 00:13:45,810
whole thing on the real AWS, it almost takes about more than an hour,

216
00:13:45,880 --> 00:13:48,994
which seems okay for a production setup,

217
00:13:49,122 --> 00:13:53,590
but for testing such a workflow it can often be time consuming.

218
00:13:53,930 --> 00:13:57,078
Now the best part about local stack is that you don't need to do a

219
00:13:57,084 --> 00:14:00,746
lot of manual configurations. Everything runs inside

220
00:14:00,848 --> 00:14:04,746
a single isolated docker container and it exposes a set

221
00:14:04,768 --> 00:14:08,266
of external network ports. So this means that if you're using any sort of

222
00:14:08,288 --> 00:14:12,438
an SDK, you can just hook them with the local stack by specifying

223
00:14:12,534 --> 00:14:15,774
which endpoint URL that they are running on

224
00:14:15,892 --> 00:14:19,918
so that you just don't have to send any of the API requests to

225
00:14:19,924 --> 00:14:23,774
the remote cloud provider. So let's check this out in action and see

226
00:14:23,892 --> 00:14:27,534
what we have got over here. So in this setup

227
00:14:27,582 --> 00:14:31,758
we have a Python script that basically uses boto three. So boto

228
00:14:31,774 --> 00:14:35,490
three is the AWS SDK for Python. And over here we are

229
00:14:35,560 --> 00:14:38,870
basically setting up some cluster ids and some regions.

230
00:14:39,290 --> 00:14:42,994
Just notice that we have defined multiple clusters over here, just showcasing

231
00:14:43,042 --> 00:14:46,406
like pretty much a global setup and we are

232
00:14:46,428 --> 00:14:50,170
creating a global cluster with a primary and a secondary

233
00:14:51,790 --> 00:14:55,626
we are creating a global cluster with primary and secondary clusters. And this

234
00:14:55,648 --> 00:14:58,758
basically simulates like a real world scenario where multiple

235
00:14:58,774 --> 00:15:02,750
database instances are managed across different regions.

236
00:15:03,330 --> 00:15:07,870
So in this case we have got run

237
00:15:07,940 --> 00:15:11,294
global cluster failover and this is basically a function

238
00:15:11,412 --> 00:15:14,766
that triggers a failover, switches the primary database with a

239
00:15:14,788 --> 00:15:17,842
secondary u one, and this is pretty much necessary for

240
00:15:17,896 --> 00:15:21,566
handling unplanned outages or basically just for maintenance.

241
00:15:21,678 --> 00:15:24,386
So in this case we are going to run this script pretty much on our

242
00:15:24,408 --> 00:15:28,258
local machine just to make sure that this setup pretty much works fine.

243
00:15:28,424 --> 00:15:31,954
So let me just go ahead and start local stack on my machine.

244
00:15:32,082 --> 00:15:35,734
So local stack is shipped as a binary or as just

245
00:15:35,772 --> 00:15:38,886
a pip packet. So if you're a python developer, you can just go ahead and

246
00:15:38,908 --> 00:15:41,706
just say like pip install local stack and that's going to set up the whole

247
00:15:41,728 --> 00:15:45,482
thing on your machine. And you can just say local stack start to

248
00:15:45,536 --> 00:15:49,190
start the local stack docker container on your local machine.

249
00:15:49,350 --> 00:15:52,794
This basically means that now you can send all of your AWS

250
00:15:52,842 --> 00:15:56,010
API requests to this running docker container.

251
00:15:56,090 --> 00:16:00,080
And over here we have specified this as localhost four, five, double six.

252
00:16:00,690 --> 00:16:04,366
Once we have done that, I guess I can just go ahead to

253
00:16:04,388 --> 00:16:08,338
my other terminal and I can just run this script right over here.

254
00:16:08,424 --> 00:16:11,634
My local stack container is ready. So as soon as we hit

255
00:16:11,672 --> 00:16:15,630
enter you can see that local stack starts creating the global cluster,

256
00:16:15,710 --> 00:16:18,982
the primary database cluster, and the rest of the things.

257
00:16:19,116 --> 00:16:22,566
You can immediately go back to the logs and

258
00:16:22,588 --> 00:16:26,198
you can see that local stack is now installing the postgres SQL, which is the

259
00:16:26,204 --> 00:16:30,038
database engine behind RDS and just making sure that everything

260
00:16:30,124 --> 00:16:33,210
is up to date and ready for this particular experiment.

261
00:16:33,550 --> 00:16:36,790
So now it's starting a global database cluster failover.

262
00:16:36,950 --> 00:16:39,578
And at the end of the decode you will notice that we have set up

263
00:16:39,584 --> 00:16:43,054
a lot of assertions to basically make sure that the failover part

264
00:16:43,092 --> 00:16:47,658
is successful. And as you can see, the test is done, all assertions have succeeded.

265
00:16:47,754 --> 00:16:51,518
And now we have a pretty good idea about how

266
00:16:51,684 --> 00:16:54,720
a cloud emulators like local stack can help you in this regard.

267
00:16:55,250 --> 00:16:59,074
In a real AWS environment, as I mentioned before, these operations might have

268
00:16:59,112 --> 00:17:03,154
taken over an hour, but using local stack you can just perform these

269
00:17:03,192 --> 00:17:07,154
kind of assertions in just less than a minute or two. And the best

270
00:17:07,192 --> 00:17:11,282
part about this is that we have not created any real cloud resources.

271
00:17:11,426 --> 00:17:15,240
Everything is happening on your local machine. And as soon as I shut down

272
00:17:15,690 --> 00:17:19,334
my local stack container, all of the resources that I have created before

273
00:17:19,372 --> 00:17:22,682
are gone. They are ephemeral in nature, so everything

274
00:17:22,736 --> 00:17:25,562
just vanishes with a poof. Cool.

275
00:17:25,616 --> 00:17:28,486
So that was a nice and steady experiment.

276
00:17:28,678 --> 00:17:31,280
Let's go ahead and let's see what else we have got.

277
00:17:32,130 --> 00:17:36,478
And yes, as I mentioned before, you can obviously use local stack with

278
00:17:36,644 --> 00:17:40,510
other services such as FIS for actually

279
00:17:40,580 --> 00:17:44,558
injecting fault into your application setup. Now FIS

280
00:17:44,654 --> 00:17:48,434
is a managed tool by AWS, and again, it comes

281
00:17:48,472 --> 00:17:51,710
with certain limitations that AWS FIS

282
00:17:51,790 --> 00:17:54,898
has. But with local stack you can obviously go beyond that and

283
00:17:54,904 --> 00:17:58,802
you can basically use a user interface or a CLI to basically inject

284
00:17:58,866 --> 00:18:02,578
chaos into your application setup. Now FIS

285
00:18:02,674 --> 00:18:06,566
has a lot of use cases. You can basically use it to strain an

286
00:18:06,588 --> 00:18:09,906
application. You can just define what kind of faults that you want to introduce.

287
00:18:10,018 --> 00:18:13,222
You can specify the resource to be mentioned as a target,

288
00:18:13,366 --> 00:18:17,046
and you can also specify like single time events, or you can induce some API

289
00:18:17,078 --> 00:18:20,378
errors and more of that. So with fis you

290
00:18:20,384 --> 00:18:24,094
can do a lot of these varying activities and you can just see

291
00:18:24,212 --> 00:18:28,346
how your cpu spike is happening or how memory usage is increasing.

292
00:18:28,458 --> 00:18:32,094
How does your system respond to this whole thing? With a consistent monitoring and

293
00:18:32,132 --> 00:18:35,614
more of that. So you can use fis with local stack,

294
00:18:35,662 --> 00:18:38,898
you can use it either using the traditional CLI experience

295
00:18:38,984 --> 00:18:42,386
that AWS itself provide, and just use local stack instead of

296
00:18:42,408 --> 00:18:46,174
that. Or else you can use a dashboard

297
00:18:46,222 --> 00:18:50,466
like this to basically control all of your chaos engineering experiments

298
00:18:50,578 --> 00:18:53,814
happening right on your local machine. So in this case,

299
00:18:53,852 --> 00:18:57,526
I'm going to use this to basically run a simple experiment on

300
00:18:57,548 --> 00:18:59,800
one of the sample applications that I have.

301
00:19:00,750 --> 00:19:03,974
So the application that I'm going to showcase to you is a serverless

302
00:19:04,022 --> 00:19:07,478
image resizer. It has like a bunch of lambda

303
00:19:07,494 --> 00:19:10,118
functions that allows you to upload an image,

304
00:19:10,214 --> 00:19:13,706
resize that image, and showcase that on a local web client.

305
00:19:13,818 --> 00:19:17,450
We have a simple website that runs inside an s three bucket.

306
00:19:17,530 --> 00:19:21,978
We have some SSM parameters, we have some SNS

307
00:19:22,074 --> 00:19:26,274
topics and more of these things. So let us actually run

308
00:19:26,312 --> 00:19:30,418
this whole setup on our local machine and showcase to you

309
00:19:30,504 --> 00:19:34,338
how you can inject fault into your local developer machine. So let

310
00:19:34,344 --> 00:19:38,146
me just quickly switch back to my vs code and we

311
00:19:38,168 --> 00:19:41,894
have the entire application cloned over here. You can grab this

312
00:19:41,932 --> 00:19:45,142
application using one of the GitHub URLs that I can share at the end,

313
00:19:45,276 --> 00:19:48,486
but let us go ahead and let us check out the application.

314
00:19:48,668 --> 00:19:51,978
But before that let me start local stack. So in this case I

315
00:19:51,984 --> 00:19:55,290
am starting my local stack instance. I'm specifying an extra

316
00:19:55,360 --> 00:19:58,854
configuration flag to basically allow the course origins,

317
00:19:58,982 --> 00:20:02,620
which I guess is pretty much of a pain for almost every developer out there.

318
00:20:02,930 --> 00:20:06,526
And it will start the local stack container, but as soon

319
00:20:06,548 --> 00:20:10,318
as it is started I can run this one script that will create

320
00:20:10,404 --> 00:20:13,838
all of the local AWS resources for me. Basically it will set up the

321
00:20:13,844 --> 00:20:18,466
whole application that I have and I

322
00:20:18,488 --> 00:20:21,698
don't need to set a lot of commands to basically run through the whole application

323
00:20:21,784 --> 00:20:26,286
deployment. So let me go ahead and let me run this deploy script

324
00:20:26,478 --> 00:20:30,134
and this will set up the application in just a few seconds which

325
00:20:30,172 --> 00:20:33,046
would otherwise have taken a few minutes if you are trying to do this whole

326
00:20:33,068 --> 00:20:36,646
thing on the real AWS. So you

327
00:20:36,668 --> 00:20:39,574
can go back to the local stack logs, you can just check out how local

328
00:20:39,612 --> 00:20:42,854
stack is creating the SM parameters, the lambda functions,

329
00:20:42,982 --> 00:20:45,900
the SNS topics and more of these things.

330
00:20:46,830 --> 00:20:50,222
And I guess this should be up and ready in just

331
00:20:50,276 --> 00:20:51,470
a few seconds.

332
00:20:55,670 --> 00:20:59,694
I guess it's taking some time over here because we are installing pillow

333
00:20:59,742 --> 00:21:03,220
because we need to set up the whole resize lambda function over there.

334
00:21:04,630 --> 00:21:09,958
But as you can see, once the whole application is deployed you

335
00:21:09,964 --> 00:21:13,458
will get a web client that we have. And over the web client

336
00:21:13,474 --> 00:21:16,742
you can basically upload the image and you can just click on one button

337
00:21:16,796 --> 00:21:20,314
and this will start the whole resize operation. So I guess the

338
00:21:20,352 --> 00:21:23,594
web assets are being specified over here. And now

339
00:21:23,632 --> 00:21:27,590
we have this particular web app running on this particular URL.

340
00:21:27,670 --> 00:21:31,118
So let me just switch right back to it and if I

341
00:21:31,124 --> 00:21:34,618
just go back to my other tab I can just hit refresh.

342
00:21:34,714 --> 00:21:39,514
And here we are. Here we have the locally running serverless

343
00:21:39,642 --> 00:21:43,406
image resizer application running pretty much on our local machine and it

344
00:21:43,428 --> 00:21:47,074
is just consuming all of the emulated AWS resources that we have

345
00:21:47,112 --> 00:21:50,578
created before. So I'm going to just click this button and I'm just going

346
00:21:50,584 --> 00:21:54,274
to list like a few function URLs that is necessary over here and just

347
00:21:54,312 --> 00:21:57,910
hit apply. And once it is done I can go ahead,

348
00:21:58,060 --> 00:22:02,806
click on this and basically specify one

349
00:22:02,828 --> 00:22:05,974
of the images that I have. In this case I'm just

350
00:22:06,012 --> 00:22:10,090
going to specify a pretty awesome picture of hagea Sophia.

351
00:22:10,510 --> 00:22:14,266
And once you click upload you can go back to the

352
00:22:14,368 --> 00:22:17,642
vs code right over here and you can actually see

353
00:22:17,696 --> 00:22:22,438
how local stack is pretty much executing like

354
00:22:22,464 --> 00:22:25,854
how local stack is pretty much executing lambdas on the back

355
00:22:25,892 --> 00:22:29,166
end. And you can see like the image has been resized and

356
00:22:29,188 --> 00:22:32,994
now it is ready pretty much. So let's go back to our

357
00:22:33,112 --> 00:22:34,180
vs code.

358
00:22:36,790 --> 00:22:39,614
Yes, here we are. Oops,

359
00:22:39,662 --> 00:22:43,346
sorry. So yes, I guess

360
00:22:43,368 --> 00:22:46,614
the image resize is pretty much successful. So you can just

361
00:22:46,652 --> 00:22:50,840
go and click refresh and this will automatically list

362
00:22:51,930 --> 00:22:55,666
the resized image right over here. So here we have the original image

363
00:22:55,698 --> 00:22:59,058
which was of these many bytes, and finally we have the resized image

364
00:22:59,074 --> 00:23:02,966
which is of these many bytes. So what if we start injecting

365
00:23:02,998 --> 00:23:06,954
some faults into our application setup? And I guess it's pretty easy with

366
00:23:06,992 --> 00:23:10,122
this whole dashboard that we have right here. So let me just

367
00:23:10,176 --> 00:23:12,940
hit refresh just to make sure that everything is ready.

368
00:23:13,310 --> 00:23:16,730
And as you can see, we have a few experiments that are pretty much specified.

369
00:23:16,810 --> 00:23:20,318
So this dashboard gives you like a set of predefined templates that

370
00:23:20,324 --> 00:23:23,406
you can use and run. So one of the first things that I want to

371
00:23:23,428 --> 00:23:27,486
showcase is how you can make a service unavailable on your local machine.

372
00:23:27,598 --> 00:23:30,626
So in this case I'm just going to mention like lambda as one of the

373
00:23:30,648 --> 00:23:34,098
things. So I can just hit lambda, I can specify the region that I want

374
00:23:34,104 --> 00:23:37,910
to run this experiment on and I can just click start experiment.

375
00:23:38,330 --> 00:23:41,862
As soon as the experiment is started, we can now go back over

376
00:23:41,916 --> 00:23:45,734
here, I can choose another file, which I guess would

377
00:23:45,772 --> 00:23:48,934
be one of the other images that I clicked during

378
00:23:48,972 --> 00:23:52,410
my recent trip to Turkey, and I can hit upload

379
00:23:52,910 --> 00:23:56,554
over here. Something will just go wrong. The image is not

380
00:23:56,592 --> 00:24:00,282
being listed, even though the original image is right over here. There is no mention

381
00:24:00,336 --> 00:24:03,726
of the resized image. If you want to see why this

382
00:24:03,748 --> 00:24:08,286
has particularly occurred, we can go back to

383
00:24:08,308 --> 00:24:10,400
the Vs code that we have right here.

384
00:24:11,090 --> 00:24:14,382
So I guess

385
00:24:14,436 --> 00:24:18,050
this is going to be it. So over here you can

386
00:24:18,120 --> 00:24:22,066
see that this whole lambda invoke operation has failed as

387
00:24:22,088 --> 00:24:25,618
per the fault injection simulator configuration. So now we

388
00:24:25,624 --> 00:24:29,122
can see that because of this configuration that we have already specified

389
00:24:29,186 --> 00:24:33,426
before, we have injected a fault into our application infrastructure,

390
00:24:33,458 --> 00:24:37,302
and this is not pretty much working out, which I think is

391
00:24:37,436 --> 00:24:40,890
very well expected. Let's go back and let's maybe

392
00:24:40,960 --> 00:24:44,522
stop this experiment and let's maybe start another one.

393
00:24:44,576 --> 00:24:48,074
So this time I want to make an AWS region just go

394
00:24:48,112 --> 00:24:51,686
unavailable just to simulate an entire regional outage.

395
00:24:51,798 --> 00:24:54,686
So in this case I can just specify us east one and I can start

396
00:24:54,708 --> 00:24:58,734
the experiment. And if I go back and I just hit

397
00:24:58,772 --> 00:25:02,238
a reload, because this entire website is being served from an s

398
00:25:02,244 --> 00:25:05,858
three bucket. So now you can actually go back to your Vs code again

399
00:25:05,944 --> 00:25:09,506
or basically to your local stack container logs, and you can see

400
00:25:09,528 --> 00:25:13,614
that there are exceptions happening. And this is because of the fault injection

401
00:25:13,662 --> 00:25:17,686
simulator configuration. So now we see this whole application is

402
00:25:17,708 --> 00:25:21,414
now set up, and now we can immediately inject fault into the setup and

403
00:25:21,452 --> 00:25:24,440
just see how our application starts responding to that.

404
00:25:25,210 --> 00:25:28,598
So this is one of the demos that I wanted to showcase.

405
00:25:28,774 --> 00:25:33,018
And yes, if you go back to your website,

406
00:25:33,104 --> 00:25:37,366
you can basically see that everything is happening because of this FIS configuration.

407
00:25:37,478 --> 00:25:40,634
So you can stop this experiment and I can just hit

408
00:25:40,672 --> 00:25:44,734
refresh and this whole application is now back and ready. But this was just

409
00:25:44,772 --> 00:25:48,666
like an initial preview. You can obviously introduce latency to every API

410
00:25:48,698 --> 00:25:52,574
call that you make on your local machine. You can inject some issues with Dynamodb,

411
00:25:52,622 --> 00:25:57,060
with kinesis, and basically you can use this experience as a way to test your

412
00:25:57,430 --> 00:26:01,166
local fis configurations and also to validate

413
00:26:01,278 --> 00:26:04,982
if your application infrastructure needs certain changes to accommodate these

414
00:26:05,036 --> 00:26:06,710
kind of interruptions.

415
00:26:08,410 --> 00:26:11,926
So now that we have came this far, let's just take a

416
00:26:11,948 --> 00:26:15,558
look about how we can further move ahead with such kind of

417
00:26:15,564 --> 00:26:19,398
a setup and how you can use open source cloud emulators like local stack

418
00:26:19,414 --> 00:26:22,922
in such a scenario. Now, the very first step that I always

419
00:26:22,976 --> 00:26:26,390
mention is that before implementing any sort of chaos

420
00:26:26,470 --> 00:26:30,718
testing suite, always try to establish a system's steady state.

421
00:26:30,804 --> 00:26:34,666
And this can be measured based upon overall throughput or error rates

422
00:26:34,698 --> 00:26:38,362
or latency. And this should always represent like an acceptable

423
00:26:38,426 --> 00:26:42,238
expected behavior of the system. Second, always look into

424
00:26:42,324 --> 00:26:45,582
creating a hypothesis that always aligns with the objective

425
00:26:45,646 --> 00:26:48,946
of your chaos testing setup, because they should

426
00:26:48,968 --> 00:26:52,306
match real world events and they should not cause deviation from

427
00:26:52,328 --> 00:26:55,060
the system's steady state. Finally,

428
00:26:55,430 --> 00:26:59,206
always try to design the experiments and put them in categories of

429
00:26:59,228 --> 00:27:02,982
knowns and unknowns. Just look at this table that I have mentioned over here

430
00:27:03,116 --> 00:27:06,326
and try to ideally target the knowns here because they

431
00:27:06,348 --> 00:27:09,446
are pretty much low hanging fruits and they should be easy to fix. But the

432
00:27:09,468 --> 00:27:13,386
ideal goal should be to discover and analyze whatever chaos your

433
00:27:13,408 --> 00:27:16,986
setup your system might end up encountering, and thus you

434
00:27:17,008 --> 00:27:19,840
might just end up venturing into some of the unknowns over here.

435
00:27:20,850 --> 00:27:24,266
Once you have the setup, you can always conduct the experiments.

436
00:27:24,298 --> 00:27:28,126
You can discover some potential failure scenarios within your

437
00:27:28,228 --> 00:27:31,374
application infrastructure and always try to

438
00:27:31,412 --> 00:27:34,758
assert in certain things like is your application failing

439
00:27:34,794 --> 00:27:38,418
for a small percentage of the production? What would happen if a certain

440
00:27:38,504 --> 00:27:41,874
availability zone or a region will suddenly go down? What will

441
00:27:41,912 --> 00:27:45,506
happen if there is a critical system performance, like if

442
00:27:45,528 --> 00:27:49,446
there is an extremely great amount of load? And how exactly does it affect the

443
00:27:49,468 --> 00:27:52,726
system performance? Now, solutions like local stack like

444
00:27:52,748 --> 00:27:55,986
k six or some other cloud native chaos engineering

445
00:27:56,018 --> 00:27:59,722
tools can certainly help you in that regard and assert in how

446
00:27:59,776 --> 00:28:04,330
well your infrastructure will treat such an interruption or such a chaos.

447
00:28:05,070 --> 00:28:08,586
And finally, yes, you can obviously test your

448
00:28:08,608 --> 00:28:12,474
cloud apps pretty much locally. You can always do away with staging if you

449
00:28:12,512 --> 00:28:15,742
want, but testing your cloud apps is definitely possible.

450
00:28:15,876 --> 00:28:19,406
And you can use cloud emulators not just to cut down on the cost and

451
00:28:19,428 --> 00:28:22,998
the time, but also to overall build a better developer

452
00:28:23,034 --> 00:28:26,546
and testing experience. Cloud emulators in

453
00:28:26,568 --> 00:28:30,018
the context of chaos engineering can always help you around with some of

454
00:28:30,024 --> 00:28:32,830
the low impact risks, like a missing failover,

455
00:28:32,910 --> 00:28:36,194
a missing handler, or things that might just fall under

456
00:28:36,232 --> 00:28:39,826
your radar during your usual unit testing or integration testing

457
00:28:39,858 --> 00:28:43,574
setup. And you can always learn from this experience. You can fix and iterate them

458
00:28:43,612 --> 00:28:47,046
quickly on your developer machine, and you don't have to wait and

459
00:28:47,068 --> 00:28:50,906
see your application blasting up in the production to actually do that.

460
00:28:51,088 --> 00:28:54,746
The second one is that you can always use these lessons to set up some

461
00:28:54,768 --> 00:28:58,422
sort of a playbook so that you can always validate these incidents,

462
00:28:58,486 --> 00:29:02,266
work upon them, and make sure that you have resilient solutions. And the best part

463
00:29:02,288 --> 00:29:06,106
is that you can actually integrate these failovers over on your CI pipelines.

464
00:29:06,218 --> 00:29:09,898
So this means that you can run these tests repeatedly on your CI pipeline,

465
00:29:09,914 --> 00:29:12,986
and you can make sure that none of the code or none of the infrastructure

466
00:29:13,018 --> 00:29:17,266
that you're adding to your application will negatively impact it in the long run.

467
00:29:17,448 --> 00:29:20,786
And finally, you will achieve the ability to handle some of the

468
00:29:20,808 --> 00:29:24,386
unplanned failovers or handlers that you might just end up

469
00:29:24,408 --> 00:29:28,446
missing. And you can certainly develop more resilient, better tested solutions

470
00:29:28,478 --> 00:29:31,794
at the end of the day. So this

471
00:29:31,832 --> 00:29:35,006
brings me to the final conclusion of this session.

472
00:29:35,118 --> 00:29:38,698
So that was all for today. Thank you folks, and I hope you enjoy the

473
00:29:38,784 --> 00:29:42,694
talk. And I do believe that you can look into shift

474
00:29:42,742 --> 00:29:45,994
left your chaos testing suite and enable your

475
00:29:46,032 --> 00:29:49,546
developers to leverage chaos as much as possible. Thanks to

476
00:29:49,568 --> 00:29:53,226
the Conf 42 team for having me today, and I'll see you

477
00:29:53,248 --> 00:29:53,720
the next time.

