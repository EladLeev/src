1
00:00:25,330 --> 00:00:29,030
My name is Charles Acol, and I work at Citibank.

2
00:00:29,610 --> 00:00:33,190
I manage the USPB

3
00:00:34,330 --> 00:00:37,622
SRE team. And our next

4
00:00:37,676 --> 00:00:40,966
phase is transforming our l two into

5
00:00:41,068 --> 00:00:44,434
production support, into an SRE cytrology

6
00:00:44,482 --> 00:00:48,582
engineering team. And as part of that, chaos engineering is a very

7
00:00:48,636 --> 00:00:52,074
core principle that we like to adopt.

8
00:00:52,122 --> 00:00:55,946
So chaos engineering really is a discipline of experimenting

9
00:00:56,058 --> 00:00:59,566
on a system in order to build confidence in the

10
00:00:59,588 --> 00:01:03,918
system's capability to withstand turbulent conditions in production.

11
00:01:04,014 --> 00:01:07,854
And really, this is, if you google that concept,

12
00:01:07,902 --> 00:01:11,662
it exists under principlesofchaos.org.

13
00:01:11,806 --> 00:01:13,890
But to give some background,

14
00:01:15,190 --> 00:01:18,454
chaos engineering was pioneered at Netflix roughly around

15
00:01:18,492 --> 00:01:21,734
2010, when they migrated from their

16
00:01:21,772 --> 00:01:25,362
legacy hardware to AWS, and they started inducing

17
00:01:25,426 --> 00:01:29,642
artificial flavor. Or at least this is one avenue of

18
00:01:29,696 --> 00:01:33,706
where we see the initial views of it.

19
00:01:33,808 --> 00:01:37,450
And then fast forward to today, 2023. I mean, it's a common

20
00:01:37,520 --> 00:01:40,958
practice in the industry across tech

21
00:01:41,044 --> 00:01:44,926
giants like Google, LinkedIn, also the

22
00:01:44,948 --> 00:01:49,134
banking industry across. And you

23
00:01:49,172 --> 00:01:53,330
have Colton Andrews from Netflix and Matthew from

24
00:01:53,480 --> 00:01:56,834
Salesforce. They kind of merged forces and they

25
00:01:56,872 --> 00:02:00,034
started Gremlin. Gremlin is a tool we also use,

26
00:02:00,072 --> 00:02:03,810
which I'll briefly touch on. And then today also

27
00:02:03,880 --> 00:02:07,434
there is component of Lightspeed,

28
00:02:07,502 --> 00:02:11,350
which is harness. That's also another very nice

29
00:02:11,420 --> 00:02:14,614
tool that can be used for chaos engineering. Of course,

30
00:02:14,652 --> 00:02:17,726
there's other tools in the industry, there's other different flavors,

31
00:02:17,778 --> 00:02:20,954
but we also have in house tools. But in

32
00:02:20,992 --> 00:02:24,586
general, that's the idea behind it. So the

33
00:02:24,608 --> 00:02:27,910
benefits of chaos engineering is to promote innovation,

34
00:02:28,070 --> 00:02:31,674
elevate partnership, improve incident response,

35
00:02:31,722 --> 00:02:35,050
generate knowledge, and really increase the reliability

36
00:02:35,130 --> 00:02:39,130
and the resiliency to kind of measure the ecosystem

37
00:02:39,290 --> 00:02:41,520
from what does that mean to the customer?

38
00:02:41,970 --> 00:02:46,718
So different flavors that we do. We do a production

39
00:02:46,894 --> 00:02:50,194
game day. We do it once a month. As part of that

40
00:02:50,232 --> 00:02:53,726
exercise, we've written tons of ansible playbooks

41
00:02:53,838 --> 00:02:57,362
where through an in house tool, we do one touch

42
00:02:57,416 --> 00:03:00,902
failover, and then we run it through the entire day out of a single data

43
00:03:00,956 --> 00:03:04,086
center. So we're really doing a

44
00:03:04,108 --> 00:03:07,286
production stress test of the ecosystem to see what

45
00:03:07,308 --> 00:03:11,354
is the threshold that it can tolerate. And we

46
00:03:11,392 --> 00:03:15,130
have tons of applications that we do that, too. And then

47
00:03:15,280 --> 00:03:19,654
we get the results, we measure it, we have automated measurement,

48
00:03:19,702 --> 00:03:23,294
and then now we're working into an automated normalization of it as

49
00:03:23,332 --> 00:03:26,782
well. Another flavor that we do in production is called

50
00:03:26,836 --> 00:03:31,146
wheels of misfortune. Wheels of misfortune is a very fun exercise.

51
00:03:31,258 --> 00:03:35,314
And where what we do is we

52
00:03:35,352 --> 00:03:38,590
gather teams across sectors, from incident management,

53
00:03:38,750 --> 00:03:42,302
problem management products, sres, performance,

54
00:03:42,366 --> 00:03:46,046
and then we usually meet every couple of weeks for

55
00:03:46,088 --> 00:03:49,910
30 minutes. We kind of pick topics, usually major

56
00:03:49,980 --> 00:03:53,894
outages, or we can go all the way to a cybersecurity. And then

57
00:03:53,932 --> 00:03:58,054
what happens after that? We conduct one exercise

58
00:03:58,102 --> 00:04:02,106
every quarter and then we record it and it

59
00:04:02,128 --> 00:04:05,754
helps build the stress level gets elevated. When you have

60
00:04:05,792 --> 00:04:09,580
outages, we have a lot of takeaways from

61
00:04:11,170 --> 00:04:14,714
meantime to recover. Do we have the right architecture

62
00:04:14,762 --> 00:04:18,922
diagram? Do we have the right factoring? Any opportunities

63
00:04:18,986 --> 00:04:22,320
for improvement? So it's kind of like a role play,

64
00:04:22,690 --> 00:04:26,798
and then you would have volunteers, non playing characters.

65
00:04:26,974 --> 00:04:30,434
So that's a fun exercise. And then we record it and measure it

66
00:04:30,472 --> 00:04:34,514
and kind of come out with certain results behind it to see what

67
00:04:34,552 --> 00:04:38,706
improvements can be done. We also do chaos engineering

68
00:04:38,738 --> 00:04:41,586
in the lower environment. So we do it in Gremlin.

69
00:04:41,698 --> 00:04:45,602
Gremlin is one of the industry standard platforms

70
00:04:45,746 --> 00:04:49,542
which is available in SAS. It allows to inject failures

71
00:04:49,606 --> 00:04:54,390
at various layers of the system. It can assess robustness

72
00:04:54,470 --> 00:04:57,286
using one of different attacks.

73
00:04:57,398 --> 00:05:02,202
Now you can do Gremlin on legacy physical

74
00:05:02,266 --> 00:05:06,206
jvms on Linux servers. And then you kind of

75
00:05:06,308 --> 00:05:10,320
measured. So let's say you have

76
00:05:11,330 --> 00:05:14,770
100 transactions per second within

77
00:05:14,840 --> 00:05:18,930
a 30 minutes time frame. Then at the ten minute margin

78
00:05:19,430 --> 00:05:23,266
you're measuring the average response time. Then you invoke a

79
00:05:23,288 --> 00:05:26,674
high cpu attack, and then you kind of observe, is there

80
00:05:26,712 --> 00:05:30,054
any impact to the I o, so on and so forth. So we do that

81
00:05:30,092 --> 00:05:33,426
also on a quarterly basis. And now what we're doing is we're

82
00:05:33,458 --> 00:05:36,806
integrating Gremlin with Openshift, where you can

83
00:05:36,828 --> 00:05:40,282
kind of measure the pods and see the different

84
00:05:40,336 --> 00:05:43,914
types of attacks that can be done. The other tool

85
00:05:43,952 --> 00:05:47,818
that we use as well is chaos monkey. Chaos monkey is

86
00:05:47,904 --> 00:05:51,690
one of the original tools that was created by Netflix,

87
00:05:51,850 --> 00:05:55,146
and it's one of my favorite tools

88
00:05:55,178 --> 00:05:59,146
as well. It stimulates failures by randomly

89
00:05:59,178 --> 00:06:03,186
terminating instances. So you can stop one

90
00:06:03,208 --> 00:06:06,834
of the namespace instances in Openshift for

91
00:06:06,872 --> 00:06:10,146
example, or PCF, Google Cloud, foundry, dell or

92
00:06:10,168 --> 00:06:13,662
AWS, or whatever ecosystem you're in. And then you measure

93
00:06:13,726 --> 00:06:17,766
what happened to the other layers or what was

94
00:06:17,868 --> 00:06:21,350
the customer experience. We do have another

95
00:06:21,420 --> 00:06:25,174
tool which is called Ape army, that's an in house tool where we

96
00:06:25,212 --> 00:06:28,854
execute different types of costs to it. And then you can do basic

97
00:06:28,902 --> 00:06:32,646
manual tests where you can manually manipulate

98
00:06:32,678 --> 00:06:35,990
the environment. You can change the yaml file.

99
00:06:36,070 --> 00:06:40,206
If you have services that are Java based, you can change the configuration or

100
00:06:40,228 --> 00:06:43,678
the parameter to disable specific

101
00:06:43,764 --> 00:06:47,658
components, or do a restart and measure the behavior.

102
00:06:47,834 --> 00:06:51,086
So those are different types of attacks that can

103
00:06:51,108 --> 00:06:55,182
be done. You can do like resource

104
00:06:55,246 --> 00:06:58,270
attack, which has high cpu, high memory,

105
00:06:58,350 --> 00:07:02,466
high I o load. There's also some that

106
00:07:02,488 --> 00:07:05,670
are like state attacks where you can shut down process

107
00:07:05,740 --> 00:07:09,922
skill or do time travel. You can do network

108
00:07:09,986 --> 00:07:13,654
attacks, latency and packet loss, or a

109
00:07:13,692 --> 00:07:18,146
black hole network connectivity. One of the other tests

110
00:07:18,178 --> 00:07:21,794
that we do is not in production.

111
00:07:21,922 --> 00:07:25,542
We kind of shut down one of the core services,

112
00:07:25,676 --> 00:07:30,202
whether it's a major database or a core mainframe component,

113
00:07:30,386 --> 00:07:34,430
and we start measure. What does that mean to the end user?

114
00:07:35,010 --> 00:07:38,174
Did they get the right message? Was their

115
00:07:38,212 --> 00:07:41,630
data available for them? So there's different flavors around

116
00:07:41,700 --> 00:07:44,894
it. And if you have any questions,

117
00:07:45,092 --> 00:07:48,462
please let me know. But thank you for listening in

118
00:07:48,596 --> 00:07:50,250
and enjoy the conference.

