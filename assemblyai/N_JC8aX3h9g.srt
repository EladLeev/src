1
00:00:00,250 --> 00:00:01,630
Are youll an SRE,

2
00:00:03,570 --> 00:00:08,042
a developer, a quality engineer

3
00:00:08,106 --> 00:00:11,406
who wants to tackle the challenge of improving reliability in

4
00:00:11,428 --> 00:00:15,294
your DevOps? You can enable your DevOps for reliability with

5
00:00:15,332 --> 00:00:18,654
chaos native. Create your free account at

6
00:00:18,692 --> 00:01:17,094
Chaos native. Litmus Cloud hello,

7
00:01:17,212 --> 00:01:21,426
my name is Rafael and my talk is titled five levels

8
00:01:21,458 --> 00:01:25,638
of high availability from multi instance to hybrid cloud.

9
00:01:25,804 --> 00:01:30,122
But first a few words about myself. I am the

10
00:01:30,176 --> 00:01:33,738
tech lead of the cloud native team at Hazelcast before

11
00:01:33,824 --> 00:01:37,126
I worked at Google and CERN. I'm also can author

12
00:01:37,158 --> 00:01:40,922
of the book Continuous Delivery with Docker and Jenkins and

13
00:01:40,976 --> 00:01:43,834
from time to time I do conference speaking and trainings,

14
00:01:43,962 --> 00:01:47,290
but on a daily basis. I'm an engineer, I'm a developer

15
00:01:47,370 --> 00:01:50,538
and I live in Krakow in Poland.

16
00:01:50,714 --> 00:01:55,074
A few words about Hazelcast Hazelcast is a distributed company.

17
00:01:55,192 --> 00:01:58,306
We're always distributed, always working remotely, and we

18
00:01:58,328 --> 00:02:01,714
produce distributed software. Our software is

19
00:02:01,752 --> 00:02:04,740
open source. What we do is,

20
00:02:05,290 --> 00:02:07,190
you may know Hazelcast,

21
00:02:09,210 --> 00:02:12,754
it's an in memory data store and stream processing

22
00:02:12,802 --> 00:02:16,338
platform. So people use it for machines,

23
00:02:16,434 --> 00:02:20,070
for processing everything where latency matters.

24
00:02:20,150 --> 00:02:24,474
So please check it out. Our agenda for today for

25
00:02:24,512 --> 00:02:28,586
this talk is pretty simple. So there will be a short introduction about

26
00:02:28,768 --> 00:02:32,686
high availability levels in general, about high availability in general.

27
00:02:32,868 --> 00:02:36,938
And then we will walk through all levels

28
00:02:37,034 --> 00:02:40,346
that you can use in your system while deploying,

29
00:02:40,378 --> 00:02:44,002
while designing your system. And while I'll be talking

30
00:02:44,056 --> 00:02:47,886
about these levels, I will always focus on the solution,

31
00:02:47,998 --> 00:02:51,506
but also on the trade off. So if

32
00:02:51,528 --> 00:02:55,090
you design your system to be available in let's say

33
00:02:55,160 --> 00:02:58,774
multiregion, what does it mean to you? What will you will achieve, but also

34
00:02:58,812 --> 00:03:02,150
what you will lose. So I will focus on the trade offs.

35
00:03:03,290 --> 00:03:06,518
So let's start with the introduction. So currently,

36
00:03:06,684 --> 00:03:10,394
any system, basically any system you want you build currently

37
00:03:10,512 --> 00:03:14,266
is based on services. So in

38
00:03:14,288 --> 00:03:17,946
the center, I mean everything now is a service. Sometimes we

39
00:03:17,968 --> 00:03:21,326
call it a microservice, sometimes we call it

40
00:03:21,348 --> 00:03:24,910
microservice even though it's huge. But it doesn't really matter.

41
00:03:24,980 --> 00:03:29,006
It doesn't matter if it's a microservice macro service

42
00:03:29,108 --> 00:03:31,200
or even a lambda function.

43
00:03:31,890 --> 00:03:37,154
What matters is that this part of the system with

44
00:03:37,192 --> 00:03:42,850
which you communicate is usually stateless.

45
00:03:43,190 --> 00:03:46,902
And stateless mean we can replicate it,

46
00:03:46,956 --> 00:03:51,074
we can deploy it wherever we want. So stateless

47
00:03:51,122 --> 00:03:54,726
thing contains the business logic and it's usually can easy part of

48
00:03:54,748 --> 00:03:58,380
your system. So just imagine for a moment that

49
00:03:59,150 --> 00:04:02,954
our system is just a bunch of stateless services,

50
00:04:03,072 --> 00:04:06,474
like a calculator service that can add two

51
00:04:06,512 --> 00:04:11,706
numbers. So then that

52
00:04:11,728 --> 00:04:15,806
is all your system. Then it's relatively simple, you can deploy it anywhere you

53
00:04:15,828 --> 00:04:19,614
want, it will work the same on my machine, on my laptop it will work

54
00:04:19,652 --> 00:04:23,780
the same on AWS. If you deploy it in

55
00:04:24,150 --> 00:04:26,994
1 million replicas, it will still work the same.

56
00:04:27,192 --> 00:04:30,978
So usually the stateless part,

57
00:04:31,064 --> 00:04:34,660
the service is not a problem, but that is like

58
00:04:35,850 --> 00:04:40,038
usually the stateless service is connected to a bunch of the stateful things

59
00:04:40,204 --> 00:04:43,906
like a data store or a queue

60
00:04:44,098 --> 00:04:48,102
or it can be some other services, internal or external. So something

61
00:04:48,156 --> 00:04:51,930
that has state from our service perspective

62
00:04:52,670 --> 00:04:56,282
and this stateless, stateful things are

63
00:04:56,336 --> 00:04:59,210
the problem in our system. So the data,

64
00:04:59,280 --> 00:05:02,142
we can say that the data is the problem. So if there is no data,

65
00:05:02,196 --> 00:05:05,150
there is no problem in terms of high availability.

66
00:05:05,490 --> 00:05:07,360
So with this in mind,

67
00:05:09,090 --> 00:05:12,574
I will always focus on the data, but I will always give you

68
00:05:12,772 --> 00:05:16,514
the whole picture as well. So with this in mind we can start

69
00:05:16,552 --> 00:05:20,210
from the first high availability level, which is single

70
00:05:20,280 --> 00:05:24,210
instance. Single instance means no high availability at all,

71
00:05:24,280 --> 00:05:27,702
just look at the diagram. So single instance is kind of. If you

72
00:05:27,756 --> 00:05:31,286
deploy your database, can application everything on your laptop that

73
00:05:31,308 --> 00:05:34,886
is a single instance. Now why would

74
00:05:34,908 --> 00:05:40,986
you ever do it? I mean it's not practical but there

75
00:05:41,008 --> 00:05:44,314
are multiple things that becomes very easy when

76
00:05:44,352 --> 00:05:46,490
you deploy everything on a single instance.

77
00:05:47,230 --> 00:05:51,118
One thing is the latency. So I did a latency experiment in

78
00:05:51,204 --> 00:05:55,406
my scenario I deployed an application

79
00:05:55,508 --> 00:05:59,054
with embedded hazelcast. Hazelcast is just a data store,

80
00:05:59,092 --> 00:06:03,134
so it doesn't matter, it's hazelcast, it's just to show you what

81
00:06:03,172 --> 00:06:06,418
happens with the latency if you deploy everything on one machine so you can

82
00:06:06,424 --> 00:06:10,210
say like a service and a database. For us, database is hazelcast

83
00:06:10,710 --> 00:06:15,414
and I measured the latency of the retry write so

84
00:06:15,452 --> 00:06:19,430
it was 80 millisecond per 10,000 of entries.

85
00:06:20,330 --> 00:06:23,574
It doesn't tell us much, you can already see it's a

86
00:06:23,612 --> 00:06:27,234
very low latency but we'll

87
00:06:27,282 --> 00:06:30,874
compare it later to what happens with the latency as we

88
00:06:30,912 --> 00:06:34,330
go farther with our high availability levels.

89
00:06:34,990 --> 00:06:37,850
So if you deploy everything on a single instance,

90
00:06:38,590 --> 00:06:41,946
what it means to you, you have no high

91
00:06:41,968 --> 00:06:45,038
availability or no scalability but you

92
00:06:45,044 --> 00:06:48,478
have very low latency and you always have a data consistency because you

93
00:06:48,484 --> 00:06:52,442
cannot have consistent data if you just have one instance of your

94
00:06:52,516 --> 00:06:55,986
data store. And there are some

95
00:06:56,008 --> 00:06:59,410
valid scenarios for such a deployed even though it may seem

96
00:06:59,910 --> 00:07:03,934
crazy but imagine like let's say edempotent

97
00:07:03,982 --> 00:07:07,510
both job that you can always repeat there's no problem

98
00:07:07,580 --> 00:07:11,954
running this on a single instance. So there might be some cases

99
00:07:12,002 --> 00:07:16,086
where you deployed your system in that way, but okay,

100
00:07:16,108 --> 00:07:20,374
you didn't come here to listen to some development

101
00:07:20,422 --> 00:07:24,250
environment. So let's go straight ahead to multiinstance.

102
00:07:24,910 --> 00:07:28,474
So level one, multi instance. So multi instance means

103
00:07:28,512 --> 00:07:32,334
that if one machines is down, the system is

104
00:07:32,372 --> 00:07:36,142
still available. How can it look like, how will be the

105
00:07:36,196 --> 00:07:39,840
classic diagram for such a system?

106
00:07:40,930 --> 00:07:44,798
So a request goes to our system, it will usually go to a load balancer,

107
00:07:44,894 --> 00:07:48,798
which will forward the traffic to the application service replicas

108
00:07:48,894 --> 00:07:52,930
which are deployed on at least two machines.

109
00:07:53,510 --> 00:07:58,802
And this stateless part of the system uses

110
00:07:58,866 --> 00:08:02,294
some stateful part of the system. So in

111
00:08:02,332 --> 00:08:05,622
our case, let's look at some data store

112
00:08:05,756 --> 00:08:09,418
which is always also deployed on at least

113
00:08:09,504 --> 00:08:12,650
two instances on at least two machines.

114
00:08:13,230 --> 00:08:16,826
If you look at this diagram, there is only one thing that is single on

115
00:08:16,848 --> 00:08:20,602
this diagram and it's load balancer. However, load balancing

116
00:08:20,666 --> 00:08:24,334
is completely separate topic and it's somehow as

117
00:08:24,372 --> 00:08:26,670
a DevOps Persona.

118
00:08:27,250 --> 00:08:30,880
Usually this problem is kind of solved for you because

119
00:08:31,250 --> 00:08:34,366
nowadays these load balancers are super reliable and youll can

120
00:08:34,468 --> 00:08:37,538
just, with a few clicks you can have it done. So we will

121
00:08:37,544 --> 00:08:40,450
not focus on a load balancer so much.

122
00:08:40,600 --> 00:08:44,322
We'll also not focus on the stateless part because we already

123
00:08:44,376 --> 00:08:48,146
said that that is the easy part of our system. So we'll

124
00:08:48,178 --> 00:08:51,954
focus on the database. So in our scenario,

125
00:08:52,002 --> 00:08:57,694
the assumption here we have two database

126
00:08:57,762 --> 00:09:01,398
instances which are connected with a fast and reliable network.

127
00:09:01,494 --> 00:09:05,370
For example, you could start two EC, two instances on AWS.

128
00:09:05,710 --> 00:09:07,820
That is our scenario right now.

129
00:09:09,630 --> 00:09:13,086
So we have two data stores, two databases, and we would

130
00:09:13,108 --> 00:09:16,750
like to use them. So the problem,

131
00:09:16,900 --> 00:09:20,430
what we are trying to solve right now is called data

132
00:09:20,500 --> 00:09:23,954
replication. And at this point, let me

133
00:09:23,992 --> 00:09:27,474
give you a short history and a

134
00:09:27,512 --> 00:09:32,098
very simplified story,

135
00:09:32,184 --> 00:09:35,560
how this data application was approached and used.

136
00:09:36,570 --> 00:09:39,910
So the SQL databases,

137
00:09:43,130 --> 00:09:45,910
not so long time ago, it was the mainstream.

138
00:09:46,730 --> 00:09:49,334
Some may argue that it's still the mainstream,

139
00:09:49,462 --> 00:09:53,482
but with SQL databases, how this problem

140
00:09:53,536 --> 00:09:57,194
was usually approached was that we had

141
00:09:57,232 --> 00:10:00,506
like so called active passive or master slave

142
00:10:00,538 --> 00:10:04,878
replication, meaning that all

143
00:10:04,964 --> 00:10:10,570
application services, they use only one database

144
00:10:10,650 --> 00:10:14,346
instance, at least for the writes.

145
00:10:14,458 --> 00:10:16,990
So you write only to zones replica.

146
00:10:17,410 --> 00:10:20,906
And if anything wrong happens, then we just do a failover

147
00:10:21,018 --> 00:10:25,190
to the second replica. Because all the

148
00:10:25,380 --> 00:10:29,474
it, everything we stored in a machine

149
00:10:29,522 --> 00:10:32,966
one is replicated to machine two. If there is a crash of

150
00:10:32,988 --> 00:10:36,790
machine one, we do a failover so we don't lose any data and

151
00:10:36,860 --> 00:10:40,170
our machine two becomes the active replica.

152
00:10:41,070 --> 00:10:44,246
And that is how most replication looks like nowadays.

153
00:10:44,278 --> 00:10:47,260
You can combine it with sharding, no problem with that.

154
00:10:48,430 --> 00:10:52,206
Now with the movement of NoSQL and people thought like we

155
00:10:52,228 --> 00:10:56,750
need something better, this master slave replication.

156
00:10:57,250 --> 00:11:00,334
So it's maybe too difficult for

157
00:11:00,372 --> 00:11:04,674
developers and sometimes not that good. So most,

158
00:11:04,712 --> 00:11:06,530
like NoSQL databases,

159
00:11:08,790 --> 00:11:12,402
kind of abstract this replication way. They do

160
00:11:12,456 --> 00:11:15,830
so called clustering, which means that your application,

161
00:11:15,900 --> 00:11:19,846
they use all the instances of database, so they connect to each of

162
00:11:19,868 --> 00:11:23,206
the instance of the database, and each of the instance they

163
00:11:23,308 --> 00:11:27,014
stores the

164
00:11:27,212 --> 00:11:30,806
primary partition of the data and also the backups

165
00:11:30,838 --> 00:11:34,842
of some other partitions. We always

166
00:11:34,896 --> 00:11:38,026
store the backup of some partitions. So if one machine is down, no problem with

167
00:11:38,048 --> 00:11:41,326
that, we migrate the data and your application,

168
00:11:41,428 --> 00:11:44,974
they can still use you don't lose any data to go

169
00:11:45,012 --> 00:11:48,558
a little deeper into. And let's look at specific example,

170
00:11:48,644 --> 00:11:52,206
because actually each database solved this

171
00:11:52,228 --> 00:11:55,778
problem a little different. So it's good to focus on one

172
00:11:55,864 --> 00:11:59,698
example. So let's focus on hazelcast, how it looks like if

173
00:11:59,704 --> 00:12:03,570
we go a little deeper. So hazelcast is a key value data store.

174
00:12:03,720 --> 00:12:08,982
So we partition all the data by keys, and now each

175
00:12:09,036 --> 00:12:13,110
member stores some partitions of the data

176
00:12:13,260 --> 00:12:16,694
and backups of some other partitions. So the

177
00:12:16,732 --> 00:12:20,298
rule here is that the backup of

178
00:12:20,304 --> 00:12:24,426
the partition is always stored on another member than the partition itself.

179
00:12:24,608 --> 00:12:27,578
So for example, partition one is stored on member one,

180
00:12:27,664 --> 00:12:31,066
so its backup backup of the partition one will be stored on

181
00:12:31,088 --> 00:12:35,230
member two or three, but never on the member one. In our case, it's stored

182
00:12:35,570 --> 00:12:40,346
on the member two. Now, in any of the member crashes,

183
00:12:40,458 --> 00:12:45,060
at any point of time, you don't lose any data because

184
00:12:45,590 --> 00:12:49,874
the backups are promoted to the main partition and everything

185
00:12:49,992 --> 00:12:53,406
works. So from the client perspective,

186
00:12:53,438 --> 00:12:56,934
from application perspective, you may not even notice that,

187
00:12:57,132 --> 00:13:00,550
okay, we have like this. So this is more or less how this

188
00:13:00,620 --> 00:13:03,880
nosql tried to address this replication problem.

189
00:13:04,810 --> 00:13:09,202
But now the question is, should these backups,

190
00:13:09,266 --> 00:13:13,002
no matter if they are clustered or if they are really

191
00:13:13,056 --> 00:13:16,714
master slave, should they be done synchronously or

192
00:13:16,752 --> 00:13:20,458
asynchronously? In other words, should we favor

193
00:13:20,544 --> 00:13:23,966
consistency, so we do a backup synchronously so we are

194
00:13:23,988 --> 00:13:27,674
sure about the data? Or should we favor latency

195
00:13:27,722 --> 00:13:31,054
and do it asynchronously? And before I answer this question,

196
00:13:31,092 --> 00:13:35,694
I did another latency experiment, and this time I deployed hazelcast

197
00:13:35,742 --> 00:13:39,490
as a database on two machines and

198
00:13:39,640 --> 00:13:43,634
features the latency of

199
00:13:43,672 --> 00:13:47,014
read write again. And as you expect, it's way

200
00:13:47,052 --> 00:13:50,422
worse than a single instance because you cannot beat like one

201
00:13:50,476 --> 00:13:54,166
machine communication, so they will not

202
00:13:54,188 --> 00:13:57,986
beat it. Here you need to have like a network involved.

203
00:13:58,178 --> 00:14:01,594
But if you look at the number, it still doesn't look that bad. It's still

204
00:14:01,632 --> 00:14:05,878
under one millisecond per entry, which is usually acceptable.

205
00:14:06,054 --> 00:14:09,366
And this is with synchronous backups, so we are sure that you will not lose

206
00:14:09,398 --> 00:14:12,766
the data. So this is pretty good.

207
00:14:12,948 --> 00:14:17,002
That is why in most cases in NoSQL databases

208
00:14:17,066 --> 00:14:21,310
like by default, you will see that these backups are done synchronously,

209
00:14:21,810 --> 00:14:25,650
but you can obviously change it. Is it the same

210
00:14:25,800 --> 00:14:30,722
for this SQL and this more

211
00:14:30,776 --> 00:14:34,514
complex databases? Not necessarily. For example

212
00:14:34,632 --> 00:14:37,670
mysql, by default they do it asynchronously.

213
00:14:39,770 --> 00:14:43,890
So you favor latency here because otherwise the latency

214
00:14:43,970 --> 00:14:47,570
would suffer. So a short summary,

215
00:14:47,730 --> 00:14:51,114
what has been level one for you so you can

216
00:14:51,152 --> 00:14:54,538
achieve data consistency because you

217
00:14:54,544 --> 00:14:58,330
can do synchronous backup, it's still an acceptable latency.

218
00:14:59,230 --> 00:15:03,914
Most tools support it, so it's

219
00:15:03,962 --> 00:15:07,182
easy to set up. Most cloud specific toolkits support

220
00:15:07,236 --> 00:15:10,590
it. And even if you've done on premises like

221
00:15:10,740 --> 00:15:14,494
Hazelcut or any other tool, it's usually very simple

222
00:15:14,532 --> 00:15:17,794
to set it up from the downsides. If you would like to

223
00:15:17,832 --> 00:15:21,282
access this, you are still inside one region. So if you youll like to access

224
00:15:21,336 --> 00:15:25,166
the data from another region, then you will have high latency accessing from

225
00:15:25,208 --> 00:15:28,614
another regions. Okay,

226
00:15:28,652 --> 00:15:31,350
let's move forward and from multizone,

227
00:15:31,850 --> 00:15:35,826
from multi instance, one step up is multizone.

228
00:15:36,018 --> 00:15:39,190
Multizone means that if one availability

229
00:15:39,270 --> 00:15:42,300
zone is down, the system is still available.

230
00:15:42,990 --> 00:15:45,450
How does it look like on a diagram?

231
00:15:46,110 --> 00:15:49,866
So here is a diagram for multizone. So again, request goes

232
00:15:49,888 --> 00:15:53,918
to cloud balancer, load balancers forwards to the traffic, to the application services,

233
00:15:54,084 --> 00:15:58,142
they use databases and now the application services,

234
00:15:58,276 --> 00:16:03,850
they need to be deployed in at least two availability

235
00:16:03,930 --> 00:16:07,314
zones. And the same with the databases, they need to be deployed in

236
00:16:07,352 --> 00:16:10,946
at least two availability zones. So if you look at

237
00:16:10,968 --> 00:16:15,330
this diagram, it's pretty similar to what we've seen with multi instance.

238
00:16:15,930 --> 00:16:19,880
That is why the first question you might ask is is it any different

239
00:16:20,650 --> 00:16:25,106
than deploying to multi

240
00:16:25,138 --> 00:16:28,566
instance multizone? Does it make any difference or just do the

241
00:16:28,588 --> 00:16:32,410
same? I just change my configuration file and that's it.

242
00:16:32,560 --> 00:16:36,860
So I would say it's not much different, but there is some difference.

243
00:16:37,630 --> 00:16:40,640
So let me first explain why it's not different.

244
00:16:41,010 --> 00:16:44,314
So I did another latency experiment and this time I deployed

245
00:16:44,362 --> 00:16:48,074
four hazelcast instances, two in each availability zones,

246
00:16:48,122 --> 00:16:51,802
and I measured the latency. And obviously it's

247
00:16:51,866 --> 00:16:55,026
worse than multiinstance, but it's not way worse. It's not

248
00:16:55,048 --> 00:16:58,274
even twice worse and it's still under one millisecond per

249
00:16:58,312 --> 00:17:02,482
entry. So that is actually usually good

250
00:17:02,536 --> 00:17:06,470
enough. That is why you can just

251
00:17:06,540 --> 00:17:09,846
move your deployed to multizone and

252
00:17:09,868 --> 00:17:13,526
do it with the same. But I also mentioned that there is a

253
00:17:13,548 --> 00:17:17,630
difference, there is some difference between multiinstance and multizone.

254
00:17:17,730 --> 00:17:19,340
And to understand the difference,

255
00:17:20,430 --> 00:17:23,626
let's focus on one example. So this is

256
00:17:23,648 --> 00:17:27,318
exactly the scenario I used for experiment. I deployed

257
00:17:27,414 --> 00:17:31,658
four hazelcast instances, two instances in each availability zone.

258
00:17:31,834 --> 00:17:35,774
The assumption here are that the

259
00:17:35,812 --> 00:17:39,614
network between availability zone is fast and reliable because

260
00:17:39,732 --> 00:17:42,080
that's how cloud providers work.

261
00:17:42,850 --> 00:17:46,382
And so if you would like to reproduce such a scenario,

262
00:17:46,446 --> 00:17:49,490
you just deploy four ec, two instances

263
00:17:50,390 --> 00:17:53,906
in one availability zone to another availability zone. And that

264
00:17:53,928 --> 00:17:57,538
is your scenario. You remember this diagram,

265
00:17:57,634 --> 00:18:01,286
probably from a moment ago I presented this.

266
00:18:01,308 --> 00:18:05,394
So we have like partitions and the backups, and the rule is the backup

267
00:18:05,442 --> 00:18:07,910
is always on another member,

268
00:18:08,510 --> 00:18:12,394
so it always works good. But imagine what would happen if

269
00:18:12,592 --> 00:18:16,106
we store the

270
00:18:16,128 --> 00:18:19,702
partition on the member one and the backup of the partition on member

271
00:18:19,766 --> 00:18:23,422
two. However, it happens that machine one

272
00:18:23,476 --> 00:18:27,262
and the machine two, they are in the same availability zone. So now

273
00:18:27,316 --> 00:18:30,510
if zone one crashes, what happens?

274
00:18:30,580 --> 00:18:34,002
We lose the data because we lost both the

275
00:18:34,056 --> 00:18:38,066
primary partition and the partition backup. That is

276
00:18:38,088 --> 00:18:42,146
why the same deployed we moved it from multiinstance to

277
00:18:42,168 --> 00:18:45,402
multi zone and it doesn't work anymore.

278
00:18:45,566 --> 00:18:49,014
We thought how to solve it in hazelcast this

279
00:18:49,052 --> 00:18:52,840
problem and we came up with the idea that

280
00:18:53,290 --> 00:18:56,566
a feature called zone aware, so we groups the

281
00:18:56,588 --> 00:19:00,074
partitions by zones and this is actually how we

282
00:19:00,112 --> 00:19:03,866
enable this in the configuration. And if

283
00:19:03,888 --> 00:19:07,622
you enable this, then hazelcast

284
00:19:07,686 --> 00:19:11,338
will know in which higher verbatim zone it is located

285
00:19:11,434 --> 00:19:15,322
and it will keep the backups

286
00:19:15,386 --> 00:19:19,210
always of the partitions always in a different availability

287
00:19:19,290 --> 00:19:22,486
zone. So that if zones zone is down you never lose

288
00:19:22,538 --> 00:19:26,318
the data, since the concept of the availability

289
00:19:26,414 --> 00:19:29,422
zones is related to the cloud. So it's different in AWS,

290
00:19:29,486 --> 00:19:32,830
different in azure, different in GCP

291
00:19:32,910 --> 00:19:36,454
and in kubernetes. In general we

292
00:19:36,652 --> 00:19:40,626
provided plugins for each environment.

293
00:19:40,818 --> 00:19:44,166
And by the way, these plugins are also used for the

294
00:19:44,188 --> 00:19:49,770
discovery and they

295
00:19:49,840 --> 00:19:53,174
used the given API,

296
00:19:53,222 --> 00:19:56,326
for example AWS API, to check okay, in which zone

297
00:19:56,358 --> 00:19:59,594
I am located. And then Hazelcast knows where

298
00:19:59,632 --> 00:20:03,230
to distribute the partition backups so that in result you

299
00:20:03,300 --> 00:20:07,034
have the partition backup always in another availability zone.

300
00:20:07,082 --> 00:20:10,480
And if one zone is down, you will never lose data.

301
00:20:11,810 --> 00:20:15,054
So that is why I said there's not much difference in terms

302
00:20:15,092 --> 00:20:18,514
of latency and in terms of the configuration. But please make

303
00:20:18,552 --> 00:20:22,446
sure that your data store is zone aware or supports like zone aware

304
00:20:22,478 --> 00:20:25,814
feature and don't take it for granted that

305
00:20:26,012 --> 00:20:30,310
it works this way. Short summary

306
00:20:31,210 --> 00:20:34,678
so level two multizone, I would say it's currently

307
00:20:34,764 --> 00:20:38,534
top one choice because you have very highly

308
00:20:38,582 --> 00:20:42,106
available system youll can keep the

309
00:20:42,128 --> 00:20:46,442
data consistency with synchronous backups and

310
00:20:46,576 --> 00:20:49,210
a lot of cloud specific toolkit that supported.

311
00:20:49,630 --> 00:20:53,098
Now please make sure that your tool really supports

312
00:20:53,114 --> 00:20:57,310
zones aware. So read how it works. You need to go a little deeper.

313
00:20:57,970 --> 00:21:01,562
And from another downside is the same as multiinstance.

314
00:21:01,626 --> 00:21:03,950
So we are still in the one region,

315
00:21:04,110 --> 00:21:07,694
meaning if we deploy our system in Europe

316
00:21:07,822 --> 00:21:11,710
and someone from us accesses our system, then latency

317
00:21:11,790 --> 00:21:15,186
is high. And that is the problem we will

318
00:21:15,208 --> 00:21:19,102
try to solve right now, going from multi zone

319
00:21:19,166 --> 00:21:22,246
to multi region. So multi region will

320
00:21:22,268 --> 00:21:25,720
be. Yeah, it's multi region means that if

321
00:21:26,330 --> 00:21:29,674
the whole geo region is down, our system is still

322
00:21:29,712 --> 00:21:33,434
available how it looks like on the diagram. So that

323
00:21:33,472 --> 00:21:37,402
will be the diagram for us. So usually

324
00:21:37,456 --> 00:21:41,470
a request goes to Geolo balancer, and it's forwarded

325
00:21:42,290 --> 00:21:46,590
to the regions which is the closest to our client,

326
00:21:47,250 --> 00:21:50,622
and then it's forwarded to one of the application services,

327
00:21:50,756 --> 00:21:54,290
and they use some data. And between the data stores in

328
00:21:54,360 --> 00:21:58,100
different regions, we have something called geore application.

329
00:21:58,630 --> 00:22:02,622
So the assumption here we have our data stores deployed

330
00:22:02,686 --> 00:22:05,330
in different regions,

331
00:22:06,090 --> 00:22:09,110
and the network may be slow and unreliable.

332
00:22:10,570 --> 00:22:13,842
For example, if youll would like to simulate, you can deploy

333
00:22:13,986 --> 00:22:17,160
two ec, two instances, one in Europe, one in us.

334
00:22:19,630 --> 00:22:23,450
On each of them, start your database, and that is your deployed.

335
00:22:25,230 --> 00:22:28,150
You may think, but what's the problem of regions?

336
00:22:28,230 --> 00:22:31,882
Like, why multiregion needs

337
00:22:31,936 --> 00:22:35,134
something like georeplication, why is it different?

338
00:22:35,332 --> 00:22:40,446
So the problem is the distance. So the physical distance is something that is

339
00:22:40,468 --> 00:22:43,662
actually the problem. If you look at the map, you look, for example,

340
00:22:43,716 --> 00:22:47,954
two regions, Finland and Oregon, it's like 10,000

341
00:22:47,992 --> 00:22:51,474
between. So even if we calculate, like take

342
00:22:51,512 --> 00:22:55,534
the speed of light in a vacuum and take the distance, so the round

343
00:22:55,582 --> 00:22:58,738
trip time of light

344
00:22:58,824 --> 00:23:02,326
in a vacuum would be 60 milliseconds. So it's already a lot.

345
00:23:02,508 --> 00:23:05,638
If it's not a vacuum, but a fiber, it will be at

346
00:23:05,644 --> 00:23:09,162
least three times more. And it does not takes

347
00:23:09,216 --> 00:23:12,940
any routers root and anything, it's just

348
00:23:13,710 --> 00:23:18,858
light. So this is something that we

349
00:23:18,864 --> 00:23:22,666
cannot solve. That is why we cannot

350
00:23:22,698 --> 00:23:26,346
use just a standard replication in between our data stores.

351
00:23:26,378 --> 00:23:28,990
We need to use something called georeplication.

352
00:23:29,810 --> 00:23:34,334
So georeplication is just like,

353
00:23:34,532 --> 00:23:37,874
you have two data stores, and you would like to have the same data in

354
00:23:37,912 --> 00:23:41,474
both of them. So youll need to replicate them and it needs to be done

355
00:23:41,512 --> 00:23:45,038
asynchronously because of the physical distance,

356
00:23:45,134 --> 00:23:49,170
your latency would suffer too much. If you don't do it asynchronously,

357
00:23:49,250 --> 00:23:52,514
youll data store must support it, and you must be prepared for the data loss,

358
00:23:52,562 --> 00:23:56,246
because you use asynchronous communication and there in

359
00:23:56,268 --> 00:23:59,670
general like two nodes, active passive or active active.

360
00:23:59,830 --> 00:24:04,794
So active passive is like you

361
00:24:04,832 --> 00:24:07,980
write only to one data store and the second one is not used,

362
00:24:08,590 --> 00:24:12,126
or it's used only for reads. And with

363
00:24:12,148 --> 00:24:15,982
such a scenario you need to be prepared for the data loss because maybe you

364
00:24:16,116 --> 00:24:19,546
wrote something to the active cluster and it crashes

365
00:24:19,658 --> 00:24:21,840
before replicating the data.

366
00:24:23,510 --> 00:24:27,090
So you need to be prepared also for eventual consistency.

367
00:24:29,110 --> 00:24:34,578
And in the active active mode means that you

368
00:24:34,584 --> 00:24:37,790
can write to both clusters. And then you

369
00:24:37,800 --> 00:24:41,126
need to be prepared for the data loss, for eventual consistency, but also for the

370
00:24:41,148 --> 00:24:44,840
conflict resolution. Because what happens if you modify the same data

371
00:24:45,930 --> 00:24:49,530
at the same time on two

372
00:24:49,680 --> 00:24:53,558
database clusters? You need to have a strategy

373
00:24:53,734 --> 00:24:56,762
how to solve this conflict. So in

374
00:24:56,816 --> 00:25:00,314
most cases, the simplest strategy is, for example, the last

375
00:25:00,352 --> 00:25:04,126
one wins. But you have to think about it inside your application

376
00:25:04,228 --> 00:25:07,918
logic, because your business logic needs to be aware what to do if you

377
00:25:07,924 --> 00:25:11,482
have a conflicting data. That is why it's actually very complex

378
00:25:11,546 --> 00:25:16,990
to say to reason about active, active georeplication.

379
00:25:18,370 --> 00:25:21,822
In headlocks we call this georeplication one replication.

380
00:25:21,886 --> 00:25:25,282
And this is actually how youll set it up. So it's actually very simple.

381
00:25:25,336 --> 00:25:28,986
You set up the one replication

382
00:25:29,038 --> 00:25:32,738
and the IP or the hostname of the target cluster and that's

383
00:25:32,754 --> 00:25:34,520
it. It will replicate the data.

384
00:25:35,690 --> 00:25:39,500
The only thing with this jury replication, it does not sound

385
00:25:40,030 --> 00:25:43,850
easy. So do I really need to lose the consistency if

386
00:25:43,920 --> 00:25:47,306
I would like to go multiregion? And I

387
00:25:47,328 --> 00:25:49,210
did another latency experiment,

388
00:25:50,530 --> 00:25:54,560
and this time

389
00:25:56,130 --> 00:26:00,474
I did something I should not do. So I've set up one hazelcast

390
00:26:00,522 --> 00:26:06,062
cluster with synchronous backup over two geographical

391
00:26:06,126 --> 00:26:10,178
regions. And I measured the latency and

392
00:26:10,264 --> 00:26:13,570
that was the result. So you see it's

393
00:26:14,070 --> 00:26:17,190
way higher than multizone and it's usually

394
00:26:17,260 --> 00:26:20,886
at the range. That is not acceptable. That is

395
00:26:20,908 --> 00:26:25,506
why you will never use synchronous

396
00:26:25,698 --> 00:26:29,830
replication across multiple geographical regions.

397
00:26:30,170 --> 00:26:34,022
And I did the same with the georeplication, obviously it was synthesis.

398
00:26:34,086 --> 00:26:37,786
The replication is asynchronous, the latency is

399
00:26:37,808 --> 00:26:41,086
the same as multiregion. Now if

400
00:26:41,108 --> 00:26:44,446
you look at this chart, that is the reason

401
00:26:44,628 --> 00:26:47,706
why you will never see a Kubernetes cluster,

402
00:26:47,898 --> 00:26:51,834
which is across multiple geographical

403
00:26:51,882 --> 00:26:55,762
regions. You will see a Kubernetes cluster across

404
00:26:55,816 --> 00:26:59,774
multiple zones, no problem with that. But you will never see a Kubernetes cluster

405
00:26:59,822 --> 00:27:03,554
across multiple geographical regions. And the reason for that

406
00:27:03,592 --> 00:27:07,510
is that internally Kubernetes, cases etCD,

407
00:27:08,010 --> 00:27:09,560
which is data store,

408
00:27:12,170 --> 00:27:15,990
which is consistent. So you cannot have this eTCD across

409
00:27:16,060 --> 00:27:19,414
multiple regions, because it will just be super slow.

410
00:27:19,462 --> 00:27:23,350
So technically you cloud have a Kubernetes cluster across multiple regions,

411
00:27:23,430 --> 00:27:26,540
but it will be so slow that you will not be able to use it.

412
00:27:28,990 --> 00:27:32,606
Yeah. So you will see for kubernetes some

413
00:27:32,628 --> 00:27:37,070
other options, like federations,

414
00:27:37,410 --> 00:27:40,586
but you cannot have one consistent

415
00:27:40,618 --> 00:27:42,830
cluster across multiple regions.

416
00:27:43,890 --> 00:27:47,506
Short summary of the level three multiregion. What does it mean

417
00:27:47,528 --> 00:27:51,774
to you? So we are super high available. You can achieve low latency

418
00:27:51,902 --> 00:27:56,002
when accessed from multiple region. That is great. And sometimes

419
00:27:56,056 --> 00:27:59,080
you can use some cloud specific tools, sometimes not.

420
00:27:59,610 --> 00:28:03,570
But on the downsides, you need to use georeplication, which is asynchronous.

421
00:28:03,730 --> 00:28:07,750
And you need to be prepared for the conflict resolution, eventual consistency.

422
00:28:09,130 --> 00:28:12,578
So it's way more complex to reason about a

423
00:28:12,604 --> 00:28:16,534
system like that. Okay, from multiregion

424
00:28:16,582 --> 00:28:20,566
we go to multicloud. So multicloud

425
00:28:20,598 --> 00:28:24,222
means that if zones cloud provider is down, the system

426
00:28:24,276 --> 00:28:27,486
is still available how it looks like

427
00:28:27,508 --> 00:28:31,326
on the diagram. So again, you will have some load balancer, which load balances the

428
00:28:31,348 --> 00:28:34,420
traffic, and you have basically the clone of the system

429
00:28:34,950 --> 00:28:38,354
on a different cloud providers and a replication in

430
00:28:38,392 --> 00:28:41,982
between. And this replication will be asynchronous,

431
00:28:42,046 --> 00:28:45,550
like a geore replication. So you may ask like

432
00:28:45,720 --> 00:28:49,334
what's different from multiregion? This diagram is actually like

433
00:28:49,372 --> 00:28:53,814
the same before. It's just you have multiple cloud providers, but that's it.

434
00:28:54,012 --> 00:28:58,158
But there are some differences. So if you deploy

435
00:28:58,194 --> 00:29:01,690
the same system on different cloud providers, you cannot use cloud

436
00:29:01,760 --> 00:29:05,654
portfolio and you cannot use VPC

437
00:29:05,702 --> 00:29:08,986
peering, and you increase the cost because you need

438
00:29:09,008 --> 00:29:12,702
to maintain the same infrastructure and the same system on a multiple cloud

439
00:29:12,756 --> 00:29:16,286
providers, which is more complex and costs more

440
00:29:16,308 --> 00:29:19,614
money. But is high availability the only

441
00:29:19,652 --> 00:29:22,986
reason for multicloud? And obviously no,

442
00:29:23,028 --> 00:29:27,010
it's not even the main reason. The main reasons for going multicloud

443
00:29:27,350 --> 00:29:30,818
is like avoiding Vernon lock in. So you

444
00:29:30,824 --> 00:29:33,730
don't want to bind yourself to one cloud provider.

445
00:29:35,850 --> 00:29:39,446
Because for example, imagine you have

446
00:29:39,468 --> 00:29:43,334
the same system deployed in different cloud providers. That is way better for

447
00:29:43,372 --> 00:29:46,982
any cost optimization, for any cloud cost

448
00:29:47,036 --> 00:29:50,586
negotiation, because you can go to AWS saying,

449
00:29:50,688 --> 00:29:54,586
okay, by the way, I'm also deployed on Azure and GCP, so can you

450
00:29:54,768 --> 00:29:58,522
lower the bill? And that is what happens

451
00:29:58,576 --> 00:30:01,678
actually with cloud providers. You negotiate with them

452
00:30:01,764 --> 00:30:05,486
if you are big enough. And it's also

453
00:30:05,508 --> 00:30:09,294
about risk mitigation if youll

454
00:30:09,332 --> 00:30:12,990
don't want to be bound to one cloud provider

455
00:30:14,630 --> 00:30:16,820
for some business reasons. Also,

456
00:30:17,590 --> 00:30:21,054
sometimes it's also about low latency. When we've built hazelcast

457
00:30:21,102 --> 00:30:27,726
cloud, hazelcast cloud is hazelcast

458
00:30:27,758 --> 00:30:30,866
AWS a service, and we build it on top of different cloud providers,

459
00:30:30,898 --> 00:30:34,454
because our users are also deployed on different

460
00:30:34,492 --> 00:30:37,794
cloud providers and they would like to have the lowest latency possible.

461
00:30:37,932 --> 00:30:42,010
So that is why we are built on different cloud providers.

462
00:30:42,590 --> 00:30:45,834
And also some data protection regulations or

463
00:30:45,872 --> 00:30:50,250
sometimes you build like heterogeneous

464
00:30:50,910 --> 00:30:54,750
environment when you use different cloud portfolio for

465
00:30:54,820 --> 00:30:58,474
different parts of the system. If you go multicloud,

466
00:30:58,522 --> 00:31:02,410
what does it mean to you? So you don't have vendor lock in, which is

467
00:31:02,580 --> 00:31:07,006
very good. You are in better position with the cloud cost negotiation,

468
00:31:07,118 --> 00:31:10,420
and you can have low latency of access from multiple cloud,

469
00:31:11,030 --> 00:31:14,462
but the setup is way more complex

470
00:31:14,526 --> 00:31:18,886
and you cannot use cloud portfolio if

471
00:31:18,908 --> 00:31:22,040
you really have the clone of the same environment on different

472
00:31:24,810 --> 00:31:28,666
cloud providers. Okay, and the last

473
00:31:28,768 --> 00:31:32,902
level for today is hybrid cloud. So hybrid

474
00:31:32,966 --> 00:31:36,170
cloud means if all cloud providers are down,

475
00:31:36,240 --> 00:31:40,380
your system will still be available. But really,

476
00:31:40,910 --> 00:31:44,206
is it possible that all cloud providers are down at

477
00:31:44,228 --> 00:31:47,758
the same time? No, it's actually not

478
00:31:47,844 --> 00:31:51,166
even possible. It's not even possible that one cloud provider is

479
00:31:51,188 --> 00:31:55,380
down. I think it never happened that the whole cloud provider, all services were down.

480
00:31:55,910 --> 00:31:59,426
There are different reasons for hybrid cloud. So then

481
00:31:59,528 --> 00:32:01,540
why would you use hybrid cloud?

482
00:32:03,270 --> 00:32:07,094
So it's usually about data requirements, regulations, data security.

483
00:32:07,292 --> 00:32:10,870
Sometimes there are regulations, for example, that the data of your

484
00:32:10,940 --> 00:32:14,534
bank customers needs to be stored in this

485
00:32:14,572 --> 00:32:17,510
country or in this building or in this city.

486
00:32:17,580 --> 00:32:21,522
So then part of your infrastructure is on premises,

487
00:32:21,586 --> 00:32:25,386
on your own servers. The other use case is that you are

488
00:32:25,408 --> 00:32:28,554
moving to the cloud. You had your own infrastructure, but you're moving to the cloud.

489
00:32:28,592 --> 00:32:32,586
And as a process, you build a hybrid cloud environment.

490
00:32:32,778 --> 00:32:36,670
And it's also sometimes about cost reduction. If you are big enough, then cloud

491
00:32:36,740 --> 00:32:40,560
may not be the cheapest thing you can get.

492
00:32:41,330 --> 00:32:44,970
How does it look like on a diagram? So again, youll have load balancer

493
00:32:45,050 --> 00:32:48,478
and the same system deployed on different cloud providers, but also the

494
00:32:48,484 --> 00:32:51,870
same system deployed on your own machines.

495
00:32:53,810 --> 00:32:57,766
So at this point, actually at

496
00:32:57,788 --> 00:33:01,606
this point, but also at the point of multicloud, you will

497
00:33:01,708 --> 00:33:05,622
usually need some abstraction. And this abstraction because it's just not

498
00:33:05,676 --> 00:33:09,518
manageable. When you manage different servers, different machines,

499
00:33:09,554 --> 00:33:12,970
it's just too difficult, too complex at this point. So usually

500
00:33:13,040 --> 00:33:17,014
what people do, they have some abstraction layer

501
00:33:17,142 --> 00:33:20,762
and they interact with this abstraction layer. And so you install kubernetes.

502
00:33:20,826 --> 00:33:24,570
Nowadays this abstraction layer is usually kubernetes

503
00:33:24,650 --> 00:33:28,394
or some derivatives from kubernetes like Openshift or IBM

504
00:33:28,442 --> 00:33:32,042
cloud. And you deployed this kubernetes on each environment,

505
00:33:32,106 --> 00:33:35,406
on the AWS, on GCP, and on your

506
00:33:35,428 --> 00:33:39,140
own machines. So at least you have the same interface to interact with.

507
00:33:39,670 --> 00:33:43,682
And it's actually how most companies now build multi cloud

508
00:33:43,736 --> 00:33:45,650
and hybrid cloud systems.

509
00:33:47,130 --> 00:33:50,706
Short summary so hybrid

510
00:33:50,738 --> 00:33:53,942
cloud means that you have no cloud lock in. You can have

511
00:33:53,996 --> 00:33:58,154
achieve low latency accessed from any custom network because you

512
00:33:58,192 --> 00:34:00,490
are the master of your infrastructure.

513
00:34:00,830 --> 00:34:04,774
But the setup is very complex and it usually requires

514
00:34:04,822 --> 00:34:07,530
this kubernetes or openshift layer.

515
00:34:08,190 --> 00:34:10,170
And it costs a fortune.

516
00:34:11,330 --> 00:34:13,070
So as a short summary,

517
00:34:14,690 --> 00:34:18,030
a short summary. What I propose is not to repeat much

518
00:34:18,100 --> 00:34:21,360
what I've said, because that could be boring, but to at least some,

519
00:34:23,430 --> 00:34:27,454
to summarize basically what I've said. So I propose

520
00:34:27,502 --> 00:34:31,406
like a graph

521
00:34:31,518 --> 00:34:35,602
how I see it. Like comparing complexity and cost to the

522
00:34:35,736 --> 00:34:39,286
high availability level. So this is how

523
00:34:39,308 --> 00:34:42,726
I see it. So at the beginning, single instance is very. It's not

524
00:34:42,748 --> 00:34:46,146
complex at all. But then if you go from single multiinstance to multi

525
00:34:46,178 --> 00:34:49,858
instance, it's actually a big step. Because you

526
00:34:49,884 --> 00:34:53,340
go from nondistributed system to a distributed system.

527
00:34:53,870 --> 00:34:57,306
So you need to think about data, applications and all those things we

528
00:34:57,328 --> 00:35:01,166
mentioned. If you go from multi instance to multizone, actually it's not such

529
00:35:01,188 --> 00:35:04,110
a big step in complexity. In terms of complexity,

530
00:35:07,890 --> 00:35:12,110
you need to make sure that your database is

531
00:35:12,260 --> 00:35:16,126
zone aware. Then from multizone to multiregion,

532
00:35:16,158 --> 00:35:19,438
it's another big step because you have long distance. So you need to be prepared

533
00:35:19,454 --> 00:35:22,846
for georetication. You cannot

534
00:35:22,878 --> 00:35:26,614
have synchronous single point of data going

535
00:35:26,652 --> 00:35:29,974
from multiregion to multicloud. You cannot use cloud

536
00:35:30,092 --> 00:35:33,430
tools. And from multicloud to hybrid cloud is another big step.

537
00:35:33,500 --> 00:35:36,230
Because you need to maintain your own infrastructures,

538
00:35:37,370 --> 00:35:39,580
which high availability level is for me.

539
00:35:40,430 --> 00:35:43,482
So I would say if youll don't know, then this is your level.

540
00:35:43,536 --> 00:35:47,014
This is what I call top one choice. Because multizone

541
00:35:47,142 --> 00:35:51,790
youll are very high available. But you can still use like synchronous

542
00:35:52,130 --> 00:35:55,438
data store, which really simplifies your

543
00:35:55,524 --> 00:35:58,954
reasoning about the system. If you are a software cabo,

544
00:35:59,002 --> 00:36:02,254
you can use single instance. Multiregion is if you need

545
00:36:02,292 --> 00:36:05,518
to go worldwide with your system. So you would like to

546
00:36:05,524 --> 00:36:09,706
achieve low latency from different regions. And multicloud

547
00:36:09,738 --> 00:36:14,286
and hybrid cloud is basically for

548
00:36:14,388 --> 00:36:18,360
the like, for the reason of compliance and security.

549
00:36:19,370 --> 00:36:22,806
So basically banking industry. So youll need to have

550
00:36:22,828 --> 00:36:26,582
a reason to do it. And with this last

551
00:36:26,636 --> 00:36:30,166
slide, I would like to thank you for listening to this talk. It was

552
00:36:30,188 --> 00:36:33,462
a pleasure speaking at Conf 42

553
00:36:33,516 --> 00:36:36,806
conference. Enjoy the rest of the

554
00:36:36,828 --> 00:36:37,090
conference.

