1
00:01:29,996 --> 00:01:33,846
Conf 42 cloud native 2022 thank

2
00:01:33,868 --> 00:01:37,890
you for joining my presentation. I hope you've been enjoying all the other presentations

3
00:01:37,970 --> 00:01:41,422
going on today. I'm my talk is entitled Local

4
00:01:41,476 --> 00:01:45,178
Microservice Development with remote kubernetes assist and it's

5
00:01:45,194 --> 00:01:48,586
really a story about how we at Stackhawk invested

6
00:01:48,618 --> 00:01:52,238
in our dev tooling and how we were able to use kubernetes and

7
00:01:52,244 --> 00:01:55,694
other cloud native services to facilitate our software

8
00:01:55,742 --> 00:01:59,086
development process. My name is Zach

9
00:01:59,198 --> 00:02:02,398
and I've been in startups for most of my career.

10
00:02:02,494 --> 00:02:05,986
I really love the opportunities and the excitement of startup companies,

11
00:02:06,168 --> 00:02:09,606
and I feel like you really get a breadth of experience that

12
00:02:09,628 --> 00:02:12,774
you can't get at larger companies or you don't often get at

13
00:02:12,892 --> 00:02:16,434
larger companies. Automation has been kind of a career

14
00:02:16,482 --> 00:02:20,474
theme for me, starting out with networks and systems and security,

15
00:02:20,672 --> 00:02:23,686
and these days I focus a lot on software delivery,

16
00:02:23,718 --> 00:02:25,740
but I still do that other stuff too.

17
00:02:27,150 --> 00:02:31,078
At Stackhawk we build tools for test driven security

18
00:02:31,264 --> 00:02:34,734
and our primary tools is a dast scanner that's built

19
00:02:34,772 --> 00:02:37,310
on the open source project OaSp Zap.

20
00:02:37,970 --> 00:02:41,274
Dast scans for dynamic application security testing,

21
00:02:41,322 --> 00:02:45,322
and it's a type of scanner that probes a web app for known vulnerabilities

22
00:02:45,386 --> 00:02:48,862
by attempting to exploit them. Among dast scanners,

23
00:02:48,926 --> 00:02:52,658
Stackhawk is the best for running in CI CD and for working in a

24
00:02:52,664 --> 00:02:55,970
team environment. It's also free for developers

25
00:02:56,310 --> 00:02:59,606
if you happen to be looking for a new challenge. I should also mention that

26
00:02:59,628 --> 00:03:02,918
we are hiring. Okay,

27
00:03:03,004 --> 00:03:06,326
so I want to talk about our app platform, because this

28
00:03:06,348 --> 00:03:09,914
is the context of our story. When we

29
00:03:09,952 --> 00:03:13,306
started about three years ago, we had a greenfield opportunity

30
00:03:13,408 --> 00:03:17,274
in front of us and we wanted to build out a really state

31
00:03:17,312 --> 00:03:20,702
of the art platform. So we looked at these

32
00:03:20,756 --> 00:03:23,854
CNCF rules for consistency between apps and we wanted

33
00:03:23,892 --> 00:03:28,190
to do like twelve factor apps, stateless design patterns,

34
00:03:28,530 --> 00:03:31,854
set up some common rules so that once

35
00:03:31,892 --> 00:03:35,360
we got started, we had a great platform to build on.

36
00:03:35,970 --> 00:03:39,342
We knew that there was going to be a run anywhere das

37
00:03:39,406 --> 00:03:42,930
scanner component to our architecture, and this is what people would run

38
00:03:43,000 --> 00:03:46,514
out in the field to scan their applications. We would also

39
00:03:46,552 --> 00:03:50,034
have a web UI and both of these components,

40
00:03:50,082 --> 00:03:52,760
and this is where you would look at your scan data and stuff,

41
00:03:53,210 --> 00:03:56,914
and both of these components would tie into microservices

42
00:03:57,042 --> 00:04:01,334
and rest APIs running in Kubernetes.

43
00:04:01,462 --> 00:04:05,558
So we had run anywhere DAS scanner react

44
00:04:05,734 --> 00:04:09,146
single page application UI tests API running

45
00:04:09,168 --> 00:04:13,118
on microservices and these microservices would run using

46
00:04:13,204 --> 00:04:18,126
Kotlin as a language to develop those microservices at

47
00:04:18,148 --> 00:04:21,550
the same time, we wanted to go ahead and invest

48
00:04:21,620 --> 00:04:25,438
some time in our build platform. So we built it

49
00:04:25,444 --> 00:04:28,654
with security in mind, but we also built it with fast iteration

50
00:04:28,702 --> 00:04:32,306
in mind. And we wanted to set this up to be a Gitops kind of

51
00:04:32,328 --> 00:04:36,274
platform where hopefully coders would just check in code,

52
00:04:36,392 --> 00:04:40,034
they'd build and test locally check in code, and then automated

53
00:04:40,082 --> 00:04:43,634
build systems would take over and deploy the software,

54
00:04:43,682 --> 00:04:45,990
as long as all the checks completed correctly.

55
00:04:46,410 --> 00:04:50,166
So to do this, we set up a bunch of AWS

56
00:04:50,278 --> 00:04:53,546
accounts, and these accounts would serve as

57
00:04:53,568 --> 00:04:57,706
our build environment and several runtime accounts so

58
00:04:57,728 --> 00:05:01,210
that we could isolate the build operations and the runtime operations.

59
00:05:01,370 --> 00:05:05,418
And then across that we would also stripe in different environments.

60
00:05:05,514 --> 00:05:09,114
So a production environment, of course, but also several

61
00:05:09,162 --> 00:05:11,760
staging environments where we could test things out.

62
00:05:13,590 --> 00:05:17,394
To help us in this build platform, we created a

63
00:05:17,432 --> 00:05:20,606
big bash script. Started out small, but it got bigger

64
00:05:20,638 --> 00:05:24,818
over time. We called it biodome. And biodome is this

65
00:05:24,984 --> 00:05:28,214
library of bash functions that would help us in

66
00:05:28,252 --> 00:05:32,198
our local development as well as in the

67
00:05:32,204 --> 00:05:36,054
pipeline when were building our software. And it would do things like get

68
00:05:36,092 --> 00:05:39,942
information about our AWS environments, like figure out what environment

69
00:05:40,006 --> 00:05:43,270
we're running in. And so what environment we would be targeting,

70
00:05:43,430 --> 00:05:47,542
what the account numbers were for these different types

71
00:05:47,686 --> 00:05:51,566
and app environments. But it

72
00:05:51,588 --> 00:05:55,114
would also contain some common functions for pushing and pulling artifacts,

73
00:05:55,162 --> 00:05:58,430
such as jars and container images.

74
00:05:59,250 --> 00:06:02,426
And it would also take care of deploying manifests and helm

75
00:06:02,458 --> 00:06:05,620
charts, or at least help with that stuff. To make it easy.

76
00:06:06,150 --> 00:06:09,938
At the same time, we adopted a platform

77
00:06:10,024 --> 00:06:13,586
called Gradle, which is a pluggable JVM tool similar to

78
00:06:13,608 --> 00:06:17,326
Maven. And this is a tool that is opinionated,

79
00:06:17,438 --> 00:06:20,918
and it makes it easy for a JVM based language like

80
00:06:21,004 --> 00:06:24,950
Kotlin to build and test and package artifacts.

81
00:06:25,610 --> 00:06:28,826
But at the same time, we went ahead and started to build our

82
00:06:28,848 --> 00:06:32,234
own library of functions and plugins that we could

83
00:06:32,272 --> 00:06:36,890
plug into gradle, and we called that library Ari.

84
00:06:38,030 --> 00:06:41,342
Finally, all these stuff runs on AWS code.

85
00:06:41,396 --> 00:06:45,070
Build, just runs build steps. It's a really simple system,

86
00:06:45,220 --> 00:06:48,826
just runs build steps in response

87
00:06:48,858 --> 00:06:52,394
to GitHub PR and were webhooks

88
00:06:52,442 --> 00:06:56,500
that come in. So then at a high level,

89
00:06:57,190 --> 00:07:00,814
what this looks like is we've got a repo

90
00:07:00,862 --> 00:07:04,274
for every microservice that we develop. And those

91
00:07:04,312 --> 00:07:07,910
repos live in GitHub. And as developers issue

92
00:07:07,980 --> 00:07:11,510
prs and merges to GitHub,

93
00:07:13,290 --> 00:07:16,834
GitHub would send a webhook over to code building in AWS.

94
00:07:16,962 --> 00:07:20,362
And code building would kick off the build job. These build job

95
00:07:20,416 --> 00:07:24,390
would use Biodome the big shell script library, as well as gradle,

96
00:07:24,550 --> 00:07:28,154
to perform all the building and testing and figuring out

97
00:07:28,192 --> 00:07:32,330
which environment we were in and deploying the software, as long as all the checks

98
00:07:32,410 --> 00:07:36,206
completed correctly. So we

99
00:07:36,228 --> 00:07:39,902
had all this stuff in place, and it felt like a pretty good platform.

100
00:07:40,036 --> 00:07:43,314
And we got started, and for a couple of weeks, it was really

101
00:07:43,352 --> 00:07:47,006
pretty cool. Developers could bring their own favorite

102
00:07:47,038 --> 00:07:50,274
idE. They would test locally on their

103
00:07:50,312 --> 00:07:53,774
laptops, code build, test, repeat, and then submit

104
00:07:53,822 --> 00:07:57,062
prs, and automated build and deployment would take over

105
00:07:57,116 --> 00:08:00,866
from there. But it turns

106
00:08:00,898 --> 00:08:04,690
out that it ended up being kind of a chore for developers

107
00:08:04,770 --> 00:08:08,506
to set up all the microservice dependencies that

108
00:08:08,528 --> 00:08:11,290
these needed to work on their target service.

109
00:08:11,440 --> 00:08:15,098
So if they're working on, like, service A and as

110
00:08:15,264 --> 00:08:19,174
we build out more microservices, maybe that microservice

111
00:08:19,302 --> 00:08:23,182
really doesn't do much unless it's got service BC and

112
00:08:23,236 --> 00:08:26,606
D. So we

113
00:08:26,628 --> 00:08:29,902
needed to figure out a way to make it easy to bring up the

114
00:08:29,956 --> 00:08:33,166
latest versions of service Bc and D so

115
00:08:33,188 --> 00:08:36,546
that they could just get to coding. And what

116
00:08:36,568 --> 00:08:40,130
we came up with was a system where we took Docker compose,

117
00:08:41,190 --> 00:08:43,970
and there's this cool feature in Docker compose,

118
00:08:44,470 --> 00:08:47,590
which is that it can overlay configuration files.

119
00:08:48,010 --> 00:08:51,334
Docker compose, if you're not familiar, is a way

120
00:08:51,372 --> 00:08:55,926
to lay out a bunch of services or containers in

121
00:08:55,948 --> 00:08:59,226
a YAmL file, and they can all talk to each other.

122
00:08:59,408 --> 00:09:02,998
So it's a nice way to put together a little assembly of containers.

123
00:09:03,094 --> 00:09:06,282
Much like microservices, it's a good way to

124
00:09:06,336 --> 00:09:10,086
develop locally. So what we did was we

125
00:09:10,128 --> 00:09:13,998
used this feature of overlays, and we concocted a

126
00:09:14,004 --> 00:09:18,026
scheme where each one of our microservice project repositories

127
00:09:18,218 --> 00:09:22,278
would contain its own compose file, a Docker compose file,

128
00:09:22,474 --> 00:09:26,254
and each repo would also define all of its microservice

129
00:09:26,302 --> 00:09:29,662
dependencies. Each microservice container,

130
00:09:29,726 --> 00:09:33,630
again, it exposes unique reserved ports.

131
00:09:33,710 --> 00:09:37,570
So for service a, you always know that it's listing on port

132
00:09:37,640 --> 00:09:41,110
3200, and maybe a couple other ports in that range.

133
00:09:42,410 --> 00:09:46,342
In each project, we would have a script, simple script called

134
00:09:46,396 --> 00:09:50,374
local start sh, and that would pull those compose files

135
00:09:50,422 --> 00:09:53,866
from all those other projects and run them together.

136
00:09:53,968 --> 00:09:58,726
They would merge and run all these dependency microservices,

137
00:09:58,918 --> 00:10:02,286
and your target app service a would be left out

138
00:10:02,308 --> 00:10:06,366
of the mix, and the expectation would be that you work

139
00:10:06,388 --> 00:10:10,302
on service a locally, but you've got all these containers running,

140
00:10:10,356 --> 00:10:14,154
and they're listening on the local host address on their reserved ports,

141
00:10:14,282 --> 00:10:17,666
and service a can talk to them and that made it a

142
00:10:17,688 --> 00:10:21,074
lot easier to build and test. And when you came back the next day

143
00:10:21,112 --> 00:10:24,900
and other people had made changes to service BC and D,

144
00:10:25,450 --> 00:10:29,798
you could just restart your Devcube version zero

145
00:10:29,964 --> 00:10:34,338
Docker compose setup and you'd get all the latest images.

146
00:10:34,514 --> 00:10:35,800
Worked really well.

147
00:10:37,390 --> 00:10:40,570
Let me kind of talk through what this took

148
00:10:40,640 --> 00:10:44,342
like. So say you've got a repository

149
00:10:44,486 --> 00:10:48,010
SVCA service a in GitHub,

150
00:10:48,430 --> 00:10:52,186
that project repository is going to have a file called Docker

151
00:10:52,218 --> 00:10:55,626
Compose service a. It's a YAML

152
00:10:55,658 --> 00:10:58,320
file, and it defines its own services.

153
00:10:58,690 --> 00:11:01,760
And you can see that top box.

154
00:11:03,590 --> 00:11:06,706
The Docker compose file just describes how to

155
00:11:06,728 --> 00:11:10,706
bring up service a itself. And when

156
00:11:10,728 --> 00:11:14,626
we run this composition, of course, if you're working on service a,

157
00:11:14,808 --> 00:11:18,022
we're not going to bring up service a in a container. So this is actually

158
00:11:18,076 --> 00:11:21,000
used for other projects that depend on service a.

159
00:11:22,330 --> 00:11:25,474
So service a in this compose file, it defines,

160
00:11:25,522 --> 00:11:29,126
hey, what image do I need? Well, I need service a with

161
00:11:29,148 --> 00:11:32,294
the latest tag, and we're getting that from an ECR

162
00:11:32,342 --> 00:11:36,218
repo in AWS. It listens on port 3200,

163
00:11:36,304 --> 00:11:39,546
so that should be exposed to the local host address, and it

164
00:11:39,568 --> 00:11:42,240
depends on service b, C, and D.

165
00:11:42,770 --> 00:11:46,030
Then if you go to the other projects for service b and service

166
00:11:46,100 --> 00:11:49,674
c and service D, you'll find similar docker compose

167
00:11:49,722 --> 00:11:52,922
files, and those might define local dependencies.

168
00:11:52,986 --> 00:11:56,642
Like some of our projects require a database or a redis store

169
00:11:56,696 --> 00:11:59,794
or something. Those can be defined in their

170
00:11:59,832 --> 00:12:03,426
own compose files as well. But we can also say that

171
00:12:03,448 --> 00:12:05,650
they depend on other microservices.

172
00:12:07,290 --> 00:12:10,914
So then same is true for the repos

173
00:12:10,962 --> 00:12:13,974
for service C and service D. Okay,

174
00:12:14,012 --> 00:12:17,126
so when you run that local start script and

175
00:12:17,148 --> 00:12:20,362
you're in project service a, it's going to pull

176
00:12:20,496 --> 00:12:23,834
the docker compose files for service B, C, and D.

177
00:12:24,032 --> 00:12:27,900
And this merged docker compose file, in effect,

178
00:12:28,350 --> 00:12:31,260
is what you bring up when you're working on service a.

179
00:12:32,350 --> 00:12:35,742
Now, what that looks like is all

180
00:12:35,876 --> 00:12:39,386
those docker containers for those other services running locally

181
00:12:39,418 --> 00:12:43,360
on your laptop. Listening on the local host address, and then

182
00:12:43,730 --> 00:12:48,002
to the right there, that box on the bottom right shows

183
00:12:48,056 --> 00:12:51,746
what you'd see in your ide when you run gradle boot run to bring

184
00:12:51,768 --> 00:12:55,346
up your local application, it comes up and it

185
00:12:55,368 --> 00:12:59,030
can connect to the other services that are running on your laptop.

186
00:13:00,410 --> 00:13:03,622
This worked really well. It was a snap now

187
00:13:03,676 --> 00:13:07,586
to bring up all your dependency microservices and just start coding.

188
00:13:07,778 --> 00:13:11,914
And this worked for like another four or five weeks. But after

189
00:13:11,952 --> 00:13:15,686
a while, the number and the size of these microservices grew

190
00:13:15,718 --> 00:13:19,130
and grew and it became a little bit hard to manage memory between

191
00:13:19,200 --> 00:13:23,214
IDe and Docker desktop. And your build tests run

192
00:13:23,332 --> 00:13:26,494
sort of functions. And we started to question if we

193
00:13:26,532 --> 00:13:29,360
had gotten laptops that just weren't powerful enough.

194
00:13:30,290 --> 00:13:34,126
Well, it turns out we do not need faster

195
00:13:34,158 --> 00:13:38,066
laptops. What we really needed to do was

196
00:13:38,168 --> 00:13:41,330
figure out a way to offload some of those microservices.

197
00:13:42,150 --> 00:13:46,486
And we had heard about different ways that you can use Kubernetes to

198
00:13:46,588 --> 00:13:48,600
assist in your development process.

199
00:13:49,210 --> 00:13:52,486
But one thing that we really wanted to keep about our

200
00:13:52,508 --> 00:13:56,070
current process was this use of local

201
00:13:56,140 --> 00:14:00,714
tools. We really like our ides. We like building

202
00:14:00,832 --> 00:14:05,366
and running and debugging things locally and using profilers

203
00:14:05,398 --> 00:14:09,626
locally. So what we did is we looked around in

204
00:14:09,648 --> 00:14:13,242
the devtool space and we found something called compose

205
00:14:13,306 --> 00:14:16,846
with a k, and compose with

206
00:14:16,868 --> 00:14:20,160
a k, you might guess by the name.

207
00:14:20,610 --> 00:14:24,770
Basically it just can reuse your existing docker compose files

208
00:14:25,110 --> 00:14:29,026
and it can generate Kubernetes manifests based on

209
00:14:29,048 --> 00:14:32,846
those. So what we did was we created

210
00:14:32,878 --> 00:14:36,094
a script called Devcube Sh and this is Devcube

211
00:14:36,142 --> 00:14:39,454
version one. And Devcube

212
00:14:39,502 --> 00:14:43,058
expected that you had compose with these k installed on your laptop,

213
00:14:43,234 --> 00:14:47,426
and it would go through that process, it would pull down your dependency docker

214
00:14:47,458 --> 00:14:50,506
compose files, use compose to generate the

215
00:14:50,528 --> 00:14:54,358
kube manifests, then go and apply those manifests to Kubernetes

216
00:14:54,534 --> 00:14:57,478
in a namespace that's based on your username.

217
00:14:57,654 --> 00:15:00,986
And then it would set up Kubernetes port forwarding to

218
00:15:01,008 --> 00:15:04,734
reach those microservices locally. And if you haven't used this before,

219
00:15:04,852 --> 00:15:08,186
it's a way to use the cubecuttle

220
00:15:08,218 --> 00:15:11,886
command. I call it cubectyl. So if you hear me say cubectyl, that's just what

221
00:15:11,908 --> 00:15:15,718
I call it. There's a cubectl

222
00:15:15,754 --> 00:15:19,266
port forward command that allows you

223
00:15:19,288 --> 00:15:23,170
to set up a port forward so that you can reach your microservices

224
00:15:24,310 --> 00:15:28,310
reach your pods or services as if they are running locally.

225
00:15:29,210 --> 00:15:32,550
So now it should look just like before

226
00:15:32,700 --> 00:15:35,890
with the Docker compose setup.

227
00:15:35,970 --> 00:15:39,994
Except now all of those dependent microservices, all those microservices that

228
00:15:40,032 --> 00:15:43,674
your service depends on are running out in kubernetes and

229
00:15:43,712 --> 00:15:46,890
you can continue to develop your target app locally.

230
00:15:47,630 --> 00:15:51,086
So what that looks like is, do you remember with

231
00:15:51,108 --> 00:15:55,306
the Docker compose setup, what you end up with is a merged

232
00:15:55,418 --> 00:15:59,294
docker compose file. So we go

233
00:15:59,332 --> 00:16:02,586
through that exact same process, we pull down that Docker

234
00:16:02,618 --> 00:16:05,794
compose merged file and then from it

235
00:16:05,832 --> 00:16:09,150
we run compose to create a bunch of manifests.

236
00:16:09,310 --> 00:16:12,994
And the manifests end up being a bunch of deployments and a bunch of

237
00:16:13,032 --> 00:16:16,494
services, so that the deployments

238
00:16:16,542 --> 00:16:20,086
are to set up the pods that host your containers and

239
00:16:20,108 --> 00:16:23,714
the services are to make it easy to connect to those pods.

240
00:16:23,762 --> 00:16:27,042
We don't have to guess the names of the pods that get generated

241
00:16:27,106 --> 00:16:28,230
by the deployments.

242
00:16:29,930 --> 00:16:33,370
So then if you do a Quebectyl get pods in

243
00:16:33,440 --> 00:16:37,274
namespace. Z conger in my case, you would

244
00:16:37,312 --> 00:16:40,818
see all of your dependent services running in kubernetes,

245
00:16:41,014 --> 00:16:43,760
and you can reach them on the localhost address.

246
00:16:44,850 --> 00:16:48,014
And so it looks much the same as the previous process.

247
00:16:48,132 --> 00:16:52,206
You're on your laptop, you run devcube up and

248
00:16:52,308 --> 00:16:55,930
it creates your services and deployments,

249
00:16:56,090 --> 00:16:59,778
and then you can see that your pods are running, and then you run your

250
00:16:59,864 --> 00:17:03,586
service a locally and you can develop it and it is able to

251
00:17:03,608 --> 00:17:07,174
walks to all those services. It was really pretty cool,

252
00:17:07,372 --> 00:17:10,962
and we kind of had this sense of, it just felt

253
00:17:11,026 --> 00:17:14,802
pretty powerful. It was really nice. It was a big performance

254
00:17:14,866 --> 00:17:18,610
boost for everybody. Our laptops cooled down,

255
00:17:18,700 --> 00:17:21,866
we could dedicate much more memory to the ide and to the

256
00:17:21,888 --> 00:17:23,500
build run test process.

257
00:17:25,070 --> 00:17:28,602
And this was kind of a hit. It worked well,

258
00:17:28,656 --> 00:17:31,854
especially for UI developers who needed to basically bring up

259
00:17:31,892 --> 00:17:34,030
the entire microservice stack.

260
00:17:35,730 --> 00:17:39,006
So these worked for like a good two years. And it

261
00:17:39,028 --> 00:17:42,542
was an amazing feat of shell scripting and local dev

262
00:17:42,596 --> 00:17:45,922
tools. But these were, got to be honest, there were

263
00:17:45,976 --> 00:17:49,534
some issues. So it's

264
00:17:49,582 --> 00:17:53,522
built on an edifice of shell scripts, right? And shell scripts over time

265
00:17:53,576 --> 00:17:57,610
can be hard to manage when they get big. They're just not built to scale

266
00:17:57,710 --> 00:18:01,430
quite that much. So we had biodome, the bash function

267
00:18:01,500 --> 00:18:05,654
library, and it had gotten pretty big at this point. And it also

268
00:18:05,692 --> 00:18:09,650
depended on a bunch of cli tools, devcube too.

269
00:18:09,820 --> 00:18:13,580
And they were finicky about the versions of devtools that you were using.

270
00:18:14,030 --> 00:18:17,050
Not only like what sember version you were using,

271
00:18:17,120 --> 00:18:20,710
but whether you were on a Mac or a Linux box or

272
00:18:20,720 --> 00:18:23,550
a Windows machine, you had to pull down different packages.

273
00:18:24,770 --> 00:18:28,094
Every software project had a bunch of shell scripts themselves,

274
00:18:28,212 --> 00:18:32,170
and these were calling Biodome. And even Devcube was requiring

275
00:18:32,330 --> 00:18:35,390
kind of a lot of locally installed tools.

276
00:18:36,370 --> 00:18:39,666
And it was especially bad for new developers coming in. I mean,

277
00:18:39,688 --> 00:18:43,006
not too bad, but they really had to do a lot to get their laptops

278
00:18:43,038 --> 00:18:46,802
ready to start developing code. They had to install the AWS,

279
00:18:46,866 --> 00:18:50,486
Cli and terraform and Docker compose and

280
00:18:50,508 --> 00:18:53,622
this compose with a k and a bunch of other things.

281
00:18:53,756 --> 00:18:56,920
And these sprawl was really starting to be a bit much.

282
00:18:58,730 --> 00:19:02,298
Do you remember I mentioned that we also use Gradle as a

283
00:19:02,304 --> 00:19:04,730
build tool for our JVM projects.

284
00:19:05,150 --> 00:19:08,870
So if you're not familiar with Gradle, it's similar to maven

285
00:19:08,950 --> 00:19:12,090
or NPM, or make or cargo.

286
00:19:12,250 --> 00:19:15,070
It's really popular for JVM applications.

287
00:19:16,290 --> 00:19:20,254
It's a neat build tool because it's highly opinionated. It's really easy

288
00:19:20,292 --> 00:19:23,330
to get started developing with Gradle,

289
00:19:23,670 --> 00:19:27,598
but it's also super extensible. And you can use Kotlin

290
00:19:27,694 --> 00:19:31,634
or groovy to build plugins and tasks that

291
00:19:31,672 --> 00:19:35,086
you can run in gradle. And since you can use Kotlin,

292
00:19:35,118 --> 00:19:38,934
that was especially useful for us since we're a Kotlin shop. It gives

293
00:19:38,972 --> 00:19:42,034
us access to rich Java and Kotlin libraries.

294
00:19:42,162 --> 00:19:45,874
And those libraries, of course, you can do anything with these libraries.

295
00:19:45,922 --> 00:19:49,574
There's a ton of them out there now. And one of the key

296
00:19:49,612 --> 00:19:53,226
things that we can do, and that was useful for us is it gives us

297
00:19:53,248 --> 00:19:56,774
access to cloud APIs. So what gradle

298
00:19:56,902 --> 00:20:00,300
ends up doing for us over time, as we

299
00:20:00,830 --> 00:20:04,810
were starting to develop our own plugins and tasks,

300
00:20:04,970 --> 00:20:08,240
is it not only builds and tests and packages code,

301
00:20:09,170 --> 00:20:12,942
it can also pull these plugins that we're developing in our project

302
00:20:12,996 --> 00:20:17,646
that we call ARI. And we can start to do things like authenticate

303
00:20:17,678 --> 00:20:21,154
to code artifact, which isn't a tough thing to do.

304
00:20:21,192 --> 00:20:25,106
And most people just do a shell script to authenticate to code artifact if they

305
00:20:25,128 --> 00:20:28,806
use it as their artifact repository. But we built it as

306
00:20:28,828 --> 00:20:32,338
a task. We can also push

307
00:20:32,354 --> 00:20:36,040
and pull containers, push and pull objects to s three.

308
00:20:36,410 --> 00:20:40,890
We can get a lot of that information about our different AWS environments,

309
00:20:42,110 --> 00:20:45,594
and we can deploy workloads to kubernetes, and we can do

310
00:20:45,632 --> 00:20:49,146
all of this kind of stuff, even opening prs to

311
00:20:49,168 --> 00:20:52,650
GitHub using these native APIs

312
00:20:52,730 --> 00:20:53,920
of those services.

313
00:20:57,970 --> 00:21:01,774
So over time, what we found was that our

314
00:21:01,812 --> 00:21:05,460
old biodome shell script started to become

315
00:21:06,310 --> 00:21:10,180
less necessary overall for our build process.

316
00:21:10,710 --> 00:21:14,126
Over time, we were building a lot of these functionality that biodome

317
00:21:14,158 --> 00:21:17,910
was providing into ARI and into our gradle tasks.

318
00:21:18,330 --> 00:21:22,562
So we made a decision to formally

319
00:21:22,626 --> 00:21:26,470
try and get off of that shell script and start building

320
00:21:26,540 --> 00:21:30,742
the rest of those functions into ARI. And furthermore,

321
00:21:30,806 --> 00:21:34,666
we wanted to abstract all of those custom functions that we were using for

322
00:21:34,688 --> 00:21:38,618
gradle tasks, abstract those into libraries that could be used by

323
00:21:38,704 --> 00:21:42,574
other software applications. And the first software application that

324
00:21:42,612 --> 00:21:46,666
we thought of was a command line utility, sort of like Biodome.

325
00:21:46,698 --> 00:21:50,206
And so we just called it biodome. But this time biodome is

326
00:21:50,228 --> 00:21:55,700
built using Kotlin. So it's a nice CLI and

327
00:21:56,550 --> 00:22:00,142
it generally speaks directly to the APIs

328
00:22:00,206 --> 00:22:04,580
for the services that it manipulates instead of relying a bunch of local

329
00:22:05,270 --> 00:22:09,254
dev tools. So it became easier for

330
00:22:09,372 --> 00:22:12,998
new developers to get on board because they would just

331
00:22:13,084 --> 00:22:16,850
download biodome. And in fact, we've got helpers in Biodome

332
00:22:16,930 --> 00:22:20,394
to help developers install any devtools that they do happen

333
00:22:20,432 --> 00:22:24,074
to need. So the advantages, at least to us,

334
00:22:24,112 --> 00:22:28,406
were super clear. Now we can write all of these build functions

335
00:22:28,438 --> 00:22:32,670
in a strongly typed language that's compose. It's testable,

336
00:22:33,090 --> 00:22:37,214
it's much easier to scale. We can grow this thing to

337
00:22:37,252 --> 00:22:41,306
a very large size, and we know JVM languages can handle

338
00:22:41,498 --> 00:22:44,914
large applications and you can build on top of them.

339
00:22:45,032 --> 00:22:48,786
And we can directly access these cloud API libraries so we can

340
00:22:48,808 --> 00:22:52,302
manipulate AWS and Docker, kubernetes, GitHub,

341
00:22:52,446 --> 00:22:55,858
anything else that comes along. And it's all written in the developer's

342
00:22:55,874 --> 00:22:59,506
own language, in the language of our platform, Kotlin.

343
00:22:59,618 --> 00:23:04,582
So it's accessible to everybody to

344
00:23:04,636 --> 00:23:08,380
use and to manipulate and to add on to, to build on.

345
00:23:10,670 --> 00:23:14,490
Okay, let's come back to our story now. We were talking about Devcube.

346
00:23:15,630 --> 00:23:19,530
So Devcube was a big shell script,

347
00:23:19,870 --> 00:23:22,634
but now it's just a part of Biodome.

348
00:23:22,762 --> 00:23:26,874
We created a subcommand in the new Kotlin based Biodome

349
00:23:27,002 --> 00:23:30,526
called Devcube, and now it's got access to all

350
00:23:30,548 --> 00:23:34,174
these common build functions that we've abstracted out into libraries

351
00:23:34,222 --> 00:23:38,046
in ArI. We have less reliance on local tools,

352
00:23:38,238 --> 00:23:41,902
and it works directly against the Kubernetes and AWS

353
00:23:42,046 --> 00:23:44,654
APIs. It's opinionated,

354
00:23:44,782 --> 00:23:48,146
super simple to use for newcomers, and it's flexible

355
00:23:48,178 --> 00:23:51,574
and extensible, so anybody can go in and add functions to it if they

356
00:23:51,612 --> 00:23:54,726
want. So the new

357
00:23:54,748 --> 00:23:58,730
devcube has a. I'll describe it from a couple of angles.

358
00:23:59,150 --> 00:24:03,174
First, I want to describe the configuration language. The configuration

359
00:24:03,222 --> 00:24:06,902
language is again Yaml, just like Docker compose,

360
00:24:07,046 --> 00:24:10,906
and it looks similar to a Docker compose configuration file,

361
00:24:11,098 --> 00:24:15,120
but it's more tuned to our exact types of services.

362
00:24:15,730 --> 00:24:19,482
So now we define microservices and other dependencies

363
00:24:19,546 --> 00:24:22,966
for our platform apps, but we can abstract

364
00:24:23,018 --> 00:24:26,354
away a lot of common details. Like in

365
00:24:26,392 --> 00:24:30,542
our previous docker compose files, we were defining resource requests

366
00:24:30,606 --> 00:24:34,386
and limits so that as these devcube environments would

367
00:24:34,408 --> 00:24:38,166
come up in kubernetes, we were telling kubernetes how

368
00:24:38,188 --> 00:24:42,162
much memory and cpu we expected those Devcube environments

369
00:24:42,226 --> 00:24:45,366
to take, and that way kubernetes could

370
00:24:45,388 --> 00:24:49,354
auto scale to handle more of these devcube environments coming

371
00:24:49,392 --> 00:24:53,126
up and down. Now we can bake

372
00:24:53,158 --> 00:24:56,694
that into the libraries that we're calling. We've got some sample sizes

373
00:24:56,742 --> 00:24:59,340
or some typical sizes that we expect,

374
00:24:59,790 --> 00:25:03,486
and of course we can still customize it within our YaML file, but a lot

375
00:25:03,508 --> 00:25:06,766
of that stuff we can just assume will be handled in a

376
00:25:06,788 --> 00:25:10,654
rational way by default. There's also a lot of

377
00:25:10,692 --> 00:25:14,394
common environment variables that we'll bake in, and pod

378
00:25:14,442 --> 00:25:17,714
permissions in kubernetes and AWS. We can build that

379
00:25:17,752 --> 00:25:21,026
into our libraries as well, so we can abstract that

380
00:25:21,048 --> 00:25:24,514
away. And for the most part you don't have to specify any of those

381
00:25:24,552 --> 00:25:29,250
details. But if you want you can, because we built some customizability

382
00:25:29,330 --> 00:25:30,280
into it.

383
00:25:32,170 --> 00:25:35,494
Then there's the developer experience. So once you've got all

384
00:25:35,532 --> 00:25:39,162
those Devcube configuration files set

385
00:25:39,216 --> 00:25:42,810
up in all of the repos for our microservices,

386
00:25:43,150 --> 00:25:47,798
a developer working on say service a can just say biodome

387
00:25:47,974 --> 00:25:51,838
devcube up by default that

388
00:25:51,924 --> 00:25:55,790
reads in the config files from all the other dependency repos

389
00:25:57,170 --> 00:26:00,730
and it builds out manifests behind the scenes

390
00:26:00,890 --> 00:26:04,334
and it applies them to kubernetes. So you end up with a devcube environment

391
00:26:04,382 --> 00:26:08,210
that looks just the same as what we had previously,

392
00:26:10,230 --> 00:26:13,666
but there's other options that we can bake in as well.

393
00:26:13,768 --> 00:26:16,806
So we've got an option to do a devcube up,

394
00:26:16,828 --> 00:26:20,146
but bring it up in a local docker compose

395
00:26:20,258 --> 00:26:24,166
like environment. So it just brings up those same containers running in

396
00:26:24,188 --> 00:26:27,814
Docker desktop. Or if you want,

397
00:26:27,932 --> 00:26:31,514
you can also bring it up in a native jvm way, so they'll all

398
00:26:31,552 --> 00:26:35,830
be running on your local machine, but just natively

399
00:26:35,990 --> 00:26:39,030
directly on your metal and not in containers.

400
00:26:39,190 --> 00:26:42,382
And that ends up being kind of a nice way to go if you just

401
00:26:42,436 --> 00:26:45,790
have a couple of microservice dependencies,

402
00:26:46,930 --> 00:26:50,400
because it's simple and lightweight and pretty fast.

403
00:26:51,970 --> 00:26:55,986
We also have a function in there to take snapshots. So you remember

404
00:26:56,088 --> 00:27:00,050
some of these services have their own databases, and they'll bring up those databases

405
00:27:01,270 --> 00:27:05,154
and as you add sample data to it, maybe users and

406
00:27:05,192 --> 00:27:08,606
some sample scan data. You hate to lose

407
00:27:08,638 --> 00:27:11,910
that environment when you bring your devcube down and bring it up the next time.

408
00:27:11,980 --> 00:27:15,158
So we added a snapshot functionality so we can take a

409
00:27:15,164 --> 00:27:18,314
copy of that, store that backup in s these

410
00:27:18,432 --> 00:27:22,070
and you can select which backup you want to use or by default

411
00:27:22,150 --> 00:27:27,258
there's just a default name for your default snapshot and

412
00:27:27,424 --> 00:27:29,530
it's great, it's really handy.

413
00:27:31,170 --> 00:27:35,114
But in addition to that biodome command, the Biodome devcube

414
00:27:35,162 --> 00:27:38,718
command now we can do devcube like things and other

415
00:27:38,804 --> 00:27:43,122
functions in gradle. So now

416
00:27:43,256 --> 00:27:47,294
gradle can deploy devcubes, and those can be super handy

417
00:27:47,422 --> 00:27:50,686
as ephemeral iterations, test environments, for instance,

418
00:27:50,878 --> 00:27:55,326
or to deploy static environments for user acceptance testing.

419
00:27:55,518 --> 00:27:58,806
And we can also use these to create a

420
00:27:58,828 --> 00:28:03,010
bunch of manifests for deployment with argo CD or flux CD.

421
00:28:03,090 --> 00:28:06,194
So this can be a way for our applications

422
00:28:06,242 --> 00:28:09,866
to generate their own installer manifests that can be

423
00:28:09,888 --> 00:28:15,050
used by cloud native tools that expect to be working with those sorts of manifests.

424
00:28:18,190 --> 00:28:21,466
And what we had come across or what we had developed

425
00:28:21,498 --> 00:28:25,246
here was really a larger internal developer platform that was

426
00:28:25,268 --> 00:28:29,934
based on our own Kotlin code, reaching out to well

427
00:28:29,972 --> 00:28:33,634
established APIs for AWS and kubernetes and all these other

428
00:28:33,752 --> 00:28:37,666
cloud native services. And it was

429
00:28:37,768 --> 00:28:41,330
great because it was really allowed to our engineers and environments.

430
00:28:41,910 --> 00:28:45,506
It was built with knowledge about the way we do things and the

431
00:28:45,528 --> 00:28:49,458
way our developers like to work. And it was easy for newcomers

432
00:28:49,474 --> 00:28:52,886
to come in and just start using this tool, but it was

433
00:28:52,908 --> 00:28:56,598
also easy to add on to, and all of us can add on to it,

434
00:28:56,684 --> 00:28:59,980
including the developers. And it just made sense.

435
00:29:02,590 --> 00:29:06,426
And we've thought about directions that we can go in the

436
00:29:06,448 --> 00:29:09,722
future with Biodome and Devcube took. So some

437
00:29:09,776 --> 00:29:13,438
potential enhancements that we've been talking about, or at

438
00:29:13,444 --> 00:29:17,242
least I've been talking about, are why not add a web UI

439
00:29:17,386 --> 00:29:21,038
and get quick access to some of the common operations that

440
00:29:21,124 --> 00:29:24,698
are available in our library in Ari?

441
00:29:24,874 --> 00:29:28,694
So we could create UAT dev cubes

442
00:29:28,762 --> 00:29:32,082
for product. So maybe product could come along and

443
00:29:32,136 --> 00:29:36,180
spin up their own UAT environment for tests that they want to do.

444
00:29:36,490 --> 00:29:40,034
Or maybe product support could use Devcubes

445
00:29:40,082 --> 00:29:43,654
for troubleshooting. They could set up an entire platform and an

446
00:29:43,692 --> 00:29:47,754
entire scanner environment so that they could run some tests and run some

447
00:29:47,792 --> 00:29:51,034
experiments. We could also create

448
00:29:51,152 --> 00:29:54,534
crds and controllers to manage our Devcube

449
00:29:54,582 --> 00:29:58,300
environments. And one idea that came up pretty quickly was

450
00:29:58,830 --> 00:30:02,250
with some of the new functionality that we have for Devcube,

451
00:30:03,230 --> 00:30:06,634
it's possible that developers will spin up more than one

452
00:30:06,672 --> 00:30:10,334
apiece. They might spin up several. And over time that could

453
00:30:10,372 --> 00:30:13,714
be wasteful. So we might want to have a process that just runs and

454
00:30:13,752 --> 00:30:17,922
watches for Devcube environments that have been around for too long,

455
00:30:18,056 --> 00:30:21,860
maybe take a snapshot of them for safety and bring them down.

456
00:30:23,030 --> 00:30:26,246
Were also thought about other functions that we can use to

457
00:30:26,428 --> 00:30:29,426
provision other kinds of resources for developers.

458
00:30:29,618 --> 00:30:33,350
For instance, when we come up with a new microservice,

459
00:30:34,330 --> 00:30:37,842
there's a whole setup process for setting up the new repo

460
00:30:37,906 --> 00:30:41,942
and the associated build pipelines and it's automated

461
00:30:42,006 --> 00:30:45,610
enough. We use terraform to do that, but it's still some work.

462
00:30:45,760 --> 00:30:49,254
Why not just have a gradle command or a biodome

463
00:30:49,302 --> 00:30:52,782
command that just creates that repo and creates those build

464
00:30:52,836 --> 00:30:57,182
pipelines. When we go to push new

465
00:30:57,236 --> 00:31:00,590
containers to ECR repos, we have to create

466
00:31:00,660 --> 00:31:04,480
these ECR repos. Again, we use terraform to do that and

467
00:31:05,410 --> 00:31:09,246
it doesn't take that long, but it takes a little bit of work encoding

468
00:31:09,278 --> 00:31:12,930
to do and it's not all that dry. So we

469
00:31:13,000 --> 00:31:16,642
actually have done this. We've created a function that whenever you use

470
00:31:16,696 --> 00:31:20,674
gradle to go and push a container to an ECR

471
00:31:20,722 --> 00:31:24,786
repo, first thing it does is check to see if that ECR repo

472
00:31:24,818 --> 00:31:28,300
exists, and if it doesn't, it just creates it for you.

473
00:31:29,070 --> 00:31:32,874
Just a huge time saver. But why not

474
00:31:32,992 --> 00:31:36,794
also make functions available for developers to be able to create their

475
00:31:36,832 --> 00:31:40,638
own eks clusters, create these own Kubernetes clusters that

476
00:31:40,644 --> 00:31:44,830
they can use to test without fear of damaging any of the other environments?

477
00:31:47,410 --> 00:31:50,766
Well, that's our developer tool story, and of

478
00:31:50,788 --> 00:31:54,302
course it's not over yet. We ended up building

479
00:31:54,356 --> 00:31:57,860
an IDP that really helps our developers get on board fast,

480
00:31:58,310 --> 00:32:02,242
focus on their work, and take part in building more functionality into it

481
00:32:02,296 --> 00:32:06,466
themselves, since it's written in Kotlin, which is what

482
00:32:06,488 --> 00:32:09,814
they know. When we look back at all the efforts we put

483
00:32:09,852 --> 00:32:13,366
in, I think everybody at Stackhawk would agree that it

484
00:32:13,388 --> 00:32:16,854
was really worth it. It's been a huge enabler, not only

485
00:32:16,892 --> 00:32:20,374
for developers, but for the product team and for our ability

486
00:32:20,422 --> 00:32:24,234
to quickly deliver and iterate. I hope that our story is

487
00:32:24,272 --> 00:32:28,166
helpful for you and on your developer

488
00:32:28,198 --> 00:32:29,660
tools journey as well.

489
00:32:31,870 --> 00:32:35,454
And I want to take a moment to thank all of the developers at

490
00:32:35,492 --> 00:32:38,478
Stackhawk. Everybody really took part in this project.

491
00:32:38,564 --> 00:32:42,202
And just to call out a couple Casey is our chief

492
00:32:42,266 --> 00:32:45,874
architect. He really has been a champion for investing in

493
00:32:45,912 --> 00:32:48,980
our local build tools and doing it right.

494
00:32:49,990 --> 00:32:54,206
Sam Boland is our full stack engineer, and he's been a massive contributor

495
00:32:54,238 --> 00:32:58,066
to the whole effort. Topher Lamey started us

496
00:32:58,088 --> 00:33:02,038
down the path of using gradle plugins and it's just paid off

497
00:33:02,124 --> 00:33:05,554
handsomely. And Brandon Ward is a new software engineer

498
00:33:05,602 --> 00:33:09,654
who came in recently, but he had a bunch of great ideas for

499
00:33:09,772 --> 00:33:13,378
how to build good tools for developers.

500
00:33:13,554 --> 00:33:17,206
Then finally Scott Gerlock, who inspired us to build a

501
00:33:17,228 --> 00:33:20,814
really solid, scalable, secure platform on cloud

502
00:33:20,852 --> 00:33:24,506
native technologies so that our laptops would never be a roadblock

503
00:33:24,538 --> 00:33:28,750
to success and thank you so much to all of you here

504
00:33:28,820 --> 00:33:32,080
at Cloud native, and thanks for watching.

505
00:33:32,530 --> 00:33:32,940
Take care.

