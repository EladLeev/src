1
00:00:00,250 --> 00:00:04,830
Are youve an SRe? A developer,

2
00:00:06,610 --> 00:00:10,474
a quality engineer who wants to tackle the challenge of improving

3
00:00:10,522 --> 00:00:14,026
reliability in your DevOps? You can enable your DevOps

4
00:00:14,058 --> 00:00:17,854
for reliability with chaos native. Create your free

5
00:00:17,892 --> 00:01:17,046
account at Chaos native. Litmus cloud hi

6
00:01:17,068 --> 00:01:20,294
folks, I am Dan, and today I'm going to be talking to you

7
00:01:20,332 --> 00:01:24,006
about how to achieve reliability nirvana. And we

8
00:01:24,028 --> 00:01:27,030
will do that by utilizing event driven design.

9
00:01:27,180 --> 00:01:29,580
So let's get to it.

10
00:01:30,430 --> 00:01:33,782
First things first, let me just give you a quick disclaimer.

11
00:01:33,846 --> 00:01:37,530
So everything that I talk about I have done in production,

12
00:01:37,870 --> 00:01:42,220
none of this is theoretical. This is stuff that I have personally done.

13
00:01:42,910 --> 00:01:46,382
And if I haven't done some of it either in production or

14
00:01:46,436 --> 00:01:49,038
maybe I've just done it in staging, I will let you know that that's the

15
00:01:49,044 --> 00:01:51,360
case. I also try to keep it real,

16
00:01:52,130 --> 00:01:55,738
meaning that if there is something that is really difficult, I will let

17
00:01:55,764 --> 00:01:59,362
you know that it's actually difficult. And some of the stuff that looks difficult,

18
00:01:59,416 --> 00:02:02,980
it is actually easy. I'll let you know about that, too. Really,

19
00:02:03,510 --> 00:02:07,046
the final piece is that my own personal goal for this

20
00:02:07,068 --> 00:02:10,466
talk is that I just want you to walk away having learned

21
00:02:10,498 --> 00:02:14,034
something, right? Just have something tangible

22
00:02:14,162 --> 00:02:17,366
at the end of a talk. So with

23
00:02:17,388 --> 00:02:23,114
that said, let me talk about myself first, because every

24
00:02:23,152 --> 00:02:26,858
single talk is supposed to have at least one slide about the presenter. So let

25
00:02:26,864 --> 00:02:30,342
me be a little self indulgent here. So I am Dan.

26
00:02:30,406 --> 00:02:33,614
I reside in Portland, Oregon. I have worked in the back end for

27
00:02:33,652 --> 00:02:37,166
about ten years, probably more this point. I've been saying that

28
00:02:37,188 --> 00:02:40,526
ten years for a while. So I

29
00:02:40,548 --> 00:02:44,026
love building and operating distributed systems. I figured

30
00:02:44,058 --> 00:02:47,442
out a while ago that I'm really into the architecture part

31
00:02:47,496 --> 00:02:51,154
and the design portions of distributed systems. It's really fun

32
00:02:51,192 --> 00:02:54,674
and really interesting. I was previously an SRE at

33
00:02:54,712 --> 00:02:58,482
Neurelic. I was an SE at Envision

34
00:02:58,546 --> 00:03:02,102
Digitalocean community. I also spent a lot of time in data centers as well,

35
00:03:02,236 --> 00:03:05,990
basically wiring stuff up well, gluing things together,

36
00:03:06,060 --> 00:03:08,886
really, between systems and software.

37
00:03:09,078 --> 00:03:12,410
And most recently, I co founded a company called Batch,

38
00:03:12,990 --> 00:03:16,486
and we focus on basically providing observability

39
00:03:16,598 --> 00:03:20,650
for data that is usually found

40
00:03:20,720 --> 00:03:24,582
on high throughput systems such as Kafka or RabbitmQ,

41
00:03:24,646 --> 00:03:28,174
et cetera, essentially message brokers. And cool fact

42
00:03:28,212 --> 00:03:30,830
is that we got into Y combinator, which is pretty sweet.

43
00:03:31,730 --> 00:03:34,994
And one fact that you can immediately take away with you is that I am

44
00:03:35,032 --> 00:03:39,262
originally from Latvia and there are at least literally

45
00:03:39,326 --> 00:03:42,750
dozens of us that like distributed systems

46
00:03:42,830 --> 00:03:46,034
and are from Latvia. So there you go. You've already

47
00:03:46,072 --> 00:03:49,686
got one thing, you know. All right, so what

48
00:03:49,708 --> 00:03:51,830
is reliability nirvana?

49
00:03:52,250 --> 00:03:55,462
Well, it is not being woken up at 03:00 a.m. On Saturday night

50
00:03:55,516 --> 00:03:58,646
or really any night at 03:00 a.m. I do not

51
00:03:58,668 --> 00:04:02,054
want to be woken up at all. We want to have predictable service failure

52
00:04:02,102 --> 00:04:05,846
scenarios. We want to have well defined service boundaries.

53
00:04:06,038 --> 00:04:09,514
We want to be security conscious. We want to have self

54
00:04:09,552 --> 00:04:14,058
healing services, and we want to be highly scalable and highly reliable.

55
00:04:14,154 --> 00:04:18,142
Of course, now you might be saying that, well, we already

56
00:04:18,196 --> 00:04:21,710
have this whatever tech. And yeah,

57
00:04:21,780 --> 00:04:25,950
you're right, we do. We have the microservices pattern

58
00:04:26,550 --> 00:04:29,986
that deals with the monolith problem that we've had of being able

59
00:04:30,008 --> 00:04:33,774
to decouple things and basically slice them up. And after we slice

60
00:04:33,822 --> 00:04:37,218
them up, we slice them into containers, which is perfect. We're now able to

61
00:04:37,224 --> 00:04:40,934
have reproducible builds. We have a really nice dev flow because

62
00:04:40,972 --> 00:04:44,374
everything is in a container. Now. We can make use of container orchestration, such as

63
00:04:44,412 --> 00:04:48,506
kubernetes or mesos and so on, to tackle all

64
00:04:48,528 --> 00:04:52,230
the concerns around lifecycles. Right, the lifecycle

65
00:04:52,310 --> 00:04:55,814
of a service. And then we have things like a service mesh,

66
00:04:55,862 --> 00:04:59,226
like service meshes which ensure that our services are able

67
00:04:59,248 --> 00:05:02,746
to talk to each other correctly and so on. And there's probably a whole slew

68
00:05:02,778 --> 00:05:07,086
of other things that you might have that

69
00:05:07,108 --> 00:05:10,222
are going to help you achieve even better reliability as well,

70
00:05:10,276 --> 00:05:14,798
such as, say, APM solutions like new Relic and Datadog

71
00:05:14,894 --> 00:05:18,386
and honeycomb and logging platforms and

72
00:05:18,408 --> 00:05:22,466
so on. There's really a ton of stuff like tracing, right? Like request tracing and

73
00:05:22,488 --> 00:05:25,922
so on. Things have gotten pretty good

74
00:05:25,976 --> 00:05:29,634
overall. Really? Right. So what is the overall problem if things

75
00:05:29,672 --> 00:05:33,094
are already pretty great? Well, the issue is that

76
00:05:33,132 --> 00:05:35,734
if you want to go a little bit higher, if you want to go and

77
00:05:35,772 --> 00:05:39,242
basically take the next step and you want to achieve even higher

78
00:05:39,296 --> 00:05:42,890
reliability, it gets exponentially harder.

79
00:05:45,950 --> 00:05:47,770
It gets exponentially harder.

80
00:05:49,470 --> 00:05:52,522
Case in point, if we're just talking about the microservices pattern

81
00:05:52,586 --> 00:05:56,842
itself, if you have, I don't know, 2030 microservices

82
00:05:56,906 --> 00:06:00,414
or something like that, you have a

83
00:06:00,452 --> 00:06:03,886
massive failure domain. You actually have no idea how

84
00:06:03,908 --> 00:06:07,794
big of your failure domain is because one service might actually take

85
00:06:07,832 --> 00:06:11,218
down six other services and cause three other services

86
00:06:11,304 --> 00:06:14,654
to become really, really slow and so on. So the usual

87
00:06:14,702 --> 00:06:18,078
approach to solving this sort of a thing is to say, well, we're just going

88
00:06:18,104 --> 00:06:21,446
to employ circuit breakers everywhere. But as it turns out,

89
00:06:21,548 --> 00:06:24,742
with circuit breakers, it is really easy to shoot yourself

90
00:06:24,796 --> 00:06:28,920
in the foot as well. And they're notoriously difficult to configure and get right

91
00:06:29,290 --> 00:06:32,534
it's not. The fact that circuit breakers are difficult to actually implement,

92
00:06:32,582 --> 00:06:36,394
it's to get them right is actually really hard. For those of you

93
00:06:36,432 --> 00:06:39,802
not familiar with Histrix Histrix style circuit breakers, the idea

94
00:06:39,856 --> 00:06:43,386
is basically, they're essentially patterns,

95
00:06:43,498 --> 00:06:46,762
code patterns to introduce

96
00:06:46,826 --> 00:06:49,280
fault tolerance into your requests, right?

97
00:06:50,690 --> 00:06:53,070
So when you're making an HTTP request,

98
00:06:53,510 --> 00:06:56,914
if it fails, then it's going to be retried automatically for you

99
00:06:56,952 --> 00:07:00,450
exponentially for however many times

100
00:07:00,520 --> 00:07:03,060
with an exponential backup and so on.

101
00:07:03,910 --> 00:07:07,670
In my experience, when it's been done, it is

102
00:07:07,820 --> 00:07:11,346
very easy to not get it right. And in some cases

103
00:07:11,458 --> 00:07:15,602
the shooting yourself in the foot part is basically misconfiguring

104
00:07:15,666 --> 00:07:19,138
in such a way that basically that it trips when it's

105
00:07:19,154 --> 00:07:23,034
not supposed to. So when the service is not actually down, something will

106
00:07:23,072 --> 00:07:26,522
happen and will cause it to trip and thus real

107
00:07:26,576 --> 00:07:29,786
requests are going to get dropped. And at the same time you also have

108
00:07:29,808 --> 00:07:33,158
to figure out how to avoid cascading failures. But the good

109
00:07:33,184 --> 00:07:36,990
news is that there's always somebody who is going to say, well, my service

110
00:07:37,060 --> 00:07:41,006
knows how to deal with that and it's going to prevent everything else after it

111
00:07:41,108 --> 00:07:44,734
from failing in a cascading fashion,

112
00:07:44,862 --> 00:07:48,974
which is of course totally not true. And whoever

113
00:07:49,022 --> 00:07:52,210
that is, their service g is actually maybe

114
00:07:52,280 --> 00:07:55,282
not that great. So at the same time,

115
00:07:55,336 --> 00:07:58,486
we also want some sort of self healing right at

116
00:07:58,508 --> 00:08:01,734
the service level, meaning that just because

117
00:08:01,772 --> 00:08:05,202
we have auto scale in place, what happens to that request,

118
00:08:05,266 --> 00:08:08,354
which was mid flight in the middle of the auto scale

119
00:08:08,402 --> 00:08:11,818
event, does it get just dropped? And are we just simply okay

120
00:08:11,904 --> 00:08:15,770
with the 0.2% of a failure rate that we're having because

121
00:08:15,840 --> 00:08:20,682
of a deployment or something like that? So that

122
00:08:20,736 --> 00:08:23,822
by itself already is hard to achieve as well.

123
00:08:23,956 --> 00:08:26,990
And at the same time, you need to keep security in mind.

124
00:08:27,140 --> 00:08:31,040
And as we all know, pms just absolutely youve

125
00:08:31,570 --> 00:08:35,074
it when you are spending time on not shipping features and just

126
00:08:35,112 --> 00:08:39,422
working on something that may seem to them as kind of useless.

127
00:08:39,566 --> 00:08:42,994
So point being that getting to that

128
00:08:43,032 --> 00:08:46,786
next level afterwards is really hard. It's akin

129
00:08:46,818 --> 00:08:50,834
to moving from vms over to containers

130
00:08:50,882 --> 00:08:54,246
for the first time. It's a fairly big deal at that point.

131
00:08:54,348 --> 00:08:58,214
There's not unfortunately like some sort of a silver bullet which is just going

132
00:08:58,252 --> 00:09:02,506
to automatically solve all these problems. So what

133
00:09:02,528 --> 00:09:05,754
you might be seeing here is that there is a pattern is starting to

134
00:09:05,792 --> 00:09:10,060
evolve, like emerge here. We're talking really about services.

135
00:09:10,510 --> 00:09:14,266
It seems like the infrastructure part and the platform components

136
00:09:14,298 --> 00:09:18,202
and so on, they're actually fine. There's nothing really inherently

137
00:09:18,266 --> 00:09:21,834
wrong with them as a matter of fact, the microservice pattern

138
00:09:21,882 --> 00:09:25,106
is great. Kubernetes is great, Docker is great. All these

139
00:09:25,128 --> 00:09:28,770
things are really fantastic. So the place

140
00:09:28,840 --> 00:09:32,354
where we need to put a focus on is on the services themselves.

141
00:09:32,472 --> 00:09:35,746
So how would we achieve that? Well, we would want

142
00:09:35,768 --> 00:09:39,934
to have some sort of a solution which ensures that maybe the services shouldn't

143
00:09:39,982 --> 00:09:43,206
rely on each other anymore, meaning that service a does not have to talk

144
00:09:43,228 --> 00:09:46,934
to service b. And as a matter of fact, none of them should do that

145
00:09:46,972 --> 00:09:50,506
at all. Right. We would also want a situation

146
00:09:50,608 --> 00:09:54,454
so that developers do not have to write code specifically

147
00:09:54,502 --> 00:09:58,282
to be able to deal with a situation where the server is coming

148
00:09:58,336 --> 00:10:01,930
back after it has dropped a bunch of requests.

149
00:10:02,010 --> 00:10:05,806
Right. Not having to write these sort

150
00:10:05,828 --> 00:10:09,566
of fairly complex fault tolerance systems and so on in

151
00:10:09,588 --> 00:10:13,294
place. Similarly, we do not

152
00:10:13,332 --> 00:10:16,706
want sres. What would be really awesome is that if sres did not have

153
00:10:16,728 --> 00:10:20,334
to write any sort of per service firewall rules and just punching holes

154
00:10:20,382 --> 00:10:23,954
in different places whenever service e needs

155
00:10:23,992 --> 00:10:27,266
to talk to service x and so on and so on, it would

156
00:10:27,288 --> 00:10:30,646
be nice to just be able to put a blanket rule down and it

157
00:10:30,668 --> 00:10:32,760
just simply works right.

158
00:10:34,330 --> 00:10:37,446
And then on top of that, it doesn't even have to be touched again at

159
00:10:37,468 --> 00:10:40,938
some point in time. A nice bonus to all of

160
00:10:40,944 --> 00:10:44,922
this would be that we would be able to investigate every single state change

161
00:10:44,976 --> 00:10:49,386
that takes place as part of a

162
00:10:49,408 --> 00:10:52,394
single request. To some extent we can already do that,

163
00:10:52,432 --> 00:10:56,314
because if we have request tracing and so on, you could potentially

164
00:10:56,362 --> 00:11:00,106
do that. But again, it's one of those solutions where while not everyone has request

165
00:11:00,138 --> 00:11:03,438
tracing, it would be nice if something just basically came

166
00:11:03,524 --> 00:11:06,930
for free, that we were just able to get it. And finally,

167
00:11:07,000 --> 00:11:10,770
a really big one is that it would be super awesome that all this

168
00:11:10,840 --> 00:11:15,134
really concrete, very specific systems

169
00:11:15,182 --> 00:11:19,094
data that is flowing from somewhere which is representative of the

170
00:11:19,132 --> 00:11:22,774
current system state would be available ultimately for

171
00:11:22,892 --> 00:11:26,326
your future analytics uses. So, meaning maybe you don't have

172
00:11:26,348 --> 00:11:29,734
a data science team right now, but maybe you will have in about six months

173
00:11:29,772 --> 00:11:33,450
or something like that, being able to show them that, hey,

174
00:11:33,520 --> 00:11:37,210
you can hook into here and you can see all the messages that are there.

175
00:11:37,360 --> 00:11:40,650
Everything that's ever transpired on our systems would be super awesome

176
00:11:40,720 --> 00:11:44,266
because they could then actually build various systems to analyze

177
00:11:44,298 --> 00:11:47,626
the data, predict things and so on, and create dashboards

178
00:11:47,658 --> 00:11:51,326
and whatever other cool stuff that data science teams do. I'm not

179
00:11:51,348 --> 00:11:54,900
a data scientist, as it turns out. This is kind of what I do instead.

180
00:11:55,830 --> 00:12:00,126
So what you might be noticing here is that reliability nirvana

181
00:12:00,158 --> 00:12:04,162
is actually not just service reliability or

182
00:12:04,216 --> 00:12:07,474
systems reliability. It's actually effortless

183
00:12:07,522 --> 00:12:10,726
service reliability. We want something that is able

184
00:12:10,748 --> 00:12:14,742
to go the next step where I do not have to spend time

185
00:12:14,876 --> 00:12:18,950
building something that is just for a singular purpose only,

186
00:12:19,020 --> 00:12:22,998
such as implementing some sort of a circuit breaker pattern.

187
00:12:23,094 --> 00:12:26,474
Well that gets me closer to better reliability. But it's not the end

188
00:12:26,512 --> 00:12:29,478
all be all. It is just one piece of the puzzle.

189
00:12:29,654 --> 00:12:33,158
And what youve might be seeing here is that what I'm going towards is

190
00:12:33,184 --> 00:12:37,006
that there kind of is a solution which is able to address all of

191
00:12:37,028 --> 00:12:40,190
those things. It is not easy by any means. However,

192
00:12:40,260 --> 00:12:43,482
it does exist and it is totally doable.

193
00:12:43,626 --> 00:12:47,282
You can actually implement it and it is totally possible. But there are certainly

194
00:12:47,336 --> 00:12:50,834
some caveats and that's the sort of stuff we're going to get into. But before

195
00:12:50,872 --> 00:12:55,206
we do that, let's define what

196
00:12:55,228 --> 00:12:58,818
is event driven, right? So the Wikipedia article,

197
00:12:58,994 --> 00:13:02,226
the Wikipedia definition says the software and systems

198
00:13:02,258 --> 00:13:03,670
architecture paradigm.

199
00:13:06,570 --> 00:13:10,186
The Wikipedia entry defines event driven as software and

200
00:13:10,208 --> 00:13:13,622
systems architectures paradigm, promoting the production, detection,

201
00:13:13,686 --> 00:13:16,010
consumption and reaction to events.

202
00:13:16,510 --> 00:13:20,640
So really what it means is that really

203
00:13:21,010 --> 00:13:24,714
there's just three actions here. It's something emits

204
00:13:24,762 --> 00:13:28,542
an event or a message. Something, oh,

205
00:13:28,596 --> 00:13:31,200
I added an extra slide, sorry about that.

206
00:13:32,210 --> 00:13:35,998
Something emits an event, something consumes an event and something reacts

207
00:13:36,014 --> 00:13:38,180
to an event or a message, right?

208
00:13:38,710 --> 00:13:42,194
That's essentially all there is to it. And it's always going in that

209
00:13:42,232 --> 00:13:45,170
pattern after the reaction.

210
00:13:46,810 --> 00:13:50,306
It might not emit an event, but it might just simply

211
00:13:50,418 --> 00:13:54,950
continue consuming an event and so on, consuming other events.

212
00:13:55,930 --> 00:13:59,446
Secondly, your event must be the source

213
00:13:59,478 --> 00:14:03,290
of truth. This is an extremely important aspect of

214
00:14:03,360 --> 00:14:07,562
event driven, is that you no longer want the entire

215
00:14:07,696 --> 00:14:11,306
system to know, like all of your services to

216
00:14:11,328 --> 00:14:15,262
know the entire state of the entire system. You want your

217
00:14:15,316 --> 00:14:19,054
one particular service to only know its own state and it shouldn't care

218
00:14:19,092 --> 00:14:22,606
about any of the states of anything else happening. As a matter of fact,

219
00:14:22,628 --> 00:14:26,354
there shouldn't be a single service that knows the entire state of anything. It should

220
00:14:26,392 --> 00:14:30,690
be just made up of single services that

221
00:14:30,760 --> 00:14:34,034
only know about their own state and nobody else's. That is

222
00:14:34,072 --> 00:14:38,134
an extremely important point. You of course want to communicate all

223
00:14:38,172 --> 00:14:41,222
your events through a message bus of some sort,

224
00:14:41,276 --> 00:14:44,450
like a broker, kafka, rabbit, MQTT,

225
00:14:44,530 --> 00:14:47,942
whatever it is. Another super

226
00:14:47,996 --> 00:14:51,446
important point is that you want everything to be completely item potent.

227
00:14:51,558 --> 00:14:54,506
And that sounds complicated, but it's really not.

228
00:14:54,688 --> 00:14:58,538
All it basically means is that your services are able to deal with

229
00:14:58,704 --> 00:15:02,314
situations where it might receive a duplicate event and

230
00:15:02,352 --> 00:15:05,662
it might receive a couple of events that have come out of order.

231
00:15:05,796 --> 00:15:09,338
And the way you deal with that is you simply keep track of the events

232
00:15:09,354 --> 00:15:12,960
that you've taken care of already. And if it's the same event

233
00:15:13,970 --> 00:15:17,634
coming through again, well, you just ignore it. And if

234
00:15:17,672 --> 00:15:20,834
it's coming out of order, well, then you apply business logic to that.

235
00:15:20,872 --> 00:15:25,006
Do you care that it's an older event or that's

236
00:15:25,038 --> 00:15:28,706
appearing after your future event has already happened? Maybe you don't.

237
00:15:28,738 --> 00:15:31,990
So you could just simply discard it. It's not terribly difficult

238
00:15:32,060 --> 00:15:35,686
to pull it off, and it sounds much more

239
00:15:35,708 --> 00:15:39,580
impressive, really, as written down, than it actually is.

240
00:15:40,030 --> 00:15:43,770
And ultimately, you must be okay with eventual consistency.

241
00:15:45,070 --> 00:15:48,474
It is just a fact here is

242
00:15:48,512 --> 00:15:52,030
that you're essentially trading

243
00:15:52,770 --> 00:15:56,862
really high availability and high reliability for

244
00:15:56,916 --> 00:16:00,634
this eventual consistency thing, and you're basically exchanging

245
00:16:00,682 --> 00:16:03,906
one thing for another. In this case, you will

246
00:16:03,928 --> 00:16:08,318
no longer be able to say that you have guaranteed consistency

247
00:16:08,414 --> 00:16:14,226
because you do not. You will probably have 99.99%

248
00:16:14,328 --> 00:16:17,586
consistency. However, there is no longer a

249
00:16:17,608 --> 00:16:21,494
way for you to guarantee that. You can just simply say that right

250
00:16:21,532 --> 00:16:25,286
now the system is mostly correct. But there's no

251
00:16:25,308 --> 00:16:28,986
way to say that it's 100% correct all the time. You just know that it

252
00:16:29,008 --> 00:16:33,158
will eventually become correct. So the components

253
00:16:33,174 --> 00:16:36,860
that actually make up an event driven system, of course

254
00:16:37,230 --> 00:16:41,310
there's an event, but the event bus of

255
00:16:41,380 --> 00:16:44,720
my choice would be Rabbit MQ 100% of the time.

256
00:16:45,410 --> 00:16:48,894
Well, 95% of the time. Let's say

257
00:16:48,932 --> 00:16:52,458
that Rabbit MQ is, for the

258
00:16:52,484 --> 00:16:53,300
most part,

259
00:16:55,350 --> 00:16:59,140
what are the event driven components? So the event driven components, of course.

260
00:17:01,110 --> 00:17:02,100
Hold on.

261
00:17:16,410 --> 00:17:21,426
So let's explore the event driven components, or let's

262
00:17:21,458 --> 00:17:25,146
explore what makes up an event driven system. Let's look at

263
00:17:25,168 --> 00:17:28,746
all the components that are involved. So, number one, of course there is an

264
00:17:28,768 --> 00:17:33,020
event bus. I would 100% choose RabbitMQ for this.

265
00:17:33,630 --> 00:17:37,226
RabbitMQ is extremely versatile when it

266
00:17:37,248 --> 00:17:40,974
comes to the sort of things you can do with it, rather than having

267
00:17:41,012 --> 00:17:44,446
to reinvent certain functionality, such as, let's say if

268
00:17:44,468 --> 00:17:48,938
you took another message broker, let's say like Kafka,

269
00:17:49,114 --> 00:17:52,226
you would probably have to basically build a lot of your

270
00:17:52,248 --> 00:17:56,046
own stuff. For example, dead lettering.

271
00:17:56,158 --> 00:17:59,380
That doesn't really exist in Kafka, so you would have to build it yourself.

272
00:18:00,070 --> 00:18:03,846
Routing based on headers. That sort of a thing doesn't exist in

273
00:18:03,868 --> 00:18:08,102
Kafka, but it definitely does exist in RabbitMQ. So by

274
00:18:08,156 --> 00:18:12,082
utilizing something with such a versatile

275
00:18:12,146 --> 00:18:16,646
way to do routing and just utilizing

276
00:18:16,678 --> 00:18:20,634
a system that has so many different features is not

277
00:18:20,672 --> 00:18:24,298
going to pigeonhole you into designing a foundation that

278
00:18:24,384 --> 00:18:27,198
might be a little less than perfect.

279
00:18:27,364 --> 00:18:30,894
Besides that, Rabbit MQ is decently fast.

280
00:18:31,012 --> 00:18:34,670
It's able to do upwards of around 20,000 messages a second,

281
00:18:34,820 --> 00:18:38,078
which is not too bad. I think it's fine,

282
00:18:38,244 --> 00:18:41,842
especially for something that serves as your internal event

283
00:18:41,896 --> 00:18:45,666
bus. Essentially, if you needed more than that,

284
00:18:45,768 --> 00:18:49,358
then you would probably have to go to something else. And RabbitMQ unfortunately

285
00:18:49,454 --> 00:18:53,134
is not distributed. You can scale

286
00:18:53,182 --> 00:18:56,526
it pretty much vertically before youve going to have to go to sharding.

287
00:18:56,558 --> 00:18:59,078
So at that point in time you probably may want to look at some of

288
00:18:59,084 --> 00:19:02,726
the tech, but for all intents and purposes, in most cases, folks that think that

289
00:19:02,748 --> 00:19:06,490
they need Kafka, they probably don't need Kafka, they probably can go with Rabbit.

290
00:19:07,070 --> 00:19:10,342
You're also going to want to have some sort of a config layer

291
00:19:10,486 --> 00:19:14,474
or a caching layer, and that is basically going to serve the purpose for

292
00:19:14,592 --> 00:19:18,326
each service. It's going to be like essentially a dumping

293
00:19:18,358 --> 00:19:21,742
ground for each one of your services to be able to write

294
00:19:21,796 --> 00:19:26,046
some sort of intermediate state to it, right? So as

295
00:19:26,068 --> 00:19:28,810
a service, when we're talking about for instance, even item potency,

296
00:19:28,890 --> 00:19:32,702
the services will want to record at some intervals that like oh,

297
00:19:32,756 --> 00:19:35,938
these are the messages that I've already processed so that in the case that the

298
00:19:35,944 --> 00:19:39,698
service gets restarted, it is going to be able to pick up right where it

299
00:19:39,784 --> 00:19:42,334
left off at for this purpose.

300
00:19:42,462 --> 00:19:46,790
SCD is fantastic for it, etCD is distributed.

301
00:19:47,130 --> 00:19:50,520
It is really rock solid. When I say

302
00:19:51,690 --> 00:19:54,774
highly latency resilient, what it really

303
00:19:54,812 --> 00:19:58,426
means is that you can stick them with 100

304
00:19:58,448 --> 00:20:02,006
and 5200 milliseconds of latency between links and ETCD

305
00:20:02,038 --> 00:20:06,262
is going to survive without any issues whatsoever. It is decently

306
00:20:06,326 --> 00:20:10,206
fast. It says that it's about 20,000 messages a

307
00:20:10,228 --> 00:20:13,886
second. I have never seen an ETCD with 20,000 messages a

308
00:20:13,908 --> 00:20:17,098
second. But let's just say it's

309
00:20:17,114 --> 00:20:20,462
probably not what youve should be shooting for anyways. You should be shooting for probably

310
00:20:20,516 --> 00:20:23,986
even under 1000 a second. And the other thing is

311
00:20:24,008 --> 00:20:27,118
that eTCD is used heavily

312
00:20:27,214 --> 00:20:30,802
by Kubernetes. So the chances of it going away are

313
00:20:30,936 --> 00:20:34,500
pretty much, well next to nothing at this point.

314
00:20:35,430 --> 00:20:39,314
You're also going to want to have someplace to store all of your events.

315
00:20:39,362 --> 00:20:42,534
Everything that has ever happened on your Rabbit MQ, you're going to want to but

316
00:20:42,572 --> 00:20:46,314
it somewhere and that place. There's really nothing much better than

317
00:20:46,352 --> 00:20:49,958
s three. If you have the ability

318
00:20:50,054 --> 00:20:53,626
to use something external, meaning don't have to run

319
00:20:53,648 --> 00:20:57,306
it yourself, such as mini or ceph or something

320
00:20:57,328 --> 00:21:00,586
like that, then s three is fantastic. Because it's super cheap,

321
00:21:00,698 --> 00:21:04,602
it is fast and it's plenty reliable. In some cases

322
00:21:04,666 --> 00:21:08,106
you might experience some hiccups with trying to write to s three, but overall,

323
00:21:08,218 --> 00:21:11,486
if you get around that, that sort of an issue, everything else after that is

324
00:21:11,508 --> 00:21:14,626
going to be fine. And finally you're going to

325
00:21:14,648 --> 00:21:17,650
want to actually fill up that event store with something.

326
00:21:17,800 --> 00:21:21,026
And for that purpose you're going to need to building an event archiver of some

327
00:21:21,048 --> 00:21:24,294
sort. Now building it completely from

328
00:21:24,332 --> 00:21:27,622
scratch, you would do it probably in go or you could probably

329
00:21:27,676 --> 00:21:31,254
use some sort of spark jobs or

330
00:21:31,372 --> 00:21:34,886
you could probably glue some things together to just move things off of

331
00:21:34,908 --> 00:21:38,730
Rabbit MQ into s three for all of the events.

332
00:21:39,150 --> 00:21:42,810
That is essentially what comprises an event driven system.

333
00:21:42,880 --> 00:21:45,806
Those are all the big components that are there. So you can kind of already

334
00:21:45,828 --> 00:21:48,480
tell that the big pieces of it really are.

335
00:21:50,130 --> 00:21:53,294
It's not infrastructure. The infrastructure is not actually

336
00:21:53,332 --> 00:21:57,434
that terribly complex. It's really the organizational

337
00:21:57,482 --> 00:22:01,042
aspect of it. Right. And it's kind of a

338
00:22:01,096 --> 00:22:04,020
paradigm shift really of how you think about things.

339
00:22:04,630 --> 00:22:07,230
How does this exactly translate to improve reliability?

340
00:22:07,310 --> 00:22:11,330
Well, number one is you do not have to think about service outages anymore.

341
00:22:11,410 --> 00:22:14,200
And by that I mean, well,

342
00:22:14,810 --> 00:22:19,266
if a service goes down in the midst of dealing

343
00:22:19,298 --> 00:22:20,310
with a request,

344
00:22:23,370 --> 00:22:26,998
not obviously, but it has not acknowledged the

345
00:22:27,004 --> 00:22:30,218
message that it has been completed. All right, so even

346
00:22:30,304 --> 00:22:34,506
if it dropped in whatever state, wherever state it was before it

347
00:22:34,528 --> 00:22:37,514
was actually completed doing the work, it's going to pick it up when it comes

348
00:22:37,552 --> 00:22:40,814
back up. And you do not need to write any extra code for

349
00:22:40,852 --> 00:22:44,606
that. That is just basically part of how all of the services in your

350
00:22:44,628 --> 00:22:48,386
stack should be operating. They pick up messages, they react to them

351
00:22:48,488 --> 00:22:51,698
and upon reaction, upon finishing working on the

352
00:22:51,704 --> 00:22:56,114
message, they acknowledge them and they move on. Right? So basically,

353
00:22:56,232 --> 00:23:00,226
yeah, service outages are a significantly smaller thing.

354
00:23:00,408 --> 00:23:04,520
The fact that you are no longer relying on any other services around you.

355
00:23:07,130 --> 00:23:10,934
You are the master of the domain. There is a single service that

356
00:23:10,972 --> 00:23:14,914
only cares about itself. That means that your failure domain is

357
00:23:15,052 --> 00:23:18,806
really small and you can put all your efforts into making sure that that failure

358
00:23:18,838 --> 00:23:22,150
domain is actually solid. Realistically,

359
00:23:22,230 --> 00:23:25,834
really what we're talking about is it's really one service and the two

360
00:23:25,872 --> 00:23:29,134
or three dependencies that it has, which is your

361
00:23:29,172 --> 00:23:32,398
event bus and ETCD and whatever 3rd,

362
00:23:32,484 --> 00:23:36,286
4th dependency that you have. But that is definitely no longer just a

363
00:23:36,308 --> 00:23:40,382
service by itself. So when you're talking about thinking through your failure domain,

364
00:23:40,526 --> 00:23:44,642
you no longer have to think about, well, what happens when service a

365
00:23:44,696 --> 00:23:48,466
or b or c goes down? And what if d becomes slow and so

366
00:23:48,488 --> 00:23:52,450
on, because they're not really part of your failure domain anymore.

367
00:23:53,030 --> 00:23:56,514
True service autonomy, that is one thing that was promised

368
00:23:56,562 --> 00:23:59,974
to all of us when the microservice pattern emerged as like

369
00:24:00,012 --> 00:24:03,398
a clear winner that, oh, everybody gets to work on their own stuff now.

370
00:24:03,484 --> 00:24:06,860
Well, the fact of the matter is that that's not entirely true because,

371
00:24:07,390 --> 00:24:10,458
yes, even though you own the code for your service,

372
00:24:10,544 --> 00:24:13,846
you are still highly dependent on this other team that owns

373
00:24:13,878 --> 00:24:16,540
service b that you have a dependency for.

374
00:24:17,070 --> 00:24:20,654
If they change their API, well, now you have to update all

375
00:24:20,692 --> 00:24:24,254
your code as well and you're going to be delayed. So what we're talking about

376
00:24:24,292 --> 00:24:27,870
here is that, again, because we do not care about anybody else but ourselves,

377
00:24:29,430 --> 00:24:32,818
we are truly becoming autonomous now.

378
00:24:32,904 --> 00:24:36,322
Well defined development workflow. What this is referring to

379
00:24:36,376 --> 00:24:40,362
is the fact that you are now going to have some sort of centralized

380
00:24:40,446 --> 00:24:44,310
schema which is going to represent

381
00:24:44,970 --> 00:24:48,886
everything that can happen on your system. Basically what we're talking about is

382
00:24:48,908 --> 00:24:52,798
a single message envelope that is going to contain actions,

383
00:24:52,914 --> 00:24:55,866
parameters, all kinds of stuff inside of it.

384
00:24:56,048 --> 00:25:00,230
And as a result of doing that, you're centralizing

385
00:25:00,310 --> 00:25:04,010
one way to communicate your interfaces

386
00:25:04,430 --> 00:25:07,806
for services, being able to do something that means that

387
00:25:07,828 --> 00:25:11,262
you no longer have to have situations where one service is using

388
00:25:11,316 --> 00:25:14,462
swagger, another service is using, I don't know,

389
00:25:14,516 --> 00:25:18,814
insomnia or postman or something like that. And there

390
00:25:18,852 --> 00:25:23,186
is now one repo which has all your schemas that say like,

391
00:25:23,368 --> 00:25:26,770
this is the sort of stuff that I expect to be in this message and

392
00:25:26,840 --> 00:25:30,530
that's the end. And that is super, super wonderful.

393
00:25:31,350 --> 00:25:34,534
There is really just an entirely another talk that we could do

394
00:25:34,572 --> 00:25:38,326
just on Protobuff schemas themselves alone. So we're just going to leave

395
00:25:38,348 --> 00:25:41,446
it at that. But point is, Protobuff is

396
00:25:41,468 --> 00:25:47,946
not even really that hard to begin with, or Avro. And what

397
00:25:47,968 --> 00:25:51,610
am I looking for? None of those message encoding

398
00:25:53,470 --> 00:25:57,534
paradigms really are that complex to begin with. And then

399
00:25:57,572 --> 00:26:01,610
finally we have dramatically lowered our attack surface.

400
00:26:01,770 --> 00:26:05,182
The fact that we no longer need to talk between services means

401
00:26:05,236 --> 00:26:08,814
that we are able to implement some

402
00:26:08,852 --> 00:26:12,358
sort of rules, like a blanket rule set on our firewall,

403
00:26:12,394 --> 00:26:15,794
to simply say like, no, we no longer need to

404
00:26:15,912 --> 00:26:19,842
accept any inbound connections and the only outbounds that we allow are talking

405
00:26:19,896 --> 00:26:23,406
to the event bus and talking to eTCD or whatever else.

406
00:26:23,448 --> 00:26:27,362
So you no longer have to basically punch firewall holes

407
00:26:27,426 --> 00:26:30,566
all over the place just to be able to allow one service to talk to

408
00:26:30,588 --> 00:26:34,262
another one. And that is amazing, absolutely amazing.

409
00:26:34,316 --> 00:26:38,874
And security is going to be super happy about it. So one

410
00:26:38,912 --> 00:26:42,854
thing is that's really important here is that folks

411
00:26:42,902 --> 00:26:47,310
probably want to see what it actually looks like to do something completely event driven.

412
00:26:47,890 --> 00:26:51,790
Batch uses is 100% event driven and

413
00:26:51,860 --> 00:26:54,894
we have about 1920 services or so.

414
00:26:54,932 --> 00:26:58,778
And every single one of them is based off of the singular go template

415
00:26:58,794 --> 00:27:02,098
that we constantly keep up to date. You can go and check it,

416
00:27:02,104 --> 00:27:05,778
but right there it is public. Just go at it.

417
00:27:05,944 --> 00:27:09,202
We use Kafka and Rabbitmq. RabbitmQ is

418
00:27:09,256 --> 00:27:13,062
our system bus for basically the bus

419
00:27:13,116 --> 00:27:16,658
where we communicate, state and so on. And Kafka

420
00:27:16,674 --> 00:27:18,600
is used basically for high throughput stuff.

421
00:27:20,090 --> 00:27:23,882
Yeah, feel free to take a look at that. Now, youve probably

422
00:27:23,936 --> 00:27:28,714
thinking that this all sounds terribly complicated and.

423
00:27:28,752 --> 00:27:32,140
Yeah, it's pretty complicated, it turns out. Yes,

424
00:27:32,510 --> 00:27:36,602
from a technical perspective, it's actually not entirely that complicated,

425
00:27:36,666 --> 00:27:40,346
depending on the expertise of your engineering

426
00:27:40,378 --> 00:27:44,638
team. However, the complicated part is

427
00:27:44,804 --> 00:27:48,526
really, I guess, the political aspect of it

428
00:27:48,548 --> 00:27:51,806
and trying to communicate all these changes and so on across the

429
00:27:51,828 --> 00:27:54,930
engineering. That part is really complicated.

430
00:27:55,270 --> 00:27:58,658
I also think it's really important for you to understand

431
00:27:58,744 --> 00:28:02,342
your message bus inside and out. There is nothing worse than actually

432
00:28:02,396 --> 00:28:05,960
designing foundation that you think is really beautiful

433
00:28:07,770 --> 00:28:11,442
and realizing some months later that this feature

434
00:28:11,506 --> 00:28:14,994
that you built into your foundation that you handcrafted

435
00:28:15,042 --> 00:28:18,138
and so on was actually something that was completely supported in

436
00:28:18,144 --> 00:28:21,546
the message bus itself. And I say that only because I have

437
00:28:21,568 --> 00:28:24,220
totally done that myself several times,

438
00:28:24,750 --> 00:28:28,186
only to realize that I really should have just sat down and just gone through

439
00:28:28,208 --> 00:28:31,646
the docs to know that like, oh, wait a second, I can just do

440
00:28:31,668 --> 00:28:35,278
this automatically. The bus can take care of this for me and I

441
00:28:35,284 --> 00:28:37,470
don't need to come up with some sort of a solution.

442
00:28:37,970 --> 00:28:41,166
Another big part is you absolutely need to accept

443
00:28:41,198 --> 00:28:44,334
that the event bus or the events really are the source of truth.

444
00:28:44,382 --> 00:28:48,162
That is super important. It is really

445
00:28:48,216 --> 00:28:51,266
one of the main, main points of event driven

446
00:28:51,378 --> 00:28:55,110
and the event sourcing architectures.

447
00:28:55,450 --> 00:28:58,774
You should also embrace eventual consistency and

448
00:28:58,812 --> 00:29:02,862
same with item potency. And you should just anticipate complex debug

449
00:29:03,026 --> 00:29:06,790
where debug was actually fairly straightforward ish,

450
00:29:06,950 --> 00:29:10,794
if you had request tracing with HTTP. Now debug has

451
00:29:10,832 --> 00:29:13,580
gotten quite a bit, quite a bit more difficult.

452
00:29:13,950 --> 00:29:17,766
This space is still kind of greenfield. There aren't

453
00:29:17,798 --> 00:29:20,814
a whole lot of tools, so youve probably going to expect to have to build

454
00:29:20,852 --> 00:29:24,446
some of this stuff yourself. I figured it would

455
00:29:24,468 --> 00:29:28,014
be probably helpful to maybe put down how

456
00:29:28,052 --> 00:29:31,026
much time certain parts of this are going to take,

457
00:29:31,208 --> 00:29:34,418
at least from the technical perspective. I have a couple of

458
00:29:34,424 --> 00:29:37,714
more slides at the end. At the very end of the

459
00:29:37,752 --> 00:29:40,946
presentation, which goes into how much

460
00:29:40,968 --> 00:29:44,566
time it takes for the organizational aspect of it as well. But I'll leave

461
00:29:44,588 --> 00:29:48,614
that off for later. So first things first,

462
00:29:48,812 --> 00:29:52,434
to set up the actual foundational infrastructure. I think it's the easiest

463
00:29:52,482 --> 00:29:56,146
part by far. It really shouldn't even, probably take

464
00:29:56,188 --> 00:29:59,706
even one week, maybe max two weeks or something like that,

465
00:29:59,808 --> 00:30:03,066
especially if youve using some third party. Things like

466
00:30:03,088 --> 00:30:06,854
that are from a vendor such as s three, right? Or maybe for the event.

467
00:30:06,912 --> 00:30:10,670
Plus youve using some sort of a platform as a service such as

468
00:30:10,740 --> 00:30:13,966
compose IO or something like that. Defining the

469
00:30:13,988 --> 00:30:17,630
schemas might take a little bit longer. It also

470
00:30:17,780 --> 00:30:21,970
varies highly based on how much expertise

471
00:30:22,310 --> 00:30:25,986
do you have in regards to how your product works. Do you understand

472
00:30:26,088 --> 00:30:29,586
every single part of it or do you understand only

473
00:30:29,608 --> 00:30:31,814
a portion of it? That means that you're going to have to talk to more

474
00:30:31,852 --> 00:30:35,590
people and so on to make sure that it fits correctly.

475
00:30:36,730 --> 00:30:40,162
And then when I'm talking about schema publishing and consumption,

476
00:30:40,226 --> 00:30:44,890
all that I'm talking about really is CI for creating releases

477
00:30:45,390 --> 00:30:46,730
for your schemas.

478
00:30:50,910 --> 00:30:54,762
It can be anywhere from medium to hard. Really,

479
00:30:54,896 --> 00:30:57,974
it entirely depends on how complicated your schemas

480
00:30:58,022 --> 00:31:01,326
are. Are you using protobuff? What are you using actually for the

481
00:31:01,348 --> 00:31:05,422
messaging, coding, all that sort of stuff? A really important thing is

482
00:31:05,476 --> 00:31:09,182
to provide an example service that uses event driven. You do not

483
00:31:09,236 --> 00:31:12,914
want to give your developers basically

484
00:31:13,032 --> 00:31:16,674
just a mandate that you should be doing a vendor event. You want to provide

485
00:31:16,792 --> 00:31:20,226
something like libraries, probably wrappers, that sort of a thing to

486
00:31:20,248 --> 00:31:22,802
say, like this is how you do it, and you just plug and play essentially,

487
00:31:22,866 --> 00:31:27,414
and you get everything. And then the last parts that

488
00:31:27,452 --> 00:31:31,266
have an asterisk next to them, they are by far the hardest

489
00:31:31,298 --> 00:31:35,082
parts of all of this. With that said, they are

490
00:31:35,136 --> 00:31:38,838
also potentially not needed right away. You'll probably want them eventually,

491
00:31:38,934 --> 00:31:42,060
but they're probably not needed right now.

492
00:31:42,750 --> 00:31:45,946
The most important one by far is having some sort

493
00:31:45,968 --> 00:31:49,406
of an event archiving solution. And that is basically something that

494
00:31:49,428 --> 00:31:52,666
is going to consume all the events

495
00:31:52,698 --> 00:31:56,062
from rabbit or Kafka and stick them into something like

496
00:31:56,116 --> 00:31:59,918
the long term storage, like s three. There is a little bit

497
00:31:59,924 --> 00:32:03,106
of complexity in that, and the fact that you actually need to probably group the

498
00:32:03,128 --> 00:32:07,170
events. You need to put them together because you don't want to have

499
00:32:07,320 --> 00:32:10,466
1 million files in one directory or whatever,

500
00:32:10,568 --> 00:32:14,034
one object space in s three. So youve going to want to group

501
00:32:14,072 --> 00:32:17,160
it, munge it and compress it, that sort of a thing.

502
00:32:17,770 --> 00:32:21,042
But the rest of them, such as a replay mechanism or an event viewer.

503
00:32:21,106 --> 00:32:25,050
Maybe you don't need it right away, but you will probably need it eventually.

504
00:32:25,710 --> 00:32:29,674
Some things, some quick tips in regards to when to

505
00:32:29,712 --> 00:32:33,546
stamp this down and what is the best approach to

506
00:32:33,568 --> 00:32:36,986
all this. So number one is that if this

507
00:32:37,008 --> 00:32:40,142
is a brand new, you have a brand new platform, everything is new,

508
00:32:40,276 --> 00:32:43,440
and you know what you're doing. This is awesome.

509
00:32:43,890 --> 00:32:47,502
That is the prime time. It is absolutely amazing to

510
00:32:47,556 --> 00:32:50,818
implement an event driven platform. It is

511
00:32:50,904 --> 00:32:55,074
fantastic. But you

512
00:32:55,112 --> 00:32:58,846
should really still only do it if you have a complete understanding

513
00:32:58,878 --> 00:33:02,434
of everything, how everything works, how youve can

514
00:33:02,472 --> 00:33:05,862
imagine how all the services are going to interact. You probably

515
00:33:05,916 --> 00:33:09,238
need to have a very good idea of all the flows that

516
00:33:09,244 --> 00:33:12,280
are going to be happening in your system. Really?

517
00:33:13,610 --> 00:33:17,446
Really. This kind of goes without saying, but I'm

518
00:33:17,478 --> 00:33:20,634
just going to point it out again, or I'm going to point it out is

519
00:33:20,672 --> 00:33:25,046
that this is largely based on youve engineering capability.

520
00:33:25,238 --> 00:33:28,974
If you have experience in this and you have experience dealing with

521
00:33:29,012 --> 00:33:32,606
architecture and with design, you could

522
00:33:32,628 --> 00:33:36,142
probably pull it off. If you do not, then you

523
00:33:36,196 --> 00:33:39,578
might want to have some friends around who are going to be able

524
00:33:39,604 --> 00:33:43,154
to put on their architecture hats together with you

525
00:33:43,272 --> 00:33:47,330
and think through all of this. With that said, you almost certainly

526
00:33:47,480 --> 00:33:50,618
want to do this with somebody else, even if they're

527
00:33:50,654 --> 00:33:54,070
less experienced. Just to make sure that

528
00:33:54,220 --> 00:33:57,430
you're not doing something totally silly and egregious.

529
00:33:58,330 --> 00:34:02,502
One final thing is that do not use CDC as your

530
00:34:02,556 --> 00:34:06,250
primary source of truth or as your only source of truth.

531
00:34:06,590 --> 00:34:10,250
You can totally use CDC or change data capture,

532
00:34:10,990 --> 00:34:15,180
but use it as a helper, not as the primary way to

533
00:34:15,730 --> 00:34:18,746
create events. Actually let your services create the events,

534
00:34:18,778 --> 00:34:22,686
not your database. So in

535
00:34:22,708 --> 00:34:26,800
most cases, though, you're probably going to have an existing.org and in that case,

536
00:34:27,810 --> 00:34:31,102
definitely move to event driven gradually. Do not

537
00:34:31,156 --> 00:34:34,562
try to do it in one big fell swoop. It never

538
00:34:34,616 --> 00:34:37,858
works. I have never seen it work. It is going to

539
00:34:37,864 --> 00:34:41,160
be a massive waste of time and there's going to be problems.

540
00:34:41,690 --> 00:34:45,058
There's functionality will be missed. The timetables

541
00:34:45,074 --> 00:34:49,270
that you assign to it are going to be exceeded dramatically.

542
00:34:49,690 --> 00:34:52,470
Just do it gradually, little by little.

543
00:34:52,620 --> 00:34:56,146
Basically you can utilize CDC or change data capture

544
00:34:56,178 --> 00:34:59,734
for this, where you are just going to expose some database

545
00:34:59,862 --> 00:35:02,938
little by little. Like every single update that is happening in

546
00:35:02,944 --> 00:35:06,666
the DB, you're going to push it out as an event and have some services

547
00:35:06,768 --> 00:35:10,334
only rely on that. The only caveat there is that you do not

548
00:35:10,372 --> 00:35:13,818
want to have a service. Half rely on CDC or directly

549
00:35:13,834 --> 00:35:16,910
on the database, and then half of the same service

550
00:35:16,980 --> 00:35:20,754
rely also on events as well. It's either it relies on one or

551
00:35:20,792 --> 00:35:22,180
it relies on the other.

552
00:35:23,750 --> 00:35:27,474
Now, in regards to some

553
00:35:27,512 --> 00:35:30,702
more reality really, of where does Sre

554
00:35:30,766 --> 00:35:34,838
fit into all of this? I think that Sre in this particular

555
00:35:34,924 --> 00:35:38,198
case is by far the most important

556
00:35:38,364 --> 00:35:42,422
part of the conversation. They need to be involved of anything

557
00:35:42,476 --> 00:35:44,860
that deals with distributed system design, really,

558
00:35:46,830 --> 00:35:50,506
to a certain degree. The only folks that truly understand

559
00:35:50,608 --> 00:35:54,054
things, how they work at a platform level are sres.

560
00:35:54,182 --> 00:35:58,022
So if you are not involved in the conversation, you should be involved.

561
00:35:58,166 --> 00:36:01,566
And if you are involved but you're not a lead, you should be a

562
00:36:01,588 --> 00:36:04,958
lead. You should be leading the charge on all this sort of

563
00:36:04,964 --> 00:36:08,334
stuff, right? Another thing is, you should know

564
00:36:08,372 --> 00:36:12,738
that this is a totally greenfield area,

565
00:36:12,904 --> 00:36:16,482
this event driven in general. Like granted, you might

566
00:36:16,536 --> 00:36:20,226
see some stuff about react or something like that. That is event driven as

567
00:36:20,248 --> 00:36:23,682
well. In essence, when it comes to event

568
00:36:23,736 --> 00:36:26,934
driven for systems, there's not a whole lot of stuff

569
00:36:26,972 --> 00:36:30,358
out there. It's part of the reason why I wanted to start a company in

570
00:36:30,364 --> 00:36:33,954
this space, because there's not a lot of stuff out there,

571
00:36:34,012 --> 00:36:37,706
and I really wanted to build something that addresses some

572
00:36:37,728 --> 00:36:41,434
of these issues. Another thing is, you need

573
00:36:41,472 --> 00:36:45,386
to get comfortable wearing an architecture hat. You will wear it no

574
00:36:45,408 --> 00:36:48,798
matter what. It's going to happen. And if youve are being a

575
00:36:48,804 --> 00:36:52,202
thought leader and you are providing documentation

576
00:36:52,266 --> 00:36:55,726
and talks and so on and so on, like it or not, you will have

577
00:36:55,748 --> 00:36:58,740
an architecture hat. It's just simply going to happen.

578
00:36:59,750 --> 00:37:02,994
Another thing then is, I guess the final bit

579
00:37:03,032 --> 00:37:08,062
to all these tips is that really, I would focus heavily

580
00:37:08,126 --> 00:37:11,858
on documentation and really on written culture in general,

581
00:37:12,024 --> 00:37:16,150
that everything should be written down. Even though a lot of us now are completely

582
00:37:16,220 --> 00:37:19,878
remote anyways, now it makes even more sense to

583
00:37:19,884 --> 00:37:23,670
do it than before, but you absolutely must have

584
00:37:23,740 --> 00:37:27,482
a written culture in place with an event driven system.

585
00:37:27,536 --> 00:37:31,350
A lot of stuff feels a lot like magic when it just works properly.

586
00:37:31,510 --> 00:37:35,434
But the thing is that when it doesn't work,

587
00:37:35,632 --> 00:37:39,038
you will absolutely wish that you had some sort of flows, some sort

588
00:37:39,044 --> 00:37:42,560
of flow diagrams, runbooks of how things are supposed to work,

589
00:37:43,330 --> 00:37:46,446
maybe proposals for how a certain part of the

590
00:37:46,468 --> 00:37:50,482
architecture is going to work, and so on. So written culture is super

591
00:37:50,616 --> 00:37:53,694
important. So in essence,

592
00:37:53,742 --> 00:37:57,826
in exchange for a pretty decent amount of complexity, you are going to

593
00:37:57,848 --> 00:38:01,522
gain a lot, right. You are going to gain real autonomy

594
00:38:01,666 --> 00:38:05,430
for both services and teams. You will be able to rebuild state,

595
00:38:05,580 --> 00:38:08,706
you will have predictable failure scenarios,

596
00:38:08,898 --> 00:38:12,502
your recovery time should increase massively because

597
00:38:12,556 --> 00:38:16,534
you no longer will have to hunt down various teams and so on.

598
00:38:16,652 --> 00:38:20,326
You will be able to sustain really long lasting outages. Not that that's

599
00:38:20,358 --> 00:38:23,418
a terribly great thing to have long lasting outages, but you will be able to

600
00:38:23,424 --> 00:38:27,018
sustain them. Security will totally thank you because

601
00:38:27,104 --> 00:38:31,274
you have just added this massive improvement

602
00:38:31,402 --> 00:38:35,466
on the entire platform and you have a really solid

603
00:38:35,578 --> 00:38:39,570
and super well defined and very robust foundation.

604
00:38:42,790 --> 00:38:46,242
It's not going to take very much explaining to say

605
00:38:46,296 --> 00:38:49,634
this is how it works, because there's basically only one

606
00:38:49,672 --> 00:38:53,394
thing heard, which is you emit an event and

607
00:38:53,512 --> 00:38:57,046
an x amount of services are going to do something about that event and are

608
00:38:57,068 --> 00:38:59,734
going to update certain parts of it. That's it.

609
00:38:59,932 --> 00:39:03,266
And then really the final part is that you will have a lifetime

610
00:39:03,298 --> 00:39:07,642
of historical records. And that is super amazing because you now have

611
00:39:07,776 --> 00:39:11,894
all the things in relation to any sort of certifications

612
00:39:11,942 --> 00:39:14,982
that you need and so on. You essentially have an audit trail

613
00:39:15,046 --> 00:39:18,454
and on top of you have analytics for your future data,

614
00:39:18,512 --> 00:39:21,758
science teams and so on. Just as a

615
00:39:21,764 --> 00:39:25,262
quick side note is that batch is using. I think I already

616
00:39:25,316 --> 00:39:28,670
alluded to this, that batch is 100% event driven.

617
00:39:29,170 --> 00:39:32,594
So I'll just give you some quick stats as to what it means for us

618
00:39:32,632 --> 00:39:36,334
is that, number one, we're a complete AWS

619
00:39:36,462 --> 00:39:40,226
shop. We are using eks, we're using MSK, which is the

620
00:39:40,248 --> 00:39:43,698
managed Kafka, and we're using lots of EC two, plus whatever

621
00:39:43,784 --> 00:39:46,200
sort of random assortment of their other services,

622
00:39:47,050 --> 00:39:49,894
the basics of route 53 for DNS and so on,

623
00:39:49,932 --> 00:39:53,574
and rds in some cases. We have a

624
00:39:53,612 --> 00:39:56,970
total of 19, I think somewhere on there in like 1920,

625
00:39:57,040 --> 00:40:00,506
maybe a little bit more Golink services. All of them are based off

626
00:40:00,528 --> 00:40:03,674
of that go template that I mentioned. We are 100%

627
00:40:03,712 --> 00:40:07,070
event driven, except of course for the front end part,

628
00:40:07,220 --> 00:40:11,114
which the front end has to talk to a public API. Those are synchronous

629
00:40:11,162 --> 00:40:14,750
requests. But we have zero inner service dependencies.

630
00:40:15,410 --> 00:40:18,686
Most services have only three dependencies, and that is rabbit,

631
00:40:18,718 --> 00:40:21,460
etcd and Kafka. And that is it.

632
00:40:21,830 --> 00:40:25,614
That means that we have an extremely

633
00:40:25,662 --> 00:40:30,626
locked down network. I'm skipping a few points there, but that

634
00:40:30,648 --> 00:40:33,778
is the result of that. We do not have a service mesh,

635
00:40:33,954 --> 00:40:37,206
we have no service discovery. We do not need any of

636
00:40:37,228 --> 00:40:41,014
it because we don't really care about accessing those

637
00:40:41,052 --> 00:40:44,474
services, and those services don't need to talk to each other. We don't care about

638
00:40:44,592 --> 00:40:48,202
having to have mtls between every single service

639
00:40:48,256 --> 00:40:51,642
and so on. The only things that we have is just

640
00:40:51,696 --> 00:40:55,462
mtls between the service itself and

641
00:40:55,536 --> 00:40:59,598
Kafka, and that's about it. And of know rabbit and

642
00:40:59,684 --> 00:41:02,926
eTCD and what this means though of

643
00:41:02,948 --> 00:41:06,942
course, is that instead of triggering behavior via curl or

644
00:41:06,996 --> 00:41:10,226
postman, we are actually triggering behavior by emitting an

645
00:41:10,248 --> 00:41:13,726
event onto the event. But, and we use a tool called plumber

646
00:41:13,758 --> 00:41:16,866
that we developed. It's also open source, you can see it

647
00:41:16,888 --> 00:41:19,650
under the batch corp GitHub.org.

648
00:41:20,950 --> 00:41:25,474
But it's a slightly different paradigm, right? Instead of just doing curl

649
00:41:25,522 --> 00:41:29,314
for an HTTP request. Well now we do plumber, but it's essentially the same concept

650
00:41:29,362 --> 00:41:32,886
as well. All we're emitting is essentially a

651
00:41:32,908 --> 00:41:35,850
message that is a protobuff message,

652
00:41:35,920 --> 00:41:39,674
right? I already mentioned, yeah, that our

653
00:41:39,712 --> 00:41:43,322
network is massively locked down. We're barely able to talk to

654
00:41:43,376 --> 00:41:47,120
anything where the services are able to only talk to very specific

655
00:41:49,650 --> 00:41:52,974
other ips on the network. And then the stats are really

656
00:41:53,012 --> 00:41:56,126
that our average event size is at 4k.

657
00:41:56,228 --> 00:41:59,534
We have about 15 million system events and that takes up

658
00:41:59,572 --> 00:42:03,186
about 100 gigs of storage in s three, which really translates to a

659
00:42:03,208 --> 00:42:06,706
couple of bucks or so a month that you need to pay for s

660
00:42:06,728 --> 00:42:10,180
three. It's really, in the grand scheme of things, it's absolutely nothing.

661
00:42:11,590 --> 00:42:14,806
So while it may seem that you are super amazing now

662
00:42:14,828 --> 00:42:17,846
at event driven, you're probably not quite yet.

663
00:42:17,948 --> 00:42:21,602
Not quite there yet. I'm not there yet either. But I have a decent

664
00:42:21,666 --> 00:42:25,146
ish idea. But to get there you should probably spend a little bit of

665
00:42:25,168 --> 00:42:28,262
time doing a little bit more research and reading on this topic.

666
00:42:28,326 --> 00:42:32,006
And you should totally start off with Martin Fowler's

667
00:42:32,038 --> 00:42:35,642
event driven. This article basically just

668
00:42:35,696 --> 00:42:39,530
talks about the idea that the fact that, well, event driven actually contains

669
00:42:39,610 --> 00:42:43,326
multiple different architectures. So you should be aware of what

670
00:42:43,348 --> 00:42:46,320
you're talking about when you say event driven in the first place.

671
00:42:46,690 --> 00:42:50,362
So it's just a good overview

672
00:42:50,426 --> 00:42:55,054
really of event driven in general. Then the event sourcing architecture

673
00:42:55,102 --> 00:42:58,162
pattern, which is basically what we discussed here,

674
00:42:58,296 --> 00:43:01,750
when you're using replays, that's essentially what youve implementing.

675
00:43:03,450 --> 00:43:07,206
It's all under the same event driven umbrella really.

676
00:43:07,388 --> 00:43:11,074
And cqRs, same thing. It's another architectures pattern

677
00:43:11,122 --> 00:43:16,118
that fits really well within the event driven umbrella.

678
00:43:16,294 --> 00:43:19,130
Now, in regards to item potency,

679
00:43:20,270 --> 00:43:24,278
everyone should probably read about what is an item potent consumer.

680
00:43:24,454 --> 00:43:27,754
The microservices IO site does it

681
00:43:27,792 --> 00:43:31,326
in very few sentences, much better than I could to

682
00:43:31,348 --> 00:43:34,846
explain what is actual item potency. Now there is one article that I

683
00:43:34,868 --> 00:43:38,430
found, which is written by Ben Morris and it is super awesome.

684
00:43:38,580 --> 00:43:41,710
There is one particular

685
00:43:41,780 --> 00:43:45,406
quote that I really liked, which was that bear in mind that if you rely

686
00:43:45,438 --> 00:43:48,802
on message ordering, then you are effectively coupling your applications together

687
00:43:48,856 --> 00:43:52,326
in a temporal or time based sense. And if

688
00:43:52,348 --> 00:43:55,974
you read between the lines, really what it's saying in that case is

689
00:43:56,012 --> 00:43:59,254
that, well, that youve probably don't want to do

690
00:43:59,292 --> 00:44:03,414
it. Youve creating potential problems for

691
00:44:03,452 --> 00:44:06,986
yourself. So in other words, do not rely on

692
00:44:07,008 --> 00:44:10,666
ordering. Create your system so

693
00:44:10,688 --> 00:44:14,474
that order doesn't really matter. And that's like where item potency comes into play.

694
00:44:14,592 --> 00:44:18,318
And at the same token, exactly one's delivery, that's another

695
00:44:18,404 --> 00:44:21,822
topic that can be discussed in detail for a very long time.

696
00:44:21,876 --> 00:44:25,982
But exactly one's delivery is very

697
00:44:26,036 --> 00:44:29,170
difficult and potentially snake oil.

698
00:44:29,510 --> 00:44:32,514
There, I just said it. Yes,

699
00:44:32,632 --> 00:44:36,500
Kafka does talk about it and yes, technically it is

700
00:44:37,110 --> 00:44:41,094
doable, but there are many,

701
00:44:41,132 --> 00:44:44,646
many caveats to it. So it's simply much better to

702
00:44:44,828 --> 00:44:48,262
design your system so that your services are

703
00:44:48,316 --> 00:44:51,480
able to deal with duplicate events in the first place.

704
00:44:53,310 --> 00:44:56,570
Okay. And that is basically it.

705
00:44:56,720 --> 00:45:00,650
I hope I was able to show you something,

706
00:45:00,800 --> 00:45:04,650
show you something new. And if this is the sort of stuff that is interesting

707
00:45:04,720 --> 00:45:07,646
to you, you should totally come and talk to me.

708
00:45:07,748 --> 00:45:11,086
If youve want to work with stuff like this, you should also come

709
00:45:11,108 --> 00:45:14,622
and talk to me. This whole

710
00:45:14,676 --> 00:45:17,854
space is super interesting and it is still

711
00:45:17,892 --> 00:45:21,520
fairly fresh. There aren't a lot of people doing it.

712
00:45:21,970 --> 00:45:25,998
And in general, high throughput observability is

713
00:45:26,084 --> 00:45:29,246
not really a thing yet. And we are trying to make it

714
00:45:29,268 --> 00:45:33,590
happen. So if you are thinking about going to event driven,

715
00:45:34,570 --> 00:45:37,942
if you have evaluated event driven and youve are not interested

716
00:45:37,996 --> 00:45:41,318
in it or youve afraid of it, come talk to me. I would love to

717
00:45:41,324 --> 00:45:44,566
nerd out about this sort of stuff in any case. All right, that is all

718
00:45:44,588 --> 00:45:47,410
I have. Thank you very much and goodbye.

