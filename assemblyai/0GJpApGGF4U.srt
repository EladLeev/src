1
00:00:25,410 --> 00:00:28,806
You. Hello and welcome to

2
00:00:28,828 --> 00:00:32,390
my session reacting to an event driven world as part of Comp 42.

3
00:00:32,460 --> 00:00:35,814
My name is Grace Janssen and I'm a developer advocate working

4
00:00:35,852 --> 00:00:39,046
at IBM based in the UK. And my twitter handle there

5
00:00:39,068 --> 00:00:42,262
is there. If you'd like to follow me. I primarily focus most of my time

6
00:00:42,316 --> 00:00:45,874
sort of in the Java and the JVM ecosystem, and mostly

7
00:00:45,922 --> 00:00:50,030
looking at things like reacting technologies and cloud native in

8
00:00:50,060 --> 00:00:53,626
infrastructure and cloud native technologies. Hopefully in this session, IBM going to be showing

9
00:00:53,658 --> 00:00:57,498
you how we can build, can architect and design our applications

10
00:00:57,594 --> 00:01:01,054
to be reactive to this sort of event driven world

11
00:01:01,092 --> 00:01:04,478
that we've created. So let's get started. But obviously no

12
00:01:04,564 --> 00:01:08,066
conference session is complete without a coffee demo. So we've got a coffee demo here

13
00:01:08,088 --> 00:01:10,962
for you today. Kind of ironic, because I don't like coffee, but anyway,

14
00:01:11,016 --> 00:01:14,446
so this coffee example is actually available as an open source

15
00:01:14,478 --> 00:01:17,074
project. So if you'd like to check it out, the link is there in this

16
00:01:17,112 --> 00:01:20,754
slide made by our cousins over at Red Hat. So in this coffee

17
00:01:20,802 --> 00:01:24,594
example, we have coffee lovers coming in and making coffee

18
00:01:24,642 --> 00:01:28,166
orders via HTTP request to a coffee shop. Then the coffee shop sends that

19
00:01:28,188 --> 00:01:31,606
order to the baristas via HTTP again, and the baristas can make the

20
00:01:31,628 --> 00:01:35,082
coffee. Now the issue with this is that when the coffee lovers make

21
00:01:35,136 --> 00:01:38,666
this request, it's a blocking request due to the nature of this. And so the

22
00:01:38,688 --> 00:01:42,266
coffee lovers essentially have to wait at the till, until the barista has

23
00:01:42,288 --> 00:01:45,562
completed their order, until they can sit down with their coffee

24
00:01:45,626 --> 00:01:49,102
and they can't place the next order until the barista has completed that first

25
00:01:49,156 --> 00:01:51,886
order. So it's a very blocking process in this regard.

26
00:01:51,988 --> 00:01:55,598
But what people often suggest when they're looking at applications like this

27
00:01:55,684 --> 00:01:59,346
to make it slightly more asynchronous and more non blocking, is to

28
00:01:59,368 --> 00:02:02,814
introduce something called events driven architecture. So event driven architecture,

29
00:02:02,862 --> 00:02:06,670
or it's often shortened to Eda, is a very popular architectural style

30
00:02:06,750 --> 00:02:10,646
that really enables events to be placed at the heart of our systems and

31
00:02:10,668 --> 00:02:14,182
our applications. When I talk about events, an event here is

32
00:02:14,236 --> 00:02:18,134
essentially a record of something that's changed or something that's happened within

33
00:02:18,172 --> 00:02:21,542
the system. So it's usually sort of a state change within

34
00:02:21,596 --> 00:02:25,478
our system. And these events are immutable, so they cannot be changed,

35
00:02:25,574 --> 00:02:29,098
but they can be sort of a new event can be created to represent a

36
00:02:29,104 --> 00:02:32,874
new state change to that same entity or object. They're ordered in

37
00:02:32,912 --> 00:02:35,946
sequence of their creation. So you can see these, we've got a basic

38
00:02:35,978 --> 00:02:39,818
sort of architectural diagram of what this really sort of represents.

39
00:02:39,914 --> 00:02:43,550
So we've got that event driven messaging backbone. So this is that immutable log

40
00:02:43,620 --> 00:02:47,262
of events placed at the heart of our system. And then we've got microservices

41
00:02:47,406 --> 00:02:50,626
consuming and producing to this event log. So you

42
00:02:50,648 --> 00:02:53,986
can see microservice one, there is publishing events to that event log,

43
00:02:54,088 --> 00:02:57,730
microservice two and three, interestingly actually publish

44
00:02:57,810 --> 00:03:01,158
and subscribe and consume from that event log

45
00:03:01,244 --> 00:03:04,966
and service four is just consuming. So event driven architecture is just

46
00:03:04,988 --> 00:03:08,054
about having sort of loosely coupled microservices that are able

47
00:03:08,092 --> 00:03:11,506
to exchange information through this production and consumption

48
00:03:11,538 --> 00:03:14,138
of events. So let's see what it looks like when we put it into our

49
00:03:14,144 --> 00:03:17,354
barista example. When we put it in, as you can see here, we're still using

50
00:03:17,392 --> 00:03:21,018
HTTP to communicate between the coffee lovers and the coffee shop. But now we've got

51
00:03:21,024 --> 00:03:24,298
an event backbone between the coffee shop and the barista and a

52
00:03:24,304 --> 00:03:27,726
new component called the board. So in this case, when our coffee order is made

53
00:03:27,748 --> 00:03:30,874
by our coffee lovers, it goes to the coffee shop and it gets added onto

54
00:03:30,922 --> 00:03:34,046
an event backbone onto that queue or that topic. And that means

55
00:03:34,068 --> 00:03:37,974
that the barista can read from that topic as and when he's finished

56
00:03:38,042 --> 00:03:41,202
or can read the next record or the next coffee that needs to be made.

57
00:03:41,256 --> 00:03:44,386
And then once the barista has made those coffees, they can then update the

58
00:03:44,408 --> 00:03:47,726
board to basically announce when that coffee has been produced.

59
00:03:47,758 --> 00:03:50,646
And the coffee lovers will then know to go and collect their order. What this

60
00:03:50,668 --> 00:03:53,846
means is that the coffee lovers no longer have to wait at the till for

61
00:03:53,868 --> 00:03:57,250
each of their orders to be processed. Instead they can leave these till

62
00:03:57,330 --> 00:04:00,518
knowing that their order has been placed and that it will eventually be made.

63
00:04:00,604 --> 00:04:04,042
So their request will eventually be satisfied. They can go down,

64
00:04:04,096 --> 00:04:07,706
sit down, talk to their friends, probably discuss Java as we all love

65
00:04:07,728 --> 00:04:10,986
to do, and then once they see the board has updated, they can then go

66
00:04:11,008 --> 00:04:14,878
and collect their coffee. So it's a much more asynchronous process here. We're trying to

67
00:04:14,884 --> 00:04:18,334
get rid of some of that blocking component from our original application to

68
00:04:18,372 --> 00:04:22,346
introduce these style of architecture. A tool that's often used is Apache

69
00:04:22,378 --> 00:04:25,886
Kafka. So if you've not come across Apache Kafka, it's an open source project

70
00:04:25,988 --> 00:04:29,294
that's all about being sort of providing this distributed streaming

71
00:04:29,342 --> 00:04:32,894
platform. So it enables things like stream history, that immutable

72
00:04:32,942 --> 00:04:35,826
data that we were talking about for that event log in the center of that

73
00:04:35,848 --> 00:04:40,102
diagram. It enables really high availability of the information within your application

74
00:04:40,236 --> 00:04:43,602
and it is extremely scalable. So if we were to introduce,

75
00:04:43,666 --> 00:04:46,966
say, Kafka in order to create that event driven backbone in

76
00:04:46,988 --> 00:04:50,614
our barista application. What does this really mean? So, does this mean

77
00:04:50,652 --> 00:04:54,070
that our coffee shop is now non blocking and highly responsive?

78
00:04:54,150 --> 00:04:57,750
In other words, is our microservice system non blocking and highly responsive?

79
00:04:57,830 --> 00:05:01,162
And people often assume that the answer to this question is,

80
00:05:01,216 --> 00:05:04,330
well, yes, I'm using Kafka. I've got this adventure of an architecture,

81
00:05:04,410 --> 00:05:07,694
so I must be highly responsive, I'm scalable, I must

82
00:05:07,732 --> 00:05:11,646
be non blocking, because I've got this asynchronicity, this decoupling. That's not the

83
00:05:11,668 --> 00:05:14,734
answer to everything. There is more to this

84
00:05:14,772 --> 00:05:18,366
application if we want it to really be non blocking and highly responsive

85
00:05:18,398 --> 00:05:21,886
from end to end, than just shoving in tools like Kafka,

86
00:05:21,998 --> 00:05:25,506
or architectural approaches like events driven architecture, and expecting it

87
00:05:25,528 --> 00:05:28,690
to magically be non blocking and highly responsive all the way through.

88
00:05:28,760 --> 00:05:32,198
Kafka is a great tool, but it isn't enough just to have a good tool

89
00:05:32,284 --> 00:05:35,366
shove it in. We need to be using it in the right ways, and we

90
00:05:35,388 --> 00:05:39,030
need to be building our applications in the right manner to really

91
00:05:39,100 --> 00:05:42,566
enable non blocking all the way through. So this is where this concept

92
00:05:42,598 --> 00:05:45,914
of reacting systems comes in. So reactive systems is really

93
00:05:45,952 --> 00:05:49,018
about looking at that sort of high level approach, that system

94
00:05:49,104 --> 00:05:52,542
level view of our application, to ensure that every

95
00:05:52,596 --> 00:05:55,706
stage of our application is asynchronous and nonblocking,

96
00:05:55,738 --> 00:05:59,198
and highly responsive and reactive. So this all stemmed from

97
00:05:59,284 --> 00:06:02,654
a manifesto that was created back in 2013 by

98
00:06:02,692 --> 00:06:05,746
a group of software engineers who really wanted to sort of lay

99
00:06:05,768 --> 00:06:09,118
out the key characteristics and behaviors we need to be expressing

100
00:06:09,134 --> 00:06:12,462
in our applications in order for them to be responsive

101
00:06:12,526 --> 00:06:16,082
and reactive for our end users. And it's sort of based around

102
00:06:16,136 --> 00:06:19,682
four key behaviors or characteristics. So the underlying

103
00:06:19,746 --> 00:06:22,946
behavior in this manifesto is having this message driven

104
00:06:22,978 --> 00:06:26,434
form of communication. Now, this is all about decoupling

105
00:06:26,482 --> 00:06:30,182
the different components of your applications so that a potential failure in one

106
00:06:30,236 --> 00:06:33,866
wouldn't cause a potential failure across the application and mean that your application is

107
00:06:33,888 --> 00:06:37,222
unresponsive. It also enables us to have that asynchronicity

108
00:06:37,286 --> 00:06:40,826
between components because we've decoupled them. So this message driven form of

109
00:06:40,848 --> 00:06:44,858
communication really allows us to achieve this asynchronicity. But interestingly,

110
00:06:44,954 --> 00:06:47,962
in the original manifesto, it was actually event driven.

111
00:06:48,106 --> 00:06:52,014
And you can check out why they switched between reactive manifesto 1.0

112
00:06:52,052 --> 00:06:55,418
to reactive manifesto 20 from event driven to message driven,

113
00:06:55,434 --> 00:06:57,850
there's an article online, you can just go and google it if you'd like to

114
00:06:57,860 --> 00:07:01,410
find out more information about that. But what's the difference between the two, because often

115
00:07:01,480 --> 00:07:04,498
when we think of things like event driven, architecture clues kind of

116
00:07:04,504 --> 00:07:07,938
in the name, we think of it being based around sort of events and

117
00:07:07,944 --> 00:07:10,806
being event driven. So what's the difference between the two? Well,

118
00:07:10,828 --> 00:07:14,438
we've got a definition here on the left for messages and a definition here on

119
00:07:14,444 --> 00:07:17,926
the right for events. So we've defined a message as an item of data sent

120
00:07:17,948 --> 00:07:21,154
to a specific location, whereas an event is more of a signal

121
00:07:21,202 --> 00:07:24,282
emitted by a component upon reaching a given state. So less

122
00:07:24,336 --> 00:07:27,498
location specific there. But interestingly, actually, when you look at

123
00:07:27,504 --> 00:07:31,018
this, you can have a sort of mesh of these two where a message

124
00:07:31,104 --> 00:07:34,298
can contain an encoded event in its payload.

125
00:07:34,394 --> 00:07:37,930
So actually you can have sort of a merge of the two. They're not necessarily

126
00:07:38,010 --> 00:07:41,678
distinct types of sort of communication methods, but when

127
00:07:41,684 --> 00:07:45,426
it comes to Kafka, it doesn't really matter. Although Kafka was traditionally seen sort

128
00:07:45,448 --> 00:07:49,554
of as event driven, they actually don't reference events anywhere in

129
00:07:49,592 --> 00:07:53,122
their sort of description of what they enable. Instead, they reference something called

130
00:07:53,176 --> 00:07:56,606
records. So they enable you to publish and subscribe to streams

131
00:07:56,638 --> 00:08:00,006
of records, store records in a durable way, and process streams of records as

132
00:08:00,028 --> 00:08:03,746
they occur. So actually, they've made this deliberate move away from the word events

133
00:08:03,778 --> 00:08:07,762
and instead use records because it can be used for both both events,

134
00:08:07,826 --> 00:08:10,986
event driven and message driven, or sort of a hybrid between the

135
00:08:11,008 --> 00:08:14,694
two. So actually, when it comes to our reactive manifesto and enabling

136
00:08:14,742 --> 00:08:18,554
that message driven, asynchronous backbone of communication for

137
00:08:18,592 --> 00:08:22,106
application, Kafka can be a really great tool to use. But there's a

138
00:08:22,128 --> 00:08:25,870
reason there's additional characteristics listed in this manifesto that are needed

139
00:08:25,940 --> 00:08:29,498
to be expressed by our applications in order for us to be reactive. So let's

140
00:08:29,514 --> 00:08:33,166
take a look at our barista example and see how we might come into problems

141
00:08:33,268 --> 00:08:36,890
if we were just shoving an event backbone and expecting it to be magically

142
00:08:36,970 --> 00:08:40,718
sort of nonblocking and asynchronous all the way through. So here's our original barista

143
00:08:40,734 --> 00:08:44,126
example. But in this example, we've only got three coffee lovers.

144
00:08:44,158 --> 00:08:47,426
Now, there are more than three coffee lovers in the world. So what happens when

145
00:08:47,448 --> 00:08:50,918
we get an influx of coffee lovers coming into our application or to our

146
00:08:50,924 --> 00:08:54,566
coffee shop trying to place coffee orders? So essentially what we've done here is

147
00:08:54,588 --> 00:08:58,150
we've created a massive increase in load on our system. Now,

148
00:08:58,220 --> 00:09:01,766
more coffee lovers obviously means more coffee orders. So although these

149
00:09:01,788 --> 00:09:05,366
coffee lovers aren't necessarily blocked, because once they make their order, it's placed

150
00:09:05,398 --> 00:09:09,146
onto the backbone and they can go back down, sit down, they're not blocked in

151
00:09:09,168 --> 00:09:13,334
this process, necessarily. It does mean, however, we've got this huge backlog

152
00:09:13,382 --> 00:09:16,622
of coffee orders on our event backbone, and unfortunately, we've only got

153
00:09:16,676 --> 00:09:20,014
one barista to serve them, or one barista to create them or,

154
00:09:20,052 --> 00:09:23,534
and complete those requests. So, in this case, we would

155
00:09:23,572 --> 00:09:27,402
have a potential form of maybe contention, potential failure.

156
00:09:27,546 --> 00:09:31,086
And it would mean, essentially, even if our barista

157
00:09:31,118 --> 00:09:33,846
doesn't go down or fail, or get stuck in a process, our barista is going

158
00:09:33,848 --> 00:09:36,786
to be slow at getting through all of those coffee orders. So our app is

159
00:09:36,808 --> 00:09:40,126
going to be not necessarily as responsive as we would necessarily like.

160
00:09:40,168 --> 00:09:42,966
Our coffee lovers are going to be waiting a while for their coffee. And this

161
00:09:42,988 --> 00:09:46,690
is where the next behavior in the reacting manifesto comes in, elasticity.

162
00:09:46,770 --> 00:09:50,474
So, being able to scale both up and down the resources within

163
00:09:50,512 --> 00:09:54,886
our applications, so that we can gracefully deal with load fluctuations

164
00:09:54,918 --> 00:09:57,930
to our application. So, it's important that, again,

165
00:09:58,000 --> 00:10:01,226
this change, this behavior changed between the reactor manifesto 1.0

166
00:10:01,248 --> 00:10:05,174
to 2.0. It was scalable. It then got changed to elastic, because they realized

167
00:10:05,222 --> 00:10:08,526
that it wasn't just about scaling up the resources, although this is great

168
00:10:08,548 --> 00:10:11,486
when you've got increased load, but when you don't have that load based on your

169
00:10:11,508 --> 00:10:15,294
system, it's really important that we're able to appropriately scale our

170
00:10:15,332 --> 00:10:19,058
application's resources back down so that we're as cost effective as possible.

171
00:10:19,144 --> 00:10:22,194
So, this is where elasticity comes in. So, in our barista example,

172
00:10:22,312 --> 00:10:26,030
if we were able to elastically scale up the number of barista microservices,

173
00:10:26,110 --> 00:10:29,606
we could provide a much more responsive, much more reacting application for

174
00:10:29,628 --> 00:10:33,974
our coffee lovers, because we could get through those coffee orders much quicker and

175
00:10:34,092 --> 00:10:37,334
gracefully deal with that load without these barista becoming a potential point

176
00:10:37,372 --> 00:10:41,226
of failure or contention within our application. Another example here,

177
00:10:41,328 --> 00:10:45,062
in this barista example, we've added an additional component. So this additional

178
00:10:45,126 --> 00:10:48,714
component is, we're calling it the coffee serving table. So, this is

179
00:10:48,752 --> 00:10:52,134
representative of, say, a downstream microservice that's

180
00:10:52,182 --> 00:10:56,314
perhaps needed for additional processing, or perhaps an external service that you're utilizing,

181
00:10:56,362 --> 00:10:59,646
like an external database. So, in this case, for the barista to

182
00:10:59,668 --> 00:11:02,762
be able to update the board and produce and serve the coffee,

183
00:11:02,826 --> 00:11:06,058
they have to place the coffee on the serving table for the coffee lover

184
00:11:06,074 --> 00:11:09,266
to come and collect. Now, what happens in the potential scenario where our

185
00:11:09,288 --> 00:11:12,638
coffee lovers are being a little bit lazy, they're not coming to collect their coffee

186
00:11:12,654 --> 00:11:16,030
orders very quickly. And so these coffee orders are building up on the table.

187
00:11:16,110 --> 00:11:19,682
The serving table is now full, and the barista is juggling coffee

188
00:11:19,826 --> 00:11:23,538
because they can't put it down on the serving table. That's essentially representing

189
00:11:23,634 --> 00:11:26,450
that third party or downstream component going offline,

190
00:11:26,530 --> 00:11:30,486
perhaps failing, or potentially getting stuck in a process. And that

191
00:11:30,508 --> 00:11:33,914
prevents that barista from being able to essentially produce any

192
00:11:33,952 --> 00:11:37,018
more coffees because it's stuck with the coffees that it's trying to load off to

193
00:11:37,024 --> 00:11:40,806
that downstream component. So in this case, this could potentially become a non

194
00:11:40,838 --> 00:11:44,894
responsive app. Because we're no longer able to get through any more coffee orders because

195
00:11:44,932 --> 00:11:48,250
we don't have resiliency built in. And that's the next characteristic,

196
00:11:48,330 --> 00:11:52,106
being able to be resilient in the face of any potential failure that could occur

197
00:11:52,138 --> 00:11:55,490
within your application. So if we were to say, maybe,

198
00:11:55,560 --> 00:11:59,454
perhaps introduce some resilient behaviors into our application, there we could introduce,

199
00:11:59,502 --> 00:12:03,122
say, an event breaker, or a circuit breaker. Sorry. Or perhaps even

200
00:12:03,176 --> 00:12:06,626
things like back pressure communication. So basically,

201
00:12:06,728 --> 00:12:10,674
letting the application know that one of those downstream components is failing,

202
00:12:10,722 --> 00:12:14,086
or is stuck with a load of some kind or a process. And being able

203
00:12:14,108 --> 00:12:17,858
to build in resilient characteristics, like perhaps spinning up another barista

204
00:12:17,954 --> 00:12:22,006
and serving table instance or replica, so that we could redirect requests

205
00:12:22,038 --> 00:12:25,626
to them, or share the load across them, or perhaps rate limit the

206
00:12:25,648 --> 00:12:29,482
number of orders coming in. All of these behaviors would help to prevent our application

207
00:12:29,616 --> 00:12:33,994
from potentially failing and becoming unresponsive. And this leads to the last characteristic.

208
00:12:34,042 --> 00:12:37,418
By enabling elasticity, resiliency, and that message driven,

209
00:12:37,434 --> 00:12:41,214
asynchronous form of communication, we can enable the last characteristic of the

210
00:12:41,252 --> 00:12:44,738
manifesto, which is being responsive. We need our applications to

211
00:12:44,744 --> 00:12:48,942
be as responsive as possible to any state changes or events that are occurring

212
00:12:49,006 --> 00:12:52,782
within our application. And by implementing these characteristics, we can essentially

213
00:12:52,846 --> 00:12:56,738
achieve that reacting, non blocking behavior and

214
00:12:56,744 --> 00:13:00,246
characteristic we need for our event driven world that we now live

215
00:13:00,268 --> 00:13:03,606
in. So, how do we go about actually building these systems, building these

216
00:13:03,628 --> 00:13:07,094
types of applications? Everything I've mentioned so far has been fairly high

217
00:13:07,132 --> 00:13:10,598
level, fairly based around sort of characteristics and behaviors of

218
00:13:10,604 --> 00:13:14,154
our application. Let's talk about these practical how do we achieve this? So we've got

219
00:13:14,192 --> 00:13:17,670
here a fairly basic application, just made up of three microservices,

220
00:13:17,750 --> 00:13:21,462
just so we can go through the various different aspects and I guess layers

221
00:13:21,526 --> 00:13:24,854
within it that we need to be considering. We've already looked at the message

222
00:13:24,912 --> 00:13:28,714
driven, asynchronous sort of data layer and how Kafka can enable

223
00:13:28,762 --> 00:13:32,574
us to help decouple the aspect, the components within our application,

224
00:13:32,772 --> 00:13:36,138
and provide that message driven asynchronicity sort of

225
00:13:36,164 --> 00:13:39,506
backbone within our application. So that's great. For the data layer. But we

226
00:13:39,528 --> 00:13:43,698
also need to think about how our microservices are interacting together,

227
00:13:43,784 --> 00:13:47,502
whether that's through Kafka or not. And so for this we can introduce reacting

228
00:13:47,566 --> 00:13:51,218
architecture patterns. So reactive architecture design patterns,

229
00:13:51,314 --> 00:13:55,030
there are many of them. We've just listed four here. It's not an extensive list.

230
00:13:55,100 --> 00:13:58,626
These are just four that we've come into sort of contact with fairly

231
00:13:58,658 --> 00:14:01,866
regularly when looking at reactive applications. So we've got

232
00:14:01,888 --> 00:14:05,142
here cqrs, which stands for command, query, responsibility,

233
00:14:05,206 --> 00:14:09,190
segregation. That's essentially all about splitting out the read and the write APIs

234
00:14:09,270 --> 00:14:12,634
so that we can have really high availability of the data within

235
00:14:12,672 --> 00:14:16,174
our application. Then we've got circuit breaker. So circuit breaking is very

236
00:14:16,212 --> 00:14:20,026
similar to the concept in electrical engineering as it is in software. So it's

237
00:14:20,058 --> 00:14:24,186
essentially being these circuit. So in this case, an upstream component recognizes

238
00:14:24,218 --> 00:14:28,382
when a downstream component is under stress or load, or perhaps is failing by perhaps

239
00:14:28,446 --> 00:14:32,174
identifying the same error message coming out of its logs. And that upstream

240
00:14:32,222 --> 00:14:35,358
component can then temporarily put a stop on the request route

241
00:14:35,374 --> 00:14:38,726
to that downstream component or that downstream microservice. And instead it

242
00:14:38,748 --> 00:14:42,406
can reroute that request to an alternative replica microservice. And then

243
00:14:42,428 --> 00:14:45,926
once that downstream component essentially becomes healthy again, it can

244
00:14:45,948 --> 00:14:49,446
then essentially reinstantiate that route to that

245
00:14:49,468 --> 00:14:52,774
downstream component, which prevents it from becoming a potential

246
00:14:52,822 --> 00:14:55,974
point of contentional failure. Then we've got sagas. So sagas

247
00:14:56,022 --> 00:15:00,134
are essentially a mechanism that takes what would have been a more traditional transaction

248
00:15:00,182 --> 00:15:03,374
that maybe we'd have done in a monolithic architecture and do it in a more

249
00:15:03,412 --> 00:15:07,086
distributed manner. So we create these sort of multiple microtransactions that

250
00:15:07,108 --> 00:15:11,034
have this fallback behavior to account for things potentially going wrong partway

251
00:15:11,082 --> 00:15:14,574
through. So it's more of like a sequence of local transactions where that

252
00:15:14,612 --> 00:15:17,726
transaction updates data within a single service. And then we've

253
00:15:17,758 --> 00:15:20,898
got backpressure. So backpressure I sort of mentioned earlier, as well

254
00:15:20,904 --> 00:15:24,258
as circuit breaker, as a potential solution to enabling that

255
00:15:24,344 --> 00:15:27,202
resiliency within our barista microservice application.

256
00:15:27,336 --> 00:15:30,806
Backpressure is a form of feedback. So it's a feedback mechanism from

257
00:15:30,828 --> 00:15:34,962
a downstream component to an upstream component to essentially help rate limit

258
00:15:35,026 --> 00:15:38,626
so that that downstream component doesn't become overloaded or overworked

259
00:15:38,658 --> 00:15:42,054
or stuck in a process and potentially become a point of contention or failure.

260
00:15:42,102 --> 00:15:45,514
So it's a communication and feedback so that we can rate limit these

261
00:15:45,552 --> 00:15:48,778
requests or the messages or events coming to that downstream component from the

262
00:15:48,784 --> 00:15:52,646
upstream component. And many of these are utilized in reactive applications.

263
00:15:52,678 --> 00:15:56,266
But as I said, you can go online and find many, many more reactive architecture

264
00:15:56,298 --> 00:15:59,454
design patterns that you can utilize when you're looking at sort of making sure

265
00:15:59,492 --> 00:16:04,138
that the communication between components of your application is asynchronous

266
00:16:04,154 --> 00:16:07,938
and nonblocking as possible. But what about within our microservices? This is sort of the

267
00:16:07,944 --> 00:16:11,026
next level we need to be thinking about. We also need to ensure that the

268
00:16:11,048 --> 00:16:14,306
logic we're writing within our microservices, the logic within our

269
00:16:14,328 --> 00:16:17,170
application, is also highly responsive,

270
00:16:17,250 --> 00:16:21,074
nonblocking and reactive. And to do this we can utilize something called reactive

271
00:16:21,122 --> 00:16:24,886
programming. So reacting programming, here's a basic definition. It's all

272
00:16:24,908 --> 00:16:28,450
about asynchronicity. Again, it's a paradigm where the availability

273
00:16:28,530 --> 00:16:32,106
of new information is what drives the logic forward, rather than

274
00:16:32,128 --> 00:16:35,770
just by a thread of execution. And we can enable this through several different

275
00:16:35,840 --> 00:16:39,174
programming patterns. So as a Java developer, you're probably familiar

276
00:16:39,222 --> 00:16:42,518
with the concept of futures. If you're not a future is essentially

277
00:16:42,614 --> 00:16:46,110
a promise to hold the result of some operation until that operation is complete.

278
00:16:46,180 --> 00:16:49,706
So really focusing on that asynchronicity there, then we've got reactive programming

279
00:16:49,738 --> 00:16:53,102
libraries. So they are all about composing asynchronous again

280
00:16:53,156 --> 00:16:56,626
and event based programs, and they include examples like Rx Java and

281
00:16:56,648 --> 00:17:00,578
smallrie mutiny and actually lots of the frameworks. We'll be going on to later

282
00:17:00,664 --> 00:17:04,018
utilize these programming libraries within them. And then we

283
00:17:04,024 --> 00:17:07,314
have the reacting stream specification. So this specification is really

284
00:17:07,352 --> 00:17:10,786
a community driven effort to provide a standard for handling

285
00:17:10,818 --> 00:17:14,738
asynchronous data streams in a non blocking manner while providing back pressure

286
00:17:14,754 --> 00:17:18,130
to stream publishers. And again, many of the frameworks we'll look at in a minute

287
00:17:18,210 --> 00:17:21,666
utilize this community driven open source specification.

288
00:17:21,778 --> 00:17:25,386
So we've looked at sort of the different layers of our application and

289
00:17:25,408 --> 00:17:28,790
where we need to be making sure that we have this sort of reactive behavior.

290
00:17:28,870 --> 00:17:32,646
We're looking at the data layer, we're looking at the microservice within the microservice

291
00:17:32,678 --> 00:17:36,494
layer, and between the components, between the microservice layer. But we need to also make

292
00:17:36,532 --> 00:17:40,142
sure the configuration we're using with tools like Kafka also

293
00:17:40,196 --> 00:17:44,106
enable these reactive behaviors. So let's take a look at how we can really utilize

294
00:17:44,138 --> 00:17:47,342
Kafka as best as possible for these reactive systems.

295
00:17:47,406 --> 00:17:50,574
So as I said before, Kafka can be a really great tool for enabling

296
00:17:50,622 --> 00:17:54,354
this message driven asynchronous form of sort of communication within

297
00:17:54,392 --> 00:17:57,918
our application. But what about the other sort of characteristics and behaviors within

298
00:17:57,944 --> 00:18:01,666
the manifesto? So let's look at resiliency first. How do we enable greater

299
00:18:01,698 --> 00:18:05,366
resiliency in Kafka. So Kafka actually is really

300
00:18:05,388 --> 00:18:08,854
beneficial in that it actually has sort of this inbuilt resiliency within

301
00:18:08,892 --> 00:18:12,726
it. So it's different from traditional message queuing systems because it provides

302
00:18:12,758 --> 00:18:16,870
this stream history. So when a consumer loads a record from Kafka,

303
00:18:16,950 --> 00:18:20,486
the record isn't removed from the topic. So that means that both that consumer

304
00:18:20,518 --> 00:18:23,998
and any other consumers can reconsume that record at a later time if

305
00:18:24,004 --> 00:18:27,626
they need to. And that's really useful for enabling consuming applications

306
00:18:27,658 --> 00:18:31,178
to recover really well from potential failures. And that's

307
00:18:31,194 --> 00:18:34,058
where this sort of immutable data comes in. It doesn't get deleted, and that stream

308
00:18:34,074 --> 00:18:37,330
history remains, which means we have a really resilient form

309
00:18:37,400 --> 00:18:41,314
of data retention and data persistence for our application. Kafka also

310
00:18:41,352 --> 00:18:44,786
has inbuilt resiliency in regards to actually how it works itself.

311
00:18:44,888 --> 00:18:48,822
So Kafka, essentially, when you start up a Kafka cluster, it will

312
00:18:48,956 --> 00:18:52,902
contain a set of kafka brokers, and a cluster usually

313
00:18:52,956 --> 00:18:56,374
has a minimum of about three brokers. And we'll see sort of the reasons behind

314
00:18:56,412 --> 00:19:00,098
that later. So Kafka is then broken down further into topics.

315
00:19:00,194 --> 00:19:03,674
And these topics are where we store our records. So a topic is sort of

316
00:19:03,712 --> 00:19:06,778
a logical grouping of a similar kind of message or record.

317
00:19:06,864 --> 00:19:10,518
And then it's up to you to define which messages or which records

318
00:19:10,534 --> 00:19:13,866
will go into which topic. So for example, with our barista example,

319
00:19:13,968 --> 00:19:17,246
we might have one topic for coffee orders, and we might have another topic for

320
00:19:17,268 --> 00:19:20,686
user information updates. But it's up to you to define what those topics are and

321
00:19:20,708 --> 00:19:24,046
which messages and records are going into which. Within a topic, you'll have one or

322
00:19:24,068 --> 00:19:28,362
more partitions. Now, partitions are distributed across the Kafka brokers.

323
00:19:28,506 --> 00:19:31,218
As you can see here, we've got partition one and broker one, partition two and

324
00:19:31,224 --> 00:19:34,610
broker two and partition three and broker three. When it comes to the brokers themselves,

325
00:19:34,760 --> 00:19:38,430
we have something called leaders and followers. So for each topic,

326
00:19:38,510 --> 00:19:41,618
one of the brokers is elected. This is all automatic by Kafka,

327
00:19:41,634 --> 00:19:45,266
but it's elected as the leader. And the other brokers are automatically assigned

328
00:19:45,298 --> 00:19:48,518
sort of a follower status replication. So these application,

329
00:19:48,604 --> 00:19:52,106
your application will connect with the leader broker. And replication of

330
00:19:52,128 --> 00:19:55,830
those records being sent from the application to Kafka get replicated

331
00:19:55,910 --> 00:19:59,142
by the followers repeatedly fetching messages from the leader.

332
00:19:59,206 --> 00:20:02,506
Again, this is all done automatically by Kafka. So this means that all

333
00:20:02,528 --> 00:20:05,274
the apps will connect to the leader, they'll consume and produce to the leader,

334
00:20:05,322 --> 00:20:08,794
and then that information will be duplicated across the different brokers

335
00:20:08,842 --> 00:20:12,282
due to that follower behavior. But what happens in the potential scenario

336
00:20:12,346 --> 00:20:16,286
where our leader broker, for example, goes down? Well, in that case, you might

337
00:20:16,308 --> 00:20:19,618
think that the application's connection with Kafka would be broken. But, no, that's not the

338
00:20:19,624 --> 00:20:22,930
case. Again, we've got this resilient built in behavior. So instead,

339
00:20:23,000 --> 00:20:26,606
what happens is a leader election occurs. So, a leader election is where Kafka

340
00:20:26,638 --> 00:20:30,034
automatically then assigns one of the followers to become the new leader

341
00:20:30,082 --> 00:20:33,586
and automatically switches over that communication to the new leader

342
00:20:33,618 --> 00:20:37,506
broker with your application. So it ensures that your application essentially

343
00:20:37,618 --> 00:20:41,522
continues to be able to communicate to Kafka to consume and produce.

344
00:20:41,666 --> 00:20:45,446
And it means that we still have a replica microservice, a replica broker.

345
00:20:45,478 --> 00:20:48,918
Sorry. So that we can still replicate that data and have that data persistence

346
00:20:49,014 --> 00:20:52,474
and ensure that we've got that resiliency behavior built in in case that second

347
00:20:52,512 --> 00:20:55,386
leader were to go down, for example. And that means it gives enough time for

348
00:20:55,408 --> 00:20:58,634
that broker to essentially come back up again and become a new follower.

349
00:20:58,682 --> 00:21:01,598
So that's really great that it means that we don't lose any data and we

350
00:21:01,604 --> 00:21:04,654
don't lose that connection with Kafka. It's that resilient behavior built

351
00:21:04,692 --> 00:21:08,606
in. So, we've talked about how Kafka itself is resilient. How about how we communicate

352
00:21:08,638 --> 00:21:13,022
with it, with our application? So, when it comes to creating resilient producers,

353
00:21:13,086 --> 00:21:16,734
we have sort of two things that we need to be considering, our delivery guarantees

354
00:21:16,782 --> 00:21:20,406
and our configuration. So, when it comes to trying to be as resilient as possible,

355
00:21:20,508 --> 00:21:23,926
you can't just do this sort of fire and forget method if

356
00:21:23,948 --> 00:21:26,966
you want full resiliency. Because if the broker were to go down with a fire

357
00:21:26,988 --> 00:21:30,086
and forget methodology, your messages could be lost. So we

358
00:21:30,108 --> 00:21:33,558
need to be thinking about our delivery guarantees to make sure that those records

359
00:21:33,574 --> 00:21:37,386
are being received. So, at most once, there's two sort of options.

360
00:21:37,488 --> 00:21:40,634
At most once and at least once at most once. With at most once,

361
00:21:40,672 --> 00:21:43,966
you might lose some messages. It's not completely resilient, but if

362
00:21:43,988 --> 00:21:47,978
you don't mind some of the messages getting sort of getting lost, this does increase

363
00:21:48,074 --> 00:21:51,774
greater throughput. But it isn't the most resilient configuration value we could

364
00:21:51,812 --> 00:21:55,230
use. Instead, we'd be looking at at least once, which ensures that

365
00:21:55,300 --> 00:21:58,606
there is guaranteed delivery of that record. But you may get duplicates.

366
00:21:58,638 --> 00:22:02,274
So that is something to consider when you're trying to pick which delivery guarantee to

367
00:22:02,312 --> 00:22:05,422
use. Then we've got the configuration. So we've got axe and retries.

368
00:22:05,486 --> 00:22:09,218
So axe is short for acknowledgement. And this is essentially acknowledging that the

369
00:22:09,224 --> 00:22:12,454
records or messages have been received by Kafka. You can either

370
00:22:12,492 --> 00:22:16,086
set axe to zero, one, or all. So zero is for when you really

371
00:22:16,108 --> 00:22:19,266
don't care about getting the message acknowledged. It's really good for fast throughput,

372
00:22:19,298 --> 00:22:23,146
but not for resiliency. One. If you set axe to one, it makes sure

373
00:22:23,168 --> 00:22:26,826
that the leader successfully received the message, but doesn't really bother about making

374
00:22:26,848 --> 00:22:30,394
sure the followers have received it. The danger with this is that if, for example,

375
00:22:30,512 --> 00:22:34,258
your broker were to go down after receiving and acknowledging

376
00:22:34,374 --> 00:22:37,566
if the leader had acknowledged that record but the followers hadn't been able

377
00:22:37,588 --> 00:22:41,342
to replicate it, you could potentially lose that record. So it's, again, not the most

378
00:22:41,396 --> 00:22:44,826
resilient, but it is faster in terms of throughput

379
00:22:44,858 --> 00:22:48,354
than all. So all is the last option. And that's essentially where

380
00:22:48,392 --> 00:22:52,046
you wait for all of the replicas to confirm that they've successfully received

381
00:22:52,078 --> 00:22:55,570
the message or record. And it's the most resilient configuration value for this

382
00:22:55,640 --> 00:22:58,754
and these. The other thing you need to consider is retries. So, retries are for

383
00:22:58,792 --> 00:23:02,562
if the axe times out or fails. So how often do you want to retry

384
00:23:02,626 --> 00:23:06,438
sending that record or message? How often do you try reproducing that event?

385
00:23:06,524 --> 00:23:09,926
But what you need to think about is how will that retry potentially affect your

386
00:23:09,948 --> 00:23:13,958
ordering? So this is important to consider when you're setting this retries configuration.

387
00:23:14,054 --> 00:23:17,270
So, let's take a look at consumers. So, with resilient consumers,

388
00:23:17,350 --> 00:23:20,938
the configuration value we need to be aware of is our sort of how we're

389
00:23:20,954 --> 00:23:24,560
committing our offsets. So, again, because Kafka has

390
00:23:25,090 --> 00:23:28,926
these stream history, and it retains all of

391
00:23:28,948 --> 00:23:32,814
the data within it. So it's got this persistence. It means that we

392
00:23:32,852 --> 00:23:36,478
need to be aware of where we've read up to so that

393
00:23:36,484 --> 00:23:39,682
we don't reread a message. If our consumer was to go down, for example,

394
00:23:39,736 --> 00:23:42,302
and come back up again. And to do this, we use something called offsets.

395
00:23:42,366 --> 00:23:45,966
So, offset is just a value assigned to each record within a topic,

396
00:23:45,998 --> 00:23:49,454
and it increases over time. For example, if we added a new record

397
00:23:49,512 --> 00:23:52,758
to this particular topic, it might be either five, depending on what you class the

398
00:23:52,764 --> 00:23:56,134
dotted line as, or six. So there are different methods of

399
00:23:56,172 --> 00:23:59,494
committing that offset. So it means when you commit it. So, for example,

400
00:23:59,532 --> 00:24:03,106
if we had a consumer and they'd read up to one, we'd want to commit

401
00:24:03,138 --> 00:24:06,342
one. So that if the consumer went offline or had to come back up again,

402
00:24:06,396 --> 00:24:09,266
then they would start at two instead of at one. So the two different methods

403
00:24:09,298 --> 00:24:12,958
of committing off offsets are manual and automatic. So let's take a

404
00:24:12,964 --> 00:24:16,254
look at our barista example again to see how these differ in terms

405
00:24:16,292 --> 00:24:19,870
of their resiliency for our application. So with autocommit,

406
00:24:20,210 --> 00:24:23,946
there's no code in the application that determines when this offset

407
00:24:23,978 --> 00:24:27,538
is going to be committed. Instead, it's relying on default settings in

408
00:24:27,544 --> 00:24:31,090
the underlying client, which in this case is probably a Java client. And that means

409
00:24:31,160 --> 00:24:34,654
it's essentially based off a timer. So it will automatically commit

410
00:24:34,702 --> 00:24:38,626
offsets for the messages that the consumer has read from Kafka based on

411
00:24:38,648 --> 00:24:42,054
a default timer method. So in this case, the barista is looking at this

412
00:24:42,092 --> 00:24:45,826
topic. And on our topic we have three records which represents three orders

413
00:24:45,858 --> 00:24:49,286
from our three coffee lovers. So we've got a coffee order, a cappuccino order and

414
00:24:49,308 --> 00:24:52,566
a latte order. So in this, our barista will start at the beginning and will

415
00:24:52,588 --> 00:24:56,326
start producing the coffee order. Now, because we're on auto commit after an allotted

416
00:24:56,358 --> 00:24:59,366
period of time, our offset is going to be committed. So we're going to commit

417
00:24:59,398 --> 00:25:02,598
that offset represented by a tick here. But unfortunately, whilst the barista

418
00:25:02,614 --> 00:25:05,886
is making the coffee order, they trip and they spill the coffee. So they've got

419
00:25:05,908 --> 00:25:09,566
no coffee left anymore. So this is representing that barista microservice going

420
00:25:09,588 --> 00:25:13,358
down partway through processing that record. What this means is that actually when the

421
00:25:13,364 --> 00:25:17,030
barista microservice comes back up again, it looks at where it's committed its offset.

422
00:25:17,050 --> 00:25:20,686
It's already committed the first offset, that coffee order. So instead it starts

423
00:25:20,718 --> 00:25:23,774
at cappuccino. They successfully make cappuccino and latte.

424
00:25:23,822 --> 00:25:26,366
But that means at the end of it all, we've only got two coffee orders

425
00:25:26,398 --> 00:25:29,090
instead of three. So we've lost a record somewhere along the way.

426
00:25:29,160 --> 00:25:32,486
However, let's take a look at manual commit. So manual commit is the sort of

427
00:25:32,508 --> 00:25:35,794
other option you can choose for when to commit that offset for your consumers.

428
00:25:35,842 --> 00:25:39,346
And this is where you write code into your application to determine

429
00:25:39,378 --> 00:25:43,078
when that's going to be committed. That might be preprocessing midway through processing if

430
00:25:43,084 --> 00:25:45,974
you want, or post processing. So in this case, we're going to do it post

431
00:25:46,012 --> 00:25:49,206
processing. We're going to only commit the offset when

432
00:25:49,228 --> 00:25:51,998
we've actually finished to the coffee order and served it up to our customer.

433
00:25:52,084 --> 00:25:54,826
So in this case, when we're making the coffee order, if we were to spill

434
00:25:54,858 --> 00:25:58,254
it, we haven't committed that offset yet. So when our barista microservice comes

435
00:25:58,292 --> 00:26:01,262
back up again, it would know to start back at coffee. So now we only

436
00:26:01,316 --> 00:26:04,330
put that tick up, we only commit that offset when the coffee is served.

437
00:26:04,410 --> 00:26:07,294
And that means by the end of it all, we've got a much more resilient

438
00:26:07,342 --> 00:26:11,006
system because we haven't lost any records,

439
00:26:11,118 --> 00:26:14,418
because we're committing our offsets at the time at which we expect

440
00:26:14,504 --> 00:26:17,714
that behavior to occur. So this is how we know Kafka has built

441
00:26:17,752 --> 00:26:21,206
in resiliency through its stream history and its immutable data and things

442
00:26:21,228 --> 00:26:24,418
like its broker system, its leader, elections, et cetera. And we're

443
00:26:24,434 --> 00:26:27,906
able to introduce greater resiliency through things like our configuration

444
00:26:28,018 --> 00:26:31,846
for our communication between our consumers and our producers with Kafka,

445
00:26:31,878 --> 00:26:35,402
through things like acknowledgements, the commit method you're using,

446
00:26:35,456 --> 00:26:39,270
etc. So let's take a look at the next behavior elasticity. How do we enable

447
00:26:39,350 --> 00:26:42,794
this sort of scalable behavior when utilizing Kafka?

448
00:26:42,842 --> 00:26:46,974
So Kafka is designed to work well at scale and to be scalable itself

449
00:26:47,092 --> 00:26:50,842
and for producing applications it does this using partitions.

450
00:26:50,906 --> 00:26:54,554
So for any particular topic there are usually one or more partitions.

451
00:26:54,602 --> 00:26:58,306
So in this case there are three, because when I created the topic I

452
00:26:58,328 --> 00:27:01,630
specified that I wanted three partitions. So it is something you need to specify.

453
00:27:01,710 --> 00:27:05,234
Kafka will then aim to spread the partitions across particular,

454
00:27:05,432 --> 00:27:09,014
for a particular topic, sorry, across different brokers. This allows us

455
00:27:09,052 --> 00:27:12,790
to really scale produced very easily as they won't have

456
00:27:12,860 --> 00:27:16,114
load for one particular topic on just one specific broker.

457
00:27:16,162 --> 00:27:19,266
And we can always add more brokers if we want to and spread

458
00:27:19,298 --> 00:27:22,906
the loads out more. So it's really great for enabling that spreading of load to

459
00:27:22,928 --> 00:27:26,966
gracefully handle load in our application and enable that scalability

460
00:27:27,158 --> 00:27:30,902
for sort of producers. Actually the interesting part when it comes to scalability

461
00:27:30,966 --> 00:27:34,254
and when we really need to sort of make a conscious effort to enable this

462
00:27:34,292 --> 00:27:37,706
behavior is in our consumers. So consuming in Kafka

463
00:27:37,738 --> 00:27:40,810
is made possible by something called consumer groups.

464
00:27:40,890 --> 00:27:44,190
So when you're consuming messages in Kafka because of this stream history, again,

465
00:27:44,260 --> 00:27:47,074
we need to think about how we're going to handle it, because if we have

466
00:27:47,112 --> 00:27:50,610
multiple consumers all trying to consume from the same topic,

467
00:27:51,350 --> 00:27:55,540
we're running the risk of potentially applications, records or

468
00:27:55,990 --> 00:27:59,494
not getting ordering guarantees, et cetera, et cetera. So in

469
00:27:59,532 --> 00:28:02,854
Kafka we have this consumer group idea to

470
00:28:02,892 --> 00:28:07,074
help ensure that we have sort of ordering guarantee and that we're not rereading

471
00:28:07,122 --> 00:28:11,046
messages from these same consumers. So this really allows sort of scalability of

472
00:28:11,068 --> 00:28:14,514
consumers by grouping them. And this grouping

473
00:28:14,562 --> 00:28:18,086
is enabled via a config value. So you put in a group id so

474
00:28:18,108 --> 00:28:20,958
that you know which consumers are joining which consumer? The group. So let's take a

475
00:28:20,964 --> 00:28:23,726
look at what this looks like in practice. So on these left hand side here,

476
00:28:23,748 --> 00:28:26,858
we have our topic, and we've got our different partitions with some of our records,

477
00:28:26,874 --> 00:28:29,422
and you see the offset on them there. And then on the right hand side,

478
00:28:29,476 --> 00:28:32,798
we have two consumer groups. Consumer group a has three consumers within it,

479
00:28:32,804 --> 00:28:35,838
and consumer group b has two consumers within it. So let's take a look at

480
00:28:35,844 --> 00:28:38,962
how they're going to be linked up to the different partitions. So because you've got

481
00:28:39,016 --> 00:28:42,866
three consumers in consumer group a and three partitions, each consumer will be

482
00:28:42,888 --> 00:28:46,366
assigned a partition. So that means that they're

483
00:28:46,398 --> 00:28:50,214
only reading from one partition. And that's important because that's where

484
00:28:50,252 --> 00:28:53,766
the ordering guarantee comes in. Now with consumer group b, there's only two

485
00:28:53,788 --> 00:28:57,602
consumers. So one of those consumers will read from two partitions.

486
00:28:57,746 --> 00:29:01,522
So essentially you can see that bottom one's reading from partition one and partition two.

487
00:29:01,596 --> 00:29:05,446
So what this means is that by only reading from one partition, we can guarantee

488
00:29:05,558 --> 00:29:09,302
that they're not going to be reading duplicate messages. And from an ordering standpoint,

489
00:29:09,366 --> 00:29:13,146
Kafka provides us ordering guarantee per partition. So it

490
00:29:13,168 --> 00:29:16,346
means that for the first consumer, for example, it will get the messages

491
00:29:16,378 --> 00:29:20,570
from zero in the correct order. So we can ensure that that ordering guarantee remains.

492
00:29:20,650 --> 00:29:23,406
What happens if we want to scale up the number of consumers, though? Here's an

493
00:29:23,428 --> 00:29:26,734
example here. If we were to add a consumer to consumer group a, it actually

494
00:29:26,772 --> 00:29:30,066
would just sit there idle, and that's because there's no partition for it

495
00:29:30,088 --> 00:29:33,506
to read from because we've already got three consumers and three partitions that already

496
00:29:33,528 --> 00:29:37,246
matched up, and we can't assign the same partition to an additional consumer

497
00:29:37,278 --> 00:29:40,454
within the same consumer group because we'd lose that guarantee that we're not

498
00:29:40,492 --> 00:29:44,050
duplicating records and we'd also lose that ordering guarantee.

499
00:29:44,130 --> 00:29:47,234
So actually this consumer would just sit there idle. Now, it might be useful,

500
00:29:47,282 --> 00:29:50,566
for example, if you wanted a spare in case one of the other consumers went

501
00:29:50,588 --> 00:29:53,218
down, it could just pick up where the other one left off and be assigned

502
00:29:53,234 --> 00:29:56,342
that partition. But right now it's essentially just a waste of resource because it's not

503
00:29:56,396 --> 00:29:59,618
sitting there doing pretty much nothing. However, if you were to add it to consumer

504
00:29:59,634 --> 00:30:02,974
group be, it would be able to be assigned a partition because there would be

505
00:30:03,012 --> 00:30:06,874
a spare partition, essentially because you've got one consumer consuming from two partitions.

506
00:30:06,922 --> 00:30:10,302
So this is where you need to be careful when you're setting up your application.

507
00:30:10,436 --> 00:30:13,598
You need to make sure that you're thinking about how many partitions you're going to

508
00:30:13,604 --> 00:30:16,926
need for each topic based on how many consumers you're essentially going

509
00:30:16,948 --> 00:30:20,766
to be sort of potentially scaling up to when you're utilizing

510
00:30:20,798 --> 00:30:24,226
your application. Now you can add new partitions once your

511
00:30:24,248 --> 00:30:27,458
system is already up and running, but an important thing to consider is that the

512
00:30:27,464 --> 00:30:30,786
more partitions you have, the more load you're putting on a system when a leader

513
00:30:30,818 --> 00:30:34,514
election happens, for example, and the ordering is only guaranteed

514
00:30:34,562 --> 00:30:37,574
while the number of partitions remains the same. So as soon as you start

515
00:30:37,612 --> 00:30:41,138
adding partitions, you lose that ordering guarantee once again. So when you're setting

516
00:30:41,154 --> 00:30:43,898
up your system, be sure to think about the number of partitions you're going to

517
00:30:43,904 --> 00:30:47,894
need before you set it up. So that's how we can enable scalability within producers

518
00:30:47,942 --> 00:30:51,498
and consumers in our application. So we've looked at the different behaviors and how

519
00:30:51,504 --> 00:30:54,982
we enable that using Kafka. We've looked at the different layers within our application

520
00:30:55,056 --> 00:30:58,254
and where we need to be introducing these reactive behaviors for an end

521
00:30:58,292 --> 00:31:01,710
to end non blocking reacting application or reacting system.

522
00:31:01,780 --> 00:31:04,890
But how do we actually go about writing reactive Kafka applications?

523
00:31:04,970 --> 00:31:08,898
What tools and technologies can we utilize? So there's obviously the standard

524
00:31:08,984 --> 00:31:12,098
Java Kafka producer and consumer clients that you can take a

525
00:31:12,104 --> 00:31:16,142
look at, but these aren't really designed to be used, they're not optimized

526
00:31:16,206 --> 00:31:19,558
for reactive systems. So instead, what we'd really suggest is taking a

527
00:31:19,564 --> 00:31:22,934
look at some of the open source reactive frameworks and toolkits that are available

528
00:31:23,052 --> 00:31:26,914
that help to provide advantages like simplified Kafka APIs

529
00:31:26,962 --> 00:31:30,978
that are reactive built in back pressure, as we mentioned in the reactive architecture

530
00:31:30,994 --> 00:31:34,610
patterns and the enabling of asynchronous per record processing.

531
00:31:34,690 --> 00:31:38,038
So examples of these open source frameworks specific

532
00:31:38,124 --> 00:31:42,142
for sort of reactive Kafka interactions include, but they're not limited to

533
00:31:42,276 --> 00:31:45,598
alpaca microprofile and vertex. These are the ones we're going to be taking a look

534
00:31:45,604 --> 00:31:48,846
at today. There are others like Project Reactor, which you can definitely take a look

535
00:31:48,868 --> 00:31:51,498
at. We're just not going to be going into it in this presentation, so let's

536
00:31:51,514 --> 00:31:54,506
take a look at these and see what the differences are. So the Alpaca Kafka

537
00:31:54,538 --> 00:31:57,826
connector is essentially it's a connector that allows consuming and

538
00:31:57,848 --> 00:32:01,534
producing from Kafka with something called ACA streams. It's part of this ACA

539
00:32:01,582 --> 00:32:05,090
framework or toolkit. So ACA and things like

540
00:32:05,160 --> 00:32:08,546
the other libraries that sort of interact with it is actually based on

541
00:32:08,568 --> 00:32:12,354
something called the actor model, which is slightly different to things like a microservice

542
00:32:12,402 --> 00:32:16,038
based application. So in the actor model, it is the actor that's a

543
00:32:16,044 --> 00:32:19,590
primitive unit of computation. So it's essentially the thing that receives a message

544
00:32:19,660 --> 00:32:23,574
and does some kind of computation based on it. Messages are sent asynchronously

545
00:32:23,622 --> 00:32:27,254
between actors and they're stored in this sort of mailbox,

546
00:32:27,382 --> 00:32:30,906
and that's how they communicate. It's a different process. It's not a one to one

547
00:32:30,928 --> 00:32:34,298
mapping between an actor and a microservice. So it can take a bit of

548
00:32:34,384 --> 00:32:37,838
sort of a paradigm or way of shift of thinking if you're going from a

549
00:32:37,844 --> 00:32:41,066
microservice based to an actor model. So that's something to bear

550
00:32:41,098 --> 00:32:44,702
in mind if you're considering Alpaca and the actor based model

551
00:32:44,756 --> 00:32:47,954
and ACA. However, if you're already utilizing the actor based model for

552
00:32:47,992 --> 00:32:51,134
your application, definitely worth taking a look at the ACA framework

553
00:32:51,182 --> 00:32:54,686
and the alpaca sort of specifically for its connection

554
00:32:54,718 --> 00:32:57,774
to Kafka. The next framework we're going to take a look at is eclipse microprofile.

555
00:32:57,822 --> 00:33:01,622
So this is really an open source, community driven specification for

556
00:33:01,676 --> 00:33:05,442
enterprise Java microservices. So it works with Java E and Jakarta ee,

557
00:33:05,506 --> 00:33:09,142
and it's really built by the community. So it's a huge range of individuals,

558
00:33:09,206 --> 00:33:12,922
organizations and vendors that contribute to this project. Within this,

559
00:33:12,976 --> 00:33:17,446
there are several different APIs that are offered to really enable greater

560
00:33:17,558 --> 00:33:20,726
sort of ease of building microservice based applications

561
00:33:20,758 --> 00:33:23,866
ready for cloud native through the use of these APIs on top of

562
00:33:23,888 --> 00:33:27,182
something like Java ee or Jakarta ee. So the bottom triangle here,

563
00:33:27,236 --> 00:33:30,554
the dark gray ones at the bottom in that triangle shape, they're the standard APIs

564
00:33:30,602 --> 00:33:33,486
that come as standard as part of the microprofile stack. The ones on the right

565
00:33:33,508 --> 00:33:36,798
hand corner here, the little sideways l shape, are the standalone projects

566
00:33:36,814 --> 00:33:40,686
that the microprofile community also works on. The hope is that these standalone projects

567
00:33:40,718 --> 00:33:44,114
will eventually become part of the standard stack, but right now they're just

568
00:33:44,152 --> 00:33:47,786
separate projects that the same community works on and they integrate

569
00:33:47,838 --> 00:33:51,606
together. So the one that we're actually interested in for reactive in this case is

570
00:33:51,628 --> 00:33:56,022
the reactive messaging specification. So the reactive messaging specification makes

571
00:33:56,076 --> 00:33:59,106
use and sort of interoperates with two other specifications.

572
00:33:59,218 --> 00:34:03,126
One is the reactive streams operator, which is another standalone project, and it provides

573
00:34:03,158 --> 00:34:06,794
a basic set of operators to link different reactive components together and

574
00:34:06,832 --> 00:34:10,106
provide kind of processing on the data that passes between them. And it

575
00:34:10,128 --> 00:34:13,406
actually interoperates with the reactive stream specification that we

576
00:34:13,428 --> 00:34:17,034
mentioned earlier. It's not a microprofile specification it's that community driven specification

577
00:34:17,082 --> 00:34:20,574
I mentioned in the reactive programming part of this presentation. So how

578
00:34:20,612 --> 00:34:24,042
does microprofile reacting messaging actually work? Well, it works by providing

579
00:34:24,106 --> 00:34:27,854
sort of annotations for you to utilize on an application spins methods,

580
00:34:27,902 --> 00:34:31,342
so there's incoming and outgoing annotations that you can utilize.

581
00:34:31,406 --> 00:34:34,814
And these annotated methods are connected together by something called channels.

582
00:34:34,862 --> 00:34:38,814
Now channels are essentially just opaque strings. If you're connecting internally

583
00:34:38,862 --> 00:34:42,466
within your application, it's just called a channel. If you're connecting say to an external

584
00:34:42,498 --> 00:34:46,834
messaging broker, that channel changes its name to a connector. Now because microprofile

585
00:34:46,882 --> 00:34:50,134
is a specification, you'll need to look at the implementations to

586
00:34:50,172 --> 00:34:53,818
understand what connectors they offer, because each implementation will offer

587
00:34:53,904 --> 00:34:57,098
different types of connectors. So the incoming, you can

588
00:34:57,104 --> 00:35:00,666
see here that we've got on method b which says order is connected via that

589
00:35:00,688 --> 00:35:04,698
channel order to say the method a with that outgoing order.

590
00:35:04,784 --> 00:35:07,914
So that's how it's connected and that's how it enables this reactive

591
00:35:07,962 --> 00:35:11,278
sort of behavior. So let's take a look at the final framework. We're going to

592
00:35:11,284 --> 00:35:14,786
take a look at this toolkit and this is the eclipse vertex project. So the

593
00:35:14,808 --> 00:35:18,580
others are sort of based on especially my profile, Java specific,

594
00:35:19,270 --> 00:35:22,754
whereas this is a polyglot toolkit. So it can be used with

595
00:35:22,792 --> 00:35:26,306
Java, JavaScript, Scala, Kotlin, et cetera, many other

596
00:35:26,328 --> 00:35:30,086
languages. It's based on something called the reacting pattern, and this is essentially a

597
00:35:30,108 --> 00:35:33,462
really event driven type of architecture. It uses a single threaded event

598
00:35:33,516 --> 00:35:37,154
loop which is actually blocking on resource emitting events and dispatches

599
00:35:37,202 --> 00:35:40,982
them to corresponding handlers and callbacks. So it's really event

600
00:35:41,036 --> 00:35:44,426
driven, it's non blocking, it runs on the JVM and it

601
00:35:44,448 --> 00:35:47,898
includes these distributed event bus and it's single threaded. And actually

602
00:35:47,984 --> 00:35:51,754
we utilize Kafka in one of our demo applications when we were converting it from

603
00:35:51,792 --> 00:35:55,726
a standard Java Kafka application to be a reacting Java kafka application.

604
00:35:55,828 --> 00:35:59,150
So let's take a look at that demo application. So this isn't necessarily

605
00:35:59,570 --> 00:36:03,258
what you'd want to do in enterprise, but this application was designed

606
00:36:03,354 --> 00:36:06,454
just to be able to help people test their Kafka integration.

607
00:36:06,522 --> 00:36:09,806
So have they set up Kafka correctly? Are they able to produce and consume

608
00:36:09,838 --> 00:36:13,166
from Kafka? Are they able to utilize it to its full advantage

609
00:36:13,198 --> 00:36:16,386
in their application? So in this we have an application that

610
00:36:16,408 --> 00:36:19,618
we actually converted to use vertex and it produced to a Kafka

611
00:36:19,634 --> 00:36:22,854
topic and then consumes back from that Kafka topic. And we also have a front

612
00:36:22,892 --> 00:36:26,326
end application where we can put in custom data

613
00:36:26,428 --> 00:36:29,494
for our messages, custom topics, and we can start

614
00:36:29,532 --> 00:36:32,834
producing and stop consuming and start consuming and stop consuming,

615
00:36:32,882 --> 00:36:36,346
etc. So actually these application is all open source. So if you'd like

616
00:36:36,368 --> 00:36:39,654
to utilize it to test your own application and your own Kafka integration,

617
00:36:39,702 --> 00:36:42,794
feel free. And the front end is all open source in that as well.

618
00:36:42,832 --> 00:36:45,822
Let's take a look at how this application works. So if we press play,

619
00:36:45,876 --> 00:36:48,606
hopefully we can see here that we can put these in our custom message.

620
00:36:48,708 --> 00:36:52,222
We can then click that start producing button, and then we can click the start

621
00:36:52,276 --> 00:36:55,406
consuming button on the right hand side to see those records that have been sent

622
00:36:55,428 --> 00:36:58,546
to Kafka coming back and being consumed from Kafka. So we can see that

623
00:36:58,568 --> 00:37:02,114
here, but we can also stop consuming and stop producing again. So in

624
00:37:02,152 --> 00:37:05,982
this, as we said from the websocket, we're sending this start stop commands.

625
00:37:06,126 --> 00:37:09,218
And so really we needed a way to be able to start and stop that

626
00:37:09,224 --> 00:37:12,854
within Kafka. And when we weren't using reactive frameworks, it become

627
00:37:12,892 --> 00:37:16,182
a bit of a threading nightmare because we had to sort of switch over

628
00:37:16,236 --> 00:37:19,394
threads depending on what we were doing. We had to instigate this pause and resume

629
00:37:19,442 --> 00:37:22,882
functionality and it was quite complicated and difficult to achieve.

630
00:37:22,946 --> 00:37:26,258
Actually, when we switched to using vertex we found all sorts of advantages.

631
00:37:26,354 --> 00:37:30,170
So for the producing side of things, in the original version

632
00:37:30,290 --> 00:37:33,486
of our application, we were doing this sort of start command that was sent

633
00:37:33,508 --> 00:37:36,686
to the back end from the websocket. That backend then started the producer, which sent

634
00:37:36,708 --> 00:37:39,998
a record every 2 seconds, and then we were sending the stop command from the

635
00:37:40,004 --> 00:37:42,526
websocket to the back end and the back end then would stop the producer and

636
00:37:42,548 --> 00:37:46,270
no records would be produced. So in these application, the standard

637
00:37:46,340 --> 00:37:50,114
producer client was essentially this call to produce a record

638
00:37:50,152 --> 00:37:53,106
as a blocking call. But switching over to the vertex producer meant that we could

639
00:37:53,128 --> 00:37:56,574
now get a future back from the send function. So it was a fairly

640
00:37:56,622 --> 00:37:59,910
small change, but it enabled us to switch from a blocking call to

641
00:37:59,980 --> 00:38:03,794
more asynchronous style call. So it meant we were able to asynchronously

642
00:38:03,842 --> 00:38:06,918
produce new records while waiting for the acknowledgement from Kafka of

643
00:38:06,924 --> 00:38:09,974
these in flight records. So it's a fairly small code change, as you can see

644
00:38:10,012 --> 00:38:13,462
here. But changing from non blocking to asynchronous is from

645
00:38:13,516 --> 00:38:17,350
sort of blocking to asynchronous is really important in reactive systems.

646
00:38:17,430 --> 00:38:19,882
But let's take a look at consuming, because this is where we saw sort of

647
00:38:19,936 --> 00:38:23,594
the greatest difference in the original version of the application, we were having

648
00:38:23,632 --> 00:38:26,846
to use this sort of for loop inside a while loop that resulted in this

649
00:38:26,868 --> 00:38:30,446
sort of flow. These we were polling for records and that poll function then

650
00:38:30,468 --> 00:38:33,742
returned a batch of records, and then we're having to iterate through each record

651
00:38:33,796 --> 00:38:36,810
in the batch and these for each record, send the record along the websocket to

652
00:38:36,820 --> 00:38:40,354
the front end, and then only after that entire iteration through all the records was

653
00:38:40,392 --> 00:38:43,906
complete, we'd be able to then essentially go and fetch new

654
00:38:43,928 --> 00:38:47,346
records. So it's quite blocking because we couldn't do anything whilst those records were being

655
00:38:47,368 --> 00:38:50,854
processed. And it didn't feel very asynchronous because we were grabbing batches of records rather

656
00:38:50,892 --> 00:38:54,022
than responding each time a new record came in. So instead,

657
00:38:54,076 --> 00:38:57,378
when we switched to the vertex Kafka client, we were able to use this concept

658
00:38:57,394 --> 00:39:01,654
of a handler function. So every time a new record arrived we were essentially able

659
00:39:01,772 --> 00:39:05,514
to call this handler function. So it made our flow a lot simpler and

660
00:39:05,552 --> 00:39:09,286
we were now able to essentially hand off the step of polling for new records

661
00:39:09,318 --> 00:39:12,566
to allow vertex to do that. So essentially now we just receive

662
00:39:12,598 --> 00:39:15,118
a new record and then we send that record log in the websocket to the

663
00:39:15,124 --> 00:39:19,070
front end for the processing. So this essentially allowed us to process

664
00:39:19,140 --> 00:39:22,686
records on a per record basis rather than a batching basis, and it left

665
00:39:22,708 --> 00:39:25,886
us free to be able to focus on the processing of records rather than

666
00:39:25,908 --> 00:39:29,522
the work of consuming that from Kafka. If you want to find out sort of

667
00:39:29,656 --> 00:39:33,246
all of the benefits that we experienced by switching from a non

668
00:39:33,278 --> 00:39:36,574
reactive to a reacting Java Kafka application, we've written up a blog

669
00:39:36,622 --> 00:39:39,458
here that you can access on the IBM developer site. Feel free to take a

670
00:39:39,464 --> 00:39:42,166
look and hopefully it will show you sort of some of the benefits you might

671
00:39:42,188 --> 00:39:45,394
be able to experience by switching to utilize some of these open source

672
00:39:45,442 --> 00:39:48,706
reactive frameworks and toolkits. So hopefully, in summary, what I've

673
00:39:48,738 --> 00:39:52,746
shown you here is that by taking sort of a non reactive application and

674
00:39:52,768 --> 00:39:55,722
sticking Kafka in, or sticking some adventure of an architectural tool in,

675
00:39:55,776 --> 00:39:59,514
it doesn't give you magically this asynchronous non blocking reactive application.

676
00:39:59,632 --> 00:40:03,374
We need to be carefully considering the Kafka configuration that we use

677
00:40:03,492 --> 00:40:07,210
to create the most reactive system possible. And we can utilize

678
00:40:07,290 --> 00:40:10,782
sort of these open source toolkits and frameworks that can provide

679
00:40:10,836 --> 00:40:14,158
additional benefits as well for us to be able

680
00:40:14,164 --> 00:40:18,058
to create the reacting characteristics and behaviors expected and

681
00:40:18,084 --> 00:40:21,746
needed to be able to create this asynchronous end to end application. But the open

682
00:40:21,768 --> 00:40:25,038
source reactive community is on hand. As I said, there are many open source frameworks

683
00:40:25,054 --> 00:40:28,470
and toolkits you can utilize depending on the architectural style of your application.

684
00:40:28,620 --> 00:40:32,054
So I'm going to demonstrate just how easy it is to get started by

685
00:40:32,092 --> 00:40:36,098
utilizing some of these reactive frameworks for Java kafka

686
00:40:36,114 --> 00:40:39,842
based applications. So I've gone on to our interactive online environment

687
00:40:39,906 --> 00:40:43,002
here where you can utilize some of our modules to get started

688
00:40:43,056 --> 00:40:47,158
with this. And I'm looking at module one here. So reacting reactive Java microservices

689
00:40:47,254 --> 00:40:51,206
where we'll be utilizing the microprofile reactive messaging to write reactive

690
00:40:51,238 --> 00:40:54,762
Java microservices that interact with Kafka. So I've already got the tab open

691
00:40:54,816 --> 00:40:57,566
here. So when you would open it up, it will ask you to sort of

692
00:40:57,588 --> 00:41:01,678
log in via social and that could be sort of any social media really.

693
00:41:01,844 --> 00:41:05,050
I've already logged in. And then when you log in, you get this online environment.

694
00:41:05,130 --> 00:41:08,066
So on the left hand side here I've got the instructions. On the right hand

695
00:41:08,088 --> 00:41:11,182
side I've got can ide. And if I go to terminal, new terminal,

696
00:41:11,246 --> 00:41:14,574
I have a new terminal turn up in the bottom right hand corner.

697
00:41:14,702 --> 00:41:18,338
Now these labs will be available after this session, so feel free to

698
00:41:18,344 --> 00:41:21,666
go through them at your own pace and go through the labs I don't

699
00:41:21,698 --> 00:41:25,254
cover in this session today. So let's get started.

700
00:41:25,372 --> 00:41:28,866
So the great thing about all of these different loads is that they actually utilize

701
00:41:28,898 --> 00:41:32,266
the same application. So here's a basic architectural diagram to

702
00:41:32,288 --> 00:41:35,706
look at, sort of what that looks like. So we've got a system microservice and

703
00:41:35,728 --> 00:41:39,258
an inventory microservice, and they're communicating via Kafka in

704
00:41:39,264 --> 00:41:43,146
the middle there. So actually the system microservice essentially

705
00:41:43,258 --> 00:41:47,642
calculates and publishes an event that contains its average system load every 15 seconds.

706
00:41:47,706 --> 00:41:52,080
And it publishes that to Kafka. And then the inventory microservice consumes that information

707
00:41:52,450 --> 00:41:56,238
and keeps an updated list of all the systems and these current system loads.

708
00:41:56,334 --> 00:42:00,286
We can access that list by accessing the systems

709
00:42:00,318 --> 00:42:03,426
rest endpoint of the inventory microservice. So you can

710
00:42:03,448 --> 00:42:07,374
see here we're utilizing microprofile reactor messaging

711
00:42:07,502 --> 00:42:11,046
in this section of the application and we're utilizing restful APIs to

712
00:42:11,068 --> 00:42:14,758
access that endpoint. So without further ado, let's get started.

713
00:42:14,924 --> 00:42:18,134
So let's just make sure I'm in the right directory here, just in

714
00:42:18,172 --> 00:42:22,118
case. Great. And then we can do a git clone of our repository

715
00:42:22,214 --> 00:42:25,606
and then we can CD into the correct directory which is just guide microprofile reactive

716
00:42:25,638 --> 00:42:29,094
messaging. So we're actually utilizing the guides here from the open Liberty

717
00:42:29,142 --> 00:42:32,630
website. If you want to take a look at what the finished

718
00:42:32,790 --> 00:42:36,490
application should look like after we complete all of this lab, this module,

719
00:42:36,570 --> 00:42:39,582
you can check out the finished directory, but we're going to head into the start

720
00:42:39,636 --> 00:42:43,198
directory for these lab because that's essentially where we can do

721
00:42:43,204 --> 00:42:45,534
all the work. And by the end of it we should get to the same

722
00:42:45,572 --> 00:42:48,686
as the finished directory and it's the same for all of our labs for

723
00:42:48,708 --> 00:42:51,806
that. So we're going to be utilizing these touch commands to make it a bit

724
00:42:51,828 --> 00:42:55,554
easier to create our file system. And then if I head to the explorer

725
00:42:55,602 --> 00:42:59,222
I should be able to see this u represents where I created sort of that

726
00:42:59,276 --> 00:43:03,238
new file. So if we follow that along it should open up for us

727
00:43:03,404 --> 00:43:06,054
and we should be able to see that file if I move this over.

728
00:43:06,172 --> 00:43:09,382
So there's the system service class that we're creating first.

729
00:43:09,516 --> 00:43:13,734
So this is a class for the system microservice, which is the one that's producing

730
00:43:13,862 --> 00:43:17,578
every 15 seconds the average system load. So cpu usage for

731
00:43:17,584 --> 00:43:20,902
the last minute. So if we open that up we should see an empty file

732
00:43:20,966 --> 00:43:24,458
and then we can insert the code we've got available here for you.

733
00:43:24,624 --> 00:43:27,726
Ibm just going to close the Explorer just so it's easier to see in this

734
00:43:27,748 --> 00:43:30,766
environment you do need to save. There isn't an auto save, so make sure you

735
00:43:30,788 --> 00:43:34,580
save because otherwise your application won't be able to build.

736
00:43:35,110 --> 00:43:38,254
So yeah, you should see that dot disappear once it saves.

737
00:43:38,382 --> 00:43:42,158
So because this is a system microservice, we're utilizing the microprofile

738
00:43:42,174 --> 00:43:46,226
reactive messaging outgoing annotation because we're producing to Kafka and

739
00:43:46,248 --> 00:43:50,230
we're producing to the Kafka topic system load. As you can see here,

740
00:43:50,380 --> 00:43:54,210
we're actually making use in this application of one of the reactive programming libraries,

741
00:43:54,290 --> 00:43:58,246
Rxjava, which you can see we're importing here as

742
00:43:58,268 --> 00:44:02,566
well as obviously we're importing the microprofile reactive messaging specification here you can see.

743
00:44:02,748 --> 00:44:06,506
So this Rxjava that we're utilizing, we're utilizing a

744
00:44:06,528 --> 00:44:10,518
method called flowable. So you can see at the bottom here we're utilizing flowable

745
00:44:10,614 --> 00:44:13,886
interval and this allows us to essentially set these frequency of

746
00:44:13,908 --> 00:44:17,262
how often the system service publishes the calculation to the event

747
00:44:17,316 --> 00:44:20,462
stream. We're utilizing flowable because it enables that

748
00:44:20,516 --> 00:44:24,554
inbuilt back pressure. The previous sort of iteration of rxjava included

749
00:44:24,602 --> 00:44:28,114
observable, but they introduced flowable so that they could have that inbuilt back

750
00:44:28,152 --> 00:44:31,310
pressure as an option. So now you have a choice between flowable and observable.

751
00:44:31,390 --> 00:44:35,006
We're utilizing flowable in this. So you can see here's

752
00:44:35,038 --> 00:44:38,918
a basic architectural diagram of what we've just created in this code here.

753
00:44:39,084 --> 00:44:42,018
So let's continue on and look at the inventory microservice.

754
00:44:42,114 --> 00:44:45,526
So for the inventory microservice, we're just going to use this

755
00:44:45,548 --> 00:44:49,126
touch command again and we're creating this inventory resource class.

756
00:44:49,228 --> 00:44:52,834
So again, if we head to our sort of explorer mode, if I close system

757
00:44:52,892 --> 00:44:55,946
and head to inventory, we can see this use sort of directs us on where

758
00:44:55,968 --> 00:44:59,178
to go, which is really helpful. Otherwise you can take a look here in

759
00:44:59,184 --> 00:45:03,226
the instructions and it will show you where to go to find this

760
00:45:03,248 --> 00:45:06,766
new file that you've created. So let's open that up. And once

761
00:45:06,788 --> 00:45:09,502
we open it up, we can then input all the code that we've got down

762
00:45:09,556 --> 00:45:13,054
here. Again, you can utilize the copy buttons in the bottom

763
00:45:13,092 --> 00:45:16,258
right hand corner and just paste it into the ide. That way makes it a

764
00:45:16,264 --> 00:45:19,426
bit easier than highlighting everything and copying it. So because this

765
00:45:19,448 --> 00:45:23,314
is the inventory microservice, we're utilizing the incoming annotation because

766
00:45:23,352 --> 00:45:26,690
we're consuming from Kafka, but we're still consuming from the same system

767
00:45:26,760 --> 00:45:30,110
load. So hence why we've got the system load there. And you

768
00:45:30,120 --> 00:45:33,286
can see a basic architectural diagram, these on the bottom left of what this should

769
00:45:33,308 --> 00:45:36,546
look like when it's all connected together. So now that we've

770
00:45:36,578 --> 00:45:40,246
created these two different classes, we now need to create the microprofile

771
00:45:40,278 --> 00:45:44,074
config properties for each microservice. So again,

772
00:45:44,112 --> 00:45:48,490
we can utilize this touch command to create the file that we need.

773
00:45:48,640 --> 00:45:51,850
So this time we're going to system first

774
00:45:51,920 --> 00:45:55,326
because that's the one we're looking at first. So if we head to system and

775
00:45:55,348 --> 00:45:59,018
instead of going into Java here, we're going to go into resources

776
00:45:59,114 --> 00:46:02,334
and there's the microprofile config properties file. So again,

777
00:46:02,372 --> 00:46:06,186
if we open that up and then copy and paste the configuration we've

778
00:46:06,218 --> 00:46:09,906
got here in the instructions. And again, remember to save, I'll close my

779
00:46:09,928 --> 00:46:13,458
explorer for this. So here you can see that because we're utilizing the

780
00:46:13,544 --> 00:46:16,946
outgoing annotation, you can see outgoing in our configuration. And I

781
00:46:16,968 --> 00:46:20,646
mentioned before how if it's an

782
00:46:20,668 --> 00:46:24,038
external channel that we're trying to connect through, so we're trying

783
00:46:24,044 --> 00:46:27,954
to connect to can external messaging broker, it's actually called a connector and each implementation's

784
00:46:28,002 --> 00:46:31,742
connectors are different. So because we're utilizing the open Liberty

785
00:46:31,906 --> 00:46:35,142
implementation of microprofile, here we're utilizing the Liberty

786
00:46:35,206 --> 00:46:39,450
Kafka connector. You can also see here is where we specify which

787
00:46:39,520 --> 00:46:42,846
Kafka topic that we want to connect to. In this case system load and

788
00:46:42,868 --> 00:46:46,586
we've got a serializer here so we can convert our object into JSOn.

789
00:46:46,618 --> 00:46:50,366
For Kafka, let's take a look at creating the

790
00:46:50,468 --> 00:46:54,058
same configuration file, but this time for the inventory microservice.

791
00:46:54,154 --> 00:46:57,794
So if we use that touch command again, head to our explorer and this time

792
00:46:57,832 --> 00:47:01,198
I'm going to close down system and open up inventory again. Make sure you're

793
00:47:01,214 --> 00:47:04,466
not going into Java, we need to be going into resources instead.

794
00:47:04,568 --> 00:47:08,166
And there's our microprofile configuration file. So if we open that

795
00:47:08,188 --> 00:47:12,770
up and then we can copy and paste in our different configuration.

796
00:47:12,930 --> 00:47:16,530
So for this one it's a little bit different because we're consuming from Kafka

797
00:47:16,610 --> 00:47:20,758
we actually have slightly different configuration. So we're using the incoming

798
00:47:20,774 --> 00:47:24,486
annotation. So we've got incoming in the configuration here. We're still utilizing

799
00:47:24,518 --> 00:47:29,098
the same Liberty Kafka connector because we're still connecting to Kafka using the

800
00:47:29,104 --> 00:47:32,646
open Liberty implementation of microprofile and we're still connecting

801
00:47:32,678 --> 00:47:35,210
to the same topic within Kafka.

802
00:47:35,630 --> 00:47:38,606
This time we've got a deserializer because we want to turn it from JSON back

803
00:47:38,628 --> 00:47:41,918
into an object. But we've also got an extra configuration value here that

804
00:47:41,924 --> 00:47:45,566
we didn't have in the previous configuration properties file. So in this

805
00:47:45,588 --> 00:47:48,338
we've got a group id. And this is what I was referring to when we

806
00:47:48,344 --> 00:47:51,986
were talking about Kafka having this idea of consumer groups. Because this

807
00:47:52,008 --> 00:47:55,266
is a consumer from Kafka, we need to assign it a group id so that

808
00:47:55,288 --> 00:47:58,618
if we were to spin up any other consumers, they would join the same consumer

809
00:47:58,654 --> 00:48:02,326
group and we wouldn't be duplicating processing of the same record

810
00:48:02,508 --> 00:48:06,338
or rereading the same record and we would have that ordering guarantee. So that's

811
00:48:06,354 --> 00:48:10,530
why we have that extra configuration value in this particular configuration

812
00:48:10,610 --> 00:48:14,314
for the inventory microservice. So the next step is to create

813
00:48:14,352 --> 00:48:17,926
a server XML file. So again we can just create this using the touch command

814
00:48:17,958 --> 00:48:21,558
we've already got here. Head to our explorer. We're creating

815
00:48:21,574 --> 00:48:25,530
this for the server microservice, sorry, for the system microservice

816
00:48:25,610 --> 00:48:29,306
we've already created the same server configuration file

817
00:48:29,338 --> 00:48:32,974
for the inventory, which is why you won't be doing it during the steps of

818
00:48:33,012 --> 00:48:36,206
this guide. You can go and check that out if you would like to.

819
00:48:36,308 --> 00:48:39,874
This time we're heading into system and then into liberty. And here you can see

820
00:48:39,912 --> 00:48:43,394
the server XML file that we need. So if we open

821
00:48:43,432 --> 00:48:47,026
that up and then I can copy and paste this code in and

822
00:48:47,048 --> 00:48:49,638
you can see here the different features that we make use of. So you can

823
00:48:49,644 --> 00:48:52,978
see we're making use of the microprofile reactive messaging specification,

824
00:48:53,074 --> 00:48:56,486
but we're also making use of several other APIs that are offered as standards as

825
00:48:56,508 --> 00:48:59,858
part of the microprofile stack. So things like microprofile configuration.

826
00:48:59,954 --> 00:49:03,578
So the configuration files we just made are actually external to our application

827
00:49:03,664 --> 00:49:07,398
logic, which is fantastic when you're trying to make cloud native applications.

828
00:49:07,494 --> 00:49:10,634
So we use it making use of microprofile config for that. We're also

829
00:49:10,672 --> 00:49:14,742
making use of things like microprofile health, JSON B and CDI.

830
00:49:14,886 --> 00:49:18,286
Again, all of these are part of that standard microprofile stack and you can go

831
00:49:18,308 --> 00:49:21,706
and check them out if you want to do some additional work on understanding

832
00:49:21,738 --> 00:49:25,438
those different APIs. We have guides on the open Liberty website that

833
00:49:25,444 --> 00:49:28,626
you can take a look at for each of those. So as I

834
00:49:28,648 --> 00:49:32,066
said, we've already created the same for the inventory microservice because it's exactly the

835
00:49:32,088 --> 00:49:35,586
same file. So we're not going to bother doing that here. So now let's go

836
00:49:35,608 --> 00:49:39,126
ahead and create the maven configuration file so we can actually build this project or

837
00:49:39,148 --> 00:49:42,146
this application again utilizing the touch command.

838
00:49:42,258 --> 00:49:45,526
This time I'm going to close down Src and

839
00:49:45,548 --> 00:49:48,706
I should see underneath system that POM XMl file

840
00:49:48,738 --> 00:49:52,170
I've just created. So again, if we open that up and head into it,

841
00:49:52,240 --> 00:49:55,626
and then I can copy and paste all of the configuration I need into this

842
00:49:55,648 --> 00:49:59,034
file from the instructions copy and paste. And then

843
00:49:59,072 --> 00:50:02,410
remember to save I'll just close my explorer so you can see it better.

844
00:50:02,480 --> 00:50:05,422
So in this you can see all of the different dependencies that we make use

845
00:50:05,476 --> 00:50:08,986
of. So for example, there's that Rx Java dependency, that reactive

846
00:50:09,018 --> 00:50:13,146
programming library, and then we're also making use of Apache Kafka, and here's

847
00:50:13,178 --> 00:50:16,322
that microprofile reactive messaging specification and the standard

848
00:50:16,376 --> 00:50:20,002
microprofile stack as well. And we're also making

849
00:50:20,056 --> 00:50:23,458
use of Jakarta ee. So it's just interesting for you to

850
00:50:23,464 --> 00:50:26,660
see some of the dependencies that we're making use of in this project.

851
00:50:27,510 --> 00:50:30,710
So let's go ahead and start reacting this application.

852
00:50:30,780 --> 00:50:34,470
Let's run the maven install and package loads so that we can create it.

853
00:50:34,620 --> 00:50:38,546
One mistake I've made there is make sure that you are in the start directory.

854
00:50:38,658 --> 00:50:42,362
You don't need to be in the start directory for any of the

855
00:50:42,416 --> 00:50:46,186
touch commands because they automatically make sure they're in the right place. But now

856
00:50:46,208 --> 00:50:49,846
that we're creating this sort of

857
00:50:49,968 --> 00:50:53,662
application, we need to be in the start directory. So now let's try and

858
00:50:53,796 --> 00:50:55,440
run those commands again.

859
00:50:57,810 --> 00:51:00,350
Now it's looking a bit better. Fantastic.

860
00:51:01,970 --> 00:51:04,610
And then we need to do a maven package.

861
00:51:07,910 --> 00:51:11,218
So this docker pull open Liberty command is just to make sure we've got the

862
00:51:11,224 --> 00:51:15,522
latest open Liberty Docker image in our sort of shared online environment here.

863
00:51:15,656 --> 00:51:18,494
Because we're sharing it, we just want to make sure we got the right addition

864
00:51:18,542 --> 00:51:22,166
in and no one sort of messed with that, so it shouldn't take too long.

865
00:51:22,348 --> 00:51:25,970
And the great thing about this environment is that if you're trying multiple

866
00:51:26,130 --> 00:51:29,398
labs it actually saves your progress. So that's why we

867
00:51:29,404 --> 00:51:33,174
have cleanup scripts at the end, so that different directories

868
00:51:33,222 --> 00:51:36,618
and different docker images aren't messing up different labs. But it means that

869
00:51:36,624 --> 00:51:40,026
if you are doing this docker pill, it will essentially stay there for any

870
00:51:40,048 --> 00:51:42,058
of the other labs you do. So you don't have to do this step for

871
00:51:42,064 --> 00:51:44,574
the other labs, but it shouldn't take too long in the first place.

872
00:51:44,612 --> 00:51:47,726
Anyway, there we go. We're complete. So now we can go

873
00:51:47,748 --> 00:51:52,186
ahead and build our two microservices. So first we're going to build the system microservice

874
00:51:52,218 --> 00:51:55,818
and then we're going to build the inventory microservice. Shouldn't take too long because they're

875
00:51:55,834 --> 00:51:59,278
not very big. And then we're going to utilize this start containers script

876
00:51:59,294 --> 00:52:02,366
that we've got which essentially starts up the different docker containers

877
00:52:02,398 --> 00:52:06,218
that we need for this application. So we'll start up docker containers for Kafka

878
00:52:06,254 --> 00:52:10,022
Zookeeper and these microservices in this project. The reason we're still using

879
00:52:10,076 --> 00:52:13,862
Zookeeper is because right now these version of Kafka we're using needs

880
00:52:13,916 --> 00:52:17,474
zookeeper for metadata information. Future versions

881
00:52:17,522 --> 00:52:20,060
of Kafka should essentially be.

882
00:52:21,550 --> 00:52:25,078
Their plan is to enable that metadata to be stored in a topic in Kafka

883
00:52:25,094 --> 00:52:29,290
itself. So you won't necessarily need zookeeper in the future, but right now,

884
00:52:29,440 --> 00:52:32,106
unfortunately we still need it. So that's why we're having to spin that up as

885
00:52:32,128 --> 00:52:35,598
well. So whilst we're waiting for this application to

886
00:52:35,604 --> 00:52:38,910
get up and running, the next step that we're going to be doing is

887
00:52:38,980 --> 00:52:42,366
essentially we're going to be doing a curl command so that we

888
00:52:42,388 --> 00:52:46,526
can ensure that we're successfully getting our system microservice

889
00:52:46,558 --> 00:52:50,386
to access and calculate that average system load, publish that to

890
00:52:50,408 --> 00:52:53,566
Kafka and these successfully consume that from Kafka in our inventory

891
00:52:53,598 --> 00:52:57,394
microservice, update our list of systems and these average system load and

892
00:52:57,432 --> 00:53:00,710
then essentially we can access that via that rest

893
00:53:00,780 --> 00:53:04,214
endpoint. There we are.

894
00:53:04,252 --> 00:53:06,726
So giving it a bit more time. We can see here that now we're able

895
00:53:06,748 --> 00:53:10,038
to access the list via the rest endpoint here. So we

896
00:53:10,044 --> 00:53:12,970
can see the host name, so the name of the system and the average system

897
00:53:13,040 --> 00:53:16,346
loads. If you were to wait a little bit longer, you could then

898
00:53:16,368 --> 00:53:19,942
use these same curl command and you should see a change in that system load

899
00:53:20,006 --> 00:53:23,638
because these is all being calculated every 15 seconds.

900
00:53:23,654 --> 00:53:26,366
So you should see some sort of change. You can see here we've changed from

901
00:53:26,388 --> 00:53:29,120
1.1719 to 1.33.

902
00:53:29,890 --> 00:53:32,974
So hopefully that should show you that actually it can be fairly

903
00:53:33,022 --> 00:53:37,074
easy utilizing a reactive framework or

904
00:53:37,112 --> 00:53:41,086
toolkit to be able to create really reactive responsive Java

905
00:53:41,118 --> 00:53:45,186
kafka based applications if you'd like. Sort of a

906
00:53:45,368 --> 00:53:49,622
very easy read. It's free, it's an ebook, and it's essentially a summary of

907
00:53:49,676 --> 00:53:52,946
everything I've explained in this presentation around reactive. So what reactive

908
00:53:52,978 --> 00:53:56,566
systems are, how you utilize them, how to go about building them, and why

909
00:53:56,588 --> 00:54:00,054
you'd want to. This really short ebook that I helped author is available for

910
00:54:00,092 --> 00:54:03,042
free online. Feel free to download it, share it amongst your colleagues,

911
00:54:03,106 --> 00:54:06,246
or utilize it as a reference point for the different aspects of

912
00:54:06,268 --> 00:54:09,538
reactive I've covered here in this presentation. As if I haven't given you enough links

913
00:54:09,554 --> 00:54:13,326
throughout this presentation, I've also got these a bunch of resources for

914
00:54:13,348 --> 00:54:16,846
you to get started with. If you have any additional questions that I'm not able

915
00:54:16,868 --> 00:54:20,266
to answer, please feel free to reach out to me on Twitter. My Twitter

916
00:54:20,298 --> 00:54:24,222
handle is here at Grace Jansen 27 and I'd be happy to answer your questions.

917
00:54:24,356 --> 00:54:26,220
Thanks very much for listening. Have a great day.

