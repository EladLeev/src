1
00:00:30,690 --> 00:00:34,582
Welcome, everyone. I'm going to talk about how to use SRE to

2
00:00:34,636 --> 00:00:38,146
address unintentional chaos in your development

3
00:00:38,178 --> 00:00:41,686
lifecycles. I refer to this unintentional chaos as

4
00:00:41,708 --> 00:00:45,378
chaotic cat. So let's dive in. So let's

5
00:00:45,474 --> 00:00:48,194
start with chaos engineering.

6
00:00:48,322 --> 00:00:52,238
So, as we all understand that chaos engineering is the practice of

7
00:00:52,404 --> 00:00:55,870
introducing intentional chaos in the production environments to basically

8
00:00:55,940 --> 00:00:58,490
identify areas and opportunities.

9
00:00:58,570 --> 00:01:02,566
Tom, improve residency. So while authoring my book on chaos

10
00:01:02,618 --> 00:01:06,130
engineering, I wondered, but unintentional chaos,

11
00:01:07,110 --> 00:01:10,942
the issues that basically seep into teams

12
00:01:11,086 --> 00:01:15,214
work day in, day out, the scenarios, the workflows that basically cause issues

13
00:01:15,352 --> 00:01:18,646
and take the team's bandwidth away.

14
00:01:18,748 --> 00:01:22,278
What am I talking about? So let's dive into that.

15
00:01:22,364 --> 00:01:25,606
I'm basically talking about three things or three

16
00:01:25,708 --> 00:01:29,478
themes in general. Let's go into those

17
00:01:29,564 --> 00:01:32,822
themes one by one. So the first one really is about speed,

18
00:01:32,886 --> 00:01:36,630
speed to market, or time to market, or the number of deployments

19
00:01:36,710 --> 00:01:40,426
per day, per week, per month. What is it that

20
00:01:40,448 --> 00:01:44,526
we're trying to achieve with that? What number are we trying to achieve? How many

21
00:01:44,628 --> 00:01:48,510
number of deployments are good enough? Where does the buck stop?

22
00:01:48,660 --> 00:01:51,914
So without the defined number of deployments,

23
00:01:51,962 --> 00:01:55,586
without the defined target number of deployments, teams are

24
00:01:55,608 --> 00:01:59,746
constantly chasing an undefined target. Really? Is it

25
00:01:59,768 --> 00:02:02,866
like no matter how many deployments you are

26
00:02:02,888 --> 00:02:05,998
doing per day, per week, it is not good enough because

27
00:02:06,024 --> 00:02:09,894
we have not defined what is good enough. In absence of thats, teams are

28
00:02:09,932 --> 00:02:13,554
under constant pressure to elevate

29
00:02:13,682 --> 00:02:17,506
the game to the next level. If they have been deploying,

30
00:02:17,538 --> 00:02:21,514
let's say ten times a day. So maybe they want to take thats

31
00:02:21,552 --> 00:02:25,494
number to the next level. They maybe want to achieve like 15 deployments

32
00:02:25,542 --> 00:02:28,762
a day or 20 deployments a day. And things will not stop

33
00:02:28,816 --> 00:02:32,106
there. They'll just continue to, as we call

34
00:02:32,128 --> 00:02:35,774
it, continuous improvement, right? So they'll continuously try to improve the

35
00:02:35,892 --> 00:02:39,406
number of deployments per day. But is it really healthy? Is it

36
00:02:39,428 --> 00:02:43,142
really efficient way of looking at the continuous improvement?

37
00:02:43,306 --> 00:02:47,502
Maybe not. So the next theme of unintentional

38
00:02:47,566 --> 00:02:51,294
chaos is dependencies. So when I say dependencies,

39
00:02:51,342 --> 00:02:55,134
I refer to the dependencies within the organization across multiple teams,

40
00:02:55,262 --> 00:02:58,374
or the dependencies on the vendor products

41
00:02:58,412 --> 00:03:01,714
or the vendor APIs. So whether it's about launching a new feature,

42
00:03:01,762 --> 00:03:05,270
rolling out a new feature, or fixing a production incident,

43
00:03:05,610 --> 00:03:09,658
team spend or invest a lot of time in

44
00:03:09,664 --> 00:03:13,126
terms of trying to identify the right team to get the approvals,

45
00:03:13,318 --> 00:03:17,418
or those right team to engage for

46
00:03:17,424 --> 00:03:21,050
the rollout, or trying to fix a production incident

47
00:03:21,130 --> 00:03:24,814
where the incident really seems to be

48
00:03:25,012 --> 00:03:28,222
from the vendor product, not from the own service.

49
00:03:28,356 --> 00:03:31,840
So it's a lot of time back and forth that teams spend

50
00:03:32,290 --> 00:03:35,874
to ensure that the right team is engaged or everyone is on the same

51
00:03:35,912 --> 00:03:40,318
page to fix the incident or to roll out the new feature.

52
00:03:40,494 --> 00:03:44,386
And it really does take

53
00:03:44,408 --> 00:03:48,618
a lot of time, takes a lot of time and also creates

54
00:03:48,814 --> 00:03:52,038
the unintentional chaos. It's like teams SrE trying to

55
00:03:52,044 --> 00:03:55,506
roll out a feature, but they have not received the approval, or let's

56
00:03:55,538 --> 00:03:58,586
say the upgraded API version from the vendor, and the feature is kind of

57
00:03:58,608 --> 00:04:02,106
stuck, even though their work on the feature is done. But because of

58
00:04:02,128 --> 00:04:04,780
the dependencies on the vendor product,

59
00:04:05,150 --> 00:04:08,730
the feature cannot be rolled. Tom, the production environments,

60
00:04:09,630 --> 00:04:13,390
issues like that, that's what I'm referring to. And the next one is

61
00:04:13,540 --> 00:04:17,642
measuring everything. Given the technical capabilities

62
00:04:17,706 --> 00:04:21,930
that we have, with lot of tools and platforms

63
00:04:22,090 --> 00:04:25,474
available to us, we can

64
00:04:25,512 --> 00:04:28,610
measure almost everything. But the question

65
00:04:28,680 --> 00:04:32,498
is, should we? And if not, how do we

66
00:04:32,504 --> 00:04:36,358
know what not to measure? So the dashboards and

67
00:04:36,364 --> 00:04:39,270
monitoring systems can get really complicated, really complex.

68
00:04:40,090 --> 00:04:42,994
But the question then is, all the panels,

69
00:04:43,042 --> 00:04:46,070
all the dashboards that youd have put together, are they really helping,

70
00:04:46,570 --> 00:04:49,960
or they're just there because they need to be there?

71
00:04:51,370 --> 00:04:54,538
How do you know which panels Sre really helping, which dashboards are

72
00:04:54,544 --> 00:04:58,458
really helping, and which data is really helping, which one is not?

73
00:04:58,624 --> 00:05:01,786
How do you know? Where do you draw the line? Which data to capture and

74
00:05:01,808 --> 00:05:03,530
which data to discard?

75
00:05:04,430 --> 00:05:08,766
That's essentially a big question. And in

76
00:05:08,788 --> 00:05:12,800
situations where teams are causing almost everything that they can,

77
00:05:13,110 --> 00:05:16,660
just because their platforms and tools allow them to,

78
00:05:18,230 --> 00:05:21,426
can actually be counterproductive, can actually create more

79
00:05:21,448 --> 00:05:25,314
chaos than solving anything. And let's talk about

80
00:05:25,432 --> 00:05:29,506
how do we get into these kind of situations? What are the precursors,

81
00:05:29,538 --> 00:05:33,746
what are the triggers that land teams

82
00:05:33,778 --> 00:05:36,630
into these kind of situations and what they can do about it?

83
00:05:36,700 --> 00:05:41,002
So one of the reasons, in my experience, is the differentiation between

84
00:05:41,136 --> 00:05:44,458
product and service, or the lack of it.

85
00:05:44,544 --> 00:05:48,070
We don't generally talk about product reliability

86
00:05:48,150 --> 00:05:52,158
or product reliability engineering. We talk about site reliability or

87
00:05:52,324 --> 00:05:55,760
service reliability. So thats is the difference.

88
00:05:56,130 --> 00:05:59,534
So going by the as a service paradigm, a service is really

89
00:05:59,572 --> 00:06:04,846
a running instance of a product. Traditionally, we used Tom buy computers.

90
00:06:04,878 --> 00:06:08,338
Now we use computers on cloud, and we use them as a

91
00:06:08,344 --> 00:06:12,642
service, meaning that we don't really own those

92
00:06:12,696 --> 00:06:16,866
computers, we don't really own the infrastructure on cloud. We just use it

93
00:06:16,968 --> 00:06:20,086
as long as we want it, and then we pay for as long as we

94
00:06:20,108 --> 00:06:23,414
use it. And then when we don't need it,

95
00:06:23,612 --> 00:06:27,334
we stop using it and we stop paying for it. So from that

96
00:06:27,372 --> 00:06:30,794
perspective, service really becomes a running instance of

97
00:06:30,832 --> 00:06:34,246
a product. Teams at the cloud provider,

98
00:06:34,278 --> 00:06:37,786
they are just building that product, but when we use them

99
00:06:37,888 --> 00:06:41,342
as customers, we use them as a service. So what that means

100
00:06:41,396 --> 00:06:45,034
is when a product is really running in the production

101
00:06:45,082 --> 00:06:49,006
environment, that's where the business critical factors like

102
00:06:49,108 --> 00:06:52,818
reliability, availability, performance, those kind of

103
00:06:52,824 --> 00:06:56,500
things come into play. Now, how do we

104
00:06:57,270 --> 00:07:01,442
focus on those aspects while we're building the product

105
00:07:01,576 --> 00:07:04,706
during those development lifecycle? So let's talk about that.

106
00:07:04,808 --> 00:07:08,360
So where does SRE fit and how does it help?

107
00:07:08,810 --> 00:07:12,578
SRE doesn't really have to be an operations

108
00:07:12,674 --> 00:07:16,102
thing. The idea really is that how do we

109
00:07:16,156 --> 00:07:19,654
align the core fundamentals of SRE with the product development lifecycle?

110
00:07:19,702 --> 00:07:22,982
How do we integrate the SRE

111
00:07:23,046 --> 00:07:26,966
practices right into the design and development

112
00:07:26,998 --> 00:07:30,418
lifecycle so that SRE doesn't have to be an afterthought?

113
00:07:30,534 --> 00:07:34,826
So talking of development lifecycles, let's talk about DevOps

114
00:07:34,858 --> 00:07:39,054
for a minute. So one of the core tenets of SRE is service level

115
00:07:39,172 --> 00:07:43,486
objectives, slos. Now, what this image is showing

116
00:07:43,518 --> 00:07:47,550
is where does SLO fit in the DevOps

117
00:07:47,630 --> 00:07:51,300
pipeline? So if you see on the top, we have the development team

118
00:07:51,990 --> 00:07:55,838
working on enhancement, bug fixes, new features, and pushing

119
00:07:55,854 --> 00:07:59,442
all the updates through a continuous delivery pipeline to the production environment.

120
00:07:59,586 --> 00:08:03,506
And on the other side, we have the operations team monitoring

121
00:08:03,618 --> 00:08:07,486
the production environment and the it systems and those platform teams

122
00:08:07,538 --> 00:08:11,370
working with the cloud infrastructure and whatnot.

123
00:08:11,710 --> 00:08:15,770
Now, service level objective, it fits right

124
00:08:15,840 --> 00:08:19,226
in the middle of the pipeline. It's providing a common

125
00:08:19,328 --> 00:08:22,926
objective or a common goal to the development as

126
00:08:22,948 --> 00:08:26,734
bell as the operations team. So let's understand what

127
00:08:26,772 --> 00:08:30,734
SLO is actually doing here, how does it help and

128
00:08:30,932 --> 00:08:35,218
what is it all about in the first place? So SLO is really a

129
00:08:35,304 --> 00:08:39,730
balancing lever or a common language that connects the product

130
00:08:39,800 --> 00:08:43,614
and the service paradigm. I showed the product and the service paradigm

131
00:08:43,662 --> 00:08:47,586
a few slides ago. So product paradigm

132
00:08:47,618 --> 00:08:50,370
is all about innovation, it's all about speed,

133
00:08:50,530 --> 00:08:53,974
how quickly product teams can launch new features and how

134
00:08:54,012 --> 00:08:58,962
innovative they can be. And service paradigm is all about stability,

135
00:08:59,106 --> 00:09:02,966
how reliable the service is, how available the service is. So SLO

136
00:09:02,998 --> 00:09:06,426
provides a common objective, a common language for the product and the

137
00:09:06,448 --> 00:09:10,998
service paradigms together. Product team can be as innovative as

138
00:09:11,024 --> 00:09:14,302
they want to be, as long as they meet the service level

139
00:09:14,356 --> 00:09:17,562
objective. And from those service paradigm,

140
00:09:17,626 --> 00:09:21,418
service perspective, the service needs to be as reliable

141
00:09:21,594 --> 00:09:25,554
as required by the SLO. So it basically

142
00:09:25,672 --> 00:09:29,490
bridges the gap, brings a common language between product

143
00:09:29,560 --> 00:09:32,900
and the service paradigms. And in other terms,

144
00:09:33,510 --> 00:09:36,918
without going into too much of details in

145
00:09:36,924 --> 00:09:42,454
terms of SLI and SLO. So SLO is

146
00:09:42,492 --> 00:09:46,690
a journey that basically translates user expectations

147
00:09:46,770 --> 00:09:50,940
or the customer journeys or the critical business transactions into something

148
00:09:51,710 --> 00:09:55,126
that can be implemented technically in the monitoring

149
00:09:55,158 --> 00:09:58,090
systems. So going by the example on those slide,

150
00:09:59,230 --> 00:10:03,098
let's say a product team is building a login module, or the

151
00:10:03,104 --> 00:10:06,698
login module already exists, that they sre maybe trying to add let's

152
00:10:06,714 --> 00:10:09,886
say a multifactor authentication to the login. And if

153
00:10:09,908 --> 00:10:13,326
they're trying to roll out that feature, the user expectations,

154
00:10:13,518 --> 00:10:17,646
the end user expectation really is that the login should complete successfully.

155
00:10:17,838 --> 00:10:21,918
And while rolling out that feature, the multifactor

156
00:10:21,934 --> 00:10:25,154
authentication feature, product teams really

157
00:10:25,192 --> 00:10:28,486
need to ensure that at least 99% of the

158
00:10:28,508 --> 00:10:32,760
login request could be successful. So they have some sort of

159
00:10:33,690 --> 00:10:37,330
margin of failure. In other terms we call that as error budget.

160
00:10:37,490 --> 00:10:41,026
So the product teams know thats when

161
00:10:41,068 --> 00:10:44,694
rolling out that feature, they need to ensure that the login request,

162
00:10:44,742 --> 00:10:48,234
they continue to work. 99% of the login request should be

163
00:10:48,272 --> 00:10:51,094
successful even with those new feature rollout.

164
00:10:51,222 --> 00:10:54,606
And from the service perspective, the teams have

165
00:10:54,788 --> 00:10:58,234
a target that they need to ensure that 99% of the login

166
00:10:58,282 --> 00:11:01,998
requests SRE successful. So they have a reliability target, they know

167
00:11:02,084 --> 00:11:06,158
how available, how reliable the service seeps to be. So it's

168
00:11:06,254 --> 00:11:10,610
really bringing a common language for the product as well as the service teams

169
00:11:12,070 --> 00:11:15,794
to meet, basically. So the process to define

170
00:11:15,842 --> 00:11:18,390
and implement SLO is really a journey,

171
00:11:19,210 --> 00:11:22,950
or to translate the critical business transactions,

172
00:11:24,090 --> 00:11:28,230
or to identify those risk on the critical business transactions

173
00:11:28,590 --> 00:11:33,094
and translate that into some objective numbers that can be implemented

174
00:11:33,222 --> 00:11:37,286
in the monitoring systems. I will not be deep

175
00:11:37,318 --> 00:11:40,526
diving into the process itself. That's not in the scope of

176
00:11:40,548 --> 00:11:44,090
this talk. So let's continue with the next theme

177
00:11:44,170 --> 00:11:47,898
of unintentional chaos. So the time that teams

178
00:11:47,994 --> 00:11:51,342
spend working out the dependencies, waiting on

179
00:11:51,396 --> 00:11:54,958
other teams basically falls

180
00:11:54,974 --> 00:11:59,074
into a bigger bucket. In the terms

181
00:11:59,112 --> 00:12:01,650
of SRE, we call that bucket as toil.

182
00:12:02,710 --> 00:12:06,226
So let's talk but toil for a minute.

183
00:12:06,338 --> 00:12:10,454
So toil is work, but it's a kind of work thats

184
00:12:10,492 --> 00:12:14,066
chaos. Certain characteristics to it, it tends

185
00:12:14,098 --> 00:12:17,970
to be manual, repetitive, can be automated,

186
00:12:18,050 --> 00:12:22,138
it's tactical, it doesn't carry any long term enduring value, and that

187
00:12:22,224 --> 00:12:25,718
it scales linearly with the service growth.

188
00:12:25,814 --> 00:12:28,246
All the characteristics that are mentioned under toil.

189
00:12:28,358 --> 00:12:31,840
So any work that the teams are doing that has

190
00:12:32,930 --> 00:12:36,974
most of these characteristics, we call that

191
00:12:37,012 --> 00:12:40,474
work as toil in the SRE terms, and waiting on other teams,

192
00:12:40,522 --> 00:12:42,910
waiting on vendor updates,

193
00:12:44,790 --> 00:12:46,770
the inherent dependencies,

194
00:12:47,910 --> 00:12:51,314
in my experience, that kind of work basically falls under

195
00:12:51,352 --> 00:12:56,370
toil in most of the cases thats can be automated and

196
00:12:56,440 --> 00:12:59,954
it doesn't really carry any long term enduring

197
00:13:00,002 --> 00:13:04,054
value. Some examples like I mentioned on the slide, it's like

198
00:13:04,252 --> 00:13:09,322
setting up some environments to reproduce a production issue or

199
00:13:09,376 --> 00:13:13,498
upgrading the API versions manually or basically

200
00:13:13,584 --> 00:13:17,418
work about work, identifying the latency of an application,

201
00:13:17,504 --> 00:13:21,390
how fast users can log in and creating some quick

202
00:13:21,460 --> 00:13:26,346
one pagers, capturing some critical metrics.

203
00:13:26,458 --> 00:13:29,966
So all that kind of work basically in my

204
00:13:29,988 --> 00:13:33,746
experience falls under toil. So bell talk about how we

205
00:13:33,768 --> 00:13:37,906
can address it and how

206
00:13:37,928 --> 00:13:41,954
we can address it and release the bandwidth that the teams are

207
00:13:41,992 --> 00:13:45,558
basically spending in doing this work. So the first things

208
00:13:45,644 --> 00:13:49,234
first, toil cannot be eliminated, it can only be reduced.

209
00:13:49,282 --> 00:13:53,320
And how do we reduce it? It's basically a cultural change

210
00:13:55,290 --> 00:13:56,920
over a period of time.

211
00:13:58,750 --> 00:14:02,602
As the team start focusing more and more on

212
00:14:02,656 --> 00:14:06,106
automation and engineering. Not just automation, more of

213
00:14:06,128 --> 00:14:07,050
engineering.

214
00:14:08,510 --> 00:14:12,586
Engineering basically involves all parts

215
00:14:12,618 --> 00:14:15,946
of the STLC or the development lifecycle.

216
00:14:16,058 --> 00:14:19,402
Automation may not necessarily involve all those steps,

217
00:14:19,466 --> 00:14:22,858
but engineering definitely does. So over a period of

218
00:14:22,884 --> 00:14:26,926
time. When we start focusing more and more on the engineering

219
00:14:26,958 --> 00:14:29,614
efforts, toil tends to reduce.

220
00:14:29,662 --> 00:14:33,026
And in the next few slides I'll show you an example

221
00:14:33,208 --> 00:14:37,282
where we can apply some sort of engineering

222
00:14:37,346 --> 00:14:41,842
mindset to address the dependency

223
00:14:41,906 --> 00:14:45,286
issues that I talked about in the beginning of this talk. So in

224
00:14:45,308 --> 00:14:48,070
terms of measuring everything on monitoring,

225
00:14:49,210 --> 00:14:53,366
in my experience, measuring everything is as bad as

226
00:14:53,468 --> 00:14:57,798
measuring nothing. So really youd need to be strategic

227
00:14:57,894 --> 00:15:00,460
in terms of what is it that we want to measure really?

228
00:15:01,250 --> 00:15:04,906
And the characteristics

229
00:15:04,938 --> 00:15:08,106
of a good monitoring system that it is, is very strategic and it's

230
00:15:08,138 --> 00:15:12,538
very focused on things that really matter from

231
00:15:12,564 --> 00:15:15,806
the user experience, proactive or from the SLOS perspective.

232
00:15:15,918 --> 00:15:19,586
So by fine tuning the monitoring and

233
00:15:19,608 --> 00:15:23,554
the measurement strategies to be aligned a bit more

234
00:15:23,752 --> 00:15:27,814
towards the slos, it's definitely a good step. And the

235
00:15:27,932 --> 00:15:31,826
other thing is we look at application monitoring

236
00:15:31,858 --> 00:15:37,030
and infrastructure monitoring, but I think there is often

237
00:15:37,100 --> 00:15:40,730
ignored or missing aspect, which is dependency monitoring.

238
00:15:41,390 --> 00:15:44,890
We need to understand how an application or a service basically

239
00:15:44,960 --> 00:15:49,366
creates to other applications and services in the workflow

240
00:15:49,558 --> 00:15:53,246
and identifying the downstream dependencies or

241
00:15:53,268 --> 00:15:56,926
the upstream dependencies. Definitely a good strategy to have in

242
00:15:56,948 --> 00:16:00,320
the monitoring space, to be able to

243
00:16:02,310 --> 00:16:06,100
use monitoring for the production incidents or

244
00:16:07,350 --> 00:16:11,486
to ensure thats the time taken to resolve production

245
00:16:11,598 --> 00:16:15,314
incidents is minimized. So let's connect all

246
00:16:15,352 --> 00:16:19,014
these does I talked, but a lot of things. So let's try to

247
00:16:19,132 --> 00:16:22,726
connect all those dots together and then see if

248
00:16:22,748 --> 00:16:26,434
things really make sense. So going over those themes

249
00:16:26,482 --> 00:16:29,962
again, if you talk about speed now,

250
00:16:30,016 --> 00:16:33,482
so with the slos being defined so we can

251
00:16:33,536 --> 00:16:37,386
now define what

252
00:16:37,408 --> 00:16:41,262
is a good enough number of deployments per day. So as long as

253
00:16:41,396 --> 00:16:45,386
the number of deployments is not impacting,

254
00:16:45,418 --> 00:16:49,486
the SLO teams can continue to deploy. So they now have a

255
00:16:49,508 --> 00:16:53,222
defined target, they know where the bug stops,

256
00:16:53,386 --> 00:16:57,586
right? So with the slos we

257
00:16:57,608 --> 00:17:00,866
get a balancing lever, like I talked about. And with that we

258
00:17:00,888 --> 00:17:04,962
can kind of put some numbers into how

259
00:17:05,016 --> 00:17:09,078
fast we want to be in terms of

260
00:17:09,244 --> 00:17:12,854
number of deployments and time to market. So in terms

261
00:17:12,892 --> 00:17:16,054
of resolving dependencies with data. So this is one

262
00:17:16,092 --> 00:17:20,086
example I often quote. So if you were developing

263
00:17:20,118 --> 00:17:23,706
a gaming application and you would want to integrate the

264
00:17:23,728 --> 00:17:26,380
Discord channel into that application,

265
00:17:27,390 --> 00:17:30,906
and if you were to define the SLO

266
00:17:30,938 --> 00:17:34,334
or the user journey, users being able

267
00:17:34,372 --> 00:17:37,758
to connect with their friends on

268
00:17:37,764 --> 00:17:38,960
the Discord channel,

269
00:17:40,930 --> 00:17:44,430
the service would have dependency on a vendor,

270
00:17:44,850 --> 00:17:48,334
on the vendor availability and their APIs and their

271
00:17:48,372 --> 00:17:52,186
performance. So basically you can look at the discord's

272
00:17:52,378 --> 00:17:55,878
status data, it's available on

273
00:17:55,884 --> 00:17:58,626
the Discord status page publicly,

274
00:17:58,818 --> 00:18:02,150
but this is really an example. So you can create

275
00:18:02,220 --> 00:18:05,686
probes to the downstream dependencies, you can get data from

276
00:18:05,708 --> 00:18:09,126
the downstream applications, and when defining the

277
00:18:09,228 --> 00:18:12,806
dependencies and the availability and the slos for

278
00:18:12,828 --> 00:18:16,150
your own services, you can actually go with those data.

279
00:18:16,220 --> 00:18:19,622
So you don't really have to depend on or wait

280
00:18:19,676 --> 00:18:23,374
on on the downstream applications. You can basically

281
00:18:23,492 --> 00:18:27,166
create some sort of probe, you can

282
00:18:27,188 --> 00:18:31,102
collect some trending data from the downstream applications and

283
00:18:31,156 --> 00:18:34,338
make your decisions accordingly. But again, this is only one of

284
00:18:34,344 --> 00:18:38,206
the ways, and it has its own pros

285
00:18:38,238 --> 00:18:42,366
and cons and there sre certain aspects associated

286
00:18:42,398 --> 00:18:46,342
with this approach, but again, one of the approaches, but you get the idea right.

287
00:18:46,396 --> 00:18:50,870
The idea is really instead of just waiting

288
00:18:51,530 --> 00:18:56,546
without any data and kind of depending

289
00:18:56,578 --> 00:18:59,674
on the manual collaboration and things like that.

290
00:18:59,712 --> 00:19:03,386
So we can go with data if it's available. And this is

291
00:19:03,408 --> 00:19:06,700
one of the approaches that we can consider

292
00:19:07,230 --> 00:19:10,670
to resolve the dependency bell.

293
00:19:10,820 --> 00:19:14,410
Finally, on measuring and monitoring

294
00:19:14,490 --> 00:19:18,174
everything like I discussed, we can fine

295
00:19:18,212 --> 00:19:22,010
tune the monitoring and measuring strategies to be more focused on slos.

296
00:19:22,170 --> 00:19:25,666
And in fact, even for the new features, if youd can define the

297
00:19:25,688 --> 00:19:29,826
SLOS upfront or define the

298
00:19:29,848 --> 00:19:33,566
strategies to ensure

299
00:19:33,598 --> 00:19:37,458
that new feature, how do we define the reliability of the new feature and

300
00:19:37,464 --> 00:19:40,934
then define the slos upfront and then

301
00:19:40,972 --> 00:19:44,870
bake that into the development? Bake that into the coding

302
00:19:46,090 --> 00:19:49,434
while the feature is being developed. So it can really help

303
00:19:49,472 --> 00:19:52,486
us achieve a very high signal to noise ratio.

304
00:19:52,678 --> 00:19:57,418
And the monitoring can be very

305
00:19:57,584 --> 00:20:01,434
powerful and useful tool to ensure

306
00:20:01,482 --> 00:20:05,374
that the production incidents have minimum time

307
00:20:05,412 --> 00:20:09,178
to resolve. And the metrics like MTTR or MTBf,

308
00:20:09,354 --> 00:20:12,858
they really improve over a period of time with these kind

309
00:20:12,884 --> 00:20:16,734
of strategies. So that's that. So by shifting SRE

310
00:20:16,782 --> 00:20:20,734
practices to the left, we can minimize the unintentional chaos

311
00:20:20,862 --> 00:20:24,654
in the product development lifecycle and ensure the SRE practices

312
00:20:24,702 --> 00:20:27,926
are baked in, into the design, into the

313
00:20:27,948 --> 00:20:31,346
development. And SRE doesn't have to be an afterthought.

314
00:20:31,538 --> 00:20:35,638
And by doing that, we can ensure that the products that we build,

315
00:20:35,804 --> 00:20:39,862
when we deploy them into production, they are reliable by

316
00:20:39,916 --> 00:20:44,022
design. So that's that.

317
00:20:44,076 --> 00:20:48,280
Thank you so much for listening to me and

318
00:20:49,050 --> 00:20:52,414
feel free to connect act and we can have follow up

319
00:20:52,452 --> 00:20:54,300
discussions if you need to. Thank you so much.

