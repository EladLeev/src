1
00:00:27,090 --> 00:00:30,706
Hi, my name is Greta Yetzita. I'm a senior technical program

2
00:00:30,738 --> 00:00:33,846
manager, Microsoft, and I'd like to talk to you about how you can bring

3
00:00:33,868 --> 00:00:35,800
a security mindset to your team.

4
00:00:37,210 --> 00:00:40,626
To set some context on why I'm talking about the subject,

5
00:00:40,738 --> 00:00:44,614
I'd like to very quickly just talk about my own career journey. When I

6
00:00:44,652 --> 00:00:48,358
finished college, I went straight into a role at IBM working on a

7
00:00:48,364 --> 00:00:52,254
security product had never worked in the space of security before

8
00:00:52,372 --> 00:00:55,760
and I had never even done this as a subject when I was in college.

9
00:00:56,130 --> 00:00:59,806
You can imagine that working on a security product it was very important for

10
00:00:59,828 --> 00:01:03,498
us to think about how we were securing our own systems

11
00:01:03,594 --> 00:01:07,822
as this was something our customers were relying on. And this was a very intimidating

12
00:01:07,886 --> 00:01:10,850
thought for me when I was first entering my career.

13
00:01:12,630 --> 00:01:16,194
After that I was working as a development manager also on

14
00:01:16,232 --> 00:01:19,446
a security product. And at this stage of my career it was

15
00:01:19,468 --> 00:01:22,722
important for me to think about how am I instilling

16
00:01:22,786 --> 00:01:26,054
a security mindset on my team? How was I bringing that

17
00:01:26,092 --> 00:01:29,306
into our culture to make sure that we had

18
00:01:29,328 --> 00:01:32,710
a high quality bar for security standards

19
00:01:32,790 --> 00:01:35,900
and making sure that our customers could really rely on our products.

20
00:01:37,630 --> 00:01:40,774
Today I'm a technical program manager at Microsoft.

21
00:01:40,902 --> 00:01:45,034
We work with some of the largest companies around the world solving

22
00:01:45,082 --> 00:01:48,382
their toughest technical challenges. We work in a code

23
00:01:48,436 --> 00:01:52,342
with model where our software developers work alongside their software

24
00:01:52,426 --> 00:01:55,838
developers to tackle whatever challenge it is that we're

25
00:01:55,854 --> 00:01:59,806
working on and has part of that we like to instill engineering

26
00:01:59,838 --> 00:02:03,140
best practices and that includes thinking about security.

27
00:02:05,830 --> 00:02:09,174
I'm sure many of you are aware of why security is

28
00:02:09,212 --> 00:02:12,920
important to think about or the impact of having poor security.

29
00:02:13,770 --> 00:02:17,426
But to really get that message across, I wanted to share some recent figures

30
00:02:17,458 --> 00:02:21,660
with you. These come from the most recent IBM security report,

31
00:02:22,030 --> 00:02:25,814
which found that the average cost of a data breach globally

32
00:02:25,942 --> 00:02:28,860
is $4.35 million.

33
00:02:30,050 --> 00:02:33,994
When an organizations doesn't have sufficient

34
00:02:34,042 --> 00:02:37,770
security measures in place, that number rises

35
00:02:37,850 --> 00:02:41,280
significantly to $5.57 million.

36
00:02:42,290 --> 00:02:45,842
And more concerning to me is once a data

37
00:02:45,896 --> 00:02:50,242
breach incident occurs, on average it takes 227

38
00:02:50,296 --> 00:02:53,762
days for a team to be able to remediate that

39
00:02:53,816 --> 00:02:57,526
breach. So what can

40
00:02:57,548 --> 00:03:01,622
you and your team do to think about security and

41
00:03:01,676 --> 00:03:06,054
bring security more to the left of your dev

42
00:03:06,092 --> 00:03:07,830
or dev psychops practices?

43
00:03:10,830 --> 00:03:14,678
The first thing that I would recommend is to document

44
00:03:14,774 --> 00:03:18,266
engineering best practices. I know that for

45
00:03:18,288 --> 00:03:22,210
most developers the thought of documentation is daunting.

46
00:03:22,310 --> 00:03:26,270
It's often not the task that we look forward to. But I also

47
00:03:26,340 --> 00:03:29,582
know that when we're adopting a new tool

48
00:03:29,636 --> 00:03:33,114
or a new product and they have good documentation, we often

49
00:03:33,172 --> 00:03:36,882
really appreciate it. I myself have worked on

50
00:03:36,936 --> 00:03:40,354
a high performing team that had really high standards for

51
00:03:40,392 --> 00:03:43,874
security, but they had never documented what the best

52
00:03:43,912 --> 00:03:47,106
practices around security were. And so it was really hard for

53
00:03:47,128 --> 00:03:50,806
me to keep up with that. And when we had new people onboarding onto the

54
00:03:50,828 --> 00:03:54,690
team or there were any major shifts and that knowledge

55
00:03:54,770 --> 00:03:58,450
was no longer there from another team member, this could

56
00:03:58,540 --> 00:04:02,138
often create chaos. And so

57
00:04:02,304 --> 00:04:05,594
if your team is just starting on the journey of security and

58
00:04:05,632 --> 00:04:09,114
you aren't really sure of what your security best practices should

59
00:04:09,152 --> 00:04:12,582
be, I'd highly recommend that you take a look at some resources,

60
00:04:12,646 --> 00:04:15,806
such as OWAsp. They have a top ten list and they

61
00:04:15,828 --> 00:04:19,934
have a lot of other resources. Has. Well, there's the Sans top 25

62
00:04:20,132 --> 00:04:23,746
and the team that I work on. We've also documented something that we

63
00:04:23,768 --> 00:04:26,370
call the CSE engineering playbook.

64
00:04:27,030 --> 00:04:30,478
And this is an overall engineering best practices playbook

65
00:04:30,574 --> 00:04:34,766
that covers a lot of different topics, but we also include security, and I'd

66
00:04:34,798 --> 00:04:38,898
highly recommend taking a look at that as part of your engineering best practices.

67
00:04:39,074 --> 00:04:42,838
I'd recommend that you document things such as your pull request policy,

68
00:04:43,004 --> 00:04:46,950
which might provide guidance, such as how many engineers need to

69
00:04:47,020 --> 00:04:49,846
review a pull request before it's being merged,

70
00:04:50,038 --> 00:04:53,494
or what the guidance is around actually writing

71
00:04:53,622 --> 00:04:57,478
good, constructive feedback into a pull request.

72
00:04:57,654 --> 00:05:01,098
This is something that I hadn't seen before until I had moved

73
00:05:01,114 --> 00:05:05,054
to CSC, and I have found really

74
00:05:05,092 --> 00:05:09,578
creates a great culture around providing good feedback

75
00:05:09,674 --> 00:05:13,454
and enabling others to really have a growth mindset

76
00:05:13,502 --> 00:05:17,314
in taking on that feedback instead of taking it personally or

77
00:05:17,432 --> 00:05:21,234
negatively. I'd also recommend that

78
00:05:21,272 --> 00:05:25,602
you add things around logging and error handling

79
00:05:25,746 --> 00:05:29,714
and a vulnerability management policy. So a vulnerability management

80
00:05:29,762 --> 00:05:33,922
policy might include things like when you've found a vulnerability,

81
00:05:34,066 --> 00:05:37,706
depending on the severity, how long do you have in

82
00:05:37,728 --> 00:05:41,526
order to try and mitigate that? What happens if you can't mitigate

83
00:05:41,558 --> 00:05:45,100
that? Is there some type of escalation path that's in place?

84
00:05:48,670 --> 00:05:52,698
This here is just an example from the CSE engineering playbook that

85
00:05:52,704 --> 00:05:56,778
I've mentioned, and this is some guidance that we've created around pull requests.

86
00:05:56,874 --> 00:06:00,334
This is just a short snippet of it, and you can scroll down

87
00:06:00,372 --> 00:06:03,620
to see a lot more when you're actually in the page itself.

88
00:06:04,550 --> 00:06:08,082
And this is just to give you an example of what your own

89
00:06:08,136 --> 00:06:11,730
guidance might look like for your own engineering best practices.

90
00:06:14,390 --> 00:06:18,422
And something from the developer mindset to think about every

91
00:06:18,476 --> 00:06:21,986
time that you're committing code is have I reviewed

92
00:06:22,178 --> 00:06:25,800
our engineering best practices before I've actually committed this?

93
00:06:29,710 --> 00:06:33,466
The next thing I'd like to talk about is threat modeling. And I

94
00:06:33,488 --> 00:06:37,066
know that the concept of threat modeling, if you've never done it before,

95
00:06:37,248 --> 00:06:39,370
can be quite intimidating.

96
00:06:40,290 --> 00:06:43,994
However, there are so many frameworks and resources

97
00:06:44,042 --> 00:06:47,214
that are out there to support you through this process that

98
00:06:47,252 --> 00:06:50,590
it really isn't has. Scary as it may seem,

99
00:06:52,210 --> 00:06:56,018
you should do threat modeling really whenever you're doing any major

100
00:06:56,104 --> 00:06:59,458
architectural changes, or sometimes even for smaller ones.

101
00:06:59,544 --> 00:07:03,054
And this is something that you might have in your engineering best practices

102
00:07:03,182 --> 00:07:06,686
to define at what stages you need to do threat modeling

103
00:07:06,718 --> 00:07:10,754
for your team. There are a ton of different frameworks

104
00:07:10,802 --> 00:07:14,102
out there that can help you go through the process

105
00:07:14,156 --> 00:07:17,366
of threat modeling. So for example, stride, which is one that I would

106
00:07:17,388 --> 00:07:21,114
often use, or the mitre attack framework. There are also

107
00:07:21,152 --> 00:07:24,826
a lot of tools that will take you through the process itself as

108
00:07:24,848 --> 00:07:28,410
well. So I mentioned OWASp earlier. They have a

109
00:07:28,480 --> 00:07:31,786
threat Dragon tool that will help you go through the threat modeling

110
00:07:31,818 --> 00:07:33,760
process if you've never done it before.

111
00:07:35,650 --> 00:07:39,182
I also highly recommend that you upskill at least one

112
00:07:39,236 --> 00:07:42,566
developers that is able to go through a threat modeling

113
00:07:42,618 --> 00:07:45,854
exercise. It's often not realistic

114
00:07:45,902 --> 00:07:49,474
to go and upskill your entire team taking up a week

115
00:07:49,512 --> 00:07:53,522
or two weeks on a topic. And so getting

116
00:07:53,576 --> 00:07:56,798
at least one developer who's upskilled in this area that can

117
00:07:56,824 --> 00:08:00,214
then share it with the rest of the team can be a really effective way

118
00:08:00,252 --> 00:08:03,720
to start bringing that knowledge into your team.

119
00:08:05,130 --> 00:08:09,066
I have previously worked with a customer that had a

120
00:08:09,088 --> 00:08:13,142
policy that required that we did threat modeling for any major architectural

121
00:08:13,206 --> 00:08:16,220
changes. And we were building an entire platform.

122
00:08:17,150 --> 00:08:20,810
And so we had documented our entire

123
00:08:20,880 --> 00:08:24,126
architecture. We had multiple meetings with their

124
00:08:24,148 --> 00:08:28,400
security team to get them up to speed on what our architecture was,

125
00:08:28,770 --> 00:08:32,518
how the services were communicating to each other, and we handed

126
00:08:32,554 --> 00:08:36,766
that over to them to review. We waited

127
00:08:36,878 --> 00:08:40,274
weeks and it almost came to months

128
00:08:40,472 --> 00:08:43,554
to hear back from them to find out if they

129
00:08:43,592 --> 00:08:46,930
had identified any vulnerabilities or if there were any major changes

130
00:08:47,000 --> 00:08:49,560
that we needed to make before we could release this.

131
00:08:50,570 --> 00:08:54,838
And eventually we heard back from them and we heard that actually

132
00:08:54,924 --> 00:08:58,646
they weren't able to do the threat modeling process because they'd never worked with

133
00:08:58,668 --> 00:09:01,882
any services in the cloud before, and they weren't comfortable doing this

134
00:09:01,936 --> 00:09:05,514
exercise because everything that they have ever worked with before was

135
00:09:05,552 --> 00:09:09,370
on premise. So what we had to do in this case was

136
00:09:09,440 --> 00:09:12,970
we as a team went through the threat modeling exercise ourselves,

137
00:09:13,330 --> 00:09:16,574
and we used one or two people from the team who had expertise in this

138
00:09:16,612 --> 00:09:19,120
area in order to be able to do that.

139
00:09:19,730 --> 00:09:23,070
Then we went back to one of our security

140
00:09:23,140 --> 00:09:27,246
experts at Microsoft and just confirmed that there weren't any major gaps

141
00:09:27,278 --> 00:09:31,598
that we had potentially missed in our threat modeling exercise. And we shared

142
00:09:31,614 --> 00:09:35,346
this back with the security team, with the customer to let them know that

143
00:09:35,368 --> 00:09:38,854
we had thought about this. And up until the time that they feel comfortable going

144
00:09:38,892 --> 00:09:41,862
through this exercise, we had gone through this too.

145
00:09:41,996 --> 00:09:45,238
Not only did this help us build trust with the customer,

146
00:09:45,404 --> 00:09:48,506
but one of the major outcomes of this was that the

147
00:09:48,528 --> 00:09:52,650
developers then once they were actually working on the solution,

148
00:09:53,150 --> 00:09:56,762
they were thinking about security and hardening even

149
00:09:56,816 --> 00:10:00,866
more as they were going through their general development

150
00:10:00,918 --> 00:10:01,710
practices.

151
00:10:04,370 --> 00:10:07,886
So this is an example of what a very basic threat model might

152
00:10:07,908 --> 00:10:11,386
look like. So on the left hand side of this diagram,

153
00:10:11,498 --> 00:10:14,350
we see that we have an external web service,

154
00:10:14,500 --> 00:10:18,082
we see that we have our Internet boundary, and then our cloud

155
00:10:18,136 --> 00:10:21,426
network is our trust boundary. We see that we have three services

156
00:10:21,528 --> 00:10:24,922
within there, and then of course a storage solution.

157
00:10:25,086 --> 00:10:28,706
And then we see four arrows that indicate

158
00:10:28,738 --> 00:10:31,320
the data flow between all of these different services.

159
00:10:33,210 --> 00:10:37,430
At the top right, we see our list of assets

160
00:10:38,110 --> 00:10:41,782
and their entry points and how they're authenticated

161
00:10:41,846 --> 00:10:45,210
with. And then finally at the bottom right, you see

162
00:10:45,280 --> 00:10:48,726
the potential threats and the mitigations to those threats.

163
00:10:48,918 --> 00:10:52,302
So one potential threat might be that any

164
00:10:52,356 --> 00:10:56,682
data that's in transit isn't being encrypted. And the mitigation

165
00:10:56,746 --> 00:11:00,234
to that would make sure that you have the latest version of TLS

166
00:11:00,282 --> 00:11:01,150
enabled.

167
00:11:04,870 --> 00:11:08,354
And for engineers who are going

168
00:11:08,392 --> 00:11:12,114
through a threat modeling practice, or who are even just introducing a new

169
00:11:12,152 --> 00:11:15,518
component into the architecture, some things that you

170
00:11:15,544 --> 00:11:18,646
might think about are is my data encrypted when

171
00:11:18,668 --> 00:11:21,826
it's at rest? Is it encrypted when it's in transit?

172
00:11:21,938 --> 00:11:25,894
And who has access to this service?

173
00:11:26,092 --> 00:11:29,466
And how is this access actually enforced? Or how is this

174
00:11:29,488 --> 00:11:31,130
access policy enforced?

175
00:11:34,190 --> 00:11:37,130
The next thing I'd like to talk about is automation.

176
00:11:37,870 --> 00:11:41,190
I think most developers know the power of automation.

177
00:11:41,350 --> 00:11:44,990
It makes everyone's life easier and everything

178
00:11:45,060 --> 00:11:48,574
is far less error prone. When we have a tool that we can trust

179
00:11:48,692 --> 00:11:51,950
to do some type of action on a regular basis,

180
00:11:52,290 --> 00:11:55,554
there areas different tools that you can use throughout your

181
00:11:55,592 --> 00:11:59,218
development processes to automate some of the security

182
00:11:59,304 --> 00:12:02,562
steps that you might need to take. So some things to think about

183
00:12:02,616 --> 00:12:06,306
automating are for example container dependency scanning

184
00:12:06,338 --> 00:12:10,006
tools. If you're using, for example, kubernetes and

185
00:12:10,028 --> 00:12:13,762
Docker in your infrastructure, static code analysis

186
00:12:13,826 --> 00:12:16,998
tools are thankfully quite popular and I

187
00:12:17,004 --> 00:12:20,698
hope that it's something that you're already using. And this is a great way to

188
00:12:20,784 --> 00:12:24,646
check for vulnerabilities in your code git commit

189
00:12:24,678 --> 00:12:28,794
hooks are super powerful for small things that

190
00:12:28,992 --> 00:12:32,874
can have big consequences. So for example, having a credential

191
00:12:32,922 --> 00:12:36,826
scanner to make sure that you're not accidentally merging

192
00:12:36,858 --> 00:12:40,030
any secrets into your public repository,

193
00:12:40,850 --> 00:12:44,382
you can automate your secrets rotation. This is something

194
00:12:44,436 --> 00:12:47,886
that is not fun to do when it's a manual task,

195
00:12:47,918 --> 00:12:51,620
and so I'd highly recommend automating this step.

196
00:12:51,990 --> 00:12:55,214
And of course there are a lot of pre built security frameworks,

197
00:12:55,262 --> 00:12:59,414
so depending on the languages that your team areas using. So for example net

198
00:12:59,452 --> 00:13:03,046
c sharp or if you're using node js and

199
00:13:03,068 --> 00:13:06,854
you want to introduce authentication or something like

200
00:13:06,892 --> 00:13:10,346
that, there's more than likely library or framework that you can

201
00:13:10,368 --> 00:13:14,118
use in order to enable that. So you don't need to reinvent the wheel

202
00:13:14,214 --> 00:13:16,570
and you can rely on those types of tools.

203
00:13:18,910 --> 00:13:23,066
This is just an example to show how simple it is to introduce

204
00:13:23,098 --> 00:13:26,302
automation. Sometimes I've taken the simplest example here,

205
00:13:26,356 --> 00:13:30,014
but this is using git secrets as

206
00:13:30,052 --> 00:13:33,934
a git commit hook. And here the most basic

207
00:13:33,982 --> 00:13:36,580
step to it really is just doing a make install.

208
00:13:40,870 --> 00:13:44,114
This is also a list of some container scanning tools that you can use.

209
00:13:44,152 --> 00:13:47,606
So things like trivia or aqua. Sonarcube is a

210
00:13:47,628 --> 00:13:51,686
super popular tool already and they have a dependency check

211
00:13:51,788 --> 00:13:55,382
plugin that you can use. And there's also a tool called

212
00:13:55,436 --> 00:13:58,470
Arent, which previously was known as Whitesource.

213
00:14:01,790 --> 00:14:05,660
And a question that a developer might ask themselves is

214
00:14:06,190 --> 00:14:09,130
what are our automated tools not catching?

215
00:14:09,710 --> 00:14:12,874
While they're super useful and do make

216
00:14:12,912 --> 00:14:16,650
the developers process much easier, they do have their gaps.

217
00:14:16,730 --> 00:14:20,126
They're not catching everything. And it's really important to understand what are

218
00:14:20,148 --> 00:14:23,266
the limitations of your tools and what are you doing to mitigate the

219
00:14:23,288 --> 00:14:24,130
limitations.

220
00:14:29,110 --> 00:14:32,850
Last but not least, I'd like for you to consider infrastructure.

221
00:14:33,830 --> 00:14:37,702
We all know that technology is ever

222
00:14:37,756 --> 00:14:41,282
evolving and we get new tools and technologies

223
00:14:41,346 --> 00:14:44,310
that help to make the development process much easier.

224
00:14:44,890 --> 00:14:48,970
But as we start to introduce these new tools and technologies, it's really important

225
00:14:49,040 --> 00:14:52,346
that we understand how are we making sure

226
00:14:52,448 --> 00:14:55,866
that we're not introducing any new attack vectors into our

227
00:14:55,888 --> 00:14:59,642
solution. And so as an example, if your

228
00:14:59,696 --> 00:15:03,306
team is already using kubernetes, or if they're looking to adopt

229
00:15:03,338 --> 00:15:06,526
kubernetes soon, have your team gone and understood what

230
00:15:06,548 --> 00:15:10,538
the security best practices are around adopting kubernetes

231
00:15:10,634 --> 00:15:13,230
and maintaining a Kubernetes infrastructure?

232
00:15:14,150 --> 00:15:18,290
Is your team looking at things like runtime security and having

233
00:15:18,360 --> 00:15:22,082
binary authorization? And also,

234
00:15:22,216 --> 00:15:25,990
have you taken a look at your cloud provider security configuration?

235
00:15:27,530 --> 00:15:30,920
As a lot of organizations are shifting to the cloud,

236
00:15:31,370 --> 00:15:35,266
there are a lot of security concerns. And then there's

237
00:15:35,298 --> 00:15:38,762
also a mindset of the responsibility is

238
00:15:38,816 --> 00:15:42,330
potentially on my cloud provider and it never is.

239
00:15:42,400 --> 00:15:45,626
It's a shared responsibility and it's something that if

240
00:15:45,648 --> 00:15:48,922
you're adopting a service from your cloud

241
00:15:48,976 --> 00:15:52,846
provider, it's important that you understand what the security

242
00:15:52,948 --> 00:15:56,366
best practices are around those. So as an

243
00:15:56,388 --> 00:15:59,262
example, and I'm outing Azure a little bit here,

244
00:15:59,316 --> 00:16:03,058
but by default on a lot of Azure services

245
00:16:03,224 --> 00:16:07,058
there's actually a setting that is

246
00:16:07,224 --> 00:16:10,898
turned on to allow any service from

247
00:16:10,984 --> 00:16:14,114
another tenant or subscription to be able to

248
00:16:14,152 --> 00:16:17,894
communicate with your service. Of course that is

249
00:16:17,932 --> 00:16:21,538
a security concern and we never want that enabled.

250
00:16:21,634 --> 00:16:24,550
We only want to communicate with trusted parties.

251
00:16:25,050 --> 00:16:28,746
And so anytime I go and work on a customer engagement and

252
00:16:28,768 --> 00:16:32,042
they have previous Azure services in place,

253
00:16:32,096 --> 00:16:35,290
I always go and make sure that they have this disabled.

254
00:16:35,870 --> 00:16:39,990
Another thing to think about when you're considering security outside

255
00:16:40,080 --> 00:16:43,354
of just your code base or your DevOps

256
00:16:43,402 --> 00:16:47,438
pipeline is to consider the maintainability of those

257
00:16:47,524 --> 00:16:50,320
additional security measures that you're taking.

258
00:16:51,410 --> 00:16:55,234
So for example, we have a motto in

259
00:16:55,272 --> 00:16:58,978
the organizations that I work in where we always meet the customer

260
00:16:59,064 --> 00:17:02,622
where they are. When we're working with a relatively junior

261
00:17:02,686 --> 00:17:06,870
team, we're not going to recommend a lot of more

262
00:17:06,940 --> 00:17:09,960
complex security solutions. So for example,

263
00:17:10,490 --> 00:17:14,200
introducing vpns when they have a very simple

264
00:17:15,610 --> 00:17:18,934
infrastructure that they're working with in the first place. So we

265
00:17:18,972 --> 00:17:23,238
might introduce a phased approach where we have an initial set of recommendations

266
00:17:23,334 --> 00:17:27,002
that is more maintainable for the team and then we provide

267
00:17:27,056 --> 00:17:30,590
them with where they need to get to and what additional security

268
00:17:30,660 --> 00:17:33,760
steps they need to introduce in the future.

269
00:17:37,170 --> 00:17:41,454
So this is just an example of the Kubernetes best practices that

270
00:17:41,492 --> 00:17:45,162
are documented on their website. It's not an exhaustive

271
00:17:45,226 --> 00:17:48,946
list at all, but it's a really great resource to

272
00:17:48,968 --> 00:17:52,610
take a look at for your team. If they're using something like Kubernetes or whatever

273
00:17:52,680 --> 00:17:55,606
it is that you're using, make sure you go and take a look at the

274
00:17:55,628 --> 00:17:59,510
documentation and look for what they have around security recommendations.

275
00:18:01,610 --> 00:18:05,734
This here is an example from one of the Azure services or

276
00:18:05,852 --> 00:18:09,114
virtual machines, just some of the recommended best

277
00:18:09,152 --> 00:18:12,380
practices that users should take.

278
00:18:15,470 --> 00:18:19,606
And so the question that a developer should ask themselves whenever

279
00:18:19,638 --> 00:18:22,318
they're making a change to their infrastructure is,

280
00:18:22,484 --> 00:18:26,350
is my change in compliance with our security policies?

281
00:18:29,970 --> 00:18:33,614
To conclude my talk, I'd like to share some potential next

282
00:18:33,652 --> 00:18:37,346
steps that you can take. And the first one is to take a look at

283
00:18:37,368 --> 00:18:41,954
your team and where they are on their journey to shifting left.

284
00:18:42,152 --> 00:18:46,754
You can take a look at the CSE Engineering playbook Owasp

285
00:18:46,802 --> 00:18:50,198
Sans, or any other good security

286
00:18:50,284 --> 00:18:53,894
resources that you're aware of. To really understand what the best

287
00:18:53,932 --> 00:18:57,682
practices are and how your team aligns with those best practices

288
00:18:57,746 --> 00:19:01,746
and where your potential gaps are, I'd also highly

289
00:19:01,778 --> 00:19:06,194
recommend that you get at least one person on your team upskilled

290
00:19:06,242 --> 00:19:09,686
on security fundamentals. This person can help you get

291
00:19:09,708 --> 00:19:13,294
that knowledge sharing done across your team and

292
00:19:13,332 --> 00:19:16,622
can help you really get that security mindset adopted across

293
00:19:16,676 --> 00:19:20,126
your team. That's everything that I wanted to share with

294
00:19:20,148 --> 00:19:23,502
you, so I thank you for your time again.

295
00:19:23,556 --> 00:19:27,066
If you'd like to take a look at the engineering playbook that I spoke

296
00:19:27,098 --> 00:19:30,746
about today, you can just search online for CSE engineering

297
00:19:30,778 --> 00:19:33,440
playbook. I'm sure it's the first thing that will pop up.

298
00:19:33,970 --> 00:19:34,460
Thank you.

