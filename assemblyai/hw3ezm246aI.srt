1
00:00:00,250 --> 00:00:01,630
Are you an SRE,

2
00:00:03,570 --> 00:00:04,830
a developer,

3
00:00:06,610 --> 00:00:10,474
a quality engineer who wants to tackle the challenge of improving

4
00:00:10,522 --> 00:00:14,026
reliability in your DevOps? You can enable your DevOps

5
00:00:14,058 --> 00:00:16,510
for reliability with chaos native.

6
00:00:16,930 --> 00:00:19,530
Create your free account at Chaos native.

7
00:00:19,610 --> 00:01:17,014
Litmus cloud hi

8
00:01:17,052 --> 00:01:20,454
there. I am Joshua Arvin Lat and

9
00:01:20,492 --> 00:01:24,406
I'm going to talk about pragmatic site reliability engineering for

10
00:01:24,428 --> 00:01:27,994
kubernetes in the cloud. So before we

11
00:01:28,032 --> 00:01:31,766
start, I'm going to introduce myself. I am the chief

12
00:01:31,798 --> 00:01:35,850
technology officer of Nuworks Interactive Labs and

13
00:01:35,920 --> 00:01:39,814
I'm also an AWS machine learning hero. I'm also one

14
00:01:39,952 --> 00:01:43,534
of the subject matter experts who help update the

15
00:01:43,572 --> 00:01:46,110
certification exams globally.

16
00:01:46,930 --> 00:01:50,874
And finally, I am the author of the book Machine

17
00:01:50,922 --> 00:01:53,650
Learning with Amazon Sagemaker Cookbook.

18
00:01:54,230 --> 00:01:57,810
So in this book we have 80 proven recipes for data

19
00:01:57,880 --> 00:02:01,886
scientists and developers to perform machine learning experiments

20
00:02:01,918 --> 00:02:05,814
and deployments. So you'll see a lot of customizations there

21
00:02:05,852 --> 00:02:09,362
using docker and using different techniques

22
00:02:09,426 --> 00:02:13,606
in order to port your machine learning model and get that to work in

23
00:02:13,628 --> 00:02:15,590
the cloud with Sagemaker.

24
00:02:17,870 --> 00:02:22,902
So let's start with the first practical

25
00:02:22,966 --> 00:02:26,950
tip. When dealing with pragmatic site reliability

26
00:02:27,030 --> 00:02:30,334
engineering Kubernetes, the first thing that comes into

27
00:02:30,372 --> 00:02:34,080
mind would be if there's going to be an issue,

28
00:02:34,530 --> 00:02:38,878
how fast would we be able to detect and

29
00:02:38,964 --> 00:02:42,174
manage that issue? So we need to

30
00:02:42,212 --> 00:02:46,100
find ways to visualize and know what's happening inside.

31
00:02:46,790 --> 00:02:50,430
So if you have a lot of nodes in your Kubernetes

32
00:02:50,510 --> 00:02:54,114
cluster, and there are different types of

33
00:02:54,152 --> 00:02:57,894
logs, logs from your application, maybe logs from

34
00:02:57,932 --> 00:03:01,254
your network, and so on, things get a bit

35
00:03:01,292 --> 00:03:04,898
trickier when you have to deal with a lot of logs and finding

36
00:03:04,914 --> 00:03:08,278
ways to visualize what's really happening, especially knowing

37
00:03:08,374 --> 00:03:12,346
the metrics, knowing what's wrong, knowing what

38
00:03:12,368 --> 00:03:15,420
part of the system is not working and what parts SRE working,

39
00:03:16,510 --> 00:03:20,286
it's not that easy as we SRE

40
00:03:20,308 --> 00:03:24,480
talking about it right now. So what we can do about it is

41
00:03:25,330 --> 00:03:29,118
maybe we can start using additional tools on

42
00:03:29,124 --> 00:03:32,994
top of the Kubernetes setup and allowing different end

43
00:03:33,032 --> 00:03:36,910
users to access those monitoring tools.

44
00:03:37,070 --> 00:03:40,562
Of course, we may be tempted to just allow

45
00:03:40,696 --> 00:03:44,226
the pragmatic site reliability engineering access those

46
00:03:44,328 --> 00:03:47,926
tools. However, the stability of

47
00:03:47,948 --> 00:03:51,746
the entire system depends on both the software

48
00:03:51,778 --> 00:03:55,734
engineers and the site reliability engineers. Because for one thing,

49
00:03:55,852 --> 00:03:59,354
infrastructure is just one part and then the other

50
00:03:59,392 --> 00:04:03,014
part would involve the application side, which the software

51
00:04:03,062 --> 00:04:06,170
engineers are continuously building on top of.

52
00:04:06,320 --> 00:04:10,666
So if there's an issue, let's say that you

53
00:04:10,688 --> 00:04:14,062
have an ecommerce website and then there sre three or four

54
00:04:14,116 --> 00:04:18,090
different parts and there's something wrong with the checkout flow

55
00:04:18,250 --> 00:04:21,902
that users can check out, or for some reason, the third

56
00:04:21,956 --> 00:04:25,170
page before the checkout page isn't working.

57
00:04:25,320 --> 00:04:29,554
So being able to detect what's wrong is

58
00:04:29,592 --> 00:04:33,758
a responsibility shared by both groups, both the software engineers

59
00:04:33,854 --> 00:04:38,454
and the site reliability engineers. And finally, it's about just

60
00:04:38,492 --> 00:04:42,246
making sure that people have the right access levels and we

61
00:04:42,268 --> 00:04:46,598
just give them the appropriate charts and

62
00:04:46,684 --> 00:04:50,026
tools to debug the problems. The next thing that we

63
00:04:50,048 --> 00:04:54,246
need to think about is what if there are so many servers

64
00:04:54,358 --> 00:04:59,306
and nodes and containers and services we need to worry about here?

65
00:04:59,488 --> 00:05:02,686
So it's critical that we're able to manage the

66
00:05:02,708 --> 00:05:06,494
data, the logs data, and being able to connect it

67
00:05:06,532 --> 00:05:10,186
properly with the monitoring tools. Because if we're

68
00:05:10,218 --> 00:05:14,174
not able to clean things ahead of time and doing it in an automated fashion,

69
00:05:14,222 --> 00:05:18,014
then the software engineers and site reliability engineers

70
00:05:18,062 --> 00:05:21,060
would have a hard time solving the problem.

71
00:05:22,950 --> 00:05:27,334
So when dealing with production level stuff,

72
00:05:27,532 --> 00:05:31,880
the number one thing that comes into mind would be time.

73
00:05:32,330 --> 00:05:36,054
We can talk about concepts all day long,

74
00:05:36,252 --> 00:05:39,654
but when we're dealing with reality, we have to worry

75
00:05:39,702 --> 00:05:43,100
about time. So when you have an issue,

76
00:05:43,550 --> 00:05:47,718
if the issue gets resolved right away, let's say automatically,

77
00:05:47,894 --> 00:05:51,462
then that saves us time, because an automated process

78
00:05:51,536 --> 00:05:55,166
is definitely better than a human who would

79
00:05:55,188 --> 00:05:58,478
still have to process and look for the issues.

80
00:05:58,564 --> 00:06:01,834
So if, let's say that there's a self healing setup involved,

81
00:06:01,962 --> 00:06:05,570
then that's much better, at least as the first layer.

82
00:06:05,910 --> 00:06:09,842
Next, if some analysis is needed and the

83
00:06:09,896 --> 00:06:13,918
problem is custom, then it would involve both automated

84
00:06:14,014 --> 00:06:18,374
and manual solutions for it. So let's say that

85
00:06:18,572 --> 00:06:22,466
you deployed something and that caused

86
00:06:22,498 --> 00:06:26,040
the system to become unstable. Then you would need

87
00:06:26,650 --> 00:06:30,266
a human to solve that problem. Let's say by rolling back

88
00:06:30,368 --> 00:06:34,490
or by doing some tweaks in the current setup or configuration.

89
00:06:35,310 --> 00:06:39,306
Speaking of time, let's play a

90
00:06:39,328 --> 00:06:43,166
quick game. So what's the game all about?

91
00:06:43,348 --> 00:06:46,766
So in this game, I'm going to let everyone

92
00:06:46,868 --> 00:06:50,334
count the number of apples in this slide and

93
00:06:50,372 --> 00:06:53,226
I'm going to share a reward.

94
00:06:53,418 --> 00:06:56,866
So for those who's going to win this game,

95
00:06:56,968 --> 00:07:00,370
in this game, we're going to give,

96
00:07:00,440 --> 00:07:03,938
I think, 25% discount. For those who will try CTO,

97
00:07:04,024 --> 00:07:08,454
purchase the book, the book that I've written this

98
00:07:08,492 --> 00:07:12,470
past couple of months. So again, if you win the game

99
00:07:12,620 --> 00:07:15,682
and you get the number of apples correctly in the next slide,

100
00:07:15,826 --> 00:07:18,746
then we'll share that promo code to you so that you can use it to

101
00:07:18,768 --> 00:07:22,300
buy the ebook. All right, so are you guys ready?

102
00:07:22,990 --> 00:07:26,586
So I'm going to give everyone 20 seconds to

103
00:07:26,608 --> 00:07:30,346
count the number of apples here. And as mentioned. For the

104
00:07:30,368 --> 00:07:33,646
winners, we'll give a 25% discount and we'll provide a

105
00:07:33,668 --> 00:07:36,110
promo code. Promo code separately.

106
00:07:36,690 --> 00:07:39,150
So, 20, 19,

107
00:07:39,490 --> 00:07:41,790
18, 17,

108
00:07:42,210 --> 00:07:45,550
16, 15, 14,

109
00:07:45,890 --> 00:07:48,906
13, 12, 1110,

110
00:07:49,098 --> 00:07:56,678
9876-5432,

111
00:07:56,764 --> 00:08:00,230
and one. So stop counting.

112
00:08:00,650 --> 00:08:04,870
So, if you have guessed, let's say, 20 apples,

113
00:08:05,690 --> 00:08:08,726
that's incorrect. All right, so let's

114
00:08:08,758 --> 00:08:12,806
try something lower. Let's say 17. If you've guessed

115
00:08:12,838 --> 00:08:16,886
17, unfortunately, that's also incorrect.

116
00:08:17,078 --> 00:08:20,982
How about 24? So, for those who have tried guessing

117
00:08:21,046 --> 00:08:24,270
that it's 24, you are also incorrect. So what's the correct

118
00:08:24,340 --> 00:08:27,294
answer? There's no correct answer for this,

119
00:08:27,412 --> 00:08:31,166
because, for one thing, it's impossible to count the number of

120
00:08:31,188 --> 00:08:34,594
apples in this slide because there

121
00:08:34,632 --> 00:08:37,998
may be apples underneath the initial layer

122
00:08:38,014 --> 00:08:41,266
of apples. And the lesson that I want to share with

123
00:08:41,288 --> 00:08:45,154
you guys here is that when things are not organized and

124
00:08:45,192 --> 00:08:49,682
when it's hard to look for the needle in the haystack,

125
00:08:49,826 --> 00:08:53,826
then it would be hard for us to identify what the problem is. So let's

126
00:08:53,858 --> 00:08:57,366
say that we were given a different set of problem similar to

127
00:08:57,388 --> 00:09:00,502
this one. Let's say that the apples are organized

128
00:09:00,566 --> 00:09:04,810
and there's a ten by ten block of apples,

129
00:09:07,070 --> 00:09:11,050
and then there are ten layers. So we're sure that ten by ten times

130
00:09:11,120 --> 00:09:14,318
ten, that would be 1000 apples much easier to count,

131
00:09:14,404 --> 00:09:17,662
because the data is organized. And the same way,

132
00:09:17,796 --> 00:09:21,966
it would take us a lot of time to count the number of apples if

133
00:09:21,988 --> 00:09:25,450
it's disorganized like this. And then if we were to

134
00:09:25,540 --> 00:09:28,978
clean things up and organize things ahead of time, then it would

135
00:09:28,984 --> 00:09:32,146
be easy to find and do aggregates and

136
00:09:32,168 --> 00:09:36,006
counts, and even look for the specific apple that we're looking for.

137
00:09:36,188 --> 00:09:40,598
So, that said, for those who sre

138
00:09:40,764 --> 00:09:44,134
a bit disappointed that they were not able CTo win that

139
00:09:44,252 --> 00:09:47,378
prize, I'll just say that I'll

140
00:09:47,394 --> 00:09:50,922
be nice today and I'll just give out 25%

141
00:09:50,976 --> 00:09:53,642
discount by using the code 25.

142
00:09:53,696 --> 00:09:57,450
Joshua. And yeah, I think it's valid between

143
00:09:57,520 --> 00:10:01,166
October 22 and December 31 of this year.

144
00:10:01,348 --> 00:10:05,440
So just take a screenshot and then use that

145
00:10:05,890 --> 00:10:08,942
when the book is launched. I think next month.

146
00:10:09,076 --> 00:10:12,254
Yeah, a couple of weeks from now. So,

147
00:10:12,292 --> 00:10:15,794
that said, why are these things

148
00:10:15,832 --> 00:10:20,114
important? These things are important because the

149
00:10:20,152 --> 00:10:23,746
faster we're able to solve problems, the better the

150
00:10:23,848 --> 00:10:27,782
system is configured, the better is our capability to

151
00:10:27,836 --> 00:10:31,602
manage the SLI, SLO and SLA.

152
00:10:31,746 --> 00:10:35,426
So we won't talk about these things in detail here. But if you're

153
00:10:35,458 --> 00:10:38,818
already aware of the fundamentals of SRE,

154
00:10:38,994 --> 00:10:42,634
it's critical that we're able to manage this and have

155
00:10:42,672 --> 00:10:45,878
a plan for it, because we cannot just assume that we'll

156
00:10:45,894 --> 00:10:48,954
be able to reach these targets. And yeah,

157
00:10:49,152 --> 00:10:53,626
we need to have a plan. And later, the other nine tips

158
00:10:53,658 --> 00:10:57,790
that I'm going to share would help us do SRE properly.

159
00:10:58,610 --> 00:11:02,174
The next tip would be knowing the

160
00:11:02,212 --> 00:11:05,442
options and alternatives. So in the screen,

161
00:11:05,496 --> 00:11:09,230
we will see some of the possible tools

162
00:11:09,390 --> 00:11:12,210
that we can use with Kubernetes.

163
00:11:13,190 --> 00:11:17,502
Let's say we have rancher, we have Prometheus, we have Kali, we have istio,

164
00:11:17,646 --> 00:11:20,754
we have appmesh, and we have helm.

165
00:11:20,882 --> 00:11:24,614
So you may or may not use some of these tools, but what these

166
00:11:24,652 --> 00:11:28,314
tools help us with is that instead of us trying to build our own

167
00:11:28,352 --> 00:11:31,942
solution, let's just learn what majority

168
00:11:32,006 --> 00:11:34,906
of the users of Kubernetes are using,

169
00:11:35,088 --> 00:11:38,534
so that if we have a requirement,

170
00:11:38,662 --> 00:11:42,794
then we're pretty sure that maybe some other professional

171
00:11:42,842 --> 00:11:46,286
out there has encountered the same problem.

172
00:11:46,468 --> 00:11:49,440
Meaning these tools may have the features already.

173
00:11:50,130 --> 00:11:53,186
All we need to do is learn how to install it and get that to

174
00:11:53,208 --> 00:11:57,490
work. However, in the next tip,

175
00:11:57,910 --> 00:12:00,980
using tools do not automatically solve the problem.

176
00:12:01,350 --> 00:12:05,042
The tools are enablers. Like I said,

177
00:12:05,176 --> 00:12:08,520
the tools are enablers. What do I mean by that?

178
00:12:08,970 --> 00:12:11,960
At the end of the day, the tools will be used by people.

179
00:12:12,490 --> 00:12:16,390
So, combining the concepts we learned from the previous slides,

180
00:12:16,730 --> 00:12:20,458
let's say that the software engineering team and then the

181
00:12:20,464 --> 00:12:23,626
site reliability engineering team are going to

182
00:12:23,648 --> 00:12:27,274
use these tools. What if the tools are

183
00:12:27,312 --> 00:12:31,774
properly set up, the tools are in place, but 80%

184
00:12:31,892 --> 00:12:35,134
of the team have no idea how

185
00:12:35,172 --> 00:12:39,406
to use these tools, have no idea, and have very

186
00:12:39,588 --> 00:12:43,006
little idea about the concepts being used when using these

187
00:12:43,028 --> 00:12:46,434
tools. And then finally, what if they

188
00:12:46,472 --> 00:12:50,846
say that they're familiar with these tools, but in reality they're

189
00:12:50,878 --> 00:12:54,226
not able to use these tools properly to troubleshoot the problems.

190
00:12:54,408 --> 00:12:58,138
So what will happen here is that at the start, during the planning stage,

191
00:12:58,174 --> 00:13:01,846
we ask the people who's familiar with this tool, and then

192
00:13:01,868 --> 00:13:05,414
everyone will say, yeah, I have used that before. And then something goes

193
00:13:05,452 --> 00:13:09,110
wrong one month from now, and then only one or two people

194
00:13:09,180 --> 00:13:13,322
are able to use the tools properly. So there, that's something that

195
00:13:13,456 --> 00:13:16,842
you need to solve, because a big part of this

196
00:13:16,896 --> 00:13:20,006
would be a human problem. So one of the possible solutions

197
00:13:20,038 --> 00:13:23,054
you need to take note of would be,

198
00:13:23,252 --> 00:13:26,654
let's say, giving them a training program to help

199
00:13:26,692 --> 00:13:30,654
them understand the tools better and how to do troubleshooting better.

200
00:13:30,852 --> 00:13:35,040
Another thing that you have to take note of is that sometimes

201
00:13:35,750 --> 00:13:39,666
the best words, the most important things we need to hear about are

202
00:13:39,688 --> 00:13:43,554
the words never said. So people will not really tell you what's really

203
00:13:43,592 --> 00:13:47,862
happening. So it's important for the management team to

204
00:13:47,916 --> 00:13:51,574
listen to the words never said by trying to understand what's really happening, by,

205
00:13:51,612 --> 00:13:55,926
let's say, auditing and by checking things

206
00:13:56,028 --> 00:13:59,654
even without people telling them or giving them feedback.

207
00:13:59,782 --> 00:14:03,590
Sometimes management teams are relying too much on feedback,

208
00:14:03,750 --> 00:14:06,938
that they assume that this

209
00:14:07,024 --> 00:14:10,406
feedback notes sre the sources of truth,

210
00:14:10,438 --> 00:14:13,090
when in fact, when you do assimilation,

211
00:14:13,190 --> 00:14:16,446
maybe that's a much better way to know what's going

212
00:14:16,468 --> 00:14:20,142
to happen or not. The next thing in our list

213
00:14:20,196 --> 00:14:23,422
would be this one. So there's a bunch

214
00:14:23,486 --> 00:14:25,810
of logos here, a bunch of tools.

215
00:14:27,030 --> 00:14:30,274
So first we have here

216
00:14:30,312 --> 00:14:34,430
Sagemaker, we have app mesh, we have eks,

217
00:14:34,590 --> 00:14:37,670
we have x ray, and we have Cloudwatch.

218
00:14:38,010 --> 00:14:41,750
The lesson I want to share here is that not everything

219
00:14:41,820 --> 00:14:45,286
needs to be stored inside the Kubernetes cluster. There may

220
00:14:45,308 --> 00:14:48,634
be tools, there may be open source tools that

221
00:14:48,672 --> 00:14:51,610
can easily be installed inside the Kubernetes cluster.

222
00:14:52,190 --> 00:14:55,926
You may be using some machine learning tools

223
00:14:55,958 --> 00:14:59,986
and workflow tools to run machine learning workloads inside the Kubernetes

224
00:15:00,118 --> 00:15:03,886
cluster. Right. But if there are

225
00:15:03,908 --> 00:15:06,586
other options available, let's say Sagemaker,

226
00:15:06,698 --> 00:15:09,930
and it has proper integration with Kubernetes.

227
00:15:10,010 --> 00:15:13,406
So in this example, you have sagemaker operators

228
00:15:13,438 --> 00:15:17,774
for Kubernetes. Then you'll be able to delegate

229
00:15:17,822 --> 00:15:21,154
and transfer some of the workload to Sagemaker so

230
00:15:21,192 --> 00:15:24,974
that you're pretty sure that it's managed there. And then there's

231
00:15:25,022 --> 00:15:29,206
less management burden inside your Kubernetes cluster, especially if

232
00:15:29,228 --> 00:15:33,062
you're dealing with a lot of services and workload there.

233
00:15:33,196 --> 00:15:36,678
And you also have app mesh, you have x ray, you have Cloudwatch. So if

234
00:15:36,684 --> 00:15:40,362
you have logs, yeah, you can use Cloudwatch to store

235
00:15:40,416 --> 00:15:43,194
those logs and help us analyze the logs there.

236
00:15:43,392 --> 00:15:47,082
The same way, instead of storing the data

237
00:15:47,136 --> 00:15:50,734
inside kubernetes, inside databases there, maybe we can use

238
00:15:50,772 --> 00:15:55,694
an RDS instance outside of the cluster so

239
00:15:55,732 --> 00:15:59,898
that at least you can deal with the manage advantages,

240
00:16:00,074 --> 00:16:03,046
the pros of using RDS,

241
00:16:03,178 --> 00:16:05,998
which is outside of your Kubernetes cluster.

242
00:16:06,094 --> 00:16:10,242
So if you need to vertically scale your

243
00:16:10,296 --> 00:16:13,618
database, then instead of you trying to

244
00:16:13,704 --> 00:16:17,670
use Kubernetes to manage the database resources there,

245
00:16:17,820 --> 00:16:20,710
you can do that using RDS separately.

246
00:16:22,090 --> 00:16:25,266
The next one involves the users,

247
00:16:25,298 --> 00:16:28,870
the target users. When creating infrastructure,

248
00:16:28,950 --> 00:16:32,742
we're not trying to build and manage the infrastructure

249
00:16:32,886 --> 00:16:37,222
just for the sake of it. The goal of SRE,

250
00:16:37,366 --> 00:16:40,666
the goal of what we're doing right now is to make sure

251
00:16:40,688 --> 00:16:44,174
that our customers are happy and the system is up almost

252
00:16:44,212 --> 00:16:48,106
100% of the time. Almost 100%. So it's

253
00:16:48,138 --> 00:16:52,414
critical that we know who the target users are and we need to understand their

254
00:16:52,452 --> 00:16:55,134
behavior. Because when dealing with systems,

255
00:16:55,182 --> 00:16:58,766
it's always going to be a combination of planned

256
00:16:58,798 --> 00:17:02,930
and unplanned work, and at the same time it will be a combination of

257
00:17:03,080 --> 00:17:06,446
automated task and manual task.

258
00:17:06,638 --> 00:17:09,826
There will be times where we will have to take more risk

259
00:17:09,858 --> 00:17:13,638
than usual. And if we know the usage rate of

260
00:17:13,644 --> 00:17:17,458
the system and we understand the behavior of the users, then maybe we

261
00:17:17,484 --> 00:17:22,218
can schedule some of the more critical work,

262
00:17:22,384 --> 00:17:26,826
maybe critical migration work, which can be done during

263
00:17:26,928 --> 00:17:30,262
off peak hours. So in this example here,

264
00:17:30,416 --> 00:17:34,014
maybe your customers for some reason

265
00:17:34,212 --> 00:17:37,934
uses the site between twelve midnight and 03:00

266
00:17:37,972 --> 00:17:41,246
a.m. And then maybe

267
00:17:41,348 --> 00:17:44,914
they go back to your site again 03:00 p.m. To 07:00 p.m.

268
00:17:45,032 --> 00:17:48,146
So it really depends on your application.

269
00:17:48,328 --> 00:17:51,934
This really depends on the users,

270
00:17:51,982 --> 00:17:55,154
the target market and the behavior changes.

271
00:17:55,272 --> 00:17:59,014
Also, day to day, maybe during weekdays they

272
00:17:59,052 --> 00:18:02,454
behave like this, during weekends they behave in some

273
00:18:02,492 --> 00:18:06,214
fashion. And then there SRE specific days in the year where

274
00:18:06,252 --> 00:18:10,570
you really have to plan ahead and prepare the infrastructure and configuration

275
00:18:13,230 --> 00:18:16,966
to carry the workload, especially in cases where there's a spike.

276
00:18:17,078 --> 00:18:20,298
So let's say there's a holiday or there's an event

277
00:18:20,464 --> 00:18:24,526
you need to prepare ahead of time and you cannot just rely on

278
00:18:24,548 --> 00:18:28,202
auto scaling to help solve the requirements

279
00:18:28,266 --> 00:18:31,774
of the business. So again, this is very critical and

280
00:18:31,812 --> 00:18:35,490
we need to know the behavior of the target users.

281
00:18:36,390 --> 00:18:40,258
The next one in our list involves managing the overall cost

282
00:18:40,344 --> 00:18:43,570
of storing, managing and searching the logs.

283
00:18:44,070 --> 00:18:47,334
Whenever we prepare infrastructure, one of

284
00:18:47,372 --> 00:18:50,902
the primary requirements we have to deal with would be cost

285
00:18:50,956 --> 00:18:54,466
estimation. It's one of the trickier things we need to worry

286
00:18:54,498 --> 00:18:58,438
about, because in

287
00:18:58,444 --> 00:19:02,918
addition to trying to predict the cost when dealing with auto scaling infrastructure,

288
00:19:03,094 --> 00:19:07,114
we also have to worry about the things which may not be

289
00:19:07,152 --> 00:19:10,700
noticeable or visible at that point in time.

290
00:19:11,070 --> 00:19:14,334
So let's say that we want to prepare some cost

291
00:19:14,372 --> 00:19:17,614
estimates. The first thing that comes into mind would be how

292
00:19:17,652 --> 00:19:21,374
much would be the database instance cost and

293
00:19:21,412 --> 00:19:26,818
then how much would the aks cluster cost?

294
00:19:26,904 --> 00:19:30,242
Right. But after a couple of months, when you check the bill,

295
00:19:30,296 --> 00:19:34,210
you'll see, hey, where did this additional cost come from?

296
00:19:34,360 --> 00:19:37,938
Oh, the logs start to build up because we're

297
00:19:37,954 --> 00:19:40,582
trying to collect a lot of logs because,

298
00:19:40,636 --> 00:19:43,974
yeah, the more logs we have, the better, because it allows us

299
00:19:44,012 --> 00:19:47,080
to debug the site better, right?

300
00:19:47,610 --> 00:19:51,446
Yeah. So you just have to worry about the additional cost of storing

301
00:19:51,478 --> 00:19:55,126
logs and also making SRE that there's

302
00:19:55,158 --> 00:19:58,794
also backup because you cannot just remove the logs and reduce the number

303
00:19:58,832 --> 00:20:02,238
of logs being collected by the system just to reduce the cost.

304
00:20:02,404 --> 00:20:06,410
So knowing the different options on where to store the logs,

305
00:20:06,570 --> 00:20:10,190
that's also the second step.

306
00:20:10,260 --> 00:20:14,050
And the third step here would be understanding the total cost

307
00:20:14,120 --> 00:20:17,694
of managing the centralized log storage.

308
00:20:17,822 --> 00:20:21,154
Because what you don't want to do is that some

309
00:20:21,192 --> 00:20:24,900
of your resources will be building a custom solution for your system,

310
00:20:25,510 --> 00:20:29,462
and instead of them doing other things, they will be forced to have

311
00:20:29,596 --> 00:20:32,226
a sophisticated centralized log storage.

312
00:20:32,418 --> 00:20:35,862
And then finally, it's critical that we manage

313
00:20:35,916 --> 00:20:39,474
the time spent searching the logs. So managing is

314
00:20:39,612 --> 00:20:43,126
one of the things we need to worry about. Searching the logs

315
00:20:43,238 --> 00:20:46,842
is critical also. So given that your system

316
00:20:46,896 --> 00:20:49,450
will be collecting a lot of logs from different sources,

317
00:20:49,950 --> 00:20:54,094
it's critical that searching the logs, especially when done manually by

318
00:20:54,132 --> 00:20:58,362
a user, it's going to be super fast and we're able to connect the logs

319
00:20:58,506 --> 00:21:02,494
collected by the system of the distributed components and

320
00:21:02,532 --> 00:21:05,826
trying to connect the dots, especially if,

321
00:21:05,848 --> 00:21:09,566
let's say component a calls component b and then component b calls

322
00:21:09,598 --> 00:21:13,794
component c and they are in different pods and different services,

323
00:21:13,912 --> 00:21:17,210
right? So being able to identify

324
00:21:17,310 --> 00:21:20,930
the problem and connecting the logs

325
00:21:21,090 --> 00:21:24,582
from each of the components is something that you need to

326
00:21:24,636 --> 00:21:27,770
set up ahead of time. So there are a lot of tools and options

327
00:21:27,840 --> 00:21:31,658
out there. But having good collaboration between

328
00:21:31,744 --> 00:21:35,594
the application development team and the SRE team

329
00:21:35,712 --> 00:21:38,220
is crucial to get that to work.

330
00:21:38,830 --> 00:21:43,040
Next in our list would be understanding the weakest links in your system.

331
00:21:43,410 --> 00:21:47,102
Sometimes when we do not understand the system enough, there's always

332
00:21:47,156 --> 00:21:50,718
that tendency. When there's a slowdown, we always

333
00:21:50,804 --> 00:21:54,546
try to say, okay, if the system is slowing down, we just need

334
00:21:54,568 --> 00:21:57,966
to scale it, we just need to do auto scaling.

335
00:21:58,078 --> 00:22:00,660
However, it doesn't really work like that in real life.

336
00:22:03,110 --> 00:22:08,322
Not all issues are due to lack

337
00:22:08,386 --> 00:22:12,082
of, let's say, compute power when it comes to processing

338
00:22:12,226 --> 00:22:15,080
the logic work. Logic code. Right.

339
00:22:15,850 --> 00:22:19,338
In some cases, maybe the bottleneck would be

340
00:22:19,344 --> 00:22:23,366
the database. So instead of us trying to always blame

341
00:22:23,398 --> 00:22:26,694
the Kubernetes cluster and the resources inside it, the resources

342
00:22:26,742 --> 00:22:30,622
being managed by that cluster, the first step

343
00:22:30,676 --> 00:22:34,970
is to actually know where the problem is. Maybe the database

344
00:22:35,130 --> 00:22:38,446
queries sre not optimized. So maybe one

345
00:22:38,468 --> 00:22:41,070
solution would be to use queries.

346
00:22:41,570 --> 00:22:44,938
Then the other solution would be maybe we need to have read replicas to solve

347
00:22:44,954 --> 00:22:49,074
the problem. And there's really no need to do auto scaling right away.

348
00:22:49,112 --> 00:22:52,526
Because even if you auto scale and the database is the bottleneck,

349
00:22:52,638 --> 00:22:55,586
auto scaling will not help solve the latency issues.

350
00:22:55,768 --> 00:22:58,742
So that's one of the things that you need to be aware of,

351
00:22:58,796 --> 00:23:03,174
because there's always the tendency to have the

352
00:23:03,212 --> 00:23:06,854
mapped solution, the canned solutions, and we feel that

353
00:23:06,892 --> 00:23:10,010
okay, if the site slow auto scaling, no, that's not the case.

354
00:23:10,080 --> 00:23:13,882
We need to spend some time, analyze what's wrong,

355
00:23:14,016 --> 00:23:17,722
and let's try to remove any sort of assumptions and

356
00:23:17,776 --> 00:23:20,846
biases to help us really solve the

357
00:23:20,868 --> 00:23:24,426
problem from the very real root

358
00:23:24,458 --> 00:23:25,440
cause of it.

359
00:23:27,810 --> 00:23:31,162
The next one in our list would involve failure.

360
00:23:31,306 --> 00:23:34,322
So the lesson here would be to prepare for

361
00:23:34,376 --> 00:23:38,686
failure so nothing fails. So understanding

362
00:23:38,718 --> 00:23:41,922
the common failure modes when

363
00:23:42,056 --> 00:23:44,290
using Kubernetes is critical.

364
00:23:44,710 --> 00:23:48,710
So some examples are shared here that would involve high cpu,

365
00:23:49,370 --> 00:23:52,786
that would involve packet loss, maybe sudden

366
00:23:52,818 --> 00:23:56,646
increase in latency would happen. And then sometimes there

367
00:23:56,668 --> 00:23:59,750
will be node failure in rare cases,

368
00:23:59,830 --> 00:24:03,770
maybe unavailable regions, maybe there's some service

369
00:24:03,840 --> 00:24:07,306
failure from time to time, and maybe some cpu throttling as

370
00:24:07,328 --> 00:24:11,834
well. So what do we do with this knowledge

371
00:24:11,882 --> 00:24:15,934
or information? What's important here is that we

372
00:24:15,972 --> 00:24:19,930
try to simulate these common failure modes

373
00:24:20,090 --> 00:24:23,570
before launching things into production

374
00:24:24,310 --> 00:24:28,514
again. The best assumption would be that things will fail and

375
00:24:28,552 --> 00:24:32,482
the goal is to prepare a layered plan and

376
00:24:32,536 --> 00:24:36,226
to prepare the automation work required so that the

377
00:24:36,248 --> 00:24:39,430
system is self healing. So you have to plan

378
00:24:39,500 --> 00:24:43,206
things ahead and include this in your timeline. Building the

379
00:24:43,228 --> 00:24:46,470
site is the first step, and then the second part

380
00:24:46,540 --> 00:24:50,134
there would be to harden the system to make it prepared

381
00:24:50,182 --> 00:24:53,754
for anything that may come up. So the previous lesson, which is

382
00:24:53,792 --> 00:24:57,674
understanding the users and their behavior is critical because

383
00:24:57,712 --> 00:25:01,274
for one thing, if let's say majority of your users are

384
00:25:01,312 --> 00:25:05,070
inside the country, are from a country, let's say Philippines,

385
00:25:05,410 --> 00:25:09,854
then maybe you don't need to have a

386
00:25:09,892 --> 00:25:12,110
system which is available globally,

387
00:25:12,630 --> 00:25:16,674
right? So that makes your system much cheaper compared to,

388
00:25:16,792 --> 00:25:20,370
let's say, requirements that involve the entire

389
00:25:20,440 --> 00:25:25,070
world. So let's say you have a website and then different

390
00:25:25,160 --> 00:25:28,854
parts in the world and different users across the globe will

391
00:25:28,892 --> 00:25:32,760
use it, then that may definitely need

392
00:25:33,370 --> 00:25:36,774
a more expensive setup. Maybe you have the

393
00:25:36,812 --> 00:25:39,718
high availability set up across different regions.

394
00:25:39,894 --> 00:25:43,526
So being prepared for those things and planning

395
00:25:43,558 --> 00:25:46,854
things ahead is critical and also being practical

396
00:25:46,902 --> 00:25:50,474
about it. Because what we want to do is to

397
00:25:50,512 --> 00:25:53,934
also save on costs. We cannot just build, build, automate this,

398
00:25:53,972 --> 00:25:57,978
make this available everywhere. It's about managing that balance

399
00:25:58,074 --> 00:26:01,454
between availability, resilience and

400
00:26:01,492 --> 00:26:05,026
cost. Next would be managing the security

401
00:26:05,128 --> 00:26:08,980
risk. Kubernetes is like any other tool.

402
00:26:09,590 --> 00:26:13,506
If it's not configured properly, then it

403
00:26:13,528 --> 00:26:17,542
can be attacked and compromised. There are tools out there which

404
00:26:17,596 --> 00:26:21,574
helps us run these tools and

405
00:26:21,692 --> 00:26:26,066
identify the risk and vulnerabilities, especially when it comes to misconfigured

406
00:26:26,178 --> 00:26:29,690
kubernetes clusters. In some cases,

407
00:26:30,350 --> 00:26:33,420
some teams would just say, oh, it's secure. Of course,

408
00:26:33,950 --> 00:26:39,126
if you misconfigured something and if you use the wrong sequence

409
00:26:39,158 --> 00:26:42,654
of things, and also you have an application which is

410
00:26:42,772 --> 00:26:46,526
easily compromised, then someone might be

411
00:26:46,548 --> 00:26:50,314
able to attack the entire system. So knowing the weakest

412
00:26:50,362 --> 00:26:53,078
links of your system when it becomes CTO security is critical.

413
00:26:53,274 --> 00:26:57,250
So in this example, let's say that we have a cloud nine control

414
00:26:57,320 --> 00:27:00,734
instance that has Kubectl

415
00:27:00,782 --> 00:27:04,450
installed there, which helps manage the Kubernetes cluster.

416
00:27:06,650 --> 00:27:10,646
What if that's the highest risk entity in our

417
00:27:10,748 --> 00:27:14,754
environment? So even if we were able to secure

418
00:27:14,802 --> 00:27:18,602
the Kubernetes cluster, the Kubernetes configuration, if that

419
00:27:18,656 --> 00:27:22,838
gets attacked and the Kubernetes cluster

420
00:27:22,854 --> 00:27:26,134
is deleted by the malicious actor, then boom,

421
00:27:26,262 --> 00:27:29,594
your entire system is down. So feel

422
00:27:29,632 --> 00:27:33,214
free to check the possible risk and issues when dealing with

423
00:27:33,252 --> 00:27:36,830
these types of setup. Let's say IaM pass rule.

424
00:27:37,250 --> 00:27:40,990
Think about how an attacker would be able to attack

425
00:27:41,060 --> 00:27:44,354
your system using different techniques and

426
00:27:44,392 --> 00:27:47,842
exploits. So that's the first step. The second

427
00:27:47,896 --> 00:27:52,210
step would be trying to look at all the other resources

428
00:27:52,630 --> 00:27:56,854
in that AWS account. So there are different techniques to

429
00:27:56,972 --> 00:28:00,166
protect this system. For example. So for

430
00:28:00,188 --> 00:28:03,814
example, you use multiple accounts to make sure

431
00:28:03,852 --> 00:28:07,746
that even if one account gets compromised, the other systems are not affected.

432
00:28:07,858 --> 00:28:12,102
Because for one thing, let's say that one of the IAM users,

433
00:28:12,166 --> 00:28:16,214
or maybe one of the easy CTO instances launched by an IAM user,

434
00:28:16,342 --> 00:28:19,866
has super admin powers, and then for some reason that

435
00:28:19,888 --> 00:28:22,110
easy to instance gets compromised.

436
00:28:22,450 --> 00:28:26,270
Then if that system gets compromised

437
00:28:26,770 --> 00:28:30,746
and that has the ability to delete EC

438
00:28:30,778 --> 00:28:34,070
two resources, delete all the resources in your account, then boom,

439
00:28:34,170 --> 00:28:37,330
even if this entire setup is secure, your entire

440
00:28:37,400 --> 00:28:40,574
AWS account would be finished.

441
00:28:40,702 --> 00:28:44,226
Would be done. So, yeah, so you might lose the data, you might lose the

442
00:28:44,248 --> 00:28:49,714
resources and make sure that you are prepared for those edge

443
00:28:49,762 --> 00:28:54,086
cases. This 1 may

444
00:28:54,108 --> 00:28:57,686
not be so obvious, but it's critical to

445
00:28:57,708 --> 00:29:01,450
have a plan. But the timing is critical.

446
00:29:01,870 --> 00:29:05,786
It's important that we plan when there is minimal pressure. Some of

447
00:29:05,808 --> 00:29:09,338
us will tell everyone and just assume this is

448
00:29:09,344 --> 00:29:12,414
the truth, that sometimes we do a better

449
00:29:12,452 --> 00:29:15,130
job when there's pressure in reality.

450
00:29:15,210 --> 00:29:18,270
Generally when there's an emergency,

451
00:29:18,850 --> 00:29:22,362
there's the time constraint. And then when we are planning,

452
00:29:22,426 --> 00:29:24,880
the more time that we have, the better.

453
00:29:25,250 --> 00:29:28,594
And when there's minimal pressure and when there's no pressure at all,

454
00:29:28,712 --> 00:29:31,810
it's better to plan there because we have the opportunity. CTO,

455
00:29:31,960 --> 00:29:35,586
prepare an exhaustive plan to prepare an exhaustive list of

456
00:29:35,608 --> 00:29:39,238
what we need to do to be able to accomplish everything that we need.

457
00:29:39,404 --> 00:29:42,854
But when there's an emergency, a lot of us will

458
00:29:42,892 --> 00:29:45,974
panic, a lot of us will be under time constraints, and we will

459
00:29:46,012 --> 00:29:50,134
not be able to prepare the best solution. So planning

460
00:29:50,182 --> 00:29:53,514
things way ahead of time is critical, and it's better

461
00:29:53,552 --> 00:29:57,290
to have a solid plan than rushing it when there's a problem

462
00:29:57,360 --> 00:30:01,206
already. So that's pretty much it. We learned

463
00:30:01,238 --> 00:30:03,920
a lot of things in this talk,

464
00:30:04,530 --> 00:30:07,758
and yeah, if you have any questions,

465
00:30:07,844 --> 00:30:11,374
feel free to reach out to me. But, yeah, thank you for listening and hope

466
00:30:11,412 --> 00:30:15,514
you learned something today in my talk and pragmatic site reliability

467
00:30:15,562 --> 00:30:19,070
engineering for kubernetes in the cloud. So again,

468
00:30:19,220 --> 00:30:23,226
I am Joshua Arvin Lat, and I'm the chief technology officer of Nuworks

469
00:30:23,258 --> 00:30:26,338
Interactive Labs. Thank you, you, and bye.

