1
00:00:00,410 --> 00:00:06,126
Jamaica makes up real

2
00:00:06,148 --> 00:00:09,530
time feedback into the behavior of your distributed systems

3
00:00:09,610 --> 00:00:12,490
and observing changes, exceptions,

4
00:00:12,570 --> 00:00:15,722
errors in real time allows you to not only experiment

5
00:00:15,786 --> 00:00:19,086
with confidence, but respond instantly to

6
00:00:19,108 --> 00:00:20,480
get things working again.

7
00:00:24,610 --> 00:01:04,830
Close hello

8
00:01:04,900 --> 00:01:08,194
and thank you for watching today's session. Chaos, chaos, chaos experiments

9
00:01:08,232 --> 00:01:11,854
under the lens of my name is Michaelem. I'm an SRE

10
00:01:11,902 --> 00:01:14,734
DevOps engineer, and I have a background in software engineering,

11
00:01:14,782 --> 00:01:18,246
AI, industrial automation. So naturally, I would say all

12
00:01:18,268 --> 00:01:22,082
of these areas pointed me towards aiops, which is my current specialization.

13
00:01:22,226 --> 00:01:26,306
This is our agenda for today. I'm going to define the basic concepts surrounding

14
00:01:26,338 --> 00:01:29,526
aiops, followed by an in depth view of how it can be

15
00:01:29,548 --> 00:01:33,206
applied to chaos engineering. I think the highlight of this session

16
00:01:33,238 --> 00:01:37,222
for many will be our live demo, after which we'll wrap up and summarized

17
00:01:37,286 --> 00:01:40,518
everything that we've talked about here today. Before we start, let's set

18
00:01:40,544 --> 00:01:43,130
the scene. These are our two focus concepts.

19
00:01:43,210 --> 00:01:46,826
Aiops, a term used to indicate the application of ML

20
00:01:46,858 --> 00:01:50,286
analytics to it ops in order to

21
00:01:50,308 --> 00:01:53,826
prevent system degradation and failure. In simple words.

22
00:01:54,008 --> 00:01:58,222
And then we have silos engineering. We'll use CE abbreviation

23
00:01:58,286 --> 00:02:02,082
throughout this presentation, which is, as you know, all about

24
00:02:02,136 --> 00:02:05,746
experimenting and testing our system's resiliency. Now imagine

25
00:02:05,778 --> 00:02:09,266
this. A hardworking SRE site. Reliability engineers

26
00:02:09,378 --> 00:02:12,866
wakes up one day, thinks about all the tasks that await

27
00:02:12,898 --> 00:02:16,562
him. So many tools, tickets, incidents,

28
00:02:16,626 --> 00:02:20,350
mail. Basically an avalanche of responsibilities.

29
00:02:20,450 --> 00:02:22,620
That sounds quite overwhelming, right?

30
00:02:23,390 --> 00:02:26,554
I think, to be honest, all of us sometimes have a feeling like that.

31
00:02:26,672 --> 00:02:30,266
But then, as he sips his morning coffee, can idea comes to

32
00:02:30,288 --> 00:02:33,262
his mind. Why the hell should it be like that?

33
00:02:33,316 --> 00:02:36,714
If only there was a way to smartly and efficiently organize

34
00:02:36,762 --> 00:02:40,494
and automate all these tasks. Well, there is one.

35
00:02:40,612 --> 00:02:44,398
Which is why we'll start with today. With today's rapidly increasing

36
00:02:44,494 --> 00:02:47,618
and more and more complex stack systems have become

37
00:02:47,704 --> 00:02:51,874
extremely critical. As I mentioned, can average SRE today

38
00:02:51,992 --> 00:02:55,130
needs to deal with tons of errors, warnings,

39
00:02:55,230 --> 00:02:58,758
tickets, critical alert? It just doesn't end. Doesn't it?

40
00:02:58,844 --> 00:03:02,438
So how can we help our poor site reliability engineer with

41
00:03:02,444 --> 00:03:06,194
his daily struggles? Well, for starters, let's introduce

42
00:03:06,242 --> 00:03:10,310
AIOPs artificial intelligence for IT operations.

43
00:03:11,130 --> 00:03:15,338
But what is exactly aiops? How does it work?

44
00:03:15,504 --> 00:03:18,214
We can segment it in three areas.

45
00:03:18,342 --> 00:03:21,806
Observe, engage, act. To the left, we see the

46
00:03:21,828 --> 00:03:25,054
ingestion of historical and real time data in the form

47
00:03:25,092 --> 00:03:28,634
of logs, metrics, text into an ML

48
00:03:28,682 --> 00:03:31,770
model, which ultimately produces actionable insights.

49
00:03:31,850 --> 00:03:35,182
And that means anomaly detection, performance analyzed,

50
00:03:35,246 --> 00:03:38,718
and so on. So, in simple words, we want to predict,

51
00:03:38,814 --> 00:03:42,930
or even better, we want to preempt failure before it even occurs.

52
00:03:43,270 --> 00:03:47,094
AIOPs collects all kinds of data network application

53
00:03:47,212 --> 00:03:50,850
storage. As we said, the goal is to predict failure,

54
00:03:50,930 --> 00:03:54,370
identify the root cause error, and reduce alert noise.

55
00:03:54,530 --> 00:03:58,074
Furthermore, autoredemiation and adapted self

56
00:03:58,112 --> 00:04:01,274
healing are also important concepts which refer to the

57
00:04:01,312 --> 00:04:04,646
ability to resolve a failure before its occurrence.

58
00:04:04,758 --> 00:04:08,822
That means to enable self healing before a problem occurs.

59
00:04:08,966 --> 00:04:12,734
Basically, the paradigm, if you think about it, is shifting here from

60
00:04:12,772 --> 00:04:16,554
reactive to proactive. We don't just detect

61
00:04:16,602 --> 00:04:20,046
errors, we prevent them. Also, remember that the

62
00:04:20,068 --> 00:04:24,094
AIOPS model is continuously collecting data and continuously

63
00:04:24,142 --> 00:04:28,130
learning from it, and therefore continuos optimizing itself.

64
00:04:28,280 --> 00:04:32,030
But let's extend our scope a bit now. How do we experiment?

65
00:04:32,110 --> 00:04:35,506
Inside aiops? We have our aIops solution,

66
00:04:35,618 --> 00:04:38,950
but now we want to test its resiliency, robustness and

67
00:04:39,020 --> 00:04:41,640
reliability. How do we do that?

68
00:04:42,890 --> 00:04:46,374
Let's read two the following definition a discipline of

69
00:04:46,412 --> 00:04:50,346
performing security experimentation on a distributed system in

70
00:04:50,368 --> 00:04:54,262
order to build confidence in the system's capability to withstand turbulent

71
00:04:54,326 --> 00:04:58,380
and malicious conditions. So what is this?

72
00:04:59,310 --> 00:05:02,970
As we already know, this refers to chaos engineering.

73
00:05:03,050 --> 00:05:06,874
We want to test our AOP solution by conducting chaos

74
00:05:06,922 --> 00:05:10,654
experiments. Now we need to ask ourselves, how do we

75
00:05:10,692 --> 00:05:13,930
plan chaos experiments? So this diagram here

76
00:05:14,020 --> 00:05:17,650
illustrates the continuous cycle of hypothesis and verification.

77
00:05:18,070 --> 00:05:22,430
What is this? We have these steady state posture which we get through observability.

78
00:05:22,590 --> 00:05:26,718
Don't worry, I'll get to this concept soon. We form a hypothesis,

79
00:05:26,894 --> 00:05:30,022
sort of is my system resilience to the disruption of

80
00:05:30,076 --> 00:05:33,254
xy services? This is an example hypothesis. We put

81
00:05:33,292 --> 00:05:36,726
it to the best through continuous verification, at the end of which

82
00:05:36,748 --> 00:05:40,346
we summarize the lesson learned and implement mitigation. This is a

83
00:05:40,368 --> 00:05:44,042
continuous cycle, as at this point we start again with the whole process

84
00:05:44,096 --> 00:05:48,074
to further experiment our system. We talked about aiops and

85
00:05:48,112 --> 00:05:51,758
c chaos engineering, but where do these meet?

86
00:05:51,924 --> 00:05:55,162
There are several things, but for today's scope,

87
00:05:55,226 --> 00:05:59,578
the most important one is observability. Were are a couple of notions relevant

88
00:05:59,594 --> 00:06:03,018
for observability. We have different sources of data illustrated

89
00:06:03,034 --> 00:06:06,734
to the left side, and basically, observability is the ability.

90
00:06:06,782 --> 00:06:10,322
Two measure a system's current state based on the data

91
00:06:10,376 --> 00:06:14,146
it generates, such as logs, metrics, and traces the

92
00:06:14,168 --> 00:06:17,826
so called golden triangle of observability. While the golden triangle

93
00:06:17,858 --> 00:06:21,810
signals are latency, traffic errors and saturation.

94
00:06:21,970 --> 00:06:25,478
In our case, as you will soon see, latency will be the

95
00:06:25,484 --> 00:06:28,950
one that we will use for our upcoming live demo. So let's get started.

96
00:06:29,100 --> 00:06:32,762
So far I think we learned about aiops, we learned about

97
00:06:32,816 --> 00:06:36,102
CE, as well as we learned about observability.

98
00:06:36,246 --> 00:06:39,850
So what now? Now we can run a chaos experiment.

99
00:06:40,270 --> 00:06:43,374
There are two questions running on SRI's mind.

100
00:06:43,572 --> 00:06:47,242
One, how does aiops react if I run a chaos

101
00:06:47,306 --> 00:06:51,194
experiment? Two, is aiops capable of recognizing

102
00:06:51,242 --> 00:06:53,850
a running chaos experiment through observability?

103
00:06:54,010 --> 00:06:57,098
Now that we have all the necessary munition to formulate

104
00:06:57,114 --> 00:06:59,810
youre hypothesis, which goes as follows,

105
00:07:00,230 --> 00:07:02,830
we assume that if we run a chaos experiments,

106
00:07:02,910 --> 00:07:06,242
aiops will be able to detect that there is one.

107
00:07:06,376 --> 00:07:10,374
The experiment will then either fail or it will be under control. These are

108
00:07:10,412 --> 00:07:14,738
the possibilities. Just a quick overview in terms of our architecture,

109
00:07:14,914 --> 00:07:18,674
youre online boutique, which is a mockup web store composed of eleven

110
00:07:18,722 --> 00:07:22,054
services splunk observability, a platform for endtoend

111
00:07:22,102 --> 00:07:25,350
monitoring which monitors our boutique locust load generator

112
00:07:25,430 --> 00:07:29,514
used to simulate active users on our boutique, which are navigating and clicking all

113
00:07:29,552 --> 00:07:32,270
over the place. And then we have litmus chaos,

114
00:07:33,570 --> 00:07:37,470
which will introduce chaos into our system into our boutique. As we said,

115
00:07:37,540 --> 00:07:41,674
latency will be our target. Now, while the observability component

116
00:07:41,722 --> 00:07:45,266
collects data from the boutique via the open telemetry collector. As we can

117
00:07:45,288 --> 00:07:48,466
see, it is the aiops component that sits on

118
00:07:48,488 --> 00:07:51,854
top of splunk observability, and that component is responsibilities

119
00:07:51,902 --> 00:07:55,454
for detecting and predicting an increased latency.

120
00:07:55,582 --> 00:07:59,286
Well, I think we're all set now. Let's go. This is

121
00:07:59,308 --> 00:08:03,414
my environment. I'm running everything in minicube. This here is

122
00:08:03,452 --> 00:08:06,902
my online boutique store, a cloud native microservices demo

123
00:08:06,956 --> 00:08:11,466
app. What I want to show you quickly is that

124
00:08:11,488 --> 00:08:15,590
it consists around, as we can see here, around ten microservices

125
00:08:15,670 --> 00:08:19,194
simulating a web based ecommerce application. And it's all running inside

126
00:08:19,232 --> 00:08:22,430
my mini cyber. Also this is,

127
00:08:22,500 --> 00:08:26,110
if you're interested, the GitHub project for the

128
00:08:26,260 --> 00:08:30,270
boutique store. I personally find it pretty handy.

129
00:08:31,010 --> 00:08:34,742
So on the other hand, we have splunk observability,

130
00:08:34,906 --> 00:08:38,414
which is a platform that provides monitoring across infrastructure,

131
00:08:38,542 --> 00:08:41,906
apps, user interfaces. So it basically provides end to

132
00:08:41,928 --> 00:08:45,490
end monitoring for the entire system through its entire lifecycle.

133
00:08:45,830 --> 00:08:50,374
What we can see here is a these view of our infrastructure and

134
00:08:50,412 --> 00:08:53,080
all of youre microservices in the boutique store.

135
00:08:54,090 --> 00:08:57,862
What we see here marked in red, it means that there's probably

136
00:08:57,916 --> 00:09:01,990
already an issue that's been detected. So what is but doing here?

137
00:09:02,140 --> 00:09:05,338
It's basically trying to identify the root cause of the issue.

138
00:09:05,504 --> 00:09:08,826
It starts with some issues on the front end and it tries to track it

139
00:09:08,848 --> 00:09:12,320
down all the way to the root cause, which is the payment service.

140
00:09:12,930 --> 00:09:16,400
What does that mean? That means that perhaps our users can

141
00:09:17,250 --> 00:09:21,210
browse through the catalog and put items into baskets,

142
00:09:21,290 --> 00:09:24,866
but might have issues while proceeding with payment it's important to

143
00:09:24,888 --> 00:09:28,398
mention that the AIOPs component licensed blanc observability

144
00:09:28,494 --> 00:09:32,270
two, which gives us the opportunity to apply AI ML

145
00:09:32,350 --> 00:09:36,086
data analysis in order to predict all sorts of events such as

146
00:09:36,188 --> 00:09:39,240
failure, system degradation and so on.

147
00:09:40,010 --> 00:09:43,250
Another relevant component running in our minicube

148
00:09:43,410 --> 00:09:47,122
is locust, and locust is an open youre

149
00:09:47,186 --> 00:09:50,714
load testing tool which I'll use to simulate proactive users in my

150
00:09:50,752 --> 00:09:54,522
boutique. I can easily just choose the

151
00:09:54,576 --> 00:09:57,802
amount of users I want two simulate, so in this case

152
00:09:57,856 --> 00:10:00,640
30 spawn rate is two.

153
00:10:01,170 --> 00:10:04,606
And the moment I click transforming it will

154
00:10:04,628 --> 00:10:10,094
basically start simulating all of these users into

155
00:10:10,132 --> 00:10:14,066
the boutique store. The last relevant component I

156
00:10:14,088 --> 00:10:16,926
must show you is Litmus chaos.

157
00:10:17,038 --> 00:10:20,734
So this is also an open youre platform. It's a chaos

158
00:10:20,782 --> 00:10:25,006
engineering platform that we use to introduce some chaos. So now

159
00:10:25,048 --> 00:10:29,158
that we've made a summary of all of our components, let's start

160
00:10:29,244 --> 00:10:32,582
an experiment. What I want to do

161
00:10:32,716 --> 00:10:37,026
is I want to inject latency through litmus

162
00:10:37,058 --> 00:10:40,170
chaos into my card service microservice.

163
00:10:41,230 --> 00:10:45,302
Basically I want to see if slunk will be able to detect

164
00:10:45,366 --> 00:10:49,542
it. What they created here is a very simple dashboard

165
00:10:49,606 --> 00:10:51,690
that's just tracking the latency.

166
00:10:52,430 --> 00:10:56,026
As you can see here, youre can set also the time span

167
00:10:56,058 --> 00:10:59,680
that you want to focus on past day, past week, past hour.

168
00:11:00,610 --> 00:11:04,170
And just to show you how I created the alerts condition,

169
00:11:04,330 --> 00:11:08,050
how it works. So right now I specified sudden change,

170
00:11:08,120 --> 00:11:12,366
which as it says here is useful for indicating an unexpected increase in latency.

171
00:11:12,558 --> 00:11:16,082
But I could have also easily chosen historical anomaly.

172
00:11:16,226 --> 00:11:19,762
What this would do would basically use the latency

173
00:11:19,826 --> 00:11:23,654
patterns from the past, if they are patterns and

174
00:11:23,772 --> 00:11:27,694
existing patterns, and use that in order to detect

175
00:11:27,762 --> 00:11:30,780
and predict if something is off or not.

176
00:11:34,990 --> 00:11:38,346
So I think were ready now to start the experiment. Let me

177
00:11:38,368 --> 00:11:42,026
go into litmus chaos. So you click here on litmus

178
00:11:42,058 --> 00:11:45,806
workflows. You want to create a chaos workflow. So you

179
00:11:45,828 --> 00:11:48,960
click schedule a workflow, select the agent.

180
00:11:50,130 --> 00:11:53,534
We want two create a fully new workflow, although you could in theory

181
00:11:53,582 --> 00:11:55,540
also use a template if youre have one.

182
00:11:58,150 --> 00:12:01,954
Here we click add new experiment. So as you can see here,

183
00:12:01,992 --> 00:12:06,062
you can inject all kinds of chaos. So container kill,

184
00:12:06,216 --> 00:12:09,154
cpu hog, network close.

185
00:12:09,282 --> 00:12:13,750
But whats we will do right now is we want to inject network latency.

186
00:12:17,950 --> 00:12:21,066
Before we proceed. We need to tune this

187
00:12:21,088 --> 00:12:24,586
a bit. So I

188
00:12:24,608 --> 00:12:28,220
need to specify the target here, which is card service.

189
00:12:29,950 --> 00:12:32,330
This is the name of my microservice.

190
00:12:35,650 --> 00:12:39,246
We don't have any probes right now. The duration of the

191
00:12:39,268 --> 00:12:43,220
chaotic experiment, let's say 200

192
00:12:44,790 --> 00:12:48,898
and the network latency let's make it 4000

193
00:12:48,984 --> 00:12:56,120
so we can detect it.

194
00:12:57,130 --> 00:13:01,142
Also, never forget to click here in advanced options and

195
00:13:01,276 --> 00:13:04,258
to enable cleanup chaos.

196
00:13:04,434 --> 00:13:08,394
This basically cleans up the chaos and restores your environment after

197
00:13:08,432 --> 00:13:10,220
the chaos experiments is over.

198
00:13:12,910 --> 00:13:16,730
Now that we've set this all up, we can proceed.

199
00:13:17,790 --> 00:13:21,358
We are scheduling it right now. Click on

200
00:13:21,444 --> 00:13:25,406
finish. And now

201
00:13:25,428 --> 00:13:26,910
let's see the workflow.

202
00:13:28,290 --> 00:13:31,802
So now what he's doing is setting up the chaos environment,

203
00:13:31,946 --> 00:13:36,014
after which he will start conducting

204
00:13:36,062 --> 00:13:39,060
latency issues.

205
00:13:40,070 --> 00:13:43,410
So what we can see here, what we will see here,

206
00:13:43,480 --> 00:13:46,882
and maybe we can already see it actually, is that in locust

207
00:13:47,026 --> 00:13:50,642
we have all the requests that our simulated users

208
00:13:50,706 --> 00:13:54,486
are executing, as well as the failures here,

209
00:13:54,588 --> 00:13:58,342
which will increase even more after these cows

210
00:13:58,406 --> 00:14:00,330
is injected.

211
00:14:02,430 --> 00:14:05,894
Okay, you also see here the percentage

212
00:14:05,942 --> 00:14:09,526
of failure, which is something pretty handy. Now let's

213
00:14:09,558 --> 00:14:13,630
go check out if

214
00:14:13,700 --> 00:14:17,546
our dashboard, if our splunk observability platform detected

215
00:14:17,578 --> 00:14:21,520
anything. And yeah, actually, as you can see here right now,

216
00:14:22,050 --> 00:14:26,014
this is these latency dashboard we can see this red triangle

217
00:14:26,062 --> 00:14:28,942
already indicates that there was an alert.

218
00:14:29,086 --> 00:14:32,514
Let me quickly dig through my emails to

219
00:14:32,552 --> 00:14:36,100
see if I've received something. Yeah, I did.

220
00:14:36,710 --> 00:14:40,402
So as you can see here, splunk observability critical alert,

221
00:14:40,466 --> 00:14:43,942
it says latency. The latency in the last eight minutes

222
00:14:43,996 --> 00:14:47,254
is more than three deviations above the norm. So it

223
00:14:47,292 --> 00:14:50,922
basically alerted me that there has been

224
00:14:51,056 --> 00:14:54,582
an increase in latency. So if we look here at the graph,

225
00:14:54,726 --> 00:14:58,634
you'll notice that before we have this peak here, before we

226
00:14:58,672 --> 00:15:02,320
have this significant increase in latency, which is

227
00:15:03,170 --> 00:15:06,606
larger than anything, before we

228
00:15:06,628 --> 00:15:09,962
notice that the alert comes actually before the increase.

229
00:15:10,026 --> 00:15:14,066
So what we're using here, we're using our AIOps model to

230
00:15:14,088 --> 00:15:18,242
basically predict when there is something off in latency before

231
00:15:18,296 --> 00:15:22,206
we actually have the error. That way we can actually even prevent

232
00:15:22,238 --> 00:15:25,950
it. In reality,

233
00:15:26,110 --> 00:15:28,890
we can do even more than just alerts.

234
00:15:29,070 --> 00:15:32,534
So let me show you

235
00:15:32,572 --> 00:15:36,502
the settings. If you go

236
00:15:36,556 --> 00:15:40,220
here, two alert message. You can actually

237
00:15:40,990 --> 00:15:44,298
specify here, runbook. This is pretty interesting

238
00:15:44,384 --> 00:15:47,926
because within this runbook you can give splunk

239
00:15:47,958 --> 00:15:52,202
observability some actions to do to remediate this issue. For instance,

240
00:15:52,346 --> 00:15:55,866
it can rebuild,

241
00:15:55,978 --> 00:15:59,470
it can reset the node that's failing or that has issues.

242
00:15:59,620 --> 00:16:03,546
So this is actually what we're talking about when we're saying that we're shifting

243
00:16:03,578 --> 00:16:07,550
from a proactive to a predictive paradigm.

244
00:16:09,190 --> 00:16:12,930
So if you remember, we posed a question earlier,

245
00:16:13,350 --> 00:16:17,746
and the question was, how does AIOps react? If I run a chaos experiment,

246
00:16:17,938 --> 00:16:21,202
as we can see in this case, it detects latency increments

247
00:16:21,266 --> 00:16:25,126
and promptly alerts me. So let's put a checkmark on

248
00:16:25,148 --> 00:16:28,746
that. The other question, if you remember, we posed was,

249
00:16:28,848 --> 00:16:32,918
is aiops capable of recognizing a running chaos experiment?

250
00:16:33,094 --> 00:16:36,410
For that, I've but another really simple dashboard.

251
00:16:38,350 --> 00:16:41,706
So this dashboard basically contains

252
00:16:41,738 --> 00:16:44,954
a counter for every time the specific pod

253
00:16:45,002 --> 00:16:48,602
is launched within the litmus mailing space. And this ultimately

254
00:16:48,666 --> 00:16:52,686
shows me every chaos experiments that was running. So here

255
00:16:52,708 --> 00:16:56,866
I said in the last week, it gives me and detects every

256
00:16:56,968 --> 00:17:00,466
chaos experiment I ran, and it also gives me account.

257
00:17:00,648 --> 00:17:03,902
So, in conclusion, we've proven our hypothesis as AIops

258
00:17:03,966 --> 00:17:07,190
is actually capable of detecting a running chaos experiment.

259
00:17:10,010 --> 00:17:13,958
Okay, let's wrap everything up. We talked today about

260
00:17:14,044 --> 00:17:17,314
aiops, which is necessary to preemptively predict failure

261
00:17:17,362 --> 00:17:21,222
and system degradation. We talked about chaos engineering,

262
00:17:21,286 --> 00:17:25,370
necessary to inject chaos into the system and testing its resiliency,

263
00:17:25,710 --> 00:17:29,274
and finally, observability. Observability provides us

264
00:17:29,312 --> 00:17:32,486
full transparency of the system through end to end monitoring.

265
00:17:32,678 --> 00:17:36,666
Now, we have tested and confirmed I hypothesis today, which claims

266
00:17:36,698 --> 00:17:40,042
that aiops can leverage observability in order to identify

267
00:17:40,106 --> 00:17:43,002
when a chaos experiment is running. So basically,

268
00:17:43,076 --> 00:17:46,786
AIops is able to detect that. We have shown this today with

269
00:17:46,808 --> 00:17:50,334
our live demo. Furthermore, through this continuous

270
00:17:50,382 --> 00:17:54,082
cycle of hypothesis and experimenting, trust in the system is

271
00:17:54,136 --> 00:17:57,890
built. And with every experiment, its reliability increases.

272
00:17:58,390 --> 00:18:01,746
A final takeaway, I would like to point out from today's session,

273
00:18:01,858 --> 00:18:05,590
start simple and scale fast. So you don't know where to start from.

274
00:18:05,660 --> 00:18:09,478
So what? Start from a simple experiment, see how it goals,

275
00:18:09,564 --> 00:18:13,394
see how the system reacts. And as you proceed, you can scale.

276
00:18:13,522 --> 00:18:16,600
You basically build more, and youre on top of that.

277
00:18:18,330 --> 00:18:22,030
Well, it seems it's time to close curtains. Thank you for watching this talk,

278
00:18:22,100 --> 00:18:25,166
and I hope you got something out of it. Until next time,

279
00:18:25,268 --> 00:18:26,030
cheers.

