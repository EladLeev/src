1
00:00:40,930 --> 00:00:44,134
Hello, my name is Pavusk and together

2
00:00:44,252 --> 00:00:47,894
with my friends Alaranievich, we want to

3
00:00:47,932 --> 00:00:52,266
show you the most in innovative multicloud

4
00:00:52,378 --> 00:00:56,414
deployment platform. Yeah, I know I'm out of that platform

5
00:00:56,532 --> 00:01:00,430
or one of the coauthors, but I really really think

6
00:01:00,500 --> 00:01:03,940
that it's a very innovative things. Let's start.

7
00:01:05,350 --> 00:01:08,738
What is the melodic platform? It is the single

8
00:01:08,824 --> 00:01:13,406
universal platform for the automatic multi cloud deployed.

9
00:01:13,518 --> 00:01:16,934
So you can just simply automatically deploy to

10
00:01:16,972 --> 00:01:21,490
the Azure AWS, Google Cloud, to any OpenStack

11
00:01:21,570 --> 00:01:25,110
cloud providers and also to one steps cloud

12
00:01:25,180 --> 00:01:28,486
provider and other cloud provided

13
00:01:28,598 --> 00:01:32,618
everything is done automatically and even more

14
00:01:32,784 --> 00:01:36,102
the usage of the resources is optimized.

15
00:01:36,246 --> 00:01:39,942
So our platform is selecting the most

16
00:01:40,096 --> 00:01:43,642
optimal set of the resources, the most optimal

17
00:01:43,706 --> 00:01:47,374
cloud providers to deploy your application.

18
00:01:47,572 --> 00:01:51,850
How it works the melodic is probably the simplest

19
00:01:51,930 --> 00:01:55,262
and the easiest way to use the multi cloud. You don't

20
00:01:55,326 --> 00:01:58,222
need to learn Azure AWS,

21
00:01:58,366 --> 00:02:01,666
Google Cloud platform OpenStack, but you

22
00:02:01,688 --> 00:02:05,910
have the one cloud agnostic independent models of the application

23
00:02:06,060 --> 00:02:09,282
and it can be deployed automatically

24
00:02:09,346 --> 00:02:13,618
to any cloud provider. It supports virtual machines

25
00:02:13,714 --> 00:02:17,254
containers serverless function which I especially

26
00:02:17,372 --> 00:02:21,130
covered on today's presentation and also big data

27
00:02:21,200 --> 00:02:25,050
frameworks and we can deploy that to the different cloud

28
00:02:25,120 --> 00:02:29,446
providers. As I already said, the deployment is fully automatic.

29
00:02:29,558 --> 00:02:32,754
So it's probably the only one multicloud

30
00:02:32,822 --> 00:02:36,506
platform which supports fully automatic deployment

31
00:02:36,618 --> 00:02:40,766
and for sure the only one platform which is doing

32
00:02:40,868 --> 00:02:45,022
advanced optimization of the cloud resources using the machine

33
00:02:45,086 --> 00:02:49,394
learning based algorithm. So first step is to model the application

34
00:02:49,592 --> 00:02:54,162
and for that we have deployed camel cloud application

35
00:02:54,296 --> 00:02:57,846
modeling and execution language which allows to

36
00:02:57,868 --> 00:03:00,882
model both application and infrastructure.

37
00:03:01,026 --> 00:03:04,440
And even more it allows to model the

38
00:03:04,970 --> 00:03:09,238
requirements, constration and optimization goals

39
00:03:09,334 --> 00:03:13,258
for the application. So everything is modeled in one

40
00:03:13,344 --> 00:03:16,682
model and this model is used CTO

41
00:03:16,816 --> 00:03:20,634
deployed application to various cloud provided and for the

42
00:03:20,672 --> 00:03:24,446
optimization proposals. It is quite similar

43
00:03:24,548 --> 00:03:28,874
language based on Tosca, but it extends

44
00:03:28,922 --> 00:03:32,170
Tosca a lot, allows for the modeling components,

45
00:03:32,250 --> 00:03:35,794
connections between the components, security rules and so

46
00:03:35,832 --> 00:03:39,438
on. And of course to model the infrastructure

47
00:03:39,534 --> 00:03:42,654
requirements so we can model the requirements,

48
00:03:42,782 --> 00:03:46,326
constraints and the value of the utility function

49
00:03:46,428 --> 00:03:50,530
which is based as a goal for the optimization.

50
00:03:50,690 --> 00:03:54,962
The utility function set what is the best deployment.

51
00:03:55,026 --> 00:03:58,854
So how we know that the given deployment for the application,

52
00:03:58,972 --> 00:04:02,266
given set of the resources is the best. One of the

53
00:04:02,288 --> 00:04:06,154
criterion is of course the cost. But if we have only the

54
00:04:06,192 --> 00:04:09,626
cost as a goal or as utility function,

55
00:04:09,808 --> 00:04:13,194
then the best solution is just simply to not deploy

56
00:04:13,242 --> 00:04:16,286
anything because in that case the cost will be zero.

57
00:04:16,388 --> 00:04:19,790
But in reality we want to deployed our application.

58
00:04:19,940 --> 00:04:22,926
So it is usually the trade off.

59
00:04:23,028 --> 00:04:26,194
But before this optimization. We need to know what

60
00:04:26,232 --> 00:04:30,050
is the context of the application, so how many resources

61
00:04:30,550 --> 00:04:33,826
are used and what is the performance, what is

62
00:04:33,848 --> 00:04:37,430
the cost and so on. And we are doing that

63
00:04:37,500 --> 00:04:41,078
by the metric collection. Then we need CTO have

64
00:04:41,244 --> 00:04:44,982
the utility function. So we need to know what is this

65
00:04:45,036 --> 00:04:48,178
past deployed. And in melodic it

66
00:04:48,204 --> 00:04:51,834
is possible to create in a very flexible way the

67
00:04:51,872 --> 00:04:55,818
utility function. And this utility function is based on the business

68
00:04:55,904 --> 00:04:59,830
value. So not on the cpu usage, memory usage,

69
00:04:59,910 --> 00:05:02,842
but on the average response to the user,

70
00:05:02,906 --> 00:05:06,750
average workload and so on. It is possible to add

71
00:05:06,820 --> 00:05:10,238
any custom metric for the application. And this custom

72
00:05:10,324 --> 00:05:14,210
metric measured by the custom sensor can

73
00:05:14,280 --> 00:05:17,470
provide the business related metric

74
00:05:17,550 --> 00:05:21,634
to the platform which is used for the optimization. And as

75
00:05:21,672 --> 00:05:25,702
I said, it is usually a trade off between the cost and

76
00:05:25,756 --> 00:05:29,960
performance, cost and availability, cost and

77
00:05:30,890 --> 00:05:35,202
other requirements. And everything is modeled

78
00:05:35,346 --> 00:05:39,194
in the camel model and automatically optimized by

79
00:05:39,232 --> 00:05:43,370
melodic. So you can consider melodic as your smart and

80
00:05:43,440 --> 00:05:47,242
autonomic DevOps operator. How it works

81
00:05:47,376 --> 00:05:51,322
first step is manual, so you need to model application

82
00:05:51,456 --> 00:05:54,782
in the camel model. But the good news is that it is

83
00:05:54,836 --> 00:05:58,266
needed to be done only once. So if you have modeled

84
00:05:58,298 --> 00:06:01,978
your application, set initial values of the parameters,

85
00:06:02,154 --> 00:06:06,260
then everything is done automatically. So after

86
00:06:06,710 --> 00:06:10,434
deploying the model, melodic is calculating the

87
00:06:10,472 --> 00:06:12,900
initial deployment plan for the application.

88
00:06:13,430 --> 00:06:16,790
Deployment plan, I mean which cloud providers to use

89
00:06:16,860 --> 00:06:20,662
and how many resources, what type of the resources and

90
00:06:20,716 --> 00:06:24,674
so on and so on. Everything is calculated automatically.

91
00:06:24,802 --> 00:06:27,950
After finding the most optimal deployment,

92
00:06:28,130 --> 00:06:32,470
the application and infrastructure is automatically

93
00:06:32,550 --> 00:06:36,422
deployed to the selected cloud providers. So virtual

94
00:06:36,486 --> 00:06:39,558
machines and other resources are provisioned.

95
00:06:39,654 --> 00:06:42,474
Then the components are deployed fully,

96
00:06:42,522 --> 00:06:46,270
automatically. And then the metric collection and

97
00:06:46,340 --> 00:06:49,934
monitoring is started. So the melodic platform

98
00:06:50,052 --> 00:06:53,886
is collecting the metrics and based on the values

99
00:06:53,918 --> 00:06:57,570
of the metrics, melodic makes a decision if the

100
00:06:57,640 --> 00:07:01,490
new deployed new solution should be

101
00:07:01,640 --> 00:07:05,102
reasoning to start rezoning process to find

102
00:07:05,176 --> 00:07:08,598
the new solution. Usually the decision about starting

103
00:07:08,684 --> 00:07:12,710
new reasoning process is based on the threshold. So if the given

104
00:07:12,780 --> 00:07:17,522
metric has the value above the certain threshold,

105
00:07:17,666 --> 00:07:21,686
then the new reasoning part is started and melodic

106
00:07:21,718 --> 00:07:25,322
is looking for the new solution. And if the new solution is

107
00:07:25,376 --> 00:07:28,662
found, then it is automatically deployed,

108
00:07:28,726 --> 00:07:32,890
but it's not deployed from the scratch. But the current one solution

109
00:07:32,970 --> 00:07:37,310
is reconfiguration. So new resources are added or

110
00:07:37,380 --> 00:07:40,314
removed if necessary or replaced.

111
00:07:40,442 --> 00:07:44,206
But everything is done on the fly. It's fully

112
00:07:44,238 --> 00:07:48,020
automatic process and how melodic is built.

113
00:07:49,430 --> 00:07:53,266
I think it's very interesting, especially for

114
00:07:53,288 --> 00:07:56,386
the developers. For the cloud native solution,

115
00:07:56,578 --> 00:08:00,450
the melodic has the pure microservice architecture

116
00:08:00,530 --> 00:08:04,630
as you can see. And these microservices are

117
00:08:04,700 --> 00:08:07,960
orchestrated by the PM process.

118
00:08:09,050 --> 00:08:12,746
We have implemented all of the logic as a business

119
00:08:12,848 --> 00:08:15,962
process using the kamunda and

120
00:08:16,016 --> 00:08:19,414
for managing the components and invoking

121
00:08:19,462 --> 00:08:23,306
the components. We are using Mu ESB as

122
00:08:23,408 --> 00:08:26,894
ESB and activeMQ with the esper as

123
00:08:26,932 --> 00:08:30,462
the monitoring plan. Thanks CTO that we are

124
00:08:30,516 --> 00:08:34,562
very flexible. We can change the logic just simply by

125
00:08:34,616 --> 00:08:37,714
drag and drop in the BPM tool.

126
00:08:37,912 --> 00:08:42,722
We avoid to hard code too much logic into

127
00:08:42,776 --> 00:08:47,170
the system. We have evaluated different integration

128
00:08:47,250 --> 00:08:50,982
method point to point so directly from the BPM to the

129
00:08:51,036 --> 00:08:54,386
certain microservice cube based integration

130
00:08:54,498 --> 00:08:58,042
ESB. But finally we have decided to use the

131
00:08:58,096 --> 00:09:02,262
ESB with the BPM integration as it is implemented

132
00:09:02,326 --> 00:09:05,894
currently in melodic. Yeah, we have an extended

133
00:09:05,942 --> 00:09:09,510
comparison of the different methods and how they fulfill

134
00:09:09,590 --> 00:09:13,182
the requirements including some kind of the

135
00:09:13,236 --> 00:09:16,270
points calculation and preparing the planning.

136
00:09:16,610 --> 00:09:20,346
And as I said finally we have evaluated

137
00:09:20,458 --> 00:09:24,302
free USB solution and four BPM engines.

138
00:09:24,366 --> 00:09:27,618
But the final solution is

139
00:09:27,704 --> 00:09:31,294
built based on the mulesB and Kamonda

140
00:09:31,342 --> 00:09:34,434
BPM workflow. We have

141
00:09:34,472 --> 00:09:38,342
documentation why we have selected that

142
00:09:38,476 --> 00:09:42,374
tools and it could be also very interesting thing to

143
00:09:42,412 --> 00:09:45,574
take a look if someone wants to build this type of the

144
00:09:45,612 --> 00:09:49,226
solutions. We have compared both ESB and

145
00:09:49,248 --> 00:09:52,506
BPM solution and based on that we have

146
00:09:52,608 --> 00:09:56,042
built the whole platform which is then

147
00:09:56,096 --> 00:10:00,798
used to deploy the applications. And today I want to show

148
00:10:00,964 --> 00:10:04,590
two examples of the use case application and then

149
00:10:04,660 --> 00:10:07,982
Alicia will go through the melodic platform and

150
00:10:08,036 --> 00:10:12,330
show the r1 deployment. One application is

151
00:10:12,420 --> 00:10:15,634
image recognition on the fly. The images are

152
00:10:15,672 --> 00:10:19,502
provided by the special augmented reality

153
00:10:19,566 --> 00:10:23,538
glasses and directly connected to the cloud and we are using

154
00:10:23,624 --> 00:10:27,506
serverless function which classify

155
00:10:27,618 --> 00:10:31,394
images almost in the near real time and melodic

156
00:10:31,442 --> 00:10:35,890
decides how much resources or how many instances

157
00:10:36,050 --> 00:10:39,834
should be run in the given moments. And also the

158
00:10:39,872 --> 00:10:44,198
second planning part is deployed using the spark

159
00:10:44,294 --> 00:10:47,942
big data framework which is also managed by melodic.

160
00:10:48,006 --> 00:10:51,294
Melodic decides how many workers should

161
00:10:51,332 --> 00:10:55,246
be used. The second use case is big

162
00:10:55,348 --> 00:10:59,710
data application spark application. It is the application used

163
00:10:59,780 --> 00:11:03,606
by the one of the polish universities to analyze

164
00:11:03,738 --> 00:11:07,378
genome data. It compares the genome of the given

165
00:11:07,464 --> 00:11:11,170
person, CTo the reference genome data to find

166
00:11:11,240 --> 00:11:14,434
the mutation and the genome data are

167
00:11:14,472 --> 00:11:17,734
collected from the persons and then the

168
00:11:17,772 --> 00:11:21,222
processing is started after sequencing to the

169
00:11:21,356 --> 00:11:25,222
digital form of the genome and the operator is

170
00:11:25,276 --> 00:11:28,778
starting the processing based on the number of the

171
00:11:28,864 --> 00:11:32,666
patient and data to process

172
00:11:32,848 --> 00:11:36,346
starting this processing, melodic is looking

173
00:11:36,448 --> 00:11:40,134
for the parameters of the training, so collected the metrics

174
00:11:40,182 --> 00:11:43,614
and checking how long it takes to process the data

175
00:11:43,732 --> 00:11:47,530
and if it process too long the new resources are added

176
00:11:47,610 --> 00:11:51,514
and the process repeats. So melodic continuously collect

177
00:11:51,562 --> 00:11:55,646
the metrics and checking what is the expected estimated

178
00:11:55,758 --> 00:11:59,586
time for the finishing job and if the time is

179
00:11:59,608 --> 00:12:03,486
too long, then again the new resources are added

180
00:12:03,598 --> 00:12:07,702
and if the time is below the expected time.

181
00:12:07,836 --> 00:12:11,382
So the business goal the reconfiguration is

182
00:12:11,436 --> 00:12:15,254
keep stable and the data are process and at the

183
00:12:15,292 --> 00:12:18,646
end the data are removed as a summary

184
00:12:18,758 --> 00:12:22,442
how the workflow in the melodic looks like. So we

185
00:12:22,496 --> 00:12:25,946
model our application in camel, then deploy the

186
00:12:25,968 --> 00:12:30,066
melodic platform, then submit the model to the melodic

187
00:12:30,118 --> 00:12:34,286
platform, press big green button in

188
00:12:34,308 --> 00:12:37,838
the melodic, Allah will show you how to do that

189
00:12:37,924 --> 00:12:42,062
and then melodic automatically find the best solution and

190
00:12:42,116 --> 00:12:45,410
deploy your application. And after that just

191
00:12:45,480 --> 00:12:48,690
connect to your application and enjoy.

192
00:12:48,840 --> 00:12:52,654
And now allah will present the demo of the melodic.

193
00:12:52,702 --> 00:12:56,130
So the demo of the platform and also the deployment

194
00:12:56,210 --> 00:12:59,654
of the application, how it is done and how

195
00:12:59,692 --> 00:13:03,414
to handle that. So thank you and allah please

196
00:13:03,532 --> 00:13:07,094
go on. Now I would like to present you how to

197
00:13:07,132 --> 00:13:10,394
automatically deploy own application by

198
00:13:10,432 --> 00:13:14,410
melodic platform. I will perform deployment of spark based

199
00:13:14,480 --> 00:13:18,282
application. We will monitor application metrics and

200
00:13:18,336 --> 00:13:21,774
observe reconfiguration process which is done by

201
00:13:21,812 --> 00:13:25,386
melodic for reasons of optimization. My melodic

202
00:13:25,418 --> 00:13:29,466
platform is installed on virtual machine on AWS

203
00:13:29,578 --> 00:13:32,570
and it is up and running. I'm logged in.

204
00:13:32,660 --> 00:13:36,142
Melodic users are managed by LDAP.

205
00:13:36,206 --> 00:13:40,046
We have three possible roles of users common user

206
00:13:40,158 --> 00:13:43,662
he can perform application deployed admin

207
00:13:43,726 --> 00:13:47,858
user. He manages of users accounts

208
00:13:47,954 --> 00:13:51,350
and also has all privileges from common

209
00:13:51,420 --> 00:13:55,270
user and technical user. He is used

210
00:13:55,340 --> 00:13:58,922
only internally by melodic components and he is

211
00:13:58,976 --> 00:14:02,346
not important from client's point of view.

212
00:14:02,528 --> 00:14:06,042
The first step in melodic usage is

213
00:14:06,096 --> 00:14:09,810
the defining of cloud settings. In provider

214
00:14:09,910 --> 00:14:13,834
settings menu part, we can check and update provided

215
00:14:13,882 --> 00:14:17,278
credentials and options as we can see in

216
00:14:17,364 --> 00:14:19,966
cloud definition for provided view,

217
00:14:20,068 --> 00:14:23,602
filling these values is required in order to

218
00:14:23,656 --> 00:14:27,170
perform successful deployment because they are based

219
00:14:27,240 --> 00:14:31,550
in contact with providers. For example, by creating virtual

220
00:14:31,630 --> 00:14:35,350
instances on my environment, I have already

221
00:14:35,420 --> 00:14:39,958
defined these values for Amazon web service and

222
00:14:40,044 --> 00:14:43,330
for OpenStack providers. In these definitions

223
00:14:43,410 --> 00:14:47,358
we provide cloud credentials and properties,

224
00:14:47,474 --> 00:14:51,274
for example settings for Amazon Security group

225
00:14:51,392 --> 00:14:54,714
or set of private images which we would

226
00:14:54,752 --> 00:14:58,506
like to use in our deployments. When our platform

227
00:14:58,608 --> 00:15:02,874
is prepared configured, we can go to deployment bookmark.

228
00:15:03,002 --> 00:15:07,022
Today I would like to deploy genome application which

229
00:15:07,076 --> 00:15:11,594
was described by Pavel a moment ago. Before deployed

230
00:15:11,722 --> 00:15:15,010
we need to model our application with its

231
00:15:15,080 --> 00:15:18,162
requirements in camel model which is

232
00:15:18,216 --> 00:15:21,730
human, understandable and editable form.

233
00:15:21,880 --> 00:15:26,194
After that such model is transformed CTO XMI

234
00:15:26,242 --> 00:15:29,858
format form understandable formaltic

235
00:15:29,954 --> 00:15:33,650
we upload this file here by drag and drop.

236
00:15:33,730 --> 00:15:37,522
Now our models is being validated and after that

237
00:15:37,596 --> 00:15:41,146
it will be saved in database. In a minute I will

238
00:15:41,168 --> 00:15:45,142
be asked for fill values of AWS developers

239
00:15:45,206 --> 00:15:48,966
credentials. Providing these credentials is required

240
00:15:49,078 --> 00:15:52,954
in order to save results of our genome application

241
00:15:53,152 --> 00:15:56,734
in AWS as freebacket, but in view

242
00:15:56,772 --> 00:16:00,394
of security reasons we shouldn't put them directly

243
00:16:00,442 --> 00:16:04,434
in camel model file. So we use placeholders in

244
00:16:04,472 --> 00:16:08,322
camel file and after that we need CTO provide these

245
00:16:08,376 --> 00:16:12,690
values here. In this case it is not the first

246
00:16:12,760 --> 00:16:16,530
upload of such model on this virtual machine.

247
00:16:16,610 --> 00:16:20,466
So these variables already exist in dedicated secure

248
00:16:20,498 --> 00:16:24,978
store. I can verify them update if they were changed

249
00:16:25,074 --> 00:16:27,800
and after that choose save button.

250
00:16:28,410 --> 00:16:32,122
In the last step I need to choose which application

251
00:16:32,256 --> 00:16:35,706
I want to deploy and which cloud providers I

252
00:16:35,728 --> 00:16:39,722
want to use. Here is also possible to run application in

253
00:16:39,776 --> 00:16:43,774
simulation mode. Simulation mode is the case when we

254
00:16:43,812 --> 00:16:47,018
don't want to deploy real virtual machines

255
00:16:47,114 --> 00:16:51,086
on provided platform but only check which

256
00:16:51,268 --> 00:16:55,086
solution will be chosen by melodic. We manually

257
00:16:55,198 --> 00:16:59,074
set values of metrics in simulation part

258
00:16:59,192 --> 00:17:02,494
and observe the result. But today our aim

259
00:17:02,542 --> 00:17:06,034
is to perform real deployment of genome

260
00:17:06,082 --> 00:17:09,954
application so I leave this option turned

261
00:17:10,002 --> 00:17:14,738
off. We would like to deploy genome only on AWS

262
00:17:14,914 --> 00:17:18,266
so we chose this cloud definition. Thanks to

263
00:17:18,288 --> 00:17:21,798
that melodic has credentials for this provider.

264
00:17:21,894 --> 00:17:26,058
After that we can go to the last step here where

265
00:17:26,224 --> 00:17:28,700
starting deployed is available.

266
00:17:29,790 --> 00:17:33,470
After starting the process, in a minute we are moved cto the

267
00:17:33,540 --> 00:17:36,654
deployment process view. Here we can

268
00:17:36,692 --> 00:17:40,558
observe the progress of that. In the meantime, I would like to

269
00:17:40,644 --> 00:17:44,034
briefly describe application which is

270
00:17:44,072 --> 00:17:48,210
being deployed by melodic. Now Genome is a big data

271
00:17:48,280 --> 00:17:51,762
application which performs some calculations and

272
00:17:51,816 --> 00:17:55,086
safe results in AWS as free

273
00:17:55,128 --> 00:17:58,674
bucket so we need to provide developers credentials

274
00:17:58,722 --> 00:18:02,978
to AWS. Genome's performance is managed by Spark.

275
00:18:03,074 --> 00:18:07,142
In genome application we use Spark as platform for

276
00:18:07,196 --> 00:18:11,190
big data operations which are performed parallel

277
00:18:11,270 --> 00:18:15,494
on many machines and managed by one machine named

278
00:18:15,542 --> 00:18:19,622
Sparkmaster. Sparkmaster is available by default

279
00:18:19,686 --> 00:18:23,598
on melodic platform. Melodic creates proper number

280
00:18:23,684 --> 00:18:27,962
of spark workers as virtual machines considered

281
00:18:28,026 --> 00:18:31,326
our requirements from camel model thanks to

282
00:18:31,348 --> 00:18:34,754
measurements of application metrics, melodic makes

283
00:18:34,792 --> 00:18:38,494
a decision about creating additional instances

284
00:18:38,542 --> 00:18:41,950
with workers or about deleting unnecessary

285
00:18:42,030 --> 00:18:46,210
ones. Spark divides all calculations named tasks

286
00:18:46,290 --> 00:18:50,550
between available workers in order to optimized application

287
00:18:50,700 --> 00:18:54,134
performance and cost. Please let me come back to

288
00:18:54,172 --> 00:18:57,706
our process. Phishing offers is the first step of

289
00:18:57,728 --> 00:19:01,850
deployment process. We have information about current

290
00:19:01,920 --> 00:19:05,414
total number of offers from previously selected

291
00:19:05,462 --> 00:19:09,514
providers. So in this case from AWS from

292
00:19:09,552 --> 00:19:13,018
these owners. Verlodic will choose the best solution

293
00:19:13,114 --> 00:19:17,006
for worker component after choosing this box

294
00:19:17,188 --> 00:19:20,846
or offer option from Mani which is available

295
00:19:20,948 --> 00:19:24,194
here, we are directed to view of

296
00:19:24,232 --> 00:19:27,522
all currently available offers. There are

297
00:19:27,576 --> 00:19:31,522
cloud with my credentials and also with

298
00:19:31,576 --> 00:19:36,002
my properties for security group and for filters

299
00:19:36,146 --> 00:19:40,790
for our private images. Also we have

300
00:19:40,860 --> 00:19:44,806
here hardware with information about

301
00:19:44,908 --> 00:19:49,558
cores, ram and disk and available locations

302
00:19:49,734 --> 00:19:53,622
where our virtual machines could be located

303
00:19:53,766 --> 00:19:56,090
and the last element here images.

304
00:19:56,830 --> 00:20:00,894
There are only private images visible here

305
00:20:01,012 --> 00:20:04,302
but of course all public images are available

306
00:20:04,436 --> 00:20:07,838
for us. Now I come back to our process

307
00:20:07,924 --> 00:20:11,390
view and we can see that the next step

308
00:20:11,460 --> 00:20:14,386
of process is generating constraint problem.

309
00:20:14,488 --> 00:20:17,938
Constraint problem is generated based off our

310
00:20:18,024 --> 00:20:22,018
requirements defined in camel model. In simple

311
00:20:22,104 --> 00:20:25,922
process view there are visualized all variables

312
00:20:25,986 --> 00:20:29,394
from constraint problem with the domain values

313
00:20:29,522 --> 00:20:32,914
for genome worker, cardinality worker

314
00:20:32,962 --> 00:20:35,730
course and provider for spark worker.

315
00:20:35,810 --> 00:20:39,930
Detailed data are shown after click of this box and

316
00:20:40,000 --> 00:20:44,186
here are presented list of variables with

317
00:20:44,288 --> 00:20:47,670
additional information about component

318
00:20:47,830 --> 00:20:51,210
type, domain and type of this domain.

319
00:20:51,290 --> 00:20:55,370
Utility formula it is used for measure utility

320
00:20:55,530 --> 00:20:58,766
of each possible solutions and choose the

321
00:20:58,788 --> 00:21:02,566
best one list of constants with types

322
00:21:02,618 --> 00:21:06,494
and values. They are created from user requirements

323
00:21:06,622 --> 00:21:10,274
and are used in melody calculations. Here we

324
00:21:10,312 --> 00:21:13,742
can see for example minimum and maximum

325
00:21:13,806 --> 00:21:17,154
values for cardinality of spark worker

326
00:21:17,202 --> 00:21:21,382
instances or the same type of restriction for number

327
00:21:21,516 --> 00:21:25,126
of spark worker cores. So we can see

328
00:21:25,228 --> 00:21:29,146
that in our deployed we would like to have

329
00:21:29,248 --> 00:21:33,226
from one to maximum ten workers and

330
00:21:33,248 --> 00:21:37,126
the last element here list of metrics with data types

331
00:21:37,158 --> 00:21:40,538
and values initial values. They describe

332
00:21:40,634 --> 00:21:43,854
current performance of this application. Thanks to

333
00:21:43,892 --> 00:21:47,706
them, melodic can make a decision about triggering

334
00:21:47,738 --> 00:21:51,450
the reconfiguration process which means creating

335
00:21:51,530 --> 00:21:54,750
new additional instances or deleting

336
00:21:54,830 --> 00:21:58,642
not fully used ones. Thanks to metrics, melodic can

337
00:21:58,696 --> 00:22:03,038
do the most important task which is cost optimization.

338
00:22:03,214 --> 00:22:06,914
We back to process view. When constraint problem is

339
00:22:06,952 --> 00:22:11,026
generated, it is time for resoning. Melodic finds

340
00:22:11,058 --> 00:22:14,374
here the best the most profitable solution for

341
00:22:14,412 --> 00:22:18,374
the problem defined by us. When rezoning is completed,

342
00:22:18,502 --> 00:22:22,646
we can observe information about calculated solution

343
00:22:22,758 --> 00:22:27,238
utility value and values for each variables.

344
00:22:27,334 --> 00:22:30,786
In that case one as worker cardinality

345
00:22:30,918 --> 00:22:34,282
for worker cores and provided for spark

346
00:22:34,346 --> 00:22:39,082
worker from zero index. So it is AWS.

347
00:22:39,226 --> 00:22:43,070
The next step in process deployment is deployed

348
00:22:43,150 --> 00:22:47,150
here melodic performs operations based on calculated

349
00:22:47,230 --> 00:22:50,962
solution. This solution is deployed for each

350
00:22:51,016 --> 00:22:54,254
application component. Melodic creates

351
00:22:54,302 --> 00:22:58,210
proper instances, remains them or deletes.

352
00:22:58,370 --> 00:23:01,446
If you want to have more detailed view,

353
00:23:01,548 --> 00:23:05,618
it is possible to see the process view using Kamunda

354
00:23:05,714 --> 00:23:08,906
by choosing advanced view button from

355
00:23:09,008 --> 00:23:11,658
upper left corner. From this view,

356
00:23:11,824 --> 00:23:15,450
Kamunda is tool for monitoring

357
00:23:15,870 --> 00:23:19,580
and for modeling processes in BPM and standard

358
00:23:19,890 --> 00:23:23,102
and for management of them. I log in by

359
00:23:23,156 --> 00:23:27,678
the same credentials as for my melodic platform and

360
00:23:27,764 --> 00:23:31,534
in order to see detailed view in Kamunda I

361
00:23:31,572 --> 00:23:35,602
need to choose running process instances and

362
00:23:35,656 --> 00:23:39,620
after that process to monitoring from the list.

363
00:23:40,790 --> 00:23:44,178
And now we can see view of chosen process

364
00:23:44,344 --> 00:23:48,678
with all the variables and also

365
00:23:48,844 --> 00:23:52,600
detailed view of the whole process

366
00:23:53,130 --> 00:23:57,142
with each steps. This view is for more

367
00:23:57,196 --> 00:24:01,450
technical users. It could be useful for example during

368
00:24:01,520 --> 00:24:05,226
diagnostic of some problems. We can see that now

369
00:24:05,328 --> 00:24:08,746
we are even here. So it is the

370
00:24:08,768 --> 00:24:12,602
end of our process. In order to verify this fact

371
00:24:12,736 --> 00:24:16,126
I go to UI again and yes,

372
00:24:16,228 --> 00:24:19,818
we can see that our application successfully

373
00:24:19,914 --> 00:24:23,762
started. So the deployment process is

374
00:24:23,816 --> 00:24:27,810
finished and I can check the result in

375
00:24:27,960 --> 00:24:30,718
your application bookmark.

376
00:24:30,894 --> 00:24:34,402
In this view there are deployed list of

377
00:24:34,456 --> 00:24:38,470
created virtual machines and functions. Genome application

378
00:24:38,620 --> 00:24:42,054
requires only virtual machines. We can see

379
00:24:42,092 --> 00:24:45,974
that melodic creates one virtual machine. Thus far

380
00:24:46,092 --> 00:24:49,526
this machine is created in AWS EC

381
00:24:49,558 --> 00:24:52,666
two provider in Dublin. What is more we

382
00:24:52,688 --> 00:24:56,154
have here button for web SSH connection which

383
00:24:56,192 --> 00:24:59,594
is really useful in testing process. When I

384
00:24:59,632 --> 00:25:03,306
successfully deployed spark application by melodic,

385
00:25:03,418 --> 00:25:05,594
I can go to Grafana.

386
00:25:05,642 --> 00:25:09,322
Grafana is tool for monitoring displaying

387
00:25:09,386 --> 00:25:13,330
statistics and metrics. We can use them

388
00:25:13,400 --> 00:25:17,074
for monitoring performance of applications deployed by

389
00:25:17,112 --> 00:25:20,962
melodic. Each application has own metrics and

390
00:25:21,016 --> 00:25:24,450
own parameters to control. So we need to create

391
00:25:24,600 --> 00:25:28,006
dedicated Grafana dashboard for each of them.

392
00:25:28,108 --> 00:25:31,426
Also genome applications has own Grafana

393
00:25:31,458 --> 00:25:34,774
settings and we can see them here.

394
00:25:34,892 --> 00:25:38,762
For now metrics from our applications are

395
00:25:38,816 --> 00:25:42,394
not available yet. We can see only that

396
00:25:42,432 --> 00:25:45,702
we have now one instance so one worker.

397
00:25:45,766 --> 00:25:49,514
In the meantime we can control our application

398
00:25:49,712 --> 00:25:52,422
in Sparkmaster UI.

399
00:25:52,566 --> 00:25:56,878
Sparkmaster is built into melodic platform so

400
00:25:56,964 --> 00:26:00,430
we go to the same IP address and 81

401
00:26:00,500 --> 00:26:04,790
81 port in order to check the spark master

402
00:26:04,890 --> 00:26:08,478
UI and here we can observe

403
00:26:08,574 --> 00:26:11,742
a list of available workers.

404
00:26:11,806 --> 00:26:15,254
After refreshing of this view, of course we can see that

405
00:26:15,292 --> 00:26:18,694
now we have one worker and

406
00:26:18,812 --> 00:26:23,106
one running applications and also one driver.

407
00:26:23,218 --> 00:26:27,458
So now all tasks are sent

408
00:26:27,564 --> 00:26:31,302
to this one worker by our spark

409
00:26:31,366 --> 00:26:34,838
master. It is situation after initial deployment

410
00:26:34,934 --> 00:26:39,370
decision about creating the new ones or

411
00:26:39,440 --> 00:26:43,098
deleting. Some of workers

412
00:26:43,194 --> 00:26:46,682
are made by melodic based on measured

413
00:26:46,746 --> 00:26:50,414
metrics. In such situation new process is

414
00:26:50,452 --> 00:26:54,578
triggered and it is named reconfiguration process.

415
00:26:54,744 --> 00:26:58,210
I think that now we can go again

416
00:26:58,280 --> 00:27:02,018
to our grafana dashboard and we can see

417
00:27:02,104 --> 00:27:05,970
that metrics are using correctly calculated and

418
00:27:06,040 --> 00:27:09,506
based to the melodic because they are visible

419
00:27:09,618 --> 00:27:12,934
also in our grafana view. Color of

420
00:27:12,972 --> 00:27:16,518
limitation of traffic lights inform us

421
00:27:16,604 --> 00:27:19,834
if application will finish on time. Now we

422
00:27:19,872 --> 00:27:24,234
can see the first estimation so it can be

423
00:27:24,352 --> 00:27:27,834
not correct. I think because we

424
00:27:27,872 --> 00:27:31,978
have no enough data for a good estimation.

425
00:27:32,154 --> 00:27:35,694
So we need to wait a minute and even now

426
00:27:35,812 --> 00:27:39,262
we can see that our light is red.

427
00:27:39,396 --> 00:27:43,218
Also we can see that our time left

428
00:27:43,384 --> 00:27:46,642
is not enough to finish our

429
00:27:46,696 --> 00:27:50,030
calculation on time. Because the initial

430
00:27:50,110 --> 00:27:53,282
indicated time is indicated in camel model.

431
00:27:53,416 --> 00:27:57,410
In this case it is equal to 60 minutes. We can observe

432
00:27:57,490 --> 00:28:01,462
how many minutes left from this time period. Under this time

433
00:28:01,516 --> 00:28:06,258
left value based on current performance. It is calculated

434
00:28:06,354 --> 00:28:09,898
the estimated time left on the left.

435
00:28:09,984 --> 00:28:13,514
On the first chart we can monitor number of

436
00:28:13,552 --> 00:28:16,454
instances. So now we have one node.

437
00:28:16,502 --> 00:28:20,922
So one worker. In the bottom ones it is presented

438
00:28:20,986 --> 00:28:24,778
number of remaining simulation. This value is decreasing

439
00:28:24,874 --> 00:28:28,910
with performing next task by Spark. On the

440
00:28:28,980 --> 00:28:32,326
right on chart named number of cores,

441
00:28:32,458 --> 00:28:37,006
we can see value of minimum course needed to finish calculations

442
00:28:37,118 --> 00:28:40,430
on time and current number of cores

443
00:28:40,590 --> 00:28:43,778
under total course value. The green one

444
00:28:43,864 --> 00:28:47,662
is the value of required number of course and the yellow

445
00:28:47,726 --> 00:28:51,546
one means current number of them. Now melodic

446
00:28:51,598 --> 00:28:55,218
claims that we need at least four cores

447
00:28:55,314 --> 00:28:58,938
and even now six cores, seven cores and

448
00:28:59,024 --> 00:29:03,610
we have only one. Also estimated time

449
00:29:03,760 --> 00:29:07,498
is higher than time left. We can see

450
00:29:07,584 --> 00:29:11,422
red light. So there are signals that

451
00:29:11,476 --> 00:29:14,682
our application needs more resources.

452
00:29:14,826 --> 00:29:17,966
In such situation, melodic makes a

453
00:29:17,988 --> 00:29:21,578
decision about triggering reconfiguration

454
00:29:21,674 --> 00:29:24,722
process. So we can suppose that

455
00:29:24,776 --> 00:29:28,434
in the background reconfiguration process should

456
00:29:28,552 --> 00:29:32,066
being done in order to verify it.

457
00:29:32,248 --> 00:29:35,666
I back to our melodic UI

458
00:29:35,778 --> 00:29:39,814
and I go to process view. And here we

459
00:29:39,852 --> 00:29:43,302
can see current process and it is

460
00:29:43,356 --> 00:29:47,058
our reconfiguration process. In reconfiguration

461
00:29:47,154 --> 00:29:51,066
process, melodic doesn't fetch new offers and

462
00:29:51,168 --> 00:29:55,062
uses the same constraint problem as for initial

463
00:29:55,126 --> 00:29:59,050
deployment. For these reasons the first step

464
00:29:59,120 --> 00:30:03,022
is rezoning. As result, we can see new

465
00:30:03,076 --> 00:30:06,266
calculated solution which will be deployed.

466
00:30:06,378 --> 00:30:10,366
Now melody claims that two workers will

467
00:30:10,388 --> 00:30:13,810
be needed and this solution is

468
00:30:13,880 --> 00:30:17,874
now deployed. So in a minute we will see

469
00:30:17,992 --> 00:30:22,018
our new worker. Oh yes, even now

470
00:30:22,104 --> 00:30:25,720
our new worker should be visible because

471
00:30:26,090 --> 00:30:30,194
the reconfiguration process is finished. I can verify

472
00:30:30,322 --> 00:30:34,438
this fact also in your application part. And yes,

473
00:30:34,524 --> 00:30:38,118
now we have two virtual machines, two workers

474
00:30:38,214 --> 00:30:42,070
and this is the new one from our reconfiguration

475
00:30:42,150 --> 00:30:45,978
process. Also I can check this fact

476
00:30:46,064 --> 00:30:50,162
in our Sparkmaster UI. I need to refresh

477
00:30:50,246 --> 00:30:54,334
this view. And now two workers are available.

478
00:30:54,532 --> 00:30:58,910
We have two life workers. So now

479
00:30:58,980 --> 00:31:03,042
we can see that Sparkmaster divides tasks between

480
00:31:03,176 --> 00:31:06,990
these two workers in case of genome.

481
00:31:07,070 --> 00:31:10,238
In the first part of performing calculations,

482
00:31:10,414 --> 00:31:14,494
additional workers are created. As far as melodic

483
00:31:14,542 --> 00:31:18,102
measures that effectiveness of application is too

484
00:31:18,156 --> 00:31:22,130
low. In the final part of performance of spark jobs,

485
00:31:22,210 --> 00:31:26,210
melodic makes decision about deleting unnecessary

486
00:31:26,290 --> 00:31:30,922
instances when it is feasible that applications will

487
00:31:30,976 --> 00:31:35,478
finish on time. And now we are in our initial

488
00:31:35,574 --> 00:31:39,034
part of the whole process because we have, as I

489
00:31:39,072 --> 00:31:43,294
mentioned, we have 60 minutes to perform the

490
00:31:43,332 --> 00:31:46,734
whole process. So we are at the beginning of them

491
00:31:46,852 --> 00:31:51,550
and now additional workers are being created

492
00:31:52,050 --> 00:31:55,620
because of effectiveness of our application.

493
00:31:56,390 --> 00:32:00,546
Now I go to Grafana view. We can see

494
00:32:00,648 --> 00:32:04,318
that now we have two workers, two nodes.

495
00:32:04,494 --> 00:32:07,894
Next tasks are done and we can

496
00:32:07,932 --> 00:32:11,862
see that now our estimated time is

497
00:32:11,916 --> 00:32:15,074
cloud to time left and even now melody

498
00:32:15,122 --> 00:32:18,586
claims that it will be possible CTO finish

499
00:32:18,688 --> 00:32:22,486
the whole process on time. But now our estimated

500
00:32:22,598 --> 00:32:25,420
time is bigger again.

501
00:32:26,350 --> 00:32:29,878
So we can suppose that in a minute

502
00:32:30,054 --> 00:32:34,574
our time will be red again. Probably we

503
00:32:34,692 --> 00:32:38,446
will see the new reconfiguration process and

504
00:32:38,468 --> 00:32:42,314
the whole process is using performed to the moment

505
00:32:42,452 --> 00:32:46,482
where our estimated time will be enough for us,

506
00:32:46,616 --> 00:32:49,922
enough for our requirements. Thanks to that,

507
00:32:50,056 --> 00:32:53,426
finishing the whole process in our expected time

508
00:32:53,528 --> 00:32:57,186
will be possible, right? So we successfully observed

509
00:32:57,218 --> 00:33:00,520
the configuration process of spark application.

510
00:33:01,050 --> 00:33:05,058
This is the end of spark application deployed

511
00:33:05,234 --> 00:33:09,162
done by melodic demonstration and we can see

512
00:33:09,216 --> 00:33:12,570
that the whole optimization process is

513
00:33:12,640 --> 00:33:16,954
done fully automatically. Okay so thank

514
00:33:16,992 --> 00:33:20,410
you very much for your attention and

515
00:33:20,560 --> 00:33:23,886
this is all from my side. Okay thank you

516
00:33:23,908 --> 00:33:27,742
AlA for the presentation. Just a few words from my

517
00:33:27,796 --> 00:33:31,642
side about the melodic. Melodic is fully open source

518
00:33:31,786 --> 00:33:36,014
so you can download the melodic here. The source

519
00:33:36,062 --> 00:33:40,158
code is hosted on the OW CTO GitHub

520
00:33:40,254 --> 00:33:44,066
so you can download the code.

521
00:33:44,168 --> 00:33:47,682
It is released under the Mozilla Public License

522
00:33:47,746 --> 00:33:51,234
20 so it can be used and challenges.

523
00:33:51,362 --> 00:33:54,998
Anyhow, welcome. We are also looking for the

524
00:33:55,084 --> 00:33:58,262
volunteers developers, open source developers.

525
00:33:58,326 --> 00:34:02,134
So if you want to work on the interesting process

526
00:34:02,182 --> 00:34:06,582
then please join us. We are currently developing

527
00:34:06,646 --> 00:34:10,262
further melodic in the scope of the morphemic platform

528
00:34:10,416 --> 00:34:14,730
with new context like polymorphic adaptation

529
00:34:14,810 --> 00:34:18,318
and proactive adaptation. But I will tell more

530
00:34:18,404 --> 00:34:22,318
about that on the next session. Probably something

531
00:34:22,404 --> 00:34:26,462
in the future. One more thing, please take a look on our

532
00:34:26,516 --> 00:34:30,282
website and also visit our Twitter, LinkedIn,

533
00:34:30,346 --> 00:34:33,934
Facebook and follow us on the social media.

534
00:34:34,052 --> 00:34:38,370
Thank you very much. Thank you for the invitation to have the session

535
00:34:38,450 --> 00:34:42,070
on the cloud native. I hope you will

536
00:34:42,140 --> 00:34:45,366
find that interesting and welcome to the

537
00:34:45,388 --> 00:34:48,774
melodic and I really invite to join to

538
00:34:48,812 --> 00:34:50,820
our community. Thank you very much.

