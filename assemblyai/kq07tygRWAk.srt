1
00:00:41,730 --> 00:00:45,474
And welcome to adopting Graviton two how honeycomb reduce our infrastructure

2
00:00:45,522 --> 00:00:49,170
spend by 40% on our highest volume service I'm Shelby spees.

3
00:00:49,250 --> 00:00:52,506
I'm a developer advocate at Honeycomb, and you can find me on Twitter

4
00:00:52,538 --> 00:00:56,206
at shelbyspeace. You might be here because you're considering migrating to

5
00:00:56,228 --> 00:00:59,582
graviton two in your environment. Now. You don't want to jump into such a change

6
00:00:59,636 --> 00:01:02,926
just because it's the new shiny. You should have a measurable outcome that you're trying

7
00:01:02,948 --> 00:01:06,494
to achieve at Honeycomb. We'd originally heard about these new instance

8
00:01:06,542 --> 00:01:10,146
types during Andy Jassey's keynote at Remnt 2019. They were

9
00:01:10,168 --> 00:01:13,886
promising lower cost, better performance, and a reduced environmental impact.

10
00:01:13,998 --> 00:01:17,742
So how is graviton two different the armbased architecture is more efficient.

11
00:01:17,806 --> 00:01:21,506
It runs cheaper because more of the physical cpu did is dedicated

12
00:01:21,538 --> 00:01:25,410
to just doing compute. It also has less power consumption, plus it's faster

13
00:01:25,490 --> 00:01:29,874
because arm doesn't share execution units between threads across different virtual cpus.

14
00:01:30,002 --> 00:01:33,722
This gives you less tail latency and variability in performance. Long story

15
00:01:33,776 --> 00:01:37,878
short, we ended up making some waves as early adopters of AWS's graviton,

16
00:01:37,894 --> 00:01:41,434
two instances in production. I'm here to share with you how we went about this

17
00:01:41,472 --> 00:01:44,814
adoption, what we learned, and what you can do to make

18
00:01:44,852 --> 00:01:48,122
large migrations safe in your own systems. For Honeycomb,

19
00:01:48,186 --> 00:01:51,934
we wanted the cost and performance improvements of graviton two. Yes,

20
00:01:52,052 --> 00:01:55,562
but it would only make sense for us if we could get those things without

21
00:01:55,636 --> 00:01:59,458
hurting our reliability. So first we had to ask, is it even worth

22
00:01:59,544 --> 00:02:03,554
the risk to being able to answer that? We needed to think about

23
00:02:03,592 --> 00:02:07,466
what's important to honeycomb as a business. Honeycomb is a data storage

24
00:02:07,518 --> 00:02:10,706
engine and analytics tool. We ingest our customers'telemetry

25
00:02:10,738 --> 00:02:14,646
data, and then we enable fast querying on that data. At Honeycomb, we use

26
00:02:14,668 --> 00:02:18,178
service level objectives, which represent a common language between engineering

27
00:02:18,194 --> 00:02:21,366
and business stakeholders. We define what success means according to

28
00:02:21,388 --> 00:02:24,838
the business and then measure it with our system telemetry

29
00:02:24,934 --> 00:02:28,714
throughout the lifecycle of a customer. That's how we know how well our services are

30
00:02:28,752 --> 00:02:32,186
doing, and that's how we measure the impact of changes. Slos are

31
00:02:32,208 --> 00:02:35,626
for service behavior that has a customer impact. So at Honeycomb,

32
00:02:35,658 --> 00:02:39,470
we want to ensure things like the in app homepage should load quickly with data,

33
00:02:39,540 --> 00:02:43,070
that user run queries are returning results fast, and that

34
00:02:43,140 --> 00:02:46,642
the customer data we're trying to ingest should get stored fast

35
00:02:46,696 --> 00:02:49,838
and successfully. These are the sorts of things that our product managers

36
00:02:49,854 --> 00:02:53,554
and our customer support teams frequently talk to engineering about. So once

37
00:02:53,592 --> 00:02:57,294
we have our SLO defined that allows us to calculate our error budget.

38
00:02:57,342 --> 00:03:00,402
How many bad events are we allowed to have in our time window?

39
00:03:00,466 --> 00:03:03,846
Just like with a financial budget, the error budget gives us some wiggle room.

40
00:03:03,948 --> 00:03:07,298
Finally, we calculate how fast we're burning through that error budget.

41
00:03:07,394 --> 00:03:10,646
The steeper the burn rate, the sooner we're going to run out. So now we

42
00:03:10,668 --> 00:03:14,134
start thinking, how soon are we going to hit zero? This allows us to alert

43
00:03:14,182 --> 00:03:17,750
proactively if something is causing us to burn through our budget faster,

44
00:03:17,830 --> 00:03:20,826
so fast that we're going to run out in a matter of hours. That's when

45
00:03:20,848 --> 00:03:24,402
we should wake somebody up. And so now we're alerting on things that we've decided

46
00:03:24,486 --> 00:03:28,414
are already important to the business, and we're doing it proactively. So thanks

47
00:03:28,452 --> 00:03:31,582
to the work that we put in to measure how our services were doing,

48
00:03:31,716 --> 00:03:35,130
we started having a period of pretty stable reliability. We're a

49
00:03:35,140 --> 00:03:38,818
small startup, so once our reliability goals are met, we care a

50
00:03:38,824 --> 00:03:42,782
lot about cost. And because we're a SaaS provider, our infrastructure

51
00:03:42,846 --> 00:03:46,206
is our number two expenditure after people. So infrastructure

52
00:03:46,238 --> 00:03:50,306
is something that scales with our production traffic. And since our sales goals involve landing

53
00:03:50,338 --> 00:03:54,070
large customer accounts, we want to position ourselves to be able to support

54
00:03:54,140 --> 00:03:57,826
the traffic increase associated with landing more big accounts.

55
00:03:57,938 --> 00:04:01,506
Technical decisions are business decisions. It affects our ability to maneuver

56
00:04:01,538 --> 00:04:04,906
in the market. So, having defined our goal and having confirmed our

57
00:04:04,928 --> 00:04:08,426
ability to measure it, we needed to decide on how to proceed. How can we

58
00:04:08,448 --> 00:04:12,854
safely experiment with an entirely different processor architecture? At Honeycombs,

59
00:04:12,902 --> 00:04:16,706
we have multiple environments. We deploy the same code, the same git hash,

60
00:04:16,758 --> 00:04:20,654
and it's running across all of those environments. Our production environment is where

61
00:04:20,692 --> 00:04:23,818
customers send their data in order to observe their own systems.

62
00:04:23,914 --> 00:04:27,314
And we have a second environment called Dog Food, where we send the telemetry from

63
00:04:27,352 --> 00:04:30,802
production honeycomb. Like I said, it's not a staging environment. It runs the exact

64
00:04:30,856 --> 00:04:34,738
same code as production. Dog food, allows us to query our production data

65
00:04:34,824 --> 00:04:37,826
the way honeycomb's users interact with their production data.

66
00:04:37,928 --> 00:04:40,978
It's a great way for honeycombers to build user empathy,

67
00:04:41,074 --> 00:04:44,658
and it also allows us to test out experimental features on a safe audience.

68
00:04:44,754 --> 00:04:48,290
So we'll often enable feature flags in dog food for testing internally.

69
00:04:48,370 --> 00:04:51,598
Then we have a third environment called Kibble, and that's where we send our telemetry

70
00:04:51,634 --> 00:04:55,258
from dog food. And so for the experimental features we've enabled in dog food,

71
00:04:55,344 --> 00:04:58,682
that telemetry gets sent over to kibble. So kibble observes dog food,

72
00:04:58,736 --> 00:05:02,054
dog's food observes prod. And one thing to know about honeycombs

73
00:05:02,182 --> 00:05:05,326
on the outside. We're bee themed, but you might get the sense on the

74
00:05:05,348 --> 00:05:09,374
inside we have a lot of dogs, so we have a number of different services,

75
00:05:09,492 --> 00:05:13,054
and the biggest ones include shepherd, our ingest API service

76
00:05:13,172 --> 00:05:16,594
retriever, our columnar storing query engine, and poodle, the front end

77
00:05:16,632 --> 00:05:19,598
web application. So we really stuck to this theme.

78
00:05:19,694 --> 00:05:23,074
For graviton two, we chose to try things out on shepherd because

79
00:05:23,112 --> 00:05:26,238
it's the highest traffic, but it's also relatively straightforward,

80
00:05:26,334 --> 00:05:29,826
it's stateless, and it only scales on cpu, and as a service it's

81
00:05:29,858 --> 00:05:33,414
optimized for throughput first and then latency. So we have a place to

82
00:05:33,452 --> 00:05:37,286
start. What's next? Well, we needed new base images, we needed to

83
00:05:37,308 --> 00:05:40,566
check that our application code was compatible, and we needed to make sure that our

84
00:05:40,588 --> 00:05:44,538
existing CI would produce build artifacts for ARm 64 honeycombs a

85
00:05:44,544 --> 00:05:47,818
Go shop. So it turns out we just needed to set Arm 64 as a

86
00:05:47,824 --> 00:05:51,194
compilation target in the go compiler. And the compiler can handle that for us,

87
00:05:51,232 --> 00:05:54,774
even if it's not compiling on an arm box. And so we updated

88
00:05:54,822 --> 00:05:58,506
our Circleci config to include a build step for the Arm 64 target.

89
00:05:58,618 --> 00:06:02,030
I will say, though, you do need an arm machine to efficiently build

90
00:06:02,100 --> 00:06:05,746
arm compatible docker images. At Honeycomb, we don't use docker for

91
00:06:05,768 --> 00:06:08,750
any production workloads, just for internal branch deploys,

92
00:06:08,830 --> 00:06:12,126
so that wasn't an issue for us. For other shops, if you're

93
00:06:12,158 --> 00:06:15,774
on Java or Python, your binaries are already architecture independent.

94
00:06:15,822 --> 00:06:19,554
But for example, if you're running c with some hand assembly,

95
00:06:19,682 --> 00:06:22,818
you might need to update a few things. My teammate Liz

96
00:06:22,914 --> 00:06:26,262
initially started out all this experimenting as a side project,

97
00:06:26,396 --> 00:06:29,826
and with a few idle afternoons of work, she was already seeing compelling

98
00:06:29,858 --> 00:06:32,862
results. So at that point we set up a b testing.

99
00:06:32,946 --> 00:06:36,826
We started with one graviton instance in a shepherd autoscaling group in dog food,

100
00:06:36,928 --> 00:06:40,646
and from there we could update our terraform code to spin up more graviton instances,

101
00:06:40,758 --> 00:06:44,094
as we felt confident in each change. When we reached 20%,

102
00:06:44,212 --> 00:06:47,566
we let that sit for a couple of weeks to observe, and here's what

103
00:06:47,588 --> 00:06:50,974
we found. Our graviton instances here in the second

104
00:06:51,012 --> 00:06:55,158
row saw lower latency overall AWS, well as less tail latency. The median

105
00:06:55,194 --> 00:06:58,846
latency was more stable across different workloads, and about 10% faster

106
00:06:58,878 --> 00:07:02,706
than the old architecture. On the old architecture, cpu utilization would

107
00:07:02,728 --> 00:07:06,034
max out around 60%. On graviton we would get closer to

108
00:07:06,072 --> 00:07:09,282
85%. So we got better utilization per cpu unit

109
00:07:09,346 --> 00:07:12,802
and zooming out a bit. Here's the overall migration in dog food shepherd.

110
00:07:12,866 --> 00:07:16,374
These graphs show our total VCPU usage at the top, and then

111
00:07:16,412 --> 00:07:20,006
at the bottom, it's showing the number of dog food shepherd hosts. So you

112
00:07:20,028 --> 00:07:23,686
can see the big cutover in midaugust. And from there, we did some tuning to

113
00:07:23,708 --> 00:07:26,898
figure out that sweet spot where we're getting the best mileage out of those cpus.

114
00:07:26,994 --> 00:07:29,950
This is my favorite graph so far. This is our cost reduction in dog food

115
00:07:29,980 --> 00:07:33,214
food. So for our dog food shepherd service, we saw pretty

116
00:07:33,252 --> 00:07:36,398
compelling results. And at that point, we decided we're ready to

117
00:07:36,404 --> 00:07:40,346
roll out to production. So what happened next? We felt confident

118
00:07:40,458 --> 00:07:43,774
about shepherd, so we migrated, prod shepherd, and saw a similar cost

119
00:07:43,812 --> 00:07:47,402
reduction for retriever. We didn't care so much about reducing costs.

120
00:07:47,466 --> 00:07:51,198
What we wanted to improve was performance. We care about fast querying.

121
00:07:51,294 --> 00:07:53,986
So it turns out that we could opt to spend a little bit more to

122
00:07:54,008 --> 00:07:57,346
get double the number of cores. Since each arm 64 core is

123
00:07:57,368 --> 00:08:00,626
able to handle 50% more load than on equivalent intel

124
00:08:00,658 --> 00:08:04,006
chips, we ended up with triple the performance. So once we were

125
00:08:04,028 --> 00:08:07,650
already all in on graviton two, migrating retriever was a no brainer.

126
00:08:07,730 --> 00:08:11,754
And retriever immediately saw a significant improvement in tail latency under

127
00:08:11,792 --> 00:08:15,798
load. Those weekday bumps just totally flatten out on the P 99 graph.

128
00:08:15,894 --> 00:08:19,834
Zooming out again, our traffic volume has increased significantly over

129
00:08:19,872 --> 00:08:23,566
this past year. We're approaching triple the workloads on retriever compared to when

130
00:08:23,588 --> 00:08:26,846
we started. But look, our tail latency is staying the

131
00:08:26,868 --> 00:08:30,554
same. It's just holding steady. So that's fantastic.

132
00:08:30,682 --> 00:08:34,474
One snag we did encounter early on was spot instance availability.

133
00:08:34,602 --> 00:08:37,986
When we started scaling up in prod, we ended up using all the n

134
00:08:38,008 --> 00:08:41,198
60 D instances available in spot. So we paused

135
00:08:41,214 --> 00:08:44,386
our migration and Liz ended up reaching out to the graviton two team,

136
00:08:44,488 --> 00:08:47,950
and they were able to shift capacity for us within a few hours. So then

137
00:08:47,960 --> 00:08:51,126
we were back business. Another thing that happened is on our

138
00:08:51,148 --> 00:08:54,866
Kafka cluster. Kafka sits between shepherd and Retriever, and it allows

139
00:08:54,898 --> 00:08:58,662
us to decouple those two services and replay event streams for

140
00:08:58,716 --> 00:09:02,218
ingest. So we were actually testing Kafka on Graviton two.

141
00:09:02,304 --> 00:09:05,786
We were so early, we were testing it before even confluent had

142
00:09:05,808 --> 00:09:09,146
tried it on the new architectures, and we're probably the first to use it for

143
00:09:09,168 --> 00:09:13,162
production workloads. And we ended up changing too many variables at once. We wanted

144
00:09:13,216 --> 00:09:16,766
to move to tiered storage on confluent Kafka to reduce the number of instances we

145
00:09:16,788 --> 00:09:20,030
were running. And we also tried the architecture switch at the same time.

146
00:09:20,100 --> 00:09:23,658
Plus, we introduced AWS, nitro, and all of these variables

147
00:09:23,674 --> 00:09:27,226
at once. That was a mistake. So we've published a blog

148
00:09:27,258 --> 00:09:30,446
post on this experience, as well as a full incident report. I highly

149
00:09:30,478 --> 00:09:33,698
recommend that you go read it to better understand the decisions we made and what

150
00:09:33,704 --> 00:09:36,978
we learned. So we've reverted the Kafka change. And we also have this

151
00:09:36,984 --> 00:09:40,274
long tail of individual hosts and smaller clusters that we'd like to migrate.

152
00:09:40,322 --> 00:09:43,718
But four of our five biggest services are fully on graviton two,

153
00:09:43,804 --> 00:09:47,286
and here's what that looks like. Those services make up the vast majority of

154
00:09:47,308 --> 00:09:51,122
our traffic, and we're really thrilled with the cost savings, the performing

155
00:09:51,186 --> 00:09:54,646
improvements. Plus, it feels great to be able to say that we've reduced

156
00:09:54,678 --> 00:09:58,282
our environmental impact as well. So here are some things I hope

157
00:09:58,336 --> 00:10:01,594
that you can take with you. The most important thing to remember when

158
00:10:01,632 --> 00:10:05,390
considering a significant technology migration is to have a goal in mind,

159
00:10:05,460 --> 00:10:09,130
something that's measurable, so you know, whether or not your change was successful,

160
00:10:09,210 --> 00:10:12,474
you need to be able to compare your experiments to a baseline.

161
00:10:12,602 --> 00:10:16,174
Slos are a really great way to approach this. Another thing to keep in mind

162
00:10:16,212 --> 00:10:20,354
is that there's always hidden risks. We're lucky to have Liz's expertise and

163
00:10:20,392 --> 00:10:23,506
sense of ownership, and I think that's really important. Part of being

164
00:10:23,528 --> 00:10:27,106
an early adopter is making sure you have that expertise in house. But we still

165
00:10:27,128 --> 00:10:31,234
ran into some snags, like Amazon running out of graviton two spot instances.

166
00:10:31,362 --> 00:10:34,566
So we're lucky that we were able to make friends with the team and talk

167
00:10:34,588 --> 00:10:37,746
to them. But it does add more variables and potential silos.

168
00:10:37,858 --> 00:10:40,978
We did have a lot of luck with terraform, cloud, and circleci.

169
00:10:41,074 --> 00:10:44,538
It smoothed out a lot of the experimentation that would normally be manual clicking in

170
00:10:44,544 --> 00:10:48,074
the console, and so we could point to individual changes and figure

171
00:10:48,112 --> 00:10:51,686
out what to revert. But all of these hidden risks have a human impact.

172
00:10:51,798 --> 00:10:54,446
And in general, it's important to take care of your people.

173
00:10:54,548 --> 00:10:58,154
Incidents happened, and we're lucky that we had existing practices

174
00:10:58,202 --> 00:11:01,918
that helped a lot. We encourage people to escalate when they need a

175
00:11:01,924 --> 00:11:05,826
break, when they are starting to feel tired. We remind, or sometimes we

176
00:11:05,928 --> 00:11:09,282
guilt people into taking time off work to make up for off hours.

177
00:11:09,336 --> 00:11:13,250
Incident response. Another thing that came up recently is that

178
00:11:13,320 --> 00:11:16,962
people had to responding to incidents. Couldn't cook dinners for themselves,

179
00:11:17,016 --> 00:11:20,278
they couldn't cook meals, and they couldn't cook for their families. And so it was

180
00:11:20,364 --> 00:11:24,034
almost this no brainer thing that once somebody said it, of course people should expense

181
00:11:24,082 --> 00:11:27,362
meals when they're doing incident response for themselves and their families.

182
00:11:27,426 --> 00:11:30,758
And so we made an official policy about that. And in general, I think it's

183
00:11:30,774 --> 00:11:33,962
good to document and make official policy out of things that are often

184
00:11:34,016 --> 00:11:37,482
unspoken agreements or assumptions so that everyone on your team

185
00:11:37,536 --> 00:11:41,366
can benefit and feel very clear in those decisions.

186
00:11:41,478 --> 00:11:45,018
One of our values at honeycomb is that we hire adults, and adults

187
00:11:45,034 --> 00:11:48,366
have responsibilities outside of work. So you're not going to build a

188
00:11:48,388 --> 00:11:51,994
sustainable, healthy, sociotechnical system, a sustainable,

189
00:11:52,042 --> 00:11:55,666
healthy team, if you don't account for those responsibilities outside of

190
00:11:55,688 --> 00:11:59,518
work. Take care of your people. Finally, optimize for safety,

191
00:11:59,614 --> 00:12:03,742
ensure that people don't feel rushed, and remember that complexity

192
00:12:03,806 --> 00:12:07,610
multiplies. So whatever you can do to isolate variables, create tight

193
00:12:07,630 --> 00:12:11,366
feedback loops. And then just keep in mind that even as

194
00:12:11,388 --> 00:12:14,998
much as you do, that things are going to intersect in unexpected ways.

195
00:12:15,164 --> 00:12:19,234
Complex systems fail in really unexpected ways. And so just acknowledging

196
00:12:19,282 --> 00:12:22,202
that sometimes things are going to take longer than you would like,

197
00:12:22,256 --> 00:12:25,546
we plan to eventually migrate kafka over to the graviton two,

198
00:12:25,648 --> 00:12:28,806
but we didn't do it in the time range that we wanted to. And that's

199
00:12:28,838 --> 00:12:33,094
okay. So just keep that in mind. Another thing is that isolating variables

200
00:12:33,142 --> 00:12:36,638
makes it easier for people to update their mental models. As changes go out,

201
00:12:36,724 --> 00:12:40,366
it really helps to get everyone talking to each other. And so allowing time

202
00:12:40,388 --> 00:12:44,126
for things to simmer and encouraging people to talk about these changes can

203
00:12:44,148 --> 00:12:48,074
be really, really helpful for your overall reliability and resilience.

204
00:12:48,202 --> 00:12:51,566
If you'd like to read our graviton two posts on the Honeycomb blog, you hear

205
00:12:51,588 --> 00:12:54,558
a couple of links and we'll be posting more about it soon, and you can

206
00:12:54,564 --> 00:12:58,118
download slides at honeycomb IO slash Shelby. Also, I'd love it if

207
00:12:58,124 --> 00:13:01,046
you reached out to me on Twitter. That's all I have for today. Thank you

208
00:13:01,068 --> 00:13:01,300
so much.

