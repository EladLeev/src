1
00:00:00,410 --> 00:00:06,126
Jamaica make up real

2
00:00:06,148 --> 00:00:09,902
time feedback into the behavior of your distributed systems and

3
00:00:09,956 --> 00:00:13,374
observing changes exceptions errors in

4
00:00:13,412 --> 00:00:16,666
real time allows you to not only experiment with confidence,

5
00:00:16,778 --> 00:00:20,480
but respond instantly to get things working again.

6
00:00:24,610 --> 00:01:07,038
Cloud Mcjolo

7
00:01:07,054 --> 00:01:10,594
I'm a senior solution architect with AWS. For the past 15 years

8
00:01:10,632 --> 00:01:12,958
I've been in financial services infrastructure,

9
00:01:13,054 --> 00:01:16,878
specifically web infrastructure, authentication systems,

10
00:01:16,974 --> 00:01:20,054
distributed caching, to name a few. And for the last

11
00:01:20,092 --> 00:01:23,186
three years I've been working with cloud and infrastructure,

12
00:01:23,218 --> 00:01:27,266
AWS code and CI CD, and I fell in love with these concepts. So that's

13
00:01:27,298 --> 00:01:31,254
me. Hi everyone, my name is Jack Yu. I'm a principal senior solutions

14
00:01:31,302 --> 00:01:34,650
architect AWS. So I've been in AWS about three years

15
00:01:34,720 --> 00:01:38,838
and helping financial service customers to adopt and optimize on AWS.

16
00:01:39,014 --> 00:01:43,034
And I have a mix of software engineering background cloud infrastructure

17
00:01:43,162 --> 00:01:46,746
and help building complex distributed systems.

18
00:01:46,938 --> 00:01:50,494
And I help highly regulated financial service customers

19
00:01:50,612 --> 00:01:54,734
architect multiregions transactions workload

20
00:01:54,862 --> 00:01:58,366
and also help to build their DevOps

21
00:01:58,398 --> 00:02:00,900
pipeline and deploy those applications as well.

22
00:02:01,430 --> 00:02:04,962
So we'll talk multi multi region terraform deployments with Terraform built

23
00:02:05,016 --> 00:02:08,582
CI CD on AWS. Everything you see today is built

24
00:02:08,636 --> 00:02:12,630
using terraform and we'll talk about multiregion deployments. So Jack,

25
00:02:12,970 --> 00:02:14,950
why multi region deployments?

26
00:02:16,650 --> 00:02:20,710
So first we want to understand what is AWS regions.

27
00:02:20,870 --> 00:02:23,994
So AWS has a concept of regions, which is

28
00:02:24,032 --> 00:02:28,070
a physical locations around those workload where we cluster data centers

29
00:02:28,230 --> 00:02:31,738
and we call each group of logical data centers and availability

30
00:02:31,834 --> 00:02:35,402
zones. And AWS cloud spans 84 availability

31
00:02:35,466 --> 00:02:39,098
zones within 26 gigabyte region worldwide.

32
00:02:39,274 --> 00:02:43,022
And each availability zones has one or more discrete data centers

33
00:02:43,086 --> 00:02:46,862
and they all have redundant power, networking and connectivities

34
00:02:47,006 --> 00:02:52,002
and they all house in separate facilities for

35
00:02:52,056 --> 00:02:54,878
vast majority of the customer workloads.

36
00:02:55,054 --> 00:02:58,738
Those highly resilient multi AZ deployment

37
00:02:58,914 --> 00:03:02,246
is actually the best way for customer to host their

38
00:03:02,268 --> 00:03:06,214
applications. This is how Amazon.com

39
00:03:06,252 --> 00:03:09,974
has run and still runs today. With that

40
00:03:10,012 --> 00:03:14,550
said, let's talk about why customers looking into multi region deployments.

41
00:03:14,710 --> 00:03:17,980
And we actually have seen multiple use cases for customers.

42
00:03:18,430 --> 00:03:22,382
So first, we see customers want to actually

43
00:03:22,516 --> 00:03:26,160
get their compute resources closer to their customers,

44
00:03:26,850 --> 00:03:30,830
so their request doesn't need to traverse all the way across

45
00:03:30,900 --> 00:03:33,700
the world to get to the compute resources they need.

46
00:03:35,270 --> 00:03:38,846
This type of customers typically have a global

47
00:03:38,878 --> 00:03:42,462
expansion plan and they want to leverage multiregions deployments

48
00:03:42,526 --> 00:03:46,054
for that purpose. Second, it's really to

49
00:03:46,092 --> 00:03:48,630
support mission critical applications.

50
00:03:49,130 --> 00:03:52,882
These type of customers want to achieve

51
00:03:52,946 --> 00:03:55,190
extreme resiliency for their workload.

52
00:03:56,010 --> 00:03:59,846
And third, it's related to the business continuity

53
00:03:59,958 --> 00:04:03,322
and regulatory requirements, that is

54
00:04:03,376 --> 00:04:06,906
to actually to build multiregion architecture to

55
00:04:06,928 --> 00:04:11,174
satisfy business disaster recovery strategies and business continuity

56
00:04:11,222 --> 00:04:12,090
requirements.

57
00:04:15,790 --> 00:04:19,882
Um, so multiregions

58
00:04:19,946 --> 00:04:23,886
come with a cost, especially when it comes to infrastructure deployment.

59
00:04:24,078 --> 00:04:28,946
So first, it's actually very difficult to make

60
00:04:28,968 --> 00:04:33,006
sure that you deploy the same infrastructure across multiple

61
00:04:33,038 --> 00:04:36,674
regions. Especially hard for the customers to use AWS

62
00:04:36,722 --> 00:04:39,030
console to deploy their infrastructures,

63
00:04:40,570 --> 00:04:43,878
and customers actually figure out those already.

64
00:04:44,044 --> 00:04:47,366
They use infrastructure as code, actually is

65
00:04:47,388 --> 00:04:51,878
the way to actually manage the consistency between different stacks,

66
00:04:51,974 --> 00:04:55,974
different environment. But that's

67
00:04:56,022 --> 00:05:00,150
actually very challenging with a single region deployment.

68
00:05:00,310 --> 00:05:04,186
With the IEC, it's actually very simple. You just multiple

69
00:05:04,298 --> 00:05:08,094
modules together and you click a button to deploy it. And management is

70
00:05:08,132 --> 00:05:12,422
extremely simple. But this actually gets very complicated

71
00:05:12,506 --> 00:05:15,906
when you have multiple business units, when you

72
00:05:15,928 --> 00:05:19,918
have multiple SDLC environment and multiple region deployment.

73
00:05:20,094 --> 00:05:24,542
And finally, organizations need to think about their deployments strategy

74
00:05:24,686 --> 00:05:27,846
and how do they leverage toolings to

75
00:05:27,868 --> 00:05:30,950
actually enable their continuous delivery strategy.

76
00:05:31,290 --> 00:05:35,474
So in this talk, Lerna and I is going to give you some prescriptive

77
00:05:35,522 --> 00:05:39,290
guidance to actually manage your multi region terraform code

78
00:05:39,360 --> 00:05:42,250
and deploy this in scale. So, Lerner,

79
00:05:42,590 --> 00:05:45,450
why don't you take us through how to manage this complexity?

80
00:05:46,110 --> 00:05:49,462
Absolutely. So let's talk about the terraform

81
00:05:49,526 --> 00:05:53,006
deployment workflow. We have four simple steps in our

82
00:05:53,028 --> 00:05:56,494
deployment workflow. First, we'll talk about infrastructure AWS code and

83
00:05:56,532 --> 00:05:59,914
git tag. So here you see two pink

84
00:05:59,962 --> 00:06:03,674
boxes. These are the accounts that we're using in this solution.

85
00:06:03,802 --> 00:06:07,266
The larger box is the central tooling account. It contains all

86
00:06:07,288 --> 00:06:11,150
of the CI CD resources, as well as a git compatible repository

87
00:06:11,230 --> 00:06:14,686
in which we store our infrastructure AWS code. So that's

88
00:06:14,718 --> 00:06:18,866
our terraform code, the infrastructure sample workload that gets deployed

89
00:06:18,898 --> 00:06:22,934
into the target workload account. That's the smaller pink box. You can

90
00:06:22,972 --> 00:06:26,630
imagine the target workload account to be belonging to a business

91
00:06:26,700 --> 00:06:30,362
unit, a line of business, and it is also per

92
00:06:30,416 --> 00:06:33,994
environment. So we're imagining a research business that

93
00:06:34,032 --> 00:06:37,226
has a dev account, Qa account, staging account.

94
00:06:37,328 --> 00:06:40,502
Similarly, another business with different requirements for security

95
00:06:40,576 --> 00:06:44,874
and access, like RISC, has its own accounts. So DevOps engineers

96
00:06:44,922 --> 00:06:47,818
are working against the terraform repository,

97
00:06:47,994 --> 00:06:52,154
and they follow their branching strategy of their choice in the solution.

98
00:06:52,202 --> 00:06:55,886
We're imagining trunk based branching strategy.

99
00:06:55,998 --> 00:06:59,266
So let me walk you through the tagging and

100
00:06:59,288 --> 00:07:02,686
how it looks like. So, first of all, DevOps engineers,

101
00:07:02,718 --> 00:07:06,626
they'll be working in short lived branches. They'll be making their changes,

102
00:07:06,808 --> 00:07:10,214
and then when they're ready with the changes, they'll submit their

103
00:07:10,252 --> 00:07:14,178
changes through a merge request for a teammate to review and approve.

104
00:07:14,274 --> 00:07:17,890
And then the code gets merged into the main branch.

105
00:07:17,970 --> 00:07:21,994
In the repo and then they can tag to release from the main

106
00:07:22,032 --> 00:07:25,994
branch. The tags will follow a convention. So we're imagining that

107
00:07:26,032 --> 00:07:29,654
first of all there's an environment like dev QA staging prod

108
00:07:29,782 --> 00:07:32,986
here I'm showing you the dev tags. Next there will be a

109
00:07:33,008 --> 00:07:36,906
deployment code like a region name or global for global resources

110
00:07:36,938 --> 00:07:40,366
deployment and we'll talk about that later. And then next will

111
00:07:40,388 --> 00:07:43,726
be the team name. So this is those business unit name as well

112
00:07:43,748 --> 00:07:46,898
as a version number. The version number is important because you want to

113
00:07:46,904 --> 00:07:50,126
know at any given point the resources that are deployed

114
00:07:50,158 --> 00:07:52,980
in your account, what version they are.

115
00:07:53,590 --> 00:07:57,106
So here, as soon as DevOps engineer git tags,

116
00:07:57,138 --> 00:08:00,678
using for example this tag, dev Eu central one research

117
00:08:00,764 --> 00:08:03,986
and then a version number, our pipeline parses

118
00:08:04,018 --> 00:08:08,322
the tag and knows from the tag which target workload

119
00:08:08,386 --> 00:08:12,134
account to deploy inside the infrastructure resources

120
00:08:12,182 --> 00:08:16,006
as well as what type of resources it's deploying and what's the scope.

121
00:08:16,118 --> 00:08:19,386
So in here we're telling the pipeline that we're intending to

122
00:08:19,408 --> 00:08:22,794
deploy into research Dev account and in EU

123
00:08:22,842 --> 00:08:25,998
central one region. Next, let's take a

124
00:08:26,004 --> 00:08:29,594
look at triggering of the pipeline. So the pipeline will get triggered

125
00:08:29,642 --> 00:08:32,890
as soon as those DevOps engineer git text against the repository.

126
00:08:32,970 --> 00:08:37,634
There is one more step in between. Jack is going to go into that and

127
00:08:37,672 --> 00:08:41,346
of course this pipeline will deploy into the target account. So as

128
00:08:41,368 --> 00:08:44,946
the pipeline runs, it goes through a number of stages. Jack is

129
00:08:44,968 --> 00:08:48,214
going to go into the details of those and then at the end it's going

130
00:08:48,252 --> 00:08:52,034
to deploy those resources, terraform infrastructure resources

131
00:08:52,082 --> 00:08:56,050
into the target account. So Jack,

132
00:08:56,210 --> 00:08:58,650
what about the core infrastructure pipeline?

133
00:09:00,350 --> 00:09:04,150
So let's zoom into different pipelines stages.

134
00:09:04,310 --> 00:09:06,970
First we want to look at those resources stage.

135
00:09:08,910 --> 00:09:12,598
In the resources stage we have a versions s those buckets,

136
00:09:12,774 --> 00:09:16,290
that is a source of pipeline. So it contains

137
00:09:16,310 --> 00:09:20,314
two pieces of information. One is the terraform code that describe the target

138
00:09:20,362 --> 00:09:24,186
state infrastructure. On the right. So on the right it contains those

139
00:09:24,228 --> 00:09:27,826
vpcs, the application load balancers, you see. And those

140
00:09:27,848 --> 00:09:31,522
second piece of information is what learned talk about the git tech

141
00:09:31,576 --> 00:09:34,882
data so that it can actually be passed on

142
00:09:34,936 --> 00:09:39,286
delayed stage of pipeline so that they can influence the

143
00:09:39,308 --> 00:09:44,370
pipeline deployments, so different regions and different accounts,

144
00:09:44,530 --> 00:09:48,134
different environments and so forth. And let's take a look into how

145
00:09:48,172 --> 00:09:49,640
we capture that information.

146
00:09:51,690 --> 00:09:54,360
So the magic here is the AWS code.

147
00:09:54,910 --> 00:09:58,726
So that actually is triggered when the DevOps

148
00:09:58,758 --> 00:10:02,678
engineers tag the git

149
00:10:02,694 --> 00:10:06,446
tech repo. So that actions would trigger a

150
00:10:06,468 --> 00:10:10,718
code build, which in turn grab information from

151
00:10:10,884 --> 00:10:14,682
the code, commit repo, that's the terraform code.

152
00:10:14,756 --> 00:10:17,954
And also it would get the git tag information,

153
00:10:18,152 --> 00:10:21,506
it bundles it and it will put it into the Amazon s

154
00:10:21,528 --> 00:10:25,038
three buckets. That in turn would trigger the

155
00:10:25,064 --> 00:10:28,726
pipeline to run. And next we

156
00:10:28,748 --> 00:10:32,230
want to look it into the infrastructure as code linting stage.

157
00:10:34,010 --> 00:10:37,362
So as best practice we would want to lend the terraform

158
00:10:37,426 --> 00:10:40,818
code very early in the pipelines. In fact it's actually the first

159
00:10:40,844 --> 00:10:44,586
step in the pipelines and that actually would ensure that the code that

160
00:10:44,608 --> 00:10:48,010
we want to deploy is actually adhering to the best practices.

161
00:10:48,350 --> 00:10:51,914
In this case we are using PTF lit. It's an open

162
00:10:51,952 --> 00:10:54,810
source tool. It performs a couple of things.

163
00:10:54,960 --> 00:10:58,510
It does those static analysis of the code to find out

164
00:10:58,580 --> 00:11:02,282
possible errors, for example illegal instances

165
00:11:02,346 --> 00:11:05,642
type. It will warn about any deprecated

166
00:11:05,706 --> 00:11:09,586
synthexes, unused declarations. And actually it

167
00:11:09,608 --> 00:11:13,090
would enforce the best practices.

168
00:11:13,750 --> 00:11:17,826
If there's any validation detected, the pipeline actually stopped

169
00:11:17,858 --> 00:11:21,720
there and would notify the DevOps engineer to fix terraform code.

170
00:11:23,850 --> 00:11:27,786
So let's take a look at the next stage. So those

171
00:11:27,808 --> 00:11:31,450
next stage is a very important stage. It's an infrastructure as code security

172
00:11:31,520 --> 00:11:34,874
scan. It's actually very crucial to

173
00:11:34,912 --> 00:11:38,810
have this security scan in this early stage.

174
00:11:40,450 --> 00:11:44,426
For illustration purposes,

175
00:11:44,538 --> 00:11:48,080
we use open source tool called checked off.

176
00:11:49,010 --> 00:11:52,302
Checked off is actually open source tool that

177
00:11:52,356 --> 00:11:54,850
contains thousands of policies.

178
00:11:55,590 --> 00:11:59,154
It's ready to be used. And of course you can use

179
00:11:59,192 --> 00:12:02,530
any tools and choice for the security stand stage.

180
00:12:03,190 --> 00:12:06,694
But essentially what it does is it will scan your terraform code and would

181
00:12:06,732 --> 00:12:10,440
generate a junit XML report and

182
00:12:12,330 --> 00:12:15,766
it would give you a report so that you

183
00:12:15,788 --> 00:12:19,420
can approve or reject in the pipelines run.

184
00:12:20,590 --> 00:12:24,986
So this actually has

185
00:12:25,008 --> 00:12:29,046
a very robust security feature so that it would scan

186
00:12:29,078 --> 00:12:32,666
anything that, for example like if it's an s three bucket

187
00:12:32,698 --> 00:12:37,018
that's open to the world or any security group that has a quad serial

188
00:12:37,114 --> 00:12:42,974
that opens to worlds. So the track top would actually find

189
00:12:43,012 --> 00:12:46,674
out that vulnerability and would actually stop the pipeline to proceed any

190
00:12:46,712 --> 00:12:49,874
further. So next we

191
00:12:49,912 --> 00:12:54,210
wanted to take a look at how the terraform actually

192
00:12:54,280 --> 00:12:56,690
get deployed to a target environment.

193
00:12:59,350 --> 00:13:02,582
So you probably will guess it, it's terraform plan

194
00:13:02,636 --> 00:13:07,270
and terraform apply, right? The terraform plan actually would generate

195
00:13:08,110 --> 00:13:12,070
terraform plan file that describe

196
00:13:12,150 --> 00:13:15,814
the changes that's going to be happening on the target workload

197
00:13:15,862 --> 00:13:19,274
environment. Now the terraform plan

198
00:13:19,392 --> 00:13:23,322
would generate that and that can be reviewed

199
00:13:23,386 --> 00:13:27,790
by a DevOps lead. Once they're okay with the change then they

200
00:13:27,860 --> 00:13:31,594
can put their manual approval in their pipelines

201
00:13:31,642 --> 00:13:35,202
so that it can go on at the terraform apply

202
00:13:35,256 --> 00:13:39,090
stage where the terraform apply actually happened to make changes

203
00:13:39,160 --> 00:13:42,830
into your target workload so Lerna,

204
00:13:42,910 --> 00:13:46,326
you put a lot of thought into this architecture. Can you highlight some of

205
00:13:46,348 --> 00:13:49,974
the key considerations here? So we

206
00:13:50,012 --> 00:13:53,350
are following multi account best practice and

207
00:13:53,420 --> 00:13:56,546
we have a central tooling account. It contains the CI

208
00:13:56,578 --> 00:14:00,234
CD resources. We have a target workload account that contains the

209
00:14:00,272 --> 00:14:03,766
sample workload. So you can imagine that the central tooling

210
00:14:03,798 --> 00:14:08,278
account has the git repository, the pipelines,

211
00:14:08,374 --> 00:14:12,546
and it needs to be accessed by the DevOps engineers to trigger these deployments

212
00:14:12,598 --> 00:14:16,122
into the business unit accounts that are the target workload accounts.

213
00:14:16,186 --> 00:14:19,710
So it's pretty sensitive in terms of the resources that it contains.

214
00:14:20,050 --> 00:14:23,230
Similarly, the target workload accounts for the business units.

215
00:14:23,310 --> 00:14:26,626
For example business unit like research that is

216
00:14:26,728 --> 00:14:30,414
publishing research documents to its external

217
00:14:30,462 --> 00:14:34,466
clients, or a risk business unit that has

218
00:14:34,568 --> 00:14:38,354
internally use only data for its internal

219
00:14:38,402 --> 00:14:42,374
clients, internal company workers. So each of

220
00:14:42,412 --> 00:14:45,686
these have a different security profile and a

221
00:14:45,708 --> 00:14:49,420
different access profile, so accordingly they need

222
00:14:49,790 --> 00:14:54,570
an account of their own. Here we are following a cell architecture principle

223
00:14:55,070 --> 00:14:59,660
and the idea is that we are categorizing these different

224
00:15:00,930 --> 00:15:05,098
use cases based on the security profile access profile

225
00:15:05,194 --> 00:15:09,466
and also we are minimizing the blessed radius by containing

226
00:15:09,498 --> 00:15:12,754
these resources that belong together. The idea is

227
00:15:12,792 --> 00:15:17,380
similar to the bulkheads that are these vertical partitions that

228
00:15:18,470 --> 00:15:22,306
is used inside shipbuilding all the way back to

229
00:15:22,328 --> 00:15:26,054
twelveth century. And this idea of bulkheads is also

230
00:15:26,092 --> 00:15:29,762
used in the space, in ISS, for example International

231
00:15:29,826 --> 00:15:33,334
Space Station. So we are applying that principle of

232
00:15:33,452 --> 00:15:37,670
containing these resources, minimizing the bless radius

233
00:15:38,090 --> 00:15:39,910
in cloud deployments.

234
00:15:41,210 --> 00:15:44,586
What about multi region pipelines? So currently our pipeline is

235
00:15:44,608 --> 00:15:48,214
a single region and from those single region pipeline

236
00:15:48,262 --> 00:15:52,322
we are deploying against workload accounts and against multiple

237
00:15:52,406 --> 00:15:56,314
regions. What if we extend our pipeline and deploy our pipeline

238
00:15:56,362 --> 00:16:00,014
resources into a second region? For example, we can do this

239
00:16:00,052 --> 00:16:03,986
because we are using terraform for our pipelines deployment as well.

240
00:16:04,168 --> 00:16:08,062
And the idea here is to use the regions boundary

241
00:16:08,126 --> 00:16:11,714
as the cell and making sure that we are containing any

242
00:16:11,752 --> 00:16:14,686
issues within that boundary within the region.

243
00:16:14,798 --> 00:16:18,514
So what we will do in this case is have each region's

244
00:16:18,562 --> 00:16:22,242
pipeline be in charge of its own regions deployments.

245
00:16:22,386 --> 00:16:26,022
Meaning if there is an issue in region one, then we want

246
00:16:26,156 --> 00:16:29,834
region two through n pipelines to continue to be able

247
00:16:29,872 --> 00:16:33,494
to deploy to their respective regions.

248
00:16:33,622 --> 00:16:36,922
So this way we are containing the issue in a

249
00:16:36,976 --> 00:16:40,970
given region and we are ensuring that there is no impact

250
00:16:41,050 --> 00:16:44,574
across all of our regions. Again,

251
00:16:44,612 --> 00:16:48,362
we're using the cell architecture principle for pipelines

252
00:16:48,506 --> 00:16:52,202
per environment. We actually have pipelines per environment.

253
00:16:52,266 --> 00:16:56,194
Here we are showing the dev pipeline that is triggered with git tags that are

254
00:16:56,312 --> 00:16:59,602
prefixed with dev in the name and these dev

255
00:16:59,656 --> 00:17:03,390
pipelines are using s three buckets that are dedicated

256
00:17:03,470 --> 00:17:07,410
to the dev resources and they're targeting

257
00:17:07,490 --> 00:17:10,790
the workloads in dev environment. So again,

258
00:17:10,860 --> 00:17:14,146
cell architecture principle applied to environment. In this case, if there's

259
00:17:14,178 --> 00:17:17,474
an issue in those dev environment with the dev pipelines,

260
00:17:17,522 --> 00:17:20,362
for example, we're not going to be impacted in the higher,

261
00:17:20,416 --> 00:17:24,006
more sensitive environments like production.

262
00:17:24,198 --> 00:17:28,410
So I find it fascinating that we are using this idea of bulkhead

263
00:17:28,830 --> 00:17:32,970
twelveth century building ships in International Space Station

264
00:17:33,050 --> 00:17:36,314
and using it in cloud deployments for multiregion.

265
00:17:36,362 --> 00:17:39,806
So it's pretty fascinating, but I'm really curious about the security

266
00:17:39,908 --> 00:17:44,180
considerations for our solution. Jack, can you walk us through those?

267
00:17:45,350 --> 00:17:49,026
Yeah, sure. It's very interesting that you kind of

268
00:17:49,048 --> 00:17:53,102
make that analogy that International Space Station and the ballcat

269
00:17:53,166 --> 00:17:56,466
with the 20th century ship

270
00:17:56,498 --> 00:18:01,110
making and multiregion deployment has in common. Very fascinating.

271
00:18:02,330 --> 00:18:05,910
So let's take a look at the security aspect. Now,

272
00:18:05,980 --> 00:18:09,734
we wanted to actually integrate those security scanning

273
00:18:09,862 --> 00:18:12,490
in the very early stages in the pipeline.

274
00:18:13,230 --> 00:18:16,650
So imagine there's a developers go in

275
00:18:16,800 --> 00:18:20,262
and try to make an s three bucket

276
00:18:20,326 --> 00:18:24,054
public, right? So if that happened,

277
00:18:24,112 --> 00:18:27,786
that actually would get caught in the very early stage. Right. In the third stage

278
00:18:27,818 --> 00:18:32,266
here you see in the security scanning, it would get caught and the pipeline

279
00:18:32,298 --> 00:18:35,934
would not proceed and deploy that open s

280
00:18:35,972 --> 00:18:40,034
those bucket change into

281
00:18:40,072 --> 00:18:43,394
the target workload accounts. So if you look

282
00:18:43,432 --> 00:18:47,190
at how traditional enterprise

283
00:18:47,930 --> 00:18:51,478
software development process goes, they actually have security

284
00:18:51,564 --> 00:18:54,914
scanning stage. AWS, a very late stage of the development

285
00:18:54,962 --> 00:18:58,966
lifecycle typically is right before production deployments.

286
00:18:59,078 --> 00:19:03,402
So imagine that happened. Then they

287
00:19:03,456 --> 00:19:07,050
pretty much have to go back to the development cycle again.

288
00:19:07,200 --> 00:19:11,054
So to be able to fix that issue and then redeploy again.

289
00:19:11,092 --> 00:19:15,786
And that's highly inefficient. So with this shifting

290
00:19:15,818 --> 00:19:19,118
left approach, the iteration of the

291
00:19:19,284 --> 00:19:23,234
development lifecycle can happen much faster. So you

292
00:19:23,272 --> 00:19:26,514
provide type feedback loop back to the developers so in case

293
00:19:26,552 --> 00:19:30,830
they make any mistakes in terms of security vulnerability

294
00:19:30,990 --> 00:19:34,898
perspective. And the last security

295
00:19:34,984 --> 00:19:38,774
principles that we're looking into is to

296
00:19:38,812 --> 00:19:42,658
actually make the pipeline AWS the authority source

297
00:19:42,754 --> 00:19:47,110
for deployment. So what it means that all the changes that happens

298
00:19:47,260 --> 00:19:51,450
to those target workload should be made from the pipelines.

299
00:19:51,870 --> 00:19:55,994
So with that concept, that would actually ensure that the

300
00:19:56,112 --> 00:19:59,922
environment perspective is all consistent.

301
00:20:00,086 --> 00:20:03,854
Right. So how do we do that? So one

302
00:20:03,892 --> 00:20:07,722
way we do that is to actually prohibit developers

303
00:20:07,786 --> 00:20:11,614
actually going in into those target environment to actually make

304
00:20:11,652 --> 00:20:14,962
changes and to enable the pipelines to be able

305
00:20:15,016 --> 00:20:18,418
to make changes only there, right? So if you

306
00:20:18,424 --> 00:20:21,794
look at an implementation perspective, it's a combination of

307
00:20:21,832 --> 00:20:25,494
the IM roles and IM policies to make

308
00:20:25,532 --> 00:20:28,978
sure that in the pipeline it actually has the permissions

309
00:20:29,074 --> 00:20:33,010
to deploy to the target environment

310
00:20:33,090 --> 00:20:36,610
and it would also prohibit any individuals,

311
00:20:36,690 --> 00:20:40,694
personnel, developers to go in into the target environment

312
00:20:40,742 --> 00:20:44,970
and start making changes. So learner,

313
00:20:45,470 --> 00:20:49,146
so let's dive into the code

314
00:20:49,168 --> 00:20:50,220
deployment part.

315
00:20:52,450 --> 00:20:55,642
So we are storing our terraform state files

316
00:20:55,706 --> 00:20:59,146
in Amazon s three buckets as per Hashicorp

317
00:20:59,178 --> 00:21:03,690
best practices for AWS terraform remote state management.

318
00:21:03,850 --> 00:21:07,034
And we also use dynamodb tables

319
00:21:07,082 --> 00:21:10,434
for the terraform state locks. This is so that in case

320
00:21:10,472 --> 00:21:13,918
there is concurrent write attempts against the state files

321
00:21:14,014 --> 00:21:17,506
that these are prevented using the lux as per best practices. So that's

322
00:21:17,538 --> 00:21:21,634
pretty standard. But if you look at our buckets

323
00:21:21,682 --> 00:21:25,414
and dynamodb tables, we actually have one set of

324
00:21:25,452 --> 00:21:29,314
these per environment. Again, we are following the cell architecture

325
00:21:29,362 --> 00:21:32,662
principle, ensuring that we're isolating and minimizing

326
00:21:32,726 --> 00:21:35,610
this impact scope per environment.

327
00:21:37,790 --> 00:21:41,726
Now if you look at those s three keys for the terraform state files themselves,

328
00:21:41,828 --> 00:21:45,134
you'll see some familiar things in there.

329
00:21:45,252 --> 00:21:48,558
They are actually coming from the git tag. So I

330
00:21:48,564 --> 00:21:51,600
want to dive into this git tag example on the left.

331
00:21:52,770 --> 00:21:56,110
So a git tag that looks like dev, EU central

332
00:21:56,190 --> 00:22:00,014
one research and a version number when the DevOps

333
00:22:00,062 --> 00:22:03,954
engineer tags the repo with this, our pipeline is

334
00:22:03,992 --> 00:22:07,938
parsing the git tag. As we had mentioned, it is taking the environment,

335
00:22:08,114 --> 00:22:11,942
the team name, so that's dev and then research and

336
00:22:11,996 --> 00:22:16,166
the deployment scope EU central one in the first example there,

337
00:22:16,268 --> 00:22:20,422
and it is using it to construct the s three key for the terraform

338
00:22:20,486 --> 00:22:24,570
state file inside the Amazon s three bucket.

339
00:22:25,230 --> 00:22:28,486
And if you look at the different terraform state files,

340
00:22:28,518 --> 00:22:33,578
there are kind of multiple reasons why we are using this structure.

341
00:22:33,754 --> 00:22:37,246
And the reason is first of all, if research dev account

342
00:22:37,428 --> 00:22:41,006
has an issue in its existing regions. So let's say

343
00:22:41,108 --> 00:22:44,974
research dev currently deployed in EU central one and us east one is

344
00:22:45,012 --> 00:22:48,574
experiencing an issue in EU central one, then we

345
00:22:48,612 --> 00:22:51,842
know, and let's say that's an issue with the terraform state.

346
00:22:51,976 --> 00:22:55,870
Maybe we need to make some terraform surgery state surgery

347
00:22:56,030 --> 00:23:00,102
in EU central one for research Dev. We know that we will not

348
00:23:00,156 --> 00:23:04,006
have any impact to the existing deployments of

349
00:23:04,028 --> 00:23:07,414
research dev in any other region like research dev, us east one

350
00:23:07,452 --> 00:23:11,174
is not going to be impacted because that's in a completely different terraform

351
00:23:11,222 --> 00:23:15,034
state file. Now similarly, if we want to expand research dev

352
00:23:15,072 --> 00:23:18,742
account to additional regions, we know that our provision

353
00:23:18,806 --> 00:23:22,346
deployments in existing regions like EU Central one and US east

354
00:23:22,378 --> 00:23:26,474
one won't be impacted because the terraform state file

355
00:23:26,522 --> 00:23:30,640
for the additional region will be in a completely different

356
00:23:31,170 --> 00:23:34,582
place. So research Dev, ap southeast one terraform

357
00:23:34,666 --> 00:23:36,180
TF state for example.

358
00:23:38,310 --> 00:23:41,534
Next, let's take a look at a pipeline demo and terraform

359
00:23:41,582 --> 00:23:43,170
code structure walkthrough.

360
00:23:45,050 --> 00:23:49,042
Let's take a look at the terraform code structure for our sample

361
00:23:49,186 --> 00:23:52,422
infrastructure code. So first we have

362
00:23:52,476 --> 00:23:56,422
our account considerations that is available under

363
00:23:56,556 --> 00:24:00,134
the environments folder. We have the different environments

364
00:24:00,182 --> 00:24:03,626
that we use that we configured, and under it

365
00:24:03,648 --> 00:24:07,370
we have those team names, these map to the business

366
00:24:07,440 --> 00:24:10,550
units, and inside of it we have variable cfrs.

367
00:24:10,630 --> 00:24:14,206
This is where we are passing the account number to the

368
00:24:14,228 --> 00:24:18,334
pipeline. So remember that the Git tag has information about

369
00:24:18,372 --> 00:24:21,806
the environment name like Dev and the team name research.

370
00:24:21,988 --> 00:24:26,114
So the pipeline parses the git tag and is able to get

371
00:24:26,152 --> 00:24:28,930
the value of the account number to target.

372
00:24:29,830 --> 00:24:33,022
Next, let's take a look at the provider configuration.

373
00:24:33,086 --> 00:24:35,990
So our provider is parameterized by region.

374
00:24:36,410 --> 00:24:39,554
And as you remember that inside the git tag

375
00:24:39,602 --> 00:24:42,934
we also talk about deployment scope. So that is

376
00:24:42,972 --> 00:24:46,178
used as the region by the provider

377
00:24:46,274 --> 00:24:49,962
to target. The provider will also assume an

378
00:24:50,016 --> 00:24:53,882
IAM role inside the target workload account. So here you're seeing

379
00:24:53,936 --> 00:24:56,934
that when the target workload account is created,

380
00:24:56,982 --> 00:25:00,662
initially this role also should be provision

381
00:25:00,726 --> 00:25:04,222
inside the account. And here you also see the account number.

382
00:25:04,276 --> 00:25:07,870
We just talked about how we feed that into the pipelines.

383
00:25:08,210 --> 00:25:12,694
Next, in main TF, we have created two terraform

384
00:25:12,762 --> 00:25:16,798
namespaces. This is helping us to ensure consistency

385
00:25:16,894 --> 00:25:20,130
of what's deployed inside each region.

386
00:25:20,870 --> 00:25:24,766
Remember that regional resources are scoped

387
00:25:24,798 --> 00:25:28,358
at the account and region level, and global resources are scoped at

388
00:25:28,364 --> 00:25:32,390
the account level. So global resources are managed

389
00:25:33,450 --> 00:25:37,074
for the whole account and regional resources are managed

390
00:25:37,202 --> 00:25:40,794
per account and region. Therefore we

391
00:25:40,832 --> 00:25:44,266
have created different terraform namespaces and in

392
00:25:44,288 --> 00:25:48,166
the pipeline we will target these namespaces depending

393
00:25:48,198 --> 00:25:51,942
on the tag. So in the tag

394
00:25:52,006 --> 00:25:56,046
we have the deployment scope if it's a global deployment, and for

395
00:25:56,068 --> 00:25:59,658
example dev underscore global, that's the prefix.

396
00:25:59,754 --> 00:26:03,786
If it's a regional deployment, then it's dev underscore and then a region name.

397
00:26:03,908 --> 00:26:07,662
So depending on the tag then we will use either module global

398
00:26:07,726 --> 00:26:11,454
resources to be deployed or module regional

399
00:26:11,502 --> 00:26:15,194
resources to be deployments. And these are mapping to the folders

400
00:26:15,342 --> 00:26:18,530
inside our repository.

401
00:26:18,690 --> 00:26:22,690
Inside these folders we have for example under global for our sample

402
00:26:22,770 --> 00:26:26,514
infrastructure workload we have IAM role, and under regional

403
00:26:26,562 --> 00:26:30,486
we have VPC, which is we're using versioned

404
00:26:30,518 --> 00:26:34,406
terraform modules. So we try to reuse as much of the existing

405
00:26:34,518 --> 00:26:38,506
well tested code as possible and also all

406
00:26:38,528 --> 00:26:42,042
the way up to an application load balancer that's external facing.

407
00:26:42,106 --> 00:26:45,674
So that's our sample workload. And this concludes

408
00:26:45,722 --> 00:26:48,922
the code structure walkthrough for our sample

409
00:26:48,986 --> 00:26:51,070
infrastructure workload in terraform.

410
00:26:51,890 --> 00:26:55,714
All right, so let's take a look at the resources in our

411
00:26:55,752 --> 00:26:59,326
accounts. So on the left hand side you are seeing our central tooling

412
00:26:59,358 --> 00:27:03,694
account and I am logged in as cloud apps. So I have list privilege

413
00:27:03,742 --> 00:27:07,542
permissions for cloud apps to be able to

414
00:27:07,676 --> 00:27:11,186
access the CI CD resources. On the right hand side you're

415
00:27:11,218 --> 00:27:15,078
seeing the workload account, the target workload account,

416
00:27:15,244 --> 00:27:19,066
and here on the right hand side, in the purple, like in

417
00:27:19,088 --> 00:27:22,762
the other browser, I have read

418
00:27:22,816 --> 00:27:26,186
only access. Okay, so let's first start with

419
00:27:26,208 --> 00:27:30,114
the central tooling account. Here you're seeing the code repository.

420
00:27:30,262 --> 00:27:33,354
This is a terraform infrastructure sample

421
00:27:33,402 --> 00:27:36,846
workload repository with the one that we just did the

422
00:27:36,868 --> 00:27:40,922
code walkthrough. So you can see the project here with the environments

423
00:27:40,986 --> 00:27:44,494
configuration and all of the folders that we discussed

424
00:27:44,542 --> 00:27:48,846
earlier. And if you look at those git tags,

425
00:27:48,878 --> 00:27:52,990
you will see all the previous Git teams that triggered pipelines

426
00:27:53,070 --> 00:27:56,930
for deployments. I have triggered

427
00:27:57,090 --> 00:28:00,278
this dev global research two six

428
00:28:00,364 --> 00:28:04,038
and also dev EU central one research two six

429
00:28:04,204 --> 00:28:07,966
for an EU central one, deployment of regional resources

430
00:28:08,018 --> 00:28:11,286
for that one. And the previous one is global resource

431
00:28:11,318 --> 00:28:14,730
deployment. And if we

432
00:28:14,800 --> 00:28:18,518
look inside the build projects,

433
00:28:18,614 --> 00:28:22,318
what we will see is that we have a number of

434
00:28:22,404 --> 00:28:26,638
build projects defined. And these are also,

435
00:28:26,804 --> 00:28:31,002
some of these are the ones that we will use inside the pipeline stage

436
00:28:31,066 --> 00:28:34,162
actions. So the ones at the bottom here,

437
00:28:34,296 --> 00:28:37,998
for example the TF lint for the linting

438
00:28:38,094 --> 00:28:41,534
of terraform code checkoff for security scanning

439
00:28:41,662 --> 00:28:45,430
the terraform plan and apply are the ones that we will use inside

440
00:28:45,500 --> 00:28:49,702
the pipeline. And also the ones

441
00:28:49,756 --> 00:28:53,190
on top are the ones that we use per environment.

442
00:28:54,090 --> 00:28:57,586
When you git tag as DevOps engineer on the

443
00:28:57,628 --> 00:29:01,654
repo, what these projects

444
00:29:01,702 --> 00:29:05,382
do is that they'll take the git tag and a full git clone

445
00:29:05,446 --> 00:29:09,770
of the repository and push that terraform artifact

446
00:29:10,290 --> 00:29:14,042
into an SG bucket

447
00:29:14,106 --> 00:29:18,510
that is versioned and it's a separate SG bucket per environment.

448
00:29:19,010 --> 00:29:22,346
So then that SG bucket becomes those source

449
00:29:22,378 --> 00:29:26,226
stage of the pipeline. So let's take a look at the pipeline itself and how

450
00:29:26,248 --> 00:29:30,478
it looks. So I've been working on the dev pipeline.

451
00:29:30,574 --> 00:29:34,286
That's why you're seeing this one used and the other ones I haven't

452
00:29:34,318 --> 00:29:37,830
been touching. So we'll look inside the dev pipeline

453
00:29:38,730 --> 00:29:41,666
and if you look there, you will see that there is a source stage.

454
00:29:41,698 --> 00:29:45,474
So this is the stage that we just mentioned with s three versioned

455
00:29:45,522 --> 00:29:48,858
bucket. And every time

456
00:29:48,944 --> 00:29:52,662
there is a data change in the SG

457
00:29:52,726 --> 00:29:57,818
version bucket that contains the terraform infrastructure code

458
00:29:57,904 --> 00:30:01,520
for our sample workload, as well as the git tag that

459
00:30:01,970 --> 00:30:05,326
the DevOps engineer just created. Every time

460
00:30:05,348 --> 00:30:09,150
there's a data event, this pipeline gets triggered.

461
00:30:10,130 --> 00:30:13,710
The next stage there will be a Tf lint of the terraform

462
00:30:13,790 --> 00:30:17,634
code. So let's take a look at the output of that. In our

463
00:30:17,672 --> 00:30:21,490
case, the tflint ran and it was successful.

464
00:30:23,910 --> 00:30:27,154
In the next stage we have the Chekhov

465
00:30:27,282 --> 00:30:31,142
security scanning of our terraform code and this

466
00:30:31,196 --> 00:30:35,522
stage runs generates a junit XML

467
00:30:35,586 --> 00:30:39,606
report of Chekhov's security successful

468
00:30:39,798 --> 00:30:44,394
rules and also the failures in

469
00:30:44,432 --> 00:30:49,206
our terraform code. And that report will be presented

470
00:30:49,318 --> 00:30:53,566
in a manual approval action to the

471
00:30:53,588 --> 00:30:57,326
person reviewing the report and deciding whether or

472
00:30:57,348 --> 00:31:01,022
not it's okay to move

473
00:31:01,076 --> 00:31:05,026
forward with the check of output or we

474
00:31:05,048 --> 00:31:08,750
should reject because we saw some security scan failures

475
00:31:08,830 --> 00:31:12,020
that we decided that we need to fix.

476
00:31:12,470 --> 00:31:15,974
So here you're seeing the check of output. Here on top is the

477
00:31:16,012 --> 00:31:19,334
actual output in the logs, but it also

478
00:31:19,372 --> 00:31:22,582
generates a junit XML file that we can view

479
00:31:22,716 --> 00:31:26,502
in the dashboard after

480
00:31:26,556 --> 00:31:29,814
this step. The next step is those terraform build stage.

481
00:31:29,942 --> 00:31:34,362
Inside the build stage we have a terraform plan action that

482
00:31:34,416 --> 00:31:38,314
generates the plan. So here we

483
00:31:38,352 --> 00:31:41,774
see that plan generated in the

484
00:31:41,812 --> 00:31:45,440
output of that job.

485
00:31:46,610 --> 00:31:50,234
And then if we look at the stage

486
00:31:50,282 --> 00:31:54,194
itself, we'll see a manual approval action that will

487
00:31:54,232 --> 00:31:58,542
present the terraform plan to the reviewer

488
00:31:58,686 --> 00:32:02,098
and the reviewer can check the plan and ensure that it

489
00:32:02,184 --> 00:32:06,402
performs all the changes as intended as per our terraform

490
00:32:06,466 --> 00:32:10,290
code. And if they're satisfied with the terraform plan, then they'll approve

491
00:32:10,370 --> 00:32:13,734
or they can reject it. If they see something funny in there,

492
00:32:13,852 --> 00:32:17,598
they'll reject it. Now, yesterday I approved

493
00:32:17,634 --> 00:32:21,354
this terraform plan and it went into terraform apply.

494
00:32:21,552 --> 00:32:25,130
Now if you look at the apply output, it's just a typical

495
00:32:26,110 --> 00:32:30,650
terraform apply. As you can see, we are applying

496
00:32:32,130 --> 00:32:35,422
what was in our terraform plan. In this case,

497
00:32:35,476 --> 00:32:39,578
I was deploying these resources into the EU central one region

498
00:32:39,754 --> 00:32:43,482
and this terraform plan completed

499
00:32:43,546 --> 00:32:47,134
successfully. The apply completed successfully.

500
00:32:47,182 --> 00:32:49,794
As you can see here, it's all green and on the right hand side,

501
00:32:49,832 --> 00:32:53,074
as you see in this region, EU central one,

502
00:32:53,192 --> 00:32:56,722
I have the resources deployments and those load balancer

503
00:32:56,866 --> 00:33:00,422
and my load balancer in there, it's working as well.

504
00:33:00,476 --> 00:33:03,942
So here you can see that I am able

505
00:33:03,996 --> 00:33:08,138
to see the output from my load balancer and

506
00:33:08,224 --> 00:33:12,010
that concludes those pipelines

507
00:33:12,510 --> 00:33:13,690
walkthrough.

508
00:33:16,660 --> 00:33:20,400
Thank you very much lauren for taking us through the demo and

509
00:33:20,470 --> 00:33:23,220
code structures. That's really helpful.

510
00:33:23,960 --> 00:33:27,830
So let's summarize what we learned about in this talk.

511
00:33:29,560 --> 00:33:32,996
So if you have one slide to take away from this talk,

512
00:33:33,098 --> 00:33:36,708
that particular slide. So it actually summarized

513
00:33:36,804 --> 00:33:41,000
what we learned so far. So you have a DevOps engineer

514
00:33:41,420 --> 00:33:45,032
to commit the telegram code and tagging a code that

515
00:33:45,086 --> 00:33:49,212
would in turn trigger the pipelines through the code

516
00:33:49,266 --> 00:33:53,068
build. And also this pretty much

517
00:33:53,154 --> 00:33:57,308
pipeline described different stages that we spoke about

518
00:33:57,474 --> 00:34:01,132
and have the pipeline actually deploy the terraform

519
00:34:01,196 --> 00:34:05,536
artifacts under target workload accounts. So it

520
00:34:05,638 --> 00:34:09,344
also illustrated the concept of the multi account structure that we learned about

521
00:34:09,462 --> 00:34:13,620
and having different pipeline per environments and

522
00:34:13,690 --> 00:34:17,712
having different accounts for different workflow deployments

523
00:34:17,776 --> 00:34:21,364
as well. So I think the best thing

524
00:34:21,402 --> 00:34:25,064
is that we build every single component here

525
00:34:25,102 --> 00:34:28,856
using terraform, which is really cool. So Lerna, what are

526
00:34:28,878 --> 00:34:30,360
some of the key takeaways?

527
00:34:31,980 --> 00:34:35,992
Absolutely. So the most important takeaway about

528
00:34:36,046 --> 00:34:39,724
multi region deployments is that we should be

529
00:34:39,842 --> 00:34:42,392
making sure that we are consistent with our deployments.

530
00:34:42,456 --> 00:34:46,476
So it helps if you're leveraging the pipeline as

531
00:34:46,498 --> 00:34:49,020
our single source of truth for the deployments.

532
00:34:49,760 --> 00:34:53,384
It helps to structure our infrastructure as code and architect

533
00:34:53,432 --> 00:34:56,844
our pipelines such that we maximize code reuse, such that

534
00:34:56,882 --> 00:35:00,992
we can be consistent in the resources that we deploy into those accounts.

535
00:35:01,176 --> 00:35:04,704
And also it's important to shift security left in our pipeline

536
00:35:04,752 --> 00:35:08,084
such that we can catch those security issues early on

537
00:35:08,202 --> 00:35:10,630
in the SDLC, as Jack mentioned.

538
00:35:11,400 --> 00:35:15,056
Thanks for joining us. Thank you for joining

539
00:35:15,088 --> 00:35:15,170
us.

