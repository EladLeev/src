1
00:00:27,330 --> 00:00:31,030
Good day everyone. Welcome to my talk on who broke the bell

2
00:00:31,610 --> 00:00:35,430
using Kuttl to improve end to end testing and release faster.

3
00:00:36,410 --> 00:00:39,698
No one wants to be responsible for breaking the bell,

4
00:00:39,794 --> 00:00:43,046
but what can you as a developer to avoid being the

5
00:00:43,068 --> 00:00:46,546
bad guy? How can project leads enable their teams

6
00:00:46,578 --> 00:00:49,590
to reduce the occurrence of broken bells?

7
00:00:50,050 --> 00:00:53,886
Have you ever seen such kind of scenario in your company where

8
00:00:54,068 --> 00:00:57,760
manager asks who has actually broken the build?

9
00:00:58,130 --> 00:01:01,934
He's little furious but

10
00:01:01,972 --> 00:01:06,194
the developer would say that I don't know who has actually broken the build but

11
00:01:06,392 --> 00:01:10,674
I will find out. I'm not sure if I

12
00:01:10,712 --> 00:01:14,402
could have myself broken the build or let me check

13
00:01:14,456 --> 00:01:17,734
with the team and come back. Okay. A quick

14
00:01:17,772 --> 00:01:22,034
introduction about myself I'm Ram Mohan Rao Chuka, senior software

15
00:01:22,082 --> 00:01:26,466
engineer R D India Bangalore. I'm passionate

16
00:01:26,498 --> 00:01:30,534
about open source. I love playing table

17
00:01:30,582 --> 00:01:34,730
tennis. I can be reachable on both

18
00:01:34,800 --> 00:01:38,682
LinkedIn or on Twitter or newly called

19
00:01:38,736 --> 00:01:42,446
x at ichuka ichuka. Let me

20
00:01:42,468 --> 00:01:45,774
create a quick introduction of my company so that

21
00:01:45,812 --> 00:01:49,370
you would understand the scenario

22
00:01:49,450 --> 00:01:53,486
much better. JFrog was founded

23
00:01:53,518 --> 00:01:57,070
in 2008. It's a publicly

24
00:01:57,150 --> 00:02:00,974
listed company, around 1100 plus employees

25
00:02:01,022 --> 00:02:05,066
and growing. And in nine locations headquartered

26
00:02:05,118 --> 00:02:09,046
in Netanya, we have around eight 7000

27
00:02:09,148 --> 00:02:12,486
plus nearly 8000 customers. And most

28
00:02:12,508 --> 00:02:16,040
of these customers are fortune hundred companies

29
00:02:16,570 --> 00:02:19,546
and out of those fortune hundred companies,

30
00:02:19,648 --> 00:02:24,090
70% of them are our customers. We have around 62

31
00:02:24,160 --> 00:02:27,786
expanding products. Almost all

32
00:02:27,808 --> 00:02:31,022
the products are hybrid and we have a

33
00:02:31,076 --> 00:02:35,450
universal DevOps platform and more importantly

34
00:02:35,530 --> 00:02:40,080
we contribute to the community. So does

35
00:02:40,770 --> 00:02:44,226
software upgrades matter? In the

36
00:02:44,248 --> 00:02:48,318
current world, software is run on everywhere.

37
00:02:48,494 --> 00:02:52,222
It is used in healthcare, politics, social interaction,

38
00:02:52,286 --> 00:02:56,662
like Twitter or any other food and

39
00:02:56,716 --> 00:02:58,600
water, transportation and energy.

40
00:02:59,850 --> 00:03:03,302
Do really software updates really matter?

41
00:03:03,436 --> 00:03:07,506
Yes. Every company is a software company and

42
00:03:07,548 --> 00:03:11,242
the quality of the software part of your company

43
00:03:11,296 --> 00:03:13,850
or the product is giving you a differentiator.

44
00:03:14,750 --> 00:03:18,614
So let's take a quick example how software

45
00:03:18,662 --> 00:03:23,534
upgrades actually really matter. So you can think of you

46
00:03:23,572 --> 00:03:27,774
have a Tesla model and you would like to do

47
00:03:27,812 --> 00:03:31,642
an upgrade. It clearly says in the instructions

48
00:03:31,706 --> 00:03:35,534
saying that when you do an upgrade, during the upgrade

49
00:03:35,582 --> 00:03:38,210
you will not be able to drive your vehicle.

50
00:03:38,550 --> 00:03:42,674
So you would be actually struck not

51
00:03:42,712 --> 00:03:45,300
driving a vehicle when a software upgrade is happening.

52
00:03:46,010 --> 00:03:49,362
So to summarize that JFrog mission

53
00:03:49,426 --> 00:03:52,440
is to power all the software upgrades in the world.

54
00:03:53,210 --> 00:03:56,806
JFrog mission and the goal has always been to help customers

55
00:03:56,908 --> 00:04:00,874
deliver upgrades faster, quicker so

56
00:04:00,912 --> 00:04:02,860
that to move the speed of the business.

57
00:04:03,790 --> 00:04:07,530
So we have large

58
00:04:07,600 --> 00:04:11,114
number of enterprises using our software

59
00:04:11,242 --> 00:04:14,686
primarily into Internet and software technology

60
00:04:14,788 --> 00:04:18,718
companies like LinkedIn, banking and finance and

61
00:04:18,804 --> 00:04:22,522
you name it, we have it and we actually

62
00:04:22,596 --> 00:04:26,002
work with the open source cloud

63
00:04:26,056 --> 00:04:29,362
vendors as well as AWS, Azure Global Cloud,

64
00:04:29,416 --> 00:04:32,660
IBM Cloud and all the logos that you see.

65
00:04:33,270 --> 00:04:37,240
So let us switch back to the context of my talk.

66
00:04:37,850 --> 00:04:41,714
So lastly, around a decade

67
00:04:41,762 --> 00:04:45,714
back, people used to follow a waterfall

68
00:04:45,762 --> 00:04:49,846
model where they used to have the requirements freezed,

69
00:04:50,038 --> 00:04:54,490
then go with an architecture and a design, then a development

70
00:04:54,910 --> 00:04:58,406
post that, a QA and a release, and post production

71
00:04:58,438 --> 00:05:02,142
and maintenance, which would almost take a year

72
00:05:02,276 --> 00:05:05,626
or two to complete the entire features released

73
00:05:05,658 --> 00:05:09,662
to the customers. Then we had something

74
00:05:09,716 --> 00:05:13,026
like an agile model where you do the

75
00:05:13,048 --> 00:05:17,234
design requirements and probably do

76
00:05:17,272 --> 00:05:21,138
a rollout to production within

77
00:05:21,224 --> 00:05:24,974
a couple of weeks or so. And there was a new

78
00:05:25,032 --> 00:05:28,470
model that evolved. It's more like dev and

79
00:05:28,540 --> 00:05:32,054
operations collaborated with each other to

80
00:05:32,092 --> 00:05:35,800
release faster. It's more like an agile way fast forward

81
00:05:36,330 --> 00:05:39,546
where if needed, releases can be

82
00:05:39,568 --> 00:05:42,620
done multiple times in a day.

83
00:05:43,310 --> 00:05:47,222
So DevOps actually means it's a collaboration

84
00:05:47,286 --> 00:05:51,454
between both devs and operation, working in silos to

85
00:05:51,492 --> 00:05:55,166
give a desired output for the customers

86
00:05:55,268 --> 00:06:00,954
to release much stable

87
00:06:01,002 --> 00:06:04,610
updates to the product or the software upgrades,

88
00:06:05,430 --> 00:06:09,614
which would mean we have actually moved from a waterfall

89
00:06:09,662 --> 00:06:13,490
model from can yearly or a monthly release to a

90
00:06:13,640 --> 00:06:16,070
daily release cycle in DevOps.

91
00:06:16,650 --> 00:06:19,960
Let's start with the agenda of my talk,

92
00:06:21,050 --> 00:06:24,950
just an overview of what I would cover in this session.

93
00:06:26,250 --> 00:06:30,138
I would first start with what an ideal development environment would

94
00:06:30,224 --> 00:06:34,806
look like, and this is more to do with developer productivity.

95
00:06:34,998 --> 00:06:38,966
In this session I will cover a quick history of our testing

96
00:06:38,998 --> 00:06:42,894
challenges and what led us to KutTl and

97
00:06:42,932 --> 00:06:46,414
the benefits of our new testing approach, which is easy to

98
00:06:46,452 --> 00:06:48,750
configure and a minimal investment,

99
00:06:49,570 --> 00:06:53,754
and how we combine KutTl and CI pipelines

100
00:06:53,802 --> 00:06:56,830
for a more streamlined and few broken belts.

101
00:06:57,350 --> 00:07:01,662
So we were evaluating a couple of tools.

102
00:07:01,806 --> 00:07:05,782
How can we leverage probably local testing on our

103
00:07:05,916 --> 00:07:09,286
dev environments where developers don't need

104
00:07:09,308 --> 00:07:13,640
to actually look up for a remote CI CD to run their test.

105
00:07:14,170 --> 00:07:17,866
So let's walk through each one

106
00:07:17,888 --> 00:07:21,434
of them and see how

107
00:07:21,472 --> 00:07:24,650
our testing challenges and what led us to cuddle.

108
00:07:25,390 --> 00:07:29,462
Just an overview of how a development ideal development environment

109
00:07:29,526 --> 00:07:32,960
would look like. It's more like a single

110
00:07:33,970 --> 00:07:37,178
click setup where everything is automated,

111
00:07:37,354 --> 00:07:40,894
you develop and test locally, and more

112
00:07:40,932 --> 00:07:45,106
importantly it's same as production environment which

113
00:07:45,128 --> 00:07:49,118
is to reproduce the production issues on local environments

114
00:07:49,214 --> 00:07:52,846
to release. If you can debug the issues, you can release

115
00:07:52,878 --> 00:07:55,330
faster, fix it and release faster.

116
00:07:55,770 --> 00:07:58,566
So say for example,

117
00:07:58,748 --> 00:08:03,446
a developer joins a new team as

118
00:08:03,468 --> 00:08:06,962
part of his onboarding process. He would be given a manual

119
00:08:07,026 --> 00:08:10,120
steps to look up to a wiki page,

120
00:08:10,810 --> 00:08:14,986
do all the installations based on the setup, which would actually take

121
00:08:15,168 --> 00:08:18,426
probably a couple of days to set up his environment or

122
00:08:18,448 --> 00:08:22,526
a day or two to set up his environment. But using automation you

123
00:08:22,548 --> 00:08:27,594
can actually have some scripts written or some modules

124
00:08:27,642 --> 00:08:31,582
that you can just run it so that the development environment is set up

125
00:08:31,636 --> 00:08:35,730
within minutes, which would mean instead

126
00:08:35,800 --> 00:08:39,938
of taking hours or days, you can actually set up the environment using

127
00:08:40,024 --> 00:08:41,860
some automation within minutes.

128
00:08:43,110 --> 00:08:47,074
Which also means no manual steps, implies error

129
00:08:47,122 --> 00:08:50,262
free and also more importantly quick

130
00:08:50,316 --> 00:08:54,162
reload. When you can actually develop everything locally,

131
00:08:54,306 --> 00:08:57,390
you can actually deploy test it locally,

132
00:08:57,570 --> 00:09:01,290
so the reload cycle is much faster.

133
00:09:01,710 --> 00:09:05,434
And as I previously said, dev environment should be as same

134
00:09:05,472 --> 00:09:09,114
as production environment. This helps to save

135
00:09:09,152 --> 00:09:12,990
us time and to reproduce production issues at ease.

136
00:09:13,490 --> 00:09:17,294
Okay, let's come to the main

137
00:09:17,492 --> 00:09:20,640
problem that most of our developers face.

138
00:09:21,330 --> 00:09:24,754
So when you take a feature, branch development developer works

139
00:09:24,792 --> 00:09:25,730
on a feature,

140
00:09:28,070 --> 00:09:31,422
he writes some unit test based on the feature developed,

141
00:09:31,566 --> 00:09:35,022
then writes some teams which may be unit teams,

142
00:09:35,166 --> 00:09:38,494
and then commits and pushes

143
00:09:38,542 --> 00:09:40,610
to a git remote repository.

144
00:09:41,510 --> 00:09:45,206
Ideally in most of the scenarios, what we

145
00:09:45,228 --> 00:09:49,034
have seen is these end to end tests are very difficult to

146
00:09:49,072 --> 00:09:52,794
set up and most of the developers don't write end

147
00:09:52,832 --> 00:09:56,458
to end teams and these teams are actually executed on

148
00:09:56,464 --> 00:10:00,314
a remote CI series server. So the problem that when

149
00:10:00,352 --> 00:10:03,530
a pull request is raised or a merge request is raised,

150
00:10:04,430 --> 00:10:07,694
since these end to end tests are executed in a

151
00:10:07,732 --> 00:10:11,246
remote CI server, say for example when

152
00:10:11,268 --> 00:10:15,186
I raise a PR test run for a couple of hours, maybe more

153
00:10:15,208 --> 00:10:19,554
than that, then if a test fails I

154
00:10:19,592 --> 00:10:23,138
need to come back and understand the logs on

155
00:10:23,144 --> 00:10:26,470
the remote CI CD server to look up what has failed.

156
00:10:27,050 --> 00:10:30,406
Then if I identify the issue, then I would be able

157
00:10:30,428 --> 00:10:33,906
to fix it and commit a joint. So this round trip

158
00:10:33,938 --> 00:10:37,298
of fixing an issue is

159
00:10:37,404 --> 00:10:40,714
huge. So instead of is there any better

160
00:10:40,752 --> 00:10:44,458
way to actually avoid running these

161
00:10:44,544 --> 00:10:48,154
end to end teams on a remote server? So we

162
00:10:48,192 --> 00:10:52,046
had an idea how these end

163
00:10:52,068 --> 00:10:54,730
to end tests can be leveraged on a local environment.

164
00:10:54,890 --> 00:10:59,742
So let me quickly go walk

165
00:10:59,796 --> 00:11:04,378
through the remote end to end test with a pictorial depiction.

166
00:11:04,474 --> 00:11:08,130
So when a developer writes code, he writes the unit test. If something

167
00:11:08,200 --> 00:11:11,426
passes, then he would raise us a pull request or

168
00:11:11,448 --> 00:11:14,734
a merger request on a remote CI CD server.

169
00:11:14,782 --> 00:11:18,482
The test run, if it failed, the round cycle

170
00:11:18,546 --> 00:11:22,246
actually continues until a merge request. After a

171
00:11:22,268 --> 00:11:25,990
successful end to end test run with the code review,

172
00:11:26,060 --> 00:11:29,306
you would be able to do a merge. But is there

173
00:11:29,328 --> 00:11:33,194
any alternative for this problem that most

174
00:11:33,232 --> 00:11:37,878
developers face not running end to end test locally?

175
00:11:38,054 --> 00:11:41,498
So we had an idea, how can we leverage

176
00:11:41,674 --> 00:11:45,246
these end to end tests locally instead of

177
00:11:45,268 --> 00:11:48,606
running these remote end to end test use local end to

178
00:11:48,628 --> 00:11:52,702
end test which are exactly similar to how these

179
00:11:52,756 --> 00:11:56,658
tests run on a remote CI CD server, which would mean exact

180
00:11:56,744 --> 00:12:00,674
replica of testing on a production instance or some

181
00:12:00,712 --> 00:12:04,482
environment very similar in a dev environment, which would mean

182
00:12:04,616 --> 00:12:08,338
you don't need to push your changes directly to a git branch,

183
00:12:08,434 --> 00:12:11,926
you can just locally commit or have it in a

184
00:12:11,948 --> 00:12:16,502
feature branch, test it and then run that with

185
00:12:16,556 --> 00:12:20,202
that. What it would mean is instead of using the changes

186
00:12:20,336 --> 00:12:24,170
since the environment is entirely local,

187
00:12:24,320 --> 00:12:27,914
you would run it. If teams fail and if you have

188
00:12:27,952 --> 00:12:31,374
a good configuration of the

189
00:12:31,412 --> 00:12:34,762
system, these end to end tests would run much faster

190
00:12:34,906 --> 00:12:38,702
and you would be able to fix them

191
00:12:38,836 --> 00:12:42,426
locally. Test it if everything works then you can raise

192
00:12:42,458 --> 00:12:46,354
a pull request or a merge request. So let me quickly give

193
00:12:46,392 --> 00:12:49,566
you an example or a pictorial depiction

194
00:12:49,598 --> 00:12:53,026
of it. So what we are saying is instead of

195
00:12:53,048 --> 00:12:56,010
running these end to end tests remotely,

196
00:12:56,190 --> 00:13:00,034
move this end to end test locally, set up an infrastructure

197
00:13:00,082 --> 00:13:03,414
very similar to having a dev environment which would set

198
00:13:03,452 --> 00:13:07,270
up your end to end environment. Run those teams

199
00:13:07,630 --> 00:13:09,500
and see everything works.

200
00:13:11,470 --> 00:13:15,034
So while we were evaluating how we can run

201
00:13:15,072 --> 00:13:19,420
these end to end teams locally, we were fortunate to

202
00:13:20,370 --> 00:13:23,962
look but for some open source tool and we identified

203
00:13:24,026 --> 00:13:27,674
a tool called Kuttl. So in talking to our teams,

204
00:13:27,722 --> 00:13:31,390
we discovered that most developers weren't running sufficient

205
00:13:31,730 --> 00:13:35,410
integration and end to end test in their local environments

206
00:13:35,750 --> 00:13:39,010
because it's too difficult to set up and administer

207
00:13:39,430 --> 00:13:43,246
test environments in an efficient way. So that's

208
00:13:43,278 --> 00:13:47,046
why we decided to rethink our entire local testing in

209
00:13:47,068 --> 00:13:50,742
hopes of cutting down the headaches and

210
00:13:50,796 --> 00:13:54,134
valuable time wasted. So we discovered a tool called

211
00:13:54,172 --> 00:13:58,390
Kuttl. Connecting Kuttl to our CI builds has empowered our developers

212
00:13:58,550 --> 00:14:02,166
to easily configure and configure

213
00:14:02,198 --> 00:14:05,658
a dev environment locally which accurately matches the

214
00:14:05,744 --> 00:14:09,340
final test environment where you run the end to end test.

215
00:14:09,890 --> 00:14:13,418
So let me give you a quick overview of Kuttl.

216
00:14:13,514 --> 00:14:17,310
Then I would give you a quick demo how

217
00:14:17,380 --> 00:14:20,906
Kuttl can be tested.

218
00:14:21,018 --> 00:14:24,050
Using Kuttl you can run end to end teams locally.

219
00:14:25,030 --> 00:14:28,146
So Kuttl is a Kubernetes test tool.

220
00:14:28,248 --> 00:14:30,850
It is a toolkit for writing teams,

221
00:14:31,750 --> 00:14:35,586
mainly designed for testing operators. I know testing

222
00:14:35,618 --> 00:14:39,206
Kubernetes operators is not easy. The motivation here is

223
00:14:39,228 --> 00:14:42,806
to leverage the existing Kubernetes ecosystem for

224
00:14:42,828 --> 00:14:46,342
a resource management way of doing

225
00:14:46,396 --> 00:14:49,706
a setup and easily asserting state within the

226
00:14:49,728 --> 00:14:53,258
cluster. So what I mean by that is instead of writing a

227
00:14:53,264 --> 00:14:56,490
go code or a Java code to get the

228
00:14:56,640 --> 00:14:59,606
current status of a Kubernetes cluster,

229
00:14:59,638 --> 00:15:03,440
to do can assertion do a yaml based

230
00:15:03,890 --> 00:15:07,914
declarative way of testing it. So Kuttl

231
00:15:07,962 --> 00:15:11,370
provides a Yaml based declarative way of doing testing,

232
00:15:11,530 --> 00:15:14,830
which would mean you don't need to learn a new language.

233
00:15:15,330 --> 00:15:19,034
Even if you are not comfortable with

234
00:15:19,092 --> 00:15:22,866
Java or a Go, you can still write these end to

235
00:15:22,888 --> 00:15:26,006
end test using a yaml based approach, which is

236
00:15:26,028 --> 00:15:30,290
very easy. I would explain the different steps in the subsequent slides,

237
00:15:30,450 --> 00:15:33,670
which would mean it also accelerates the ability to create

238
00:15:33,740 --> 00:15:36,470
the end to end testing environment.

239
00:15:37,130 --> 00:15:41,030
So let's get started with how can I install kuttl?

240
00:15:41,190 --> 00:15:45,078
If you are a Mac user you can use a brew tab kudo

241
00:15:45,094 --> 00:15:48,860
builder tab. So Kuttl is actually a part of

242
00:15:49,870 --> 00:15:53,466
pudobuilder was CNCF project for

243
00:15:53,568 --> 00:15:57,486
developing operators and they developed a tool called Kuttl for

244
00:15:57,508 --> 00:16:01,514
testing the operators in a declarative way. If you are a Linux user,

245
00:16:01,562 --> 00:16:07,642
you can use Kubectl

246
00:16:07,786 --> 00:16:11,346
crew install kuttl if you are

247
00:16:11,368 --> 00:16:14,434
a Go developer you can still do an API integration with

248
00:16:14,472 --> 00:16:18,406
your code, very similar to how selenium can

249
00:16:18,428 --> 00:16:21,858
be done in Java. So go get GitHub pudo

250
00:16:21,874 --> 00:16:25,106
builder Kuttl crew is a Kubectl

251
00:16:25,138 --> 00:16:28,394
packet manager. Kuttl is

252
00:16:28,432 --> 00:16:32,170
both CLI tool as well as an API for testing.

253
00:16:33,470 --> 00:16:37,562
So Kuttl is for if you are a developer who wants to

254
00:16:37,696 --> 00:16:41,294
test operators or any kubernetes resources for

255
00:16:41,332 --> 00:16:45,006
that matter without writing any go code, and if

256
00:16:45,028 --> 00:16:48,510
you want to test kubernetes applications in different versions,

257
00:16:48,930 --> 00:16:52,270
Kuttl would provide a framework that is very easy

258
00:16:52,340 --> 00:16:55,666
to create and execute as well.

259
00:16:55,848 --> 00:17:00,286
And if you are an application admin, if you want to operate the creation

260
00:17:00,318 --> 00:17:04,366
of a kubernetes cluster you can use ansible as well. But Kuttl

261
00:17:04,398 --> 00:17:08,630
also provides a cloud native way of doing testing.

262
00:17:09,130 --> 00:17:12,422
So let me first start

263
00:17:12,476 --> 00:17:15,922
with three main parts of Kuttl.

264
00:17:16,066 --> 00:17:19,398
First is a test suit test suit.

265
00:17:19,494 --> 00:17:23,622
You can see line number two there kind test suit

266
00:17:23,766 --> 00:17:27,290
and with an API version defined as Kuttl dev

267
00:17:27,360 --> 00:17:30,810
v one beta one. This is actually a CRD custom

268
00:17:30,880 --> 00:17:34,442
resource definition and you can see

269
00:17:34,496 --> 00:17:38,110
line number three kind start

270
00:17:38,180 --> 00:17:41,646
kind as false which would mean if you

271
00:17:41,668 --> 00:17:45,550
don't provide any kubernetes cluster

272
00:17:45,630 --> 00:17:50,114
you can use the existing cluster as well. If you want to use the

273
00:17:50,152 --> 00:17:53,346
local kind is also a kubernetes cluster which you can

274
00:17:53,368 --> 00:17:56,610
spin it off spin up using docker desktop.

275
00:17:56,770 --> 00:18:00,742
So for my demo I would be using start kind as true.

276
00:18:00,876 --> 00:18:04,562
So I don't want to use any external GCP or azure

277
00:18:04,626 --> 00:18:08,638
or any external AWS clusters.

278
00:18:08,754 --> 00:18:12,186
I would like to demo entire thing on my local environment. So I would be

279
00:18:12,208 --> 00:18:15,866
using a docker desktop. The prerequisite for this

280
00:18:15,888 --> 00:18:19,382
demo, or using kuttl in conjunction

281
00:18:19,446 --> 00:18:23,646
with kind is to have a docker desktop and

282
00:18:23,668 --> 00:18:26,862
the name name is the end to end test

283
00:18:26,916 --> 00:18:30,254
that I've just given it. Next is

284
00:18:30,292 --> 00:18:34,770
the test directories where you want to run these tests

285
00:18:35,430 --> 00:18:38,866
and the commands you can see. I would explain each one

286
00:18:38,888 --> 00:18:42,290
of them. So test suit is a collection of teams

287
00:18:44,790 --> 00:18:48,546
and there is a yaml file called test suit configuration file

288
00:18:48,578 --> 00:18:52,262
where this is actually defined how the suit would look like

289
00:18:52,396 --> 00:18:55,794
and line number eleven. You can ee a timeout

290
00:18:55,842 --> 00:18:59,802
of 300 seconds. Say that the test suit runs more than 300

291
00:18:59,856 --> 00:19:03,226
seconds, which would mean the

292
00:19:03,248 --> 00:19:06,794
test would actually fail. Suit would fail with an error saying

293
00:19:06,832 --> 00:19:10,566
that it is a timeout. So you can have a timeout

294
00:19:10,758 --> 00:19:14,062
on running those test suits as well. The first step is

295
00:19:14,116 --> 00:19:17,934
a test suit. Next is a test step where

296
00:19:17,972 --> 00:19:20,720
you define kind as a test step.

297
00:19:21,330 --> 00:19:24,542
This is also a CRD and where you execute

298
00:19:24,606 --> 00:19:28,306
commands. So it's more like if you have a bash script or if

299
00:19:28,328 --> 00:19:30,740
you have anything you can directly use.

300
00:19:31,990 --> 00:19:35,738
For my example, I would cite

301
00:19:35,774 --> 00:19:39,314
with installing artifactory a stateful

302
00:19:39,362 --> 00:19:43,494
application, and to see the

303
00:19:43,532 --> 00:19:47,010
install went successfully while doing an assertion.

304
00:19:47,170 --> 00:19:50,598
So test is a step of collection of test steps.

305
00:19:50,694 --> 00:19:54,154
So you can have n number of test

306
00:19:54,192 --> 00:19:57,980
steps inside a

307
00:19:58,350 --> 00:20:01,838
test I would cite with an example

308
00:20:02,004 --> 00:20:05,550
in my demo. Next is the assertion part.

309
00:20:05,620 --> 00:20:09,770
So once I do a test, I would like to do an assertion

310
00:20:09,930 --> 00:20:13,346
whether the test is successfully achieved. So this is where a

311
00:20:13,368 --> 00:20:17,074
declarative way of testing happens here where you set,

312
00:20:17,192 --> 00:20:20,980
since it is a stateful set application, I would expect

313
00:20:21,350 --> 00:20:24,690
the default installation of artifactory would come up with

314
00:20:24,840 --> 00:20:28,614
a single replica and I would also test whether that

315
00:20:28,652 --> 00:20:32,040
replica is ready. Replicas is equals to one.

316
00:20:32,410 --> 00:20:35,830
So the test route structure would something like that.

317
00:20:35,980 --> 00:20:39,450
So I have a demo application where I would have a test

318
00:20:39,600 --> 00:20:43,210
and add end to end test. I have

319
00:20:43,280 --> 00:20:46,662
three to four tests that I would run. So more importantly,

320
00:20:46,726 --> 00:20:50,414
Kuttl supports parallel execution of tests where you can run

321
00:20:50,452 --> 00:20:53,440
n number of teams, parallel eight in specific.

322
00:20:53,970 --> 00:20:57,422
So you can create a test suit with eight tests and

323
00:20:57,476 --> 00:20:59,310
run all of them in parallel.

324
00:21:01,410 --> 00:21:04,994
So let me quickly walk through a

325
00:21:05,032 --> 00:21:09,854
demo, let me share my terminal

326
00:21:09,902 --> 00:21:13,890
screen, let me

327
00:21:13,960 --> 00:21:17,462
give you the structure. So I have four

328
00:21:17,516 --> 00:21:19,720
tests that I would like to run.

329
00:21:20,890 --> 00:21:25,510
So let me quickly open the test

330
00:21:25,660 --> 00:21:29,146
cuttle test yaml. So where you can see this

331
00:21:29,168 --> 00:21:32,442
is a test suit which I would be running, which would have

332
00:21:32,496 --> 00:21:35,900
four tests. So I'm doing can installation of

333
00:21:36,270 --> 00:21:43,680
artifactory in four different tests test

334
00:21:44,290 --> 00:21:48,266
before I run, I would make sure that Docker

335
00:21:48,298 --> 00:21:52,080
is running, which is not in my case.

336
00:21:52,450 --> 00:21:56,226
So let me wait for Docker to come up. Okay then I

337
00:21:56,248 --> 00:21:59,566
would run Kubectl

338
00:21:59,678 --> 00:22:03,250
Kuttl test which would run the entire suit.

339
00:22:03,590 --> 00:22:07,142
So what it would create is since I've specified start

340
00:22:07,196 --> 00:22:10,422
kind as true, which would create a kind

341
00:22:10,476 --> 00:22:14,066
cluster, we can actually get the kubeconfig

342
00:22:14,098 --> 00:22:16,760
file and connect to that cluster as well.

343
00:22:17,130 --> 00:22:22,070
So let me do an export of this kubeconfig

344
00:22:22,890 --> 00:22:26,566
file. So I use an open source

345
00:22:26,598 --> 00:22:30,226
tool called canines to view the Kubernetes clusters.

346
00:22:30,358 --> 00:22:34,110
You can do a brew install of this canines.

347
00:22:35,010 --> 00:22:40,298
So what this Kubectl

348
00:22:40,314 --> 00:22:44,900
Kuttl test has done is it has executed the test suit and

349
00:22:46,630 --> 00:22:50,846
you can see it has actually run the prerequisites

350
00:22:50,878 --> 00:22:58,166
commands as part of the test suit. So it

351
00:22:58,188 --> 00:23:01,190
has created a JFrog repository,

352
00:23:01,530 --> 00:23:05,174
helm repo ad and then it has

353
00:23:05,212 --> 00:23:09,238
run four tests. You can see end to end test has four tests.

354
00:23:09,334 --> 00:23:13,206
So what it would do is it creates four namespaces

355
00:23:13,398 --> 00:23:17,002
and runs these install tests and

356
00:23:17,056 --> 00:23:19,690
then does the assertion of these tests,

357
00:23:20,590 --> 00:23:24,530
which would probably take five to ten minutes to run these tests.

358
00:23:24,630 --> 00:23:28,494
So in the meantime I would go back to the documentation and help

359
00:23:28,532 --> 00:23:31,882
you understand how Kuttl documentation

360
00:23:31,946 --> 00:23:36,494
is specified. So as

361
00:23:36,532 --> 00:23:39,726
I said, kuttl is from Kudo

362
00:23:39,758 --> 00:23:43,262
builder. It's a CNCF

363
00:23:43,326 --> 00:23:47,190
approved project. It has quite a but of maintenance.

364
00:23:47,850 --> 00:23:51,138
It's a declarative way of testing Kubernetes operators,

365
00:23:51,154 --> 00:23:55,350
but it can be used for any Kubernetes resources.

366
00:23:56,010 --> 00:23:59,306
So there is a specific slack channel associated with

367
00:23:59,328 --> 00:24:03,318
this in Kubernetes slack called Kudo.

368
00:24:03,494 --> 00:24:06,954
You can go and ask if you have any questions around that

369
00:24:07,072 --> 00:24:10,830
and they have a good documentation. How Cuttlewood works

370
00:24:10,980 --> 00:24:14,382
as I previously discussed, Kuttl has three things.

371
00:24:14,516 --> 00:24:18,334
One is test suit, test step assertion, and it has

372
00:24:18,372 --> 00:24:21,710
something called collectors and commands. You can go through the documentation,

373
00:24:23,670 --> 00:24:27,694
some CLI usage, how Kuttl

374
00:24:27,742 --> 00:24:31,102
can be used, you can see brew install Kuttl.

375
00:24:31,246 --> 00:24:35,502
Then you would run Kubectl

376
00:24:35,646 --> 00:24:39,510
Kuttl test which would run the entire test suit.

377
00:24:40,170 --> 00:24:44,230
There are few examples. How can you actually create

378
00:24:44,300 --> 00:24:48,538
your own test suit? Very simple,

379
00:24:48,704 --> 00:24:53,386
go through the documentation and if you have any questions you

380
00:24:53,408 --> 00:24:56,774
can always reach out to Slack channel. At Kudos

381
00:24:56,822 --> 00:24:59,942
slack there are some tricks and things

382
00:25:00,016 --> 00:25:04,350
where when you want to load

383
00:25:04,690 --> 00:25:08,366
images. So when you want to

384
00:25:08,388 --> 00:25:12,206
load these images, say if

385
00:25:12,228 --> 00:25:16,398
you want to run these tests very frequently

386
00:25:16,494 --> 00:25:20,626
you don't want these images or some images to be downloaded every time.

387
00:25:20,728 --> 00:25:24,930
So just to make sure that kind also provides

388
00:25:25,450 --> 00:25:29,510
loading images much faster. It's more like caching those images.

389
00:25:30,570 --> 00:25:34,294
Let's switch back to the demo where we

390
00:25:34,332 --> 00:25:36,760
are. Let's see how the installation would.

391
00:25:37,390 --> 00:25:41,002
Let's check the installation part. So as I said,

392
00:25:41,056 --> 00:25:44,394
it has created four namespaces and it is trying

393
00:25:44,432 --> 00:25:48,170
to run the install of artifactory.

394
00:25:48,670 --> 00:25:52,314
It's a stateful application and we will be doing assertion.

395
00:25:52,442 --> 00:25:54,640
So let me do a quick sit.

396
00:25:55,650 --> 00:25:59,866
So canines provides

397
00:25:59,898 --> 00:26:03,566
a UI way of managing the clusters

398
00:26:03,758 --> 00:26:07,602
so you can see. So my

399
00:26:07,656 --> 00:26:10,914
assertion on these test cases, test cases is to

400
00:26:10,952 --> 00:26:14,340
have the stateful set application,

401
00:26:15,930 --> 00:26:19,590
the read replicas would be one. So once

402
00:26:19,740 --> 00:26:23,426
every artifactory starts up in each namespace,

403
00:26:23,458 --> 00:26:25,270
sorry, in each namespace.

404
00:26:28,250 --> 00:26:32,314
So ee here the artifactory started in one of the namespaces. So once

405
00:26:32,352 --> 00:26:35,866
that assertion is completed, that namespace is

406
00:26:35,888 --> 00:26:39,146
actually got deleted by cutting. So it cleans up once

407
00:26:39,168 --> 00:26:42,666
the test is done. So once it runs four teams,

408
00:26:42,858 --> 00:26:46,942
it will also give out a report of what

409
00:26:46,996 --> 00:26:50,174
tests it has run, what tests have been successful and

410
00:26:50,212 --> 00:26:53,922
what were the failures. So you can have

411
00:26:53,976 --> 00:26:57,650
a report format as XML or JSON

412
00:26:58,390 --> 00:27:01,860
which can be actually integrated with the CI pipeline to see

413
00:27:02,790 --> 00:27:06,326
how the test actually failed. And one more

414
00:27:06,348 --> 00:27:09,830
good thing about Kuttl is it provides detailed output

415
00:27:10,170 --> 00:27:13,318
logging onto the console so you can see

416
00:27:13,404 --> 00:27:17,570
what actually has happened when the installation is doing it.

417
00:27:17,740 --> 00:27:21,434
So you can see. So once

418
00:27:21,472 --> 00:27:25,290
the test is actually done, it deletes the namespace.

419
00:27:26,190 --> 00:27:29,494
Let me switch back to the ports. So canines

420
00:27:29,542 --> 00:27:32,794
provides a good way of switching to ports,

421
00:27:32,922 --> 00:27:36,126
replicas, deployments and other aspects as

422
00:27:36,148 --> 00:27:40,446
well. It's very easy way and a convenient way of using

423
00:27:40,628 --> 00:27:44,146
of managing kubernetes clusters. So you can

424
00:27:44,168 --> 00:27:47,634
see still few upgrade tests are running.

425
00:27:47,752 --> 00:27:52,146
We would wait for the final result, but you

426
00:27:52,168 --> 00:27:53,300
can also see,

427
00:27:56,730 --> 00:28:01,030
let me see the logging how the namespaces are getting created.

428
00:28:01,450 --> 00:28:05,560
So once it randomly creates a namespace and

429
00:28:06,410 --> 00:28:09,242
does an install command on top of it.

430
00:28:09,296 --> 00:28:14,246
So I'm running an install one helm

431
00:28:14,278 --> 00:28:18,474
install of this application with some

432
00:28:18,512 --> 00:28:21,902
default parameters and a scale test.

433
00:28:21,956 --> 00:28:25,870
So all these test

434
00:28:25,940 --> 00:28:30,026
output is actually provided in the console to see if something breaks.

435
00:28:30,138 --> 00:28:33,874
Say for example if a test breaks or test fails, you would

436
00:28:33,912 --> 00:28:37,074
get a detailed report why the test has

437
00:28:37,112 --> 00:28:39,700
failed. Say for example,

438
00:28:40,950 --> 00:28:43,940
before I switch back to a failed example,

439
00:28:45,450 --> 00:28:48,840
I would just like to see the final report how

440
00:28:49,370 --> 00:28:51,510
this test has actually failed.

441
00:28:53,610 --> 00:28:57,160
So it is actually deleting the final namespace of that test.

442
00:28:57,850 --> 00:29:01,034
So you can see it has run all the teams, all the tests have

443
00:29:01,072 --> 00:29:04,874
actually passed. Say for example if

444
00:29:04,912 --> 00:29:08,986
there is some failure due to some issue in our code it

445
00:29:09,008 --> 00:29:12,350
would give a detailed report why it has failed. Say for example,

446
00:29:12,500 --> 00:29:16,350
you have set the replica count as two instead of one. So it would

447
00:29:16,420 --> 00:29:20,254
give an assertion saying that your test

448
00:29:20,292 --> 00:29:25,150
case has failed. Expected output is one

449
00:29:25,300 --> 00:29:29,154
but you have given as two, so it gives

450
00:29:29,192 --> 00:29:33,010
a clear indication of why the test has actually failed.

451
00:29:33,510 --> 00:29:36,766
Hope this Kuttl

452
00:29:36,798 --> 00:29:40,502
can be I've given a simple example of an install test. It can be used

453
00:29:40,556 --> 00:29:43,734
for any API testing. Say for

454
00:29:43,772 --> 00:29:47,838
example, if you want to test an endpoint where you can do a post request

455
00:29:47,954 --> 00:29:51,686
and get the response back, you can do an assertion on that response

456
00:29:51,718 --> 00:29:54,874
as well. So let

457
00:29:54,912 --> 00:29:59,500
me go back to my presentation so

458
00:30:00,690 --> 00:30:04,414
quick summary of references that what we have learned so

459
00:30:04,452 --> 00:30:07,706
far Kuttl documentation is documented at Kuttl

460
00:30:07,738 --> 00:30:12,154
dev Docs. The GitHub page is GitHub, Kudo builder Kuttl

461
00:30:12,282 --> 00:30:16,722
and there is a slack channel called Kudo and

462
00:30:16,776 --> 00:30:20,894
another tool that open source tool that we have used called canines for managing

463
00:30:20,942 --> 00:30:24,866
the Kubernetes clusters. So let's have

464
00:30:24,888 --> 00:30:29,014
a quick summary of what we have learned so far. Kuttl is

465
00:30:29,052 --> 00:30:32,950
more importantly an open source tool anybody

466
00:30:33,020 --> 00:30:37,378
can contribute and it's free to use. It can be used for local

467
00:30:37,484 --> 00:30:38,730
end to end testing.

468
00:30:41,150 --> 00:30:44,346
When you have local end to end

469
00:30:44,368 --> 00:30:47,798
testing and you are able to fix most of the issues locally

470
00:30:47,974 --> 00:30:51,534
then which would mean few broken builds, which would

471
00:30:51,572 --> 00:30:54,910
also mean you could release much faster,

472
00:30:55,890 --> 00:30:59,518
which would eventually mean happy developers and happy customers

473
00:30:59,604 --> 00:31:00,350
eventually.

474
00:31:02,930 --> 00:31:09,406
If you have any questions, I'm freely available on

475
00:31:09,428 --> 00:31:13,710
LinkedIn or on Twitter with my hashtag ichuka.

476
00:31:14,370 --> 00:31:15,810
Thanks for joining my session.

