1
00:00:39,010 --> 00:00:42,994
Hello everyone, thank you for joining my talk. For tips

2
00:00:43,042 --> 00:00:45,430
that help you leverage your airflow pipelines.

3
00:00:46,170 --> 00:00:49,254
Today I'm going to tell you for real

4
00:00:49,292 --> 00:00:52,862
world cases is how I curatively solved for nonstandard data

5
00:00:52,916 --> 00:00:56,618
engineering tasks with airflow.

6
00:00:56,714 --> 00:01:00,414
So yeah, let's go. I'm not going to stop

7
00:01:00,452 --> 00:01:04,770
you about who I am because I believe it should be told

8
00:01:04,840 --> 00:01:08,146
you in the intro. So let's go

9
00:01:08,168 --> 00:01:13,330
straight to the tips and because of we have only 30 minutes before

10
00:01:13,400 --> 00:01:18,614
the first tip, I know that

11
00:01:18,732 --> 00:01:22,022
most of you should face like with

12
00:01:22,076 --> 00:01:25,718
the very little experience in the data engineering should face

13
00:01:25,804 --> 00:01:29,738
the situation where you have a lot of similar

14
00:01:29,824 --> 00:01:33,674
pipelines which differs to each

15
00:01:33,712 --> 00:01:40,574
other just with small information

16
00:01:40,692 --> 00:01:44,160
like I dont know, ids, start date,

17
00:01:46,530 --> 00:01:50,430
which API is called and so on and so forth.

18
00:01:52,550 --> 00:01:56,340
Basically so you don't need to create

19
00:01:57,110 --> 00:02:00,114
separate pipelines for all of them.

20
00:02:00,312 --> 00:02:04,434
We can auto generate the pipelines for

21
00:02:04,472 --> 00:02:08,062
them using some configuration.

22
00:02:08,206 --> 00:02:11,798
In that particular case we can create a typical decks based on

23
00:02:11,804 --> 00:02:15,478
the CSV file. So my client has a

24
00:02:15,484 --> 00:02:18,922
lot of different decentralized organization which

25
00:02:18,976 --> 00:02:23,020
we need to grab the data from. The API was

26
00:02:24,910 --> 00:02:28,620
the same, we have just a different id for the data

27
00:02:29,890 --> 00:02:33,918
we should download and the

28
00:02:34,004 --> 00:02:37,902
information about this was started from

29
00:02:37,956 --> 00:02:42,494
the different start date. So I

30
00:02:42,532 --> 00:02:45,566
just add all the information about all of

31
00:02:45,588 --> 00:02:49,182
this decentralized application in the same file, in the CC

32
00:02:49,246 --> 00:02:53,326
file and created deck factory that created

33
00:02:53,518 --> 00:02:57,350
Ingodeck for all of these pipelines.

34
00:02:57,770 --> 00:03:01,366
What of pros of this approach? It's really easy to

35
00:03:01,388 --> 00:03:04,550
add a new entity, basically add a new

36
00:03:04,620 --> 00:03:09,158
entity, adding a new deck. It's just one line in the config,

37
00:03:09,334 --> 00:03:13,126
adding all the start date, all the information about ids

38
00:03:13,158 --> 00:03:17,020
and so on and so forth and scheduler will pick up it for you.

39
00:03:17,470 --> 00:03:20,654
Less code obviously we don't need to

40
00:03:20,692 --> 00:03:23,680
create any additional code.

41
00:03:24,850 --> 00:03:28,814
The DAC factory just create a DAC for you so no

42
00:03:28,852 --> 00:03:32,126
need to new files, single file, add in

43
00:03:32,148 --> 00:03:35,490
configuration it will work flexible.

44
00:03:36,070 --> 00:03:40,546
On my view it's flexible enough so

45
00:03:40,648 --> 00:03:44,180
we can create a start date for each particular

46
00:03:44,890 --> 00:03:48,534
pipelines and make sure that we

47
00:03:48,572 --> 00:03:52,226
do not create any additional garbage documents

48
00:03:52,338 --> 00:03:55,494
that will not add any value and will

49
00:03:55,532 --> 00:03:58,018
not download any information from it.

50
00:03:58,204 --> 00:04:01,322
Isolation we can control the store date.

51
00:04:01,376 --> 00:04:03,100
So as I said,

52
00:04:03,790 --> 00:04:08,460
but why I added this

53
00:04:09,070 --> 00:04:12,606
point just because we had an

54
00:04:12,628 --> 00:04:16,526
opportunity to create one single

55
00:04:16,628 --> 00:04:23,650
deck with all of these entities

56
00:04:24,230 --> 00:04:27,970
and upload the information in the single deck.

57
00:04:30,070 --> 00:04:34,222
Obviously for some of the pipelines, like for optimism,

58
00:04:34,366 --> 00:04:38,360
it will be a lot of API calls with empty data.

59
00:04:39,770 --> 00:04:43,974
We don't really want it. And as soon as

60
00:04:44,012 --> 00:04:48,146
we add something in the past, we have to retrigger

61
00:04:48,338 --> 00:04:51,946
all these decks in the past to download all

62
00:04:51,968 --> 00:04:54,380
the information, which is not really great.

63
00:04:54,910 --> 00:04:58,890
And so having a single deck

64
00:04:59,890 --> 00:05:03,022
allow you to have more control over a single

65
00:05:03,076 --> 00:05:07,066
pipeline. Also covered with data validation tests,

66
00:05:07,258 --> 00:05:11,098
which I didn't mention. We have a separate

67
00:05:11,194 --> 00:05:15,458
pipeline for the data validation and it was not

68
00:05:15,544 --> 00:05:19,010
included anywhere in the config.

69
00:05:19,350 --> 00:05:23,810
But adding line, adding one

70
00:05:23,960 --> 00:05:27,910
decentralized organization in this config

71
00:05:28,250 --> 00:05:32,034
was automatically picked up by the data validation

72
00:05:32,082 --> 00:05:37,046
pipelines and also it was included in

73
00:05:37,068 --> 00:05:40,780
the data validation test. So if we add

74
00:05:41,470 --> 00:05:44,570
any new decentralized organization,

75
00:05:44,910 --> 00:05:49,002
the data downloaded for it was already validated with

76
00:05:49,056 --> 00:05:53,242
our data validation test, which is really great without any additional

77
00:05:53,306 --> 00:05:57,166
efforts. Cons it may

78
00:05:57,188 --> 00:06:00,926
require some additional understanding of airflow. There are a

79
00:06:00,948 --> 00:06:04,690
lot of options to break something in

80
00:06:04,760 --> 00:06:08,498
this airflow or do not have patience to give

81
00:06:08,584 --> 00:06:11,730
scheduler to render all of these pipelines.

82
00:06:12,150 --> 00:06:14,340
So yeah,

83
00:06:16,330 --> 00:06:19,974
you may expect some complications with this

84
00:06:20,012 --> 00:06:24,840
approach. Kind of similar pipelines sometimes

85
00:06:26,490 --> 00:06:30,186
you may think that your pipelines are similar,

86
00:06:30,288 --> 00:06:33,658
but it's not really similar.

87
00:06:33,744 --> 00:06:37,226
They have a lot of different conditions and

88
00:06:37,248 --> 00:06:41,594
so on and so forth. So you may end up in the

89
00:06:41,632 --> 00:06:45,278
tier deck factory is a spaghetti bowl with a

90
00:06:45,284 --> 00:06:47,950
lot of if conditions and so on and so forth.

91
00:06:48,370 --> 00:06:52,474
So probably this may

92
00:06:52,532 --> 00:06:56,962
create more confusion than be

93
00:06:57,016 --> 00:07:02,734
easy for you. So sometimes it's

94
00:07:02,782 --> 00:07:06,310
really better to create separate pipelines for this

95
00:07:06,380 --> 00:07:09,030
kind of similar pipelines.

96
00:07:09,850 --> 00:07:14,120
Overall, good approach. I will

97
00:07:14,970 --> 00:07:19,050
recommend everyone to at least try that because having

98
00:07:19,120 --> 00:07:22,202
experience and having opportunity, having this

99
00:07:22,336 --> 00:07:25,610
tool under your belt is really really useful.

100
00:07:26,510 --> 00:07:30,550
So let's go further. Tip number two, you can create a typical

101
00:07:30,630 --> 00:07:33,450
deck based on the shareable config.

102
00:07:34,030 --> 00:07:39,600
Basically is an upgrade of the previous case.

103
00:07:40,290 --> 00:07:43,860
But in my case my client wanted to add

104
00:07:44,550 --> 00:07:48,562
configuration add pipelines on

105
00:07:48,616 --> 00:07:52,242
his own. I obviously gave him

106
00:07:52,296 --> 00:07:56,162
this opportunity by creating a sharebo config as a Google sheet.

107
00:07:56,226 --> 00:08:00,520
And basically what I did

108
00:08:02,890 --> 00:08:06,070
in the airflow code, I grab this data

109
00:08:06,140 --> 00:08:10,394
via Google Sheet API and

110
00:08:10,512 --> 00:08:13,900
create pipelines based on this data.

111
00:08:14,670 --> 00:08:17,834
Mostly this is it.

112
00:08:18,032 --> 00:08:22,250
But later I made an upgrade to this pipeline.

113
00:08:22,410 --> 00:08:26,302
I've downloaded data from this

114
00:08:26,356 --> 00:08:31,706
API and validated

115
00:08:31,818 --> 00:08:36,258
it and then loaded to

116
00:08:36,344 --> 00:08:43,490
a local file and then ask scheduler to create

117
00:08:43,560 --> 00:08:46,722
pipelines based on the information in the local file.

118
00:08:46,866 --> 00:08:51,400
Why I did that, I'll tell you a bit later.

119
00:08:52,090 --> 00:08:55,206
So let's go to the cons, to the

120
00:08:55,228 --> 00:08:58,322
pros, sorry, pros.

121
00:08:58,386 --> 00:09:01,980
Obviously other people can create airflow DAC for you.

122
00:09:02,670 --> 00:09:06,150
You don't need to maintain all the configuration.

123
00:09:06,230 --> 00:09:10,006
Basically the people who understand how to do this can do it for you

124
00:09:10,048 --> 00:09:13,406
and you can focus on different things and

125
00:09:13,428 --> 00:09:17,802
do not switch focus on maintaining

126
00:09:17,866 --> 00:09:21,134
these pipelines, which is a really good thing if you ask

127
00:09:21,172 --> 00:09:25,810
me. Changes available without deployment

128
00:09:26,470 --> 00:09:28,930
in the previous pipeline,

129
00:09:30,070 --> 00:09:33,940
Uni was required to

130
00:09:34,390 --> 00:09:37,618
commit changes to the configuration file,

131
00:09:37,714 --> 00:09:44,694
somehow deploy that to the airflow server and

132
00:09:44,732 --> 00:09:49,590
only after it was rendered and created in

133
00:09:49,660 --> 00:09:53,402
your Airflow server. Here, as soon as you added one

134
00:09:53,456 --> 00:09:57,194
line to the Google Sheet config it is picked up by

135
00:09:57,232 --> 00:10:01,002
scheduler and rendered in your airflow center is minus

136
00:10:01,066 --> 00:10:03,840
one step. Great. Yeah,

137
00:10:07,330 --> 00:10:11,166
there are only two cons. It's probably a lot of

138
00:10:11,348 --> 00:10:14,720
validation work for this option.

139
00:10:15,170 --> 00:10:16,910
First of all, it's performance.

140
00:10:18,770 --> 00:10:22,546
Before doing it, you have to make sure that API you

141
00:10:22,568 --> 00:10:25,782
are grabbing data from have a small

142
00:10:25,836 --> 00:10:29,366
delay because two or 3 seconds may be crucial for a

143
00:10:29,388 --> 00:10:33,794
scheduler and end up crushing

144
00:10:33,842 --> 00:10:37,270
your scheduler and stopping running

145
00:10:37,340 --> 00:10:40,380
or airflow pipelines, which is not great.

146
00:10:41,550 --> 00:10:45,862
You need to handle user experience. For those of you who didn't

147
00:10:45,926 --> 00:10:50,640
have an opportunity to

148
00:10:51,090 --> 00:10:55,200
work with the user, experience may be surprised how user can break

149
00:10:56,050 --> 00:10:59,914
everything. So obviously you need to documentation

150
00:10:59,962 --> 00:11:03,586
to explain your user how to add your pipelines and

151
00:11:03,768 --> 00:11:07,010
it better be extensive and understandable.

152
00:11:07,590 --> 00:11:11,682
Input data validation the

153
00:11:11,736 --> 00:11:14,020
step I previously told you,

154
00:11:16,250 --> 00:11:19,960
grabbing data from the API and only then

155
00:11:20,810 --> 00:11:24,450
validating it and then loading

156
00:11:24,610 --> 00:11:28,300
it to the local file and

157
00:11:28,750 --> 00:11:31,930
build your pipeline based on this file.

158
00:11:32,990 --> 00:11:36,538
It is really for validating the data

159
00:11:36,624 --> 00:11:40,326
because even though you added the documentation

160
00:11:40,438 --> 00:11:43,920
and invested a lot of your time in it,

161
00:11:44,850 --> 00:11:48,366
user may skip it, may do not understand it

162
00:11:48,388 --> 00:11:52,554
right, and so on and so forth. So you'd better to validate the data and

163
00:11:52,612 --> 00:11:56,740
do not pass the data

164
00:11:57,190 --> 00:12:00,814
that garbage to the scheduler

165
00:12:00,862 --> 00:12:04,926
because it obviously may broke your scheduler,

166
00:12:04,958 --> 00:12:09,814
which is not a good thing. May break your scheduler and

167
00:12:09,932 --> 00:12:13,922
even though you have documentation, you have your validation,

168
00:12:13,986 --> 00:12:18,010
test something. You're also a human and

169
00:12:18,080 --> 00:12:22,460
you can skip something and

170
00:12:23,630 --> 00:12:28,010
you find your user who will break your cluster.

171
00:12:28,350 --> 00:12:32,880
So you'd better to have an error notification to

172
00:12:33,250 --> 00:12:35,280
react as soon as it possible.

173
00:12:36,770 --> 00:12:40,414
Overall, good option may save

174
00:12:40,452 --> 00:12:43,594
you a lot of time, but it's

175
00:12:43,642 --> 00:12:50,640
better to have a lot of time

176
00:12:51,090 --> 00:12:55,154
to invest a lot of safety checkers

177
00:12:55,322 --> 00:12:58,806
to make sure that everything works fine. Let's go

178
00:12:58,828 --> 00:13:00,600
to the tip. Number three,

179
00:13:02,090 --> 00:13:05,670
how to generate decks based on your airflow entities. Basically,

180
00:13:05,740 --> 00:13:10,170
it's the combination of both of these previous cases.

181
00:13:10,830 --> 00:13:14,506
Why it can be useful in my experience, I have a case,

182
00:13:14,608 --> 00:13:17,738
had a case where

183
00:13:17,824 --> 00:13:22,640
my client had a lot of different

184
00:13:25,090 --> 00:13:28,730
MySQL databases. They were created,

185
00:13:28,810 --> 00:13:33,682
dropped and so on and so forth and

186
00:13:33,736 --> 00:13:37,810
I always had to create new pipelines,

187
00:13:38,230 --> 00:13:43,982
pipelines based on the different connection

188
00:13:44,046 --> 00:13:47,238
to the MySQL of this database. Just grab this data,

189
00:13:47,324 --> 00:13:50,486
drop the pipeline and so on and so forth. So a

190
00:13:50,508 --> 00:13:55,974
lot of maintenance. But as

191
00:13:56,012 --> 00:13:59,722
you may understand adding information to the

192
00:13:59,856 --> 00:14:03,226
configuration file or credentials to configuration file is

193
00:14:03,248 --> 00:14:07,050
not a good thing. So I decided to make

194
00:14:07,120 --> 00:14:11,114
it like that. I created airflow

195
00:14:11,162 --> 00:14:14,478
connection to the MySQL database with the certain

196
00:14:14,564 --> 00:14:18,320
prefix, certain prefix and

197
00:14:18,850 --> 00:14:22,618
in the airflow you can use

198
00:14:22,724 --> 00:14:26,770
SQL Alhami to query the metadata DB.

199
00:14:27,750 --> 00:14:31,566
Then list all the connection

200
00:14:31,598 --> 00:14:35,910
you have, filter only one with the certain prefix and

201
00:14:35,980 --> 00:14:40,054
create airflow pipelines based

202
00:14:40,172 --> 00:14:43,240
on all the information that you found.

203
00:14:46,090 --> 00:14:50,362
It is as it is really good thing you do not to

204
00:14:50,496 --> 00:14:55,002
maintain any configuration. All the configuration is

205
00:14:55,056 --> 00:14:58,202
already in the MySQL in your

206
00:14:58,256 --> 00:15:01,806
metadata DB. And if the connection is fine

207
00:15:01,988 --> 00:15:05,614
so everything should work fine. Pros no

208
00:15:05,652 --> 00:15:10,414
need to handle external API calls. So yeah no

209
00:15:10,452 --> 00:15:13,758
need to handle any configuration external APIs

210
00:15:13,934 --> 00:15:19,154
everything in your metadata DB. So if one

211
00:15:19,192 --> 00:15:22,846
way or another scheduler already call your metadata

212
00:15:22,878 --> 00:15:27,094
DB and everything

213
00:15:27,292 --> 00:15:30,646
is in it, what are the

214
00:15:30,668 --> 00:15:35,000
cons? Configuration can be lost. I dont know if you

215
00:15:35,850 --> 00:15:40,326
faced a situation where your database

216
00:15:40,438 --> 00:15:44,170
was metadata airflow database was lost,

217
00:15:44,750 --> 00:15:48,842
not really great. Or for example you

218
00:15:48,896 --> 00:15:52,814
have to migrate your airflow from one

219
00:15:52,852 --> 00:15:56,126
server to another. So also the situation

220
00:15:56,228 --> 00:15:58,510
where metadata DB can be lost.

221
00:15:59,810 --> 00:16:02,946
But once you lost it you also lost all of your

222
00:16:02,968 --> 00:16:06,846
connections and you lost all of your configuration. So it's

223
00:16:06,878 --> 00:16:10,930
better to have a backup of your configuration.

224
00:16:11,990 --> 00:16:15,558
It's slightly higher load on the metadata DB but one way

225
00:16:15,564 --> 00:16:23,334
or another scheduler make

226
00:16:23,532 --> 00:16:27,650
a lot of calls during its regular run. So one additional

227
00:16:27,730 --> 00:16:30,700
call will not be a problem.

228
00:16:32,190 --> 00:16:35,834
Yeah this is the

229
00:16:36,032 --> 00:16:38,700
one. So let's go next.

230
00:16:39,150 --> 00:16:42,966
Okay, tip number four, make your airflow

231
00:16:42,998 --> 00:16:45,230
pipelines even driving.

232
00:16:47,010 --> 00:16:50,814
Some of you may like what airflow is for

233
00:16:50,852 --> 00:16:54,622
scheduled by jobs, how we can make it even

234
00:16:54,676 --> 00:16:58,900
driving. But there are options. So sometimes

235
00:17:00,710 --> 00:17:05,054
you may require, I don't know, there is a low

236
00:17:05,112 --> 00:17:08,406
volume of events, say few like

237
00:17:08,508 --> 00:17:14,166
two or three an hour. But you may need result

238
00:17:14,268 --> 00:17:17,850
of this pipelines as soon as it possible. Once the

239
00:17:17,920 --> 00:17:21,690
event was put into the event

240
00:17:21,760 --> 00:17:22,490
occur.

241
00:17:24,910 --> 00:17:28,970
So yeah I had pretty much the same

242
00:17:29,040 --> 00:17:32,526
case that

243
00:17:32,628 --> 00:17:37,310
how I did it. So our application was

244
00:17:37,380 --> 00:17:41,294
put the event to the Google cloud

245
00:17:41,492 --> 00:17:44,962
pop up. Basically just event queue and

246
00:17:45,016 --> 00:17:49,122
once event was in it it

247
00:17:49,256 --> 00:17:52,990
triggered the cloud function. At cloud function triggered

248
00:17:53,070 --> 00:17:56,786
airflow DAC via airflow

249
00:17:56,818 --> 00:18:00,114
API. We can make it directly

250
00:18:00,162 --> 00:18:03,526
but we don't have control over

251
00:18:03,628 --> 00:18:07,614
the application. We just haven't

252
00:18:07,682 --> 00:18:11,210
had an opportunity to put the information in the event queue.

253
00:18:13,150 --> 00:18:17,414
Basically if you create airflow pipeline

254
00:18:17,462 --> 00:18:19,770
without schedule, you can trigger it manually.

255
00:18:20,530 --> 00:18:24,282
And if you have an API, you can trigger

256
00:18:24,346 --> 00:18:27,882
it via API, sort of a manual API

257
00:18:27,946 --> 00:18:32,094
call. What are the

258
00:18:32,132 --> 00:18:35,438
process of this approach result of the execution?

259
00:18:35,534 --> 00:18:38,766
Do not rely on schedule. Basically it's

260
00:18:38,798 --> 00:18:42,002
a definition of event dragon. Really really

261
00:18:42,056 --> 00:18:45,622
good things. Another way to do that

262
00:18:45,756 --> 00:18:49,634
would be to create a pipeline that runs

263
00:18:49,682 --> 00:18:53,458
once a minute, that check number of events

264
00:18:53,554 --> 00:18:57,270
in that queue. And if there are more than a zero,

265
00:18:57,340 --> 00:19:00,440
just grab all of them and run the pipelines for

266
00:19:00,890 --> 00:19:04,842
all of these pipelines. But in this

267
00:19:04,896 --> 00:19:08,666
particular case you end up having tons of

268
00:19:08,768 --> 00:19:12,000
1 minute dag runs which

269
00:19:12,370 --> 00:19:16,106
will overload your metadata

270
00:19:16,138 --> 00:19:20,382
DB with tons of garbage dag runs and

271
00:19:20,516 --> 00:19:24,306
end up slow down metadata DB on all of your

272
00:19:24,408 --> 00:19:27,634
airflow experience. What are the

273
00:19:27,672 --> 00:19:32,162
cons? It's a limited limitation obviously

274
00:19:32,296 --> 00:19:36,534
of that approach is

275
00:19:36,652 --> 00:19:40,514
that if your pipeline

276
00:19:40,562 --> 00:19:43,640
have, I don't know, thousands of events an hour,

277
00:19:45,850 --> 00:19:49,306
it will not be applicable to the

278
00:19:49,328 --> 00:19:52,714
airflow and it will

279
00:19:52,752 --> 00:19:56,906
not work. So probably the best that

280
00:19:57,008 --> 00:20:02,990
airflow can give you is one

281
00:20:03,060 --> 00:20:04,720
event in five minutes,

282
00:20:06,450 --> 00:20:11,200
which is pretty good in mind. Like sometimes

283
00:20:11,570 --> 00:20:14,850
is enough. And if it's enough,

284
00:20:14,920 --> 00:20:18,098
why can't we do that? So basically these

285
00:20:18,184 --> 00:20:21,458
are the four tips I wanted to

286
00:20:21,544 --> 00:20:26,114
tell you about it. Let's sum

287
00:20:26,162 --> 00:20:30,146
all of them. Create your pipelines based on the CSV

288
00:20:30,178 --> 00:20:33,814
file, then upgrade it to

289
00:20:33,852 --> 00:20:37,866
shareable config. If you need some

290
00:20:37,888 --> 00:20:41,430
of your colleagues or non

291
00:20:41,590 --> 00:20:44,794
development or not, software engineering guy

292
00:20:44,992 --> 00:20:47,340
wanted to add pipelines to it.

293
00:20:47,790 --> 00:20:51,754
Create your entities. Create airflow entities.

294
00:20:51,882 --> 00:20:57,646
If the

295
00:20:57,668 --> 00:21:01,870
thing that you would need to create information based

296
00:21:01,940 --> 00:21:05,650
on are secure and you already

297
00:21:05,720 --> 00:21:09,410
stored it in the airflow and

298
00:21:09,560 --> 00:21:12,942
in case you need your results of your pipelines

299
00:21:13,006 --> 00:21:16,290
as soon as some event was triggered,

300
00:21:16,450 --> 00:21:20,626
you can make your airflow

301
00:21:20,658 --> 00:21:23,400
pipelines event driven. Yeah.

302
00:21:24,570 --> 00:21:28,520
So this is it. If you have any questions,

303
00:21:29,290 --> 00:21:32,534
add me to the social network. Feel free to ask

304
00:21:32,572 --> 00:21:35,894
any question. I would be glad to hear

305
00:21:35,932 --> 00:21:39,414
it. So yeah, this is

306
00:21:39,452 --> 00:21:43,086
it. Thank you for your time. Hope you all

307
00:21:43,108 --> 00:21:44,540
enjoyed the conference and see you there.

