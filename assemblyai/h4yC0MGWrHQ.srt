1
00:00:23,690 --> 00:00:26,866
Everyone, welcome my, welcome to my talk on introduction

2
00:00:26,898 --> 00:00:30,614
to vector databases. So over the next 30, 40 minutes,

3
00:00:30,732 --> 00:00:34,642
I want to take you through a general introduction of what vector databases

4
00:00:34,706 --> 00:00:38,262
are and how they help you search over your data

5
00:00:38,316 --> 00:00:42,098
in a much more organic, organic manner.

6
00:00:42,194 --> 00:00:46,322
And then I want to introduce you to the basic concepts of vector databases,

7
00:00:46,466 --> 00:00:49,734
how we take those basic concepts and scale them up so that you can search

8
00:00:49,772 --> 00:00:53,882
over for hundreds of millions of data objects, if not billions of data objects.

9
00:00:54,026 --> 00:00:58,282
And then I'll end off with hopefully, what's an engaging

10
00:00:58,346 --> 00:01:00,910
demonstration of the power of vector databases?

11
00:01:02,530 --> 00:01:06,190
So before we jump into vector databases, a little bit about myself.

12
00:01:06,340 --> 00:01:10,174
I'm a developer advocate at Weaviate and I'm an engineer and data scientist

13
00:01:10,222 --> 00:01:13,486
by training. And the first time I really learned

14
00:01:13,518 --> 00:01:17,574
about vector databases, that was a bit of a light bulb moment for me

15
00:01:17,692 --> 00:01:21,474
where I thought, why doesn't everybody just use vector

16
00:01:21,522 --> 00:01:25,830
databases? They're just a much more natural way to

17
00:01:25,980 --> 00:01:29,254
search over and deal with your unstructured data.

18
00:01:29,372 --> 00:01:32,762
And so if the only thing that you get out of this talk is that

19
00:01:32,816 --> 00:01:37,130
nugget of insight around what vector databases can

20
00:01:37,200 --> 00:01:40,654
help you accomplish and how they can help improve the projects that you're working on,

21
00:01:40,692 --> 00:01:42,720
then I'll have considered my job done.

22
00:01:44,210 --> 00:01:48,110
Okay, so the essence or the main idea

23
00:01:48,180 --> 00:01:52,094
behind vector databases is that these allow you to go

24
00:01:52,132 --> 00:01:56,562
from a classical approach of keyword search, where in,

25
00:01:56,696 --> 00:01:59,570
let's say a SQL structured database,

26
00:01:59,990 --> 00:02:03,826
if you want to look for an item, you would have to do some sort

27
00:02:03,848 --> 00:02:07,494
of keyword search or exact matching search.

28
00:02:07,692 --> 00:02:11,510
Vector databases transition from that idea

29
00:02:11,580 --> 00:02:15,494
and allow you to do a similarity search or a semantic search over

30
00:02:15,532 --> 00:02:16,360
your data.

31
00:02:19,210 --> 00:02:22,434
This is a fairly abstract definition,

32
00:02:22,482 --> 00:02:25,560
so let me further explain this using an example.

33
00:02:26,330 --> 00:02:29,366
So imagine you've got a bunch of

34
00:02:29,388 --> 00:02:32,926
documents that you store in your database. The first one here as an

35
00:02:32,948 --> 00:02:36,378
example is how to build a rest API. Imagine you have thousands

36
00:02:36,394 --> 00:02:40,378
and thousands of these and you want to search over these documents.

37
00:02:40,554 --> 00:02:44,370
The traditional approach would be you go into your search

38
00:02:44,440 --> 00:02:48,402
bar, you type out the word python, and the

39
00:02:48,456 --> 00:02:51,794
traditional keyword search would go in and

40
00:02:51,832 --> 00:02:55,602
would essentially look for the word python anywhere in

41
00:02:55,656 --> 00:02:59,190
your document, right? So imagine you only have two documents here.

42
00:02:59,260 --> 00:03:02,646
The word python is nowhere to be found. So it says that it

43
00:03:02,668 --> 00:03:05,910
returns nothing and there's no articles that have this keyword.

44
00:03:06,410 --> 00:03:10,106
The more fundamental problem with this traditional keyword search is that

45
00:03:10,128 --> 00:03:13,498
it technically doesn't even understand whether you mean

46
00:03:13,584 --> 00:03:17,046
Python the animal, the snake, or python the programming

47
00:03:17,078 --> 00:03:20,606
language. And that gets to the heart of the problem here.

48
00:03:20,708 --> 00:03:24,320
Keyword search is just doing string matching to find out

49
00:03:24,770 --> 00:03:28,302
the document that you are looking for, it doesn't actually

50
00:03:28,356 --> 00:03:32,334
understand the context and the meaning behind your

51
00:03:32,372 --> 00:03:35,658
search. And so on the other hand, if we

52
00:03:35,684 --> 00:03:39,346
do a semantic search, we go in, we type out the exact same

53
00:03:39,448 --> 00:03:42,706
word, and now it recognizes that in

54
00:03:42,728 --> 00:03:46,158
the context of the documents that you've provided me, you're probably not looking for the

55
00:03:46,184 --> 00:03:49,634
animal, you're looking for a programming language for data scientists,

56
00:03:49,682 --> 00:03:53,094
which is the Python programming language. And the essence here

57
00:03:53,132 --> 00:03:57,190
is that it understands your query and it matches it

58
00:03:57,340 --> 00:04:00,486
with a similar document that's in your

59
00:04:00,508 --> 00:04:04,586
database. And in order for this to happen, it has to understand

60
00:04:04,688 --> 00:04:08,378
everything that's in your database, the documents as well as your query, and then it

61
00:04:08,384 --> 00:04:11,866
has to match it appropriately. And this functionality of

62
00:04:11,888 --> 00:04:15,742
understanding your data and then going in and matching it is exactly

63
00:04:15,796 --> 00:04:19,326
what a vector database does. And instead of just being able to

64
00:04:19,348 --> 00:04:22,994
search over a couple of documents or thousands of documents, it can search over

65
00:04:23,032 --> 00:04:26,482
hundreds of millions or billions of documents. And that's the

66
00:04:26,536 --> 00:04:29,780
scalability of the vector database that we'll talk about in a bit.

67
00:04:32,310 --> 00:04:35,774
So really, if we want to achieve

68
00:04:35,822 --> 00:04:39,174
this end goal of semantic search, similarity search

69
00:04:39,292 --> 00:04:43,078
over our documents, there's a couple of hurdles in our way.

70
00:04:43,164 --> 00:04:46,520
The first hurdle being that we need to take our unstructured data,

71
00:04:46,890 --> 00:04:50,410
we need to be able to process it, understand it and search through it.

72
00:04:50,480 --> 00:04:54,010
And that's a difficult task. The second tall order,

73
00:04:54,080 --> 00:04:57,466
the second hurdle in the way is that it's not enough to just be able

74
00:04:57,488 --> 00:05:00,842
to search over and understand a small amount

75
00:05:00,896 --> 00:05:04,374
of data. We have to be able to do this in a scalable

76
00:05:04,422 --> 00:05:08,026
and secure way so that we can search over hundreds of millions or billions

77
00:05:08,058 --> 00:05:11,438
of documents. And so those are the two hurdles that are in the

78
00:05:11,444 --> 00:05:15,006
way before we can achieve this idea of semantic search that

79
00:05:15,028 --> 00:05:18,350
I just presented. So we'll go through and see how vector databases

80
00:05:18,430 --> 00:05:20,100
address each one of these issues.

81
00:05:21,270 --> 00:05:24,594
So the first issue, how do we understand and search through

82
00:05:24,632 --> 00:05:28,246
our data? Well, we use machine learning models to understand the

83
00:05:28,268 --> 00:05:31,862
context of our unstructured data. And so every time I say unstructured data,

84
00:05:31,916 --> 00:05:35,458
I mean either natural language, text. So this can be documents,

85
00:05:35,554 --> 00:05:38,662
books, emails, or it can also be

86
00:05:38,716 --> 00:05:41,674
images, video, audio. All of your unstructured data,

87
00:05:41,792 --> 00:05:45,914
we pass them through a machine learning model. It understands the context of that

88
00:05:45,952 --> 00:05:50,206
data and then we use the output of the machine learning model to

89
00:05:50,228 --> 00:05:54,010
learn about these context in our vector database. So let's

90
00:05:54,090 --> 00:05:56,910
dig deeper into this concept of using ML.

91
00:05:58,450 --> 00:06:01,920
So let's say you've got your data over here

92
00:06:03,350 --> 00:06:07,106
on the left hand side, upper left. This can be emails, videos,

93
00:06:07,208 --> 00:06:10,914
audio, images. We're going to pass each

94
00:06:10,952 --> 00:06:13,860
one of these through our machine learning model.

95
00:06:14,470 --> 00:06:18,130
And our machine learning model is going to spit out a vector

96
00:06:18,290 --> 00:06:21,506
associated corresponding with each one of our unstructured

97
00:06:21,538 --> 00:06:25,126
data objects. And the way that I like to think about this is that our

98
00:06:25,148 --> 00:06:28,610
unstructured data is in human understandable format.

99
00:06:28,770 --> 00:06:31,590
We can read an email, we can view and understand an image,

100
00:06:31,670 --> 00:06:34,842
but the machine or the computer can't understand it. So these

101
00:06:34,896 --> 00:06:38,358
vectors that the computer generates are machine understandable.

102
00:06:38,454 --> 00:06:41,834
So it's much more easier for a machine to

103
00:06:41,872 --> 00:06:45,070
understand these vectors for our data.

104
00:06:45,140 --> 00:06:48,234
So now that we have our data translated into machine language,

105
00:06:48,362 --> 00:06:51,920
now what we're going to do is project this and plot this out

106
00:06:52,290 --> 00:06:55,922
and create vector representations. So each object

107
00:06:56,056 --> 00:06:59,518
that we had a vector for here is now represented

108
00:06:59,614 --> 00:07:03,394
using a green dot on the right hand side. And so we call

109
00:07:03,432 --> 00:07:06,786
this a vector space or an embedding

110
00:07:06,818 --> 00:07:10,280
space. So we take all of our vectors and we embed them

111
00:07:10,890 --> 00:07:15,186
into this vector space that I've demonstrated

112
00:07:15,218 --> 00:07:18,634
using a 3d graph. There's two

113
00:07:18,672 --> 00:07:23,194
important things about this vector space. The first one is that

114
00:07:23,392 --> 00:07:26,630
it preserves similarity between objects.

115
00:07:26,710 --> 00:07:30,234
So, for example, if you look at the vector for these word cat,

116
00:07:30,432 --> 00:07:34,138
it is going to be close by to the vector for the image

117
00:07:34,154 --> 00:07:37,466
of the cat. And the machine learning model understands

118
00:07:37,498 --> 00:07:41,322
that the word cat and the image of the cat are similar in nature

119
00:07:41,466 --> 00:07:45,440
in these unstructured data. So it's going to keep the vectors closer together.

120
00:07:45,970 --> 00:07:49,262
So similarly, if you have the word chicken and the image of a chicken,

121
00:07:49,326 --> 00:07:53,106
those are going to be closer together in vector space. On the

122
00:07:53,128 --> 00:07:56,194
other hand, if you take a look at the word cat and

123
00:07:56,232 --> 00:07:59,874
the word banana, the vector for the word banana, those two concepts

124
00:07:59,922 --> 00:08:03,880
are further away, and so the corresponding vectors are also further away.

125
00:08:04,650 --> 00:08:08,994
And so in this way, you can take objects, or unstructured

126
00:08:09,042 --> 00:08:12,182
data, objects where you can show them to a human,

127
00:08:12,236 --> 00:08:14,906
and you can ask them which two of these things are similar and which two

128
00:08:14,928 --> 00:08:18,554
of these things are different. Now, you can do the same thing by conducting a

129
00:08:18,592 --> 00:08:22,214
distance metric around your vector objects

130
00:08:22,262 --> 00:08:25,630
in vector space, and a machine can do this much more easily.

131
00:08:26,530 --> 00:08:29,386
The second thing that's important to keep in mind is that even though I'm showing

132
00:08:29,418 --> 00:08:32,830
you these green dots in a 3d space where I have three axes,

133
00:08:33,490 --> 00:08:36,674
in reality these vector spaces are often very high

134
00:08:36,712 --> 00:08:41,278
dimensional. They can be 300 dimensional, 600 dimensional, 2000 dimensional,

135
00:08:41,374 --> 00:08:44,706
depending on how much data you want to preserve, how accurate you

136
00:08:44,728 --> 00:08:48,498
want the vector representation to be, you're going to choose a higher dimensional

137
00:08:48,514 --> 00:08:52,214
vector space. It's kind of like asking a person to read

138
00:08:52,252 --> 00:08:56,262
a book and summarize it into one page. And that

139
00:08:56,316 --> 00:09:00,034
summarization is going to lose a lot of data. If you ask them to summarize

140
00:09:00,082 --> 00:09:03,706
it into one chapter, they'll be able to preserve a lot more information in that

141
00:09:03,728 --> 00:09:06,954
one chapter. So the higher the dimensionality of the vectors, the more

142
00:09:06,992 --> 00:09:10,426
descriptive and the more information that they are going to preserve from the

143
00:09:10,448 --> 00:09:12,910
original unstructured data format.

144
00:09:15,330 --> 00:09:18,030
Okay, so now that we have these vector representations,

145
00:09:18,690 --> 00:09:21,678
that's not enough. What we need to be able to do is we need to

146
00:09:21,684 --> 00:09:24,750
be able to have millions and millions, if not billions,

147
00:09:24,830 --> 00:09:29,010
of these vector representations, along with their

148
00:09:29,080 --> 00:09:32,142
unstructured data object counterparts.

149
00:09:32,286 --> 00:09:36,070
And then we need to be able to search over and query these objects

150
00:09:36,890 --> 00:09:40,662
thousands and thousands of times per second. And this is this idea

151
00:09:40,716 --> 00:09:44,102
of being able to scale your vectors and search

152
00:09:44,156 --> 00:09:47,942
over them that a vector database really excels

153
00:09:48,006 --> 00:09:51,466
at. So in order

154
00:09:51,488 --> 00:09:55,194
to be able to search over our data, we need to first

155
00:09:55,232 --> 00:09:58,842
of all store billions of these

156
00:09:58,896 --> 00:10:02,438
data objects, both the vectors as well as the non vector

157
00:10:02,534 --> 00:10:06,382
unstructured counterparts. In order to have this happen,

158
00:10:06,436 --> 00:10:10,254
we need to have our machine learning models work at scale in a production level

159
00:10:10,292 --> 00:10:14,270
environment. And so the idea is that every time you have a

160
00:10:14,340 --> 00:10:18,226
data object, an unstructured data object come in, it has to go through

161
00:10:18,248 --> 00:10:21,346
the machine learning model. You have to perform inference, you have to

162
00:10:21,368 --> 00:10:24,834
take the vector that comes out, pair it with

163
00:10:24,872 --> 00:10:28,006
the object that went in producing that vector, and then you have to store both

164
00:10:28,028 --> 00:10:31,846
of these things into your vector database. And then of

165
00:10:31,868 --> 00:10:35,826
course the vector database, the keywordsto there being database has to support crud

166
00:10:35,858 --> 00:10:39,126
operations. Any of these green objects that you have on the left

167
00:10:39,148 --> 00:10:42,390
hand side here could need to be deleted, updated.

168
00:10:42,470 --> 00:10:46,298
You could need to add new data objects depending on the

169
00:10:46,304 --> 00:10:49,578
velocity of your data that you're dealing with. So a

170
00:10:49,584 --> 00:10:53,162
vector database has to have crud operation

171
00:10:53,226 --> 00:10:53,840
support.

172
00:10:55,890 --> 00:10:59,774
So when we're talking about scaling vector search and

173
00:10:59,812 --> 00:11:03,086
scaling, the ability to embed vector objects in

174
00:11:03,108 --> 00:11:06,354
our vector databases, that's exactly what

175
00:11:06,392 --> 00:11:10,146
a vector database excels at. So I want to go through the

176
00:11:10,168 --> 00:11:13,538
definition of a vector database, and then the problems that

177
00:11:13,544 --> 00:11:16,130
you need to tackle as you need to scale,

178
00:11:16,730 --> 00:11:20,706
storing vector objects on the billion object scale

179
00:11:20,738 --> 00:11:23,750
as well as searching over them on a billion object scale.

180
00:11:24,410 --> 00:11:27,926
So when we talk about a vector database, really these fundamental, the first

181
00:11:27,948 --> 00:11:31,366
fundamental is that you need to store the unstructured data objects

182
00:11:31,478 --> 00:11:34,810
and all of these corresponding vector embeddings.

183
00:11:35,310 --> 00:11:38,986
Anything that you want to be able to perform vector search over, you need to

184
00:11:39,008 --> 00:11:43,390
have the original unstructured object as well as its vector embedding.

185
00:11:44,610 --> 00:11:48,286
And then it's not enough to just do this at

186
00:11:48,308 --> 00:11:51,550
a small scale, you have to be able to scale this up efficiently

187
00:11:52,850 --> 00:11:56,190
to millions and millions of data objects.

188
00:11:58,210 --> 00:12:01,794
And so if we look at some of the challenges that a vector database needs

189
00:12:01,832 --> 00:12:04,594
to solve, the first thing that it needs to do is to be able to

190
00:12:04,632 --> 00:12:08,102
store both your data objects, your unstructured data

191
00:12:08,156 --> 00:12:11,366
objects, as well as the vector representations. You have

192
00:12:11,388 --> 00:12:15,254
to be able to perform similarity search. These idea of a semantic search over

193
00:12:15,292 --> 00:12:18,754
your objects as well as a structured filtering.

194
00:12:18,802 --> 00:12:22,522
So for example, in this picture on the right hand side, let's say I wanted

195
00:12:22,576 --> 00:12:26,650
to tell my vector database to query and search through

196
00:12:26,720 --> 00:12:30,202
all of the animal objects that I've got in my database and

197
00:12:30,256 --> 00:12:34,046
tell me which one of these objects I

198
00:12:34,068 --> 00:12:37,886
can make a recipe out of. So in these case

199
00:12:37,988 --> 00:12:41,486
it would sub filter, it would do this structured filtering where

200
00:12:41,508 --> 00:12:45,218
it would exclude all of these company logos, all of these fruits out,

201
00:12:45,304 --> 00:12:49,134
and then it would allow only the animal

202
00:12:49,182 --> 00:12:52,754
objects to pass through. And then you would go through and then

203
00:12:52,792 --> 00:12:56,374
say okay, which ones can we use in a recipe? And then

204
00:12:56,492 --> 00:12:59,814
it would let the chicken pass through that filter. And then you could do some

205
00:12:59,852 --> 00:13:03,846
sort of vector search over the

206
00:13:03,868 --> 00:13:07,640
post filtered objects. And then of course

207
00:13:08,010 --> 00:13:11,194
let's say you have new data that's coming in, you have to be able

208
00:13:11,232 --> 00:13:15,002
to take that unstructured data object, turn it into a vector store.

209
00:13:15,056 --> 00:13:18,540
Both the unstructured data object as well as the vector, you have to support

210
00:13:19,230 --> 00:13:23,066
create options, you have to support delete

211
00:13:23,098 --> 00:13:25,440
options as well as update options.

212
00:13:26,290 --> 00:13:29,854
And these, the main idea is that in order to make this scalable and

213
00:13:29,892 --> 00:13:33,166
efficient, you have to implement a nearest neighbor's algorithm,

214
00:13:33,278 --> 00:13:34,980
which we'll talk about in a second.

215
00:13:36,630 --> 00:13:40,686
So when we're vectorizing data, when we're vectorizing images

216
00:13:40,718 --> 00:13:44,658
or natural language, we use machine learning for that. And usually

217
00:13:44,744 --> 00:13:48,406
those are neural network or deep learning models. And you

218
00:13:48,428 --> 00:13:51,526
can use any open source model or any one

219
00:13:51,548 --> 00:13:54,178
of the companies that we've partnered with, for example cohere,

220
00:13:54,194 --> 00:13:58,146
OpenAI, Google's new large language model,

221
00:13:58,268 --> 00:14:01,466
to take in your data, vectorize it,

222
00:14:01,648 --> 00:14:04,460
and then the vector database stores that data.

223
00:14:05,310 --> 00:14:08,954
So once you've done that, this is similar to what your data

224
00:14:08,992 --> 00:14:12,686
would look like. And then what we need to do is go ahead and

225
00:14:12,788 --> 00:14:15,946
query our data. So let me show you an example of what querying a vector

226
00:14:15,978 --> 00:14:20,302
database looks like. And it's quite different from something

227
00:14:20,356 --> 00:14:23,486
like a structured query language query that you would

228
00:14:23,508 --> 00:14:27,506
see. So all of the green dots on the right hand side are your data

229
00:14:27,688 --> 00:14:31,294
points that are embedded in vector space. So now let's say a user

230
00:14:31,342 --> 00:14:35,010
comes along and they have a question. We're going to take that question,

231
00:14:35,080 --> 00:14:38,950
that query, and we're going to pass it through the same machine learning model

232
00:14:39,020 --> 00:14:42,854
and create a vector for that question, which shows

233
00:14:42,892 --> 00:14:45,320
up as that red dot on the right hand side.

234
00:14:46,730 --> 00:14:50,514
And the human understandable representation

235
00:14:50,562 --> 00:14:54,186
for this query is nothing other than a word. So in

236
00:14:54,208 --> 00:14:57,850
this case, the word being kitten. So if a user comes along and

237
00:14:57,920 --> 00:15:01,162
queries your vector database with the word kitten, that word goes

238
00:15:01,216 --> 00:15:04,746
through the same machine learning model, it gets projected into vector space and it creates

239
00:15:04,778 --> 00:15:08,766
that red dot. And the act of vector searching over

240
00:15:08,868 --> 00:15:12,446
your vector space is essentially the act of

241
00:15:12,548 --> 00:15:15,886
going through and saying, which green dots are the closest

242
00:15:15,918 --> 00:15:19,106
to my pink dot over here? And then the closest ones. Let's say the

243
00:15:19,128 --> 00:15:23,566
user wanted the top three closest vectors

244
00:15:23,758 --> 00:15:27,078
that are in my database. It's going to go through and pick

245
00:15:27,164 --> 00:15:30,582
the closest three green dots to my pink dot and return

246
00:15:30,636 --> 00:15:33,846
those to the user in the

247
00:15:33,868 --> 00:15:37,830
corresponding images or text for those dots.

248
00:15:39,930 --> 00:15:43,254
In reality, we don't actually go through and do

249
00:15:43,292 --> 00:15:46,634
a brute force search where we compare the distance of the pink dot to every

250
00:15:46,672 --> 00:15:49,914
other green dot. That would take hours and hours depending on how much data you

251
00:15:49,952 --> 00:15:53,630
have. What we do instead of doing

252
00:15:53,780 --> 00:15:57,294
a full brute force nearest neighbor search is what's known as

253
00:15:57,332 --> 00:16:01,230
a ann, an approximate nearest neighbor search. And the idea

254
00:16:01,300 --> 00:16:05,006
behind this is that instead of searching through all

255
00:16:05,028 --> 00:16:08,114
of the green objects that you have in your database, you kind of set up

256
00:16:08,152 --> 00:16:11,602
a hierarchy of layers over here where you enter

257
00:16:11,656 --> 00:16:15,762
your search at the very top and you look through a very small

258
00:16:15,816 --> 00:16:19,078
subset of all of your objects that

259
00:16:19,084 --> 00:16:23,554
you have in your vector database. And then as you go down this hierarchy

260
00:16:23,602 --> 00:16:26,806
of search, you search over more and more data points.

261
00:16:26,988 --> 00:16:31,222
And so in order to get to the final nearest neighbors, it takes a significantly

262
00:16:31,286 --> 00:16:34,986
smaller amount of time. You have to do significantly less comparisons and

263
00:16:35,008 --> 00:16:38,186
compute. The advantage here is that you can

264
00:16:38,208 --> 00:16:42,186
search over hundreds of millions of objects without actually having to do hundreds

265
00:16:42,218 --> 00:16:45,914
of millions of distance computations. The disadvantage

266
00:16:45,962 --> 00:16:49,934
over here is the a in this algorithm's name,

267
00:16:49,972 --> 00:16:53,234
it's approximate, so you're not guaranteed to get the

268
00:16:53,272 --> 00:16:56,900
closest nearest neighbors. For that, you would have to do a brute force search.

269
00:16:58,230 --> 00:17:01,886
But given the amount of time that we save doing approximate nearest

270
00:17:01,918 --> 00:17:05,206
neighbors, this is the

271
00:17:05,228 --> 00:17:08,722
only way to reliably do vector

272
00:17:08,786 --> 00:17:12,994
search at scale. You have to have some sort of approximate algorithm

273
00:17:13,042 --> 00:17:15,510
that can search over all of your data objects.

274
00:17:17,610 --> 00:17:21,194
Okay? So with those fundamental concepts of being

275
00:17:21,232 --> 00:17:25,350
able to embed your unstructured data objects

276
00:17:25,510 --> 00:17:29,290
into vectors and then put that into your vector database and then scalably search

277
00:17:29,360 --> 00:17:33,014
over them, supporting crud operations that defines

278
00:17:33,062 --> 00:17:35,520
the foundations of what a vector database is.

279
00:17:36,050 --> 00:17:39,866
Weaviate that I'm going to introduce now is an open source vector database

280
00:17:39,978 --> 00:17:43,374
and you can try it, you can go to our website and play around

281
00:17:43,412 --> 00:17:47,246
with it. And the main idea behind Weaviate is that it understands

282
00:17:47,278 --> 00:17:50,926
your data because it vectorizes your data. It understands

283
00:17:50,958 --> 00:17:55,054
your data in this vector space and it allows you to search over

284
00:17:55,192 --> 00:17:58,840
your data in a way that it understands it.

285
00:18:01,610 --> 00:18:05,062
So I want to show you a typical vector search

286
00:18:05,116 --> 00:18:08,886
pipeline with Weaviate just to give you a center idea of how all

287
00:18:08,908 --> 00:18:10,860
of these moving pieces come together.

288
00:18:11,710 --> 00:18:15,834
So everything kind of revolves around the machine learning model,

289
00:18:16,032 --> 00:18:20,138
the machine learning model that can be open source so it can be Resnet 50

290
00:18:20,224 --> 00:18:23,902
that's widely available. It can be a model that a friend

291
00:18:23,956 --> 00:18:27,438
uploaded to hugging face and made available to the wider community. It can

292
00:18:27,444 --> 00:18:31,214
be a model that, for example, OpenAI has

293
00:18:31,332 --> 00:18:35,374
created and is an API for. So all of these models

294
00:18:35,502 --> 00:18:38,962
allow you to take your data over

295
00:18:39,016 --> 00:18:42,642
here and the data can be in whatever format the model

296
00:18:42,696 --> 00:18:46,130
understands and generate vectors for that data.

297
00:18:46,200 --> 00:18:49,826
And then you take those vectors and you pop them into VVA, and VVA stores

298
00:18:49,858 --> 00:18:53,446
both the unstructured data object as well as the

299
00:18:53,468 --> 00:18:57,138
vector representation for that object. So now let's

300
00:18:57,154 --> 00:19:00,218
say a user comes by and they have a query they want to

301
00:19:00,224 --> 00:19:03,654
search over your data using a concept.

302
00:19:03,782 --> 00:19:08,266
We're going to take that query that

303
00:19:08,288 --> 00:19:12,294
has to be in the same modality as the data modality

304
00:19:12,342 --> 00:19:15,966
that the machine learning model supports. Weve going to take that query, pass that

305
00:19:15,988 --> 00:19:19,806
through the machine learning model and generate a vector for that query similar to

306
00:19:19,828 --> 00:19:22,958
that red dot that I just showed a couple of minutes ago,

307
00:19:23,044 --> 00:19:25,460
and we're going to pop that into weve as well,

308
00:19:25,990 --> 00:19:29,730
and we're going to do a nearest neighbor search around

309
00:19:29,800 --> 00:19:33,582
that query. And depending on the results, depending on the closest

310
00:19:33,646 --> 00:19:37,462
objects that we have in our vector database, we take that and we return

311
00:19:37,516 --> 00:19:39,350
these results to the user.

312
00:19:42,010 --> 00:19:45,410
And the cool thing about Weaviate is that it's modular

313
00:19:45,490 --> 00:19:48,754
in the sense that you can go ahead and plug and play whichever

314
00:19:48,802 --> 00:19:52,026
models you want to use, whether that's your own proprietary model,

315
00:19:52,208 --> 00:19:56,026
you can plug that in, you can plug and play any one

316
00:19:56,048 --> 00:19:59,418
of the partner companies models that are available. So if you want to use an

317
00:19:59,424 --> 00:20:03,226
OpenAI model, you can plug that in. We've integrated with Google's Palm

318
00:20:03,258 --> 00:20:06,654
model that was released just last week.

319
00:20:06,852 --> 00:20:09,982
You can vectorize your data using that model.

320
00:20:10,116 --> 00:20:14,020
You just have to specify which model you want to use. The other option

321
00:20:14,630 --> 00:20:18,354
that's also popular is you can bring your data pre vectorized to

322
00:20:18,392 --> 00:20:20,660
us and then we can store that into weve eight.

323
00:20:22,550 --> 00:20:25,986
The different data modalities that we support are limited only

324
00:20:26,008 --> 00:20:29,926
by what the machine learning model understands. So if you have a machine learning model

325
00:20:30,028 --> 00:20:33,602
that understands image, video, audio,

326
00:20:33,746 --> 00:20:37,394
all of these different data modalities, you can take all of those different data modalities,

327
00:20:37,442 --> 00:20:41,160
vectorize it using the model, and plug it into vv eight.

328
00:20:43,230 --> 00:20:46,906
Probably one of the things that I'm most interested about is what happens when you

329
00:20:46,928 --> 00:20:50,442
take the results, the list of results that are the closest in vector space.

330
00:20:50,576 --> 00:20:54,346
What can you do with them? And weaviate supports this modular output

331
00:20:54,458 --> 00:20:58,078
where instead of just displaying the results, you can pipe them

332
00:20:58,164 --> 00:21:01,914
through any other functionality so you can re rank

333
00:21:01,962 --> 00:21:05,582
them. You can do some question answering with them. You can

334
00:21:05,636 --> 00:21:09,038
even pass them to a large language model like Chat

335
00:21:09,054 --> 00:21:12,338
GPT, which is a really interesting application

336
00:21:12,424 --> 00:21:15,154
that a lot of people are interested in. So I'm going to dive into that

337
00:21:15,192 --> 00:21:17,350
a little bit over the next few slides.

338
00:21:18,090 --> 00:21:21,958
So the main idea behind this is we want to use vector search,

339
00:21:22,044 --> 00:21:25,670
this idea of searching over hundreds of millions of data,

340
00:21:25,740 --> 00:21:29,922
unstructured data objects, and returning the most relevant data objects.

341
00:21:29,986 --> 00:21:33,226
And instead of showing the results to you, we send them off to

342
00:21:33,248 --> 00:21:36,746
a large language model. And the whole idea behind this is that you

343
00:21:36,768 --> 00:21:40,380
prompt a large language model and you say, answer this question,

344
00:21:40,690 --> 00:21:44,234
given the information that is returned by a vector database.

345
00:21:44,282 --> 00:21:48,554
So the information returned by a vector database provides

346
00:21:48,602 --> 00:21:52,270
relevant context that the large language model can then use

347
00:21:52,340 --> 00:21:54,690
in formulating a response to your prompt.

348
00:21:56,470 --> 00:22:00,462
And so imagine you have a browser of Chat GPT

349
00:22:00,526 --> 00:22:04,306
open. You would say, answer my question. Whatever your question is, you would type it

350
00:22:04,328 --> 00:22:07,642
in, and then you would say, the vector database

351
00:22:07,726 --> 00:22:11,366
returns all of this relevant information that you need to know.

352
00:22:11,388 --> 00:22:15,154
And you say, here's everything relevant that you need to know to answer my original

353
00:22:15,202 --> 00:22:18,466
question. And so now the workflow

354
00:22:18,498 --> 00:22:21,946
for asking your Chat GPT model, a prompt is a

355
00:22:21,968 --> 00:22:25,382
bit different, where you can say you have a prompt

356
00:22:25,446 --> 00:22:29,306
that comes in, you pass it to your large language model,

357
00:22:29,408 --> 00:22:32,890
but instead of just letting it rely on its general knowledge

358
00:22:32,970 --> 00:22:36,794
of information, you also pass it relevant documents

359
00:22:36,842 --> 00:22:40,574
or relevant information. Usually how I've seen

360
00:22:40,612 --> 00:22:44,314
people solve this problem is they go through, they see whatever

361
00:22:44,372 --> 00:22:48,194
information is relevant, they copy paste that and they

362
00:22:48,232 --> 00:22:52,050
pass it along with the prompt into the same window.

363
00:22:52,630 --> 00:22:56,006
The problem with that is that there's only a limited amount of information that you

364
00:22:56,028 --> 00:22:59,590
can copy paste in. And the other problem with that is

365
00:22:59,740 --> 00:23:03,682
you have to do all of the relevant information identification

366
00:23:03,746 --> 00:23:07,366
and filtering yourself. So imagine you've got

367
00:23:07,468 --> 00:23:11,074
thousands of documents here and only some are relevant

368
00:23:11,122 --> 00:23:14,602
to the prompt that you're asking. You have to sit there and go through

369
00:23:14,656 --> 00:23:17,478
each one at a time and say, this is relevant. That's not relevant.

370
00:23:17,574 --> 00:23:21,126
Once you're done this, you'll have a subset of the relevant filtered

371
00:23:21,158 --> 00:23:24,522
documents. Then you can go ahead and pass the prompt

372
00:23:24,586 --> 00:23:27,786
over to your large language model along with the documents

373
00:23:27,818 --> 00:23:30,160
that you filtered over that you copy paste in.

374
00:23:31,330 --> 00:23:34,702
But if you think about what the point of the user is over here,

375
00:23:34,756 --> 00:23:37,986
they're just performing similarity search over your documents. They're reading the

376
00:23:38,008 --> 00:23:41,842
documents one by one. They have some concept that they're looking for,

377
00:23:41,976 --> 00:23:44,882
whether it's present in the documents, and then if it is, it goes through.

378
00:23:44,936 --> 00:23:48,678
If not, it gets rejected. It's not going to end up in

379
00:23:48,684 --> 00:23:52,146
the list of relevant documents. That's exactly what a vector

380
00:23:52,178 --> 00:23:55,590
database excels at. So if we want to scale these approach,

381
00:23:55,930 --> 00:23:59,466
we can replace that user that was sitting there and filtering our

382
00:23:59,488 --> 00:24:03,254
documents with a vector database. And the vector database,

383
00:24:03,302 --> 00:24:06,598
its main job is to house hundreds of millions

384
00:24:06,614 --> 00:24:09,990
of documents and search over them to provide relevant,

385
00:24:10,070 --> 00:24:12,830
the most relevant ones that are relevant to your prompt.

386
00:24:13,650 --> 00:24:16,766
And in the demonstration that I'll show, I'll actually show you a

387
00:24:16,788 --> 00:24:20,106
demonstration of how I'll have 100,000 objects that are stored

388
00:24:20,138 --> 00:24:23,658
in my vector database. I'll provide it

389
00:24:23,684 --> 00:24:27,346
some context to query over those documents. And then I'll filter the

390
00:24:27,368 --> 00:24:31,474
documents and send it to a large language model and then use generative search

391
00:24:31,592 --> 00:24:32,850
over the documents.

392
00:24:35,270 --> 00:24:37,720
And so in the example that I'll show you,

393
00:24:38,410 --> 00:24:42,150
I'm using Weaviate. The cool thing about Weaviate is that we've implemented

394
00:24:42,810 --> 00:24:46,294
an endpoint whereby you can pass in all

395
00:24:46,332 --> 00:24:49,814
the documents and then instead of returning the results, you can

396
00:24:49,852 --> 00:24:54,022
say, take these results that Weaviate returns these filtered relevant documents

397
00:24:54,166 --> 00:24:58,026
and send them to a large language model. And what you see at the end

398
00:24:58,048 --> 00:25:01,370
of that is the generated text as a result

399
00:25:01,440 --> 00:25:05,054
of the answer. So you see the customized response that the large

400
00:25:05,092 --> 00:25:08,206
language model is going to provide to your prompt as

401
00:25:08,228 --> 00:25:10,640
well as the relevant documents that you've passed in.

402
00:25:12,290 --> 00:25:15,554
So that's a lot of talking from my side. So what I want to do

403
00:25:15,592 --> 00:25:18,834
is I want to go over a short demo that

404
00:25:18,872 --> 00:25:21,650
shows you the power of vector databases and what they enable.

405
00:25:23,750 --> 00:25:24,500
Okay,

406
00:25:27,640 --> 00:25:30,916
so let me

407
00:25:30,938 --> 00:25:34,308
go into my Jupyter notebooks ide

408
00:25:34,394 --> 00:25:36,932
over here. Let's start off all the way at the top.

409
00:25:37,066 --> 00:25:41,216
So to get this demo working you're

410
00:25:41,248 --> 00:25:44,808
going to need the Python Weaviate client. You're also going to

411
00:25:44,814 --> 00:25:47,370
need to go to the link to download the data.

412
00:25:48,300 --> 00:25:51,930
And then the other thing that you're going to need is to go to

413
00:25:52,460 --> 00:25:55,836
weaviate cloud services over here and

414
00:25:55,858 --> 00:25:58,828
then log in and you're going to need to create a cluster. So these is

415
00:25:58,834 --> 00:26:02,408
a remote cluster, a remote instance of weaviate

416
00:26:02,424 --> 00:26:05,840
that is going to store your data and then perform vector search over it.

417
00:26:05,910 --> 00:26:09,616
I've already created this cluster over here and you

418
00:26:09,638 --> 00:26:13,884
can see that I've already uploaded about 100,000 unstructured

419
00:26:13,932 --> 00:26:16,800
data objects in there ready for us to query.

420
00:26:18,420 --> 00:26:21,892
So we're going to go in here and then we're going to go in,

421
00:26:21,946 --> 00:26:25,296
import our Python Weaviate client.

422
00:26:25,408 --> 00:26:29,396
The other thing we're going to need to provide is a WCS token. So the

423
00:26:29,418 --> 00:26:33,188
WCS token is important because once you create your cluster,

424
00:26:33,364 --> 00:26:37,064
if you enable authentication over here, you'll see that you have a

425
00:26:37,102 --> 00:26:40,648
token that you're going to need to provide to be able to remotely hook into

426
00:26:40,814 --> 00:26:44,620
that instance. So over here this token

427
00:26:45,680 --> 00:26:48,808
is provided from these console.

428
00:26:48,904 --> 00:26:53,070
And then if you're using any third party machine learning models to vectorize your data

429
00:26:53,440 --> 00:26:57,484
or query your data, you're also going to need to provide API

430
00:26:57,532 --> 00:27:01,388
keys for them. So here I've provided the relevant keys

431
00:27:01,484 --> 00:27:05,410
and then once the client is ready

432
00:27:05,940 --> 00:27:09,796
it'll print out. True. So a

433
00:27:09,818 --> 00:27:13,904
little bit about the 100,000 objects that I've uploaded, these are just Wikipedia

434
00:27:13,952 --> 00:27:17,360
articles that weve chunked up into paragraphs

435
00:27:17,520 --> 00:27:21,076
and weve got a bunch of metadata around them. So for example, we have the

436
00:27:21,098 --> 00:27:24,872
id for the Wikipedia article, the title, and then we have the actual text

437
00:27:24,926 --> 00:27:28,456
from the paragraph, the URL, the wiki id, so on

438
00:27:28,478 --> 00:27:31,736
and so forth. We're going to take all this data and

439
00:27:31,758 --> 00:27:34,984
we're going to batch it and upload it to our remote

440
00:27:35,032 --> 00:27:36,780
instance that we just created.

441
00:27:37,920 --> 00:27:41,148
Before we can do that, we have to create a database schema that

442
00:27:41,234 --> 00:27:44,936
lets weaviate know what data is coming in, how we vectorize

443
00:27:44,968 --> 00:27:48,176
it. So to do that we define a class and we give

444
00:27:48,198 --> 00:27:52,050
it a name. So these are going to be Wikipedia articles, a description over these

445
00:27:52,660 --> 00:27:56,192
and then we specify the vectorizer. So because our data is

446
00:27:56,246 --> 00:27:59,908
text, we want to vectorize text. So we use a specific

447
00:27:59,994 --> 00:28:03,764
text to vec machine learning model. In this particular case,

448
00:28:03,802 --> 00:28:07,088
this is a multilingual model and that's

449
00:28:07,104 --> 00:28:10,608
going to be very advantageous later down the road. So I'll come back to that

450
00:28:10,634 --> 00:28:14,410
in a second. We're also going to specify exactly

451
00:28:15,500 --> 00:28:18,772
the distance metric that we want to use when we're

452
00:28:18,836 --> 00:28:21,864
conducting vector search. So in this case it's going to be a dot product.

453
00:28:21,982 --> 00:28:25,804
So when it's comparing how far away your query vector is

454
00:28:25,922 --> 00:28:29,612
from all the other vectors, it's going to conduct a drop product between

455
00:28:29,666 --> 00:28:33,016
those two vectors to find out which two data points are closer

456
00:28:33,048 --> 00:28:36,912
together, which ones are farther apart, and then we go in and we name

457
00:28:36,966 --> 00:28:40,976
all of our properties over here. So we've got the text of

458
00:28:40,998 --> 00:28:45,292
the Wikipedia article, we've got the title, the URL, the metadata

459
00:28:45,436 --> 00:28:49,252
that we went through in our pandas data frame. So once

460
00:28:49,306 --> 00:28:53,044
we're ready with the schema, we're going to go ahead and create

461
00:28:53,082 --> 00:28:57,764
the schema and then we go ahead and batch upload data into

462
00:28:57,802 --> 00:29:00,960
EVA. So we're going to start off, and we're

463
00:29:01,460 --> 00:29:05,510
going to say start off with a batch size of 100. So upload 100

464
00:29:05,880 --> 00:29:09,296
article paragraphs at a time and then we'll set this to dynamic

465
00:29:09,328 --> 00:29:12,620
so that this can increase over time if necessary.

466
00:29:13,520 --> 00:29:16,972
And then we're going to go in and loop through our

467
00:29:17,026 --> 00:29:20,396
data and upload 100 objects at

468
00:29:20,418 --> 00:29:24,364
a time. So this takes some time.

469
00:29:24,402 --> 00:29:27,480
So in prep for this demo, I've already uploaded all of

470
00:29:27,490 --> 00:29:30,864
that data and you can see that all

471
00:29:30,902 --> 00:29:34,096
100,000 uploaded correctly. Once the data is in there,

472
00:29:34,118 --> 00:29:36,848
you want to do a quick check to make sure that you've got all of

473
00:29:36,854 --> 00:29:40,468
the unstructured data objects are registered and counted for. The way

474
00:29:40,474 --> 00:29:43,700
you can do that is just by doing this simple query and

475
00:29:43,770 --> 00:29:47,476
counting how many objects there are. There's 100,000. Another way

476
00:29:47,498 --> 00:29:51,648
to verify that is, as I showed, if you go into the console,

477
00:29:51,744 --> 00:29:55,064
you'll see how many objects you've got in here using

478
00:29:55,102 --> 00:29:58,616
this object count. So now that all of

479
00:29:58,638 --> 00:30:01,192
our data is in these, I want to go through and show you these different

480
00:30:01,246 --> 00:30:04,604
ways that you can search over your data. And I'm going to start off

481
00:30:04,642 --> 00:30:08,536
with the way that I started this talk with classic

482
00:30:08,568 --> 00:30:12,684
word search. So this is boring old word search where I'm going to go

483
00:30:12,722 --> 00:30:17,148
in and create a filter where I'm

484
00:30:17,164 --> 00:30:20,450
going to look for a specific word in the titles property

485
00:30:21,460 --> 00:30:25,264
of my objects in my vector database and I provide in

486
00:30:25,302 --> 00:30:28,688
the exact word that I want to match. And then I'm going

487
00:30:28,694 --> 00:30:32,736
to print out only the first one. So I slice out and I print

488
00:30:32,768 --> 00:30:36,356
out the first object that it finds. So for

489
00:30:36,378 --> 00:30:38,964
example, if I go ahead and if I do a word search for the word

490
00:30:39,002 --> 00:30:42,244
avocado, it matches with the word avocado that's

491
00:30:42,292 --> 00:30:46,260
found in this document, that's in the title, and it returns

492
00:30:46,420 --> 00:30:50,216
this text from that Wikipedia paragraph, I can

493
00:30:50,238 --> 00:30:54,184
go ahead and do the same word search for data science and it goes

494
00:30:54,222 --> 00:30:57,532
ahead and it matches the word data science over here with a string in between,

495
00:30:57,586 --> 00:31:01,276
and it returns this. So nothing exciting, nothing interesting.

496
00:31:01,458 --> 00:31:04,760
But notice what happens when I do a word search for fast animals.

497
00:31:04,840 --> 00:31:08,176
Supposedly I'm looking for all the different or one

498
00:31:08,198 --> 00:31:11,744
of the paragraphs that describes a fast animal. It goes ahead and

499
00:31:11,782 --> 00:31:14,832
gives me this error, and the code is not wrong,

500
00:31:14,886 --> 00:31:18,336
the implementation is wrong. The problem here is that if

501
00:31:18,358 --> 00:31:22,080
I take away this word search function and I show you the actual query,

502
00:31:22,240 --> 00:31:26,084
I go ahead and I do a value string of

503
00:31:26,122 --> 00:31:28,740
fast animal and it looks for this string.

504
00:31:29,800 --> 00:31:33,204
What I actually get back is an empty

505
00:31:33,252 --> 00:31:37,304
list. And the reason why is because nowhere in my 100,000 objects do

506
00:31:37,342 --> 00:31:40,324
I find this string fast space animal.

507
00:31:40,452 --> 00:31:43,560
And that's one of the downfalls of keyword search that I was showing you before.

508
00:31:43,630 --> 00:31:47,196
If the actual string does not exist, you get nothing back.

509
00:31:47,298 --> 00:31:51,100
The database doesn't understand what you're trying to ask for. It doesn't understand the data,

510
00:31:51,250 --> 00:31:54,408
so you don't get this back. So now what I want to show you

511
00:31:54,434 --> 00:31:57,536
is with vector search or semantic search, you can really

512
00:31:57,558 --> 00:32:00,848
remedy this problem really quickly with semantic search.

513
00:32:00,934 --> 00:32:05,072
What we want to do instead is go over and

514
00:32:05,206 --> 00:32:08,768
search for a concept. Instead of searching for a value string or

515
00:32:08,774 --> 00:32:12,164
a keyword search, we want to search for a concept and

516
00:32:12,202 --> 00:32:15,696
that concept is going to be vectorized and we look for the closest concepts.

517
00:32:15,808 --> 00:32:18,228
So we have a parameter here,

518
00:32:18,314 --> 00:32:21,524
concept, and we're going to go through. And one

519
00:32:21,562 --> 00:32:25,290
other thing that's important here is we're going to call the near text search.

520
00:32:25,820 --> 00:32:29,636
It's going to go through and it looks for the text objects

521
00:32:29,668 --> 00:32:33,004
that are the closest to my query object over here

522
00:32:33,042 --> 00:32:39,016
that I'm providing. And I also limit the return to three because it'll

523
00:32:39,048 --> 00:32:43,368
be nicer to look at, it won't overpopulate

524
00:32:43,544 --> 00:32:46,624
the page in front of me. So I'm going to only return the three most

525
00:32:46,662 --> 00:32:50,480
relevant results, the three vectors that are the closest to my query vector.

526
00:32:50,900 --> 00:32:54,800
And then I have a function that's going to format and style this nicely.

527
00:32:55,540 --> 00:32:59,844
Let's say I go through and I search for this

528
00:32:59,882 --> 00:33:02,996
concept, a programming language used for machine learning.

529
00:33:03,178 --> 00:33:06,820
And the first result, the closest vector

530
00:33:07,160 --> 00:33:10,776
to my query vector is python, and then it's c plus plus and then

531
00:33:10,798 --> 00:33:14,584
central processing unit. And if you look at what we're doing here,

532
00:33:14,622 --> 00:33:17,656
we're literally just typing and chatting with our

533
00:33:17,678 --> 00:33:21,688
vector database. I queried it using this concept

534
00:33:21,784 --> 00:33:25,484
programming language used for machine learning, and it realized even

535
00:33:25,522 --> 00:33:29,756
though the exact string was nowhere to be found in

536
00:33:29,938 --> 00:33:33,636
any of these texts, it found the closest concept

537
00:33:33,768 --> 00:33:37,088
to what I was asking and it returned that. And that's the

538
00:33:37,094 --> 00:33:40,704
power of vector databases. You can never do this with a

539
00:33:40,822 --> 00:33:44,476
structured or unstructured regular SQL

540
00:33:44,508 --> 00:33:48,096
NoSQL database. The only way that you can do

541
00:33:48,118 --> 00:33:51,620
this is if your vector database understands your data as well as

542
00:33:51,690 --> 00:33:55,604
the query what you're asking for. And it has a way to quantify how

543
00:33:55,642 --> 00:33:59,504
similar or dissimilar those two things are, which a vector database

544
00:33:59,632 --> 00:34:02,760
exactly does. That's the main power of a vector database.

545
00:34:03,580 --> 00:34:07,384
Again, if I go back to my original query of fast animals and I

546
00:34:07,422 --> 00:34:10,916
conduct a vector search now, now it gives me relevant answers,

547
00:34:10,948 --> 00:34:14,620
right? So it goes through and it vectorizes fast animals and it realizes that

548
00:34:14,690 --> 00:34:18,216
a gazelle, a cheetah and a bobcat are fast animals,

549
00:34:18,328 --> 00:34:21,644
because when I vectorized these objects, there was

550
00:34:21,682 --> 00:34:26,288
some mention or it understood that these

551
00:34:26,374 --> 00:34:29,452
unstructured definitions, text definitions,

552
00:34:29,516 --> 00:34:33,200
are affiliated with fast objects. It could be mentioned somewhere

553
00:34:33,860 --> 00:34:37,040
in the object itself, or so on and so forth.

554
00:34:38,500 --> 00:34:41,716
And this is the power of vector databases. And if

555
00:34:41,738 --> 00:34:45,172
you remember, I told you that this was a multilingual model

556
00:34:45,226 --> 00:34:48,756
that we were using to vectorize our data. And that means that

557
00:34:48,778 --> 00:34:52,484
you can query it in any language that you want. So here I've

558
00:34:52,532 --> 00:34:56,356
queried it with, this means great movies in Chinese

559
00:34:56,468 --> 00:35:00,760
and it comes back and it shows me the most relevant

560
00:35:02,240 --> 00:35:06,300
data objects that I've stored in here. So, got goodfellas, totally spies.

561
00:35:06,880 --> 00:35:09,996
You can also query in Hindi. So this is

562
00:35:10,098 --> 00:35:13,080
the same query, great movies in Hindi,

563
00:35:13,160 --> 00:35:16,160
you get Schindler's list, the Dark Knight.

564
00:35:16,740 --> 00:35:20,604
So this is quite powerful. The flexibility of your vector database

565
00:35:20,652 --> 00:35:24,960
is only limited by the modalities and

566
00:35:25,030 --> 00:35:28,820
data types that your machine learning model understands and can vectorize.

567
00:35:31,640 --> 00:35:35,060
And again, vacation spots. This is in Farsi and it

568
00:35:35,130 --> 00:35:38,676
understands that as well. For the

569
00:35:38,698 --> 00:35:42,004
next part here, what I want to show you is this idea of generative

570
00:35:42,052 --> 00:35:45,384
search, searching over your vector database and then instead of just

571
00:35:45,422 --> 00:35:49,284
returning the results to you, piping those to a large language

572
00:35:49,332 --> 00:35:52,960
model, and then providing those results

573
00:35:53,060 --> 00:35:56,472
as context to the large language model so that it can answer a query

574
00:35:56,536 --> 00:35:59,912
or a prompt using those documents

575
00:35:59,976 --> 00:36:03,708
as context. So the context that I'm going to provide

576
00:36:03,794 --> 00:36:07,064
here is going to be from this return query.

577
00:36:07,112 --> 00:36:10,924
So I do a semantic search over my vector database for famous basketball players

578
00:36:10,972 --> 00:36:14,076
and it returns to me three famous basketball players. You've got Will Chamberlain,

579
00:36:14,108 --> 00:36:17,584
Magic Johnson and Will Chamberlain. The reason why it repeats

580
00:36:17,632 --> 00:36:21,556
will Chamberlain here is because the same Wikipedia article can

581
00:36:21,578 --> 00:36:25,332
be chunked multiple times. So I've got different paragraphs from the exact

582
00:36:25,386 --> 00:36:28,768
same Wikipedia article. So now what I'm

583
00:36:28,784 --> 00:36:32,216
going to do is instead of show you the results of this query, I'm going

584
00:36:32,238 --> 00:36:35,636
to tell Weaviate to take these results,

585
00:36:35,748 --> 00:36:38,888
send them to OpenAI's large language model,

586
00:36:39,054 --> 00:36:42,860
answer a question reading these results, and then

587
00:36:42,930 --> 00:36:46,136
give me the generated text back. And this process is known

588
00:36:46,168 --> 00:36:50,620
as generative search or retrieval augmented

589
00:36:51,280 --> 00:36:54,990
generation. So here

590
00:36:55,680 --> 00:36:59,168
the interesting thing that I want to do is this is the prompt that

591
00:36:59,174 --> 00:37:02,576
I would give to chat CPT. So I want it to

592
00:37:02,598 --> 00:37:06,028
write me some interview questions that I can ask. So this is something funny that's

593
00:37:06,044 --> 00:37:10,044
going on here that I'll explain in a bit that I can ask title

594
00:37:10,172 --> 00:37:13,876
and also how title would answer them. Here's some information about them.

595
00:37:13,898 --> 00:37:17,476
And then I've got text in here. So to understand where these titles and

596
00:37:17,498 --> 00:37:21,144
text come from, let's look at the actual query here.

597
00:37:21,262 --> 00:37:25,032
I start off and I query my client and I say that I want to

598
00:37:25,166 --> 00:37:28,596
do a near text search where the concept is famous

599
00:37:28,628 --> 00:37:31,992
basketball players. And this will return something

600
00:37:32,046 --> 00:37:35,944
like this that I've shown here. And what I want to extract

601
00:37:35,992 --> 00:37:39,644
from this is the title as well as the

602
00:37:39,682 --> 00:37:43,116
text. So it's going to give me the title of the Wikipedia article which

603
00:37:43,138 --> 00:37:46,844
is shown here as an example. And these the text of the Wikipedia article

604
00:37:46,892 --> 00:37:50,956
which as an example I've highlighted over here. And instead of showing

605
00:37:50,988 --> 00:37:54,188
you the returned objects,

606
00:37:54,284 --> 00:37:58,464
I am going to pass them over to the generative

607
00:37:58,512 --> 00:38:02,230
model using the with generate command here.

608
00:38:03,480 --> 00:38:07,700
And so in this case what happens is the title gets replaced with

609
00:38:07,770 --> 00:38:11,844
whatever title was returned by the vector database. The text here gets replaced

610
00:38:11,892 --> 00:38:15,108
with whatever text was returned by the vector database.

611
00:38:15,204 --> 00:38:18,744
And that creates the whole prompt. And that prompt gets sent to the large

612
00:38:18,782 --> 00:38:22,564
language model. And this single prompt

613
00:38:22,692 --> 00:38:26,188
parameter that I've provided here essentially makes it so that every single

614
00:38:26,274 --> 00:38:29,384
data object that the vector database returned gets passed

615
00:38:29,432 --> 00:38:33,036
one by one to the large language model. And then you get

616
00:38:33,138 --> 00:38:36,268
the equivalent number of responses back that you can show.

617
00:38:36,354 --> 00:38:39,776
So here I'm just going to show you one of the responses back. So if

618
00:38:39,798 --> 00:38:43,164
we scroll down here, you can see that the relevant

619
00:38:43,212 --> 00:38:47,030
context that was provided was Will Chamberlain and

620
00:38:48,920 --> 00:38:52,836
the text for this Wikipedia article title. And then the

621
00:38:52,858 --> 00:38:56,596
generated text that I got back from OpenAI was what was

622
00:38:56,618 --> 00:39:00,520
your biggest challenge as a basketball player? So it's essentially made a question answer

623
00:39:00,590 --> 00:39:04,136
session where I ask questions to will Chamberlain and

624
00:39:04,158 --> 00:39:07,496
he responds based on what

625
00:39:07,518 --> 00:39:11,204
the large language model understands of the context that I provided

626
00:39:11,252 --> 00:39:14,972
it. So this is the power of generative search that

627
00:39:15,026 --> 00:39:17,944
comes built in with weaviate.

628
00:39:18,072 --> 00:39:21,468
And this is just one query that I can do all of

629
00:39:21,474 --> 00:39:25,308
this with. The other interesting thing that

630
00:39:25,314 --> 00:39:28,848
I can do is I can say write me a heroic tale about,

631
00:39:28,934 --> 00:39:32,828
again, take the results from the vector database and then pipe

632
00:39:32,844 --> 00:39:36,244
them to the generative model and here's some context about them. This is the actual

633
00:39:36,282 --> 00:39:40,304
paragraph. And so it goes in and it generates

634
00:39:40,352 --> 00:39:44,612
me a story about will Chamberlain and

635
00:39:44,666 --> 00:39:48,416
all of the context that's provided here. It comes from the general knowledge

636
00:39:48,448 --> 00:39:52,024
of the general knowledge of the large language model

637
00:39:52,142 --> 00:39:55,716
as well as these context that the text and title that the vector database

638
00:39:55,748 --> 00:39:56,890
provided it with.

639
00:39:59,020 --> 00:40:02,184
Another interesting thing that you can do is instead of

640
00:40:02,222 --> 00:40:06,300
passing in one of the unstructured objects at a time and generating

641
00:40:07,040 --> 00:40:10,588
a prompt result using one object at a time, you can group all of

642
00:40:10,594 --> 00:40:14,160
the objects that the vector database returns and pass these all together

643
00:40:14,230 --> 00:40:18,290
to your large language model to answer a more complicated question.

644
00:40:19,380 --> 00:40:23,548
So for example here, my question to Chachi

645
00:40:23,564 --> 00:40:27,728
Bt is which of these basketball players mentioned in text

646
00:40:27,814 --> 00:40:31,236
is the most accomplished? And it has to choose at

647
00:40:31,258 --> 00:40:35,156
least one and explain why. And the titles and the text here are going

648
00:40:35,178 --> 00:40:39,216
to be replaced by 15 of the retrieved documents that we v eight returns

649
00:40:39,248 --> 00:40:42,928
to me. And so here I go through

650
00:40:43,114 --> 00:40:47,060
and I'm going to show you the articles that were provided as context.

651
00:40:47,220 --> 00:40:50,356
First of all, so these are the names of the articles that we provided,

652
00:40:50,388 --> 00:40:53,564
the large language model as context. And then

653
00:40:53,602 --> 00:40:56,892
this is the answer that the

654
00:40:56,946 --> 00:41:00,590
large language model provided to us. So all the way over here

655
00:41:01,040 --> 00:41:04,812
and it shows that Will Chamberlain was

656
00:41:04,866 --> 00:41:08,656
the greatest basketball player, the most accomplished basketball player. And it

657
00:41:08,678 --> 00:41:12,336
explains why, given the context of information of not

658
00:41:12,358 --> 00:41:16,176
just will Chamberlain but all of the other basketball players that

659
00:41:16,278 --> 00:41:18,790
we asked it to compare Will Chamberlain against.

660
00:41:20,840 --> 00:41:24,388
And then one last example here, kind of got excited when

661
00:41:24,394 --> 00:41:27,668
I was putting this together. I go ahead and I say,

662
00:41:27,754 --> 00:41:31,684
give me five famous basketball players.

663
00:41:31,812 --> 00:41:35,428
Weve goes and searches over my Wikipedia documents.

664
00:41:35,524 --> 00:41:39,096
It returns the titles for those basketball players as well

665
00:41:39,118 --> 00:41:42,708
as the context, the paragraph for those basketball players.

666
00:41:42,884 --> 00:41:46,776
And then I ask story

667
00:41:46,878 --> 00:41:51,132
of tell me a story where these people, all these basketball players fight

668
00:41:51,186 --> 00:41:54,664
each other and then I give it context. I give it information that the vector

669
00:41:54,712 --> 00:41:58,160
database returned to me and I pass that in over here.

670
00:41:58,310 --> 00:42:01,776
And so if we look at the results now, first let's look at

671
00:42:01,798 --> 00:42:05,328
the context that was provided to Chat GPT here. So here

672
00:42:05,414 --> 00:42:08,396
we gave it the information and the name for Will Chamberlain,

673
00:42:08,428 --> 00:42:12,436
Magic Johnson. Again, a repeat of Will Chamberlain, Scottie Pippen. We also

674
00:42:12,458 --> 00:42:15,936
gave it information for James Naismith, which is what the vector database

675
00:42:15,968 --> 00:42:19,188
returns. James Naismith is not a basketball player, he's the inventor

676
00:42:19,204 --> 00:42:22,840
of basketball. But we'll let that slide for a second. Let's have a look at

677
00:42:22,910 --> 00:42:25,976
the generated story that we got.

678
00:42:26,158 --> 00:42:30,756
So in this generated story we're

679
00:42:30,788 --> 00:42:34,836
essentially customizing the response of Chad

680
00:42:34,868 --> 00:42:38,604
CPT to these context that we provided. So now the story starts off

681
00:42:38,642 --> 00:42:42,376
and it's saying that will Chamberlain and Magic Johnson were both legends,

682
00:42:42,408 --> 00:42:45,276
so on and so forth. And it tells a very intricate story.

683
00:42:45,378 --> 00:42:49,468
It's got Scottie Pippen in there and it's

684
00:42:49,484 --> 00:42:53,516
kind of pitting them against each other. And then it shows that Chamberlain stood tall,

685
00:42:53,548 --> 00:42:56,828
which it thinks that once Chamberlain is the best. So of course he's

686
00:42:56,844 --> 00:43:00,452
going to win at the end of the day. But that's the power

687
00:43:00,506 --> 00:43:04,144
of vector databases and what you can do with the inputs,

688
00:43:04,192 --> 00:43:08,052
the outputs, how you can chain them with large language models to

689
00:43:08,106 --> 00:43:11,876
get these large language models to answer your prompts

690
00:43:12,068 --> 00:43:15,160
grounded in the context that the vector database provides.

691
00:43:16,220 --> 00:43:20,768
And so this is one of the most exciting things around vector databases

692
00:43:20,964 --> 00:43:24,990
right now, where vector databases essentially act like

693
00:43:26,000 --> 00:43:29,928
long term memory for these large language models.

694
00:43:30,024 --> 00:43:33,636
They can go and retrieve ten of the most relevant documents

695
00:43:33,688 --> 00:43:37,724
to a prompt over millions of documents, and then answer your prompt,

696
00:43:37,852 --> 00:43:40,000
given that information as context.

697
00:43:42,340 --> 00:43:45,650
Okay, that's the end of my demo, so I'm going to go back

698
00:43:46,120 --> 00:43:49,110
and go over here.

699
00:43:49,800 --> 00:43:53,664
So I hope everybody enjoyed this intro to vector

700
00:43:53,712 --> 00:43:57,124
databases. If you have any questions, feel free

701
00:43:57,162 --> 00:44:00,804
to connect with me on Twitter LinkedIn. You can join our slack

702
00:44:00,852 --> 00:44:04,392
community. The entire team is around, we're happy to help.

703
00:44:04,526 --> 00:44:08,596
We'd love to get you to try and use weve

704
00:44:08,628 --> 00:44:11,690
eight. If you have any cool ideas, let us know.

705
00:44:12,460 --> 00:44:16,040
And then if you do have any questions as you're using WeV,

706
00:44:16,560 --> 00:44:20,028
feel free to shoot us a message. If you come up with anything interesting,

707
00:44:20,114 --> 00:44:23,996
if you come up with cool implementations, cool projects that

708
00:44:24,018 --> 00:44:26,910
you're using Weaviate with, give us a shout out.

709
00:44:27,680 --> 00:44:31,484
We'd love to talk to you. You can also blog about

710
00:44:31,522 --> 00:44:34,684
it. Always love to see what the community uses this open

711
00:44:34,722 --> 00:44:38,596
source tool. For me thank you to

712
00:44:38,698 --> 00:44:41,620
Con 42. This was great. I really enjoyed this,

713
00:44:41,690 --> 00:44:45,012
and I hope you guys enjoyed this as much as I did.

714
00:44:45,146 --> 00:44:46,740
Thank you, everybody. Take care.

