1
00:00:23,930 --> 00:00:27,286
Everyone, this is a gist. Today my talk is

2
00:00:27,388 --> 00:00:30,962
about how to do the traffic governance

3
00:00:31,026 --> 00:00:34,818
from your application to your database infrastructure

4
00:00:34,994 --> 00:00:38,486
on the Kubernetes. Before to answer this question

5
00:00:38,588 --> 00:00:41,862
I will raise another question and the

6
00:00:41,916 --> 00:00:45,494
most request from all of our community. That is

7
00:00:45,612 --> 00:00:49,914
how to upgrade your existing monolithic

8
00:00:50,002 --> 00:00:54,330
databases cluster. Maybe MySQL or PostgreSQL

9
00:00:54,410 --> 00:00:58,126
or Oracle or SQL silver to make those

10
00:00:58,228 --> 00:01:01,662
databases cluster become the sharding architecture or

11
00:01:01,716 --> 00:01:05,198
make it become the distributed database architecture,

12
00:01:05,294 --> 00:01:09,618
right? And then to do the traffic governance because

13
00:01:09,784 --> 00:01:13,234
in the sharding architecture the policy is

14
00:01:13,272 --> 00:01:17,406
so complicated, right? So Trista

15
00:01:17,438 --> 00:01:20,882
Pan, the Sofia yes, cofounder CTO the CTO

16
00:01:20,946 --> 00:01:24,626
my area it's around the database mesh,

17
00:01:24,738 --> 00:01:29,226
the database distributed database. About the

18
00:01:29,408 --> 00:01:33,702
database Management AI platform development

19
00:01:33,846 --> 00:01:37,562
because I'm a developer and spend a lot of my time

20
00:01:37,616 --> 00:01:41,206
and efforts in open source, especially in Apache

21
00:01:41,238 --> 00:01:45,686
Software foundation. So now I'm the mentoring

22
00:01:45,798 --> 00:01:49,818
to incubator Apache project and be the member

23
00:01:49,914 --> 00:01:53,490
of this Apache Software foundation. Sometimes I will post

24
00:01:53,560 --> 00:01:57,986
some articles or some about the business

25
00:01:58,088 --> 00:02:02,014
or startup or open source or the databases

26
00:02:02,142 --> 00:02:06,420
cloud stuff on my Twitter linking. If you are interested inside

27
00:02:06,970 --> 00:02:10,354
topics, please give a look there and let's

28
00:02:10,482 --> 00:02:14,374
discuss all the stuff there, right? So today our

29
00:02:14,412 --> 00:02:18,090
content will include the following item parts. The first

30
00:02:18,160 --> 00:02:21,526
one gave the brief introduction about background.

31
00:02:21,638 --> 00:02:25,498
A second one, light found the new requirements for the

32
00:02:25,584 --> 00:02:29,638
databases on cloud. A third one I will give the architecture

33
00:02:29,734 --> 00:02:33,582
and the solution AAS one will dive into a

34
00:02:33,636 --> 00:02:38,026
SQL lifecycle in this distributed

35
00:02:38,058 --> 00:02:41,438
database system. Then if I have enough time,

36
00:02:41,524 --> 00:02:44,830
I will give the detailed introduction about the dymo,

37
00:02:44,910 --> 00:02:48,354
right? So first part is the

38
00:02:48,392 --> 00:02:52,114
digital transformation is so popular these

39
00:02:52,152 --> 00:02:56,406
days, right? Because people really want to leverage all the

40
00:02:56,588 --> 00:03:00,614
novel technologies to upgrade their

41
00:03:00,812 --> 00:03:04,182
infrastructure or think out of

42
00:03:04,236 --> 00:03:07,946
some new ideas to service

43
00:03:08,048 --> 00:03:11,786
their customers and users efficiently and

44
00:03:11,888 --> 00:03:15,466
effectively, right? So it's not just about how

45
00:03:15,488 --> 00:03:19,450
to do the change about your infrastructure

46
00:03:20,530 --> 00:03:23,870
from the development to your delivery

47
00:03:24,210 --> 00:03:28,254
paradigm, it's also about the culture change or

48
00:03:28,372 --> 00:03:31,150
mindset. So that's a background.

49
00:03:32,470 --> 00:03:36,802
In this background, how about the database? Because all

50
00:03:36,856 --> 00:03:40,114
of the changes will raise the new

51
00:03:40,312 --> 00:03:43,134
requirements about our infrastructure,

52
00:03:43,262 --> 00:03:47,334
about our databases, and currently from our community.

53
00:03:47,452 --> 00:03:52,134
And from my experience, people have the following major

54
00:03:52,252 --> 00:03:55,926
concerns. The first one, how to manage

55
00:03:56,028 --> 00:03:59,820
and store so matches data,

56
00:04:00,270 --> 00:04:03,754
right. The second one, how to make each

57
00:04:03,952 --> 00:04:07,642
request to be answered as fast as it can.

58
00:04:07,776 --> 00:04:11,322
The third one about how to do the traffic governance.

59
00:04:11,386 --> 00:04:15,514
Because as I said before, especially in the distributed

60
00:04:15,562 --> 00:04:19,390
database system, there are complicated

61
00:04:20,050 --> 00:04:23,806
topology among your different computing nodes,

62
00:04:23,838 --> 00:04:27,134
your application and your storage nodes,

63
00:04:27,182 --> 00:04:30,962
right? So we hope that someone or

64
00:04:31,016 --> 00:04:34,674
some application platform to help us to deal with all

65
00:04:34,712 --> 00:04:38,782
of the topology and then we'll consider elastic

66
00:04:38,846 --> 00:04:41,990
scaling. That means scalability for our

67
00:04:42,060 --> 00:04:45,958
future scenarios and future data,

68
00:04:46,044 --> 00:04:49,702
right? Then if there it's out of the box

69
00:04:49,836 --> 00:04:53,514
solution or deployment or tools that will be

70
00:04:53,552 --> 00:04:57,786
perfect, right? So to answer the following questions I

71
00:04:57,808 --> 00:05:01,340
will give my answer about each of them. First,

72
00:05:01,710 --> 00:05:05,242
large data to manage and efficient acquirings in

73
00:05:05,296 --> 00:05:09,390
all of the needs. I will give the data sharding answer.

74
00:05:09,540 --> 00:05:12,994
Next one about the czech government. Based on

75
00:05:13,032 --> 00:05:16,066
the data sharding architecture we can do the

76
00:05:16,168 --> 00:05:20,114
high availability and rewrite waiting or other like

77
00:05:20,152 --> 00:05:23,410
the SQL audit or based

78
00:05:23,480 --> 00:05:27,650
on some metrics to do the traffic strategy.

79
00:05:27,730 --> 00:05:30,850
All the stuff then about elastic

80
00:05:30,930 --> 00:05:35,240
scaling. That means we can help user to research

81
00:05:35,610 --> 00:05:38,646
their computing nodes and SQLserver nodes

82
00:05:38,678 --> 00:05:42,474
of a distributed database system. Later on I will give

83
00:05:42,512 --> 00:05:45,690
some introduction about such part.

84
00:05:45,840 --> 00:05:48,966
And then thanks to the Kubernetes,

85
00:05:49,078 --> 00:05:52,862
we found that the macro service application works so well

86
00:05:52,916 --> 00:05:55,450
and effectively on the Kubernetes.

87
00:05:55,610 --> 00:05:58,880
So could we use the similar

88
00:05:59,650 --> 00:06:04,114
prems, primitives or other tools or

89
00:06:04,232 --> 00:06:07,746
use the similar mechanism on the Kubernetes to

90
00:06:07,768 --> 00:06:11,394
help us manage our databases or data is

91
00:06:11,432 --> 00:06:14,754
possible? I think it's possible because most of the

92
00:06:14,792 --> 00:06:18,022
companies are working on that way, right? All right,

93
00:06:18,076 --> 00:06:21,974
so how to do that part? How to do help us to

94
00:06:22,012 --> 00:06:25,814
include all the solutions into one and just give

95
00:06:25,852 --> 00:06:29,526
the out of the box solution to help a user to adopt

96
00:06:29,558 --> 00:06:33,386
it. Before give the solution or the answer I

97
00:06:33,408 --> 00:06:36,266
need to first give the background of database system.

98
00:06:36,368 --> 00:06:39,734
Let us see this architecture

99
00:06:39,782 --> 00:06:44,702
again to consider about the databases. Because if

100
00:06:44,756 --> 00:06:48,346
we can know the fundamental

101
00:06:48,378 --> 00:06:51,886
of the database system, then we will have the better way to

102
00:06:51,908 --> 00:06:55,506
solve the issues I mentioned before. First I

103
00:06:55,528 --> 00:06:58,882
want to say that here a database system,

104
00:06:59,016 --> 00:07:02,882
actually they made up two parts. First one

105
00:07:02,936 --> 00:07:06,262
is computing nodes, right? A second one

106
00:07:06,316 --> 00:07:09,794
is storage nodes. That means our database,

107
00:07:09,842 --> 00:07:13,138
no matter it's a distributed one or monolithic,

108
00:07:13,314 --> 00:07:16,402
they have these two parts.

109
00:07:16,466 --> 00:07:18,700
So important capabilities, right?

110
00:07:19,870 --> 00:07:23,580
But for the distributed database system, they just

111
00:07:24,590 --> 00:07:28,470
split the computing nodes and storage nodes separately

112
00:07:28,630 --> 00:07:32,122
and deploy them in different

113
00:07:32,176 --> 00:07:35,690
locations. So that means this database

114
00:07:35,770 --> 00:07:40,266
become a distributed one. But whereas

115
00:07:40,378 --> 00:07:44,302
our monolithic databases, they merge the computing

116
00:07:44,366 --> 00:07:47,970
capability and the storage capability in it together.

117
00:07:48,120 --> 00:07:52,130
So you can just one common to

118
00:07:52,200 --> 00:07:56,498
deploy this single, I mean database

119
00:07:56,594 --> 00:08:00,182
instance consisting of computing nodes and

120
00:08:00,236 --> 00:08:04,086
storage nodes together in one machine, right? That's the difference

121
00:08:04,188 --> 00:08:07,678
between the monolithic and the distributed

122
00:08:07,714 --> 00:08:11,706
databases, right? So today we will

123
00:08:11,888 --> 00:08:14,940
sync the solution in this way.

124
00:08:16,270 --> 00:08:20,086
We could consider that if we already have

125
00:08:20,128 --> 00:08:23,918
the Mysql or postgresql here, right?

126
00:08:24,004 --> 00:08:27,002
That's over your databases cluster.

127
00:08:27,066 --> 00:08:31,038
Existing database cluster, right? So could we just

128
00:08:31,124 --> 00:08:35,122
regard such monolithic database as

129
00:08:35,176 --> 00:08:38,786
the storage nodes of a new

130
00:08:38,968 --> 00:08:41,380
distributed database system,

131
00:08:41,750 --> 00:08:45,114
right? And we don't

132
00:08:45,182 --> 00:08:48,610
do any change to our existing databases,

133
00:08:48,770 --> 00:08:51,974
don't do any generous action on them,

134
00:08:52,092 --> 00:08:57,314
just import the computing nodes

135
00:08:57,442 --> 00:09:00,278
in this system, right?

136
00:09:00,364 --> 00:09:03,674
So these computing nodes can works

137
00:09:03,792 --> 00:09:06,970
as a database server, right?

138
00:09:07,120 --> 00:09:11,274
If your databases is like the MySQL

139
00:09:11,322 --> 00:09:15,134
or PostgreSQL, right? So now we can make those

140
00:09:15,252 --> 00:09:19,150
storage nodes become the local storage nodes, I mean become

141
00:09:19,220 --> 00:09:22,702
the local database instance. And we can

142
00:09:22,756 --> 00:09:27,006
just import the global computing

143
00:09:27,038 --> 00:09:30,478
nodes working as the database SQLServer.

144
00:09:30,574 --> 00:09:34,910
Then the computing nodes plus the SQLServer nodes will become

145
00:09:35,080 --> 00:09:38,774
the distributed database system, right? So in

146
00:09:38,812 --> 00:09:42,610
that way we can upgrade your existing database,

147
00:09:42,690 --> 00:09:46,022
become a distributed one. So the last part

148
00:09:46,076 --> 00:09:49,962
is sharding Sophia. Sharding Sophia. It can work at this

149
00:09:50,016 --> 00:09:53,814
role. I mean it could be work as a database proxy

150
00:09:53,862 --> 00:09:57,194
or database pretend itself

151
00:09:57,312 --> 00:10:01,520
aas a database server, like a MySQL server or

152
00:10:01,970 --> 00:10:05,374
PostgreSQL server. So if

153
00:10:05,412 --> 00:10:08,846
we import sharding Sophia here and working as a

154
00:10:08,868 --> 00:10:13,262
computing node, and it will connect to different database

155
00:10:13,406 --> 00:10:16,898
instance, that means the storage nodes of this

156
00:10:16,984 --> 00:10:20,894
new database distributed database

157
00:10:20,942 --> 00:10:24,954
system and sharding Sophia also have the governance

158
00:10:25,022 --> 00:10:29,000
node to help synchronize all of the metadata change

159
00:10:29,690 --> 00:10:33,234
among different computing nodes. I mean shirting Sophia,

160
00:10:33,362 --> 00:10:36,978
then we can by this way upgrading

161
00:10:37,074 --> 00:10:41,366
our existing monolithic MySQL cluster

162
00:10:41,478 --> 00:10:45,654
or postgres cluster become a distributed

163
00:10:45,782 --> 00:10:50,514
MySQL cluster or postgresql

164
00:10:50,662 --> 00:10:54,618
database cluster, right? Another benefit from this solution,

165
00:10:54,714 --> 00:10:58,782
that because we adopt the

166
00:10:58,916 --> 00:11:02,742
computing and storage splitting

167
00:11:02,826 --> 00:11:06,900
architecture, so we can do the

168
00:11:07,590 --> 00:11:11,858
research on computing nodes or

169
00:11:12,024 --> 00:11:15,540
storage nodes, that means sharding Sophia or

170
00:11:15,850 --> 00:11:18,850
your databases independently,

171
00:11:19,010 --> 00:11:22,822
right? At this point, if you found that you need

172
00:11:22,876 --> 00:11:26,760
more computing power, then you can just

173
00:11:27,470 --> 00:11:31,638
spin up more sharding Sophia proxy

174
00:11:31,814 --> 00:11:35,366
or sharding Sophia.

175
00:11:35,478 --> 00:11:39,462
So that means you can have more computing

176
00:11:39,526 --> 00:11:43,438
power computing nodes working in this

177
00:11:43,604 --> 00:11:45,840
distributed database system.

178
00:11:46,290 --> 00:11:50,266
But another aspect that some users

179
00:11:50,298 --> 00:11:54,158
found, they need more storage capabilities,

180
00:11:54,334 --> 00:11:58,338
then you don't spend too much time, effort money

181
00:11:58,504 --> 00:12:02,322
on such computing nodes. You can,

182
00:12:02,456 --> 00:12:06,226
I mean create more database instance,

183
00:12:06,338 --> 00:12:10,182
right? So here maybe one, two, three, maybe there are four or

184
00:12:10,236 --> 00:12:13,462
five, one. And sharding Sophia can connect

185
00:12:13,596 --> 00:12:17,462
to the new database instance. And to help you

186
00:12:17,596 --> 00:12:21,574
reshard your original data

187
00:12:21,772 --> 00:12:25,162
among one, two, true, the old and the new

188
00:12:25,216 --> 00:12:28,742
one. I mean the new storage

189
00:12:28,806 --> 00:12:32,570
nodes, your new postgresql nodes will contain

190
00:12:32,730 --> 00:12:36,490
the data and resharded by sharding Sophia.

191
00:12:36,570 --> 00:12:39,674
So that's the benefit of this solution.

192
00:12:39,802 --> 00:12:43,422
The last part let us know more about this

193
00:12:43,476 --> 00:12:47,406
row. Computing nodes Apache sharding Sophia so Apache

194
00:12:47,438 --> 00:12:50,562
sharding Sophia. Why do I say that

195
00:12:50,616 --> 00:12:53,954
it can help us do that work? Because here

196
00:12:54,072 --> 00:12:58,294
sharding Sophia is an ecosystem to transfer any

197
00:12:58,332 --> 00:13:01,570
databases into distributed databases

198
00:13:01,730 --> 00:13:05,954
and enhance it with a sharding feature, elastic skilling

199
00:13:06,002 --> 00:13:09,606
feature, data encryption feature or more,

200
00:13:09,708 --> 00:13:13,598
right? So from the slogan it looks like Trista

201
00:13:13,634 --> 00:13:16,762
pan work while and this project

202
00:13:16,896 --> 00:13:20,302
also have strong community to help us to answer

203
00:13:20,356 --> 00:13:23,966
some questions. And because now you can see here

204
00:13:24,148 --> 00:13:26,270
the statistic on GitHub,

205
00:13:27,010 --> 00:13:31,534
more than 17,000 search and

206
00:13:31,652 --> 00:13:35,586
released for nearly 15 times

207
00:13:35,768 --> 00:13:40,222
and also have more than 400 contributors

208
00:13:40,286 --> 00:13:44,194
there, right? So that means you don't worry that you will

209
00:13:44,232 --> 00:13:47,862
be the first person to use the project. You don't worry about

210
00:13:47,916 --> 00:13:49,510
the analytic,

211
00:13:51,210 --> 00:13:54,486
all about the issues about this community

212
00:13:54,588 --> 00:13:58,714
because your issue maybe has

213
00:13:58,752 --> 00:14:02,458
been found by others by this community, right? So it's a

214
00:14:02,464 --> 00:14:05,722
mature community and mature project for us

215
00:14:05,776 --> 00:14:09,226
to use. And hasten document is

216
00:14:09,408 --> 00:14:12,850
so detailed and to help us enter hasten

217
00:14:12,950 --> 00:14:16,574
concept help us to set

218
00:14:16,612 --> 00:14:19,870
up this ecosystem or the solution.

219
00:14:20,290 --> 00:14:23,802
So sharding Sophia provides two clients.

220
00:14:23,866 --> 00:14:27,626
The first one is sharding Sophia proxy, the next one sharding Sophia

221
00:14:27,658 --> 00:14:30,414
GDBC. But like I said before,

222
00:14:30,532 --> 00:14:34,446
sharding Sophia proxy it can work as the computing

223
00:14:34,478 --> 00:14:38,286
nodes Azure sharding suffer GDBC same. But today we will sharding

224
00:14:38,318 --> 00:14:42,646
Sophia proxy do our demo show. And so you can see here

225
00:14:42,828 --> 00:14:46,306
shorting CV proxy can visits MysQL

226
00:14:46,418 --> 00:14:50,578
or PostgreSQL or RDS databases.

227
00:14:50,754 --> 00:14:55,610
So that means shorting Sophia proxy can help us manage your database

228
00:14:55,950 --> 00:15:00,006
cluster and also can upgrade make

229
00:15:00,048 --> 00:15:04,190
it become the distributed one and help us to do the

230
00:15:04,340 --> 00:15:07,982
traffic governance and to help us manage the

231
00:15:08,036 --> 00:15:12,998
complicated topology of your distributed

232
00:15:13,034 --> 00:15:16,482
database system, right? Because all the application will

233
00:15:16,536 --> 00:15:20,174
first send the request to Sherdin Sophia. Sherdin Sophia

234
00:15:20,222 --> 00:15:23,922
do a lot of computing, global computing and

235
00:15:23,976 --> 00:15:28,374
to target which database cluster have the

236
00:15:28,492 --> 00:15:32,102
expected data and then do

237
00:15:32,156 --> 00:15:35,526
and merge the different local readout side to

238
00:15:35,548 --> 00:15:39,270
become the final one and to return to our annulars.

239
00:15:39,350 --> 00:15:42,682
And also another benefit that it

240
00:15:42,736 --> 00:15:46,762
can help us to do what that's the real

241
00:15:46,816 --> 00:15:50,198
rest bleeding. That means because your databases

242
00:15:50,374 --> 00:15:54,170
like this, the first databases instance,

243
00:15:54,330 --> 00:15:57,722
maybe it will have a lot of replica for this shard,

244
00:15:57,786 --> 00:16:01,374
right? And have many replica for the second shard and

245
00:16:01,412 --> 00:16:05,342
have replica for the third shard. And then

246
00:16:05,476 --> 00:16:09,230
the sharding Sophia will to judge this request,

247
00:16:09,310 --> 00:16:12,626
this SQL it's select

248
00:16:12,728 --> 00:16:17,510
SQL or DML SQL the

249
00:16:17,580 --> 00:16:22,306
update or insert. So it will automatically

250
00:16:22,498 --> 00:16:26,610
route the SQL to different primary

251
00:16:26,690 --> 00:16:30,502
nodes and its replica. You can

252
00:16:30,556 --> 00:16:34,586
just random route the request to

253
00:16:34,608 --> 00:16:38,234
the replica or to use other

254
00:16:38,352 --> 00:16:42,460
strategies. But the main

255
00:16:42,990 --> 00:16:46,306
target or main work of sharing

256
00:16:46,358 --> 00:16:49,774
Sophia proxy or GDB say that it can

257
00:16:49,812 --> 00:16:53,790
help you to leverage your replicas performance

258
00:16:53,870 --> 00:16:57,890
and your primary nodes performance to make the

259
00:16:58,040 --> 00:17:01,566
throughput to be input. So that's

260
00:17:01,598 --> 00:17:04,318
the benefit of sharding Sophia,

261
00:17:04,494 --> 00:17:07,794
right? So the last part that I

262
00:17:07,832 --> 00:17:11,750
will give the final solution here, shorting Sophia.

263
00:17:12,330 --> 00:17:16,342
Provide the sharding Sophia charts and you can use the helm by

264
00:17:16,396 --> 00:17:20,274
one command to light the helm to help you deploy

265
00:17:20,322 --> 00:17:23,382
insurancefia cluster in this Kubernetes.

266
00:17:23,526 --> 00:17:26,826
And also today if you already have

267
00:17:26,848 --> 00:17:31,040
your postgresql instance, that's okay, you can ignore this part.

268
00:17:31,810 --> 00:17:35,774
But today I want to give this complete demo. So I

269
00:17:35,812 --> 00:17:39,102
use the postgreSql charts to help me to

270
00:17:39,156 --> 00:17:43,586
deploy two postgres instance here.

271
00:17:43,768 --> 00:17:47,074
So now on this Kubernetes we have the

272
00:17:47,112 --> 00:17:50,222
computing nodes, we have the storage nodes

273
00:17:50,286 --> 00:17:53,682
and computing nodes plus storage nodes become the

274
00:17:53,736 --> 00:17:57,766
final distributed system. Our application

275
00:17:57,948 --> 00:18:01,922
can just send the request to our sharding Sophia

276
00:18:01,986 --> 00:18:07,254
proxy. And sharding Sophia proxy will help

277
00:18:07,292 --> 00:18:10,502
us to do short

278
00:18:10,556 --> 00:18:14,726
data sharding or rewrite or SQL audit

279
00:18:14,838 --> 00:18:18,586
or obstacation or authority such stuff.

280
00:18:18,688 --> 00:18:22,070
So that's all the features of shorting Sophia,

281
00:18:22,230 --> 00:18:25,822
right? You can see

282
00:18:25,876 --> 00:18:29,470
here or the application just

283
00:18:29,540 --> 00:18:33,594
send the request to shortening Sophia proxy and shorting Sophia proxy

284
00:18:33,642 --> 00:18:36,846
will help us short data, rewrite,

285
00:18:36,878 --> 00:18:40,242
splitting and to guarantee and

286
00:18:40,296 --> 00:18:44,062
to found that maybe there are many replica.

287
00:18:44,126 --> 00:18:47,910
If sharding Sophia found the primary crashed, it will

288
00:18:47,980 --> 00:18:51,510
send loadercrest to our replica ones,

289
00:18:51,660 --> 00:18:55,094
right? So that's the sharding Sophia proxies function

290
00:18:55,212 --> 00:18:58,646
and sharding Sophia garners help us to synchronize the

291
00:18:58,668 --> 00:19:02,294
metadata among different proxy and sharding Sophia

292
00:19:02,342 --> 00:19:06,042
operator. It help us to guarantee the high

293
00:19:06,096 --> 00:19:09,782
availability of sharding Sophia proxy and also

294
00:19:09,936 --> 00:19:13,342
to do the elastic computing node skew in

295
00:19:13,396 --> 00:19:16,522
or skew out. So that's the sharning sphereex operator.

296
00:19:16,586 --> 00:19:20,602
It's like DBA on the Kubernetes to guarantee

297
00:19:20,666 --> 00:19:24,178
this distributed system. Another point I want to

298
00:19:24,264 --> 00:19:28,494
say that PostgreSQL or MySQL,

299
00:19:28,622 --> 00:19:30,930
it's self availability.

300
00:19:32,710 --> 00:19:36,174
We need to other tools to guarantee

301
00:19:36,302 --> 00:19:39,578
its availability. But sharing Sophia

302
00:19:39,774 --> 00:19:42,982
could be aware of the

303
00:19:43,036 --> 00:19:47,720
different roles of the databases and to help to

304
00:19:48,250 --> 00:19:52,482
route or reroute the traffic to different postgresql

305
00:19:52,546 --> 00:19:56,374
instance. But today I have

306
00:19:56,412 --> 00:20:00,960
no enough time to give more details but I

307
00:20:01,330 --> 00:20:04,702
will give the final part. Let us to see that.

308
00:20:04,756 --> 00:20:08,190
How about the SQL? So here when the application

309
00:20:08,340 --> 00:20:12,106
status request to sharding Sophia proxy sharding Safari

310
00:20:12,138 --> 00:20:16,114
proxy will use the sharding algorithm to found

311
00:20:16,312 --> 00:20:19,842
which databases contain the

312
00:20:19,896 --> 00:20:23,620
expected data, right? And to gather the data

313
00:20:24,150 --> 00:20:28,126
from the database instance and to the sharding

314
00:20:28,158 --> 00:20:32,358
CP proxy and merge the local readout site and to

315
00:20:32,524 --> 00:20:36,454
return them to our end user. But another way

316
00:20:36,492 --> 00:20:40,582
that it will also to judge

317
00:20:40,646 --> 00:20:43,914
or to evaluate like here, it's a

318
00:20:43,952 --> 00:20:47,894
select SQL right select statement. So sharing Sophia

319
00:20:47,942 --> 00:20:51,500
proxy will automatically send the select

320
00:20:51,810 --> 00:20:55,742
statement to the replica ones, not the primary ones.

321
00:20:55,876 --> 00:20:59,146
Also you can to light sharding Sphereex

322
00:20:59,178 --> 00:21:02,746
to help you to send a request to

323
00:21:02,788 --> 00:21:05,826
the primary ones or replica ones. That's okay,

324
00:21:05,928 --> 00:21:09,906
it's up to you. You can just write some the YAML file to

325
00:21:09,928 --> 00:21:12,420
tell sharing CV to do the such stuff.

326
00:21:14,230 --> 00:21:18,562
But all of the change statements, I mean insert

327
00:21:18,626 --> 00:21:23,042
or update or create, it will automatically

328
00:21:23,106 --> 00:21:26,758
send all of the change data statement to the

329
00:21:26,844 --> 00:21:31,094
primary ones. So primary ones will synchronize

330
00:21:31,142 --> 00:21:34,842
the changes to their replica. So that's the clear now,

331
00:21:34,896 --> 00:21:38,554
right? Okay, so the demo show have no

332
00:21:38,592 --> 00:21:42,014
time to give the one

333
00:21:42,212 --> 00:21:46,030
by one step by step the

334
00:21:46,180 --> 00:21:49,726
demo, but you can refer to

335
00:21:49,908 --> 00:21:53,214
my steps to create or to

336
00:21:53,252 --> 00:21:56,862
test that solution. All right, so see you

337
00:21:56,916 --> 00:22:00,254
next time. And if you also have any questions,

338
00:22:00,372 --> 00:22:04,602
just contact me on my Twitter GitHub or linking

339
00:22:04,666 --> 00:22:08,198
and and that's all. So see you.

340
00:22:08,364 --> 00:22:08,610
Bye.

