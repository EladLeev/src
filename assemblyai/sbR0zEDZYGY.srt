1
00:00:00,250 --> 00:00:01,630
Are you an SRE,

2
00:00:03,570 --> 00:00:07,358
a developer, a quality

3
00:00:07,444 --> 00:00:11,162
engineer who wants to tackle the challenge of improving reliability

4
00:00:11,226 --> 00:00:14,970
in your DevOps? You can enable your DevOps for reliability

5
00:00:15,050 --> 00:00:18,286
with chaos native. Create your free account

6
00:00:18,388 --> 00:01:17,510
at Chaos native Litmus Cloud welcome

7
00:01:17,580 --> 00:01:20,966
to conf 42 SRE 2021.

8
00:01:21,068 --> 00:01:25,126
I am Uma Mukara and I will be speaking

9
00:01:25,228 --> 00:01:28,550
today about how do you use Chaos

10
00:01:28,630 --> 00:01:32,902
engineers to do continuous validation of slos,

11
00:01:33,046 --> 00:01:36,538
the service level objectives, and thereby how

12
00:01:36,624 --> 00:01:39,754
you can improve the resilience around the services

13
00:01:39,872 --> 00:01:44,160
that you are operating on. Before we start, a little bit about

14
00:01:44,530 --> 00:01:48,362
who we are. Chaos native provides

15
00:01:48,506 --> 00:01:52,838
chaos engineering solutions for improving the reliability

16
00:01:52,954 --> 00:01:56,802
around cloud native and hybrid services. I am

17
00:01:56,856 --> 00:02:01,042
Uma Mukkara. I'm the CEO of Chaos native and

18
00:02:01,096 --> 00:02:04,626
also a co creator and maintainer of the

19
00:02:04,648 --> 00:02:08,650
popular open source Chaos engineering project Bitmas

20
00:02:08,750 --> 00:02:12,722
Chaos. So let's talk about the service uptime,

21
00:02:12,866 --> 00:02:16,866
which is the primary requirement or delivery

22
00:02:17,058 --> 00:02:19,290
of an SRE.

23
00:02:20,030 --> 00:02:24,042
Why is reliability so important and

24
00:02:24,096 --> 00:02:27,994
why there is such a big function called SRE or

25
00:02:28,032 --> 00:02:30,880
site reliability engineering around that?

26
00:02:31,730 --> 00:02:36,042
So digitization or digital transformation

27
00:02:36,186 --> 00:02:39,514
is a reality today. And the ecommerce

28
00:02:39,562 --> 00:02:42,990
traffic is really improving

29
00:02:43,070 --> 00:02:47,250
or increasing multifold

30
00:02:47,910 --> 00:02:51,634
and retaining the customers is really

31
00:02:51,752 --> 00:02:55,530
important. Retaining your users satisfaction

32
00:02:55,710 --> 00:02:59,830
is really important. A few transaction drops could

33
00:02:59,900 --> 00:03:04,182
cause a lot of deficit in the credibility and

34
00:03:04,236 --> 00:03:07,330
you could be losing those

35
00:03:07,420 --> 00:03:10,986
customers just because you dropped a few transactions out

36
00:03:11,008 --> 00:03:14,780
of thousands or millions sometimes.

37
00:03:15,630 --> 00:03:19,418
So in general, in the modern era, the expectations of

38
00:03:19,504 --> 00:03:23,278
surveys have increased by

39
00:03:23,444 --> 00:03:27,342
the end users. And also we

40
00:03:27,396 --> 00:03:30,622
are delivering software faster. So that

41
00:03:30,676 --> 00:03:34,242
also really means that the software does not need to

42
00:03:34,376 --> 00:03:37,570
be reliable more than ever.

43
00:03:37,720 --> 00:03:41,554
So we need faster changes to the software and more

44
00:03:41,592 --> 00:03:44,850
reliable services. At least that is the expectation.

45
00:03:45,450 --> 00:03:49,234
And the testing mechanisms have also improved.

46
00:03:49,282 --> 00:03:53,266
People are doing great amount of testing,

47
00:03:53,458 --> 00:03:57,174
good quality testing through DevOps, but that

48
00:03:57,212 --> 00:03:59,770
is not sufficient.

49
00:04:00,910 --> 00:04:04,906
The proof is that we are continuing to see the

50
00:04:04,928 --> 00:04:08,778
service outages now and then. So the idea

51
00:04:08,864 --> 00:04:12,202
here is to use surprise testing

52
00:04:12,266 --> 00:04:16,094
in production, continue to break things in production so

53
00:04:16,132 --> 00:04:20,030
that you find the weaknesses early and you fix them

54
00:04:20,100 --> 00:04:23,602
so you continuously improve your

55
00:04:23,656 --> 00:04:27,506
reliability of the service. These are

56
00:04:27,528 --> 00:04:31,502
some of the example companies that are using chaos

57
00:04:31,566 --> 00:04:36,994
engineering to improve their service reliability.

58
00:04:37,122 --> 00:04:40,710
And in the cloud native space, there is another reason

59
00:04:40,860 --> 00:04:43,590
why reliability is a bigger challenge.

60
00:04:44,410 --> 00:04:48,202
In the traditional DevOps you build and

61
00:04:48,256 --> 00:04:52,394
ship at certain interval and

62
00:04:52,432 --> 00:04:55,910
the same is being done much faster.

63
00:04:55,990 --> 00:04:59,674
You build fast, you ship fast in cloud

64
00:04:59,712 --> 00:05:03,774
native space, and also the number of microservices or

65
00:05:03,812 --> 00:05:07,274
the number of application containers

66
00:05:07,402 --> 00:05:12,270
that you need to deal with has improved by many folds.

67
00:05:12,630 --> 00:05:16,658
What this really means is you are getting

68
00:05:16,824 --> 00:05:20,274
more binaries or more application

69
00:05:20,392 --> 00:05:24,130
changes into your service environment,

70
00:05:24,470 --> 00:05:29,430
and you are also getting

71
00:05:29,500 --> 00:05:33,160
them faster. So the chance that

72
00:05:33,610 --> 00:05:37,314
something else can fail and that can affect your

73
00:05:37,452 --> 00:05:41,014
service is more now, in fact multifold

74
00:05:41,062 --> 00:05:43,900
more, maybe ten times more, 100 times more.

75
00:05:44,270 --> 00:05:47,306
So the reliability is a bigger question,

76
00:05:47,488 --> 00:05:50,910
what happens if something else fails? Will I

77
00:05:50,980 --> 00:05:54,080
continue to work properly? That's the application

78
00:05:54,450 --> 00:05:58,314
or a service question that we'd be asking in cloud native

79
00:05:58,362 --> 00:06:01,294
space. So, to summarize this,

80
00:06:01,492 --> 00:06:05,006
the application, the microservices app that you're developing

81
00:06:05,038 --> 00:06:08,946
in cloud native, is less than 10% of

82
00:06:08,968 --> 00:06:12,574
the code in your entire service. Your service depends

83
00:06:12,622 --> 00:06:16,566
on other cloud native services, other cloud native platforms such as

84
00:06:16,588 --> 00:06:19,800
kubernetes and the underlying infrastructure services.

85
00:06:20,250 --> 00:06:23,874
So you need to be validating not just the negative

86
00:06:23,922 --> 00:06:27,806
scenarios within your application and the functional scenarios,

87
00:06:27,938 --> 00:06:31,402
but also will your service continue to run

88
00:06:31,456 --> 00:06:35,178
fine if there is a fault happening on

89
00:06:35,264 --> 00:06:39,594
any of the other 90% dependent services or

90
00:06:39,632 --> 00:06:43,002
software slo? That's the bigger challenge that we are dealing

91
00:06:43,066 --> 00:06:47,054
with cloud native, and the answer is

92
00:06:47,252 --> 00:06:51,086
practice chaos engineers. What is

93
00:06:51,108 --> 00:06:53,854
chaos engineering? I'm already doing some testing.

94
00:06:53,902 --> 00:06:57,602
I'm doing some negative testing, failure testing it is called,

95
00:06:57,656 --> 00:07:00,990
or failed testing mostly that's

96
00:07:01,070 --> 00:07:05,754
really about the application related negative scenarios

97
00:07:05,902 --> 00:07:09,474
we are talking about introducing chaos testing,

98
00:07:09,602 --> 00:07:13,330
which is the dependent component

99
00:07:13,490 --> 00:07:17,042
failure, how those will affect

100
00:07:17,186 --> 00:07:19,740
your application service.

101
00:07:20,670 --> 00:07:24,250
So we are saying that you power up your product

102
00:07:24,320 --> 00:07:28,374
engineering with addition of chaos engineering,

103
00:07:28,502 --> 00:07:32,640
and it is always an incremental process. You cannot change

104
00:07:33,890 --> 00:07:37,486
the reliability of the system through chaos engineering in

105
00:07:37,508 --> 00:07:40,766
a quarter or in two quarters. It's an incremental process, it's a

106
00:07:40,788 --> 00:07:44,402
continuous process. And just like any other

107
00:07:44,456 --> 00:07:48,466
engineering process, you need to practice chaos engineering also

108
00:07:48,648 --> 00:07:52,414
as an extension to your existing development or DevOps

109
00:07:52,462 --> 00:07:56,566
processes. And the end result would be you are building a

110
00:07:56,588 --> 00:07:59,560
complete digital immunity to your services.

111
00:08:00,090 --> 00:08:03,526
Whatever happens, whatever fails, I will continue to

112
00:08:03,548 --> 00:08:06,950
run fine. That's the promise you are trying to achieve.

113
00:08:09,230 --> 00:08:12,614
So if you want me to summarize, what is chaos

114
00:08:12,662 --> 00:08:16,682
engineering? It's about breaking things on

115
00:08:16,736 --> 00:08:20,286
purpose. In DevOps, it could

116
00:08:20,308 --> 00:08:23,854
be in production or pre production, or at the time of

117
00:08:23,892 --> 00:08:27,774
development itself. But trying to do

118
00:08:27,812 --> 00:08:31,514
this as an engineering process is what makes chaos

119
00:08:31,562 --> 00:08:34,834
engineering very, very effective. You try to

120
00:08:34,952 --> 00:08:38,302
cover the entire chaos or fault

121
00:08:38,366 --> 00:08:42,462
dependency scenarios, and you design chaos

122
00:08:42,526 --> 00:08:46,050
experiments and you try to automate

123
00:08:46,130 --> 00:08:50,550
all this chaos workflows and you try to collaborate

124
00:08:50,890 --> 00:08:53,954
with your DevOps. If you are can ops,

125
00:08:54,002 --> 00:08:57,186
you try to collaborate with Dev and vice

126
00:08:57,218 --> 00:09:00,874
versa, and you try to integrate chaos engineering into

127
00:09:00,912 --> 00:09:04,250
your existing tools, and that becomes a complete

128
00:09:04,320 --> 00:09:08,330
chaos engineering and it will incrementally result in

129
00:09:08,400 --> 00:09:12,110
better metrics related to service operations.

130
00:09:14,370 --> 00:09:17,840
So this is a very simple way of

131
00:09:19,010 --> 00:09:22,282
saying how to do chaos engineering, right?

132
00:09:22,436 --> 00:09:25,474
And the below section talks about how

133
00:09:25,512 --> 00:09:29,246
do you do that in cloud native. But it's

134
00:09:29,278 --> 00:09:33,086
also about introducing

135
00:09:33,118 --> 00:09:36,834
a fault is one way to say chaos, but chaos engineering

136
00:09:36,962 --> 00:09:41,154
is is my service level objectives are continuous

137
00:09:41,202 --> 00:09:45,382
to be met. That's the real end

138
00:09:45,436 --> 00:09:48,998
goal. If your slos are being met then you're good.

139
00:09:49,084 --> 00:09:52,586
If not, then there is a problem which you need to fix.

140
00:09:52,768 --> 00:09:56,790
And how you would try to do this in cloud native

141
00:09:56,870 --> 00:10:00,638
is try to follow the same principles that you do

142
00:10:00,724 --> 00:10:04,906
follow for your application, development and operations

143
00:10:05,098 --> 00:10:09,230
using operators and custom resources.

144
00:10:10,050 --> 00:10:13,534
One example that I will be talking little later is litmus

145
00:10:13,582 --> 00:10:17,538
chaos. Litmus chaos follows this approach to do

146
00:10:17,704 --> 00:10:21,940
chaos engineering in a completely cloud native way.

147
00:10:23,590 --> 00:10:26,934
So chaos Engineering summary is if

148
00:10:26,972 --> 00:10:30,550
you have any challenges related to service

149
00:10:30,620 --> 00:10:34,482
failures, or being able to reproduce

150
00:10:34,546 --> 00:10:37,946
a service failure, or unable to

151
00:10:38,048 --> 00:10:41,498
recover from a service failure fast enough,

152
00:10:41,664 --> 00:10:44,650
then you probably need chaos engineering.

153
00:10:45,630 --> 00:10:49,178
And if you invest in chaos engineering, these are

154
00:10:49,264 --> 00:10:52,746
the benefits or return on your investments,

155
00:10:52,938 --> 00:10:57,134
and you will have faster way to

156
00:10:57,252 --> 00:11:01,054
identify a scenario or faster way to

157
00:11:01,092 --> 00:11:04,986
inject a failure or identify a failure scenario.

158
00:11:05,178 --> 00:11:08,706
You will have reduced MTTR and

159
00:11:08,808 --> 00:11:12,740
better MTTF. You will have increased distance between

160
00:11:13,590 --> 00:11:17,430
the failures and that's exactly what you want. You want less outages.

161
00:11:19,770 --> 00:11:23,122
So what are some of the chaos engineering use cases?

162
00:11:23,266 --> 00:11:26,454
We would have heard of game days where try

163
00:11:26,492 --> 00:11:30,698
to go and try to surprise the

164
00:11:30,864 --> 00:11:34,218
operations team through some game days.

165
00:11:34,304 --> 00:11:37,526
And that's generally how you start chaos engineering.

166
00:11:37,638 --> 00:11:41,374
But once you buy in the

167
00:11:41,412 --> 00:11:45,114
benefits of chaos engineering, you try to introduce chaos

168
00:11:45,162 --> 00:11:48,650
engineering into your dev pipelines,

169
00:11:48,730 --> 00:11:52,446
CI pipelines, or into your quality engineering pipelines or

170
00:11:52,468 --> 00:11:56,382
test beds. But if you're looking at Ops

171
00:11:56,446 --> 00:12:00,542
as an SRE, you will use chaos engineering

172
00:12:00,686 --> 00:12:03,922
for continuous validation of your service level

173
00:12:03,976 --> 00:12:07,526
objectives. That's really the goal as

174
00:12:07,548 --> 00:12:11,334
an SRE that you would look for. Let's look at what

175
00:12:11,372 --> 00:12:14,502
is a service level objectives and what is

176
00:12:14,556 --> 00:12:18,266
service level objective validation really means in

177
00:12:18,288 --> 00:12:21,786
a bit more detail. So if

178
00:12:21,808 --> 00:12:25,462
you ask me what is SLO or a service level objective

179
00:12:25,526 --> 00:12:29,434
is, it's really as simple as just to

180
00:12:29,472 --> 00:12:32,778
tell is my service operating optimally,

181
00:12:32,874 --> 00:12:36,522
correctly as expected, and typically

182
00:12:36,666 --> 00:12:39,902
slo are observed. You have good

183
00:12:39,956 --> 00:12:42,982
monitoring dashboards, monitoring systems,

184
00:12:43,146 --> 00:12:47,074
and the answer you're trying to get there is,

185
00:12:47,192 --> 00:12:50,946
is my service running optimally currently at this time? Can I

186
00:12:50,968 --> 00:12:54,100
say it? And also about history,

187
00:12:54,470 --> 00:12:57,942
was there a problem last day, last week,

188
00:12:57,996 --> 00:13:02,230
last month, how my service has been performing

189
00:13:03,610 --> 00:13:07,902
in the recent past? Right so that is Slo observation.

190
00:13:08,066 --> 00:13:12,022
Then what is slo validation? Slo validation

191
00:13:12,086 --> 00:13:15,162
is really about so far so good.

192
00:13:15,296 --> 00:13:19,580
But how will my service be in the next

193
00:13:20,210 --> 00:13:23,680
minute? What happens if something goes wrong?

194
00:13:24,210 --> 00:13:27,566
Can I guarantee my service will stay up? Right.

195
00:13:27,668 --> 00:13:30,910
So that's kind of validating SLO.

196
00:13:32,050 --> 00:13:35,730
So how do you do that? You try to continuous

197
00:13:36,150 --> 00:13:39,860
pull in some fault against your service.

198
00:13:40,710 --> 00:13:44,034
A dependent failure will be

199
00:13:44,232 --> 00:13:47,494
scheduled and then validate if

200
00:13:47,532 --> 00:13:51,846
your service is continuous to perform

201
00:13:51,948 --> 00:13:55,960
or your slo is met. So that's the idea of

202
00:13:57,130 --> 00:14:00,602
validating an SLO and making sure that my service

203
00:14:00,736 --> 00:14:04,282
will continue to run fine no matter what

204
00:14:04,336 --> 00:14:08,806
happens. So in other words, chaos engineering

205
00:14:08,998 --> 00:14:12,430
will be used to guarantee that

206
00:14:12,500 --> 00:14:15,040
no matter what, your service is okay.

207
00:14:16,210 --> 00:14:20,010
And the best practice of chaos engineering

208
00:14:20,090 --> 00:14:24,094
is not just to do it only in Ops, but try to introduce

209
00:14:24,142 --> 00:14:27,486
chaos as a culture into your entire DevOps.

210
00:14:27,518 --> 00:14:30,610
Of course, there will be some initial inertia from

211
00:14:30,680 --> 00:14:34,546
various segments of your DevOps, but the idea is,

212
00:14:34,648 --> 00:14:38,546
once through game days and a significant

213
00:14:38,658 --> 00:14:42,710
introduction of the benefits lectures to your

214
00:14:42,780 --> 00:14:46,882
organization, you would be able to convince that chaos

215
00:14:46,946 --> 00:14:50,826
engineering is in fact, good practice, is a

216
00:14:50,848 --> 00:14:54,410
good practice, and you can start introducing into your quality

217
00:14:54,480 --> 00:14:58,262
engineering efforts your pipelines and so forth.

218
00:14:58,406 --> 00:15:02,014
And of course, on the operations side, you will try

219
00:15:02,052 --> 00:15:05,694
to do continuous validation of slos through

220
00:15:05,732 --> 00:15:09,518
chaos engineering. So the typical process

221
00:15:09,604 --> 00:15:10,240
is.

222
00:15:14,550 --> 00:15:18,174
The typical process is you find a suitable chaos

223
00:15:18,222 --> 00:15:21,540
engineering platform. Don't try to do everything on your own,

224
00:15:21,910 --> 00:15:25,798
and there are tools available, platforms available

225
00:15:25,964 --> 00:15:29,398
for you to get started very quick.

226
00:15:29,564 --> 00:15:33,830
Much of the work is done by these platforms. And then you

227
00:15:33,980 --> 00:15:37,486
start spending time in identifying the chaos scenarios,

228
00:15:37,618 --> 00:15:40,518
start building them properly,

229
00:15:40,694 --> 00:15:43,414
design them properly, implement them properly,

230
00:15:43,542 --> 00:15:46,634
and then start automating. And then as

231
00:15:46,672 --> 00:15:50,258
you start automating, you will find more chaos scenarios

232
00:15:50,294 --> 00:15:53,834
or need for more chaos scenarios. And then the DevOps

233
00:15:53,882 --> 00:15:57,840
process will kick in for chaos engineers as well.

234
00:15:59,170 --> 00:16:02,882
So, in summary, the idea of

235
00:16:02,936 --> 00:16:06,594
improving reliability is take an

236
00:16:06,632 --> 00:16:10,578
approach of chaos engineering underneath and

237
00:16:10,664 --> 00:16:13,854
start improving your reliability in incremental

238
00:16:13,902 --> 00:16:17,526
steps. So let's look at one

239
00:16:17,708 --> 00:16:21,794
such platform which will help do chaos

240
00:16:21,842 --> 00:16:25,634
engineering. And I am a litmus chaos

241
00:16:25,682 --> 00:16:28,666
maintainer. Of course, I'll be talking about Litmus here,

242
00:16:28,848 --> 00:16:32,186
and Litmus has been there for

243
00:16:32,368 --> 00:16:35,814
about four years now, and it's been adopted

244
00:16:35,942 --> 00:16:39,606
by some of the big enterprise DevOps teams.

245
00:16:39,718 --> 00:16:43,786
It's been in good usage. There is continuous downloads

246
00:16:43,898 --> 00:16:47,022
of about 1000 plus every day.

247
00:16:47,156 --> 00:16:50,446
Litmus. That shows that there are

248
00:16:50,468 --> 00:16:54,014
many people using it on a daily basis in the CI pipelines

249
00:16:54,062 --> 00:16:58,306
and so forth. And more importantly, Litmus is

250
00:16:58,408 --> 00:17:02,654
very stable with 20 general availability done recently,

251
00:17:02,782 --> 00:17:06,854
and it's got lot of experiments readily available

252
00:17:07,052 --> 00:17:11,442
through Chaos Hub, and it has a very dynamic

253
00:17:11,506 --> 00:17:15,318
community with lots of contributors and many vendors coming in

254
00:17:15,404 --> 00:17:18,150
to add significant features and so forth.

255
00:17:18,990 --> 00:17:22,650
Slo, you can use litmus to do

256
00:17:22,800 --> 00:17:26,726
real practical chaos engineering

257
00:17:26,918 --> 00:17:30,862
in your DevOps and

258
00:17:30,916 --> 00:17:34,910
overall you have something called chaos center in litmus.

259
00:17:35,250 --> 00:17:39,226
That's where the team, the DevOps Persona,

260
00:17:39,338 --> 00:17:42,742
whether you're a developer or an SRE or a QA,

261
00:17:42,826 --> 00:17:47,300
can come in and try to design develop

262
00:17:48,070 --> 00:17:51,630
a chaos workflow or a chaos scenario

263
00:17:51,790 --> 00:17:55,674
into your chaos hubs, your privately hosted

264
00:17:55,742 --> 00:17:59,746
chaos hubs. Or you can pull the chaos experiments

265
00:17:59,778 --> 00:18:03,702
from public hub also if it's accessible from your

266
00:18:03,756 --> 00:18:07,510
environment and you end up designing

267
00:18:07,870 --> 00:18:11,306
implementing a chaos workflow and it can

268
00:18:11,328 --> 00:18:14,966
be targeted against various types

269
00:18:14,998 --> 00:18:18,054
of resources, including cloud platforms,

270
00:18:18,102 --> 00:18:21,530
bare metal or vmware resources apart from Kubernetes

271
00:18:21,610 --> 00:18:24,794
itself. So the typical approach

272
00:18:24,842 --> 00:18:28,990
is you have a lot of experiments of various types and you have

273
00:18:29,060 --> 00:18:32,510
a good SDK as well. If you want a new experiment,

274
00:18:32,870 --> 00:18:36,574
you can write, and if you have a Chaos engineering

275
00:18:36,622 --> 00:18:40,242
logic, chaos experiment logic already, you can pull in

276
00:18:40,296 --> 00:18:44,750
through a docker container and push it into chaos

277
00:18:44,830 --> 00:18:48,230
engineering Litmus chaos platform very easily.

278
00:18:48,570 --> 00:18:52,118
And you use these experiments to build

279
00:18:52,204 --> 00:18:55,894
a litmus workflow and you write

280
00:18:56,012 --> 00:18:59,734
the steady state hypothesis validation using litmus probes

281
00:18:59,862 --> 00:19:03,450
and use it in any of the following use cases,

282
00:19:03,950 --> 00:19:07,274
SLO validation or management, that's what we just talked

283
00:19:07,312 --> 00:19:11,162
about. And continuous chaos testing in your quality engineers

284
00:19:11,226 --> 00:19:14,894
or game days or to validate your

285
00:19:14,932 --> 00:19:18,846
observability system is working fine. And this is another

286
00:19:18,948 --> 00:19:22,522
very important use case that I have seen people using

287
00:19:22,596 --> 00:19:26,478
chaos engineering for. You have great investments

288
00:19:26,574 --> 00:19:30,146
in observability and you don't know whether

289
00:19:30,328 --> 00:19:33,586
those are going to be helping you when there

290
00:19:33,608 --> 00:19:37,106
is a real service outage. How do you know that you

291
00:19:37,128 --> 00:19:40,594
got everything that you're going to need when there is a failure?

292
00:19:40,722 --> 00:19:43,430
So why don't we introduce a failure and see,

293
00:19:43,580 --> 00:19:47,502
and continue to introduce failures and see if your observability

294
00:19:47,586 --> 00:19:51,500
platforms, your investments, are yielding the right

295
00:19:52,030 --> 00:19:55,802
returns. And also many of us will

296
00:19:55,856 --> 00:19:59,446
have skilled testing or performance testing.

297
00:19:59,558 --> 00:20:03,678
Try to introduce chaos and see things will be okay there

298
00:20:03,764 --> 00:20:07,754
or not. So these are some of the use cases that you can use chaos

299
00:20:07,802 --> 00:20:11,514
engineers for. So let's look at how chaos

300
00:20:11,562 --> 00:20:15,294
engineering happens with litmus.

301
00:20:15,342 --> 00:20:19,220
You have chaos center, as I said a little bit before,

302
00:20:19,590 --> 00:20:23,534
and your goal is to write fault templates

303
00:20:23,582 --> 00:20:27,570
or chaos engineering chaos workflows

304
00:20:27,730 --> 00:20:31,750
into a database. It could be a git

305
00:20:32,090 --> 00:20:35,874
backed database or the database

306
00:20:35,922 --> 00:20:39,738
that is provided by Chaos center itself, like MongoDB or

307
00:20:39,744 --> 00:20:43,290
Percona, and you will have

308
00:20:43,440 --> 00:20:46,666
certain team of people who will be

309
00:20:46,768 --> 00:20:50,506
writing both chaos experiments

310
00:20:50,538 --> 00:20:53,966
or chaos workflows, and there will be a certain set

311
00:20:53,988 --> 00:20:57,882
of members who would be either just viewing

312
00:20:58,026 --> 00:21:01,658
what's happening or scheduling such chaos workflows.

313
00:21:01,754 --> 00:21:05,710
So Chaos center allows everybody to collaborate

314
00:21:05,790 --> 00:21:10,050
and work together like in any other typical dev environment.

315
00:21:11,030 --> 00:21:14,546
So once you have the fault templates, you're going to

316
00:21:14,568 --> 00:21:17,218
schedule them against various resources,

317
00:21:17,394 --> 00:21:21,714
and you're going to validate resilience, and you're going to generate reports.

318
00:21:21,842 --> 00:21:25,190
And more importantly, Litmus also has

319
00:21:25,260 --> 00:21:28,550
additional advanced features like auto remediation.

320
00:21:28,710 --> 00:21:32,634
If the blast radius happens

321
00:21:32,752 --> 00:21:36,698
to be more, or your chaos is getting out of control,

322
00:21:36,864 --> 00:21:41,102
you can take remediate actions through

323
00:21:41,156 --> 00:21:44,606
litmus. Also we have command probes that are

324
00:21:44,628 --> 00:21:48,762
written during chaos or post chaos.

325
00:21:48,906 --> 00:21:52,334
You can take any action that you want as

326
00:21:52,372 --> 00:21:56,382
an action, you would be initiating a remediating task

327
00:21:56,446 --> 00:21:59,794
here to control or bring back the services

328
00:21:59,912 --> 00:22:03,902
quickly. So the typical process to summarize

329
00:22:03,966 --> 00:22:07,298
is you introduce the platform, you develop scenarios,

330
00:22:07,394 --> 00:22:11,222
chaos scenarios, you automate them, and once

331
00:22:11,276 --> 00:22:14,706
you find it beneficial, a particular experiment,

332
00:22:14,818 --> 00:22:17,994
you put it into your regular QA as well.

333
00:22:18,112 --> 00:22:21,130
That is shift left chaos testing.

334
00:22:22,830 --> 00:22:26,154
What do you approach and where

335
00:22:26,192 --> 00:22:30,382
do you start? Chaos engineering, which stack is

336
00:22:30,436 --> 00:22:33,226
typically you start with infrastructure layer,

337
00:22:33,338 --> 00:22:36,846
and it's easiest most of the times. And then you go

338
00:22:36,868 --> 00:22:40,590
into your message queues or proxy servers

339
00:22:41,570 --> 00:22:45,342
like Kafka et cetera, the middle layer API servers.

340
00:22:45,486 --> 00:22:49,214
And then you get into your databases, stateful applications,

341
00:22:49,342 --> 00:22:53,300
and then you will have your actual application layer itself.

342
00:22:54,390 --> 00:22:58,690
And let's look at how Slo validation

343
00:22:58,770 --> 00:23:02,562
happens in litmus chaos. So Litmus

344
00:23:02,626 --> 00:23:06,040
has a Lego block, as I call it.

345
00:23:08,350 --> 00:23:12,534
You have an experiment. The experiment has two parts, chaos experiment

346
00:23:12,582 --> 00:23:16,474
or litmus experiment. One is about the fault itself. How do you

347
00:23:16,512 --> 00:23:20,654
declaratively specify a

348
00:23:20,692 --> 00:23:23,918
fault, how long the fault should happen and what are the

349
00:23:23,924 --> 00:23:28,090
parameters of the fault? And then probe

350
00:23:28,170 --> 00:23:32,390
is the steady state hypothesis validation.

351
00:23:32,570 --> 00:23:36,622
So what can I keep observing before the chaos,

352
00:23:36,686 --> 00:23:39,694
during the chaos, and after the chaos?

353
00:23:39,822 --> 00:23:43,762
And there are multiple types of probes that litmusk gives and

354
00:23:43,816 --> 00:23:47,826
together is what makes it as a chaos experiment.

355
00:23:48,018 --> 00:23:51,234
And if that you consider as a Lego block,

356
00:23:51,362 --> 00:23:55,110
which is declaratively very efficient

357
00:23:55,530 --> 00:23:58,618
for you to tune a given fault and a

358
00:23:58,624 --> 00:24:02,474
given steady state hypothesis validation. You have many such

359
00:24:02,592 --> 00:24:05,814
lego blocks or chaos experiments in Litmus Chaos

360
00:24:05,862 --> 00:24:09,766
hub. You use them to build a

361
00:24:09,888 --> 00:24:13,242
meaningful chaos scenario, like a Lego toy,

362
00:24:13,386 --> 00:24:17,134
and you schedule that. And once you schedule that,

363
00:24:17,172 --> 00:24:20,462
the state hypothesis validation is already built

364
00:24:20,516 --> 00:24:24,242
in into the workflow and you just observe the result.

365
00:24:24,376 --> 00:24:27,726
If the resilience score provided by litmus

366
00:24:27,758 --> 00:24:31,314
workflow is good, that means you're good and your

367
00:24:31,352 --> 00:24:35,286
service is continuous to do fine, else you

368
00:24:35,308 --> 00:24:38,440
have an opportunity to go and fix something.

369
00:24:39,530 --> 00:24:43,206
So the summary for SREs here as

370
00:24:43,228 --> 00:24:45,990
far as the SLO validation is concerned,

371
00:24:46,570 --> 00:24:50,362
take a look at the chaos coverage across your

372
00:24:50,416 --> 00:24:54,362
service stack and try to design and

373
00:24:54,416 --> 00:24:58,554
implement chaos test across the service stack and

374
00:24:58,752 --> 00:25:02,026
try to schedule them with

375
00:25:02,128 --> 00:25:05,982
a surprise, right? So you have to continuously do them

376
00:25:06,116 --> 00:25:09,354
with some randomness on what gets scheduled.

377
00:25:09,402 --> 00:25:13,594
You got tens or hundreds of chaos scenarios.

378
00:25:13,642 --> 00:25:17,074
You don't know what is going to get scheduled, so that's the

379
00:25:17,112 --> 00:25:20,734
surprise. But definitely something is going to get scheduled.

380
00:25:20,782 --> 00:25:24,610
A fault is always happening and you are continuously validating,

381
00:25:25,350 --> 00:25:28,902
and if it is validated, that's exactly what you want.

382
00:25:28,956 --> 00:25:32,978
Your service is good. If it's not, that's also good news. You found a weakness

383
00:25:33,074 --> 00:25:36,934
and you're going to fix it. So that's about

384
00:25:37,052 --> 00:25:40,806
how chaos engineering can be used for continuously

385
00:25:40,838 --> 00:25:44,346
validating your service resilience and how

386
00:25:44,368 --> 00:25:48,022
can you get started? Litmus Chaos again is a popular

387
00:25:48,166 --> 00:25:51,914
open source chaos engineering platform. It's conveniently

388
00:25:51,962 --> 00:25:55,674
hosted for free at Chaos native

389
00:25:55,722 --> 00:25:59,342
Cloud and you can sign up and get

390
00:25:59,396 --> 00:26:02,734
started. The entire set of experiments or

391
00:26:02,772 --> 00:26:07,150
suite of experiments are available on Chaos native cloud,

392
00:26:07,300 --> 00:26:11,870
or you can host it on your on premise.

393
00:26:12,210 --> 00:26:16,246
We do have an enterprise service ring where you

394
00:26:16,268 --> 00:26:19,560
get enterprise support with some additional features as well.

395
00:26:20,170 --> 00:26:23,314
So with that, I would like to thank you for your audience.

396
00:26:23,442 --> 00:26:26,340
You can reach out to me at my Twitter handle. Thank you.

