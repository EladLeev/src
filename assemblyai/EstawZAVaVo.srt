1
00:02:02,660 --> 00:02:06,544
Today I would like to discuss how to build a more

2
00:02:06,582 --> 00:02:09,760
robust patch API six ingress controller with

3
00:02:09,830 --> 00:02:13,850
litmus Chaos. Let me introduce myself first.

4
00:02:14,700 --> 00:02:18,724
I'm Jin two, an Apache API six PMC member,

5
00:02:18,852 --> 00:02:22,536
maintainer of the Kubernetes Ingress NJX project,

6
00:02:22,718 --> 00:02:26,412
and Microsoft MVP. If you would like to

7
00:02:26,466 --> 00:02:29,640
get in touch with me, you can find my GitHub

8
00:02:29,720 --> 00:02:34,332
profile and email address on the slides in

9
00:02:34,386 --> 00:02:37,952
this talk. The agenda is to discuss why

10
00:02:38,006 --> 00:02:42,108
we need Chaos engineering, how to design chaos

11
00:02:42,284 --> 00:02:45,324
experiments for an ingress controller,

12
00:02:45,452 --> 00:02:48,756
how to practice it, the benefits and

13
00:02:48,778 --> 00:02:50,790
the future of this field.

14
00:02:51,400 --> 00:02:56,100
First, why we need Chaos Engineering

15
00:02:57,160 --> 00:03:00,820
let's review the definition of chaos engineering.

16
00:03:01,260 --> 00:03:05,400
Chaos Engineering is a process of evaluating

17
00:03:05,820 --> 00:03:10,628
software system by simulation destructive

18
00:03:10,724 --> 00:03:14,840
events such as server network outage or

19
00:03:14,910 --> 00:03:17,628
APisix routing. In this process,

20
00:03:17,794 --> 00:03:22,760
we test the system's resilience and reliability

21
00:03:22,920 --> 00:03:26,360
in unstable and unexpected condition

22
00:03:26,520 --> 00:03:30,190
by introduced chaos, for example,

23
00:03:30,960 --> 00:03:34,896
server fraud. Chaos engineering can

24
00:03:34,998 --> 00:03:38,690
also help teams simulate real world

25
00:03:39,940 --> 00:03:43,910
scenarios in a security

26
00:03:45,560 --> 00:03:49,520
control environment to uncover

27
00:03:49,600 --> 00:03:53,716
hidden risk and identify performance

28
00:03:53,908 --> 00:03:57,370
botnecks in distributed system.

29
00:03:57,740 --> 00:04:00,936
This approach is an

30
00:04:01,038 --> 00:04:04,940
effective way to prevent system downtime or

31
00:04:05,010 --> 00:04:07,928
production interactions.

32
00:04:08,104 --> 00:04:12,332
Netflix approach to handling system

33
00:04:12,466 --> 00:04:16,948
inspired us to take a more scientistic

34
00:04:17,064 --> 00:04:21,088
approach that driven the boss and

35
00:04:21,254 --> 00:04:25,712
development of the chaos engineering what

36
00:04:25,766 --> 00:04:29,540
is Chaos engineering? I think the first one

37
00:04:29,610 --> 00:04:33,408
is introduce the introduction

38
00:04:33,504 --> 00:04:37,904
of the disruptive

39
00:04:38,032 --> 00:04:42,280
events. Cows engineering involves

40
00:04:44,140 --> 00:04:48,516
introducing disruptive events

41
00:04:48,628 --> 00:04:56,248
such as network partitions, service degradation

42
00:04:56,424 --> 00:04:59,420
and resource constraints.

43
00:05:01,200 --> 00:05:05,908
Two simulate real world scenarios

44
00:05:06,024 --> 00:05:10,652
and these these system's ability to handle unexpected

45
00:05:10,796 --> 00:05:15,068
condition. The purpose of this is to identify

46
00:05:15,164 --> 00:05:19,172
and weakness and

47
00:05:19,306 --> 00:05:23,184
use the information to improve the system's

48
00:05:23,312 --> 00:05:26,740
design and the architecture.

49
00:05:27,720 --> 00:05:32,260
Make it more robust and resilient.

50
00:05:33,560 --> 00:05:38,120
Then test the system's resilience.

51
00:05:40,220 --> 00:05:44,216
Today's technical landscape is

52
00:05:44,398 --> 00:05:47,960
constantly involved and fast phased

53
00:05:48,400 --> 00:05:52,700
to ensure the system are robust, scalable and

54
00:05:52,770 --> 00:05:56,500
able to hand unexpected challenge

55
00:05:56,600 --> 00:06:00,384
and conditions. It's very important

56
00:06:00,502 --> 00:06:04,112
to test the system silence in real

57
00:06:04,166 --> 00:06:07,932
worlds.

58
00:06:08,076 --> 00:06:11,332
Chaos engineering is an effective way

59
00:06:11,386 --> 00:06:19,088
to do this. It involves introducing

60
00:06:19,264 --> 00:06:22,884
disruptive events to observe

61
00:06:22,932 --> 00:06:27,812
the system's response and machine

62
00:06:27,956 --> 00:06:31,860
ability to hand unexpected expected

63
00:06:31,940 --> 00:06:35,900
condition to measure these impact of

64
00:06:35,970 --> 00:06:39,564
the disruptive event on the

65
00:06:39,602 --> 00:06:43,548
system. Resilience organization can monitor system

66
00:06:43,634 --> 00:06:48,370
logs, performance metrics and user experiments.

67
00:06:49,300 --> 00:06:53,344
By tracking these metrics, organizations can

68
00:06:53,462 --> 00:06:57,308
gain a better understanding of the system's behave

69
00:06:57,404 --> 00:07:02,020
and identify area of the improvement.

70
00:07:02,680 --> 00:07:05,808
Next one is discovering

71
00:07:05,984 --> 00:07:07,350
hidden problems.

72
00:07:09,320 --> 00:07:13,636
Distributed system can be prone to hidden

73
00:07:13,828 --> 00:07:16,468
issues such as data loss,

74
00:07:16,564 --> 00:07:20,440
performance botnecks and communication

75
00:07:20,940 --> 00:07:24,172
errors. These problems can be

76
00:07:24,226 --> 00:07:27,788
hard to detect as they often only

77
00:07:27,874 --> 00:07:33,660
become visible when these system is underpriced.

78
00:07:34,480 --> 00:07:37,840
Chaos engineering can help uncover this

79
00:07:37,910 --> 00:07:42,880
hidden issue by introducing

80
00:07:43,700 --> 00:07:47,360
disruptive events. This information

81
00:07:47,510 --> 00:07:50,912
can these be used to improve the system's

82
00:07:50,976 --> 00:07:54,548
design and architecture, making it

83
00:07:54,634 --> 00:07:57,060
more reliable.

84
00:07:58,360 --> 00:08:01,544
By identify and resolve this

85
00:08:01,662 --> 00:08:05,050
problem, organization can enhance the

86
00:08:05,660 --> 00:08:09,224
ability and performance of the system of

87
00:08:09,262 --> 00:08:13,236
these system. These can help prevent

88
00:08:13,348 --> 00:08:17,356
downtime, reduce the risk of

89
00:08:17,538 --> 00:08:21,630
data loss and opensource the system continue

90
00:08:22,240 --> 00:08:25,180
two run smoothly.

91
00:08:27,280 --> 00:08:31,310
What is worse and why we need it?

92
00:08:32,340 --> 00:08:34,864
Why we need it? First,

93
00:08:34,982 --> 00:08:38,640
distributed system are complex

94
00:08:39,400 --> 00:08:42,912
with many inherent cows

95
00:08:42,976 --> 00:08:44,230
in the system.

96
00:08:48,360 --> 00:08:52,164
The use of cloud and micro

97
00:08:52,212 --> 00:08:55,544
surface architecture provide us

98
00:08:55,662 --> 00:08:59,816
with many advantages, but it

99
00:08:59,998 --> 00:09:03,960
also comes up with completed,

100
00:09:04,800 --> 00:09:08,300
completed and chaos which

101
00:09:08,370 --> 00:09:12,440
can lead two failure. The engineer's

102
00:09:12,600 --> 00:09:16,350
responsibility is to make the system as

103
00:09:16,660 --> 00:09:20,956
reliable as possible. Without testing,

104
00:09:21,148 --> 00:09:25,056
we have no confidence to let

105
00:09:25,158 --> 00:09:29,376
our product be used in production environment

106
00:09:29,568 --> 00:09:32,660
in order to make it more robust.

107
00:09:33,320 --> 00:09:37,540
In addition to the conventional

108
00:09:37,960 --> 00:09:41,688
unit test,

109
00:09:41,854 --> 00:09:46,392
we decide to introduce kelse test when

110
00:09:46,446 --> 00:09:49,896
an error occurred. Repelling it

111
00:09:50,078 --> 00:09:55,176
takes time and can cause immeasurable

112
00:09:55,288 --> 00:09:58,892
loss which may have long

113
00:09:58,946 --> 00:10:01,310
term effect in the future.

114
00:10:02,800 --> 00:10:06,770
In the process of the repair, we need to consider

115
00:10:07,780 --> 00:10:12,156
various facts, include the complex

116
00:10:12,268 --> 00:10:15,548
of the system, the type of the error,

117
00:10:15,644 --> 00:10:19,552
and possible new problem in order to ensure

118
00:10:19,616 --> 00:10:22,900
that the final repair is effective.

119
00:10:23,400 --> 00:10:24,340
Moreover,

120
00:10:26,360 --> 00:10:29,748
when an opensource project bring

121
00:10:29,914 --> 00:10:33,680
serious faults to the user in the production

122
00:10:33,840 --> 00:10:37,912
environment, many user will choose to

123
00:10:37,966 --> 00:10:41,828
switch as a product. Back to today's

124
00:10:41,924 --> 00:10:45,860
topic, how to design Kelsey's

125
00:10:45,940 --> 00:10:49,180
experiments for an Ingress controller.

126
00:10:50,800 --> 00:10:54,780
Let's talk about what is Ingress

127
00:10:55,120 --> 00:10:58,780
first, ingress is a resource

128
00:10:58,860 --> 00:11:02,732
object in Kubernetes. It contains

129
00:11:02,796 --> 00:11:07,120
rules for how client outside the cluster

130
00:11:08,740 --> 00:11:12,260
can excise the service inside these cluster.

131
00:11:13,080 --> 00:11:19,572
These rules include which

132
00:11:19,626 --> 00:11:23,764
client can access which service, how to

133
00:11:23,802 --> 00:11:27,656
root client request to the service,

134
00:11:27,758 --> 00:11:30,760
and how to hand these client request.

135
00:11:31,340 --> 00:11:35,404
On the right is a simple

136
00:11:35,522 --> 00:11:39,404
example. As you can see, ingress is a very

137
00:11:39,522 --> 00:11:43,310
simple resource. No need to make it more

138
00:11:44,160 --> 00:11:47,424
complicated than it needs

139
00:11:47,542 --> 00:11:51,468
to be. These what is Ingress

140
00:11:51,564 --> 00:11:54,880
controller? An ingress resource

141
00:11:55,860 --> 00:11:59,452
requires an ingress controller to precise

142
00:11:59,516 --> 00:12:03,300
h. Otherwise it has no practical

143
00:12:03,880 --> 00:12:07,684
use. The Ingress controller translator the

144
00:12:07,722 --> 00:12:11,388
ingress rules into configuration

145
00:12:11,504 --> 00:12:15,796
on a proxy allow external

146
00:12:15,908 --> 00:12:20,360
clients to access service within these cluster.

147
00:12:20,700 --> 00:12:24,220
Ingress controller is a specific

148
00:12:24,370 --> 00:12:28,424
type of load balance that receives

149
00:12:28,552 --> 00:12:32,552
ingress rules from the cluster and then translates

150
00:12:32,616 --> 00:12:36,636
them. Two configuration that can proxy

151
00:12:36,668 --> 00:12:40,240
client rules. This effectively

152
00:12:40,820 --> 00:12:44,960
manages how external external clients

153
00:12:45,540 --> 00:12:48,856
excise service with the cluster.

154
00:12:48,988 --> 00:12:53,024
However, in a production environment,

155
00:12:53,152 --> 00:12:56,800
we need more complex capabilities

156
00:12:56,960 --> 00:13:00,550
such as limiting access

157
00:13:00,920 --> 00:13:03,720
opensource and request method,

158
00:13:04,220 --> 00:13:06,760
authentication and authorization.

159
00:13:08,140 --> 00:13:12,404
The ingress resource object doesn't include

160
00:13:12,452 --> 00:13:15,928
this part, so most ingress

161
00:13:16,024 --> 00:13:20,172
controller extend the semantics of

162
00:13:20,226 --> 00:13:24,284
the ingress through annotations in

163
00:13:24,322 --> 00:13:28,220
the ingress resource. Different ingress

164
00:13:28,300 --> 00:13:32,348
controller have different implementations.

165
00:13:32,524 --> 00:13:37,244
For example, the annotation used by Kubernetes

166
00:13:37,372 --> 00:13:41,200
Ingress NJX and Apache API six ingress

167
00:13:41,360 --> 00:13:44,932
are different. Okay,

168
00:13:45,066 --> 00:13:48,740
what is Apache API six ingress?

169
00:13:50,040 --> 00:13:54,120
Apache API six Ingress controller is a controller for

170
00:13:54,270 --> 00:13:57,880
Kubernetes ingress resource that helps

171
00:13:58,700 --> 00:14:02,330
administrators manage and

172
00:14:03,760 --> 00:14:08,012
control ingress traffic. It use

173
00:14:08,146 --> 00:14:11,772
Apache API six as a deadline to provide

174
00:14:11,906 --> 00:14:14,888
users with dynamic routing,

175
00:14:14,984 --> 00:14:18,416
load balance and security

176
00:14:18,518 --> 00:14:22,092
policies and other filters to improve

177
00:14:22,156 --> 00:14:25,360
network controller and ensure high

178
00:14:25,430 --> 00:14:28,812
available availability and security

179
00:14:28,966 --> 00:14:32,820
for their business. API six Ingress

180
00:14:33,160 --> 00:14:36,884
support three configuration method you can

181
00:14:36,922 --> 00:14:41,344
use Kubernetes Ingress and customer resource

182
00:14:41,472 --> 00:14:45,140
or gateway API. Each of

183
00:14:45,210 --> 00:14:48,920
these has its own advantage.

184
00:14:49,420 --> 00:14:50,410
For example,

185
00:14:53,660 --> 00:14:56,872
if you using ingress resource,

186
00:14:57,016 --> 00:15:01,164
this is simple to describe and is

187
00:15:01,202 --> 00:15:04,780
a resource carried by kubernetes by default.

188
00:15:05,920 --> 00:15:09,688
It's also easy to integrate

189
00:15:09,784 --> 00:15:13,932
with other components. Next one is Gateway

190
00:15:13,996 --> 00:15:17,072
API. Gateway API is the next

191
00:15:17,206 --> 00:15:21,700
generation. Ingress provide rich semantics

192
00:15:22,120 --> 00:15:26,724
and functions. Also the

193
00:15:26,762 --> 00:15:31,292
last one is CRD. Apache API Six Ingress

194
00:15:31,456 --> 00:15:35,816
provide a site of customer

195
00:15:35,918 --> 00:15:39,796
resources to Apiai

196
00:15:39,828 --> 00:15:44,120
Six's own resource which is convenient

197
00:15:44,480 --> 00:15:48,270
for user to use and understand.

198
00:15:50,400 --> 00:15:55,004
API six ingress adopts special

199
00:15:55,122 --> 00:15:59,452
architecture with control plane handing

200
00:15:59,516 --> 00:16:03,740
routing rules without carrying building

201
00:16:03,820 --> 00:16:08,664
traffic. All client requests

202
00:16:08,732 --> 00:16:16,630
are precisely through the deadline, therefore any

203
00:16:17,480 --> 00:16:21,548
abnormality in the control plane

204
00:16:21,584 --> 00:16:25,556
will not affect the traffic.

205
00:16:25,668 --> 00:16:29,770
In addition, API six ingress controller has

206
00:16:32,780 --> 00:16:35,260
a retry module.

207
00:16:36,640 --> 00:16:40,808
After the control plane component is restored,

208
00:16:40,904 --> 00:16:44,280
the routing rules can be synced

209
00:16:44,360 --> 00:16:47,676
to the data plan and Apiai

210
00:16:47,708 --> 00:16:52,044
Six Ingress also support integration

211
00:16:52,172 --> 00:16:55,840
with external service discovery components.

212
00:16:56,420 --> 00:16:59,788
These what is Litmus Chaos?

213
00:16:59,964 --> 00:17:03,532
Litmus Chaos is Litmus

214
00:17:03,596 --> 00:17:07,372
Chaos is an open source chaos engineering

215
00:17:07,436 --> 00:17:13,796
framework and incubating

216
00:17:13,988 --> 00:17:16,200
project of the CNCF.

217
00:17:17,340 --> 00:17:22,120
It provides an infrastructure

218
00:17:22,700 --> 00:17:27,784
experiments framework to validate

219
00:17:27,832 --> 00:17:32,088
the stability of controllers and microservice

220
00:17:32,184 --> 00:17:35,980
architecture. It can simulate

221
00:17:36,340 --> 00:17:41,376
container level and application level environment as

222
00:17:41,398 --> 00:17:43,520
well as nature,

223
00:17:46,340 --> 00:17:50,064
force and upgrade to understand how

224
00:17:50,102 --> 00:17:54,308
the system respond to these

225
00:17:54,394 --> 00:17:58,132
trends. The framework can also

226
00:17:58,266 --> 00:18:01,850
explore the behavior changes

227
00:18:02,300 --> 00:18:06,152
between controller and applications and how

228
00:18:06,206 --> 00:18:09,588
controller responds to challenges

229
00:18:09,764 --> 00:18:13,080
in specific status.

230
00:18:13,760 --> 00:18:14,940
In addition,

231
00:18:16,720 --> 00:18:20,860
Litmus Kels offer convenient observability

232
00:18:24,320 --> 00:18:27,760
capabilities. It is high

233
00:18:27,830 --> 00:18:32,336
extensible and integratable with

234
00:18:32,438 --> 00:18:36,048
other tools to enable the

235
00:18:36,134 --> 00:18:39,800
creation of customer experiments.

236
00:18:39,980 --> 00:18:44,432
Kubernetes development developers

237
00:18:44,576 --> 00:18:48,612
and sres use litmus to

238
00:18:48,666 --> 00:18:53,716
manage cows in a declarative

239
00:18:53,908 --> 00:18:57,672
manner and identify weakness in

240
00:18:57,726 --> 00:19:01,240
their applications and infrastructures.

241
00:19:04,460 --> 00:19:08,692
Someone asked me why I chaos litmus

242
00:19:08,756 --> 00:19:12,668
chaos over other products. That is

243
00:19:12,754 --> 00:19:16,824
a topic for another time, but for summarize

244
00:19:16,952 --> 00:19:20,864
lead meals cows has filter functions I

245
00:19:20,902 --> 00:19:24,560
need and I'm more familiar with

246
00:19:24,630 --> 00:19:28,800
it. Okay, how to design cows

247
00:19:29,320 --> 00:19:30,420
experiment?

248
00:19:32,600 --> 00:19:36,870
This is a general procedural application

249
00:19:37,480 --> 00:19:41,628
to applicable

250
00:19:41,744 --> 00:19:45,908
to these design of the calcium experiment

251
00:19:46,084 --> 00:19:50,200
in any scenarios.

252
00:19:51,420 --> 00:19:54,972
First you should define the

253
00:19:55,026 --> 00:19:59,790
system under test, identify the specific

254
00:20:00,320 --> 00:20:04,396
components of the system you want to experiments on

255
00:20:04,498 --> 00:20:08,524
and develop a clear and mature

256
00:20:08,652 --> 00:20:12,720
objective for these experiment.

257
00:20:14,100 --> 00:20:20,260
This includes creating prohibitive

258
00:20:21,000 --> 00:20:24,848
list of the components such as hardware

259
00:20:24,944 --> 00:20:28,320
and software that will be tested

260
00:20:28,400 --> 00:20:33,028
as well as defining

261
00:20:33,124 --> 00:20:37,604
the scope of the experiment

262
00:20:37,732 --> 00:20:41,880
and the expected outcomes.

263
00:20:42,700 --> 00:20:46,124
Next one choose the right

264
00:20:46,322 --> 00:20:49,512
experiment, select an experiments

265
00:20:49,656 --> 00:20:52,380
that is alien.

266
00:20:52,880 --> 00:20:57,504
With these objective you

267
00:20:57,542 --> 00:21:01,328
have set and closely mimic us

268
00:21:01,414 --> 00:21:05,040
and real world scenario.

269
00:21:05,780 --> 00:21:09,556
This will help ensure that the

270
00:21:09,658 --> 00:21:13,412
experiment product meaningful result

271
00:21:13,546 --> 00:21:17,220
and accurately

272
00:21:18,040 --> 00:21:20,950
reflect the behavior of the system.

273
00:21:21,500 --> 00:21:26,600
Next one is establish hypothesis.

274
00:21:29,500 --> 00:21:33,764
Establish hope is about how the system will

275
00:21:33,902 --> 00:21:37,980
behave during the experiments and

276
00:21:38,130 --> 00:21:41,404
what outcome you want.

277
00:21:41,602 --> 00:21:47,070
This should be based on past

278
00:21:47,680 --> 00:21:51,688
experiments, experience or

279
00:21:51,874 --> 00:21:55,600
research and it should be reasonable and

280
00:21:55,670 --> 00:21:59,776
testable. Next one is render

281
00:21:59,968 --> 00:22:03,824
experiment render experiments

282
00:22:03,952 --> 00:22:08,224
in controlled environment

283
00:22:08,352 --> 00:22:11,850
such as staging environment to limit these

284
00:22:13,580 --> 00:22:17,444
potential for harm to the production

285
00:22:17,492 --> 00:22:22,324
system. Collector all relevant

286
00:22:22,452 --> 00:22:25,548
data during the experiment and

287
00:22:25,634 --> 00:22:28,510
store it security.

288
00:22:30,480 --> 00:22:34,348
There may be different opinions on

289
00:22:34,434 --> 00:22:38,272
whether the experiment should take

290
00:22:38,326 --> 00:22:42,400
place directly in the production environment.

291
00:22:42,820 --> 00:22:46,144
However, for most scenarios we

292
00:22:46,182 --> 00:22:50,548
need to opensource the service level

293
00:22:50,634 --> 00:22:55,044
objective of the system is

294
00:22:55,082 --> 00:23:00,272
met. The last one is evaluate

295
00:23:00,416 --> 00:23:03,592
the result, evaluate the

296
00:23:03,646 --> 00:23:07,224
result of the experiments and

297
00:23:07,342 --> 00:23:10,600
compare these to your harness.

298
00:23:10,940 --> 00:23:14,456
Analyze the data collected and document

299
00:23:14,568 --> 00:23:17,768
any observation

300
00:23:17,864 --> 00:23:23,384
or building. This includes identify

301
00:23:23,512 --> 00:23:29,256
any unexpected result or describe

302
00:23:29,448 --> 00:23:33,552
face and determine how they might

303
00:23:33,686 --> 00:23:36,716
affect the system. Additionally,

304
00:23:36,828 --> 00:23:40,804
consider how the result of the experiment can be

305
00:23:40,842 --> 00:23:44,468
used to improve the system. Okay,

306
00:23:44,554 --> 00:23:48,260
let's see the main usage

307
00:23:49,400 --> 00:23:52,680
scenarios of the ingress controller.

308
00:23:54,700 --> 00:23:58,916
Proxy traffic is the most important capability

309
00:23:59,108 --> 00:24:01,610
so I write it three times.

310
00:24:02,380 --> 00:24:05,916
The other functions are all based on

311
00:24:05,938 --> 00:24:07,500
these core functions.

312
00:24:08,720 --> 00:24:12,840
Consequently, when conducting

313
00:24:13,000 --> 00:24:16,860
CALC engineering normally process normally

314
00:24:17,680 --> 00:24:21,120
proxy traffic is these key metrics.

315
00:24:22,180 --> 00:24:27,104
Next we

316
00:24:27,142 --> 00:24:30,864
can use the general mode about two define

317
00:24:30,912 --> 00:24:34,644
the system under the past. We can

318
00:24:34,682 --> 00:24:38,640
see for API six ingress users

319
00:24:38,720 --> 00:24:42,660
need to create root configurations

320
00:24:42,820 --> 00:24:46,852
such as ingress gateway, API or CRD

321
00:24:46,996 --> 00:24:51,850
and apply them to the Kubernetes cluster through

322
00:24:52,300 --> 00:24:56,012
Kubernetes. This process goes

323
00:24:56,066 --> 00:25:00,140
through Kubernetes server for authentication authorization

324
00:25:00,880 --> 00:25:03,932
and then store it in

325
00:25:03,986 --> 00:25:07,592
eTCD. Then ApIaI six ingress controller

326
00:25:07,656 --> 00:25:11,584
continually watch over change

327
00:25:11,702 --> 00:25:14,716
in the Kubernetes resources.

328
00:25:14,908 --> 00:25:19,080
These configuration are these translated

329
00:25:19,180 --> 00:25:24,912
to the configuration on the database? When a client requests

330
00:25:24,976 --> 00:25:29,220
the database, it excites the upstream service according

331
00:25:29,880 --> 00:25:33,108
to the routine rules. It is

332
00:25:33,194 --> 00:25:36,736
clear that if Kubernetes API

333
00:25:36,768 --> 00:25:38,760
servers has an exception,

334
00:25:40,060 --> 00:25:43,448
it will prevent the configuration from being

335
00:25:43,534 --> 00:25:47,276
created or the ingress controller from getting

336
00:25:47,378 --> 00:25:50,056
the correct configuration.

337
00:25:50,248 --> 00:25:54,030
This is obvious and

338
00:25:54,960 --> 00:26:00,060
certain scenarios so no experimentation

339
00:26:00,220 --> 00:26:01,250
is needed.

340
00:26:03,860 --> 00:26:07,456
If there is exception in the

341
00:26:07,558 --> 00:26:13,792
deadline such as network interruption,

342
00:26:13,936 --> 00:26:17,572
crash or podcast, it will

343
00:26:17,626 --> 00:26:20,752
also not be able to do normal traffic

344
00:26:20,816 --> 00:26:25,856
process to do normal traffic proxy.

345
00:26:26,048 --> 00:26:29,400
This is also doesn't need to experiment.

346
00:26:30,140 --> 00:26:34,856
Therefore, the scope of our experiment

347
00:26:34,968 --> 00:26:38,350
is mainly the impact on the system.

348
00:26:42,720 --> 00:26:47,200
If the ingress controller has an exception.

349
00:26:47,940 --> 00:26:52,272
Next we can choose we should choose

350
00:26:52,326 --> 00:26:55,856
the red experiments based on the

351
00:26:56,038 --> 00:26:59,990
above reasons. We can directly cover many

352
00:27:00,520 --> 00:27:04,608
scenarios of incorrect

353
00:27:04,704 --> 00:27:07,972
configuration through end two end test

354
00:27:08,106 --> 00:27:11,896
mainly through chaos engineering to verify whether

355
00:27:11,998 --> 00:27:15,960
the data plan can still proxy traffic

356
00:27:16,380 --> 00:27:20,708
normally when the ingress controller occurred an exception

357
00:27:20,804 --> 00:27:23,396
such as DNS error,

358
00:27:23,508 --> 00:27:27,880
network interruption or port killed.

359
00:27:28,380 --> 00:27:36,112
Then establish for

360
00:27:36,206 --> 00:27:39,776
each for for each

361
00:27:39,958 --> 00:27:43,276
second we can create the following

362
00:27:43,468 --> 00:27:47,596
hypothesis. When these ingress controller

363
00:27:47,708 --> 00:27:49,350
get something,

364
00:27:51,560 --> 00:27:55,268
the client request can still

365
00:27:55,354 --> 00:27:57,620
get a normal response.

366
00:27:58,360 --> 00:28:02,760
This is our hypothesis.

367
00:28:03,260 --> 00:28:07,240
Next we should run the run

368
00:28:07,390 --> 00:28:11,160
experiments. The experiment and

369
00:28:11,310 --> 00:28:15,768
variable variable has been determined

370
00:28:15,864 --> 00:28:19,308
so all that is

371
00:28:19,394 --> 00:28:22,828
left it to conduct these

372
00:28:22,994 --> 00:28:26,690
experiment. Litmus chaos provide

373
00:28:27,860 --> 00:28:32,236
various way to conduct experiments.

374
00:28:32,428 --> 00:28:35,804
We can do this through the litmus portal.

375
00:28:35,932 --> 00:28:40,688
To do this, we need to create calcium scenarios,

376
00:28:40,864 --> 00:28:44,660
select the application to be experimented

377
00:28:45,400 --> 00:28:52,760
and these steps are relatively

378
00:28:53,100 --> 00:28:56,660
straightforward. However, we must pay attention

379
00:28:56,740 --> 00:29:00,744
to the factor that

380
00:29:00,942 --> 00:29:05,560
litmus chaos include a proberous

381
00:29:05,980 --> 00:29:10,360
opensource. These problem resource are

382
00:29:10,430 --> 00:29:14,590
plaguable checks that can be defined with

383
00:29:15,760 --> 00:29:19,360
chaos engine for any chaos experiment.

384
00:29:20,020 --> 00:29:23,968
The experiment port execute these

385
00:29:24,054 --> 00:29:27,920
checks based on the mode. These are defined in

386
00:29:28,070 --> 00:29:31,660
and factor. These are five factors.

387
00:29:31,740 --> 00:29:35,172
These are facts as necessary condition in

388
00:29:35,226 --> 00:29:39,284
determining the vector of these

389
00:29:39,482 --> 00:29:45,130
experiment. In addition to these standard

390
00:29:46,460 --> 00:29:50,730
in building checks, at the same time we can also

391
00:29:51,420 --> 00:29:56,076
schedule experiment which is a very variable function.

392
00:29:56,258 --> 00:30:00,332
Additionally, litmus also

393
00:30:00,386 --> 00:30:04,696
support running experiments by submit

394
00:30:04,808 --> 00:30:09,696
Yaml manifest these

395
00:30:09,798 --> 00:30:13,500
how to evaluate

396
00:30:13,660 --> 00:30:15,840
the resource.

397
00:30:16,260 --> 00:30:21,920
Litmus has building statistical

398
00:30:22,820 --> 00:30:26,948
repos that clear shows

399
00:30:27,034 --> 00:30:30,420
these result of the experiments.

400
00:30:31,260 --> 00:30:34,984
There are also other rich reports such

401
00:30:35,022 --> 00:30:39,668
as compression of experiment,

402
00:30:39,844 --> 00:30:44,128
pensions execution

403
00:30:44,324 --> 00:30:48,120
records. It can also be injected

404
00:30:48,200 --> 00:30:52,140
with promises and

405
00:30:52,290 --> 00:30:56,500
Grafana to provide a unified

406
00:30:56,600 --> 00:31:00,000
dashboard for integration.

407
00:31:00,900 --> 00:31:05,360
However, due to my current experiments

408
00:31:05,940 --> 00:31:09,008
scenarios, I only used

409
00:31:09,094 --> 00:31:12,976
the building reports these

410
00:31:13,078 --> 00:31:16,644
benefits and filter Apache API six

411
00:31:16,842 --> 00:31:20,592
is an open source project that is applied

412
00:31:20,656 --> 00:31:24,544
to various company and environment.

413
00:31:24,672 --> 00:31:28,824
Chaos Engineering has given us

414
00:31:29,022 --> 00:31:32,090
confidence that the

415
00:31:32,620 --> 00:31:36,092
delivered API six ingress is

416
00:31:36,146 --> 00:31:40,156
stable and reliable. Thanks to our

417
00:31:40,258 --> 00:31:44,012
completed end two end test, we no

418
00:31:44,066 --> 00:31:48,972
longer need to worry about unexpected

419
00:31:49,116 --> 00:31:52,672
behavior due to the introduction of

420
00:31:52,726 --> 00:31:57,040
new prs. Chaos Engineering also

421
00:31:57,190 --> 00:32:00,596
has also helped us to identify a

422
00:32:00,618 --> 00:32:05,104
bug. When multiple perspective

423
00:32:05,232 --> 00:32:09,200
killed of the API six ingress controller

424
00:32:09,280 --> 00:32:13,080
pod occurred, it may cause a configuration

425
00:32:13,580 --> 00:32:17,732
failed cause a configuration

426
00:32:17,796 --> 00:32:19,960
failure. Fortunately,

427
00:32:21,980 --> 00:32:25,340
these problem has been fixed

428
00:32:25,760 --> 00:32:30,840
and I'm now continual

429
00:32:30,920 --> 00:32:34,856
Kelsey test through a private

430
00:32:35,048 --> 00:32:38,430
deployment environment. I plan to

431
00:32:39,040 --> 00:32:43,040
introduce Kelsey experiments based on

432
00:32:43,110 --> 00:32:46,844
litmus into the CI environment of Apache

433
00:32:46,892 --> 00:32:50,832
API Six Ingress project, and I want to

434
00:32:50,886 --> 00:32:54,960
provide reference documents and examples

435
00:32:55,780 --> 00:33:00,400
for other opensource users to implement

436
00:33:01,100 --> 00:33:05,290
engineering ApIai six ingress in their own

437
00:33:06,140 --> 00:33:10,212
environment. That's all. Thank you. I'm honored

438
00:33:10,276 --> 00:33:13,416
to be here to share some of my

439
00:33:13,518 --> 00:33:15,770
experience with you.

440
00:33:16,940 --> 00:33:20,728
If you are interested, feel free to

441
00:33:20,814 --> 00:33:23,910
contact me anytime. See you.

