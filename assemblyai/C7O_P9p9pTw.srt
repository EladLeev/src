1
00:00:27,410 --> 00:00:31,238
This is Joel Tosi. We'll be talking about metrics that matter. There's the

2
00:00:31,324 --> 00:00:34,870
slides, all that fun stuff, all the social media stuff.

3
00:00:35,020 --> 00:00:38,294
Let's jump into it, call right some quick

4
00:00:38,332 --> 00:00:40,760
background so you know where I'm coming from with this.

5
00:00:41,130 --> 00:00:44,182
I do a lot of help with organizations. And of course, just as

6
00:00:44,236 --> 00:00:47,686
I'm sure you all are asked, people ask me all

7
00:00:47,708 --> 00:00:51,374
the time for metrics. For a while there, I was

8
00:00:51,412 --> 00:00:55,242
the guy that kept on saying, those metrics are bad. You can't

9
00:00:55,306 --> 00:00:59,018
just look at cycle time. You can't just look at burn down charts. You can't

10
00:00:59,034 --> 00:01:02,142
just look at cpu percentages. And I kept on saying,

11
00:01:02,276 --> 00:01:05,834
those are bad metrics. You need to do better. And then I realized

12
00:01:05,962 --> 00:01:09,218
I couldn't just be the person that said all the metrics were bad.

13
00:01:09,304 --> 00:01:12,818
I actually had to have some ideas on what was better. So anyway,

14
00:01:12,904 --> 00:01:15,858
that's where I'm coming from. I was tired of being the person that said all

15
00:01:15,864 --> 00:01:18,962
metrics were bad, and I wanted to be the person that said, here's some better

16
00:01:19,016 --> 00:01:22,866
ideas. Let's see what we can do about it. Quick takeaway

17
00:01:22,898 --> 00:01:26,022
for you. Look, you can't ignore metrics as much as we want to,

18
00:01:26,076 --> 00:01:29,286
as much as we wanted to say, make it easier, make it better.

19
00:01:29,468 --> 00:01:32,854
People want metrics. They want to know if they're making good investments.

20
00:01:32,902 --> 00:01:36,426
They want to be able to prove that ideas are working. So we need

21
00:01:36,448 --> 00:01:39,610
to be able to guide better metrics for organizations.

22
00:01:40,370 --> 00:01:44,014
When we can't measure what

23
00:01:44,052 --> 00:01:47,054
we should, we measure what we can. And then, of course,

24
00:01:47,092 --> 00:01:50,640
we optimize for the wrong thing. So let's do better.

25
00:01:51,010 --> 00:01:55,134
All right, first thought for you, and then

26
00:01:55,172 --> 00:01:59,186
we'll jump into some fancy math. We're talking about orienting and grouping. I'll put this

27
00:01:59,208 --> 00:02:02,770
up for you real quick, just around the same page. This is a quick

28
00:02:02,840 --> 00:02:06,002
idea of a value stream. On the left, customer wants something,

29
00:02:06,056 --> 00:02:10,166
a business hypothesis. On the right, the customer gets it. Everybody's happy in

30
00:02:10,188 --> 00:02:13,430
the mill. You can see some ideas around there on variability.

31
00:02:14,010 --> 00:02:17,794
When ideas are cheap, for example, there hasn't

32
00:02:17,842 --> 00:02:21,354
been code written or deployed yet or to be

33
00:02:21,392 --> 00:02:24,858
supported. We probably want to exploit variability. We want to

34
00:02:24,944 --> 00:02:28,394
take more ideas and find out if the ideas should

35
00:02:28,432 --> 00:02:32,438
be invested in before it's too late.

36
00:02:32,534 --> 00:02:36,286
Once we commit to an idea, we want to minimize variability and deliver quickly.

37
00:02:36,468 --> 00:02:40,474
We'll get through those ideas here a little bit more later around variability.

38
00:02:40,602 --> 00:02:43,386
What I want us to think about, though, right off the bat, is when we're

39
00:02:43,418 --> 00:02:47,090
thinking about metrics, we have to be careful that we don't suboptimize the system,

40
00:02:47,160 --> 00:02:50,386
that we don't optimize one aspect at the cost of the

41
00:02:50,408 --> 00:02:53,634
whole. For example, if we're focusing on how quickly we can

42
00:02:53,672 --> 00:02:57,314
deploy servers on that very far side of the value stream,

43
00:02:57,442 --> 00:03:00,870
the deployment and operations, if we're focusing only on

44
00:03:00,940 --> 00:03:04,594
the quickness of deployment, but not on the whole value stream,

45
00:03:04,642 --> 00:03:07,878
we could be suboptimizing the delivery. So again,

46
00:03:07,964 --> 00:03:11,322
think about these things in context and we'll get back into more of this later

47
00:03:11,376 --> 00:03:15,834
on. For quick groupings for

48
00:03:15,872 --> 00:03:19,706
organizations I work with, I want them to be able to know

49
00:03:19,728 --> 00:03:22,522
where they're at and to be able to think about what could be better.

50
00:03:22,576 --> 00:03:25,978
So I did these groupings right off the bat. Talk about simple metrics.

51
00:03:26,074 --> 00:03:29,246
This is where a lot of organizations, if they don't have metrics at all,

52
00:03:29,268 --> 00:03:32,958
this could be a good place to start. Simple things that

53
00:03:33,044 --> 00:03:36,734
organizations can start capturing, easy to count, easy to collect.

54
00:03:36,782 --> 00:03:40,174
How many defects do we have? How many teams are doing automated

55
00:03:40,222 --> 00:03:42,942
deployments? What's our rate of delivery?

56
00:03:43,086 --> 00:03:46,818
Very interesting. I'm sorry, not very interesting. Very simple metrics

57
00:03:46,914 --> 00:03:50,310
that are very isolated in that value stream. Now,

58
00:03:50,380 --> 00:03:54,274
again, if you don't have any metrics, this gives you someplace

59
00:03:54,322 --> 00:03:58,150
to start. Are they interesting over long periods of time?

60
00:03:58,300 --> 00:04:02,026
Probably not. They don't tell you a whole story. But if you don't have anything,

61
00:04:02,208 --> 00:04:05,100
knowing your defect rate would be a good start.

62
00:04:05,870 --> 00:04:09,338
Assuming you're already there and you want to get to a better space,

63
00:04:09,424 --> 00:04:13,022
you could look at this idea of directional metrics. So if you think about

64
00:04:13,076 --> 00:04:16,526
simple metrics and we add a period of

65
00:04:16,548 --> 00:04:20,826
time, a time horizon in them, then we can start talking about directional metrics.

66
00:04:21,018 --> 00:04:24,946
Is our defect rate going down over time? Are we increasing our

67
00:04:24,968 --> 00:04:28,526
code coverage? Is there a percentage reduction in defects?

68
00:04:28,558 --> 00:04:32,354
Is our cycle time decreasing? So again, what we could say here is

69
00:04:32,472 --> 00:04:34,820
given some investment or some focus,

70
00:04:35,450 --> 00:04:38,514
we've invested in infrastructure automation,

71
00:04:38,642 --> 00:04:42,754
has that actually reduced our cycle time? We've invested

72
00:04:42,802 --> 00:04:45,714
in test driven development or better test automation,

73
00:04:45,842 --> 00:04:49,622
has that had a significant reduction in our defects. So again,

74
00:04:49,676 --> 00:04:53,290
if we can start looking at causation and correlation over time,

75
00:04:53,440 --> 00:04:56,250
that's where I start seeing these directional metrics come in.

76
00:04:56,400 --> 00:05:00,134
Again, if you're in the simple space, getting to directional is better. If you're indirectional,

77
00:05:00,182 --> 00:05:03,546
you should be looking at what also might be better before we

78
00:05:03,568 --> 00:05:07,194
get to what we better in that space. I love this book from Don Reinerson,

79
00:05:07,242 --> 00:05:10,478
principles of product development flow. If you haven't read it, I highly recommend it.

80
00:05:10,564 --> 00:05:14,106
What I love about Don Reinerson's book, among many things

81
00:05:14,148 --> 00:05:17,810
here is this quote. When cycle times are long, innovation happens

82
00:05:17,880 --> 00:05:21,026
so late that it becomes imitation. If our cycle times for our

83
00:05:21,048 --> 00:05:24,914
teams are months and quarters or years,

84
00:05:25,112 --> 00:05:28,726
it's hard to say, why aren't you being innovative? You can be

85
00:05:28,748 --> 00:05:32,982
innovative. You learn too late what the next things might

86
00:05:33,036 --> 00:05:36,402
be, and your ability to adapt to the market is out the window.

87
00:05:36,466 --> 00:05:40,122
So again, I put that up there for

88
00:05:40,176 --> 00:05:43,814
context, that cycle times are interesting in the context

89
00:05:43,862 --> 00:05:47,994
of making better products. And so if we think about this last grouping here,

90
00:05:48,112 --> 00:05:50,250
impactful or economic metrics,

91
00:05:51,150 --> 00:05:54,974
these metrics actually require intentionality. So not just cycle time

92
00:05:55,012 --> 00:05:58,698
reduction, but for cycle time for a delivery that actually mattered.

93
00:05:58,794 --> 00:06:02,638
Now, if you take back that earlier value stream we talked, but where it was

94
00:06:02,804 --> 00:06:06,266
a little bit of product discovery and product framing and then delivery

95
00:06:06,378 --> 00:06:09,998
and operations, reduction of a cycle time for a delivery that mattered

96
00:06:10,014 --> 00:06:13,406
is interesting because it actually starts going across that whole value stream. It talks

97
00:06:13,438 --> 00:06:17,190
about finding products that are interesting and then being able to deliver them

98
00:06:17,260 --> 00:06:19,750
in an efficient and effective manner.

99
00:06:20,330 --> 00:06:24,322
Systemic cost reductions, lowering the cost of deployments

100
00:06:24,386 --> 00:06:28,334
or testing or overall running of businesses,

101
00:06:28,482 --> 00:06:32,298
stopping bad ideas, reducing queues, reducing toil inside of an

102
00:06:32,304 --> 00:06:35,238
organization. These are impactful and economic metrics.

103
00:06:35,334 --> 00:06:38,410
And these are more interesting than just

104
00:06:38,480 --> 00:06:42,026
finding out if we have less defects. These are more interesting than

105
00:06:42,048 --> 00:06:45,306
just counting how many story points a team is delivering.

106
00:06:45,338 --> 00:06:48,542
This is actually saying, is the work we're doing making a difference?

107
00:06:48,676 --> 00:06:52,526
And I find this to be super interesting. It's also very challenging for

108
00:06:52,548 --> 00:06:56,066
a lot of organizations because to actually measure items that are

109
00:06:56,088 --> 00:07:00,142
impactful or economic, you have to agree organizations

110
00:07:00,206 --> 00:07:04,046
on what these items actually mean. You'd have to agree what a delivery

111
00:07:04,078 --> 00:07:08,018
that mattered actually is. You'd actually have to agree what

112
00:07:08,104 --> 00:07:11,686
systemic cost reductions are out there. You'd have to agree upon what

113
00:07:11,708 --> 00:07:15,094
do you do with bad ideas and not just have sunk cost fallacies, you'd actually

114
00:07:15,132 --> 00:07:18,454
have to do agree upon why queues are bad and why toil is

115
00:07:18,492 --> 00:07:22,186
bad. So you have to have this higher level agreement to actually get to

116
00:07:22,208 --> 00:07:25,850
this point. Again, if you have nothing, simple is good. If you have simple,

117
00:07:25,920 --> 00:07:28,198
directional is better. If you're having directional,

118
00:07:28,294 --> 00:07:32,302
impactful is a good place to get to. That being said,

119
00:07:32,356 --> 00:07:35,498
how would you actually know if you made a change, that these metrics

120
00:07:35,514 --> 00:07:39,390
were improving? How do you separate signal from noise?

121
00:07:40,850 --> 00:07:44,762
To actually move from simple and directional to impactful require

122
00:07:44,826 --> 00:07:48,290
new thinking. And so this is where we actually need some math,

123
00:07:48,790 --> 00:07:52,846
this dapper young gentleman here, Walter Schuert. So if you've heard of Schuert

124
00:07:52,878 --> 00:07:57,010
charts, or process behavior charts. This is what we're talking about, control charts.

125
00:07:57,170 --> 00:08:01,282
Walter Schuert came up with a way, using statistics, to distinguish

126
00:08:01,346 --> 00:08:04,742
between common cause variation and special

127
00:08:04,796 --> 00:08:08,678
cause variation. Put more succinctly, if you make a change,

128
00:08:08,764 --> 00:08:12,778
you would use Schuer charts to say if your change actually made a

129
00:08:12,784 --> 00:08:16,714
difference. Here's where it comes from, right? The way you

130
00:08:16,752 --> 00:08:20,458
actually deliver value is a system. How you go about building,

131
00:08:20,544 --> 00:08:23,886
deploying your products is actually a system. That's how you

132
00:08:23,908 --> 00:08:27,854
work internally. If you do nothing at all, a Stable system

133
00:08:27,892 --> 00:08:31,502
will continue to deliver within a given range. Right? You might have

134
00:08:31,556 --> 00:08:35,250
a delivery every two weeks. You might have

135
00:08:35,320 --> 00:08:38,994
a certain number of defects, you might have certain market share.

136
00:08:39,112 --> 00:08:42,702
If you change nothing at all within a certain range,

137
00:08:42,766 --> 00:08:46,546
you will get repeatable results. So our goal is

138
00:08:46,568 --> 00:08:50,114
not to react to noise just because we invested in infrastructure

139
00:08:50,162 --> 00:08:53,954
automation. Are we actually seeing a reduction in toil?

140
00:08:54,002 --> 00:08:58,220
Are we actually seeing more stable environments? Right? So how do we actually know

141
00:08:58,750 --> 00:09:02,186
what to expect? Let's talk about how to do these.

142
00:09:02,368 --> 00:09:06,202
Here's a quick example. Imagine you

143
00:09:06,256 --> 00:09:09,498
had a new product released. This could be product,

144
00:09:09,584 --> 00:09:12,426
this could be tech, this could be deployments, this could be defects. But in this

145
00:09:12,448 --> 00:09:15,846
example, we're just using a product that we're trying to make sales.

146
00:09:15,968 --> 00:09:19,214
And your sales day to day kind of look like this. Eight on the first

147
00:09:19,252 --> 00:09:22,478
day, six the second day, ten the third day, six the fourth day. So you

148
00:09:22,484 --> 00:09:25,774
can kind of see how this plays out, right? If we were to graph that

149
00:09:25,812 --> 00:09:29,234
on a time graph, with time

150
00:09:29,272 --> 00:09:32,418
being the x axes and conversions being the y axes, it would look a little

151
00:09:32,424 --> 00:09:35,838
bit like this right here, the red line in the middle being the average over

152
00:09:35,864 --> 00:09:39,814
the period of time. Now, imagine if

153
00:09:39,852 --> 00:09:43,286
we had that. That was our number of conversions per day. And on

154
00:09:43,308 --> 00:09:47,110
day eleven, we had 14 conversions. Now, obviously,

155
00:09:47,180 --> 00:09:50,266
we would say whatever we did on day eleven was awesome. We should do that

156
00:09:50,288 --> 00:09:53,894
again. Whatever we released, the team should be celebrated

157
00:09:53,942 --> 00:09:57,850
and get raises. But hold on. On day twelve, there was only four

158
00:09:57,920 --> 00:10:01,562
sales. I guess we have to let that team go

159
00:10:01,616 --> 00:10:04,654
because they're just not performing as well as we thought they would. But on day

160
00:10:04,692 --> 00:10:07,966
13, it goes to eleven, and you can see how this goes, right? So if

161
00:10:07,988 --> 00:10:10,510
we didn't use any kind of analysis,

162
00:10:10,930 --> 00:10:14,514
and we said on day eleven, we released a new version of the

163
00:10:14,552 --> 00:10:18,180
product, we might celebrate for no reason,

164
00:10:18,550 --> 00:10:21,060
how would we know it actually made a difference or not?

165
00:10:21,830 --> 00:10:25,950
You go about using these sure charts. Now, the math

166
00:10:26,110 --> 00:10:29,398
is relatively straightforward. You can kind of see in the top here around 15,

167
00:10:29,484 --> 00:10:33,480
there's a yellow dotted line, and then there's actually a dotted line at zero

168
00:10:33,850 --> 00:10:37,366
to figure out the upper and lower bounds of the

169
00:10:37,388 --> 00:10:40,714
stable system. So, in essence, any values within

170
00:10:40,752 --> 00:10:44,490
the upper and lower bound are going to happen naturally through common

171
00:10:44,560 --> 00:10:48,106
cause variation, not special cause. The way we calculate those

172
00:10:48,128 --> 00:10:51,882
upper and lower bounds, we find the moving average.

173
00:10:52,026 --> 00:10:55,614
So the delta between day one and day two, between day

174
00:10:55,652 --> 00:10:59,006
two and day three, between day three and day four, and that's the

175
00:10:59,028 --> 00:11:00,190
moving average,

176
00:11:02,370 --> 00:11:06,334
we divide the total of those deltas by

177
00:11:06,372 --> 00:11:10,066
the number of data points. So number the

178
00:11:10,088 --> 00:11:13,314
deltas between one, day one and day two, day two and day three, day three

179
00:11:13,352 --> 00:11:16,126
and day four and so on and so forth. We sum those up and divide

180
00:11:16,158 --> 00:11:19,446
by nine because there's nine deltas. Once we have

181
00:11:19,468 --> 00:11:24,120
that value, we multiply by 2.67.

182
00:11:24,490 --> 00:11:28,694
Now we can go into. Why is it 2.67? You can read the book yourself.

183
00:11:28,892 --> 00:11:33,002
It's just for ease of math. Look, the story becomes the same once

184
00:11:33,056 --> 00:11:36,810
we take that moving average. We multiply by the 2.67,

185
00:11:36,880 --> 00:11:40,266
we add it to the existing average, the red line, and we

186
00:11:40,288 --> 00:11:43,910
subtract it from the red line to get the upper and lower bounds.

187
00:11:44,070 --> 00:11:47,466
Now that we have the upper and lower bounds, you can see the upper bounds

188
00:11:47,498 --> 00:11:51,018
are a little bit above 15. The lower bound would actually be negative, but we'll

189
00:11:51,034 --> 00:11:55,214
say zero because you're not going to have negative sales. Now that we know

190
00:11:55,412 --> 00:11:59,026
this system should produce between zero and 15 sales on

191
00:11:59,048 --> 00:12:02,206
any given day, and that would be normal variation.

192
00:12:02,318 --> 00:12:06,174
We could see that on day eleven when we launched the new product. With 14

193
00:12:06,222 --> 00:12:09,462
sales, it actually didn't matter. And on day twelve,

194
00:12:09,516 --> 00:12:12,422
with four sales, it didn't matter. On day 13, it didn't matter.

195
00:12:12,556 --> 00:12:16,342
That's common variation. The change we made did not

196
00:12:16,396 --> 00:12:20,410
matter. Kind of sad. But what's interesting

197
00:12:20,480 --> 00:12:24,554
about this is we can't celebrate changes

198
00:12:24,672 --> 00:12:28,810
that don't make a difference. And so we should use process control charts to actually

199
00:12:28,880 --> 00:12:32,666
say, are the things we're doing making a difference and can we

200
00:12:32,688 --> 00:12:36,394
back it up statistically? Key takeaways

201
00:12:36,442 --> 00:12:39,578
for you with this idea of Schuer charts. Be intentional with what you're measuring,

202
00:12:39,674 --> 00:12:42,880
right? Know what you're measuring and if it's making a difference or not.

203
00:12:43,490 --> 00:12:46,674
More frequent data points obviously make this easier. If you're trying

204
00:12:46,712 --> 00:12:50,626
to look at are we increasing the stability of our

205
00:12:50,648 --> 00:12:53,602
environments and you only get data points once a week,

206
00:12:53,736 --> 00:12:57,410
it's going to take a while for you to actually be able to predict stability.

207
00:12:57,750 --> 00:13:00,406
If you're trying to look at set defects. It's the same thing if you're looking

208
00:13:00,428 --> 00:13:03,926
at product releases and you're trying to see if a new feature makes a

209
00:13:03,948 --> 00:13:08,022
difference, but you only check once a month, you're going to need more

210
00:13:08,076 --> 00:13:11,498
time to get enough data to make it easier. So you

211
00:13:11,504 --> 00:13:14,522
need to figure, but how to get more frequent data. Again,

212
00:13:14,576 --> 00:13:18,598
this process has process control charts, Schuert charts, behavior charts,

213
00:13:18,694 --> 00:13:22,430
whatever you want, control charts, whatever you'd like to call it. It works for product

214
00:13:22,500 --> 00:13:25,840
releases, process releases, and tech releases as well.

215
00:13:26,370 --> 00:13:29,920
It's just math. It works all right.

216
00:13:31,730 --> 00:13:34,498
Know your actual problem, just like we talked about there.

217
00:13:34,584 --> 00:13:37,970
Now, I quickly went through some groupings,

218
00:13:38,470 --> 00:13:40,862
simple, directional,

219
00:13:41,006 --> 00:13:44,386
impactful metrics. We talked about how to know

220
00:13:44,408 --> 00:13:47,810
if the changes we're making in these metrics are actually provable.

221
00:13:48,330 --> 00:13:51,638
I want to leave you with some ideas of what I think are actually

222
00:13:51,804 --> 00:13:55,634
more interesting metrics than just cycle time, or even cycle

223
00:13:55,682 --> 00:13:59,194
time that matters, or reducing toil. Here's where my energy is

224
00:13:59,232 --> 00:14:02,890
most recently. This is a huge

225
00:14:02,960 --> 00:14:06,422
one for me, this idea of predictability versus variability.

226
00:14:06,486 --> 00:14:09,958
If you remember back in that first slide with the value stream, we talked,

227
00:14:09,984 --> 00:14:14,122
but exploit variability on the left side and minimize

228
00:14:14,186 --> 00:14:18,030
variability on the right side. Many organizations

229
00:14:18,530 --> 00:14:22,234
want more predictability, but they don't monitor

230
00:14:22,282 --> 00:14:25,506
their variability. This kind of ties in a little bit to the

231
00:14:25,528 --> 00:14:29,646
previous area where we talked about process control charts

232
00:14:29,678 --> 00:14:33,534
and Schubert charts. What I want you to think about is in many organizations,

233
00:14:33,582 --> 00:14:37,318
they have high variability in the delivery side of

234
00:14:37,324 --> 00:14:40,182
the value stream, in the build, test,

235
00:14:40,316 --> 00:14:44,294
deploy release side of the value stream. What this looks

236
00:14:44,332 --> 00:14:47,350
like, this high variability, is if you think about

237
00:14:47,420 --> 00:14:50,826
when you go to test your product releases, you go to

238
00:14:50,848 --> 00:14:54,854
test your next release. Is the test setup always predictable?

239
00:14:54,902 --> 00:14:58,646
Is the execution. If you run the tests over and over again, are the results

240
00:14:58,678 --> 00:15:03,230
the same? Is the setup of the data easy

241
00:15:03,300 --> 00:15:06,686
and predictable? Is the access consistent? And so what

242
00:15:06,708 --> 00:15:11,710
we see with a lot of organizations is that the tests are unpredictable

243
00:15:13,350 --> 00:15:16,370
in the value stream. For product delivery,

244
00:15:16,950 --> 00:15:21,074
they're unpredictable because sometimes the lower environments are

245
00:15:21,112 --> 00:15:24,446
up, sometimes they're down, sometimes the dependencies

246
00:15:24,558 --> 00:15:28,246
are available, sometimes they're not. Sometimes the firewalls are

247
00:15:28,268 --> 00:15:31,702
blocking things in lower environments, sometimes they're not. Sometimes the data is ready,

248
00:15:31,756 --> 00:15:35,478
sometimes it's not. Sometimes the data is changed. Now,

249
00:15:35,644 --> 00:15:38,874
when we have high variability on the right side of the value

250
00:15:38,912 --> 00:15:41,606
stream, in the delivery side of the execution,

251
00:15:41,798 --> 00:15:44,810
and people are asking for more predictability,

252
00:15:45,150 --> 00:15:48,986
when will it be done? How long will it take?

253
00:15:49,168 --> 00:15:53,146
The problem is not getting more predictability. The problem is getting

254
00:15:53,248 --> 00:15:56,654
less variability. And this is something that I work

255
00:15:56,692 --> 00:16:00,238
with organizations over and over on, and you can do it as well.

256
00:16:00,324 --> 00:16:03,822
And I would hope that you do it as well. Help people realize

257
00:16:03,966 --> 00:16:07,150
how much variability they have. And when you have high variability,

258
00:16:07,230 --> 00:16:10,594
predictability is out the window. You're all

259
00:16:10,712 --> 00:16:14,974
obviously very good at math. If 80%

260
00:16:15,032 --> 00:16:18,950
of the time your code works

261
00:16:19,020 --> 00:16:22,598
as expected, and then the next 80% of

262
00:16:22,604 --> 00:16:26,054
the time that all the test passed as expected, and then

263
00:16:26,092 --> 00:16:29,954
the next 80% of the time, the build works as expected,

264
00:16:30,002 --> 00:16:33,514
and then 80% of the time the deployment works as expected, and then

265
00:16:33,552 --> 00:16:36,778
80% of the time the environments work as

266
00:16:36,864 --> 00:16:40,230
expected. If you have those five events changed together,

267
00:16:40,320 --> 00:16:43,726
chained together, the overall predictability is

268
00:16:43,748 --> 00:16:47,630
not 80%, it is 0.8 to the fifth power,

269
00:16:47,780 --> 00:16:51,360
right? So six, whatever,

270
00:16:51,810 --> 00:16:55,522
four, three, you're probably under

271
00:16:55,576 --> 00:16:58,958
20%. Does the work ever get through that whole chain

272
00:16:58,974 --> 00:17:02,066
of events without having problems? So if

273
00:17:02,088 --> 00:17:06,126
you want to be predictable and you're doing your best guesses,

274
00:17:06,238 --> 00:17:10,034
knowing that only one out of five times, or even less, actually significantly

275
00:17:10,082 --> 00:17:14,054
less than 5% time, I think it's actually going to

276
00:17:14,172 --> 00:17:17,822
get through successfully. The problem isn't how do you get more predictability?

277
00:17:17,906 --> 00:17:22,086
The problem isn't add more process to become more predictable. The root

278
00:17:22,118 --> 00:17:26,230
of the problem is the variability. So we have to address variability.

279
00:17:26,390 --> 00:17:30,398
Variability also leads to large queue times,

280
00:17:30,484 --> 00:17:34,302
people and teams waiting. This is

281
00:17:34,356 --> 00:17:38,640
very expensive. So again, think about

282
00:17:39,250 --> 00:17:42,442
are we worried about predictability or are we worried about variability

283
00:17:42,506 --> 00:17:44,660
and make sure we're solving the right problem.

284
00:17:46,230 --> 00:17:49,966
Another area I work with extensively and do a lot of research lately

285
00:17:49,998 --> 00:17:52,866
on is this idea of cognitive load. Many,

286
00:17:52,968 --> 00:17:56,946
many teams, especially now that everybody is DevOps and devsecops

287
00:17:56,978 --> 00:17:58,680
and everybody does everything,

288
00:18:00,250 --> 00:18:03,586
the sheer number of contexts that teams are grappling

289
00:18:03,618 --> 00:18:07,158
with is through the roof. You can see it in this example

290
00:18:07,244 --> 00:18:11,514
here, not exactly a great piece of code through

291
00:18:11,552 --> 00:18:15,434
nobody's fault of their own. The problem is the team is working with too

292
00:18:15,472 --> 00:18:18,554
many contexts. There's too much

293
00:18:18,752 --> 00:18:22,234
work happening inside here where the code and the architecture actually isn't even

294
00:18:22,272 --> 00:18:26,266
quite set up right. And so teams have too much cognitive to load. The repos

295
00:18:26,298 --> 00:18:29,678
and the code bases get large. You can see bad couplings across

296
00:18:29,764 --> 00:18:33,002
teams and deployments, and this is a cognitive

297
00:18:33,066 --> 00:18:37,022
load problem. And so then the question becomes, how do we reduce

298
00:18:37,086 --> 00:18:40,306
cognitive load for teams? It could be

299
00:18:40,328 --> 00:18:44,066
rearchitecting. That tends to be what needs to happen quite

300
00:18:44,088 --> 00:18:47,874
a bit. It could be replatforming. But again, this idea,

301
00:18:47,912 --> 00:18:51,506
if we start looking at the cognitive load on teams, and we're measuring cognitive load

302
00:18:51,538 --> 00:18:55,234
on teams and we figure out ways of reducing the cognitive load.

303
00:18:55,362 --> 00:18:59,346
This simplifies the work that teams do significantly.

304
00:18:59,458 --> 00:19:02,634
It makes the work flow more smoothly, it makes everybody's job

305
00:19:02,672 --> 00:19:06,090
less stressful, and we just end up with a better space

306
00:19:06,160 --> 00:19:09,786
to be in. So again, I'm looking now at cognitive load on

307
00:19:09,808 --> 00:19:12,846
teams and how do I capture it, and how do I help teams lower their

308
00:19:12,868 --> 00:19:16,542
cognitive load? And that just makes everybody's day

309
00:19:16,596 --> 00:19:19,854
better. I also look at

310
00:19:19,892 --> 00:19:23,710
information lead time quite a bit. This is really interesting

311
00:19:23,780 --> 00:19:27,066
for me because the people closest to the work should decide

312
00:19:27,098 --> 00:19:29,954
the work to do and how to do the work right. So in the very

313
00:19:29,992 --> 00:19:33,458
center of the bubble here, I've done this with a few organizations where we'll put

314
00:19:33,464 --> 00:19:37,214
this up visually and we'll see when a problem comes in

315
00:19:37,272 --> 00:19:40,994
or an idea comes in, or the team themselves observes

316
00:19:41,042 --> 00:19:44,438
something that's interesting. How far up do they need to

317
00:19:44,444 --> 00:19:48,374
go to get an answer to a question, can we do this?

318
00:19:48,572 --> 00:19:51,962
Would this be a better idea? Is this an option instead?

319
00:19:52,096 --> 00:19:55,194
And so if you think about this, if the team needs to ask

320
00:19:55,232 --> 00:19:58,950
the manager's approval, and the manager needs to ask the business approval,

321
00:19:59,030 --> 00:20:02,574
and the business has to ask the execs approval to make a change that the

322
00:20:02,612 --> 00:20:06,094
team found out, then we actually have an information lead time

323
00:20:06,132 --> 00:20:09,982
problem. The team doesn't have enough

324
00:20:10,036 --> 00:20:13,760
information to make a decision close to the identification of the problem.

325
00:20:14,370 --> 00:20:18,002
Now, what can you do about this? This isn't about like,

326
00:20:18,056 --> 00:20:21,682
you need to be able to get the execs to answer questions faster or

327
00:20:21,736 --> 00:20:25,106
the business needs to have more autonomy. The root of

328
00:20:25,128 --> 00:20:28,294
this problem that we look at for how do we solve information lead

329
00:20:28,332 --> 00:20:32,006
time is providing context further down into the circles, closer to

330
00:20:32,028 --> 00:20:35,718
the work. If you have an information lead time problem,

331
00:20:35,884 --> 00:20:39,754
getting better context closer to the team, closer to where the work is

332
00:20:39,792 --> 00:20:43,674
done, is the solution. It sounds very

333
00:20:43,712 --> 00:20:46,220
easy and it is very difficult to do.

334
00:20:47,310 --> 00:20:50,554
We have to get the right context from the executives to the

335
00:20:50,592 --> 00:20:53,902
business around why investments are being made a certain way. It also

336
00:20:53,956 --> 00:20:57,962
gets into prioritization aspects. The business has to give context to management

337
00:20:58,026 --> 00:21:01,646
around the returns they're looking for and

338
00:21:01,748 --> 00:21:05,438
why they're identifying these opportunities to focus on right now. And the

339
00:21:05,444 --> 00:21:08,498
managers have to be able to bridge that gap into the team,

340
00:21:08,584 --> 00:21:11,794
and the team has to want that information and know what to do with

341
00:21:11,832 --> 00:21:15,460
it. They have to want that ownership of the product and the problem space.

342
00:21:15,850 --> 00:21:19,238
So again, information lead time way more interesting

343
00:21:19,324 --> 00:21:22,200
to me than counting cycle time.

344
00:21:23,370 --> 00:21:26,870
And lastly, I spend a lot of my time looking at social

345
00:21:26,940 --> 00:21:32,394
learning. Now, what I like about social learning is

346
00:21:32,592 --> 00:21:36,154
not only is it just kind of better for the team, right? Not only

347
00:21:36,192 --> 00:21:39,740
is it just better for, like, we have a more skilled team,

348
00:21:40,190 --> 00:21:42,800
we also have discovered things where,

349
00:21:43,490 --> 00:21:46,798
by supporting social learning, we actually lower

350
00:21:46,884 --> 00:21:50,254
the dependency upon team members. And so, to be very

351
00:21:50,292 --> 00:21:54,114
clear, what I mean by social learning is the team that is

352
00:21:54,152 --> 00:21:57,874
working on products learns together. Now,

353
00:21:57,912 --> 00:22:01,630
this doesn't mean that just the engineers

354
00:22:01,710 --> 00:22:05,350
learn one thing and just the testers learned one thing. It means the whole team

355
00:22:05,420 --> 00:22:10,066
learns together across skills and across contexts.

356
00:22:10,258 --> 00:22:14,454
It might sound silly, but I can't tell you the number of times where

357
00:22:14,652 --> 00:22:18,054
a nontechnical person, a business analyst maybe,

358
00:22:18,252 --> 00:22:21,850
would say, like, I don't know why the code looks like that.

359
00:22:22,000 --> 00:22:25,206
Can you explain it to me? And then through explaining it to the business analyst,

360
00:22:25,238 --> 00:22:28,454
they ask a question about the product that then helps the engineer.

361
00:22:28,582 --> 00:22:32,266
And conversely, if an engineer is working with some kind of

362
00:22:32,288 --> 00:22:35,706
deployment and they're trying to explain things to a test engineer,

363
00:22:35,738 --> 00:22:39,230
and the test engineer says, but how do I test it? Like this.

364
00:22:39,380 --> 00:22:42,894
You have this nice bridge of understanding, and this

365
00:22:42,932 --> 00:22:46,674
idea of social learning just amplifies a team's ability to get work

366
00:22:46,712 --> 00:22:50,914
done. So I really like this idea of social learning. There's this

367
00:22:50,952 --> 00:22:54,794
item down here at the bottom. You can kind of see it says diffusion index.

368
00:22:54,942 --> 00:22:59,110
Diffusion index is a metric that I actually look with in learning

369
00:22:59,180 --> 00:23:04,066
teams, and it looks at what's

370
00:23:04,098 --> 00:23:07,314
the gap between the highest performer and the lowest performer?

371
00:23:07,362 --> 00:23:11,174
I'm sorry, that's the wrong way of looking at the highest skilled and the lowest

372
00:23:11,222 --> 00:23:15,306
skilled on a team. And so what we mean by that is

373
00:23:15,488 --> 00:23:19,562
teams and people self assess. And we look at the gap between

374
00:23:19,696 --> 00:23:23,614
the people that self assess their skills are the highest versus the people that

375
00:23:23,652 --> 00:23:26,974
assess their skills the lowest. And what we found is

376
00:23:27,012 --> 00:23:30,654
that when we shrink that gap, when we shrink that gap between

377
00:23:30,692 --> 00:23:34,474
the highest, the perceived highest skilled, and the perceived lowest skilled across

378
00:23:34,532 --> 00:23:38,462
a team. So, across skills, when we can shrink that gap,

379
00:23:38,606 --> 00:23:42,194
we tend to have less reliancy on

380
00:23:42,232 --> 00:23:45,730
a single person to make a decision. We tend to have less reliancy on

381
00:23:45,800 --> 00:23:49,038
a single person to do a certain facet of work. And so, all of a

382
00:23:49,064 --> 00:23:52,754
sudden, those silos that exist within a team start to shrink.

383
00:23:52,882 --> 00:23:56,626
So, again, I love this idea of social learning. I love this idea of diffusion

384
00:23:56,658 --> 00:24:00,246
index. I love this idea of measuring the gaps within perceived

385
00:24:00,278 --> 00:24:04,726
skills within a team and looking at how do we address those gaps?

386
00:24:04,838 --> 00:24:08,218
Because, again, once we increase the capabilities of teams, we increase the

387
00:24:08,224 --> 00:24:12,070
capabilities of organizations, and now, all of a sudden, work is easier.

388
00:24:12,150 --> 00:24:15,966
People are less stressed out. We're not working as many hours because there

389
00:24:15,988 --> 00:24:18,970
isn't one person waiting on one person to make a decision,

390
00:24:19,050 --> 00:24:22,366
waiting on another person to make a decision. Work gets more

391
00:24:22,388 --> 00:24:25,666
enjoyable, work flows more smoothly, people are

392
00:24:25,688 --> 00:24:29,666
less stressed out. And that is a wonderful thing. So I

393
00:24:29,688 --> 00:24:32,958
gave you this kind of groupings of metrics.

394
00:24:33,054 --> 00:24:36,406
We went through some math talking about how do we

395
00:24:36,428 --> 00:24:39,606
know the changes we're doing actually make sense? And then I

396
00:24:39,628 --> 00:24:45,480
ended with where my interest is lately. And really look,

397
00:24:46,970 --> 00:24:50,214
metrics are always going to improve. Metrics are always going to get better. So always

398
00:24:50,252 --> 00:24:53,558
be thinking about what might be more interesting to you and to your organization

399
00:24:53,654 --> 00:24:57,610
and to your team. If you're looking for books, I love these books.

400
00:24:58,030 --> 00:25:00,250
The first one by a good friend, Mark Raven.

401
00:25:01,890 --> 00:25:05,934
Measures of success how to react less lead better, improve more

402
00:25:06,052 --> 00:25:10,080
Mark is a wonderful person in the lean community,

403
00:25:10,450 --> 00:25:14,346
looking at statistical analysis, statistical controls. How do you actually get continuous

404
00:25:14,378 --> 00:25:17,314
improvement in teams? I've learned a ton from Mark.

405
00:25:17,512 --> 00:25:21,442
The Schuert charts and the examples, I'm sorry, the Schuer charts come exactly

406
00:25:21,496 --> 00:25:25,026
from this book. Understanding variation the key to managing chaos from

407
00:25:25,048 --> 00:25:28,774
Donald Wheeler if you're wondering why 2.667

408
00:25:28,812 --> 00:25:33,400
is the multiplier it's explained in the book. If you're wondering, well, what happens

409
00:25:34,730 --> 00:25:38,710
if the charts are nonlinear, if they're exponential or parabolic,

410
00:25:39,530 --> 00:25:42,854
this book will get into how to handle those types of situations.

411
00:25:42,982 --> 00:25:46,106
Again, we're looking for the story, and we're just looking at how do we create

412
00:25:46,128 --> 00:25:49,894
those upper and lower bounds to find out and separate signal from noise.

413
00:25:50,022 --> 00:25:53,782
And the last book there, principles of product development flow by Don Reinerson.

414
00:25:53,926 --> 00:25:57,086
Again, I can't recommend it enough. A good economics book,

415
00:25:57,188 --> 00:26:01,262
a good way of just looking at u curve optimizations and

416
00:26:01,316 --> 00:26:05,454
other types of metrics that are probably more interesting than just counting defects.

417
00:26:05,502 --> 00:26:08,702
Counting deploys monitoring cpu uptime.

418
00:26:08,846 --> 00:26:11,140
Lots of good stuff inside there as well.

419
00:26:12,150 --> 00:26:16,034
So to recap, you can help everybody get

420
00:26:16,072 --> 00:26:20,118
better metrics. Understand where you're at, how you can improve, and always

421
00:26:20,204 --> 00:26:24,294
think about the questions you're trying to answer and

422
00:26:24,332 --> 00:26:28,050
think about what might be other ways of getting there. Be careful

423
00:26:28,130 --> 00:26:31,946
with metrics. Make sure you see the same reality as

424
00:26:31,968 --> 00:26:36,022
the people you're sharing data with. Sometimes people don't see the same reality.

425
00:26:36,086 --> 00:26:39,446
So we need to talk to data, not talk to emotion.

426
00:26:39,558 --> 00:26:43,086
Make sure we see the same reality and are going to a

427
00:26:43,108 --> 00:26:46,606
better place. Make sure if you're making changes, make sure

428
00:26:46,628 --> 00:26:49,806
your changes actually matter. And fundamentally, maybe you

429
00:26:49,828 --> 00:26:53,114
ask yourself, are we actually learning anything, or are our metrics

430
00:26:53,162 --> 00:26:56,080
just reinforcing what we already think and believe.

431
00:26:57,730 --> 00:27:01,486
That's what I got. I'll be on discord if you

432
00:27:01,508 --> 00:27:04,734
want to chat. Love to hear what questions you have. Thanks for having

433
00:27:04,772 --> 00:27:07,990
me. The slides are at that link. The slides are also

434
00:27:08,140 --> 00:27:11,254
with Con 42. Love to hear what other

435
00:27:11,292 --> 00:27:14,180
metrics you all have and what's working for you. Thanks much.

