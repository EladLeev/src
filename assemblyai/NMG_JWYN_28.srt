1
00:02:21,800 --> 00:02:24,388
Hi. Welcome to my talk.

2
00:02:24,554 --> 00:02:27,812
Pleasure to come share with you some of the lessons I've learned in building

3
00:02:27,866 --> 00:02:31,588
reliable systems. Along the way, let me jump in

4
00:02:31,594 --> 00:02:35,028
by introducing myself. My name is Kolton Andrus, CTO of a

5
00:02:35,034 --> 00:02:38,684
chaos engineering company, name Gremlin. But prior to that, I worked

6
00:02:38,722 --> 00:02:42,344
at Amazon and Netflix, where I was responsible for helping ensure

7
00:02:42,392 --> 00:02:45,980
that our systems were reliability, and that when they weren't reliable, we were

8
00:02:46,050 --> 00:02:49,436
acting and fixing it as quick as possible. Why are we

9
00:02:49,458 --> 00:02:52,840
here today? We're here today because we don't want to end up on this page.

10
00:02:52,930 --> 00:02:56,156
We don't want to end up in the news for an outage that occurred.

11
00:02:56,268 --> 00:02:59,916
And unfortunately, this is being more and more commonplace in today's

12
00:02:59,948 --> 00:03:03,428
day and age, and we feel for things and feel for the folks that

13
00:03:03,434 --> 00:03:07,040
are in these circumstances. We're operating very complex

14
00:03:07,120 --> 00:03:10,464
systems with lots of moving pieces and interconnected

15
00:03:10,512 --> 00:03:14,212
dependencies. And this makes the job of building a reliable system

16
00:03:14,346 --> 00:03:17,956
fairly difficult. In the past, this is a world where one architect or

17
00:03:17,978 --> 00:03:21,240
person could hold all of the things in their head and help and make sure

18
00:03:21,310 --> 00:03:24,024
the right decisions were being made. But today,

19
00:03:24,142 --> 00:03:27,044
reliability's problem is really everyone's problem.

20
00:03:27,182 --> 00:03:30,876
It's really up to us to be able to mitigate issues and

21
00:03:30,898 --> 00:03:34,684
failures early and often along the path, so that it

22
00:03:34,882 --> 00:03:38,424
doesn't conspire into larger failures and cascading

23
00:03:38,472 --> 00:03:41,916
failures. And so I'd love to talk a little bit about what I've

24
00:03:41,948 --> 00:03:46,364
learned and what I think is most effective in building complex distributed

25
00:03:46,412 --> 00:03:49,904
systems that are reliability. The first of a couple of

26
00:03:49,942 --> 00:03:52,956
simple tenets is to just expect failure.

27
00:03:53,148 --> 00:03:56,432
Sometimes, as engineers, we're thoughtful about the happy path,

28
00:03:56,496 --> 00:04:00,710
and we really need to be considering the alternate paths that our users may experience.

29
00:04:01,160 --> 00:04:04,756
Failure can occur at any time, at any level, and we really

30
00:04:04,778 --> 00:04:08,520
need to ensure that we're handling that failure gracefully. And by doing that,

31
00:04:08,590 --> 00:04:12,184
we're helping simplify the surface area and

32
00:04:12,302 --> 00:04:15,976
making it so that when failures do occur, there's less of us for us to

33
00:04:15,998 --> 00:04:19,296
figure. But this rolls right into the second tenant,

34
00:04:19,348 --> 00:04:23,196
which is, we need to keep our system simple. We need to, where possible,

35
00:04:23,298 --> 00:04:27,112
try to do the simpler, easier thing, as opposed to the clever

36
00:04:27,176 --> 00:04:31,016
or more complex things. As we saw in the previous slide, our systems

37
00:04:31,048 --> 00:04:35,072
are complex enough. And so a bit of a rule of thumb here is

38
00:04:35,206 --> 00:04:38,908
that if we things, some fix, some optimization

39
00:04:39,004 --> 00:04:43,264
is going to yield an order of magnitude better performance. Then it's probably worth

40
00:04:43,302 --> 00:04:47,456
that overhead or complexity. But if we're seeing only an incremental gain,

41
00:04:47,568 --> 00:04:51,392
we may want to think about the side effects of that additional

42
00:04:51,456 --> 00:04:55,364
complex and choose to leave it. But the

43
00:04:55,402 --> 00:04:58,996
next one is also one that's probably fairly straightforward and you've

44
00:04:59,028 --> 00:05:02,504
heard before, but we need to talk about it. We need

45
00:05:02,542 --> 00:05:05,864
redundancy. We need redundancy in our hosts and containers. We need

46
00:05:05,902 --> 00:05:09,576
redundancy in our data. We need redundancy in the ways in which we can

47
00:05:09,598 --> 00:05:13,320
do work within our system. Ultimately, a lot of failure

48
00:05:13,400 --> 00:05:16,876
testing and a lot of reliability comes down to, is there another way to get

49
00:05:16,898 --> 00:05:20,956
it done, or are we at a hard failure point? And so,

50
00:05:21,058 --> 00:05:24,736
thinking about our single points of failure and how to mitigate those

51
00:05:24,838 --> 00:05:28,428
along the way help us to balance that concern.

52
00:05:28,524 --> 00:05:32,130
Now, I will mention the keep things simple is also somewhat in

53
00:05:32,500 --> 00:05:36,180
conflict with this. And if you have redundant everything, you actually

54
00:05:36,250 --> 00:05:40,020
have a much more complicated system than a single instance of everything.

55
00:05:40,090 --> 00:05:43,408
So we need to weigh the pros and cons of that approach.

56
00:05:43,584 --> 00:05:47,016
How do we test to know if we're in compliance with this?

57
00:05:47,118 --> 00:05:50,564
The question is, are we comfortable bringing down a host,

58
00:05:50,692 --> 00:05:53,944
a service, a zone, a region? If we

59
00:05:53,982 --> 00:05:57,684
are, then we feel good that our system will continue operating

60
00:05:57,732 --> 00:06:00,744
and the right things will happen. If we don't have that confidence.

61
00:06:00,792 --> 00:06:04,828
If we're unwilling to do it, then we're probably not there yet.

62
00:06:04,994 --> 00:06:08,108
By the way, this is why chaos monkey was built, is that in

63
00:06:08,114 --> 00:06:12,076
the cloud, hosts can fail, and we have to be able to handle that contingency.

64
00:06:12,188 --> 00:06:16,492
And by forcing it to occur to our engineers, and that's a social strategy,

65
00:06:16,636 --> 00:06:20,016
then we're expecting them to consider and be able

66
00:06:20,038 --> 00:06:23,424
to address, and we're able to handle those

67
00:06:23,462 --> 00:06:26,836
host failures. Next, I want to think a little bit

68
00:06:26,858 --> 00:06:30,756
about how we design for operations. We often don't think

69
00:06:30,778 --> 00:06:34,212
about operations when we're designing our services. We wait until it's built

70
00:06:34,266 --> 00:06:37,432
or deployed or until there's an issue to really come back and

71
00:06:37,486 --> 00:06:40,760
put a fine tooth comb through things.

72
00:06:40,910 --> 00:06:44,600
And so if we consider this earlier on one, we can think about

73
00:06:44,670 --> 00:06:47,784
how to observe the service. How do we know that it's behaving well?

74
00:06:47,822 --> 00:06:51,548
And more than just error rates at the front door, how do we know that

75
00:06:51,714 --> 00:06:55,244
the underlying components are healthy and that they're performing the way

76
00:06:55,282 --> 00:06:58,956
we expect? We need to expose configurability that allows us

77
00:06:58,978 --> 00:07:03,024
to tune and to make sure that the system has the right

78
00:07:03,142 --> 00:07:06,130
edges and the right points that are going to protect itself.

79
00:07:06,500 --> 00:07:10,224
And all of these things that we're building likely should be treated as first

80
00:07:10,262 --> 00:07:14,196
class citizens with our source code checked into source control for

81
00:07:14,218 --> 00:07:17,264
our configurations, our runbooks, or our alerts,

82
00:07:17,312 --> 00:07:21,076
our monitors, our scripts. Next, we just need

83
00:07:21,098 --> 00:07:24,896
to think about this a little earlier and more consistently throughout

84
00:07:24,928 --> 00:07:28,244
the process. If we, similar to test driven

85
00:07:28,292 --> 00:07:31,496
development, are thinking about the failure modes up front,

86
00:07:31,598 --> 00:07:34,600
we're more likely to be able to leave room for them,

87
00:07:34,670 --> 00:07:38,104
design for them, or be able to address them, than if we have to come

88
00:07:38,142 --> 00:07:41,836
back and duct tape a solution on after the fact. If the

89
00:07:41,858 --> 00:07:44,988
case here, every time we add a new dependency to our service,

90
00:07:45,074 --> 00:07:48,936
is a great opportunity to ask ourselves, is this a critical dependency?

91
00:07:49,048 --> 00:07:52,210
Can I gracefully degrade? Do I really need it?

92
00:07:54,100 --> 00:07:57,088
Lastly, we want to be thoughtful about traffic control.

93
00:07:57,254 --> 00:08:00,464
Our services. We never want to allow in more work than

94
00:08:00,502 --> 00:08:04,096
we're able to complete. And so in interest of protecting ourselves and

95
00:08:04,118 --> 00:08:07,744
the work we have taken on, we need to shed work if we're unable

96
00:08:07,792 --> 00:08:11,844
to do it well. This creates a faster failure loop for our

97
00:08:11,882 --> 00:08:14,788
consumers that help them understand the state of our service,

98
00:08:14,874 --> 00:08:18,536
as opposed to a delay and a wait while things are

99
00:08:18,558 --> 00:08:22,216
unknown. Similarly, when we're calling our dependencies, it's an

100
00:08:22,238 --> 00:08:26,296
opportunity for us to a be good citizens and b protect ourselves if

101
00:08:26,318 --> 00:08:29,512
that dependency fails, and the circuit breaker pattern works

102
00:08:29,566 --> 00:08:33,196
wonders here. First, if that service is

103
00:08:33,218 --> 00:08:36,312
failing, we don't want to continue calling it. We don't want to make things worse,

104
00:08:36,376 --> 00:08:38,988
and if we know the outcome is going to be a failure, we don't want

105
00:08:38,994 --> 00:08:42,296
to waste our time. But second, if that service is failing,

106
00:08:42,328 --> 00:08:46,252
often circuit breakers are helping us to think about how we could gracefully

107
00:08:46,316 --> 00:08:49,584
degrade. What do we do if that does fail? And what other

108
00:08:49,702 --> 00:08:54,276
source of truth could we find for that information to

109
00:08:54,298 --> 00:08:58,384
steal a page from the security world? I think that failure

110
00:08:58,432 --> 00:09:01,504
modeling is actually a very useful exercise as we're

111
00:09:01,552 --> 00:09:05,396
designing and building our systems. And it's worth the team's time to

112
00:09:05,418 --> 00:09:08,904
spend a little bit of time together brainstorming. What are the types of things

113
00:09:08,942 --> 00:09:12,664
that could go wrong? What happens if two things go wrong at the same time?

114
00:09:12,782 --> 00:09:15,896
Which of these failures are non starters are things

115
00:09:15,918 --> 00:09:19,384
that we just must live with, that we cannot change? And what are the failures

116
00:09:19,432 --> 00:09:22,908
that we can turn into non failures by gracefully degrading that

117
00:09:22,914 --> 00:09:26,472
we can ensure behave the way we expect? Ultimately,

118
00:09:26,536 --> 00:09:30,760
this is a risk assessment, and it's a business and a technological decision

119
00:09:30,840 --> 00:09:34,496
in what we think sounds most appropriate. And so the one

120
00:09:34,518 --> 00:09:37,548
but of advice I'll give here is that many things can fail.

121
00:09:37,644 --> 00:09:41,468
And it seems like the combination of failure might be rare.

122
00:09:41,564 --> 00:09:45,264
But as we're dealing with components, with thousands of moving pieces,

123
00:09:45,312 --> 00:09:48,964
perhaps many, many more failure becomes commonplace. And something

124
00:09:49,002 --> 00:09:52,164
that seemed unlikely may occur more frequently than you

125
00:09:52,202 --> 00:09:56,388
think. A little visual for how we think about this is

126
00:09:56,474 --> 00:10:00,216
looking at a service diagram. And from this we can get a view of the

127
00:10:00,238 --> 00:10:03,880
dependencies that we rely upon. We can reason about how important

128
00:10:03,950 --> 00:10:07,000
those dependencies are. In the case of an ecommerce app,

129
00:10:07,070 --> 00:10:10,028
we know that the checkout service is being to be critical and we're not going

130
00:10:10,034 --> 00:10:13,452
to be able to perform meaningful work without it. But something

131
00:10:13,506 --> 00:10:17,084
like the recommendation service that offers other things we might like to

132
00:10:17,122 --> 00:10:20,312
buy could fail and we could hide from the user

133
00:10:20,376 --> 00:10:23,856
and they could still continue on completing the mission that they

134
00:10:23,878 --> 00:10:26,000
have come to us to accomplish.

135
00:10:27,220 --> 00:10:30,544
Which leads us to talk a little bit about our dependencies. There's more than

136
00:10:30,582 --> 00:10:33,984
just the services we rely on when it comes to the dependencies.

137
00:10:34,112 --> 00:10:37,792
There's infrastructure, there's the network, there's our cloud providers,

138
00:10:37,856 --> 00:10:41,104
there's our external service provider tools,

139
00:10:41,152 --> 00:10:44,544
whether that's a database, whether we need to hit the IRS's

140
00:10:44,592 --> 00:10:48,312
or the government's financial services to get the latest interest rate.

141
00:10:48,446 --> 00:10:51,736
There's lots of moving pieces here, and the first step is

142
00:10:51,758 --> 00:10:55,000
just being aware of them. Do we know what we rely upon?

143
00:10:55,900 --> 00:10:59,876
The second piece is knowing what's critical. And for those things that we rely

144
00:10:59,908 --> 00:11:03,352
upon, do we need it? Must we need it? In many cases,

145
00:11:03,416 --> 00:11:06,508
this is often a bit of a guess. And from my experience,

146
00:11:06,594 --> 00:11:10,620
this is a great place where failure testing comes into play. By going and

147
00:11:10,690 --> 00:11:14,096
actually causing the failure of a dependency, we can see if the

148
00:11:14,118 --> 00:11:17,248
system is able to withstand it and we can test if we're able to

149
00:11:17,254 --> 00:11:21,004
gracefully degrade. And that's how we turn as many critical

150
00:11:21,052 --> 00:11:24,064
failures into non critical failures was possible.

151
00:11:24,262 --> 00:11:28,336
Now, some we're going to have to rely upon,

152
00:11:28,448 --> 00:11:31,716
and in those cases, we want to work with those teams to make sure that

153
00:11:31,738 --> 00:11:35,220
they're doing the best they can to build a highly reliability service.

154
00:11:35,370 --> 00:11:38,660
If we're trying to build a service with four nines of uptime

155
00:11:38,740 --> 00:11:42,424
on top of a bunch of services that have three nines of uptime, we're probably

156
00:11:42,462 --> 00:11:45,576
going to be disappointed, because as we do the math on

157
00:11:45,598 --> 00:11:49,356
the availability of those services, it actually gets a little worse as we

158
00:11:49,378 --> 00:11:53,304
compose them, not better. So I want to share a quote

159
00:11:53,352 --> 00:11:57,128
that's one of my personal favorites from James Hamilton comes from on designing

160
00:11:57,144 --> 00:12:01,052
and deploying Internet scale services. It's about 15 years old,

161
00:12:01,106 --> 00:12:04,464
but the advice in there is all applicable and

162
00:12:04,502 --> 00:12:08,016
a great read and worth your time. But he essentially challenges us

163
00:12:08,038 --> 00:12:11,392
that if we're unwilling to go fail our data centers and go cause

164
00:12:11,446 --> 00:12:14,592
the failures that occur, that we're not actually confident

165
00:12:14,656 --> 00:12:17,888
our system can withstand them. And if we're unwilling

166
00:12:17,904 --> 00:12:21,696
to go do this testing and to validate our recovery

167
00:12:21,728 --> 00:12:25,460
mechanisms, then likely those recovery mechanisms won't work

168
00:12:25,530 --> 00:12:29,636
when needed. And as someone who's been in this situation in the past, if there's

169
00:12:29,748 --> 00:12:33,236
two failures that are happening at the same time, and we're

170
00:12:33,268 --> 00:12:37,044
going to go out and mitigate them, and we have a recovery mechanism that doesn't

171
00:12:37,092 --> 00:12:40,440
work, now we're dealing with multiple failures. We have to debug,

172
00:12:40,520 --> 00:12:42,990
diagnose and fix at the same time,

173
00:12:44,000 --> 00:12:46,732
while in the middle of dealing with it, in the middle of the night,

174
00:12:46,786 --> 00:12:50,296
urgently. And so we want those recovery mechanisms

175
00:12:50,328 --> 00:12:53,216
that are there to save us and to make things go smoothly. We want to

176
00:12:53,238 --> 00:12:55,890
make sure they work and have confidence in them.

177
00:12:56,500 --> 00:12:59,760
So, great. What should you do today?

178
00:12:59,910 --> 00:13:03,376
What are the most effective places to begin for a team that's new to this,

179
00:13:03,398 --> 00:13:07,124
or a team that wants to get better at this? The first is go hit

180
00:13:07,162 --> 00:13:11,040
redundancy. Start simple. Make sure you can lose a host.

181
00:13:11,200 --> 00:13:14,776
Graduate to being able to lose a zone or a data center, not your

182
00:13:14,798 --> 00:13:18,024
entire application, but a big piece of it. And then

183
00:13:18,062 --> 00:13:22,228
lastly, turn your disaster recovery plan from an academic paper exercise

184
00:13:22,324 --> 00:13:25,784
into a real live exercise that your

185
00:13:25,822 --> 00:13:29,224
company executes. Do a failover between zones or

186
00:13:29,262 --> 00:13:32,796
regions, do a traffic shift, and I promise you, you'll find and

187
00:13:32,818 --> 00:13:36,124
uncover lots of little things you weren't aware of that would have caused this

188
00:13:36,162 --> 00:13:39,016
to be a problem. If the real world event occurs,

189
00:13:39,128 --> 00:13:42,192
and having lived through that, you can make it so that when the real event

190
00:13:42,246 --> 00:13:45,970
occurs, it can run smoothly. And that's what we want here.

191
00:13:46,500 --> 00:13:50,064
The second thing is to understand our dependencies. First, we must

192
00:13:50,102 --> 00:13:53,580
know them all. Next, we must know which of them are critical,

193
00:13:53,660 --> 00:13:57,024
which we can do by going and testing them with a hard failure.

194
00:13:57,152 --> 00:14:00,724
And then lastly, we can tune how we operate and interact with those

195
00:14:00,762 --> 00:14:04,324
dependencies to ensure that we back off, that we time out,

196
00:14:04,362 --> 00:14:07,850
or that we stop calling them if things are going wrong.

197
00:14:08,620 --> 00:14:12,456
Lastly, and not to be understated, we need to be able to train our

198
00:14:12,478 --> 00:14:15,592
teams. Some folks have been living this for many years.

199
00:14:15,646 --> 00:14:19,448
Some folks are new to this approach and giving them a place to

200
00:14:19,534 --> 00:14:23,084
ask questions, a place to practice, a place

201
00:14:23,122 --> 00:14:26,412
to ensure that they can get the runbooks and that they're up to date,

202
00:14:26,466 --> 00:14:29,628
that they know what the alerts and the monitors look like, that they have access

203
00:14:29,714 --> 00:14:33,452
to their systems is paramount. It's key to allow people

204
00:14:33,506 --> 00:14:36,856
to practice and train during the day, after the coffee's kicked

205
00:14:36,888 --> 00:14:40,510
in, as opposed to 02:00 in the morning when things are going wrong,

206
00:14:40,960 --> 00:14:42,850
you so with that, I want to thank you.

