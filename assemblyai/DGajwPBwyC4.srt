1
00:00:23,290 --> 00:00:27,382
Hi, welcome to this session on several architecture for product defect detection using

2
00:00:27,436 --> 00:00:31,186
computer vision. My name is Mohsin Khan. I'm a solutions architect

3
00:00:31,218 --> 00:00:34,854
at Amazon Web Services. Let's get

4
00:00:34,892 --> 00:00:38,738
started. In this session I'll be taking you through how computer vision

5
00:00:38,754 --> 00:00:42,150
can be applied to industrial use cases and why is quality

6
00:00:42,220 --> 00:00:45,910
such an important aspect to manage for manufacturing organizations?

7
00:00:46,570 --> 00:00:50,414
We'll have a look at Amazon Lookout for vision, followed up a review

8
00:00:50,452 --> 00:00:54,314
of a solution architecture, product product, product defect detection, computer vision

9
00:00:54,362 --> 00:00:57,918
and serverless services. And finally, there's going to

10
00:00:57,924 --> 00:01:01,438
be a solution demonstration and some resources that you can have a look at

11
00:01:01,444 --> 00:01:02,590
for further reading.

12
00:01:05,610 --> 00:01:09,314
Computer vision can be utilized across the various

13
00:01:09,362 --> 00:01:12,566
stages of industrial processes. Now, manufacturing by its

14
00:01:12,588 --> 00:01:16,734
nature is a very complex and convoluted process, started from starting from production

15
00:01:16,882 --> 00:01:19,274
down to assembling resource, assembling a product,

16
00:01:19,392 --> 00:01:23,274
packaging, logistics, and then storage of the products.

17
00:01:23,472 --> 00:01:26,806
It can be applied to a variety of scenarios from asset

18
00:01:26,838 --> 00:01:30,640
management, worker safety, quality assurance and process control.

19
00:01:31,410 --> 00:01:34,990
In this session, I'll be focusing on the quality management aspect

20
00:01:35,650 --> 00:01:37,550
of the industrial processes.

21
00:01:39,330 --> 00:01:43,166
Within quality management, there are a number of use cases

22
00:01:43,198 --> 00:01:47,570
that we can cater to with computer vision, such as automated quality inspection,

23
00:01:48,070 --> 00:01:51,422
root cause analysis, reducing product defects,

24
00:01:51,486 --> 00:01:53,010
and optimizing yield.

25
00:01:55,050 --> 00:01:58,150
Let's first have a look at why quality is such an important

26
00:01:58,220 --> 00:02:02,050
aspect for manufacturing or industrial organizations.

27
00:02:02,210 --> 00:02:04,870
Now, quality impacts the cost of operations,

28
00:02:05,370 --> 00:02:09,274
costs to operations and customers, and many organizations will

29
00:02:09,312 --> 00:02:12,922
have true quality related cost as high as 15% to 20%,

30
00:02:13,056 --> 00:02:15,820
as reported by Aberdeen Strategy Research.

31
00:02:16,430 --> 00:02:20,206
Now, some customers even go as high as 40%. This is a

32
00:02:20,228 --> 00:02:22,350
huge fraction of their sales revenue.

33
00:02:24,210 --> 00:02:27,870
So what sort of factors and metrics contribute to these costs?

34
00:02:28,530 --> 00:02:32,366
Some of the top metrics include defect rework,

35
00:02:32,478 --> 00:02:35,986
scrapping, customer returns, complaints and warranty and

36
00:02:36,008 --> 00:02:39,426
corrective action processes. To give you

37
00:02:39,448 --> 00:02:43,394
a reference point, in 2018, us based manufacturing are

38
00:02:43,432 --> 00:02:47,202
estimated to spend about $26 billion in total

39
00:02:47,256 --> 00:02:50,934
claims. So managing quality is

40
00:02:50,972 --> 00:02:52,870
a very important challenge to solve.

41
00:02:54,170 --> 00:02:58,010
So what are organizations currently doing for quality

42
00:02:58,160 --> 00:03:01,814
assurance? For starters, there's a manual inspection

43
00:03:01,862 --> 00:03:04,902
process both inline and in offline inspection.

44
00:03:05,046 --> 00:03:08,266
And though this process is agile and flexible, it lacks in

45
00:03:08,288 --> 00:03:11,242
throughput. It has a slower feedback loop,

46
00:03:11,306 --> 00:03:15,454
it's a matter of days, hours or

47
00:03:15,492 --> 00:03:18,862
minutes, and again, it's prone to human

48
00:03:18,916 --> 00:03:22,626
error, so the results could

49
00:03:22,648 --> 00:03:26,526
be subjective or incomplete as well. There are machine

50
00:03:26,558 --> 00:03:29,906
vision solutions available as well, and although they're fast and

51
00:03:29,928 --> 00:03:33,810
repeatable with a lower cost of inspection and

52
00:03:33,880 --> 00:03:37,086
faster feedback loop, but they have high upfront costs

53
00:03:37,198 --> 00:03:41,386
that limit coverage and are inflexible and may need purpose

54
00:03:41,438 --> 00:03:44,706
built hardware or cameras to be able to cater

55
00:03:44,738 --> 00:03:47,370
to automated defect detection.

56
00:03:49,310 --> 00:03:52,682
Now, this is where Amazon Lookout provision comes in. It's a machine learning service

57
00:03:52,736 --> 00:03:56,614
that allows you to detect or spot product defects and visual representations

58
00:03:56,662 --> 00:03:58,090
using computer vision.

59
00:04:00,190 --> 00:04:03,806
Let's have a look at the different stacks that we have for

60
00:04:03,828 --> 00:04:07,514
our machine learning services. Now at AWS, we are innovating

61
00:04:07,562 --> 00:04:11,066
on behalf of our customers to deliver the broadest and deepest set of

62
00:04:11,188 --> 00:04:14,926
machine learning capabilities so that builders of all levels

63
00:04:14,958 --> 00:04:18,958
of experience can use them and remove the undifferentiated heavy lifting

64
00:04:19,054 --> 00:04:22,610
that's required in building, training and deploying machine learning models.

65
00:04:23,990 --> 00:04:27,682
Amazon Lookout provision lies within the specialized

66
00:04:27,746 --> 00:04:29,720
stack of AI services,

67
00:04:30,970 --> 00:04:35,058
so it's completely focused on industrial use cases and it's

68
00:04:35,074 --> 00:04:38,838
been specially designed to cater to such scenarios

69
00:04:39,014 --> 00:04:40,330
and use cases.

70
00:04:43,640 --> 00:04:47,108
Apart from Amazon lookout for vision, there are a number of industrial AI services

71
00:04:47,194 --> 00:04:50,904
that are also there. There is Amazon lookout for

72
00:04:50,942 --> 00:04:54,404
equipment and Amazon monitoring that help you with real time condition

73
00:04:54,452 --> 00:04:58,490
monitoring. There's also AWS Panorama that enables your

74
00:04:59,580 --> 00:05:02,600
standard IP cameras with computer vision.

75
00:05:03,820 --> 00:05:07,468
But we'll keep the focus on Amazon lookout for vision and the

76
00:05:07,474 --> 00:05:09,870
automated quality management use case. Here,

77
00:05:14,080 --> 00:05:17,388
let's have a look at how computer vision can be done at scale and

78
00:05:17,394 --> 00:05:21,024
what are the challenges that it presents. I'll focus on three main

79
00:05:21,062 --> 00:05:25,200
areas. To be able to do computer vision and use computer

80
00:05:25,270 --> 00:05:29,280
vision, you have to first have access to sufficient images of product

81
00:05:29,350 --> 00:05:32,916
defects. Once you have that, you'll need to

82
00:05:33,018 --> 00:05:36,452
spend a lot of time in training, validating and testing machine learning

83
00:05:36,506 --> 00:05:40,164
models. Secondly, once you have a model with

84
00:05:40,202 --> 00:05:43,716
a traditional on premises model, you will have to deploy it on

85
00:05:43,738 --> 00:05:47,812
some infrastructure that you'll have to manage that presents challenges

86
00:05:47,876 --> 00:05:51,448
with scalability and compute requirements as

87
00:05:51,454 --> 00:05:56,516
well as security AWS well. And finally, from a liability

88
00:05:56,628 --> 00:05:59,976
point of view, you will have limited support for improving your machine

89
00:06:00,008 --> 00:06:03,020
learning models at the plant or a manufacturing facility.

90
00:06:04,480 --> 00:06:07,980
So how does Amazon lookout for vision tackle these challenges?

91
00:06:08,640 --> 00:06:11,772
With lookout for vision, you can create a custom machine learning model

92
00:06:11,826 --> 00:06:15,296
with as few AWS 30 images, and importantly, without any

93
00:06:15,318 --> 00:06:18,876
sort of machine learning expertise. You can run your machine

94
00:06:18,908 --> 00:06:22,752
learning models in the cloud and even use low resolution

95
00:06:22,816 --> 00:06:26,116
cameras for gathering your

96
00:06:26,138 --> 00:06:28,630
data and training a machine learning model.

97
00:06:29,720 --> 00:06:33,428
Amazon lookout for vision can help you train machine

98
00:06:33,444 --> 00:06:37,188
learning models in diverse conditions

99
00:06:37,204 --> 00:06:40,056
as well. Finally,

100
00:06:40,158 --> 00:06:43,796
your process engineers and quality managers or operators can provide feedback

101
00:06:43,828 --> 00:06:47,416
from machine learning models in real time, and thereby

102
00:06:47,448 --> 00:06:51,580
it allows you to iteratively and continuously improve the performance of your models.

103
00:06:52,240 --> 00:06:55,976
Now, all of this, you don't need to have any machine learning expertise,

104
00:06:56,168 --> 00:06:59,648
and also you don't need to maintain any sort

105
00:06:59,654 --> 00:07:03,260
of servers or differences

106
00:07:03,420 --> 00:07:05,840
or need to deploy your model anywhere.

107
00:07:10,200 --> 00:07:13,480
So what are some of the use cases that lookout for vision can tackle?

108
00:07:13,820 --> 00:07:17,876
Lookout for vision can tackle use cases ranging from detecting surface

109
00:07:17,908 --> 00:07:21,064
defects to shape defects. It can also

110
00:07:21,102 --> 00:07:24,852
help you identify the absence, presence or misalignment

111
00:07:24,916 --> 00:07:28,792
of objects in an image. It can also help you uncover

112
00:07:28,856 --> 00:07:32,460
consistency issues such as in a steel coil or a paper roll.

113
00:07:36,140 --> 00:07:39,524
What is a typical customer journey for lookup

114
00:07:39,572 --> 00:07:43,548
revision? So we start with gathering the

115
00:07:43,634 --> 00:07:47,724
data set or gathering the images, which is known as image acquisition part.

116
00:07:47,922 --> 00:07:51,352
Once we have the images for our defects and normal

117
00:07:51,496 --> 00:07:55,024
products, we can upload them to Amazon history or

118
00:07:55,062 --> 00:07:59,040
we can import them into Amazon lookout for vision via its console.

119
00:08:01,620 --> 00:08:05,380
The images can be labeled or put in prenamed folders called

120
00:08:05,530 --> 00:08:09,108
as normal and anomaly. Once we have the images and the

121
00:08:09,114 --> 00:08:12,310
data set created, we can start model training.

122
00:08:13,240 --> 00:08:16,944
Once a model is trained, we can visualize

123
00:08:16,992 --> 00:08:20,436
its performance via the console dashboard, which provides

124
00:08:20,468 --> 00:08:24,520
us metrics like precision, recall and f one score.

125
00:08:25,020 --> 00:08:29,152
And finally, once our model is trained and we are satisfied with its performance,

126
00:08:29,236 --> 00:08:32,536
we can integrated inferencing into our application via

127
00:08:32,568 --> 00:08:33,950
simple API call.

128
00:08:36,900 --> 00:08:40,716
And once we get more and more data, we can work on iteratively

129
00:08:40,748 --> 00:08:43,360
improving a model through feedback.

130
00:08:46,600 --> 00:08:49,984
Lookout for Vision provides you binary image classification differences

131
00:08:50,032 --> 00:08:53,508
result. And once you get that result,

132
00:08:53,594 --> 00:08:57,520
it allows a user to make a number of decisions ranging from classification

133
00:08:57,680 --> 00:09:00,410
rating of the product, binning the product,

134
00:09:00,940 --> 00:09:04,408
scrapping it, or maybe using the result for

135
00:09:04,494 --> 00:09:08,244
investigating a process and also for improving the machine learning

136
00:09:08,302 --> 00:09:12,124
model. So overall you are able to make your decisions with

137
00:09:12,162 --> 00:09:14,510
more accuracy and in less time.

138
00:09:17,200 --> 00:09:19,150
Let's take a look at a quick demo.

139
00:09:26,020 --> 00:09:29,184
So as I mentioned, we start

140
00:09:29,222 --> 00:09:32,904
with an image acquisition process. So first we have to gather

141
00:09:32,972 --> 00:09:36,356
images for our product. Here we

142
00:09:36,378 --> 00:09:40,276
have can image of a defective printed circuit board which

143
00:09:40,298 --> 00:09:42,230
has got scratches on its side.

144
00:09:44,980 --> 00:09:48,704
There's another image for a printed circuit board

145
00:09:48,742 --> 00:09:50,390
which has got bent pins here.

146
00:09:52,840 --> 00:09:56,544
And finally, there's another defect here with improper

147
00:09:56,592 --> 00:10:00,168
soldering. Once we

148
00:10:00,174 --> 00:10:04,004
have gathered our images for the defects,

149
00:10:04,052 --> 00:10:07,396
we can get started with creating a lookout for vision

150
00:10:07,428 --> 00:10:10,616
model. So we start by logging into the

151
00:10:10,638 --> 00:10:14,030
AWS console, go to lookout for vision service,

152
00:10:16,900 --> 00:10:20,576
and we get started with the initial setup which is creating an

153
00:10:20,598 --> 00:10:24,160
s three bucket which is going to host our project's artifacts.

154
00:10:26,280 --> 00:10:28,710
Then we'll create a project,

155
00:10:31,080 --> 00:10:34,884
we give a project name, and then we

156
00:10:34,922 --> 00:10:37,590
move on to creating a data set.

157
00:10:38,280 --> 00:10:41,464
To be able to set up a data set, we first create a folder on

158
00:10:41,502 --> 00:10:45,096
s three. In that folder. We can create a

159
00:10:45,118 --> 00:10:48,836
couple of folders called anomaly and normal.

160
00:10:48,948 --> 00:10:53,240
This will enable lookout for vision to infer the label on the images automatically.

161
00:10:54,140 --> 00:10:57,388
Now that we have uploaded our images onto s three, we can copy the s

162
00:10:57,394 --> 00:11:01,096
three Uri for the bucket and we go on to lookout provision

163
00:11:01,128 --> 00:11:03,070
console and create a data set.

164
00:11:04,560 --> 00:11:07,824
We've got the option to create a single data set or training and test data

165
00:11:07,862 --> 00:11:11,168
set. In this case, we go forward with a single data set.

166
00:11:11,334 --> 00:11:15,116
We import images from the s three bucket by providing

167
00:11:15,148 --> 00:11:18,720
the s three bucket Uri and we check on automatically

168
00:11:18,800 --> 00:11:24,994
attach labels to images based on the folder the

169
00:11:25,032 --> 00:11:28,846
images have already been placed into. Normally a normal folder, so lookout for vision

170
00:11:28,878 --> 00:11:32,520
can simply infer the labels by looking at the folder name.

171
00:11:33,050 --> 00:11:37,080
Now that we have the data set up, let's move on to training a model.

172
00:11:39,690 --> 00:11:43,160
Training a model is as simple as just clicking the train model button.

173
00:11:46,120 --> 00:11:49,416
Once we click the train model button and process with

174
00:11:49,438 --> 00:11:52,884
the next steps, it's going to take some time depending on the number of images

175
00:11:52,932 --> 00:11:56,844
we have in the data set. As soon as the model training is complete,

176
00:11:56,962 --> 00:12:00,984
we can have a look at its model performance

177
00:12:01,032 --> 00:12:04,940
metrics like precision, recall and f one score

178
00:12:05,760 --> 00:12:08,270
and have a look at the test results as well.

179
00:12:15,650 --> 00:12:19,246
Apart from this, once we have a model train and

180
00:12:19,268 --> 00:12:23,198
running we can do trial detections which allow us to provide

181
00:12:23,364 --> 00:12:26,906
feedback so that we can integrate

182
00:12:26,938 --> 00:12:31,426
that feedback into a new model version to

183
00:12:31,448 --> 00:12:34,866
be able to do trial detection, we create a new task for

184
00:12:34,888 --> 00:12:39,090
trial detection. We select the right model and select the images

185
00:12:39,690 --> 00:12:41,750
against which we want to run inferencing.

186
00:12:45,650 --> 00:12:49,086
We choose the files or the image files that we want

187
00:12:49,108 --> 00:12:50,640
to test against our model.

188
00:13:00,050 --> 00:13:04,690
Once the images are uploaded into lookout provision for the trial detection task,

189
00:13:07,030 --> 00:13:08,930
we're going to get some results.

190
00:13:10,470 --> 00:13:14,098
Looking at the once a trial detection task is completed, we'll have a

191
00:13:14,104 --> 00:13:17,430
look at the results and we can provide feedback so we get to know

192
00:13:17,500 --> 00:13:20,930
if the model classified those images AWS anomalous or normal,

193
00:13:21,010 --> 00:13:23,670
and we also get their associated confidence score.

194
00:13:24,730 --> 00:13:29,194
Now we can verify machine productions so

195
00:13:29,232 --> 00:13:32,554
we can provide feedback whether the inference results were correct or

196
00:13:32,592 --> 00:13:36,300
incorrect. And once we have done that, we can

197
00:13:37,550 --> 00:13:40,958
feed this back into the model, into the data set

198
00:13:41,044 --> 00:13:42,640
and retrain our model.

199
00:13:49,080 --> 00:13:52,790
This allows us to improve our

200
00:13:53,400 --> 00:13:55,750
model iteratively over time.

201
00:14:04,560 --> 00:14:07,900
Finally, let's see how we can work with the AWS CLI

202
00:14:08,060 --> 00:14:11,616
or the command line interface. Now, to use

203
00:14:11,638 --> 00:14:14,656
the model, we first have to start it so we can do it via the

204
00:14:14,678 --> 00:14:17,910
CLI or the SDK as well.

205
00:14:18,600 --> 00:14:22,070
So we start the model first via the command line.

206
00:14:26,630 --> 00:14:31,586
There are a number of API or command line interface commands

207
00:14:31,618 --> 00:14:35,974
that you can use. So once

208
00:14:36,012 --> 00:14:40,070
the model is started, we can run detect anomalies by providing

209
00:14:40,970 --> 00:14:45,194
an image and get

210
00:14:45,232 --> 00:14:48,486
an anomalies result along with the associated

211
00:14:48,518 --> 00:14:52,314
confidence score. Now that we have set up our

212
00:14:52,352 --> 00:14:56,314
model and have some context, let's move on to the

213
00:14:56,352 --> 00:15:00,334
solutions architect for product defect detection. So we start by

214
00:15:00,372 --> 00:15:03,614
establishing our users or personas who are going to be

215
00:15:03,652 --> 00:15:07,726
involved in the overall solution. So first up we've got the camera that

216
00:15:07,748 --> 00:15:11,138
has got some compute capability or a client application

217
00:15:11,224 --> 00:15:14,946
that's responsible for aggregating images, collecting them and

218
00:15:14,968 --> 00:15:16,740
then sending them across to the cloud.

219
00:15:18,230 --> 00:15:21,870
Then we have our data science or admin users and their main responsibility

220
00:15:21,950 --> 00:15:25,666
is going to be managing the training, the lookout for vision

221
00:15:25,698 --> 00:15:29,526
model, and managing its startup and shutdown. We have

222
00:15:29,548 --> 00:15:33,958
our business users and these could be our c level or executives or

223
00:15:34,124 --> 00:15:37,834
our vps who'd be mainly interested in gaining or visualizing those

224
00:15:37,872 --> 00:15:41,834
insights from the manufacturing process or the defect detection process.

225
00:15:42,032 --> 00:15:45,694
And finally, our quality managers and operators would be mainly concerned about

226
00:15:45,732 --> 00:15:49,566
getting notifications and alerts whenever a defect is detected so they can

227
00:15:49,588 --> 00:15:51,390
take appropriate actions.

228
00:15:55,970 --> 00:15:59,498
At the heart of this solution is going to be lookout for vision

229
00:15:59,674 --> 00:16:03,266
as we have already seen and we've seen how we train a

230
00:16:03,288 --> 00:16:06,706
model. With lookout for vision, the data science or

231
00:16:06,728 --> 00:16:10,660
admin users can train the model

232
00:16:11,110 --> 00:16:14,646
via the console or via the CLI, and they

233
00:16:14,668 --> 00:16:18,070
can have a lightweight static website

234
00:16:18,220 --> 00:16:21,458
that would allow them to start or shut down the model so that they don't

235
00:16:21,474 --> 00:16:23,610
need to access the console directly.

236
00:16:26,320 --> 00:16:29,292
Next, we move on to the image ingestion and storage part.

237
00:16:29,426 --> 00:16:32,744
Now here the camera or the client

238
00:16:32,792 --> 00:16:36,680
application. Once it's captured the image, it can invoke an API

239
00:16:36,760 --> 00:16:40,604
via the Amazon API gateway. It can optionally authorize

240
00:16:40,652 --> 00:16:44,224
it via custom authorizer lambda function, and once

241
00:16:44,262 --> 00:16:47,936
it's authorized, it can invoke a lambda function which would allow it to

242
00:16:48,038 --> 00:16:51,396
get a signed URL from Amazon simple storage service or Amazon S

243
00:16:51,418 --> 00:16:54,708
three. Now the sign URL is going

244
00:16:54,714 --> 00:16:58,432
to be returned back to the camera or the client,

245
00:16:58,576 --> 00:17:01,924
and it can then associate different metadata to the image,

246
00:17:01,972 --> 00:17:05,208
like a camera id, assembly line id, an image id,

247
00:17:05,294 --> 00:17:08,772
or a facility Id, et cetera,

248
00:17:08,916 --> 00:17:11,690
and then upload that image into s three.

249
00:17:12,780 --> 00:17:16,712
Once the images lands in s three, it's going to initiate an image notification

250
00:17:16,856 --> 00:17:21,340
which is going to start AWS step functions workflow

251
00:17:22,560 --> 00:17:26,184
with step functions workflow, there are going to be three different steps.

252
00:17:26,312 --> 00:17:29,884
Firstly, a lambda function is going to invoke the detect anomalies

253
00:17:29,932 --> 00:17:33,548
API for lookout for vision. It's going to take the image

254
00:17:33,564 --> 00:17:37,490
from s three, send that to lookout for vision to get an inference result,

255
00:17:37,940 --> 00:17:41,296
and the results that it's going to get, it's going to send to another lambda

256
00:17:41,328 --> 00:17:44,676
function which is going to store them in Amazon DynamoDB, which is

257
00:17:44,778 --> 00:17:48,496
going to be a persistent store for this solution. Amazon DynamoDb

258
00:17:48,528 --> 00:17:51,904
is a highly scalable, reliable NoSQL

259
00:17:51,952 --> 00:17:55,816
key value based store. Once the

260
00:17:55,838 --> 00:17:59,876
record is added to DynamoDB, it's going to be sent across to a DynamoDB

261
00:17:59,908 --> 00:18:03,448
stream and from there a lambda function which is going to

262
00:18:03,454 --> 00:18:06,492
be a stream reader is going to take that

263
00:18:06,546 --> 00:18:10,556
record and then enrich it with additional data,

264
00:18:10,738 --> 00:18:14,600
or process the data to add or modify some values

265
00:18:14,680 --> 00:18:18,396
and then send them to Amazon kinesis data firehose to

266
00:18:18,418 --> 00:18:22,144
bash them up. Kinesis data firehose allows us

267
00:18:22,182 --> 00:18:25,856
to bash together a number of records and send them to s

268
00:18:25,878 --> 00:18:29,688
three which is going to be a data lake. For the inference results

269
00:18:29,884 --> 00:18:33,536
from this data lake, business users can use Amazon Quicksight,

270
00:18:33,568 --> 00:18:36,932
which is a serverless business intelligence visualization tool

271
00:18:37,066 --> 00:18:40,996
to build dashboards and analysis to

272
00:18:41,018 --> 00:18:45,080
get answers to a number of business queries.

273
00:18:48,380 --> 00:18:52,136
Finally, the third lambda function in our step functions workflow is using to

274
00:18:52,318 --> 00:18:55,630
send a notification via Amazon simple notification service.

275
00:18:56,560 --> 00:19:00,440
This is going to publish a message to SNS topic

276
00:19:00,520 --> 00:19:04,536
which is going to send an email notification to quality managers

277
00:19:04,568 --> 00:19:07,600
or operators would be subscribed to that SNS topic.

278
00:19:08,580 --> 00:19:12,400
We can replace emails with SMS,

279
00:19:13,860 --> 00:19:17,632
or you can also hook up your custom application with

280
00:19:17,686 --> 00:19:21,700
SNS as well via HTTP or HTTPs endpoints.

281
00:19:23,000 --> 00:19:26,912
And finally, from a monitoring and alerting standpoint, we use Amazon Cloudwatch,

282
00:19:26,976 --> 00:19:30,816
which allows us to create alarms and dashboards,

283
00:19:30,928 --> 00:19:34,264
along with providing a single pane of glass for looking

284
00:19:34,302 --> 00:19:37,736
at logs that are generated by our serverless application.

285
00:19:37,838 --> 00:19:41,236
So the various lambda functions that we have here would generate some logs

286
00:19:41,268 --> 00:19:45,076
and we can visualize them via

287
00:19:45,108 --> 00:19:48,584
Cloudwatch. Importantly, we can also

288
00:19:48,622 --> 00:19:51,956
create alarms, such as if the number of defects exceed

289
00:19:51,988 --> 00:19:57,520
a certain threshold, our quality managers or operators could be alerted accordingly.

290
00:19:59,460 --> 00:20:03,360
This is how everything comes together. It's a completely

291
00:20:03,430 --> 00:20:07,104
serverless solution and you can get started by deploying it

292
00:20:07,142 --> 00:20:11,232
with a one click cloud formation

293
00:20:11,296 --> 00:20:15,476
deployment. Apart from the

294
00:20:15,498 --> 00:20:19,460
visualizations that you need to create in quicksight, everything else

295
00:20:19,530 --> 00:20:23,800
in the solution can be set up via single cloud formation deployment.

296
00:20:27,170 --> 00:20:30,240
Let's move on to our demo. So in this demo,

297
00:20:31,410 --> 00:20:34,874
we're going to simulate the process of a camera taking images

298
00:20:34,922 --> 00:20:39,006
and then uploading them to Amazon S three and from there which triggers

299
00:20:39,118 --> 00:20:42,274
the step functions workflow which will detect whether

300
00:20:42,312 --> 00:20:46,066
that image is defective or normal. And based on that it's going to show the

301
00:20:46,088 --> 00:20:50,006
results as well as send email notifications. And finally, we can

302
00:20:50,028 --> 00:20:54,098
have a visualization via Amazon Quicksight as well as Amazon Cloudwatch

303
00:20:54,194 --> 00:20:55,350
dashboards.

304
00:21:00,730 --> 00:21:04,070
So we start up by logging into our

305
00:21:04,140 --> 00:21:07,914
management front end which would allow us to have a view of the different

306
00:21:07,952 --> 00:21:11,046
projects and the different models that have been created for the purpose

307
00:21:11,078 --> 00:21:13,500
of the demo. The model has already been started.

308
00:21:15,950 --> 00:21:18,926
Let's take a look at the data set we used in our model. So this

309
00:21:18,948 --> 00:21:22,174
is for metal casting products. It's got

310
00:21:22,212 --> 00:21:25,794
about 6000 plus images that we've used for training

311
00:21:25,832 --> 00:21:29,358
the model. Moving on to the lookout provision console,

312
00:21:29,534 --> 00:21:33,042
let's have a look at our data

313
00:21:33,096 --> 00:21:38,694
set. As I said, it's got 6000 plus images and

314
00:21:38,892 --> 00:21:43,110
we've trained a model that's got very good

315
00:21:43,180 --> 00:21:44,870
model performance metrics.

316
00:21:46,410 --> 00:21:49,874
And now we're going to simulate the process of uploading images

317
00:21:49,922 --> 00:21:53,574
via a simple python script which is also going to pass some additional

318
00:21:53,622 --> 00:21:57,414
metadata like assembly line id or a camera

319
00:21:57,462 --> 00:22:01,526
id. We've initiated

320
00:22:01,558 --> 00:22:05,018
the script and it's uploading the images into Amazon script. And as

321
00:22:05,104 --> 00:22:08,750
these images are added and those event notifications have been triggered,

322
00:22:10,130 --> 00:22:13,406
the images are being sent to lookout provision for inferencing and the

323
00:22:13,428 --> 00:22:16,862
results are being stored in Dynamodb. And we'll shortly

324
00:22:16,926 --> 00:22:20,210
get email notifications in our email inbox.

325
00:22:22,890 --> 00:22:26,280
So here's the first notification. Let's wait for a few more.

326
00:22:28,250 --> 00:22:31,682
There we go. So we get email notifications. Looking at

327
00:22:31,756 --> 00:22:35,546
the notification itself we see the images id, we see where

328
00:22:35,568 --> 00:22:39,050
it's stored in s three. What's the date, time for the inference result

329
00:22:39,120 --> 00:22:43,450
and the associated confidence score that we get from lookout provision.

330
00:22:43,970 --> 00:22:47,182
Now as more and more images are being processes, these emails are going to pop

331
00:22:47,236 --> 00:22:50,926
up. Now looking at from a monitoring standpoint into

332
00:22:50,948 --> 00:22:54,526
the Amazon Cloudwatch dashboard, we can see as

333
00:22:54,548 --> 00:22:58,690
more images are processed, the processed image count is going to increase along

334
00:22:58,760 --> 00:23:02,126
with whenever a defects is detected. The detected anomaly

335
00:23:02,158 --> 00:23:06,394
count metric is also going to increase and this dashboard

336
00:23:06,542 --> 00:23:10,150
is completely extensible so you can add

337
00:23:10,220 --> 00:23:13,350
more widgets to it depending on your requirements.

338
00:23:15,290 --> 00:23:18,466
Now moving on to the lookout

339
00:23:18,498 --> 00:23:21,882
provision dashboard in quicksight. So this

340
00:23:21,936 --> 00:23:26,106
is a custom dashboard that a user or

341
00:23:26,128 --> 00:23:29,754
a business user can create which allows you to create

342
00:23:29,792 --> 00:23:33,738
a number of visualizations like bar charts, pie charts,

343
00:23:33,834 --> 00:23:38,622
so count of records by assembly line or by

344
00:23:38,676 --> 00:23:42,810
anomalous or non anomalous. It can also allow you to create these line charts

345
00:23:42,890 --> 00:23:47,282
for tracking the inference results over time and

346
00:23:47,336 --> 00:23:52,066
also distribution of your confidence. So what

347
00:23:52,088 --> 00:23:55,730
are the confidence associated with your inference results? High, low,

348
00:23:55,800 --> 00:23:59,014
medium, et cetera. And you can also create

349
00:23:59,052 --> 00:24:02,120
heat maps. Now this is just an example.

350
00:24:03,130 --> 00:24:06,438
It completely depends on your business case and scenario on the

351
00:24:06,524 --> 00:24:09,958
types of visualizations you want to create. Now once we've done with

352
00:24:09,964 --> 00:24:12,778
the inferencing, we can stop the model so that we don't incur any sort of

353
00:24:12,784 --> 00:24:13,740
additional cost.

354
00:24:17,890 --> 00:24:21,326
I hope you enjoyed the demo. Here are a few more resources that you can

355
00:24:21,348 --> 00:24:25,326
have a look at. So there's a blog for detect manufacturing defects in

356
00:24:25,348 --> 00:24:29,074
real time using Amazon lookout provision that you can have a look at. I also

357
00:24:29,112 --> 00:24:33,202
mentioned a solution earlier, so the solution is available on GitHub called

358
00:24:33,256 --> 00:24:37,490
Amazon Lookout for vision serverless app that allows you a one click deploy

359
00:24:38,330 --> 00:24:42,694
way to set up all the backend or the serverless solution into

360
00:24:42,732 --> 00:24:46,434
your AWS account. And there is a reference architecture

361
00:24:46,482 --> 00:24:50,026
as well that you can have a look at. Here's a quick

362
00:24:50,128 --> 00:24:54,424
view for this and

363
00:24:54,462 --> 00:24:58,772
to add to this lookout provision now also supports edge inferencing.

364
00:24:58,916 --> 00:25:02,650
There's a reference architecture available for it that you can

365
00:25:02,960 --> 00:25:06,204
review for further information. So for use

366
00:25:06,242 --> 00:25:09,528
cases where you need low latency inferencing

367
00:25:09,624 --> 00:25:12,990
or you've got intermittent networking connectivity, you can also

368
00:25:13,760 --> 00:25:17,736
train your lookout for vision model and deploy it on edge devices

369
00:25:17,848 --> 00:25:20,750
and run inferencing from there.

370
00:25:22,720 --> 00:25:26,604
There are a few more resources blog posts that

371
00:25:26,642 --> 00:25:30,404
you can also review. Thank you

372
00:25:30,442 --> 00:25:33,796
so much for listening. I hope you enjoyed this session and thank

373
00:25:33,818 --> 00:25:36,770
you so much conf 42 for giving me the opportunity to speak here.

