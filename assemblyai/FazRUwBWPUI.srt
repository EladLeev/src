1
00:01:28,130 --> 00:01:31,954
Hi and welcome to my presentation about how to debug

2
00:01:32,002 --> 00:01:35,670
a container with a sidecar in Kubernetes

3
00:01:36,410 --> 00:01:40,394
using Gefyra. My name is Michael. I am software

4
00:01:40,442 --> 00:01:44,430
engineer and co founder at Blushu. Blueshoe is a

5
00:01:44,500 --> 00:01:48,042
Munich based software development provider

6
00:01:48,186 --> 00:01:51,962
for cloud native software. We are creating

7
00:01:52,026 --> 00:01:55,934
a couple of tools and platforms, for instance Unikube IO

8
00:01:56,062 --> 00:01:59,582
or Jifira. And in my day to day business I am advising

9
00:01:59,646 --> 00:02:04,238
our teams and our customers how to do cloud native development.

10
00:02:04,414 --> 00:02:07,842
If you want to reach me, then drop me a line at Michael at Unicube

11
00:02:07,906 --> 00:02:11,474
IO or find me on GitHub. And here is my agenda

12
00:02:11,522 --> 00:02:14,774
for today. So first of all, I'd like to introduce you

13
00:02:14,812 --> 00:02:17,854
to Jifira and its project goals.

14
00:02:18,002 --> 00:02:22,678
Then I'd like to talk about my development infrastructure,

15
00:02:22,854 --> 00:02:26,406
my demo application and yeah, how to debug

16
00:02:26,518 --> 00:02:29,674
my debug with Jifira. In the end,

17
00:02:29,712 --> 00:02:33,100
I will wrap everything up. So let's get started.

18
00:02:33,550 --> 00:02:36,942
Jifira is under development for

19
00:02:36,996 --> 00:02:40,574
a couple of months now. We have started it to

20
00:02:40,692 --> 00:02:45,358
give developers a completely new way of writing and testing their applications

21
00:02:45,534 --> 00:02:49,394
by using kubernetes right from the beginning and to make

22
00:02:49,432 --> 00:02:51,300
this as convenient as possible.

23
00:02:51,990 --> 00:02:56,162
So we'd like to promote more service oriented

24
00:02:56,226 --> 00:03:00,370
thinking and to foster domain driven mindsets.

25
00:03:00,530 --> 00:03:04,722
And yeah, we'd like to see the adoption of advanced kubernetes

26
00:03:04,786 --> 00:03:09,014
patterns to become part of modern overall

27
00:03:09,062 --> 00:03:13,402
software architectures. Then generally speaking,

28
00:03:13,536 --> 00:03:17,210
about using kubernetes right from the beginning will

29
00:03:17,280 --> 00:03:20,954
increase the dev prosperity by an order of magnitude.

30
00:03:21,082 --> 00:03:24,938
So since you maybe already have members in your teams

31
00:03:25,114 --> 00:03:28,442
taking a lot of effort to describe kubernetes

32
00:03:28,506 --> 00:03:32,160
environments for production or testing, why don't you take

33
00:03:32,930 --> 00:03:36,306
this work and bring it to your developers as

34
00:03:36,328 --> 00:03:39,698
well? Yeah, in the past we have been working with telepresence two

35
00:03:39,784 --> 00:03:43,326
for quite some time, but we have been at least our teams

36
00:03:43,358 --> 00:03:47,334
a little bit dissatisfied with the features and

37
00:03:47,372 --> 00:03:50,838
the approaches. And yeah, couldn't find a

38
00:03:50,844 --> 00:03:54,470
good solution for us. So we set OAuth and created Jifira.

39
00:03:55,210 --> 00:03:59,034
One of the major project goals of Jifira is to

40
00:03:59,152 --> 00:04:03,078
make use of conventional mechanisms and toolings

41
00:04:03,174 --> 00:04:07,354
that your developers are working nowadays already. So for

42
00:04:07,392 --> 00:04:10,894
instance, we'd like to support your favorite ide

43
00:04:11,092 --> 00:04:14,782
code hot reloading and mounting the current state

44
00:04:14,836 --> 00:04:18,602
of my source into the development container.

45
00:04:18,746 --> 00:04:22,806
You can override environment variables, drop into an interactive

46
00:04:22,858 --> 00:04:26,706
shell and read the logs easily. And most importantly for

47
00:04:26,728 --> 00:04:30,914
this example is that you can attach a debugging quite

48
00:04:30,952 --> 00:04:34,890
easily to your application container instance

49
00:04:35,070 --> 00:04:38,674
which is currently subject to your development

50
00:04:38,722 --> 00:04:42,402
work. Gefyra creates a dedicated

51
00:04:42,546 --> 00:04:46,402
docker network on top of your local docker host,

52
00:04:46,546 --> 00:04:50,314
and by employing a sidecar which creates the

53
00:04:50,352 --> 00:04:54,086
underlying VPN connection to your Kubernetes cluster,

54
00:04:54,198 --> 00:04:57,770
your application behaves as it would run

55
00:04:57,920 --> 00:05:02,154
already within the context of a Kubernetes namespace,

56
00:05:02,282 --> 00:05:05,902
and that makes it very convenient for

57
00:05:05,956 --> 00:05:11,806
developers to write code that is for

58
00:05:11,828 --> 00:05:14,850
the execution already part of the Kubernetes cluster.

59
00:05:16,470 --> 00:05:19,860
So speaking about my example

60
00:05:20,230 --> 00:05:24,194
project here, I will bootstrap a local

61
00:05:24,392 --> 00:05:27,750
Kubernetes cluster using k means.

62
00:05:27,820 --> 00:05:31,814
I have to do a couple of cluster configs such

63
00:05:31,852 --> 00:05:34,930
as selecting the right Kubernetes

64
00:05:35,010 --> 00:05:38,422
version, set the correct port forwardings for

65
00:05:38,476 --> 00:05:42,318
HTTP traffic, and more importantly for JFIRA

66
00:05:42,354 --> 00:05:45,594
to work. I have dependencies which I am going

67
00:05:45,632 --> 00:05:48,774
to install using ham charts and customize,

68
00:05:48,902 --> 00:05:52,126
and I will be providing a plain or a couple of

69
00:05:52,148 --> 00:05:55,870
plain Yaml files to describe my custom

70
00:05:55,940 --> 00:06:00,682
backend application. And of course developers

71
00:06:00,746 --> 00:06:04,734
are using Kubecontrol also during development

72
00:06:04,782 --> 00:06:08,210
time in order to interact with the Kubernetes cluster.

73
00:06:10,150 --> 00:06:13,714
So I need a Kubernetes cluster. As I said,

74
00:06:13,752 --> 00:06:17,240
it'll be case 3d. My demo application

75
00:06:17,610 --> 00:06:21,330
will perform or demonstrates

76
00:06:21,490 --> 00:06:25,638
an Oauth two login flow, or more

77
00:06:25,724 --> 00:06:29,606
precisely an openid connect flow. So I need some sort

78
00:06:29,628 --> 00:06:33,558
of identity provider. In my example I will be using keycloak

79
00:06:33,654 --> 00:06:37,194
and for that to work I need a custom realm with an auth

80
00:06:37,232 --> 00:06:40,998
two client. For my back end service I

81
00:06:41,024 --> 00:06:44,286
need of course a test user with the required privileges to

82
00:06:44,308 --> 00:06:48,254
log in, and I need the ingress configuration that

83
00:06:48,292 --> 00:06:51,838
supports that local fully fledged or to lock in

84
00:06:51,844 --> 00:06:55,906
flow for my demonstration. And on the other hand of course

85
00:06:56,008 --> 00:06:59,614
I need the workloads in order to run my demo backend

86
00:06:59,662 --> 00:07:03,726
application. And for this example I will be employing

87
00:07:03,758 --> 00:07:07,394
the Oauth two proxy in a Kubernetes sidecars

88
00:07:07,442 --> 00:07:10,902
pattern. The backend application itself is

89
00:07:11,036 --> 00:07:14,498
made with fast API, so this is a popular

90
00:07:14,674 --> 00:07:17,834
Python web framework. But this

91
00:07:17,872 --> 00:07:22,170
example, or better yet, this pattern, is not specific to

92
00:07:22,240 --> 00:07:25,686
Python as a programming language. Rather it's agnostic

93
00:07:25,718 --> 00:07:31,214
to the programming language that you are using to

94
00:07:31,332 --> 00:07:35,210
set everything up. I will be using another tool that's created

95
00:07:35,290 --> 00:07:39,342
by our teams. It's called Getdeck and it will set

96
00:07:39,396 --> 00:07:43,202
me up this environment in a

97
00:07:43,256 --> 00:07:49,454
second. I will just run deck,

98
00:07:49,502 --> 00:07:53,410
get to this public repository

99
00:07:53,750 --> 00:07:56,678
and I'm selecting the deck OAuth to demo.

100
00:07:56,844 --> 00:07:58,950
So this is all open source.

101
00:08:00,090 --> 00:08:03,382
It processes five sources of

102
00:08:03,436 --> 00:08:06,866
different kinds such as helm charts for the keycloak

103
00:08:06,978 --> 00:08:10,826
plain yaml in order to initialize keycloak with realm and

104
00:08:10,848 --> 00:08:14,618
the user and everything and of course my demo application

105
00:08:14,704 --> 00:08:18,090
as a backend. In addition, for this deck

106
00:08:18,590 --> 00:08:22,346
there is the Kubernetes dashboard available which is convenient

107
00:08:22,378 --> 00:08:26,186
for developers to watch all the services and ports

108
00:08:26,218 --> 00:08:29,934
and coming up, the published ports are listed down below here.

109
00:08:30,052 --> 00:08:33,810
So my HTTP traffic will go on localhost port

110
00:08:33,880 --> 00:08:38,002
80 80. Wonderful. So what's inside

111
00:08:38,136 --> 00:08:42,514
of my example? I have at

112
00:08:42,552 --> 00:08:45,734
least two domains, local domains running in order

113
00:08:45,772 --> 00:08:49,510
to establish the OpenID connect flow. I have

114
00:08:49,580 --> 00:08:53,094
on the one hand the Oauth two demo domain. I am

115
00:08:53,132 --> 00:08:56,690
using Nipio here on port 80 80

116
00:08:56,850 --> 00:09:00,874
in order to serve my Oauth two demo which

117
00:09:00,912 --> 00:09:04,262
is created with the sidecars pattern.

118
00:09:04,406 --> 00:09:08,698
That means that each and every request that

119
00:09:08,784 --> 00:09:13,120
comes through my ingress is then first

120
00:09:13,810 --> 00:09:17,770
authorized by the OAuth two proxy

121
00:09:17,930 --> 00:09:22,160
and only authorized requests are passed through

122
00:09:22,630 --> 00:09:26,674
to my Python backend application. And that means

123
00:09:26,792 --> 00:09:30,578
that I separated my back end completely from

124
00:09:30,664 --> 00:09:33,518
the OAuth two login flow,

125
00:09:33,614 --> 00:09:37,782
which greatly increases at least the security because

126
00:09:37,836 --> 00:09:42,150
I don't have to write custom code for the lock in mechanisms

127
00:09:43,530 --> 00:09:46,758
and I'm using standard software here.

128
00:09:46,844 --> 00:09:50,314
And on the other hand I have the keycloak running on

129
00:09:50,352 --> 00:09:54,170
another domain. It's keycloak on my localhost Nibio

130
00:09:54,990 --> 00:09:58,442
on port 80 82. So just a quick

131
00:09:58,496 --> 00:10:02,122
recall how the OpenID connect flow

132
00:10:02,186 --> 00:10:05,630
is working. So if I want to access

133
00:10:05,780 --> 00:10:09,402
my backend application from my browser,

134
00:10:09,546 --> 00:10:13,066
I first have to request an authorization

135
00:10:13,178 --> 00:10:16,926
code and this is done by a redirect from the

136
00:10:16,948 --> 00:10:21,170
AutH to reverse proxy to the JSON web token issuer.

137
00:10:22,950 --> 00:10:26,834
In this case it's keycloak. And upon providing

138
00:10:26,882 --> 00:10:30,678
my login credentials I will be receiving the authorization code

139
00:10:30,764 --> 00:10:34,182
and a redirect and it redirects me back to the auth

140
00:10:34,236 --> 00:10:39,034
two reverse proxy and from there my

141
00:10:39,072 --> 00:10:42,970
authorization code gets exchanged for a valid access

142
00:10:43,040 --> 00:10:46,666
token that will travel along

143
00:10:46,768 --> 00:10:50,018
in a HTTP header to my backend

144
00:10:50,054 --> 00:10:53,706
applications and having a closer

145
00:10:53,738 --> 00:10:57,514
look to the workload yaml that is creating

146
00:10:57,562 --> 00:11:01,454
the sidecars pattern in the container section you can find two

147
00:11:01,492 --> 00:11:05,058
containers running in one pod. So there is the first

148
00:11:05,144 --> 00:11:08,210
is the auth two proxy which is

149
00:11:08,360 --> 00:11:12,242
being served on port 80 nine which

150
00:11:12,296 --> 00:11:15,510
is published through the Kubernetes service.

151
00:11:15,660 --> 00:11:19,142
And the second container is the OAuth two demo app.

152
00:11:19,276 --> 00:11:22,818
This one will be target for the Jifira bridge operations

153
00:11:22,914 --> 00:11:27,320
in a couple of minutes and this container is

154
00:11:28,590 --> 00:11:32,202
listening on port 8155 and the AutH

155
00:11:32,256 --> 00:11:36,266
two proxy is configured to upstream to

156
00:11:36,368 --> 00:11:40,254
that port and this sidecars pattern is then

157
00:11:40,292 --> 00:11:43,770
rolled out with each replication of the deployment,

158
00:11:43,930 --> 00:11:47,530
meaning that for every pod that is scheduled

159
00:11:47,610 --> 00:11:50,618
by the OAuth to demo deployment.

160
00:11:50,794 --> 00:11:54,482
Exactly. This pattern is part of each

161
00:11:54,536 --> 00:11:58,686
pod and therefore I'm

162
00:11:58,718 --> 00:12:02,434
not scaling just one component, for instance my auth two

163
00:12:02,472 --> 00:12:06,182
demo app, but rather I am scaling the auth

164
00:12:06,236 --> 00:12:09,638
two proxy as well as my back end application.

165
00:12:09,804 --> 00:12:14,374
And this is pretty much what the sidecars patterns is

166
00:12:14,412 --> 00:12:17,922
useful for. So to see this in action

167
00:12:18,066 --> 00:12:21,350
I will head over to my browser

168
00:12:22,010 --> 00:12:25,706
and I point it to auth two demo on my

169
00:12:25,728 --> 00:12:29,802
local domain. Just hitting the refresh button here and

170
00:12:29,856 --> 00:12:33,322
the OAuth two proxy welcomes me with this login

171
00:12:33,386 --> 00:12:37,406
screen and it is configured to use OpenID connect for

172
00:12:37,428 --> 00:12:41,070
the login flow. So I hit the sign

173
00:12:41,140 --> 00:12:44,770
in with Openid connect and now I'm

174
00:12:46,070 --> 00:12:50,066
please notice how I got redirected to keycloak here

175
00:12:50,248 --> 00:12:54,050
and I am now using my demo

176
00:12:54,120 --> 00:12:57,186
user. It's John at Gefyra

177
00:12:57,378 --> 00:13:01,074
Dev and the same is for the password.

178
00:13:01,202 --> 00:13:04,534
I hit the lock in and here

179
00:13:04,572 --> 00:13:09,090
we go. I got redirected back to the auth two demo domain

180
00:13:09,170 --> 00:13:13,322
and the response for this simple example

181
00:13:13,456 --> 00:13:17,466
application is JSON telling me helps world and

182
00:13:17,488 --> 00:13:20,922
this application allows me to for instance retrieve

183
00:13:20,986 --> 00:13:25,338
items so I can go to the item route Thames

184
00:13:25,434 --> 00:13:30,730
and put it Thames

185
00:13:30,810 --> 00:13:34,270
and I put n one two three here and it says ooh,

186
00:13:35,250 --> 00:13:38,740
an internal server error. So this is the

187
00:13:39,430 --> 00:13:43,378
HTTP 500, a bug that is

188
00:13:43,544 --> 00:13:46,934
currently present in my current state of the

189
00:13:46,972 --> 00:13:50,200
application. And yeah,

190
00:13:50,810 --> 00:13:54,550
we already found the bug. Now we might take care

191
00:13:54,620 --> 00:13:58,398
about what is required with Jifira

192
00:13:58,434 --> 00:14:01,834
in order to fix it. So this is the code that

193
00:14:01,872 --> 00:14:05,194
is serving the items route. And first

194
00:14:05,232 --> 00:14:09,194
thing that comes to mind is I think it's not too

195
00:14:09,392 --> 00:14:13,370
uncommon anti pattern to have an if else branch

196
00:14:13,450 --> 00:14:16,894
that separates two environments. In this

197
00:14:16,932 --> 00:14:20,830
case it is probing if a access

198
00:14:20,900 --> 00:14:24,834
token is available here and if not which

199
00:14:24,872 --> 00:14:29,294
is for a development

200
00:14:29,342 --> 00:14:32,686
environment which was not created using kubernetes

201
00:14:32,798 --> 00:14:36,454
and this pattern. The token is

202
00:14:36,492 --> 00:14:40,194
not really used for creating the response.

203
00:14:40,242 --> 00:14:43,638
As you can see the email is not given in this case.

204
00:14:43,804 --> 00:14:47,094
But once this application moves into

205
00:14:47,212 --> 00:14:50,986
a Kubernetes environment employing the sidecar and also

206
00:14:51,168 --> 00:14:55,158
forwarding the access token, I'm hitting

207
00:14:55,334 --> 00:14:59,494
this nasty bug. So ns and attentive

208
00:14:59,542 --> 00:15:02,800
audience, you might already spotted what's the problem here.

209
00:15:03,250 --> 00:15:07,230
I'd like to keep it open for a couple of seconds.

210
00:15:08,770 --> 00:15:12,000
Right. The process with Gefyra is quite simple.

211
00:15:12,390 --> 00:15:15,534
You run Gefyra app in order to set up the development

212
00:15:15,582 --> 00:15:19,122
environment and the infrastructures. You can

213
00:15:19,176 --> 00:15:22,370
then run a jifira run within

214
00:15:22,520 --> 00:15:25,860
virtually any image that you'd like to run

215
00:15:26,250 --> 00:15:29,250
in a context of a Kubernetes namespace.

216
00:15:29,330 --> 00:15:33,186
Maybe it's a new service that is not yet reflected

217
00:15:33,298 --> 00:15:36,694
in Kubernetes workloads, but you would like to run

218
00:15:36,732 --> 00:15:40,570
and develop a new service in an existing mesh.

219
00:15:41,950 --> 00:15:45,334
You can run afterwards the bridge

220
00:15:45,382 --> 00:15:49,418
command which intercepted an existing service,

221
00:15:49,584 --> 00:15:53,006
and tunnels all the traffic hitting that particular

222
00:15:53,108 --> 00:15:56,590
container to your development instance.

223
00:15:56,930 --> 00:16:00,954
And in this case you may write code, fix bugs,

224
00:16:01,082 --> 00:16:04,130
or write new features. Once you're done,

225
00:16:04,200 --> 00:16:07,566
you can commit and push, and CI CD

226
00:16:07,598 --> 00:16:11,166
pipeline will take over. And from a developer's

227
00:16:11,198 --> 00:16:14,962
perspective, you're now able to run the Jifira down command in order

228
00:16:15,016 --> 00:16:18,740
to tear the development infrastructure down.

229
00:16:19,270 --> 00:16:22,870
So the Gefyra run command with this

230
00:16:22,940 --> 00:16:26,546
parameter list is doing the following

231
00:16:26,658 --> 00:16:30,474
I specify the image, so this is basically

232
00:16:30,592 --> 00:16:33,814
the same image that is deployed to my Kubernetes cluster.

233
00:16:33,862 --> 00:16:37,958
At the moment. I'd like to assign a name, it's my fast API

234
00:16:38,054 --> 00:16:41,770
demo. For further reference, I want

235
00:16:41,840 --> 00:16:45,502
this container instance to run in the or two demo

236
00:16:45,556 --> 00:16:48,766
namespace, which is the namespace for my example application,

237
00:16:48,948 --> 00:16:52,458
and I'd like to mount my current working

238
00:16:52,564 --> 00:16:56,494
tree to this container. I am overriding

239
00:16:56,542 --> 00:17:00,462
the starter command here. I am using debug PI,

240
00:17:00,526 --> 00:17:03,646
which is a Python implementation for the debug

241
00:17:03,678 --> 00:17:07,350
adapter protocol. It is available for a long list

242
00:17:07,420 --> 00:17:12,102
of programming languages too. So the

243
00:17:12,156 --> 00:17:16,086
debug PI is waiting for a debug client to connect,

244
00:17:16,268 --> 00:17:19,834
in this case on port 5678. And then I

245
00:17:19,872 --> 00:17:23,754
am starting Uvcorn. It's my application server, and this

246
00:17:23,792 --> 00:17:28,186
is basically the same command that the application is also started in

247
00:17:28,208 --> 00:17:31,566
Kubernetes at the moment, except for the reload flag at the

248
00:17:31,588 --> 00:17:35,102
end, which allows me to reload the

249
00:17:35,156 --> 00:17:38,880
application. Upon changing my source code,

250
00:17:39,650 --> 00:17:43,666
I will head over to vs code

251
00:17:43,848 --> 00:17:46,786
to demonstrates how this looks.

252
00:17:46,888 --> 00:17:50,318
So first I have to run the Gefyra

253
00:17:50,414 --> 00:17:54,238
up command. It installs Gfira's operator

254
00:17:54,334 --> 00:17:56,550
to my local Kubernetes cluster,

255
00:17:57,210 --> 00:18:01,426
does everything else which is required for my local development

256
00:18:01,458 --> 00:18:05,574
infrastructure. I have the code which

257
00:18:05,612 --> 00:18:09,910
is currently serving the server error

258
00:18:10,070 --> 00:18:13,098
already at hand here, and I

259
00:18:13,104 --> 00:18:17,834
will be running a

260
00:18:17,872 --> 00:18:21,758
development instance of this application container in

261
00:18:21,764 --> 00:18:26,160
a second. So Jifira is up

262
00:18:27,410 --> 00:18:33,378
ready. So I am running

263
00:18:33,544 --> 00:18:34,770
this command.

264
00:18:38,630 --> 00:18:42,162
Okay, this container has been started locally. I can

265
00:18:42,216 --> 00:18:47,622
inspect the docker ps with my

266
00:18:47,676 --> 00:18:50,840
fast API running locally here.

267
00:18:53,130 --> 00:18:56,934
So. And now for vs code to

268
00:18:57,052 --> 00:19:00,742
connect to the debugger, I'm going to create a launch

269
00:19:00,806 --> 00:19:05,222
JSon. We'll do this with the debug extension,

270
00:19:05,366 --> 00:19:09,450
create a launch JsOn and select

271
00:19:09,520 --> 00:19:13,466
the remote attach in order to connect to a remote

272
00:19:13,578 --> 00:19:17,134
Python debug server and it asks me

273
00:19:17,172 --> 00:19:21,040
about the host name and in order to find

274
00:19:21,410 --> 00:19:26,660
out the IP address of

275
00:19:30,630 --> 00:19:34,910
my local

276
00:19:35,000 --> 00:19:38,978
container I am running the docker inspect command

277
00:19:39,154 --> 00:19:43,160
and it tells me the IP address. By the way, this will be part

278
00:19:43,530 --> 00:19:47,378
of Jifira in one of the upcoming

279
00:19:47,554 --> 00:19:51,082
releases to make this even more easy.

280
00:19:51,216 --> 00:19:54,986
So I put the IP address in here, it's the default port and I

281
00:19:55,008 --> 00:19:58,086
hit enter and vs code creates

282
00:19:58,118 --> 00:20:02,190
a launch JSON. And now by starting the debug

283
00:20:03,650 --> 00:20:07,466
I am getting connected to my local container

284
00:20:07,498 --> 00:20:10,686
instance and it already tells me that Uvcorn is

285
00:20:10,708 --> 00:20:14,274
running on this container address

286
00:20:14,472 --> 00:20:17,940
and it basically started the application already.

287
00:20:20,310 --> 00:20:23,250
Wonderful. Now getting back to my slides,

288
00:20:23,910 --> 00:20:27,922
because now I have started the container instance

289
00:20:28,066 --> 00:20:31,698
running in my Jifira context

290
00:20:31,794 --> 00:20:36,242
and it is running as part of the Kubernetes

291
00:20:36,386 --> 00:20:39,430
namespace in my application landscape.

292
00:20:39,590 --> 00:20:42,746
So in order to receive requests I

293
00:20:42,768 --> 00:20:46,534
have to create the Jifira bridge and this command

294
00:20:46,662 --> 00:20:49,974
is going to do that. It's a

295
00:20:50,032 --> 00:20:54,094
bridge, and on the one end of the bridge I

296
00:20:54,132 --> 00:20:57,280
target my fast API demo, the local

297
00:20:59,010 --> 00:21:02,522
container instance that I just created, and on

298
00:21:02,676 --> 00:21:06,546
the other end there will be everything scheduled by

299
00:21:06,568 --> 00:21:10,750
the Kubernetes deployment Oauth to demo. So this deployment

300
00:21:10,830 --> 00:21:13,700
is placed in the namespace Oauth to demo.

301
00:21:14,150 --> 00:21:18,454
And I am particularly interested in all

302
00:21:18,572 --> 00:21:22,102
containers within pods that are named or

303
00:21:22,156 --> 00:21:25,586
to demo app. You remember it's the second container

304
00:21:25,698 --> 00:21:30,226
in my sidecars pattern which runs on port 8155.

305
00:21:30,348 --> 00:21:34,294
So this is the same that I'd like to forward to my local container

306
00:21:34,342 --> 00:21:37,946
instance and I assign the name my fast API at

307
00:21:37,968 --> 00:21:40,490
this point again for further reference.

308
00:21:42,690 --> 00:21:46,320
So getting back to vs code,

309
00:21:47,410 --> 00:21:51,630
I will change to the terminal again, clear my terminal,

310
00:21:53,010 --> 00:21:56,450
and run the Gefyra bridge command,

311
00:21:59,030 --> 00:22:02,210
and it selects one pod with this name.

312
00:22:02,360 --> 00:22:06,134
Jifira is now waiting for the bridge to become active, and once

313
00:22:06,252 --> 00:22:10,482
a connection is established, my local container instance

314
00:22:10,546 --> 00:22:15,862
is now serving the request for

315
00:22:15,916 --> 00:22:20,330
the auth two domain. I can demonstrate this if

316
00:22:20,400 --> 00:22:26,442
I go back to the browser and

317
00:22:26,496 --> 00:22:30,082
here I can go for instance

318
00:22:30,166 --> 00:22:34,014
back to the front page and I get the already working hello

319
00:22:34,052 --> 00:22:38,670
world response. So if I get to the etems,

320
00:22:40,210 --> 00:22:44,126
one, two, three, it's still the internal

321
00:22:44,158 --> 00:22:48,020
server error of course, because I did not change any code

322
00:22:48,470 --> 00:22:51,620
so far. So getting back to

323
00:22:52,710 --> 00:22:55,890
vs code and challenging

324
00:22:55,970 --> 00:22:59,746
to my code that is being executed,

325
00:22:59,858 --> 00:23:03,618
I can now drop a breakpoint

326
00:23:03,794 --> 00:23:07,618
at this position in order to

327
00:23:07,644 --> 00:23:11,146
interrupt the execution and to find out what's wrong

328
00:23:11,328 --> 00:23:14,780
with this code. So if I now

329
00:23:15,470 --> 00:23:19,450
start a new request on that particular route,

330
00:23:21,010 --> 00:23:24,350
it is interrupted and vs code

331
00:23:24,420 --> 00:23:28,640
already popped up with the breakpoint being

332
00:23:29,010 --> 00:23:33,742
halted the execution. And I'm now able to inspect

333
00:23:33,886 --> 00:23:38,798
the data, which is the JSON

334
00:23:38,814 --> 00:23:43,250
web token decoded. And I am now able to inspect

335
00:23:43,590 --> 00:23:46,914
the keys of the web token. You can see it's

336
00:23:46,962 --> 00:23:49,698
just an ordinary JSON web token,

337
00:23:49,794 --> 00:23:54,598
nothing special here, but it tells me the email

338
00:23:54,684 --> 00:23:58,746
key is actually written with a lower e in

339
00:23:58,768 --> 00:24:02,042
the beginning. And if I go

340
00:24:02,096 --> 00:24:04,060
on with this run,

341
00:24:05,150 --> 00:24:09,066
I'm even able to head to the

342
00:24:09,248 --> 00:24:12,846
output of the application. And here it tells me

343
00:24:12,948 --> 00:24:16,734
about the key error too. So now I can

344
00:24:16,772 --> 00:24:20,494
change this uppercase e to a

345
00:24:20,532 --> 00:24:24,690
lowercase e and remove the breakpoint.

346
00:24:25,670 --> 00:24:29,534
And since I activated the reload

347
00:24:29,582 --> 00:24:32,942
flag in my application server,

348
00:24:33,086 --> 00:24:36,294
I will be reloading the code. And now

349
00:24:36,492 --> 00:24:40,054
my application is executing my changed code.

350
00:24:40,172 --> 00:24:43,586
I hit the refresh and it still says internal

351
00:24:43,618 --> 00:24:44,710
server error.

352
00:24:47,790 --> 00:24:52,566
And this is because I forgot to save the source

353
00:24:52,598 --> 00:24:56,246
file. Okay, here we go. So this response

354
00:24:56,278 --> 00:24:58,726
is now working and I fixed the bug.

355
00:24:58,838 --> 00:24:59,690
Wonderful.

356
00:25:04,690 --> 00:25:08,526
Yeah, basically that's it. Back to

357
00:25:08,548 --> 00:25:11,390
my slides. As I said,

358
00:25:11,540 --> 00:25:14,722
in order to fix this debug, I had to make

359
00:25:14,776 --> 00:25:18,290
the uppercase email to a lowercase email

360
00:25:18,440 --> 00:25:22,782
because this key access caused

361
00:25:22,846 --> 00:25:27,240
an exception. That's it.

362
00:25:28,970 --> 00:25:32,214
I have demonstrates that Jifira is

363
00:25:32,252 --> 00:25:35,634
able to create a kubernetes native development

364
00:25:35,682 --> 00:25:40,134
approach by creating a local container

365
00:25:40,182 --> 00:25:43,622
instance with all conventional capabilities

366
00:25:43,686 --> 00:25:47,770
for developers writing their code being executed at the same time

367
00:25:47,840 --> 00:25:51,710
already within a kubernetes context and

368
00:25:51,860 --> 00:25:56,206
just side by side with existing adjacent services.

369
00:25:56,388 --> 00:26:00,046
So there's no need anymore for a docker compose or

370
00:26:00,068 --> 00:26:04,286
vagrant setup or any custom scripts that create

371
00:26:04,468 --> 00:26:08,158
a developing infrastructure which is not really

372
00:26:08,244 --> 00:26:11,646
matching your production systems. If you

373
00:26:11,668 --> 00:26:16,022
want to follow along this example, please head over to dev

374
00:26:16,156 --> 00:26:19,334
use casesauth two demo and

375
00:26:19,372 --> 00:26:23,558
if you're interested in using Getdeck, I would be happy to

376
00:26:23,644 --> 00:26:27,126
see you in this repository too. So if

377
00:26:27,148 --> 00:26:30,614
you do have any question then please reach out and in

378
00:26:30,652 --> 00:26:32,260
any case, have a wonderful day.

