1
00:00:25,410 --> 00:00:29,126
Hello everyone, and welcome to my presentation. Thanks for attending and thanks to

2
00:00:29,148 --> 00:00:32,582
the organizing team of Conf 42, Python 2021

3
00:00:32,636 --> 00:00:36,134
for putting together this great event for giving me the opportunity to present on

4
00:00:36,172 --> 00:00:39,926
it. Today I'm going to talk about delivering successful API integrations with

5
00:00:39,948 --> 00:00:42,710
Python. But before I do that, let me introduce myself.

6
00:00:42,860 --> 00:00:46,166
My name is Jose and I work as an independent contractor based in

7
00:00:46,188 --> 00:00:49,982
London. I work as a full stack developer, so usually working

8
00:00:50,076 --> 00:00:54,030
both with front end applications and with backend applications as well.

9
00:00:54,100 --> 00:00:57,882
And for the past few years I've had a long term affair with microservices

10
00:00:57,946 --> 00:01:01,482
and APIs. So I've helped multiple clients build microservices

11
00:01:01,546 --> 00:01:05,166
architectures and to delivering API integrations. Along the

12
00:01:05,188 --> 00:01:08,462
way, I've made multiple mistakes, but I've also learned

13
00:01:08,526 --> 00:01:12,686
a great deal of things about what it takes to deliver a successful API integrations.

14
00:01:12,798 --> 00:01:16,850
As a result of this experience, I got the idea of writing a book

15
00:01:16,920 --> 00:01:20,626
about developing microservice APIs with Python. The book is published

16
00:01:20,658 --> 00:01:24,534
by Manning and it's currently available through manning early access program.

17
00:01:24,652 --> 00:01:27,474
If you want to get a copy of the book, you can use the following

18
00:01:27,522 --> 00:01:30,586
discount code to get a 35% discount from the

19
00:01:30,608 --> 00:01:34,710
price. I'm also the founder and creator of Microapis IO.

20
00:01:34,790 --> 00:01:38,650
This is a website that makes it easy to launch API mock service

21
00:01:38,720 --> 00:01:41,866
with one click, with no signup or login required. All you need

22
00:01:41,888 --> 00:01:45,646
to do is copy the API specification in the input panel on

23
00:01:45,668 --> 00:01:49,418
the left side here on the website. This will trigger a validation

24
00:01:49,514 --> 00:01:53,038
process in the server of the API document and

25
00:01:53,124 --> 00:01:56,546
if the document is valid you will be able to click on this button to

26
00:01:56,568 --> 00:02:00,174
get the mock server. You will get a base server

27
00:02:00,222 --> 00:02:04,254
URL for the API as well as a sample URL from the specification

28
00:02:04,382 --> 00:02:07,838
which you can click to test that the server is working correctly.

29
00:02:08,014 --> 00:02:11,046
If you would like to connect with me, I try to be active in all

30
00:02:11,068 --> 00:02:14,178
of these platforms in Twitter, GitHub, Medium and LinkedIn.

31
00:02:14,274 --> 00:02:17,922
So if you would like to discuss anything related to software,

32
00:02:17,986 --> 00:02:21,386
microservices, APIs or Python, please feel free to

33
00:02:21,408 --> 00:02:24,666
reach out to me in these platforms. So what's the agenda for

34
00:02:24,688 --> 00:02:27,786
this presentation? First of all, I'm going to talk about the

35
00:02:27,808 --> 00:02:31,318
completely of API integrations. Why are they so difficult? Why it's

36
00:02:31,334 --> 00:02:34,766
so tricky to make them succeed from the start? Then I'm going

37
00:02:34,788 --> 00:02:38,174
to introduce documentation driven development as an approach that

38
00:02:38,212 --> 00:02:41,966
can help us address the complexity of these integrations and it can

39
00:02:41,988 --> 00:02:45,394
help us reduce the chances of failure. I'm going to show you how you can

40
00:02:45,432 --> 00:02:48,894
introduce documentation driven development within your API

41
00:02:48,942 --> 00:02:52,546
development workflow by showing you a simple example of a to

42
00:02:52,568 --> 00:02:56,066
do applications with a rest API in front of it, which we are going to

43
00:02:56,088 --> 00:02:59,666
build with fast API. We're going to test and validate the API

44
00:02:59,698 --> 00:03:03,298
with thread and we are going to run mock services on this specification.

45
00:03:03,394 --> 00:03:07,046
I'm going to show you how you can include this process within your

46
00:03:07,068 --> 00:03:10,166
continuous integration server, and we are using to deploy all

47
00:03:10,188 --> 00:03:14,038
of this to Heroku. If you're interested in checking out the code for this presentation,

48
00:03:14,134 --> 00:03:17,606
it's available in my personal GitHub repository in the repo

49
00:03:17,638 --> 00:03:21,526
that I prepared for this presentation. So why are API integrations so

50
00:03:21,568 --> 00:03:25,086
tricky? If you picture the typical situation of

51
00:03:25,188 --> 00:03:28,958
a team working on an API integration, we usually have a

52
00:03:29,044 --> 00:03:32,446
team working on the API backend and a team working on

53
00:03:32,468 --> 00:03:36,514
the API clients. The client can be anything from a front end application running

54
00:03:36,552 --> 00:03:40,190
on the browser to a mobile app or another microservices.

55
00:03:40,270 --> 00:03:43,554
Typically what happens is both teams will be working in

56
00:03:43,592 --> 00:03:47,314
parallel and at some point we release the API servers,

57
00:03:47,442 --> 00:03:50,934
then we release the API clients, we get them talking

58
00:03:50,972 --> 00:03:54,754
to each other and the integration fails. And this failure

59
00:03:54,802 --> 00:03:58,630
can happen for multiple reasons, but very often it happens for simple

60
00:03:58,700 --> 00:04:01,926
things like a misunderstanding between the frontend and

61
00:04:01,948 --> 00:04:05,546
the backend about what the format of a certain field could be. In this

62
00:04:05,568 --> 00:04:09,210
case, I'm showing the example of a misunderstanding with a date

63
00:04:09,360 --> 00:04:13,370
field, which the client is sending with slashes separating

64
00:04:13,450 --> 00:04:17,770
the different elements of the date, while the server is expecting dashes

65
00:04:17,850 --> 00:04:21,294
in the date field. These kind of errors are very common and

66
00:04:21,332 --> 00:04:25,406
they lead to all sorts of problems in our API integrations.

67
00:04:25,518 --> 00:04:29,410
Now, how do we end up in this situation? What takes us here?

68
00:04:29,560 --> 00:04:33,106
And obviously there is a large variety of factors that can

69
00:04:33,128 --> 00:04:36,046
affect the outcome of our API integrations.

70
00:04:36,158 --> 00:04:39,526
But when it comes to failure in communication between the

71
00:04:39,548 --> 00:04:42,886
front end and the backend, usually everything build down to one of

72
00:04:42,908 --> 00:04:46,802
the following three factors. It can be the case that we don't have documentation

73
00:04:46,866 --> 00:04:50,518
at all, and instead of it, maybe we are working with JSON examples.

74
00:04:50,614 --> 00:04:54,762
Now JSON examples are a very common resource when working

75
00:04:54,816 --> 00:04:58,342
with API integrations, but they don't offer sufficient coverage

76
00:04:58,406 --> 00:05:02,106
of the different payloads which are accepted by the server or which are

77
00:05:02,128 --> 00:05:05,566
returned by the server. So in these situations it is very difficult for

78
00:05:05,588 --> 00:05:09,566
the API client development team to figure out the integration with the

79
00:05:09,588 --> 00:05:13,050
server. In some other cases we have something like documentation,

80
00:05:13,130 --> 00:05:16,766
but it's not really documentation, or it's not documentation written

81
00:05:16,798 --> 00:05:20,466
in a standard format. What do I mean by this is we often end

82
00:05:20,488 --> 00:05:23,870
up writing API documentation in something like Google Docs,

83
00:05:23,950 --> 00:05:27,698
sharepoint or confluence, and we do that in non standard formats.

84
00:05:27,794 --> 00:05:31,510
Or again, maybe we include JSON examples instead of actual

85
00:05:31,580 --> 00:05:35,206
schemas of the API. The problem with this is this type of

86
00:05:35,228 --> 00:05:39,046
documentation cannot be leveraged with the whole ecosystem of

87
00:05:39,068 --> 00:05:43,082
tools and frameworks that we have in the API ecosystem to make our life

88
00:05:43,136 --> 00:05:46,566
easier when it comes to maintaining and releasing our APIs,

89
00:05:46,678 --> 00:05:50,582
they don't help us to test and validate our implementations

90
00:05:50,726 --> 00:05:54,430
because it's difficult to manage our API integrations. Another problem

91
00:05:54,500 --> 00:05:57,946
we often find as well is we don't have a proper design stage

92
00:05:57,978 --> 00:06:02,030
of the API. So instead of having the frontend team sitting together

93
00:06:02,100 --> 00:06:05,746
with the backend team and talking about what the API should look like

94
00:06:05,768 --> 00:06:09,506
and what the requirements should be, often the API is kind of

95
00:06:09,608 --> 00:06:13,538
an afterthought of the backend development process and we

96
00:06:13,624 --> 00:06:17,246
end up releasing random URLs and we end up with a messy

97
00:06:17,278 --> 00:06:21,346
collection of URLs and resources in the servers, which are difficult for the client development

98
00:06:21,378 --> 00:06:25,222
team to understand and figure out how to use in the clients. Now,

99
00:06:25,276 --> 00:06:29,206
to avoid these situations, obviously the best thing is to use

100
00:06:29,388 --> 00:06:33,158
proper API documentation, and what actually counts as API

101
00:06:33,174 --> 00:06:36,298
documentation depends on the type of API that we are using

102
00:06:36,384 --> 00:06:39,530
or the type of protocol. So if we are working with rest

103
00:06:39,600 --> 00:06:43,126
APIs, we want to use the open API specifications format.

104
00:06:43,238 --> 00:06:47,082
If we are working with a GraphQL API, that should be the schema definition language,

105
00:06:47,146 --> 00:06:51,354
and if we are working with something like GRPC, we should be expecting the documentation

106
00:06:51,402 --> 00:06:54,606
to come in the form of protocol buffers. So each protocol or type

107
00:06:54,628 --> 00:06:57,746
of API has its own format, and we should be making an

108
00:06:57,768 --> 00:07:01,518
effort to use that format, because then we will be able to use various tools

109
00:07:01,534 --> 00:07:04,834
and frameworks to make our life easier when working with these

110
00:07:04,872 --> 00:07:08,486
APIs. Now, what is documentationdriven development? So this is an

111
00:07:08,508 --> 00:07:11,362
approach that you may know already under different names.

112
00:07:11,426 --> 00:07:15,426
It's also known as design first, API first or contract first API

113
00:07:15,458 --> 00:07:18,786
development. The basic idea is we design and products

114
00:07:18,818 --> 00:07:22,566
the API specification first before we start working on the API client

115
00:07:22,598 --> 00:07:26,426
and the server. Then we build the API client and

116
00:07:26,448 --> 00:07:30,214
the server against the specification, and we use the specification

117
00:07:30,262 --> 00:07:33,294
to validate our code before we release it. Now,

118
00:07:33,332 --> 00:07:36,462
how does this work in practice? I'm going to show you with a simple example.

119
00:07:36,596 --> 00:07:40,606
Like I said before, I prepared a simple example of

120
00:07:40,788 --> 00:07:44,746
to do application. It's a very simple application that allows

121
00:07:44,778 --> 00:07:48,478
us to create a task. We can update a task,

122
00:07:48,574 --> 00:07:52,254
we can delete it, or we can retrieve the details of one task or multiple

123
00:07:52,302 --> 00:07:56,542
tasks from the server. The specifications is written in the open API

124
00:07:56,606 --> 00:08:00,326
format 30 and it's written in Yaml. But to

125
00:08:00,348 --> 00:08:04,050
get a better visualization of it, let's move on to a swagger UI.

126
00:08:04,130 --> 00:08:08,182
So when working with API documents, I highly recommend

127
00:08:08,236 --> 00:08:11,846
you to use Swagger editor. Swagger editor makes it really easy to work

128
00:08:11,868 --> 00:08:15,414
with API documents because first of all it can validate the document.

129
00:08:15,462 --> 00:08:18,534
So if there is any problem with it, it will tell you where the error

130
00:08:18,582 --> 00:08:22,202
is and what type of error it is. So if we remove this line,

131
00:08:22,256 --> 00:08:26,062
for example, it tells us that there is a structural problem in line

132
00:08:26,116 --> 00:08:29,646
13 and it tells us what kind of problem it is. So let's put

133
00:08:29,668 --> 00:08:33,390
this line back. Now the bi specification is valid and

134
00:08:33,460 --> 00:08:36,970
we can see that it has five simple endpoints.

135
00:08:37,050 --> 00:08:40,718
We can also see the payloads, sorry, the schemas for the

136
00:08:40,724 --> 00:08:44,074
payloads in this API. So we have a schema for error

137
00:08:44,122 --> 00:08:47,526
messages. We have a schema for the type of payload that we

138
00:08:47,548 --> 00:08:50,882
should be sending to the server when we create or update a task.

139
00:08:50,946 --> 00:08:53,686
And we have a schema for the type of payload that we will get from

140
00:08:53,708 --> 00:08:56,966
the server when we get the details of a task. Now let me show you

141
00:08:56,988 --> 00:09:00,742
how we can leverage this documentation on the client side to

142
00:09:00,796 --> 00:09:04,026
run a mock server when we're working on the client, I'm going to show you

143
00:09:04,048 --> 00:09:07,334
two ways of doing it. One of them is running the mock server locally,

144
00:09:07,382 --> 00:09:11,098
and another way is running it in the cloud. To run the server locally,

145
00:09:11,194 --> 00:09:15,134
I recommend you to use Prism, which is a CLI tool built by

146
00:09:15,172 --> 00:09:18,510
stoplight. It's a very powerful tool to run rest

147
00:09:18,580 --> 00:09:22,698
applications locally against the specification document.

148
00:09:22,874 --> 00:09:27,118
A prism is an NPM package, so you will need to have NPM

149
00:09:27,214 --> 00:09:31,038
as well as a node JS runtime available locally

150
00:09:31,134 --> 00:09:34,466
and optionally. If you want to manage the dependencies with yarn, you will

151
00:09:34,488 --> 00:09:38,290
need to have yarn as well. The NPM dependencies for this project

152
00:09:38,360 --> 00:09:41,954
are listed in the package JSOn file. So we have the Prism

153
00:09:42,002 --> 00:09:45,446
Cli as well as thread. I will introduce thread a little bit later in

154
00:09:45,468 --> 00:09:48,706
this presentation to install the dependencies I'm going to use yarn.

155
00:09:48,738 --> 00:09:52,282
All you need to do is run the yarn command just like that,

156
00:09:52,416 --> 00:09:55,834
and after the dependencies are installed you will see can old

157
00:09:55,872 --> 00:09:59,546
modules folder available in your directory. So this

158
00:09:59,568 --> 00:10:03,326
folder contains all the dependencies that come with these libraries as well

159
00:10:03,348 --> 00:10:07,546
as all the commands that are available with them. So the prism

160
00:10:07,578 --> 00:10:11,086
Cli is available within this folder that

161
00:10:11,108 --> 00:10:14,286
is under bin and prism. To run the

162
00:10:14,308 --> 00:10:17,874
mock server we use the mock command available in this Cli and

163
00:10:17,912 --> 00:10:21,298
we give it the path to the open API specification file. So if

164
00:10:21,304 --> 00:10:24,338
we run this command, the mock server is now running.

165
00:10:24,424 --> 00:10:28,242
The first thing we see in the logs is a list of the endpoints

166
00:10:28,306 --> 00:10:32,326
available in this mock server. So let's try out running

167
00:10:32,428 --> 00:10:36,034
a request against one of these endpoints.

168
00:10:36,162 --> 00:10:39,286
So I'm going to do it with CuRl and I'm going to

169
00:10:39,308 --> 00:10:43,306
use JQ to parse the JSON payload returned by the server to

170
00:10:43,328 --> 00:10:46,714
have a nice representation of it. If you can see here, this is

171
00:10:46,752 --> 00:10:50,442
a list of items. Prism has included only one item in the list,

172
00:10:50,496 --> 00:10:53,482
but that's a perfectly valid situation for this API.

173
00:10:53,546 --> 00:10:56,926
And the payload contains all the expected attributes that we should be

174
00:10:56,948 --> 00:11:00,494
finding in this payload. Now this

175
00:11:00,532 --> 00:11:04,014
is how we would run the mock server locally. We can do it as well

176
00:11:04,052 --> 00:11:07,570
in the cloud. I'm going to show you how to do it with microapisio.

177
00:11:08,230 --> 00:11:12,702
So what we need to do is we need to copy the API specification

178
00:11:12,846 --> 00:11:16,514
and we need to paste it in the input panel which

179
00:11:16,552 --> 00:11:20,246
is here on the left. We paste it here. First thing that the

180
00:11:20,268 --> 00:11:23,366
server is using is validating the API. Now we can

181
00:11:23,388 --> 00:11:26,902
click on this button to launch the MOOC server. Like I said before,

182
00:11:26,956 --> 00:11:30,518
we get the base URL as well as a sample URL of the

183
00:11:30,604 --> 00:11:34,186
API. So if we click on this one we get a payload with

184
00:11:34,208 --> 00:11:38,170
a valid list of items from the server. Let's try this

185
00:11:38,240 --> 00:11:42,026
in the terminal as well with curl. Let's clear the

186
00:11:42,048 --> 00:11:45,562
terminal and do a curl on this. We will use GQ

187
00:11:45,626 --> 00:11:49,374
as well to pass the JSON payload and what we get

188
00:11:49,412 --> 00:11:52,714
is a list of items. In this case we are getting more than one item.

189
00:11:52,762 --> 00:11:56,222
So the experience is a little bit different from what you get with Prism,

190
00:11:56,286 --> 00:11:59,886
but in both cases we're getting perfectly valid payloads from the servers.

191
00:11:59,998 --> 00:12:03,726
So this is a very useful approach to building API

192
00:12:03,758 --> 00:12:07,070
integrations. I'm currently using this MOOC service when I work with

193
00:12:07,080 --> 00:12:10,486
my clients in my current contract, and it's making

194
00:12:10,588 --> 00:12:14,102
our life to build the API integration so much easier because

195
00:12:14,156 --> 00:12:17,650
we can simulate the interactions with the server while the

196
00:12:17,740 --> 00:12:21,542
endpoints are big implemented and we can get simulation

197
00:12:21,606 --> 00:12:25,418
of network latency issues. So obviously

198
00:12:25,584 --> 00:12:29,366
there's some data that is not going to be available within microseconds.

199
00:12:29,398 --> 00:12:33,434
It might take a little bit longer than that and we can implement the API

200
00:12:33,482 --> 00:12:36,410
client in a way that is able to handle these situations.

201
00:12:36,490 --> 00:12:40,602
Now this is how we leverage the benefits of documentation driven development

202
00:12:40,666 --> 00:12:44,346
in the client side. Let's see how we benefit

203
00:12:44,378 --> 00:12:47,794
from this. In the backend so like I said before, we are going to build

204
00:12:47,832 --> 00:12:51,090
the API with Fastapi. For those of you who don't know,

205
00:12:51,160 --> 00:12:54,446
Fast API is a highly performant web API

206
00:12:54,478 --> 00:12:58,166
framework for Python. It's a very recent project, but it's one of the

207
00:12:58,188 --> 00:13:01,762
most popular Python projects at the moment. It's very well written,

208
00:13:01,826 --> 00:13:05,318
very well designed, it has a very intuitive interface, and it

209
00:13:05,324 --> 00:13:09,026
is extraordinarily well documented. So if you haven't checked but Fastapi

210
00:13:09,058 --> 00:13:12,794
yet, you should definitely check it out. I think it's without any question the

211
00:13:12,832 --> 00:13:16,090
best API development framework for Python right now. Now,

212
00:13:16,160 --> 00:13:19,642
Fastapi works with pydantic to validate data

213
00:13:19,696 --> 00:13:23,694
payloads in the server. So Pydantic is another very

214
00:13:23,732 --> 00:13:27,658
popular library in Python for data passing and validation.

215
00:13:27,754 --> 00:13:31,274
And as you can see in this example, the way we define the validation

216
00:13:31,322 --> 00:13:34,974
rules for our payloads is by using type hints.

217
00:13:35,022 --> 00:13:38,526
So this gives us a very pythonic and very intuitive

218
00:13:38,638 --> 00:13:42,094
way of defining the validation rules for our models.

219
00:13:42,222 --> 00:13:46,098
So let me show you the dependencies for

220
00:13:46,264 --> 00:13:49,766
the app. They are listed in a PIP file. We have

221
00:13:49,788 --> 00:13:53,206
a couple of development packages. We have threadhooks which

222
00:13:53,228 --> 00:13:57,378
I will introduce a little bit later. We have also data model code generator,

223
00:13:57,554 --> 00:14:02,002
which is a library that is going to help us translate the open API specification

224
00:14:02,066 --> 00:14:05,574
schemas into pydantic models. And we have a couple of products

225
00:14:05,622 --> 00:14:09,546
packages. Obviously we have Fast API which is going to help us build

226
00:14:09,648 --> 00:14:13,558
the API application, and we have Uvicon which is going to help us run

227
00:14:13,584 --> 00:14:16,670
the web server. Now for those of you who are not familiar with it,

228
00:14:16,740 --> 00:14:19,934
data model code generator is a library that helps you

229
00:14:19,972 --> 00:14:23,710
translate any kind of JSON schema specification

230
00:14:23,790 --> 00:14:27,870
into binatic models. It is extremely useful and very powerful,

231
00:14:28,030 --> 00:14:31,410
and in most cases I would recommend you don't write your data

232
00:14:31,480 --> 00:14:34,846
models manually if you have a specification

233
00:14:34,958 --> 00:14:38,978
at hand. First, I recommend you that you use this tool to do the translations

234
00:14:39,074 --> 00:14:42,918
since it can help you avoid many mistakes in the translation process.

235
00:14:43,084 --> 00:14:46,502
So first things first, let us stop

236
00:14:46,556 --> 00:14:50,854
the mock server of prism that we started before. Let's clear up the terminal

237
00:14:50,902 --> 00:14:53,946
and let's install the python dependencies for this project.

238
00:14:54,048 --> 00:14:57,946
So we do that because we have dev dependencies. We do

239
00:14:57,968 --> 00:14:59,610
that with the dev flag.

240
00:15:03,250 --> 00:15:07,246
So our dependencies are already installed and now we have to activate the

241
00:15:07,348 --> 00:15:10,874
PPNV environment. We do that with PPNV shell. The environment

242
00:15:10,922 --> 00:15:14,334
is already activated and now we can start working on the project. Like I said,

243
00:15:14,372 --> 00:15:17,966
the first thing we want to do is we want to generate the pydantic models

244
00:15:17,998 --> 00:15:21,874
so we do that with the following command, which is data model code

245
00:15:21,912 --> 00:15:25,902
gen. We need to give it the input which is the open APIs specification

246
00:15:25,966 --> 00:15:29,046
file, and we need to give it an output which is the file where we

247
00:15:29,068 --> 00:15:33,190
want to see the schemas written to. So we run the command and

248
00:15:33,260 --> 00:15:36,806
the schemas file is already available. So this is the

249
00:15:36,828 --> 00:15:40,474
file. It contains some metadata like the

250
00:15:40,512 --> 00:15:43,786
file we use to generate the models as well as the time when we run

251
00:15:43,808 --> 00:15:47,626
the command. So data model code generator makes an

252
00:15:47,648 --> 00:15:51,194
excellent job at translating the open APIs schemas into

253
00:15:51,232 --> 00:15:55,066
pydantic models. But if we look closely at the file,

254
00:15:55,098 --> 00:15:58,798
we see there are a couple of duplications. So in particular

255
00:15:58,884 --> 00:16:02,078
these two classes are duplicated here below and really they should be

256
00:16:02,084 --> 00:16:06,046
the same. So let's delete these two classes to make maintenance easier

257
00:16:06,078 --> 00:16:09,614
in the future, and let's rename these classes

258
00:16:09,662 --> 00:16:13,506
here. If you're not familiar with pedantic, you may find this ellipses here a little

259
00:16:13,528 --> 00:16:17,174
bit confusing. This is just a way of telling pedantic that a field that

260
00:16:17,212 --> 00:16:20,658
has been declared with the field class is required.

261
00:16:20,754 --> 00:16:24,406
Otherwise, any field that is directly declared with a

262
00:16:24,428 --> 00:16:27,458
type hint is supposed to be required,

263
00:16:27,554 --> 00:16:31,270
unless you mark it explicitly with the optional type hint.

264
00:16:31,350 --> 00:16:34,794
So now we have our pydantic models ready, let's move on to the

265
00:16:34,832 --> 00:16:38,262
API file. So I have created

266
00:16:38,326 --> 00:16:41,674
the API endpoints for the API in this

267
00:16:41,712 --> 00:16:45,166
file. In API Py, the first thing we have is a list for the to

268
00:16:45,188 --> 00:16:48,686
do items. So to keep things simple, I've decided to use an

269
00:16:48,708 --> 00:16:52,602
in memory list implementations of the data instead of a persistent storage.

270
00:16:52,666 --> 00:16:56,114
If you're familiar with flask, the interface here

271
00:16:56,152 --> 00:16:59,906
will look very familiar. The way we define the endpoints is

272
00:17:00,008 --> 00:17:03,714
using decorators on the application object. The decorators are

273
00:17:03,752 --> 00:17:07,638
named after the HTTP endpoint for

274
00:17:07,724 --> 00:17:11,154
each endpoint in the API. So this is for a get endpoint

275
00:17:11,202 --> 00:17:15,286
on the to do URL path. In cases where the

276
00:17:15,388 --> 00:17:18,726
API endpoint returns data for the user, we want to use a

277
00:17:18,748 --> 00:17:22,234
response model class that fast API can use

278
00:17:22,272 --> 00:17:25,350
to validate the data that we are sending to the user,

279
00:17:25,430 --> 00:17:28,810
and also to serialize the data. In cases where the

280
00:17:28,880 --> 00:17:32,542
API endpoint returns a status code which is different

281
00:17:32,596 --> 00:17:36,430
from the standard 200 status code, we can specify that

282
00:17:36,500 --> 00:17:40,010
in the status code parameter. If the API endpoint

283
00:17:40,090 --> 00:17:43,486
accepts a payload in the request from

284
00:17:43,508 --> 00:17:47,266
the user, we can also tell fast API, which is

285
00:17:47,288 --> 00:17:51,214
the pedantic model that should be used to validate the request

286
00:17:51,262 --> 00:17:54,626
payload. And in cases where the URL contains a

287
00:17:54,648 --> 00:17:57,958
parameter, we can also tell fast API, what is the

288
00:17:57,964 --> 00:18:01,058
type that should be used to validate the URL parameter?

289
00:18:01,154 --> 00:18:05,490
So this is all about the API layer. To initialize

290
00:18:05,570 --> 00:18:09,730
the server, all we need to do is create an instance

291
00:18:09,810 --> 00:18:13,142
of the fastapi class we are running here in debug mode,

292
00:18:13,206 --> 00:18:16,998
and we are also importing the API roots into this file

293
00:18:17,094 --> 00:18:21,094
to load them at the startup time. There are other ways of loading

294
00:18:21,142 --> 00:18:25,114
the API views. So if you are familiar with flask blueprints,

295
00:18:25,162 --> 00:18:28,462
fast API has a similar concept to them. And that's really the type of

296
00:18:28,516 --> 00:18:31,758
approach you want to use if you're building a production application

297
00:18:31,844 --> 00:18:35,234
with fast API. In this case, just to keep things simple, I'm using this

298
00:18:35,272 --> 00:18:38,862
approach. So we have the API implemented.

299
00:18:38,926 --> 00:18:42,626
Let's now run it with Uvicon. So to run the application

300
00:18:42,728 --> 00:18:46,066
with Uvicon, we have to give it the path to the file with

301
00:18:46,088 --> 00:18:49,494
dot notation, and within the file after a column we have to tell it

302
00:18:49,532 --> 00:18:53,206
which is the variable that represents the server. So if

303
00:18:53,228 --> 00:18:56,774
we run this command, we get the API server running and

304
00:18:56,812 --> 00:19:00,102
we can check it out in this URL. So let's go ahead and

305
00:19:00,156 --> 00:19:03,446
visit that URL. Now if we visit the to

306
00:19:03,468 --> 00:19:07,594
do endpoint, for example, we will get can empty list. Fast API is

307
00:19:07,632 --> 00:19:11,594
capable of generating an open API specification from

308
00:19:11,632 --> 00:19:15,722
the implementation and also a swagger UI visualization

309
00:19:15,786 --> 00:19:19,134
of the API. So let's go ahead and visit that URL. And this is

310
00:19:19,172 --> 00:19:22,874
the swagger UI for the API that we have written in Python

311
00:19:22,922 --> 00:19:26,626
with fast API. With this we can already interact with the server. So if

312
00:19:26,648 --> 00:19:30,334
we run the get endpoint, we get again an empty

313
00:19:30,382 --> 00:19:34,002
list. So let's go ahead and create one item to verify things are working

314
00:19:34,056 --> 00:19:37,486
fine. So if we execute this, we get a valid response

315
00:19:37,518 --> 00:19:40,886
from the servers with a 201 status code.

316
00:19:41,068 --> 00:19:44,566
So if we run the get endpoint again, now we

317
00:19:44,588 --> 00:19:47,638
have one item in the list. So the API seems to

318
00:19:47,644 --> 00:19:51,238
be working as expected. And typically now we would write

319
00:19:51,324 --> 00:19:54,998
a bunch of unit test cases to make sure all the rest of the endpoints

320
00:19:55,014 --> 00:19:58,310
are working fine and we cover some edge cases in the API.

321
00:19:58,390 --> 00:20:02,234
Now those unit tests are fine, but in addition to that, I encourage

322
00:20:02,282 --> 00:20:06,154
you to use as well a proper API test framework

323
00:20:06,282 --> 00:20:09,646
because usually unless you are ultimate expert in

324
00:20:09,668 --> 00:20:12,986
APIs, I can guarantee you that you're going to miss some edge

325
00:20:13,018 --> 00:20:16,958
cases in your test suite. So in this presentation I'm going to introduce

326
00:20:16,974 --> 00:20:20,386
you to thread. There are some other test frameworks as

327
00:20:20,408 --> 00:20:24,750
well, which you can explore, but thread is a classic API test framework

328
00:20:24,830 --> 00:20:28,646
that will get you covered with all possible edge cases when

329
00:20:28,668 --> 00:20:32,786
it comes to API communication. So it will test the payloads

330
00:20:32,818 --> 00:20:36,914
of your server. It will test the return status

331
00:20:36,962 --> 00:20:40,566
codes and the payloads for those status codes. So a combination

332
00:20:40,598 --> 00:20:43,894
of unit tests that make sure that the application is behaving

333
00:20:43,942 --> 00:20:47,786
correctly in communication with a test suit run by dread will

334
00:20:47,808 --> 00:20:51,606
get you covered with your API applications. Now how we run dread

335
00:20:51,718 --> 00:20:55,502
first of all, dread is an NPM package. So I already listed before

336
00:20:55,556 --> 00:20:59,438
dread in the package JSOn file that I showed you before that

337
00:20:59,524 --> 00:21:03,266
is here. So when we run yarn to install these

338
00:21:03,288 --> 00:21:07,150
dependencies before we already installed thread, and to run thread,

339
00:21:07,230 --> 00:21:10,418
what we need to do is bit by big.

340
00:21:10,504 --> 00:21:14,258
That is the thread CLI together with

341
00:21:14,424 --> 00:21:17,782
the first input is the path to the

342
00:21:17,836 --> 00:21:21,430
API file that we are going to use for validation. The second

343
00:21:21,500 --> 00:21:25,014
parameter is the URL where thread will be able to

344
00:21:25,052 --> 00:21:28,614
run the tests. And the third parameter here is

345
00:21:28,732 --> 00:21:32,046
with the server flag is the command that thread

346
00:21:32,098 --> 00:21:35,354
needs to run to make sure that it can

347
00:21:35,392 --> 00:21:38,954
launch the web server to run the test suite. So if we run

348
00:21:38,992 --> 00:21:39,820
this now,

349
00:21:42,870 --> 00:21:46,662
threat is now testing the API and it's telling us that five

350
00:21:46,716 --> 00:21:50,294
tests are passing but three are failing. Now let's have a

351
00:21:50,332 --> 00:21:53,826
close look at those tests that are failing. So this one for example,

352
00:21:53,948 --> 00:21:57,786
is the delete request on a specific resource that

353
00:21:57,808 --> 00:22:01,818
is failing. The but

354
00:22:01,904 --> 00:22:05,030
request on a specific item is also failing,

355
00:22:05,110 --> 00:22:08,314
and the get request on

356
00:22:08,352 --> 00:22:11,802
a specific item is failing as well. All the other requests

357
00:22:11,866 --> 00:22:15,646
are fine. This is just a repetition of the request that

358
00:22:15,668 --> 00:22:19,230
I mentioned before that was failing. So if you think about it,

359
00:22:19,300 --> 00:22:22,606
what is failing here is those requests that target the

360
00:22:22,628 --> 00:22:26,562
specific items in the server. So when dread is trying to perform

361
00:22:26,616 --> 00:22:30,322
an operation with an existing item, it is failing. And now the reason

362
00:22:30,376 --> 00:22:34,306
why this is happening is because thread is using random ids

363
00:22:34,338 --> 00:22:37,878
to test the API. It's using one id for

364
00:22:38,044 --> 00:22:41,586
creating the resource, and then it's using a different id to retrieve

365
00:22:41,618 --> 00:22:45,746
a resource or to perform operations on it. Obviously, random resources don't

366
00:22:45,778 --> 00:22:49,466
exist on the server, so we have to customize the behavior of thread in such

367
00:22:49,488 --> 00:22:53,370
a way that it always uses the same id that was returned when

368
00:22:53,440 --> 00:22:56,474
we created a resource on the server. We can do that with

369
00:22:56,512 --> 00:23:00,526
threadhooks. That was the dependency that I included here.

370
00:23:00,628 --> 00:23:04,634
This plugin allows us to customize the behavior of thread

371
00:23:04,682 --> 00:23:08,714
and to keep track of the state of the test suite. I've prepared a file

372
00:23:08,762 --> 00:23:12,046
with collection of tools here that affect the

373
00:23:12,068 --> 00:23:15,506
behavior of thread. The first thing we are doing is creating a dictionary which

374
00:23:15,528 --> 00:23:18,798
we are going to use to keep track of the state of the test suite.

375
00:23:18,894 --> 00:23:22,882
And then what we are doing is telling dread that when we

376
00:23:22,936 --> 00:23:25,506
create a task using the post method,

377
00:23:25,618 --> 00:23:29,078
we need to save the id of this task. We are

378
00:23:29,084 --> 00:23:32,710
going to use this id in the following methods that perform

379
00:23:32,780 --> 00:23:36,434
operations on a specific task. So when dread wants to update

380
00:23:36,482 --> 00:23:40,314
a task, we are going to tell it to use the existing task id that

381
00:23:40,352 --> 00:23:43,958
we obtained when we created the task. And when we delete

382
00:23:43,974 --> 00:23:46,906
the task or get the details of the task, we're going to tell it to

383
00:23:46,928 --> 00:23:50,686
use that same id. So the file is already available. And to use

384
00:23:50,708 --> 00:23:54,666
the file we used thread with the following

385
00:23:54,778 --> 00:23:58,734
parameters. We need to use the hook files flag and

386
00:23:58,772 --> 00:24:02,586
point it to the path of the file that contains the hooks.

387
00:24:02,698 --> 00:24:06,066
We have to tell it in which language the hooks are written. So in this

388
00:24:06,088 --> 00:24:09,506
case we wrote the tools in Python. So we just simply tell

389
00:24:09,528 --> 00:24:13,240
it that the hooks are written in Python. If we run this command now,

390
00:24:15,370 --> 00:24:18,802
the test suite is passing fine. Now no errors,

391
00:24:18,866 --> 00:24:22,258
eight tests and the eight tests are passing

392
00:24:22,354 --> 00:24:26,354
now we have verified that our API implementation completely

393
00:24:26,402 --> 00:24:29,802
with the API specification file. We would like to make sure that

394
00:24:29,856 --> 00:24:33,226
this test is run every time we make any changes to

395
00:24:33,248 --> 00:24:36,506
the code and the code is validated before we make a release. How we

396
00:24:36,528 --> 00:24:40,266
do that we can do it by incorporating this test suite in our continuous

397
00:24:40,298 --> 00:24:44,014
integration server. So I've prepared a Travis file for

398
00:24:44,052 --> 00:24:48,474
this exercise. So the Travis file contains instructions

399
00:24:48,602 --> 00:24:52,530
about how to install thread to run the test suite.

400
00:24:53,750 --> 00:24:57,342
It tells the server also how to install the python dependencies.

401
00:24:57,486 --> 00:25:00,962
It tells the server what's the command that has to be run

402
00:25:01,016 --> 00:25:04,498
to run the test. And we also provide some deployment configuration so

403
00:25:04,504 --> 00:25:07,974
that this can be deployed into Heroku. We are also telling the server to use

404
00:25:08,012 --> 00:25:11,218
the correct version of Python so that Ppemp doesn't complain.

405
00:25:11,314 --> 00:25:14,518
So to test how this works, we are going to make a commit here.

406
00:25:14,604 --> 00:25:17,980
We are going to commit the changes we made to the schemas file before

407
00:25:20,190 --> 00:25:23,258
and now we are going to push this to make it simple, I'm going to

408
00:25:23,264 --> 00:25:27,630
push directly to master. So git push origin master

409
00:25:28,130 --> 00:25:31,770
I think we are in master. Yes, so git push

410
00:25:31,850 --> 00:25:34,910
origin master master.

411
00:25:36,210 --> 00:25:39,646
So this is now in GitHub and Travis is going to

412
00:25:39,668 --> 00:25:43,314
get a trigger, a notification when at

413
00:25:43,352 --> 00:25:47,314
some point to run the test suite and then deploy the code if

414
00:25:47,352 --> 00:25:51,026
it is valid. So we just need to give it a moment. Now the

415
00:25:51,048 --> 00:25:54,630
build is starting, we're going to follow the logs.

416
00:25:59,350 --> 00:26:03,330
So Travis has run the threat test suite against the application.

417
00:26:03,480 --> 00:26:06,926
The tests are passing and therefore Travis is moving on

418
00:26:06,968 --> 00:26:10,882
to the deployment stage of the continuous integration

419
00:26:10,946 --> 00:26:14,674
process. We can monitor the deployment process in Heroku,

420
00:26:14,802 --> 00:26:18,226
and that is already triggering the deployment it's

421
00:26:18,258 --> 00:26:21,602
about to release. And this is the URL

422
00:26:21,666 --> 00:26:25,546
that we can use to visit the application. Just need to

423
00:26:25,568 --> 00:26:29,286
leave it a minute. Okay, so the build is finished now, we can now visit

424
00:26:29,318 --> 00:26:32,698
the application on this URL. So let's go ahead and do that. We're going to

425
00:26:32,704 --> 00:26:36,506
visit the docs endpoint that I mentioned before contains the swagger

426
00:26:36,538 --> 00:26:40,334
UI to interact with the application more easily. So let's go ahead

427
00:26:40,372 --> 00:26:43,450
and do that. And this is the swagger UI.

428
00:26:43,530 --> 00:26:46,654
Now if we try the get endpoint, the list

429
00:26:46,692 --> 00:26:50,226
is empty, obviously, because the application was just released and we

430
00:26:50,248 --> 00:26:53,602
are visiting a new instance of the app. So let's go ahead and create

431
00:26:53,656 --> 00:26:57,662
a task. We do that, we obtain a successful

432
00:26:57,726 --> 00:27:00,998
response, and now we execute the get endpoint again,

433
00:27:01,084 --> 00:27:04,370
and we have one task in the list. So the server was validated,

434
00:27:04,450 --> 00:27:07,254
it's working as expected. At the same time,

435
00:27:07,372 --> 00:27:10,886
the client development team has been working against the

436
00:27:10,908 --> 00:27:14,230
same specification. So things are never 100%

437
00:27:14,300 --> 00:27:18,282
certain. But if we follow this approach, we can be fairly certain that at least

438
00:27:18,336 --> 00:27:21,882
when it comes to API communication, both the server and

439
00:27:21,936 --> 00:27:25,514
both the client and the server will be talking to each other in the same

440
00:27:25,552 --> 00:27:29,878
language. So this is really everything I wanted to introduce in this presentation.

441
00:27:29,974 --> 00:27:33,626
Thanks for listening again. If you're interested in connecting with me, please do

442
00:27:33,648 --> 00:27:36,382
so in any of these platforms on Twitter, GitHub,

443
00:27:36,446 --> 00:27:40,402
medium or LinkedIn. And if you want to get a 30% discount code

444
00:27:40,456 --> 00:27:43,346
on my book, feel free to use the following code.

445
00:27:43,528 --> 00:27:44,960
Thank you and have a great day.

