1
00:00:24,330 --> 00:00:26,994
Hi. Hello. In this session,

2
00:00:27,122 --> 00:00:30,486
we learn about chaos engineering and how to

3
00:00:30,508 --> 00:00:33,874
build resilient and wellarchitected applications

4
00:00:33,922 --> 00:00:37,682
with it. Wellarchitected applications

5
00:00:37,746 --> 00:00:41,394
are designed and built to be secure, high performing,

6
00:00:41,442 --> 00:00:45,362
and resilient. You need to test your applications

7
00:00:45,426 --> 00:00:48,534
and validate that it operates. AWS designed and

8
00:00:48,572 --> 00:00:50,230
is resilient to failures.

9
00:00:54,310 --> 00:00:57,774
We'll start with a quick look at AWS

10
00:00:57,902 --> 00:01:01,870
well architected and how that ties together with chaos

11
00:01:01,950 --> 00:01:05,926
engineering. Then we'll do a short intro

12
00:01:06,028 --> 00:01:10,360
to AWS fault injection simulator and an example.

13
00:01:16,500 --> 00:01:20,524
Creating technology solutions is lot like constructing

14
00:01:20,572 --> 00:01:24,512
a physical building. If the foundation is not solid,

15
00:01:24,656 --> 00:01:28,324
it may cause structural problems that undermine the

16
00:01:28,362 --> 00:01:30,710
integrity and function of the building.

17
00:01:32,200 --> 00:01:35,530
The Wellarchitected framework is a set of questions

18
00:01:35,980 --> 00:01:39,752
and design principles to drive better outcomes for

19
00:01:39,806 --> 00:01:43,448
anyone who wants to build and operate workloads on

20
00:01:43,454 --> 00:01:47,256
the cloud. It helps build secure,

21
00:01:47,448 --> 00:01:51,384
highperforming, resilient and efficient infrastructure

22
00:01:51,512 --> 00:01:55,180
for a wide variety of applications and workloads.

23
00:01:59,630 --> 00:02:02,966
Built around six pillars, AWS well

24
00:02:03,008 --> 00:02:07,134
architected provides a consistent approach for customers to

25
00:02:07,172 --> 00:02:11,310
evaluate architectures and implement scalable designs.

26
00:02:11,970 --> 00:02:15,534
If you neglect the six pillars of operational excellence,

27
00:02:15,662 --> 00:02:19,550
security, reliability, performance efficiency,

28
00:02:19,710 --> 00:02:23,486
cost optimization, and sustainability when architecting

29
00:02:23,518 --> 00:02:27,350
solutions, it can become a challenge to build a system

30
00:02:27,420 --> 00:02:30,662
that delivers functional requirements and meets your

31
00:02:30,716 --> 00:02:31,670
expectations.

32
00:02:34,090 --> 00:02:37,954
When you incorporate these pillars, it will help you produce

33
00:02:38,002 --> 00:02:41,354
stable and efficient systems, allowing you to

34
00:02:41,392 --> 00:02:43,610
focus on functional requirements.

35
00:02:48,150 --> 00:02:51,970
In this session, we'll touch on three pillars.

36
00:02:52,710 --> 00:02:55,894
Operational excellence, which is the ability to

37
00:02:55,932 --> 00:02:59,542
run and monitor systems to deliver business value and

38
00:02:59,596 --> 00:03:03,670
continually improving processes and procedures

39
00:03:04,410 --> 00:03:07,930
reliability, which is the ability of a system

40
00:03:08,080 --> 00:03:11,930
to recover from infrastructure or service failures

41
00:03:12,430 --> 00:03:16,314
and performance efficiency, which is the ability to

42
00:03:16,352 --> 00:03:20,794
use computing resources efficiently to meet system requirements

43
00:03:20,922 --> 00:03:25,054
and to maintain that efficiency as demand changes and

44
00:03:25,092 --> 00:03:26,830
technologies evolve.

45
00:03:30,350 --> 00:03:34,138
In the reliability pillar of the well architected framework,

46
00:03:34,314 --> 00:03:38,030
there is a segment that talks about failure injection

47
00:03:38,930 --> 00:03:42,714
run tests that inject failures regularly

48
00:03:42,842 --> 00:03:45,950
into preproduction and production environments,

49
00:03:46,470 --> 00:03:49,874
and this comes as a recommendation from our many years of

50
00:03:49,912 --> 00:03:50,500
experience.

51
00:03:53,910 --> 00:03:57,714
This practice of using fault injection to test your

52
00:03:57,752 --> 00:04:02,150
environments is better known as chaos engineering.

53
00:04:04,920 --> 00:04:08,420
Chaos engineering is the process

54
00:04:08,570 --> 00:04:12,244
of stressing an application by creating disruptive

55
00:04:12,292 --> 00:04:16,036
events, observing how the system responds,

56
00:04:16,148 --> 00:04:18,200
and implementing improvements.

57
00:04:24,040 --> 00:04:27,200
And we do this to prove or disprove

58
00:04:27,280 --> 00:04:30,584
our assumptions about our system's capability to

59
00:04:30,622 --> 00:04:34,632
handle these disruptive events. But rather than let those

60
00:04:34,686 --> 00:04:38,724
disruptive events happen at odd

61
00:04:38,772 --> 00:04:42,296
times during a weekend or in the production environment,

62
00:04:42,408 --> 00:04:45,692
we create them in a controlled environment and

63
00:04:45,746 --> 00:04:47,230
during the working hours.

64
00:04:50,640 --> 00:04:54,284
It is also very important to understand that chaos

65
00:04:54,332 --> 00:04:58,400
engineering is not about breaking things randomly without purpose.

66
00:04:58,980 --> 00:05:02,220
It is about breaking things in a controlled environment

67
00:05:02,300 --> 00:05:05,864
through well planned experiments. In order to build confidence

68
00:05:05,932 --> 00:05:09,792
in your application and tools you are using to withstand

69
00:05:09,936 --> 00:05:11,700
turbulent conditions,

70
00:05:13,480 --> 00:05:16,992
let's discuss different phases of chaos engineering.

71
00:05:17,136 --> 00:05:24,562
First. Steady state steady

72
00:05:24,626 --> 00:05:28,166
state this phase involves an understanding of the

73
00:05:28,188 --> 00:05:31,554
behavior and configuration of the system under normal

74
00:05:31,602 --> 00:05:35,034
conditions. By defining your steady state,

75
00:05:35,152 --> 00:05:38,314
you can detect deviations from that state and

76
00:05:38,352 --> 00:05:42,330
determine if your system chaos fully returned to the known good

77
00:05:42,400 --> 00:05:46,554
state. Next phase

78
00:05:46,602 --> 00:05:50,318
is hypothesis. After you understand

79
00:05:50,404 --> 00:05:53,914
the steady state behavior, you can write a hypothesis

80
00:05:53,962 --> 00:05:57,422
about it. It can be challenging to decide what should

81
00:05:57,476 --> 00:06:01,522
happen. Chaos engineering recommends that you choose real

82
00:06:01,576 --> 00:06:04,882
world events that are likely to occur and that

83
00:06:04,936 --> 00:06:06,900
will impact the user experience.

84
00:06:10,740 --> 00:06:13,860
Next stage is run experiment.

85
00:06:14,600 --> 00:06:18,004
You don't need to run experiments in production right away.

86
00:06:18,202 --> 00:06:22,020
A great place is to get started with chaos engineering

87
00:06:22,440 --> 00:06:26,884
in a staging environment. By running experiments in staging,

88
00:06:27,012 --> 00:06:31,412
you can see how your system will likely react in production

89
00:06:31,556 --> 00:06:34,440
while earning trust within your organization.

90
00:06:34,940 --> 00:06:38,696
And as you gain confidence, you can begin running experiments

91
00:06:38,728 --> 00:06:39,820
in production.

92
00:06:42,890 --> 00:06:46,902
The next phase is verify. This step

93
00:06:46,956 --> 00:06:50,822
is to analyze and document the data to understand what

94
00:06:50,876 --> 00:06:54,102
happened. Lessons learned during the experiment

95
00:06:54,166 --> 00:06:57,500
are critical and should promote a culture of support.

96
00:06:58,350 --> 00:07:01,340
Here are some questions that you can address.

97
00:07:01,870 --> 00:07:05,434
What happened? What was the impact

98
00:07:05,482 --> 00:07:09,326
on your customers? What did we learn? Did we

99
00:07:09,348 --> 00:07:13,034
have enough information in the notification to investigate

100
00:07:13,082 --> 00:07:16,846
further? What could have reduced our time to detect

101
00:07:16,958 --> 00:07:19,620
or time to remediate by 50%?

102
00:07:20,790 --> 00:07:23,726
Can we apply this to other similar systems?

103
00:07:23,838 --> 00:07:27,490
And how can we improve our incident response processes?

104
00:07:30,690 --> 00:07:34,382
And finally, learning from your experiments in

105
00:07:34,436 --> 00:07:38,702
order to improve the system improvements such as its

106
00:07:38,756 --> 00:07:41,978
resilience to failure, its performance,

107
00:07:42,154 --> 00:07:45,118
the monitoring, the alarms, the operations,

108
00:07:45,214 --> 00:07:46,740
and the overall system,

109
00:07:51,980 --> 00:07:56,420
and to help create and run these chaos engineering experiments,

110
00:07:56,500 --> 00:07:59,900
we can use AWS fault injection simulator

111
00:08:01,280 --> 00:08:04,760
it's a fully managed service for running fault injection

112
00:08:04,840 --> 00:08:08,732
experiments on AWS that makes it easier to

113
00:08:08,786 --> 00:08:12,044
improve an application's performance, observability,

114
00:08:12,172 --> 00:08:13,440
and resilience.

115
00:08:18,400 --> 00:08:22,120
AWS fault injection simulator, or FIS,

116
00:08:22,280 --> 00:08:26,296
is a fully managed chaos engineering service designed

117
00:08:26,328 --> 00:08:29,824
to be easy to get started and to allow you to

118
00:08:29,862 --> 00:08:33,020
test your systems against real world failures.

119
00:08:33,180 --> 00:08:36,556
Whether they are simple, such as stopping an instance,

120
00:08:36,668 --> 00:08:40,160
or more complex. It fully embraces

121
00:08:40,240 --> 00:08:43,764
the idea of safeguards, which is a way to monitor the

122
00:08:43,802 --> 00:08:47,412
blast radius of the experiment and stop if

123
00:08:47,466 --> 00:08:49,830
certain alarms are set off.

124
00:08:54,830 --> 00:08:58,614
We have four main components that are part of fault injection

125
00:08:58,662 --> 00:09:02,442
simulator. An action is the

126
00:09:02,496 --> 00:09:06,230
fault injection activity that you run on targets

127
00:09:06,310 --> 00:09:10,350
using fault injection simulator. A target

128
00:09:11,810 --> 00:09:15,082
can be a specific resource in your AWS environment,

129
00:09:15,226 --> 00:09:18,666
or one or more resources that match criteria

130
00:09:18,698 --> 00:09:22,130
that you specify. For example, resources that have

131
00:09:22,200 --> 00:09:26,222
specific tags an experiment template

132
00:09:26,366 --> 00:09:29,394
that contains one or more actions to run on

133
00:09:29,432 --> 00:09:32,822
specified targets during an experiment. It also

134
00:09:32,876 --> 00:09:36,422
contains the stop conditions that prevent the experiment from

135
00:09:36,476 --> 00:09:38,070
going out of bonds.

136
00:09:40,090 --> 00:09:43,110
And after you create an experiment template,

137
00:09:45,710 --> 00:09:48,582
you can use it to start an experiment.

138
00:09:48,726 --> 00:09:52,426
And you can use a single experiment template to create and

139
00:09:52,448 --> 00:09:56,410
run in multiple environments and multiple experiments.

140
00:10:00,960 --> 00:10:02,800
Let's take our scenario.

141
00:10:05,060 --> 00:10:08,844
Let's say we have an application and management

142
00:10:08,892 --> 00:10:12,130
has decided that our in house built application,

143
00:10:13,000 --> 00:10:16,832
until now used to share messages within our organization,

144
00:10:16,976 --> 00:10:20,196
should be made public. The application

145
00:10:20,298 --> 00:10:23,604
chaos so far had limited use or downtime or

146
00:10:23,642 --> 00:10:27,064
any disruptions, so the fact that it

147
00:10:27,102 --> 00:10:30,712
hasn't been built using best practices was

148
00:10:30,766 --> 00:10:34,772
never an issue. But this new decision

149
00:10:34,836 --> 00:10:38,456
means that all of that will change. Our mission

150
00:10:38,488 --> 00:10:42,670
is to create chaos. Engineering experiments stress the application,

151
00:10:43,120 --> 00:10:46,408
simulate disruptive events, and observe

152
00:10:46,504 --> 00:10:50,152
how the system responds. Then we can make

153
00:10:50,226 --> 00:10:54,108
improvements to the application and test how those improvements

154
00:10:54,204 --> 00:10:56,960
affect the application and the users.

155
00:10:58,980 --> 00:11:02,616
To start with, our application consists

156
00:11:02,748 --> 00:11:06,708
of one single Amazon EC two instance and one

157
00:11:06,794 --> 00:11:10,496
Amazon RDS instance running in one availability

158
00:11:10,608 --> 00:11:14,260
zone. They are the fronted by

159
00:11:14,410 --> 00:11:18,152
an application load balancer. Even with

160
00:11:18,206 --> 00:11:21,384
only a single Amazon EC two instance, it is

161
00:11:21,422 --> 00:11:25,240
still useful to include an application load balancer.

162
00:11:25,740 --> 00:11:30,220
This lets you configure health checks performed against the EC two instance.

163
00:11:30,560 --> 00:11:34,392
It also makes it easier to add more easy to instances

164
00:11:34,456 --> 00:11:38,216
later. The Amazon EC

165
00:11:38,248 --> 00:11:41,740
two autoscaling group helps improve resiliency.

166
00:11:41,900 --> 00:11:45,296
If the EC two instance fails its health check,

167
00:11:45,398 --> 00:11:49,056
the Amazon EC two auto scaling group will replace it.

168
00:11:49,238 --> 00:11:52,572
Based on this architecture, we can now create chaos

169
00:11:52,636 --> 00:11:56,560
engineering experiments to test how the application handles

170
00:11:56,640 --> 00:11:58,340
disruptive events.

171
00:12:05,300 --> 00:12:08,832
Given that our applications is running on only

172
00:12:08,886 --> 00:12:12,736
one instance, we are relying heavily on that instance.

173
00:12:12,928 --> 00:12:16,180
All requests are handled by that single

174
00:12:16,250 --> 00:12:20,032
instance. What if our single instance is stopped

175
00:12:20,096 --> 00:12:21,590
and then started again?

176
00:12:24,060 --> 00:12:27,864
So our hypothesis is if our only instance is

177
00:12:27,902 --> 00:12:31,240
stopped and started again, the application will stop

178
00:12:31,310 --> 00:12:34,810
accepting request, but quickly recover again.

179
00:12:37,360 --> 00:12:43,004
The action is stop and start instance and

180
00:12:43,042 --> 00:12:45,500
the target is single instance.

181
00:12:46,720 --> 00:12:50,144
Note that this experiment will cause an application to

182
00:12:50,182 --> 00:12:53,648
stop serving request. It is advised to not perform

183
00:12:53,734 --> 00:12:57,232
experiments where we know that the outcome will cause

184
00:12:57,286 --> 00:13:01,104
an outage, but this is in a non production

185
00:13:01,152 --> 00:13:04,192
environment and to test a specific scenario.

186
00:13:04,336 --> 00:13:07,968
Next, let's learn how to run experiments

187
00:13:08,064 --> 00:13:11,300
in AWS fault injection simulator.

188
00:13:11,960 --> 00:13:15,290
Navigate to AWS console and open

189
00:13:15,660 --> 00:13:19,112
AWS FIS service. Click on

190
00:13:19,166 --> 00:13:27,166
Create experiment template and

191
00:13:27,188 --> 00:13:30,740
then we create a new experiment template. Here,

192
00:13:31,670 --> 00:13:35,570
let's add a description for us. It is stop single

193
00:13:35,640 --> 00:13:39,140
instance, enter a name,

194
00:13:45,070 --> 00:13:46,990
select an IM role.

195
00:13:51,270 --> 00:13:53,810
Next we need to add an action.

196
00:13:55,350 --> 00:13:59,986
Click on add an action new action give

197
00:14:00,008 --> 00:14:03,670
it a name. Here it is

198
00:14:03,740 --> 00:14:05,270
stop one instance,

199
00:14:07,930 --> 00:14:11,782
select action type which is EC two

200
00:14:11,836 --> 00:14:12,950
stop instance,

201
00:14:14,910 --> 00:14:26,014
then action parameter and

202
00:14:26,052 --> 00:14:29,438
then add a target. We are

203
00:14:29,444 --> 00:14:30,960
going to edit it here,

204
00:14:35,800 --> 00:14:43,252
give it a name and

205
00:14:43,306 --> 00:14:46,724
select the resource id. This is the

206
00:14:46,762 --> 00:14:51,476
EC two instance that we have and

207
00:14:51,498 --> 00:14:55,050
it's currently in running state. So we'll add it and save.

208
00:14:57,740 --> 00:15:01,944
Next we'll click

209
00:15:01,982 --> 00:15:05,624
on create experiment template and give a confirmation that

210
00:15:05,662 --> 00:15:07,150
we want to create it.

211
00:15:10,190 --> 00:15:12,970
Next we'll go and start this experiment.

212
00:15:16,380 --> 00:15:19,992
We again have to confirm that we need to start

213
00:15:20,126 --> 00:15:23,420
the experiment and if you see the state

214
00:15:23,490 --> 00:15:25,310
is initiating right now,

215
00:15:28,160 --> 00:15:30,190
the experiment is running now.

216
00:15:32,800 --> 00:15:34,750
Now if you go back to the website,

217
00:15:36,660 --> 00:15:40,640
the EC two instance is stopping right now and it has been stopped.

218
00:15:42,260 --> 00:15:45,440
If you go to the website now, you won't be able to access

219
00:15:45,510 --> 00:15:49,540
it and the experiment has been completed

220
00:15:52,580 --> 00:15:56,636
now after a few minutes you'll

221
00:15:56,668 --> 00:16:01,844
see again that it has automatically started running and

222
00:16:01,882 --> 00:16:04,964
if you go back to the website and

223
00:16:05,002 --> 00:16:08,470
refresh the page, the application is up and running again.

224
00:16:10,600 --> 00:16:13,848
So this is how you can run an experiment in

225
00:16:13,934 --> 00:16:15,720
AWS FIS.

226
00:16:18,700 --> 00:16:22,292
After running the first experiment on single EC two instance

227
00:16:22,356 --> 00:16:26,188
architecture, we collect that we don't have any alarms in place

228
00:16:26,274 --> 00:16:29,452
that tells us if the application is responding to

229
00:16:29,506 --> 00:16:33,116
requests or not and responding as it

230
00:16:33,138 --> 00:16:35,996
should. Simply put,

231
00:16:36,178 --> 00:16:38,690
if the application works or not.

232
00:16:44,080 --> 00:16:47,976
So by adding a cloud watch synthetic canary,

233
00:16:48,088 --> 00:16:52,296
we can check that the application responds. After the improvements,

234
00:16:52,408 --> 00:16:56,524
we have new metrics and new alarm in place to help us monitor

235
00:16:56,572 --> 00:16:59,360
the application and detect failures.

236
00:17:03,630 --> 00:17:07,574
After running our first experiments on single EC two instance

237
00:17:07,622 --> 00:17:11,150
architecture, we can clearly see that having a single

238
00:17:11,220 --> 00:17:15,002
instance is a liability for the resilience and reliability

239
00:17:15,066 --> 00:17:19,166
of that application. Having a single instance means

240
00:17:19,348 --> 00:17:23,070
if the instance fails, then it cannot operate

241
00:17:23,150 --> 00:17:25,540
and our users will have a bad time.

242
00:17:29,390 --> 00:17:31,500
So what do we do?

243
00:17:32,030 --> 00:17:36,070
We add multiple instances again.

244
00:17:36,160 --> 00:17:40,266
After the improvements, our application now uses multiple EC

245
00:17:40,298 --> 00:17:44,030
two instances to help withstand turbulent conditions.

246
00:17:44,370 --> 00:17:48,314
If one EC two instance fails, the application load balancer

247
00:17:48,362 --> 00:17:52,020
will fail over and send traffic to the remaining healthy ones.

248
00:17:54,230 --> 00:17:57,822
Based on the improved architecture, we can now create additional

249
00:17:57,886 --> 00:18:01,654
chaos engineering experiments and test the reliability and

250
00:18:01,692 --> 00:18:03,240
resilience of our application.

251
00:18:08,090 --> 00:18:11,606
With the improvements made, we can now repeat one

252
00:18:11,628 --> 00:18:14,680
of our previous experiments to see the difference.

253
00:18:15,690 --> 00:18:19,206
What if one of the instance in auto

254
00:18:19,238 --> 00:18:22,714
scaling group is stopped? The theory is that if

255
00:18:22,752 --> 00:18:26,450
one EC two instance fails, the application load balancer

256
00:18:26,550 --> 00:18:30,160
will fail over and send traffic to the healthy ones.

257
00:18:30,770 --> 00:18:34,314
So the hypothesis is if one instance

258
00:18:34,362 --> 00:18:37,566
in our auto scaling group is stopped and started again,

259
00:18:37,668 --> 00:18:41,490
the application will continue serving requests to client.

260
00:18:42,230 --> 00:18:45,726
The action is stop and start instance

261
00:18:45,918 --> 00:18:49,774
and target. Now is one instance in auto scaling

262
00:18:49,822 --> 00:18:53,494
group. This is just an

263
00:18:53,532 --> 00:18:57,410
example on how you can write experiments and improvise

264
00:18:57,490 --> 00:19:00,546
to include chaos engineering for your workloads.

265
00:19:00,738 --> 00:19:04,694
You can further continue the journey by distributing the workload to

266
00:19:04,732 --> 00:19:09,110
multiple availability zone, improving RDS availability,

267
00:19:09,530 --> 00:19:13,030
and implementing continuous integration and delivery.

268
00:19:17,850 --> 00:19:21,722
To summarize, today we learnt about AWS

269
00:19:21,786 --> 00:19:24,682
well architected Chaos engineering,

270
00:19:24,826 --> 00:19:28,046
AWS fault injection simulator and how to

271
00:19:28,068 --> 00:19:30,000
write an experiment for it.

272
00:19:31,890 --> 00:19:34,620
Thank you for joining the session. I hope you like.

