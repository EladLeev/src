1
00:01:28,370 --> 00:01:32,226
Hello everyone, I'm Shai Almog. Today we'll talk about debugging

2
00:01:32,258 --> 00:01:35,602
at scale in production, specifically about kubernetes

3
00:01:35,666 --> 00:01:39,650
debugging. I'm assuming everyone here knows the basics of kubernetes,

4
00:01:39,730 --> 00:01:43,454
so so I will dive right into the basic problem description and

5
00:01:43,492 --> 00:01:46,862
then into the three tools I will show today. But first,

6
00:01:46,916 --> 00:01:50,346
a few things about me I was a consultant for over a decade.

7
00:01:50,378 --> 00:01:53,690
I worked at sun, founded a couple of companies, wrote a couple of books,

8
00:01:53,770 --> 00:01:56,802
wrote a lot of open source code, and currently work

9
00:01:56,856 --> 00:02:00,334
as a developer advocate for Lightrun. My email and Twitter

10
00:02:00,382 --> 00:02:04,082
accounts are listed here, so feel free to write to me. I have a

11
00:02:04,136 --> 00:02:08,382
blog that talks about debugging and production issues at talktodeduct

12
00:02:08,446 --> 00:02:12,086
dev. It would be great if you check it out and let me

13
00:02:12,108 --> 00:02:15,366
know what you think. I also have a series of videos on

14
00:02:15,388 --> 00:02:18,418
my Twitter account called 142nd Ducklings

15
00:02:18,514 --> 00:02:22,166
where I teach complex things in 140 seconds.

16
00:02:22,278 --> 00:02:25,866
The current series is based on debugging and it covers a lot of

17
00:02:25,888 --> 00:02:29,690
things most developers don't know and would find helpful.

18
00:02:30,130 --> 00:02:34,442
Containers and orchestrators revolutionized development and production,

19
00:02:34,586 --> 00:02:37,870
no doubt. But in a way, kubernetes made

20
00:02:37,940 --> 00:02:41,854
debugging production issues harder than previously was.

21
00:02:42,052 --> 00:02:45,874
In the past we had physical servers we could just work

22
00:02:45,912 --> 00:02:49,170
with, or even vps. Now we

23
00:02:49,240 --> 00:02:52,930
face much greater difficulty in this age due to those big

24
00:02:53,000 --> 00:02:56,326
challenges. The massive scale enabled by

25
00:02:56,348 --> 00:02:59,910
Kubernetes is a huge boon, but it also

26
00:02:59,980 --> 00:03:02,440
makes debugging remarkably difficult.

27
00:03:02,810 --> 00:03:06,310
We need new tools to deal with those scale.

28
00:03:06,730 --> 00:03:10,086
We now have multiple layers of abstraction

29
00:03:10,198 --> 00:03:14,822
to the deployed where failures can happen in the orchestrators

30
00:03:14,966 --> 00:03:18,646
container or code layers, each failure

31
00:03:18,758 --> 00:03:22,314
requires a different set of skills and solutions.

32
00:03:22,442 --> 00:03:25,674
Tracking the cause to the right layer isn't

33
00:03:25,722 --> 00:03:29,150
necessarily trivial. Finally, there's the

34
00:03:29,220 --> 00:03:33,230
bare bones or lean deployment problem. When debugging,

35
00:03:33,750 --> 00:03:37,538
this is the first problem I want to focus on. We'll get

36
00:03:37,544 --> 00:03:39,380
to the other two soon enough.

37
00:03:40,310 --> 00:03:43,534
It's the problem of those bare naked container.

38
00:03:43,662 --> 00:03:47,734
We can connect to a bare bone container, but we have

39
00:03:47,852 --> 00:03:51,814
nothing to do inside it. Nothing is installed. We can

40
00:03:51,852 --> 00:03:54,482
inspect logs, but that relies on luck.

41
00:03:54,546 --> 00:03:58,266
Furthermore, if your logs are already ingested by a

42
00:03:58,288 --> 00:04:01,734
solution like elastic, you probably don't have anything valuable

43
00:04:01,782 --> 00:04:04,090
to do within a bare bones container.

44
00:04:04,510 --> 00:04:08,698
Kubectl debug solves these problems and can work

45
00:04:08,784 --> 00:04:13,310
even with a crashed container or a bare bones image.

46
00:04:13,730 --> 00:04:17,034
The Kubectl debug command adds ephemeral

47
00:04:17,082 --> 00:04:20,426
containers to a running pod. An ephemeral

48
00:04:20,458 --> 00:04:24,274
container is a temporary element that would vanish once

49
00:04:24,312 --> 00:04:27,982
the pod is destroyed. With it we can inspect

50
00:04:28,126 --> 00:04:32,146
everything that we need in the pod. Most changes we do in it

51
00:04:32,248 --> 00:04:35,862
don't matter, they won't impact the pod after

52
00:04:35,916 --> 00:04:39,586
we're gone. It works with bare bones

53
00:04:39,618 --> 00:04:44,242
container. The way it does this is with a separate image

54
00:04:44,386 --> 00:04:47,538
so we can have an image that includes everything

55
00:04:47,644 --> 00:04:51,114
in it. The container spun from the image is

56
00:04:51,152 --> 00:04:54,726
ephemeral and can include a proper distro

57
00:04:54,918 --> 00:04:59,050
and the set of tools we need. Kubectl debug

58
00:04:59,550 --> 00:05:03,654
was introduced in version 1.23 so if youre

59
00:05:03,702 --> 00:05:07,182
still in an older version you will need to wait for that.

60
00:05:07,316 --> 00:05:11,054
If you use hosted kubernetes you need to check those

61
00:05:11,092 --> 00:05:14,514
version they use. Let's start with

62
00:05:14,552 --> 00:05:18,846
a simple demo. As you can see we have here a few pods.

63
00:05:19,038 --> 00:05:22,354
We're experiencing an issue and would like to

64
00:05:22,392 --> 00:05:26,520
increase the logging level so we can better see what's going on.

65
00:05:27,450 --> 00:05:30,802
I can use exec and log in directly

66
00:05:30,866 --> 00:05:34,642
to the live pod. I log in with proper bash shell.

67
00:05:34,706 --> 00:05:38,510
I'm sure most of you did that in the past as it's

68
00:05:38,530 --> 00:05:42,134
pretty easy here I can just use standard commands

69
00:05:42,182 --> 00:05:46,026
like cat and grep. Check the logging level. This is all

70
00:05:46,048 --> 00:05:50,170
good. We can see the current level is at info.

71
00:05:50,850 --> 00:05:54,654
Unfortunately I don't even have vim if I want

72
00:05:54,692 --> 00:05:58,222
to edit this file now when the

73
00:05:58,276 --> 00:06:01,982
container has apt or APK and

74
00:06:02,036 --> 00:06:05,534
when those pod isn't crashed I could in

75
00:06:05,572 --> 00:06:09,166
theory just apt get install vim, but that's

76
00:06:09,198 --> 00:06:12,626
got its own problems and is a painful process.

77
00:06:12,808 --> 00:06:16,402
We don't want people in production just installing packages

78
00:06:16,466 --> 00:06:20,018
left and right, even if it's cleaned up. The risks

79
00:06:20,114 --> 00:06:23,410
are sometimes tools high pods shouldn't

80
00:06:23,490 --> 00:06:26,690
be touched in production. Once deployed,

81
00:06:26,850 --> 00:06:30,166
all the information and state of a pod

82
00:06:30,278 --> 00:06:34,214
should be described in its manifest, unless it's

83
00:06:34,262 --> 00:06:38,410
strictly a statewall pod, like a database, et cetera.

84
00:06:38,830 --> 00:06:42,510
So installing like this is problematic.

85
00:06:43,250 --> 00:06:46,718
So let's exit for a moment and try connecting again

86
00:06:46,804 --> 00:06:51,482
with Kubectl debug. I'll use the busybox

87
00:06:51,546 --> 00:06:54,770
image in this case and we'll see how that works.

88
00:06:54,920 --> 00:06:58,418
Notice that this is the image referenced in

89
00:06:58,424 --> 00:07:01,934
those Kubectl debug docs. So I'm

90
00:07:01,982 --> 00:07:05,166
connected to the pod again, or so it seems.

91
00:07:05,288 --> 00:07:09,010
Technically I'm connected to a new ephemeral

92
00:07:09,090 --> 00:07:12,150
container and not to the pod directly.

93
00:07:12,490 --> 00:07:15,686
This is an important distinction, but as you

94
00:07:15,708 --> 00:07:19,146
can see again, I don't have Vim or really any of

95
00:07:19,168 --> 00:07:22,198
the tools I would expect like visual, vm,

96
00:07:22,294 --> 00:07:25,626
trace, youre, et cetera. I can fix that. I can

97
00:07:25,648 --> 00:07:29,434
create an image that represents everything I

98
00:07:29,472 --> 00:07:32,826
need and packages all of it all of the tools

99
00:07:32,858 --> 00:07:37,194
I need. Then pass that image to Kubectl debug

100
00:07:37,322 --> 00:07:40,826
and just use these tools. But here's

101
00:07:40,858 --> 00:07:44,786
the thing, I'm not unique. We're all pretty much the

102
00:07:44,808 --> 00:07:48,834
same. We all expect the same thing

103
00:07:48,952 --> 00:07:52,674
in our debugging sessions. And that image I can

104
00:07:52,712 --> 00:07:56,246
use is probably the same image you would use tools,

105
00:07:56,428 --> 00:07:59,510
so why not have one generic image?

106
00:08:00,330 --> 00:08:03,686
This is where koolkits comes in. Coolkits is an

107
00:08:03,708 --> 00:08:07,486
open youre project that includes a set of opinionated,

108
00:08:07,618 --> 00:08:11,850
curated, platform specific tools for Kubectl debug,

109
00:08:12,510 --> 00:08:16,074
so you can have everything you might need

110
00:08:16,272 --> 00:08:19,318
at your fingertips while debugging.

111
00:08:19,494 --> 00:08:22,714
So what does this mean when you use

112
00:08:22,752 --> 00:08:26,394
Kubectl debug to spin up an ephemeral container?

113
00:08:26,522 --> 00:08:29,738
It's built using a coolkit's image.

114
00:08:29,914 --> 00:08:33,470
Currently there are four standard images,

115
00:08:34,050 --> 00:08:37,882
a go image that includes tools such as Delve,

116
00:08:37,946 --> 00:08:41,954
Pprof, Go, Calvis, and many others the

117
00:08:41,992 --> 00:08:45,482
JVM toolkit, which includes tools such as Sdkman,

118
00:08:45,646 --> 00:08:49,494
jmxterm, honest profiler, visual, vm and much

119
00:08:49,532 --> 00:08:52,674
more. The node version includes NVM,

120
00:08:52,722 --> 00:08:55,880
NDB, zero, x, vtop and much more.

121
00:08:56,330 --> 00:09:00,390
And finally the Python version includes pyn,

122
00:09:00,550 --> 00:09:03,980
IPDb, ipython and much more.

123
00:09:04,430 --> 00:09:08,358
But this is just the tip of the iceberg as all the versions

124
00:09:08,454 --> 00:09:12,614
include the many tools you would expect in any proper debugging

125
00:09:12,662 --> 00:09:16,574
session such as Vim htop. Also, we also have

126
00:09:16,612 --> 00:09:20,634
lots of networking tools like traceroute NMaP database

127
00:09:20,682 --> 00:09:23,790
clients for postgres mysql

128
00:09:23,870 --> 00:09:27,220
redis again so much more.

129
00:09:28,310 --> 00:09:31,698
So let's continue from where we left off in

130
00:09:31,704 --> 00:09:35,694
those demo. We can disconnect from the current session and then

131
00:09:35,752 --> 00:09:38,978
spin up a new session with the Koolkits image.

132
00:09:39,074 --> 00:09:42,834
Notice we can also use the shorthand KK

133
00:09:42,882 --> 00:09:46,342
command for many operations which I don't use here,

134
00:09:46,476 --> 00:09:50,374
but you can see the syntax in the Koolkits docs specifically

135
00:09:50,422 --> 00:09:53,594
in this case. Notice I use the JVM version of

136
00:09:53,632 --> 00:09:57,322
coolkits, which I chose because I'm a Java guy.

137
00:09:57,456 --> 00:10:01,610
But if you're using a different environment, you can use what fits

138
00:10:01,690 --> 00:10:05,614
there. In coolkits, pretty much every tool I want

139
00:10:05,652 --> 00:10:09,306
is already pre installed as part of the image by default.

140
00:10:09,418 --> 00:10:13,058
This means we can just connect and everything is already

141
00:10:13,144 --> 00:10:16,706
there. Since were all very similar in our needs.

142
00:10:16,808 --> 00:10:19,940
Koolkits includes the common things most of us

143
00:10:20,390 --> 00:10:24,274
need based on the platform or language. It has

144
00:10:24,312 --> 00:10:27,814
sensible defaults and comes with ubuntu as the

145
00:10:27,852 --> 00:10:31,702
distribution. This is important. You have a

146
00:10:31,756 --> 00:10:35,222
full distribution like would have in a desktop or

147
00:10:35,276 --> 00:10:39,610
in a regular server. This is very helpful for debugging

148
00:10:39,950 --> 00:10:43,418
so you get everything you need even when debugging a

149
00:10:43,424 --> 00:10:47,254
bare bones container. Notice that thanks to Kubectl

150
00:10:47,302 --> 00:10:50,620
Debug, we have full access to the main application,

151
00:10:51,710 --> 00:10:55,550
main application's container, file system and pods process

152
00:10:55,620 --> 00:10:58,782
namespace so we can do everything there

153
00:10:58,916 --> 00:11:02,554
while residing in a more convenient environment

154
00:11:02,682 --> 00:11:05,620
and having our cake and eating it.

155
00:11:06,150 --> 00:11:09,774
So to finish the story from before, I can just use vim

156
00:11:09,822 --> 00:11:13,794
to edit the file and change the logging level to error, which I can

157
00:11:13,832 --> 00:11:17,590
then confirm using cat and grip. I can also do

158
00:11:17,660 --> 00:11:21,234
a lot of other things such as profile using a profiler,

159
00:11:21,282 --> 00:11:24,306
debug using with GDB or JDB.

160
00:11:24,418 --> 00:11:28,050
I can use Jmxterm to perform JMX operations,

161
00:11:28,130 --> 00:11:31,510
which lets you configure the way the JVM behaves in runtime

162
00:11:31,590 --> 00:11:35,370
and pretty much anything I can do with a local machine.

163
00:11:36,190 --> 00:11:39,222
To give you a sense of what Koolkits installs,

164
00:11:39,366 --> 00:11:43,306
this is the list of packages for the JVM clients

165
00:11:43,418 --> 00:11:47,242
and this is bound to grow as you can all submit pull requests

166
00:11:47,306 --> 00:11:50,494
with your favorite packages. This is just those

167
00:11:50,532 --> 00:11:53,870
JVM specific image. The other images contain

168
00:11:54,030 --> 00:11:57,346
similar tools at a similar scale, and you

169
00:11:57,368 --> 00:12:01,890
can get all that thanks to Kubectl, debug and koolkits.

170
00:12:02,550 --> 00:12:06,002
I didn't forget about this slide. How do we debug

171
00:12:06,066 --> 00:12:09,234
issues of massive scale and massive depth?

172
00:12:09,362 --> 00:12:12,806
Instead of talking theory, let's talk about

173
00:12:12,908 --> 00:12:16,774
real world example. What if

174
00:12:16,972 --> 00:12:21,638
what we're tracking seems to be an application debug?

175
00:12:21,814 --> 00:12:25,946
This is a common occurrence for sure. We might not know it

176
00:12:25,968 --> 00:12:29,146
at this stage, but that might be the place we want

177
00:12:29,168 --> 00:12:32,926
to investigate. We can use one of the debuggers in

178
00:12:32,948 --> 00:12:36,782
koolkits to track it, but that would only work if

179
00:12:36,836 --> 00:12:40,430
we know the server where the issue manifests.

180
00:12:40,770 --> 00:12:44,754
It's also remarkably risky. Connecting a debugger to

181
00:12:44,792 --> 00:12:48,420
a production environment can lead to multiple problems,

182
00:12:48,870 --> 00:12:52,180
stopping on a breakpoint by accident using a

183
00:12:52,710 --> 00:12:55,846
conditional statement that grinds the system to a

184
00:12:55,868 --> 00:12:59,138
halt, exposing a security vulnerability.

185
00:12:59,314 --> 00:13:02,818
JDWP itself is literally an open invitation

186
00:13:02,914 --> 00:13:06,194
for hacking. We can try using logs

187
00:13:06,242 --> 00:13:09,914
and probably should start there, but more often than not,

188
00:13:09,952 --> 00:13:12,890
the issue we needed isn't logged.

189
00:13:13,470 --> 00:13:17,030
We can try using various observability tools.

190
00:13:17,110 --> 00:13:21,022
They're great, but not for application level

191
00:13:21,076 --> 00:13:25,002
issues. They rule for big picture analysis

192
00:13:25,066 --> 00:13:28,880
and container level problems, not for application level problems.

193
00:13:29,970 --> 00:13:34,238
We used to call this continuous observability, but developer observability

194
00:13:34,334 --> 00:13:38,014
makes more sense. It's a newer set of tools designed

195
00:13:38,062 --> 00:13:42,494
to solve this exact problem observability is defined

196
00:13:42,542 --> 00:13:45,974
as the ability to understand how your system works on

197
00:13:46,012 --> 00:13:49,826
the inside without chipping new code. The without chipping

198
00:13:49,858 --> 00:13:53,954
new code portion is key, but what's developer

199
00:13:54,002 --> 00:13:57,262
observability? With developer observability,

200
00:13:57,426 --> 00:14:01,162
we don't ship new code either. We can ask questions about

201
00:14:01,216 --> 00:14:04,934
the code. Normal observability works by instrumenting

202
00:14:04,982 --> 00:14:08,166
everything and receiving the information. With developer

203
00:14:08,198 --> 00:14:11,854
observability, we flip that, we ask questions and

204
00:14:11,892 --> 00:14:15,934
then instrument based on those questions. So how does

205
00:14:15,972 --> 00:14:19,806
that work in practice? In practice, we add an agent

206
00:14:19,908 --> 00:14:23,666
to every pod. This lets us debug the source code

207
00:14:23,768 --> 00:14:27,666
directly from the IDE, almost like debugging a

208
00:14:27,688 --> 00:14:31,154
local project. To start,

209
00:14:31,192 --> 00:14:34,594
we need to sign up for a free lightrun account@lightrun.com.

210
00:14:34,632 --> 00:14:37,974
Slash free notice that Lightrun has a very generous free

211
00:14:38,012 --> 00:14:41,718
tier you can use to experiment with the product. Pretty much

212
00:14:41,804 --> 00:14:45,446
everything I show here can be accomplished with a free account.

213
00:14:45,548 --> 00:14:49,386
I'll skip the actual setup since it's covered there and we

214
00:14:49,408 --> 00:14:52,938
don't have much time. You can check out the lightrun

215
00:14:53,024 --> 00:14:56,874
docs for more detailed instructions on setting lightrun in

216
00:14:56,912 --> 00:15:00,694
docker, minikube, etc. Unlike Kubectl debug,

217
00:15:00,822 --> 00:15:04,110
we need to install the agent before the problem

218
00:15:04,180 --> 00:15:07,774
occurs. So if we do run into a problem,

219
00:15:07,972 --> 00:15:11,338
we will be able to skip right in. Let's skip

220
00:15:11,434 --> 00:15:14,594
right ahead to a simplified demo right

221
00:15:14,632 --> 00:15:17,540
in the id once the agent is set up,

222
00:15:18,230 --> 00:15:21,742
this is the prime main app in kotin. It simply

223
00:15:21,806 --> 00:15:25,586
loops over numbers and checks if they are a prime number.

224
00:15:25,688 --> 00:15:29,714
It keeps for ten milliseconds, so it won't completely demolish

225
00:15:29,762 --> 00:15:32,822
the cpu. But other than that, it's a pretty simple

226
00:15:32,876 --> 00:15:36,386
application. It just counts the number of times it finds

227
00:15:36,498 --> 00:15:39,820
along the way and prints the results at the end.

228
00:15:40,190 --> 00:15:43,418
We can use this code we use this code a

229
00:15:43,424 --> 00:15:47,420
lot when debugging, since it's cpu intensive and very simple.

230
00:15:47,950 --> 00:15:52,158
In this case, we would like to observe the variable I,

231
00:15:52,324 --> 00:15:55,706
which is the value we're evaluating here, and print

232
00:15:55,738 --> 00:15:59,534
out CNT, which represents the number of primes we found

233
00:15:59,572 --> 00:16:03,154
so far. The simplest tool we have is the

234
00:16:03,192 --> 00:16:06,914
ability to inject log into the application. We can

235
00:16:06,952 --> 00:16:09,710
also inject a snapshot or add metrics.

236
00:16:09,790 --> 00:16:12,594
I'll discuss all of those soon enough.

237
00:16:12,792 --> 00:16:16,382
Selecting log opens the UI to enter

238
00:16:16,456 --> 00:16:19,990
a new log. I can write more than just text

239
00:16:20,060 --> 00:16:24,006
in the curly braces. I can include any expression I want,

240
00:16:24,108 --> 00:16:28,374
such as the value of the variables that

241
00:16:28,412 --> 00:16:32,006
I included in those expression. I can also invoke methods

242
00:16:32,038 --> 00:16:35,226
and do all that sort of thing. But here's the thing

243
00:16:35,328 --> 00:16:38,694
if I invoke a method that's too computationally

244
00:16:38,742 --> 00:16:42,720
intensive, or if I invoke a method that changes the application state,

245
00:16:43,250 --> 00:16:46,750
the log won't be added. I'll get an error.

246
00:16:47,330 --> 00:16:51,166
After clicking OK, we see the log appearing above the

247
00:16:51,188 --> 00:16:54,606
line in the ide. Notice that this is behavior specific to

248
00:16:54,628 --> 00:16:57,714
intellij or jetbrain's ides. In visual studio code,

249
00:16:57,752 --> 00:17:00,866
it will show a marker on the side. Once the

250
00:17:00,888 --> 00:17:05,006
log is hit, we'll see logs appear in batches.

251
00:17:05,118 --> 00:17:08,782
Notice I chose to pipe logs to the id for convenience,

252
00:17:08,926 --> 00:17:12,262
but there's more I can do with them. For now, the thing

253
00:17:12,316 --> 00:17:15,526
I want to focus on is the last line. Notice that the

254
00:17:15,548 --> 00:17:19,514
log point is paused due to high core rate. This means

255
00:17:19,632 --> 00:17:23,674
the additional logs won't show for a short period of time.

256
00:17:23,792 --> 00:17:27,814
Since logging needed threshold of cpu usage,

257
00:17:27,942 --> 00:17:32,270
this can happen quickly or slowly depending on how you're observing.

258
00:17:32,610 --> 00:17:36,138
Let's move on to a different demo. This is the node

259
00:17:36,154 --> 00:17:40,074
JS project that implements the initial backend of a microservice

260
00:17:40,122 --> 00:17:43,666
architecture. This is the method that gets invoked when we

261
00:17:43,688 --> 00:17:46,770
click a movie and want to see the details.

262
00:17:47,270 --> 00:17:50,974
This time I'll add a snapshot. Some other developer

263
00:17:51,022 --> 00:17:54,654
observability tools call this a capture or a nonbreaking

264
00:17:54,702 --> 00:17:58,614
breakpoint, which to me sounds weird built. The idea is usually the

265
00:17:58,652 --> 00:18:02,374
same. Once I press ok, the camera button appears on

266
00:18:02,412 --> 00:18:06,422
the left, indicating the location of the snapshot like you would see

267
00:18:06,476 --> 00:18:10,282
with a regular ide breakpoint. Now I'll just

268
00:18:10,336 --> 00:18:13,466
access the production in

269
00:18:13,488 --> 00:18:17,274
the front end that triggers this code. And now

270
00:18:17,392 --> 00:18:20,298
we wait a second and the snapshot is hit.

271
00:18:20,464 --> 00:18:24,174
So what is the snapshot? It gives us a

272
00:18:24,212 --> 00:18:27,646
stack twice and variables, just like a regular breakpoint we

273
00:18:27,668 --> 00:18:30,974
all know and love. But it doesn't stop at

274
00:18:31,012 --> 00:18:34,674
that point, so your server won't be stuck waiting for

275
00:18:34,712 --> 00:18:38,674
a step over. Now obviously youre can't step

276
00:18:38,792 --> 00:18:42,830
over the code, so you need to step by individual snapshots.

277
00:18:42,990 --> 00:18:47,570
But this is a huge benefit, especially in production scenarios.

278
00:18:47,730 --> 00:18:51,926
But it lets much better this was

279
00:18:52,108 --> 00:18:55,366
relatively simple in terms of observability. Let's up the

280
00:18:55,388 --> 00:18:59,174
ante a bit and talk about user specific problems. So here

281
00:18:59,212 --> 00:19:02,842
I have a problem with those request one specific user is

282
00:19:02,896 --> 00:19:06,794
remaining that the list on his machine doesn't match the

283
00:19:06,832 --> 00:19:10,538
list for his peers. The problem is that if I put a

284
00:19:10,544 --> 00:19:14,906
snapshot I'll get a lot of noise because there are many users

285
00:19:15,018 --> 00:19:18,734
reloading all at the same time. So a solution to

286
00:19:18,772 --> 00:19:22,506
this is to use conditional snapshots just like youre

287
00:19:22,548 --> 00:19:25,874
can with a regular debugger. Notice that you can

288
00:19:25,912 --> 00:19:29,326
define a condition for a log and for metrics

289
00:19:29,358 --> 00:19:32,594
as well. This is one of those key features of

290
00:19:32,632 --> 00:19:36,974
continuous observability. I add a new snapshot

291
00:19:37,022 --> 00:19:40,566
and in it I have an option to define quite a lot of things.

292
00:19:40,668 --> 00:19:44,226
I won't even discuss the advanced version of this dialogue

293
00:19:44,258 --> 00:19:47,554
in this session. This is a really trivial

294
00:19:47,602 --> 00:19:51,706
condition. We already have a simple security utility class that

295
00:19:51,728 --> 00:19:55,498
I can use to query the current user ID, so I

296
00:19:55,584 --> 00:19:59,238
just make use of that and compare the response

297
00:19:59,334 --> 00:20:02,958
to the ID of the user that's experiencing a problem.

298
00:20:03,124 --> 00:20:06,814
Notice I use the fully qualified name of the class.

299
00:20:06,932 --> 00:20:10,506
I could have just written security and it's

300
00:20:10,538 --> 00:20:14,118
very possible that it would have worked, but it isn't

301
00:20:14,154 --> 00:20:17,986
guaranteed names can clash on those agent and

302
00:20:18,008 --> 00:20:22,034
the agent slides isn't were of things we have in the IDE. As such,

303
00:20:22,072 --> 00:20:26,174
it's often good practice to be more specific. After pressing

304
00:20:26,222 --> 00:20:29,606
ok we see a special version of the snapshot icon with

305
00:20:29,628 --> 00:20:33,126
a question mark on it. This indicates that this action has

306
00:20:33,148 --> 00:20:36,966
a condition on it. Now it's just a waiting game for the

307
00:20:36,988 --> 00:20:40,538
user to hit the snapshot. This is the point were

308
00:20:40,624 --> 00:20:44,602
normally you go make yourself a cup of coffee or just go home

309
00:20:44,736 --> 00:20:48,106
and check this out the next day. That's the beauty of

310
00:20:48,128 --> 00:20:51,478
this sort of instrumentation. In this case, I won't

311
00:20:51,494 --> 00:20:54,686
make you wait long. The snapshot gets hit by the

312
00:20:54,708 --> 00:20:58,238
right user despite other users coming in. This specific

313
00:20:58,324 --> 00:21:01,550
request is from the right user id. We can now review

314
00:21:01,620 --> 00:21:05,090
the stack information and fix the user specific bug.

315
00:21:05,830 --> 00:21:08,766
The next thing I want to talk about is metrics.

316
00:21:08,878 --> 00:21:12,290
Apms give us large scale performance information,

317
00:21:12,440 --> 00:21:15,054
but they don't tell us fine grained details.

318
00:21:15,182 --> 00:21:19,014
Here we can count the number of times a line of code was

319
00:21:19,052 --> 00:21:22,402
reached using a cluster. We can even use a configuration

320
00:21:22,466 --> 00:21:25,686
to qualify that, so we can do something like count the number

321
00:21:25,708 --> 00:21:29,090
of times a specific user reached that line of code.

322
00:21:29,260 --> 00:21:32,954
We also have a method duration, which tells us how long

323
00:21:32,992 --> 00:21:35,370
a method took to execute.

324
00:21:35,790 --> 00:21:39,558
We can even measure the time it takes to perform a code block

325
00:21:39,654 --> 00:21:43,514
using a TikTok. That lets us narrow down the performance

326
00:21:43,562 --> 00:21:47,626
impact of a larger method to a specific problematic segment.

327
00:21:47,738 --> 00:21:52,330
In this case, I'll just use the method. Duration measurements

328
00:21:52,410 --> 00:21:55,714
typically have a name under which we can pipe them or

329
00:21:55,752 --> 00:21:59,314
log them. So I'll just give this method duration a

330
00:21:59,352 --> 00:22:03,614
clear name. In this case I'm just printing it out to the console.

331
00:22:03,742 --> 00:22:07,206
But all these measurements can be piped to stacksd and

332
00:22:07,228 --> 00:22:10,902
Prometheus. I'm a pretty

333
00:22:10,956 --> 00:22:14,406
awful DevOps so I really don't want to demo that

334
00:22:14,508 --> 00:22:18,074
in this case, but it does work if youre know how to use

335
00:22:18,112 --> 00:22:21,622
these tools. As you can see, the duration

336
00:22:21,686 --> 00:22:25,114
information is now piped into the logs and provides us

337
00:22:25,232 --> 00:22:28,474
with some information on the current performance of the

338
00:22:28,512 --> 00:22:31,680
method. The last thing I want to talk about

339
00:22:32,370 --> 00:22:36,202
brings this all together and that's tags.

340
00:22:36,346 --> 00:22:40,554
We can define tags to group agents together, such as production

341
00:22:40,682 --> 00:22:43,502
green, blue, ubuntu, et cetera.

342
00:22:43,646 --> 00:22:46,690
Every pod can be a part of multiple tags.

343
00:22:47,510 --> 00:22:51,022
Every action we discuss today can be applied to a tag

344
00:22:51,166 --> 00:22:55,274
and as such can run on multiple machines simultaneously

345
00:22:55,342 --> 00:22:59,222
and asynchronously. This solves the scale problem

346
00:22:59,356 --> 00:23:03,286
when debugging. So in closing, I'd like to

347
00:23:03,308 --> 00:23:05,960
review some of the things we discussed today.

348
00:23:07,710 --> 00:23:11,130
Kubectl debug made debugging

349
00:23:11,470 --> 00:23:14,906
crashed pods possible it also made it possible to

350
00:23:14,928 --> 00:23:18,342
debug a pod based on a bare bones image.

351
00:23:18,486 --> 00:23:22,414
Koolkits made Kubectl debug easier to use with

352
00:23:22,452 --> 00:23:25,582
preinstalled tools. Lightrun made

353
00:23:25,636 --> 00:23:29,402
keeps secure, readonly real time debugging at scale

354
00:23:29,546 --> 00:23:32,670
easy thanks for bearing with me.

355
00:23:32,740 --> 00:23:36,254
I hope you enjoyed the presentation. Please feel free to

356
00:23:36,292 --> 00:23:39,694
ask any questions and also feel free to write to me.

357
00:23:39,892 --> 00:23:43,406
Also, please check out talktodeduct dev where I talk

358
00:23:43,428 --> 00:23:46,918
about debugging in depth. And check out lightrun.com,

359
00:23:47,004 --> 00:23:50,726
which I think you guys will like a lot. If you

360
00:23:50,748 --> 00:23:54,486
have any questions, my email is listed were and I'll be

361
00:23:54,508 --> 00:23:56,180
happy to help. Thanks for watching.

