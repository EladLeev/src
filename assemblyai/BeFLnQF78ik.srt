1
00:00:25,650 --> 00:00:29,286
Concurrency primitives of Golang, when to and when not

2
00:00:29,308 --> 00:00:32,454
to use some of them. Over the years I've seen a lot of code being

3
00:00:32,492 --> 00:00:35,654
refactored every time there's a marginal change in

4
00:00:35,692 --> 00:00:39,394
complexity because of some concurrency primitive, and I really wish

5
00:00:39,442 --> 00:00:43,000
I knew some of these things which I probably will talk about.

6
00:00:43,370 --> 00:00:46,934
And that could actually save a lot of channels and

7
00:00:46,972 --> 00:00:50,302
a lot of toil just having to go about refactoring this

8
00:00:50,476 --> 00:00:53,710
while speaking with concurrency. One of the important things to discuss

9
00:00:53,780 --> 00:00:57,262
is what exactly is a race? A data

10
00:00:57,316 --> 00:01:01,034
race? To be fairly honest, the most common definition

11
00:01:01,082 --> 00:01:05,086
that comes to the mind is reading and writing to a same memory

12
00:01:05,118 --> 00:01:09,166
location. But before we get to that, there's an important concept

13
00:01:09,198 --> 00:01:12,126
that needs to be covered, which is memory ordering.

14
00:01:12,318 --> 00:01:15,490
I'll probably show a small snippet of a code and

15
00:01:15,560 --> 00:01:18,290
I want you to guess what the output would be.

16
00:01:18,440 --> 00:01:21,654
Here's a simple piece of code. There's a declaration of VAR a

17
00:01:21,692 --> 00:01:25,074
and b which is type int. There's a function f assigns

18
00:01:25,122 --> 00:01:28,362
a equal to one, b equal to two. There's a function g which does

19
00:01:28,416 --> 00:01:32,074
print b and print a. You can

20
00:01:32,112 --> 00:01:35,194
ignore the fact that there will be a data race in here,

21
00:01:35,392 --> 00:01:39,260
because the interesting bit is it is possible

22
00:01:39,630 --> 00:01:43,360
that g prints two first and then zero.

23
00:01:43,810 --> 00:01:47,418
Pay slight attention to this. What is the possibility

24
00:01:47,514 --> 00:01:51,802
when it prints two and zero when print b observed

25
00:01:51,866 --> 00:01:55,262
the value of b as two, whereas the print

26
00:01:55,326 --> 00:01:59,538
a which happens after print b did not yet

27
00:01:59,624 --> 00:02:03,618
observe the value of a equal to one which was

28
00:02:03,784 --> 00:02:06,806
executed before b equal to two.

29
00:02:06,988 --> 00:02:11,254
Why does this happen? It is because compilers at

30
00:02:11,292 --> 00:02:14,790
the time of compilation or at runtime may

31
00:02:14,860 --> 00:02:18,118
do perform instruction ordering change.

32
00:02:18,284 --> 00:02:21,754
So it's not guaranteed that what you see as a equal to one

33
00:02:21,792 --> 00:02:25,338
and b equal to two outside of the block outside of

34
00:02:25,344 --> 00:02:28,934
these scope of that function would be observed in the same manner

35
00:02:29,062 --> 00:02:32,586
and things is a memory ordering problem. And this results

36
00:02:32,618 --> 00:02:36,042
int everything else where we need to now start serializing,

37
00:02:36,186 --> 00:02:40,510
because what we're trying to do is we are solving this unpredictability.

38
00:02:40,930 --> 00:02:44,506
Here's a sample piece of code. It's a pseudocode

39
00:02:44,698 --> 00:02:48,194
to comes it may look like Python, to others it may look like go.

40
00:02:48,392 --> 00:02:52,146
We have a bunch of URLs. There is an

41
00:02:52,168 --> 00:02:55,790
array of responses where we will gather all the responses that

42
00:02:55,800 --> 00:02:59,622
we get by fetching the URLs. There's a small counter of total

43
00:02:59,676 --> 00:03:03,330
bytes received. Simply put, for I in URLs,

44
00:03:03,410 --> 00:03:07,554
fetch the URL using a pool. So we're trying to restrict

45
00:03:07,602 --> 00:03:10,950
the number of parallel connections that can be made outbound.

46
00:03:11,110 --> 00:03:15,222
Once we receive the data. We want to write it to a response array

47
00:03:15,366 --> 00:03:19,306
and also update total bytes received. The control

48
00:03:19,408 --> 00:03:22,842
must block until all the URLs are fetched

49
00:03:22,906 --> 00:03:26,142
and return the response altogether. The total

50
00:03:26,196 --> 00:03:29,422
bytes received are also being sent by telemetry, but that is not

51
00:03:29,476 --> 00:03:32,946
relevant. There are four aspects of

52
00:03:33,048 --> 00:03:36,818
concurrency control which are happening here.

53
00:03:36,984 --> 00:03:41,090
First is the handoff. The handoff is once

54
00:03:41,160 --> 00:03:45,234
these parallelism is done, or I'm liberally using

55
00:03:45,272 --> 00:03:49,126
the word parallel here because that's confusingly used, parallel and

56
00:03:49,148 --> 00:03:52,982
concurrent. Once that is done, the control must pass

57
00:03:53,036 --> 00:03:56,438
on to the main routine, and that's a handoff. So somebody

58
00:03:56,524 --> 00:04:00,518
has to wait to see if all the workers

59
00:04:00,694 --> 00:04:04,346
are done working on what they have done, and only then it must

60
00:04:04,368 --> 00:04:08,250
proceed forward. There's a concept of data sharing here.

61
00:04:08,400 --> 00:04:11,646
Each of the fetch URLs we want to do in a

62
00:04:11,668 --> 00:04:15,550
non blocking manner, which should be able to send

63
00:04:15,620 --> 00:04:18,986
data to be returned to a response array.

64
00:04:19,178 --> 00:04:22,526
There's a serialization happening as well because we do

65
00:04:22,548 --> 00:04:25,938
not want all the URLs to be executed together.

66
00:04:26,104 --> 00:04:30,020
There is a control mechanism which will allow only

67
00:04:30,390 --> 00:04:33,826
certain number of URLs to be hit, and that's these property of

68
00:04:33,848 --> 00:04:37,830
a pool. Then there's also a data consistency problem here because

69
00:04:37,980 --> 00:04:41,462
we want to channel the total bytes received, but because

70
00:04:41,516 --> 00:04:45,394
there are multiple threads that may be performing this, multiple go routines

71
00:04:45,442 --> 00:04:49,306
that may be performing this, multiple processes that may be performing this. Based on the

72
00:04:49,328 --> 00:04:53,366
language implementation, the value of total bytes received

73
00:04:53,478 --> 00:04:57,542
must increase collectively. That's a data concurrency

74
00:04:57,606 --> 00:05:01,786
part as well. So to highlight these again, what are the four challenges?

75
00:05:01,898 --> 00:05:05,166
A control handoff which is passing on

76
00:05:05,348 --> 00:05:09,818
the work, the control from a set of workers

77
00:05:09,994 --> 00:05:13,522
routines to the main serialization. We want

78
00:05:13,576 --> 00:05:17,086
the ability to control what gets executed

79
00:05:17,118 --> 00:05:20,418
at what point of time and what gets to wait, and a control

80
00:05:20,504 --> 00:05:24,082
to block unblock data sharing work

81
00:05:24,136 --> 00:05:27,986
while may be happening in parallel or in non

82
00:05:28,018 --> 00:05:32,770
blocking asynchronous manner. The data must be receivable

83
00:05:32,850 --> 00:05:36,086
by some other process as well, and data consistency at

84
00:05:36,108 --> 00:05:39,546
all points of time. If we have agreed to increment the

85
00:05:39,568 --> 00:05:42,902
integer, then everybody should see a fresh value of an integer

86
00:05:42,966 --> 00:05:46,410
which is incremented. This is also

87
00:05:46,480 --> 00:05:49,866
a derivative of saying that while multiple processes are coordinating with

88
00:05:49,888 --> 00:05:53,946
each other, they will usually have a consensus problem. To solve

89
00:05:53,978 --> 00:05:57,422
a consensus problem, the control needs

90
00:05:57,476 --> 00:06:00,926
to be offloaded to somebody outside the system.

91
00:06:01,108 --> 00:06:04,850
And this is exactly why we need synchronization primitives.

92
00:06:05,430 --> 00:06:09,490
I'm going to call it a marshall. Not to be confused with Marshall Json.

93
00:06:09,990 --> 00:06:13,602
Like a game marshall. What kind of

94
00:06:13,656 --> 00:06:16,290
marshals exist to achieve this synchronization?

95
00:06:16,450 --> 00:06:19,922
There is a sync weight group. There's a sync mutex,

96
00:06:20,066 --> 00:06:23,458
anatomic channels and lockless data structures.

97
00:06:23,634 --> 00:06:27,174
I'll probably not go into the depths of the definition of

98
00:06:27,212 --> 00:06:30,700
defining what these are, because that is almost pretty much available.

99
00:06:31,070 --> 00:06:35,050
I want to narrow this down to what semantics can be used

100
00:06:35,120 --> 00:06:38,342
for what aspect of the problem statement which we discussed

101
00:06:38,406 --> 00:06:42,266
just a few slides back over here. Control handoff,

102
00:06:42,298 --> 00:06:45,662
serialization, data sharing, and data consistency. The first

103
00:06:45,716 --> 00:06:49,534
one is a sync weight group. Fairly straightforward. You must have seen

104
00:06:49,572 --> 00:06:53,278
this all over Golang, blogs, et cetera. Pretty straightforward to use,

105
00:06:53,364 --> 00:06:56,706
but what is it used for? It's precisely only and only used

106
00:06:56,728 --> 00:07:00,494
for control handoff. What is it not used for is it's

107
00:07:00,542 --> 00:07:04,206
not used for serialization. What I mean by that is that using weight

108
00:07:04,238 --> 00:07:07,542
groups you are more often than not only and only

109
00:07:07,596 --> 00:07:11,206
just waiting for control. As the name suggests, it's a wait group

110
00:07:11,308 --> 00:07:15,570
to reach the main routine while some other parallel

111
00:07:15,650 --> 00:07:19,458
routines are doing their job. It's not used for data sharing.

112
00:07:19,554 --> 00:07:23,110
There is no way you can share data, and it's not used for data consistency

113
00:07:23,190 --> 00:07:26,794
either. Using things definition I'm going to through

114
00:07:26,832 --> 00:07:30,394
the slides, there'll always be a fun section where we talk about some

115
00:07:30,432 --> 00:07:33,934
fun mistakes. These fun mistakes are usually

116
00:07:34,052 --> 00:07:37,470
things that we would miss out on, and it

117
00:07:37,540 --> 00:07:40,602
gives us an insight on how these things work at the depth.

118
00:07:40,746 --> 00:07:44,206
Now here's a simple program. What is wrong here? To walk

119
00:07:44,228 --> 00:07:47,726
you through the code, there's a funk main which declares a weight

120
00:07:47,758 --> 00:07:51,538
group. There is a for loop zero to 10 weight group add

121
00:07:51,624 --> 00:07:55,138
simple construct. There's a go routine being called where we call hello

122
00:07:55,304 --> 00:07:58,726
inside hello, we do a print and then we just wait.

123
00:07:58,908 --> 00:08:02,978
Classic example of control handoff where we are waiting.

124
00:08:03,154 --> 00:08:06,486
What could possibly go wrong here? What would go

125
00:08:06,508 --> 00:08:09,722
wrong here is that when you run this code,

126
00:08:09,856 --> 00:08:13,366
it runs int this problem of all goroutine are asleep.

127
00:08:13,398 --> 00:08:17,210
It runs into a deadlock problem. But weight group

128
00:08:17,280 --> 00:08:20,842
is supposed to solve a concurrency problem, not create another problem.

129
00:08:20,976 --> 00:08:24,366
And the reason for that is that even concurrency semantics need to

130
00:08:24,388 --> 00:08:27,466
respect the principles of the language. Now what is the principle

131
00:08:27,498 --> 00:08:30,794
of the language? The principle of the language is I'm

132
00:08:30,842 --> 00:08:34,354
passing weight group by value and not as

133
00:08:34,392 --> 00:08:38,082
a reference. So the goroutine see a copy of

134
00:08:38,136 --> 00:08:41,474
that synchronization primitive and they call a

135
00:08:41,512 --> 00:08:44,970
done on that and hence it runs into a deadlocks.

136
00:08:45,150 --> 00:08:49,366
So even the synchronization primitives need

137
00:08:49,548 --> 00:08:52,950
to cater to the principle of the language.

138
00:08:53,290 --> 00:08:56,962
The next one is sync mutex. What is the sync

139
00:08:57,026 --> 00:09:00,386
mutex used for? It's used for serialization

140
00:09:00,578 --> 00:09:03,526
by using mutexes also locks,

141
00:09:03,638 --> 00:09:07,574
we have the ability of controlling which routine should work, which routine

142
00:09:07,622 --> 00:09:11,206
should not work. When I say which, you're not identifying

143
00:09:11,238 --> 00:09:14,702
a routine in particular, but you have the ability to rewrites code.

144
00:09:14,756 --> 00:09:18,506
These only one can get executed while the other is waiting

145
00:09:18,538 --> 00:09:22,282
for a read or a write operation to happen. So things ability to serialize

146
00:09:22,346 --> 00:09:26,382
operations is what you get because that's what locks do effectively.

147
00:09:26,526 --> 00:09:29,010
And it also allows data consistency,

148
00:09:29,430 --> 00:09:32,898
because while inside a lock you can increment a

149
00:09:32,904 --> 00:09:36,386
value, so the other reader cannot read the value. But what

150
00:09:36,408 --> 00:09:40,022
it doesn't do, it doesn't do a control handoff because

151
00:09:40,076 --> 00:09:43,638
it's used as a communication exchange control

152
00:09:43,724 --> 00:09:47,894
mechanism between two processes, and usually not used for a handoff, which is where

153
00:09:48,092 --> 00:09:51,494
a weight group comes into the picture. And it's also not used for data sharing

154
00:09:51,542 --> 00:09:54,940
because there is no construct of it carrying its own data.

155
00:09:55,710 --> 00:09:59,066
What are the fun mistakes around mutexes int?

156
00:09:59,088 --> 00:10:02,750
A simple counter which has an embedded mutex inside it,

157
00:10:02,820 --> 00:10:06,126
a pretty well known construct in Golang int also has an

158
00:10:06,148 --> 00:10:11,374
integer n. There are two methods. There's an add method which

159
00:10:11,412 --> 00:10:15,598
acquires a lock and increments n by the integer pass. There's another

160
00:10:15,684 --> 00:10:19,122
value method which also rewrites a lock and

161
00:10:19,176 --> 00:10:22,514
returns the c n. So effectively there should

162
00:10:22,552 --> 00:10:26,190
not be any race condition here, because we are judiciously using unlocks.

163
00:10:26,350 --> 00:10:30,054
Now what can go wrong here? If I run this code, when I

164
00:10:30,092 --> 00:10:34,082
run this code, I surprisingly actually run into a race condition.

165
00:10:34,226 --> 00:10:37,742
Now why is that? Because we just discussed that even synchronization

166
00:10:37,826 --> 00:10:41,398
primitives need to respect the principles of the language.

167
00:10:41,494 --> 00:10:44,940
So what's happening here? What's happening here is

168
00:10:45,310 --> 00:10:49,114
counter is not a method which has been

169
00:10:49,152 --> 00:10:53,738
bound. Value is not a method which has been bound. Cto the pointer reference.

170
00:10:53,914 --> 00:10:57,722
What that means is that when value is invoked,

171
00:10:57,866 --> 00:11:01,326
the state of the counter is copied and so is the

172
00:11:01,348 --> 00:11:05,006
sync mutex. And while it is getting copied, it tries

173
00:11:05,038 --> 00:11:08,766
to read n because somebody else had still acquired a lock

174
00:11:08,798 --> 00:11:12,722
on that n. Effectively, it doesn't even matter

175
00:11:12,776 --> 00:11:17,080
what you have inside the body of the code just by accessing value,

176
00:11:17,450 --> 00:11:22,870
because the process of calling value invokes

177
00:11:23,450 --> 00:11:27,094
a copy to happen, and by the virtue of that a

178
00:11:27,132 --> 00:11:31,110
read to happen on n, and hence it results in a race condition.

179
00:11:31,270 --> 00:11:35,226
So even if I was to replace that entire body of the

180
00:11:35,248 --> 00:11:38,682
code with a return one, this would be the exact same

181
00:11:38,736 --> 00:11:41,914
race condition. How do we solve this? We just

182
00:11:41,952 --> 00:11:45,262
make sure that we actually use a pass by reference here.

183
00:11:45,316 --> 00:11:49,146
So the counter should be bound, the pointer should be binding,

184
00:11:49,178 --> 00:11:52,586
the value method, not the other way around. It's a fair conclusion

185
00:11:52,618 --> 00:11:56,082
to say that while resolving a consensus problem,

186
00:11:56,216 --> 00:11:59,582
the marshals themselves are not immune to the consensus

187
00:11:59,646 --> 00:12:03,678
problem. They themselves have to adhere. CTo all of these principles,

188
00:12:03,854 --> 00:12:07,334
underneath all these mutexes weight groups is the

189
00:12:07,372 --> 00:12:10,758
third Marshall, which is the bedrock of all synchronization, which is these

190
00:12:10,764 --> 00:12:14,006
sync atomic. Now surprisingly, atomic has very

191
00:12:14,028 --> 00:12:17,490
limited applicability as such directly.

192
00:12:17,570 --> 00:12:21,286
And most of the times we end up using the constructs

193
00:12:21,318 --> 00:12:25,146
on top of this. But it is the underlying construct which

194
00:12:25,168 --> 00:12:28,246
is used behind most of these other primitives,

195
00:12:28,278 --> 00:12:31,342
which are higher order. Now, what is an atomic use for

196
00:12:31,396 --> 00:12:35,326
data consistency? All int, all through, nothing else.

197
00:12:35,508 --> 00:12:38,702
There is a value. I want to atomically change that value,

198
00:12:38,836 --> 00:12:42,382
update an integer and do nothing else.

199
00:12:42,436 --> 00:12:46,470
It is not uses for control handoff. It cannot be used for serialization.

200
00:12:46,570 --> 00:12:50,066
I mean there can be derivatives of it, but by direct virtue of its own

201
00:12:50,088 --> 00:12:53,166
properties, it doesn't do this by primitives.

202
00:12:53,198 --> 00:12:57,026
Weight group is a derivative of this. So those allow because using atomics you

203
00:12:57,048 --> 00:13:00,198
can create such higher other primitives as well.

204
00:13:00,364 --> 00:13:03,826
Like we'll discuss later, lock free data structure. And it doesn't

205
00:13:03,858 --> 00:13:07,026
do data sharing. It's not used for data sharing because it doesn't carry

206
00:13:07,058 --> 00:13:09,922
it from data like channels do.

207
00:13:10,076 --> 00:13:13,478
Now here's an applicability of atomically performing

208
00:13:13,494 --> 00:13:16,966
a load and store. There's a simple map type map

209
00:13:16,998 --> 00:13:20,410
string string. There's an atomic value inside m store.

210
00:13:20,480 --> 00:13:23,646
We basically save a map. Then there's a read function and there's an

211
00:13:23,668 --> 00:13:26,814
insert function. Read function just atomically does

212
00:13:26,852 --> 00:13:30,350
a m load and converts the value of type

213
00:13:30,420 --> 00:13:34,602
to map. Insert, however, tries to update

214
00:13:34,666 --> 00:13:37,746
this value so it performs can m dot store.

215
00:13:37,928 --> 00:13:41,618
Now just int this simple piece of code while,

216
00:13:41,704 --> 00:13:45,134
and this is a piece of code which has been copied from the Golang documentation.

217
00:13:45,182 --> 00:13:48,774
So what can possibly go wrong here? What can possibly go wrong

218
00:13:48,812 --> 00:13:52,722
these is that if multiple writers

219
00:13:52,866 --> 00:13:56,978
try to invoke the insert method, the construct is not immune

220
00:13:56,994 --> 00:14:00,506
to it. Now what we do is we are doing a

221
00:14:00,528 --> 00:14:04,362
mix and match. So while we are discussing atomics, but we have started using

222
00:14:04,416 --> 00:14:08,214
other constructs to solve our problems. So we introduced

223
00:14:08,262 --> 00:14:12,202
a mutex here. And on the insert we just

224
00:14:12,256 --> 00:14:15,750
guarantee serialization by performing a mutex

225
00:14:15,830 --> 00:14:19,482
lock and then we just defer it. What this does is that if multiple

226
00:14:19,626 --> 00:14:22,802
routines are trying cto invoke the insert method only

227
00:14:22,856 --> 00:14:26,690
prone of them runs at a time because mutexes are great at serialization.

228
00:14:27,350 --> 00:14:31,282
We just agreed that and now we will

229
00:14:31,416 --> 00:14:34,500
just perform this mutex block. Next up,

230
00:14:35,450 --> 00:14:39,506
what would you expect the output to be here there's

231
00:14:39,538 --> 00:14:43,522
a funk a. There's a main method. Inside the main method

232
00:14:43,666 --> 00:14:47,718
there is xy two integers. There is

233
00:14:47,884 --> 00:14:51,770
a print ln, which is basically calling the a

234
00:14:51,840 --> 00:14:55,722
function. Inside the function we pass the pointer of

235
00:14:55,776 --> 00:14:59,286
the integer inside the body of an a. It accepts

236
00:14:59,318 --> 00:15:02,286
an integer and it returns a channel. The channel,

237
00:15:02,468 --> 00:15:05,726
just before it returns, it spawns a go routine and it

238
00:15:05,748 --> 00:15:08,862
does can atomic increment of an integer value.

239
00:15:08,996 --> 00:15:12,574
There are two operations of this. In one variation we

240
00:15:12,612 --> 00:15:16,162
simply call log print ln and we pass the

241
00:15:16,216 --> 00:15:19,874
two fun we call the two functions and we read the channel value from

242
00:15:19,912 --> 00:15:23,266
it. In another variation we store it into two

243
00:15:23,288 --> 00:15:26,514
variables, ab and bv. There are two functions, a and

244
00:15:26,552 --> 00:15:30,422
a called again, and the second line of it will

245
00:15:30,476 --> 00:15:34,326
read from that. They don't look entirely different if

246
00:15:34,348 --> 00:15:37,142
you think about it, because what we have just done is that in the second

247
00:15:37,196 --> 00:15:40,250
variation we have taken the initialization one step ahead.

248
00:15:40,320 --> 00:15:43,962
So it's two stage. Now it's not just one stage. What would you expect

249
00:15:44,016 --> 00:15:47,738
the output to be? It's interesting that when I

250
00:15:47,744 --> 00:15:51,130
run this code the first execution

251
00:15:51,630 --> 00:15:54,830
gives me a two and a four, whereas the second

252
00:15:54,900 --> 00:15:59,242
execution gives me a four and a four. Now which is understandable,

253
00:15:59,306 --> 00:16:02,894
the four and four part. Why? Because it's the same atomic

254
00:16:02,942 --> 00:16:06,802
operation. And remember, atomic operations were about data

255
00:16:06,856 --> 00:16:10,494
consistency. So if it's the same integer

256
00:16:10,622 --> 00:16:14,402
which has been incremented twice and read on the channel it will

257
00:16:14,456 --> 00:16:18,182
obviously be four. But why did the two happen? To answer

258
00:16:18,236 --> 00:16:21,686
this, let's add some log statement. Now what we do

259
00:16:21,708 --> 00:16:25,890
is just after the atomic ad I've added a log print ln

260
00:16:25,970 --> 00:16:29,398
and there's a time sleep of 2 seconds. So what that means is

261
00:16:29,404 --> 00:16:32,966
that before the value is returned it's actually going to sleep for 2 seconds.

262
00:16:33,078 --> 00:16:36,230
Now when we run this, the first execution

263
00:16:36,390 --> 00:16:39,946
prints one prone and two four. The second also prints one, one and

264
00:16:39,968 --> 00:16:42,946
four four. But interestingly, if you observe the timestamp,

265
00:16:43,078 --> 00:16:46,494
the first int happens at the 16th second and then

266
00:16:46,532 --> 00:16:50,574
it waits for 2 seconds and then int prints one and waits another

267
00:16:50,612 --> 00:16:55,686
2 seconds and returns two and four. Whereas the second implementation

268
00:16:55,818 --> 00:16:59,282
on the 20th 2nd, both of them print one and then after

269
00:16:59,336 --> 00:17:02,754
2 seconds because both waited for 2 seconds return a four and four.

270
00:17:02,872 --> 00:17:06,750
So effectively what's happening is the arguments inside

271
00:17:06,840 --> 00:17:10,626
the function are executed serially. There's a classic

272
00:17:10,658 --> 00:17:14,338
mistake that we do when we're dealing with this. A simple way to solve

273
00:17:14,354 --> 00:17:18,194
is use the lower construct, which is actually concurrent

274
00:17:18,242 --> 00:17:21,562
and not the first one because that would happen one after the other. Now this

275
00:17:21,616 --> 00:17:25,514
can result in a situation because it is possible that you

276
00:17:25,552 --> 00:17:29,162
may get blocked on the other value because the one hasn't worked.

277
00:17:29,296 --> 00:17:32,494
Clearly evident in this code here because it happened as

278
00:17:32,532 --> 00:17:36,462
two and these, the other value came as four. We also discussed that

279
00:17:36,596 --> 00:17:40,222
atomics and mutexes can both actually be uses for data

280
00:17:40,276 --> 00:17:43,730
consistency. So are they interchangeable? Is a common question.

281
00:17:43,880 --> 00:17:47,506
Atomic, as we said, are the bedrock of int

282
00:17:47,688 --> 00:17:51,554
using that others are done now? Yes and no,

283
00:17:51,592 --> 00:17:55,154
because there's only one case where you can actually interchangeably call

284
00:17:55,192 --> 00:17:58,306
them as performing the same role, which is assume there was

285
00:17:58,328 --> 00:18:02,514
an integer operation where we had to increment something. Now I may use atomic

286
00:18:02,562 --> 00:18:06,022
add int, or I may actually take a lock and do an unlock and apply

287
00:18:06,076 --> 00:18:08,966
it. Int will give me the same behavior at the end of the day.

288
00:18:09,068 --> 00:18:11,546
And this is the only time where we say that oh yeah, there may be

289
00:18:11,568 --> 00:18:15,062
overlapping concerns, but interestingly atomics are actually way faster,

290
00:18:15,126 --> 00:18:18,458
so you may be able to do more number of atomic operations compared with

291
00:18:18,464 --> 00:18:22,042
the locks because atomics are sent directly to the CPU and

292
00:18:22,096 --> 00:18:25,806
these are no language. VM ordered locks which are

293
00:18:25,828 --> 00:18:29,246
being performed. So you would actually see a drastic performance gain. But all

294
00:18:29,268 --> 00:18:32,746
over Golang we've always read and seen please do not communicate

295
00:18:32,778 --> 00:18:36,194
by sharing memory. Instead share memory by communicating, which takes

296
00:18:36,232 --> 00:18:40,402
us to the channels. Now what are channels used for like

297
00:18:40,456 --> 00:18:44,814
atomics are only and only used for primarily data consistency.

298
00:18:44,942 --> 00:18:47,854
Channels are used for everything, which is other than that, which is control,

299
00:18:47,912 --> 00:18:51,222
handoff, serialization, data sharing. It's surprising how much you can actually

300
00:18:51,276 --> 00:18:55,442
start doing with channels. I mean it's only not used for data consistency

301
00:18:55,586 --> 00:18:58,360
now because channels are so widely used.

302
00:18:58,730 --> 00:19:01,942
I'm going to cover a lot of these fun mistakes.

303
00:19:02,006 --> 00:19:05,786
Fun for me, maybe not fun for your others. Look at

304
00:19:05,808 --> 00:19:09,466
things. Piece of code. What could be going wrong here?

305
00:19:09,568 --> 00:19:12,830
There's a funk request which returns an InT. There's a channel,

306
00:19:12,980 --> 00:19:16,046
there is an I, it loops over zero to

307
00:19:16,068 --> 00:19:19,854
five increments at plus plus, and it

308
00:19:20,052 --> 00:19:23,402
writes the value to a channel. What could go prone?

309
00:19:23,476 --> 00:19:26,546
These. What can go prone here is that

310
00:19:26,728 --> 00:19:30,434
those goroutine are waiting to write on

311
00:19:30,472 --> 00:19:33,506
a channel. Now if the receiver or the reader of

312
00:19:33,528 --> 00:19:37,618
the request only read it once, there are multiple

313
00:19:37,714 --> 00:19:41,058
invocations of those functions which are just blocked forever

314
00:19:41,154 --> 00:19:44,550
because they are just waiting for the channel to clear up to rewrites.

315
00:19:44,700 --> 00:19:48,246
To solve for this, we have constructs. What we do is we

316
00:19:48,268 --> 00:19:51,786
wrap it inside a select clause which tries to write to

317
00:19:51,808 --> 00:19:55,334
a channel, and if it doesn't work it falls to the default,

318
00:19:55,382 --> 00:19:58,762
which is an empty. Surprisingly, this is also not the correct

319
00:19:58,816 --> 00:20:03,262
way, because this can also run into a unique condition, which is the

320
00:20:03,316 --> 00:20:07,310
last line can block forever now, because it's possible that

321
00:20:07,380 --> 00:20:11,278
even before the channel is read from

322
00:20:11,444 --> 00:20:15,298
outside of the request, the other goroutine tried

323
00:20:15,384 --> 00:20:18,994
writing, found nothing, and fell through

324
00:20:19,032 --> 00:20:22,658
the default section. So now the return channel

325
00:20:22,744 --> 00:20:26,658
is waiting forever. One of the most interesting questions

326
00:20:26,744 --> 00:20:30,086
that I always face when

327
00:20:30,108 --> 00:20:33,926
I'm writing code as well, is when and who should close an

328
00:20:33,948 --> 00:20:37,254
open channel. There's one of the things that I never thought, and it always takes

329
00:20:37,292 --> 00:20:41,522
me the hard way, a simple piece of code. Again, it's a for loop.

330
00:20:41,666 --> 00:20:44,746
Inside the for loop there's a value which is returned to a channel which has

331
00:20:44,768 --> 00:20:48,346
been produced. So you can think of it like a producer. And underneath there

332
00:20:48,368 --> 00:20:52,266
is a receiver which basically ends the value, appends it to an array.

333
00:20:52,378 --> 00:20:56,142
Once we are done, we print. When I print, I find that

334
00:20:56,196 --> 00:21:00,574
one is missing. Now, this would happen if

335
00:21:00,612 --> 00:21:04,350
my program exited, obviously this loop. After code C, my programs

336
00:21:04,420 --> 00:21:08,414
exited. Now, because WG weight was a weight

337
00:21:08,462 --> 00:21:11,986
group on these producers. Once producers were

338
00:21:12,008 --> 00:21:15,838
done producing and the channel was closed immediately,

339
00:21:16,014 --> 00:21:19,250
it's possible that the receiver has not yet

340
00:21:19,320 --> 00:21:22,966
performed the operation on receive and the function got exited and

341
00:21:22,988 --> 00:21:26,134
the program got exited. And hence that's the reason why I did not see

342
00:21:26,172 --> 00:21:29,482
a one. So how do I guarantee this, that if ten were

343
00:21:29,536 --> 00:21:33,018
sent, ten were received in this particular things? First of

344
00:21:33,024 --> 00:21:36,394
the implementation, the very first implementation, what we do is we

345
00:21:36,432 --> 00:21:40,330
detach the close responsibility from the sender.

346
00:21:41,650 --> 00:21:45,182
What we do is we basically make the WG wait

347
00:21:45,316 --> 00:21:48,986
in another goroutine, and that is the one which closes.

348
00:21:49,178 --> 00:21:53,262
And the execution of reading through the channel now

349
00:21:53,316 --> 00:21:56,914
is passed through the main routine in

350
00:21:56,952 --> 00:22:00,798
which I range over the channel. And even if it is closed

351
00:22:00,814 --> 00:22:04,306
by the goroutine, there is still an iteration that

352
00:22:04,328 --> 00:22:07,766
will happen which will still be able to read from the channel. This is one

353
00:22:07,788 --> 00:22:11,430
way of implementing it. Another way of implementing it, which is actually

354
00:22:11,500 --> 00:22:15,378
far more prevalent, is when both producers and senders

355
00:22:15,474 --> 00:22:18,726
and receivers are actually two different go routines which need

356
00:22:18,748 --> 00:22:22,590
to communicate. And this is where we introduce the dungeon. So you're

357
00:22:22,610 --> 00:22:26,394
producing and the consumer is receiving. But at

358
00:22:26,432 --> 00:22:30,154
comes point of time, the control flow must not leave

359
00:22:30,192 --> 00:22:33,422
these parent function. And hence we have two

360
00:22:33,476 --> 00:22:37,022
weight constructs. Now we are actually waiting via the wait

361
00:22:37,076 --> 00:22:40,574
group. We close the channel and then we wait on

362
00:22:40,612 --> 00:22:44,160
another channel, which is triggered after

363
00:22:44,630 --> 00:22:48,242
the receivers are done receiving. So these are two

364
00:22:48,296 --> 00:22:51,746
constructs of it. What else can go wrong with the channel?

365
00:22:51,928 --> 00:22:55,374
Let's look at things long running piece of code. It accepts

366
00:22:55,422 --> 00:22:58,774
a messages channel. What we're trying to achieve here is read from

367
00:22:58,812 --> 00:23:02,534
messages, and if any of those reads take more than

368
00:23:02,572 --> 00:23:06,118
a minute, then just return. And a bot, it's a

369
00:23:06,124 --> 00:23:09,578
fairly straightforward code. It compiles. But what's going wrong here,

370
00:23:09,664 --> 00:23:13,674
what's going wrong here is that channel can still decommemary, because inside each

371
00:23:13,712 --> 00:23:17,466
code operations we are creating a new time after.

372
00:23:17,648 --> 00:23:20,854
And this keeps on getting created, created, created.

373
00:23:20,982 --> 00:23:24,206
All we wanted to do was we just wanted to wait for

374
00:23:24,228 --> 00:23:27,710
a minute. A better way to deal with this is to

375
00:23:27,780 --> 00:23:31,886
initialize a time dot after, save an allocation, keep reusing it,

376
00:23:31,988 --> 00:23:35,514
keep looking for t channels output. If int happens after a minute,

377
00:23:35,562 --> 00:23:39,226
it will return otherwise formed. Print ln. Once it's

378
00:23:39,258 --> 00:23:43,034
done with the select, just do a reset. What this does is it doesn't

379
00:23:43,082 --> 00:23:46,486
keep creating those channels and the time dot after in

380
00:23:46,508 --> 00:23:49,894
every single iteration. Now all of these are about when two people

381
00:23:49,932 --> 00:23:53,542
are trying to compete for a resource here,

382
00:23:53,596 --> 00:23:57,462
everything, every such construct was about that. One of the best ways to

383
00:23:57,516 --> 00:24:01,226
resolve a conflict is to avoid int from happening. Now this is where

384
00:24:01,248 --> 00:24:05,034
we introduce the notion of lockless data structures. It's a study

385
00:24:05,072 --> 00:24:09,078
in itself on how lockless data structures are implemented.

386
00:24:09,254 --> 00:24:12,474
Why I stress on lockless data structures is because generalized

387
00:24:12,522 --> 00:24:16,174
lock free algorithms are very hard to implement. Designing lock free

388
00:24:16,212 --> 00:24:19,966
data structures is relatively easier. My slides have a bunch of

389
00:24:19,988 --> 00:24:23,374
these links which are from Microsoft research and other

390
00:24:23,412 --> 00:24:26,786
research papers which talk about building these common data structures which

391
00:24:26,808 --> 00:24:31,154
are actually lockless. And most of them use atomic underneath. Because as

392
00:24:31,192 --> 00:24:35,220
we discussed earlier, atomic is almost the bedrock of all concurrency control.

393
00:24:35,750 --> 00:24:39,030
Many a times. What also happens is that a simple

394
00:24:39,100 --> 00:24:42,966
solution is actually way better than a smart solution. If you look

395
00:24:42,988 --> 00:24:46,610
at this piece of code, there's an input array of integers,

396
00:24:46,690 --> 00:24:50,934
and there's an output array of integers. We need to run over the input array,

397
00:24:51,062 --> 00:24:54,682
perform a go routine, which is something,

398
00:24:54,736 --> 00:24:58,266
it does something, get the output of it and append it to the

399
00:24:58,288 --> 00:25:01,702
output array. The simplest way to do this would be using a lock,

400
00:25:01,766 --> 00:25:05,274
because now we're trying to serialize the access to the result output

401
00:25:05,322 --> 00:25:08,238
array. Or do we really need a lock here?

402
00:25:08,404 --> 00:25:12,286
A simpler way would just be to use an array and

403
00:25:12,308 --> 00:25:15,506
use positional index. Now arrays, as long as they

404
00:25:15,528 --> 00:25:19,666
are positionally accessed, can actually leave and do

405
00:25:19,688 --> 00:25:23,314
not require a need of a lock. We can just simply do run

406
00:25:23,352 --> 00:25:26,566
with an index. Once we get the output, we access the

407
00:25:26,588 --> 00:25:29,894
array via the positional index, and it does

408
00:25:29,932 --> 00:25:34,646
the job so many times we actually may not even need a

409
00:25:34,668 --> 00:25:38,314
very sophisticated concurrency control mechanism because this itself will do our

410
00:25:38,352 --> 00:25:41,866
job. Just to recap, what is the

411
00:25:41,888 --> 00:25:45,670
need for concurrency constructs? Because we want to solve

412
00:25:45,830 --> 00:25:48,620
the unpredictability problem, we want control.

413
00:25:49,150 --> 00:25:52,474
There are two kinds of that. There are control constructs

414
00:25:52,522 --> 00:25:56,078
which are used for control handoff. There are data constructs which are

415
00:25:56,084 --> 00:25:59,742
used for data sharing, and data consistency. Constructs also

416
00:25:59,796 --> 00:26:03,402
need to adhere to language principles. We saw how weight groups,

417
00:26:03,466 --> 00:26:07,274
how counters, or how channels as well can actually misbehave

418
00:26:07,322 --> 00:26:10,654
if you're not careful about how we are applying them. And now

419
00:26:10,692 --> 00:26:14,510
we also probably understand which prone to use when to recap

420
00:26:14,890 --> 00:26:17,974
were to look at the same problem again. Now when

421
00:26:18,012 --> 00:26:21,350
we look at this, we probably are better equipped to handle this problem.

422
00:26:21,500 --> 00:26:24,934
Thank you. I'm CTO and founder at last

423
00:26:24,972 --> 00:26:28,050
nine. We are an observability company and I'm Pushova.

