1
00:00:40,930 --> 00:00:44,594
Hi everyone, we'd like to invite you to the talk about the Kubernetes

2
00:00:44,642 --> 00:00:49,042
operator that we built at Aerospike for a distributed database and join

3
00:00:49,106 --> 00:00:52,526
the talk you it's the

4
00:00:52,548 --> 00:00:55,914
first time that I'm speaking in a conference in such a format of a YouTube

5
00:00:55,962 --> 00:00:59,854
stream and I'm excited. If you learned anything interesting, please tag me.

6
00:00:59,892 --> 00:01:03,722
Please tag the conference and please use the conference hashtags conf

7
00:01:03,796 --> 00:01:07,502
42 and cloud native. My name is Natalie Pistunovich.

8
00:01:07,566 --> 00:01:11,006
I'm a developer advocate lead at Aerospike, a Google developer expert

9
00:01:11,038 --> 00:01:14,546
for Go, an OpenAI developer ambassador and I

10
00:01:14,568 --> 00:01:18,278
organize the Berlin user groups for the go community

11
00:01:18,444 --> 00:01:21,858
and women tech makers. I'm also organizing the conferences

12
00:01:21,954 --> 00:01:24,902
go for fun Europe cloud nine ha.

13
00:01:25,036 --> 00:01:28,946
And besides Berlin. And you're welcome to follow me on Twitter. My handle

14
00:01:28,978 --> 00:01:32,842
is Natalie piss. So what's in our agenda today? We're going to talk about

15
00:01:32,896 --> 00:01:36,310
what are Kubernetes operators, what is Aerospike?

16
00:01:36,390 --> 00:01:40,262
Then we're going to see high level design of these aerospike

17
00:01:40,326 --> 00:01:43,786
Kubernetes operator and I will tell you some of the engineering

18
00:01:43,818 --> 00:01:47,566
challenges that we faced developing it. So let's start with saying what

19
00:01:47,588 --> 00:01:51,402
is a Kubernetes operator? It's designed for automation.

20
00:01:51,546 --> 00:01:54,978
Kubernetes offers out of the box automation and with it you

21
00:01:54,984 --> 00:01:59,166
can automate and deploy and running workloads.

22
00:01:59,358 --> 00:02:02,866
You can also automate how Kubernetes does that.

23
00:02:02,968 --> 00:02:06,566
The core of Kubernetes controlled plane is the

24
00:02:06,588 --> 00:02:10,694
API server. It exposes an HTTP API that

25
00:02:10,732 --> 00:02:15,074
lets end clusters, different parts of the cluster and external

26
00:02:15,122 --> 00:02:18,506
components communicate with each other. We're here today to

27
00:02:18,528 --> 00:02:22,566
talk about the operators. So what is the definition of an operators?

28
00:02:22,758 --> 00:02:26,666
Operators are clients of the Kubernetes API. They act as

29
00:02:26,688 --> 00:02:30,166
controllers for a custom resource. In Kubernetes,

30
00:02:30,278 --> 00:02:33,758
a controller is a control loop that watches the state of

31
00:02:33,764 --> 00:02:37,614
the cluster and it makes or request changes where needed.

32
00:02:37,732 --> 00:02:41,802
Each controller tries to move the current cluster state closer to the desired

33
00:02:41,866 --> 00:02:45,214
state. The controller tracks at least one Kubernetes resource

34
00:02:45,262 --> 00:02:49,006
type and as we said, operator tracks

35
00:02:49,038 --> 00:02:52,626
the state of a custom resource. A custom resource is

36
00:02:52,648 --> 00:02:56,206
an object that extends the Kubernetes API or allows

37
00:02:56,238 --> 00:02:59,490
you to introduce your own API into a project or a cluster.

38
00:02:59,570 --> 00:03:02,946
A custom resource definition CRD is a file

39
00:03:02,978 --> 00:03:06,274
that defines your own object kinds and it lets the API

40
00:03:06,322 --> 00:03:09,766
server handle the entire lifecycle. For example, aerospike is

41
00:03:09,788 --> 00:03:13,706
a database and it's a custom resource. Our engineers built an operator for

42
00:03:13,728 --> 00:03:17,350
it because it's not part of the Kubernetes ecosystem. The operator

43
00:03:17,430 --> 00:03:21,030
pattern is used for automating repeatable tasks and it combines

44
00:03:21,110 --> 00:03:24,398
custom resources and custom controllers. It is used

45
00:03:24,484 --> 00:03:28,014
to take the human out of the equation, because doing such

46
00:03:28,052 --> 00:03:31,642
things is boring. And when you do boring things, you make mistakes.

47
00:03:31,786 --> 00:03:35,274
One more time for the people in the back, in case you did not write

48
00:03:35,332 --> 00:03:39,042
your own operator or did not dive into the ones that we're using,

49
00:03:39,176 --> 00:03:43,074
maybe this was already a little confusing. So let's say that

50
00:03:43,112 --> 00:03:46,466
we start with a user that tells that it wants to

51
00:03:46,488 --> 00:03:50,514
do things. So it sends a command to the Kubernetes cluster. The API server

52
00:03:50,562 --> 00:03:53,446
exposes an HTTP API that, as we said,

53
00:03:53,548 --> 00:03:57,522
lets end users different parts of the cluster and the external components

54
00:03:57,586 --> 00:04:01,306
communicate with one another. Then Kubernetes creates pods to

55
00:04:01,328 --> 00:04:04,998
host the application instance. Each pod is tied to a node.

56
00:04:05,094 --> 00:04:09,050
A cluster is a set of worker machines called nodes that run

57
00:04:09,120 --> 00:04:12,510
containerized apps. Every cluster has at least one

58
00:04:12,580 --> 00:04:15,914
worker node. And let's say in our example we have n pods

59
00:04:15,962 --> 00:04:19,454
that are tied to n nodes. They all are

60
00:04:19,492 --> 00:04:22,782
created by a deployment object. Deployments are usually

61
00:04:22,836 --> 00:04:25,486
used for stateless applications like web servers.

62
00:04:25,598 --> 00:04:29,230
Pods that are deployed by deployment are identical and interchangeable,

63
00:04:29,310 --> 00:04:32,862
and they're created in a random order with random hashes

64
00:04:32,926 --> 00:04:36,354
in their pod names. On the other hand, stateful sets are

65
00:04:36,392 --> 00:04:39,666
used for stateful applications when dealing with databases.

66
00:04:39,778 --> 00:04:43,286
You definitely want to have a stateful set because we do want to store the

67
00:04:43,308 --> 00:04:46,646
data. Pods that are deployed by a stateful set component are

68
00:04:46,668 --> 00:04:50,394
not identical. They each have their own identity, which they keep

69
00:04:50,432 --> 00:04:53,862
between restarts, and each can be addressed individually.

70
00:04:54,006 --> 00:04:57,354
Service is an object then an abstract way

71
00:04:57,392 --> 00:05:01,094
to expose an application running on a set of nodes as a network

72
00:05:01,142 --> 00:05:04,750
service. A config map is an API object used to store

73
00:05:04,820 --> 00:05:07,530
non confidential data in key value pairs.

74
00:05:07,610 --> 00:05:10,922
Pods can consume config maps as environment variables,

75
00:05:10,986 --> 00:05:14,810
as command line arguments, or as configuration files in a volume.

76
00:05:14,890 --> 00:05:18,878
A config map allows you to decouple environment specific configurations

77
00:05:19,054 --> 00:05:23,038
from your container images so that your applications are easily

78
00:05:23,134 --> 00:05:27,006
portable. In kubernetes, controllers are control loops

79
00:05:27,038 --> 00:05:30,150
that watch the state of your cluster and then, as we said,

80
00:05:30,220 --> 00:05:34,274
make a request or just change the situation in a way that's

81
00:05:34,322 --> 00:05:37,806
needed in order to bring the cluster state closer

82
00:05:37,858 --> 00:05:40,986
to the desired stateful. And it tracks at least one

83
00:05:41,008 --> 00:05:44,214
resource type. And these there is custom resource.

84
00:05:44,342 --> 00:05:47,990
For example, our database and this one is handled

85
00:05:48,070 --> 00:05:51,546
by these operator. And both concepts,

86
00:05:51,658 --> 00:05:55,210
controller and operator, they represent patterns.

87
00:05:55,290 --> 00:05:58,346
They don't involve language specific implementation framework,

88
00:05:58,458 --> 00:06:01,978
which means that in order to write a control or an operator,

89
00:06:02,074 --> 00:06:06,462
you'll need to follow the convention, but you don't need to use any specific language.

90
00:06:06,606 --> 00:06:10,734
So to put this on writing, kubernetes operators would do the following

91
00:06:10,782 --> 00:06:14,178
things. Probably it minimizes the manual deploying and

92
00:06:14,184 --> 00:06:17,986
lifecycle management, so handles things like resource management

93
00:06:18,018 --> 00:06:21,462
or complex resource management, scale up or down the

94
00:06:21,516 --> 00:06:25,266
size of the cluster, and upgrade or downgrade the version.

95
00:06:25,378 --> 00:06:28,294
It manages your configuration. And of course it does.

96
00:06:28,332 --> 00:06:32,010
Monitoring basically take the human out of the boring part

97
00:06:32,080 --> 00:06:34,986
of the work to make sure that no mistakes are made.

98
00:06:35,168 --> 00:06:39,002
So in our example, what does the operators manage

99
00:06:39,136 --> 00:06:43,418
or a little bit about aerospike aerospike is a NoSQL database

100
00:06:43,514 --> 00:06:47,114
and it implements a hybrid memory architecture where the index

101
00:06:47,162 --> 00:06:50,718
is purely in memory, so not persisted, and the data is

102
00:06:50,724 --> 00:06:54,226
stored only on a persistent storage and reads directly from

103
00:06:54,248 --> 00:06:57,394
the disk. The disk I O is not required to access the

104
00:06:57,432 --> 00:07:00,978
index, which enables predictable performance. There are

105
00:07:01,064 --> 00:07:04,866
however strict SLAS petabytes of data handled in

106
00:07:04,888 --> 00:07:09,058
sub milliseconds and there is transactional guarantees.

107
00:07:09,234 --> 00:07:12,866
Basically means that the database transactions provide asset guarantees

108
00:07:12,898 --> 00:07:15,986
if needed. You can also have strong consistency,

109
00:07:16,098 --> 00:07:19,990
which is a term you probably heard from the cap theorem for distributed databases.

110
00:07:20,150 --> 00:07:24,262
All those reasons are why clients that are big financial

111
00:07:24,326 --> 00:07:27,830
institutes, for example banks and other clients from other industries,

112
00:07:27,910 --> 00:07:31,802
are using aerospike. Some other features that are a little more technical but

113
00:07:31,856 --> 00:07:35,290
relevant for the rest of this presentation would be rack

114
00:07:35,370 --> 00:07:38,906
awareness, which is a feature that allows you to store different replicas

115
00:07:38,938 --> 00:07:43,042
of records on different hardware failure groups. For these resilience and

116
00:07:43,096 --> 00:07:47,134
a multicluster XDR or cross data center replication

117
00:07:47,182 --> 00:07:50,254
setup. Multisite is when the nodes

118
00:07:50,302 --> 00:07:54,222
that are comprising a single cluster are distributed across different steps,

119
00:07:54,286 --> 00:07:57,622
a physical rack in a data center, an entire data center,

120
00:07:57,756 --> 00:08:00,514
or an availability zone in a cloud region.

121
00:08:00,642 --> 00:08:04,274
Basically, these cluster is stretched across regions and cloud providers,

122
00:08:04,322 --> 00:08:07,714
and it expands horizontally. This uses synchronous replication

123
00:08:07,762 --> 00:08:10,678
to deliver a global distributed transaction capability.

124
00:08:10,854 --> 00:08:14,442
The update speed is only limited by things like the speed of light.

125
00:08:14,576 --> 00:08:18,234
You can also go asynchronous for that. You'll use the cross data

126
00:08:18,272 --> 00:08:21,542
center replication setup, which uses asynchronous replication

127
00:08:21,606 --> 00:08:25,226
to connect to clusters that are located at different geographically distributed

128
00:08:25,258 --> 00:08:28,846
sites. It can extend the data infrastructure to any number of

129
00:08:28,868 --> 00:08:32,014
clusters easily. So we talked a little bit about

130
00:08:32,052 --> 00:08:35,742
the database. Let's talk about the operator. The Kubernetes

131
00:08:35,806 --> 00:08:39,346
operator is driven by a single custom resource CR,

132
00:08:39,448 --> 00:08:43,662
and it conforms with operator custom resource definition CRD.

133
00:08:43,806 --> 00:08:47,270
The cluster specs include things like the size,

134
00:08:47,340 --> 00:08:51,042
so the number of nodes per cluster and the resource allocation request.

135
00:08:51,106 --> 00:08:54,546
For example, the cpu per node it has the complete aerospike

136
00:08:54,578 --> 00:08:58,478
configurations and for example the YAML version of the Aerospike

137
00:08:58,514 --> 00:09:02,406
server, converting YAML based configuration to the aerospike

138
00:09:02,438 --> 00:09:06,406
version of them. And it handles the security configuration, TLS user

139
00:09:06,438 --> 00:09:10,258
management and so on. Because of some of the special features

140
00:09:10,294 --> 00:09:14,042
that we covered, it has some special considerations

141
00:09:14,186 --> 00:09:17,774
in what it does and how. So the deploying of

142
00:09:17,812 --> 00:09:21,050
the database clusters is a pretty obvious feature.

143
00:09:21,210 --> 00:09:24,686
Manages all the things lifecycle management, which means database

144
00:09:24,718 --> 00:09:27,982
cluster scale up and down, server version upgrade and downgrade,

145
00:09:28,046 --> 00:09:32,030
aerospike configuration management, rack awareness management,

146
00:09:32,110 --> 00:09:35,826
and cluster access control management. Also it handles all

147
00:09:35,848 --> 00:09:39,890
the fine details of the multi cluster cross data center replication setup.

148
00:09:39,970 --> 00:09:43,858
So remember how we said it spreads across the different availability zones,

149
00:09:43,954 --> 00:09:47,286
different cloud providers, and even combination of cloud and

150
00:09:47,388 --> 00:09:51,098
bare metal? That's a lot of configuration to figure out and keep

151
00:09:51,184 --> 00:09:54,842
up. And it monitors everything. So here are some

152
00:09:54,896 --> 00:09:57,994
of the engineering challenges we faced when we were developing it,

153
00:09:58,032 --> 00:10:01,622
with the first one being the persistent data. Each pod has a dedicated

154
00:10:01,686 --> 00:10:05,306
storage, and as we said, it must be persistent. We are using a database

155
00:10:05,338 --> 00:10:08,814
here. The logic is if it's new storage, it means that it probably

156
00:10:08,852 --> 00:10:12,830
has old data, because just like with computer memory, you cannot assume whether

157
00:10:12,900 --> 00:10:16,446
the storage that you were allocated with is empty or

158
00:10:16,468 --> 00:10:19,806
just filled with crash. But if you're

159
00:10:19,838 --> 00:10:23,262
restarting a pod, it means you probably have their relevant

160
00:10:23,326 --> 00:10:26,578
data. So you definitely don't want to touch that when you change the

161
00:10:26,584 --> 00:10:29,878
configuration. This is when the pod restarts, or when maybe something went wrong.

162
00:10:29,964 --> 00:10:33,574
You do want to save the storage, you do want to reuse that data.

163
00:10:33,692 --> 00:10:37,426
So a restarted pod has no metrics and there's

164
00:10:37,458 --> 00:10:40,754
kind of no kubernetes way of using that and telling

165
00:10:40,802 --> 00:10:44,442
whether this is a restart or a new pod. It also does not help

166
00:10:44,496 --> 00:10:47,878
that you probably have a new image because you did something like a version update.

167
00:10:47,974 --> 00:10:52,166
So how do you do this? These answer is flags. Add a flag

168
00:10:52,278 --> 00:10:55,646
using the init containers. This is what you run before

169
00:10:55,748 --> 00:10:59,406
your containers run, and that's how you init these devices. This is where

170
00:10:59,428 --> 00:11:03,418
you do the wiping of the data. How not to wipe data twice?

171
00:11:03,514 --> 00:11:07,406
The operator makes a cr for each resource in which we create a

172
00:11:07,428 --> 00:11:11,426
single tone instance upon initialization. So basically when

173
00:11:11,448 --> 00:11:15,070
the wiping is happening, we're adding a flag in the file.

174
00:11:15,150 --> 00:11:18,514
And then next time a pod restarts, it checks the config file.

175
00:11:18,562 --> 00:11:21,798
It steps that these flags exist so it knows not to wipe the data.

176
00:11:21,884 --> 00:11:25,622
Smart. Next challenge is changes during

177
00:11:25,676 --> 00:11:29,478
a rolling update. Say something happened, and the solution

178
00:11:29,574 --> 00:11:32,630
is to update the server version on all the ten nodes

179
00:11:32,710 --> 00:11:36,458
update on, node one complete, node two complete. Node three

180
00:11:36,544 --> 00:11:39,834
complete, abort. Suddenly you realize this is

181
00:11:39,872 --> 00:11:43,222
not the right thing for you to do, and you want to abort the server

182
00:11:43,286 --> 00:11:47,034
version update. But if the command that you issued is update

183
00:11:47,082 --> 00:11:50,286
on all ten nodes, how are you going to stop that? The way

184
00:11:50,308 --> 00:11:54,462
that we implemented this is that after every operation it recues

185
00:11:54,526 --> 00:11:57,694
the reconciliation request. Basically the operator

186
00:11:57,742 --> 00:12:01,442
is asking the API after every node, now what?

187
00:12:01,576 --> 00:12:04,990
This way, after it completed updating node three to the new version,

188
00:12:05,070 --> 00:12:08,386
the next step that it will receive as a command in the response

189
00:12:08,418 --> 00:12:11,750
to the question now what would be rollback or

190
00:12:11,820 --> 00:12:16,054
update to the old version? Node one, these, node two these, nodes three.

191
00:12:16,172 --> 00:12:19,794
And to make things even more efficient, the operator

192
00:12:19,922 --> 00:12:23,546
requests a delay in the response. Let's say that it

193
00:12:23,568 --> 00:12:26,726
knows that the migration of this specific node, which it cannot

194
00:12:26,758 --> 00:12:30,630
abort, will take this amount of time. A few records, it tens

195
00:12:30,710 --> 00:12:34,254
to the API, please respond to me, but not right

196
00:12:34,292 --> 00:12:38,026
away, but in a few seconds, because it can be that in those few seconds

197
00:12:38,058 --> 00:12:41,646
until the migration will be over, you will receive yet another change.

198
00:12:41,748 --> 00:12:45,006
So just make sure that you save resources and tell me

199
00:12:45,028 --> 00:12:48,306
what is the most up to date thing that I should do. And while it

200
00:12:48,328 --> 00:12:52,510
sounds very trivial to you now go check out different operators.

201
00:12:52,590 --> 00:12:56,274
I think these is a cool idea. The third challenge is

202
00:12:56,312 --> 00:13:00,150
what happens when you reach a really large scale. And well,

203
00:13:00,220 --> 00:13:03,826
we know that cloud is great for prototyping, but it can get pricey

204
00:13:03,858 --> 00:13:07,334
at a very large scale. And we have customers with

205
00:13:07,372 --> 00:13:11,394
half a trillion objects to give you a scale. Imagine that $1

206
00:13:11,442 --> 00:13:14,138
buys you three and a half objects. So this is a little bit of a

207
00:13:14,144 --> 00:13:17,462
funny thing to say, because an object is kind of a row in the database,

208
00:13:17,526 --> 00:13:21,286
and, well, $1 does not buy you three and a half rows. But let's just

209
00:13:21,328 --> 00:13:25,658
say in this case half a trillion is how much Jeff Bezos

210
00:13:25,754 --> 00:13:29,674
can afford. And remember, we have these slas for clients that require

211
00:13:29,722 --> 00:13:32,974
petabytes of traffic in sub milliseconds. Next,

212
00:13:33,012 --> 00:13:35,930
there is the issue that cloud hardware is not homogeneous.

213
00:13:36,010 --> 00:13:39,506
It gives you a promise of a minimum cpu, but it doesn't commit to

214
00:13:39,528 --> 00:13:43,022
that. It means that some of the machines are in the minimal setup,

215
00:13:43,086 --> 00:13:47,026
but others can have a higher setup. And aerospike, due to

216
00:13:47,048 --> 00:13:50,614
its architecture is disk heavy. Sharing the I O means

217
00:13:50,652 --> 00:13:54,406
you definitely get a slice, but it's hard to cap the size of

218
00:13:54,428 --> 00:13:58,754
it. This means that your machine might respond slowly on messages and distributed

219
00:13:58,802 --> 00:14:02,266
database send around a lot of messages to make sure that they're in

220
00:14:02,288 --> 00:14:06,326
sync, to make sure that they know where is the most up to date replica

221
00:14:06,358 --> 00:14:10,182
of the data is right now and also to endpoints like the heartbeat,

222
00:14:10,326 --> 00:14:14,506
then there is also networking. The network is not private,

223
00:14:14,618 --> 00:14:18,650
but you do get a slice of it. However, if you have noisy neighbors,

224
00:14:18,730 --> 00:14:22,414
they can drive your performance down. Also, let's not

225
00:14:22,452 --> 00:14:26,194
even start the conversation about the cascading effects of such any

226
00:14:26,232 --> 00:14:30,322
of those interruptions. It's something that it's really hard to predict and

227
00:14:30,376 --> 00:14:33,858
well, the spoiler is there, an operator alone will not solve these.

228
00:14:33,944 --> 00:14:37,890
So how do our clients solve that private cloud? When you get

229
00:14:37,960 --> 00:14:41,522
to a really, really large scale, get a whole host

230
00:14:41,586 --> 00:14:45,014
and split the resources internally and do budget to have

231
00:14:45,052 --> 00:14:48,854
comes overcapacity. When your client is for example, snap in their

232
00:14:48,892 --> 00:14:52,486
scale, you do want to read from the client, not from the master.

233
00:14:52,598 --> 00:14:55,834
Be aware and max your communication to

234
00:14:55,872 --> 00:14:59,478
a local one because latency matters a lot at the scale.

235
00:14:59,574 --> 00:15:02,814
Of course Kubernetes will work great in such a setup. Think about it,

236
00:15:02,852 --> 00:15:06,590
it started inside Google in their private cloud. And yes,

237
00:15:06,660 --> 00:15:10,382
of course the operator will work great in these setup as well.

238
00:15:10,436 --> 00:15:14,014
If you want to read the operator source code, of course it's open

239
00:15:14,052 --> 00:15:17,922
source, available in GitHub. And here's a recap of what we saw today.

240
00:15:18,056 --> 00:15:21,490
We talked about the Kubernetes operator, how it

241
00:15:21,560 --> 00:15:24,978
controls the custom resource, what does it mean and what is a

242
00:15:24,984 --> 00:15:28,486
custom resource? Then we discussed a little bit some of the

243
00:15:28,508 --> 00:15:32,466
challenges that we faced when we built our distributed database operator

244
00:15:32,498 --> 00:15:36,006
at Aerospike. And the recommendations that you should be taking home

245
00:15:36,108 --> 00:15:39,318
are keep the data upon pod restart because

246
00:15:39,404 --> 00:15:43,542
that is a database. Be able to revert a rolling update immediately because

247
00:15:43,596 --> 00:15:47,206
that's definitely important. Doesn't happen often, but in the one time you do

248
00:15:47,228 --> 00:15:50,410
want this to happen and at a very large scale

249
00:15:50,490 --> 00:15:53,978
you can have all sorts of new problems and you need more than one solution.

250
00:15:54,074 --> 00:15:57,726
And automate, automate automate thank you very much for attending the

251
00:15:57,748 --> 00:16:00,958
talk. Please tweet, please share and I am

252
00:16:01,044 --> 00:16:03,660
looking forward to all your feedback. Thank you.

