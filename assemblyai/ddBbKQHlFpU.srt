1
00:00:25,570 --> 00:00:29,478
Security. Hi, everyone. It's great to be back at

2
00:00:29,564 --> 00:00:33,234
Conf 42. My name is Josh Stella.

3
00:00:33,282 --> 00:00:36,914
I am the co founder and CTO of Fugue.

4
00:00:37,042 --> 00:00:40,600
We are a cloud security software company.

5
00:00:41,050 --> 00:00:44,146
I have spent at this point, pretty much the last decade

6
00:00:44,178 --> 00:00:47,378
of my life, both at AWS and at Fugue,

7
00:00:47,474 --> 00:00:51,614
focused on cloud security. ##ity from

8
00:00:51,652 --> 00:00:55,178
a practical perspective, and what I mean by practical

9
00:00:55,274 --> 00:00:58,926
is, what are hackers actually doing and how does

10
00:00:58,948 --> 00:01:03,220
it actually hurt you? That's all that really matters in cloud security.

11
00:01:03,590 --> 00:01:08,062
So today's focus is going to minimizing the blast

12
00:01:08,206 --> 00:01:11,598
radius of a, of a cloud breach.

13
00:01:11,774 --> 00:01:15,662
So you may or may not be familiar with this term.

14
00:01:15,806 --> 00:01:19,414
I don't know where I picked it up. I've been using it for many years.

15
00:01:19,612 --> 00:01:23,698
Blast radius refers to how much damage

16
00:01:23,874 --> 00:01:27,802
has begun done by the breach. So you can focus

17
00:01:27,856 --> 00:01:31,466
on the penetration aspect of the breach, and we often do that. We want

18
00:01:31,488 --> 00:01:34,540
to prevent attackers from gaining access

19
00:01:35,150 --> 00:01:36,890
to our resources.

20
00:01:37,790 --> 00:01:41,054
But more importantly, how much damage do

21
00:01:41,092 --> 00:01:44,346
they do? And damage can be expressed

22
00:01:44,378 --> 00:01:46,640
in lots of different ways.

23
00:01:47,730 --> 00:01:51,326
There's the amount of data stolen, sensitivity of

24
00:01:51,348 --> 00:01:55,634
the data stolen, what can be done with the stolen data.

25
00:01:55,832 --> 00:01:59,522
Those all assume a data exfiltration or

26
00:01:59,576 --> 00:02:02,974
data theft kind of breach. There are other kinds

27
00:02:03,022 --> 00:02:06,790
of blast radius that I would argue are typically much

28
00:02:06,860 --> 00:02:11,750
worse. So, for example, ransomware has

29
00:02:11,820 --> 00:02:15,814
one of the ugliest profiles, minimizing the blast

30
00:02:16,012 --> 00:02:19,926
radius of a, any category of breach,

31
00:02:20,118 --> 00:02:23,690
depending on how resilient you are to it.

32
00:02:23,840 --> 00:02:26,890
So today we're going to examine,

33
00:02:27,470 --> 00:02:31,466
we've only got about a half hour, so we're going to examine

34
00:02:31,658 --> 00:02:35,162
ones real world breach

35
00:02:35,306 --> 00:02:39,066
that I would argue had a very large blast radius.

36
00:02:39,178 --> 00:02:42,670
It's still unclear the details about

37
00:02:42,820 --> 00:02:46,642
exactly what was accessed, but we have some clues that we'll go through.

38
00:02:46,776 --> 00:02:50,466
The reason we're going to do that, and by the way, I am going to

39
00:02:50,488 --> 00:02:54,178
name names because real world breaches are the only way

40
00:02:54,344 --> 00:02:57,830
to actually understand cloud security topics.

41
00:02:58,170 --> 00:03:02,582
Generalization is

42
00:03:02,636 --> 00:03:06,274
basically useless. You really have to look at what hackers

43
00:03:06,322 --> 00:03:10,534
are actually doing to have a practical, useful approach

44
00:03:10,582 --> 00:03:13,770
to cloud security. So we'll be looking at

45
00:03:13,840 --> 00:03:17,130
the twitch breach that happened, I believe,

46
00:03:17,200 --> 00:03:20,874
last month at this point. And in that twitch

47
00:03:20,922 --> 00:03:24,554
breach, there's quite a large quantity

48
00:03:24,602 --> 00:03:28,334
of data and quite a few types of data that

49
00:03:28,452 --> 00:03:32,206
were stolen and then posted on

50
00:03:32,308 --> 00:03:35,794
four chan, so we'll get into that in some detail.

51
00:03:35,912 --> 00:03:39,282
The reason we're going to do that is to talk about

52
00:03:39,336 --> 00:03:42,660
how to make sure that doesn't happen to you.

53
00:03:43,030 --> 00:03:46,502
Okay, so three slides today.

54
00:03:46,636 --> 00:03:50,914
This is number ones, and let's

55
00:03:50,962 --> 00:03:54,310
go to slide number two. If I have my.

56
00:03:54,460 --> 00:03:58,458
There we go. And the last slide just has my email address on it.

57
00:03:58,624 --> 00:04:02,566
We're not going to be doing slideware today. We are going to be spending

58
00:04:02,758 --> 00:04:06,070
most of our time at a whiteboard

59
00:04:06,230 --> 00:04:10,060
and reviewing some content online

60
00:04:10,610 --> 00:04:14,238
around that particular breach. The reason we're using to

61
00:04:14,244 --> 00:04:18,346
be spending so much time at the whiteboard today and not at a terminal

62
00:04:18,458 --> 00:04:22,560
or something similar, is because

63
00:04:25,030 --> 00:04:28,242
minimizing the blast radius of a

64
00:04:28,296 --> 00:04:32,114
function of one trick, it is

65
00:04:32,152 --> 00:04:35,510
a function of the design of the system. It is a function

66
00:04:35,580 --> 00:04:38,982
of how you are organizing your

67
00:04:39,036 --> 00:04:42,914
computing resources and what API keys

68
00:04:42,962 --> 00:04:46,502
have access to what kinds of data or other

69
00:04:46,556 --> 00:04:49,766
resources. So it's very architectural. All right,

70
00:04:49,788 --> 00:04:53,226
but before we really drill into that, I have

71
00:04:53,248 --> 00:04:56,534
to watch time. That's why I'm looking over here. Before we really drill

72
00:04:56,582 --> 00:04:59,882
into that, I want to show you some data from our

73
00:04:59,936 --> 00:05:04,646
latest state of cloud security survey.

74
00:05:04,678 --> 00:05:08,462
We do this every year at Fug. This year we did it with our

75
00:05:08,516 --> 00:05:11,550
good friends and partners over at Sonotype.

76
00:05:12,550 --> 00:05:17,422
And what we do is we go ask 300 organizations

77
00:05:17,486 --> 00:05:20,674
that are operating at scale on the

78
00:05:20,712 --> 00:05:24,450
cloud what they're thinking about, what they're seeing,

79
00:05:24,520 --> 00:05:27,846
their concerns, et cetera. So this particular set of

80
00:05:27,868 --> 00:05:32,002
data are around what our respondents

81
00:05:32,146 --> 00:05:36,870
replied to, and we asked what are the most common cloud misconfiguration

82
00:05:37,550 --> 00:05:42,022
incidents? An incident in this case typically

83
00:05:42,086 --> 00:05:45,782
means not like a hacker breaking in necessarily,

84
00:05:45,846 --> 00:05:49,146
although that would be one. But more typically it

85
00:05:49,168 --> 00:05:53,038
would be when

86
00:05:53,124 --> 00:05:56,634
misconfigurations happen in these services and hopefully

87
00:05:56,682 --> 00:05:59,966
are detected prior to a hacker exploiting them.

88
00:06:00,068 --> 00:06:03,906
So I was really pleased to see iam top the

89
00:06:03,928 --> 00:06:08,020
list this time. That is

90
00:06:09,510 --> 00:06:13,330
a good thing. This is the first year where it has been

91
00:06:13,400 --> 00:06:17,046
the most popular response, and we track

92
00:06:17,148 --> 00:06:21,062
all of these cloud breaches and how they're done. And I can tell you that

93
00:06:21,116 --> 00:06:24,742
IAM is a major factor in most,

94
00:06:24,796 --> 00:06:28,646
if not all of them. It is

95
00:06:28,748 --> 00:06:32,106
the network in the cloud. You need to think of it

96
00:06:32,128 --> 00:06:36,374
as a network in the cloud. It is how your resources communicate

97
00:06:36,502 --> 00:06:40,566
with each other. And as we're thinking about blast radius,

98
00:06:40,758 --> 00:06:44,158
what we're talking about is limiting the amount of access

99
00:06:44,244 --> 00:06:47,834
from any one point. Right? And IAM is central

100
00:06:47,882 --> 00:06:52,154
to that. Other things on here, like security group and firewall rules,

101
00:06:52,282 --> 00:06:55,410
that's typically more oriented toward

102
00:06:55,750 --> 00:06:59,682
talking about techniques to get penetration for hackers than

103
00:06:59,736 --> 00:07:02,770
blast radius issues, although it can be related.

104
00:07:04,230 --> 00:07:08,166
Encryption is another area on here that's talked about

105
00:07:08,348 --> 00:07:10,840
at rest and in transit in the cloud.

106
00:07:11,530 --> 00:07:14,710
Intransit encryption is much, actually less

107
00:07:14,780 --> 00:07:18,534
important within the application than

108
00:07:18,572 --> 00:07:21,194
in the data center days, it was. I mean, you should turn it on,

109
00:07:21,232 --> 00:07:25,020
you should use it. But the attackers are not

110
00:07:25,390 --> 00:07:28,854
like reading packets off of your network.

111
00:07:28,982 --> 00:07:32,222
I have yet to see a real world cloud

112
00:07:32,276 --> 00:07:36,110
breach where those kinds of network data center

113
00:07:36,180 --> 00:07:40,270
oriented approaches were being taken. It's really

114
00:07:40,340 --> 00:07:44,018
about the control plane APIs in the cloud and getting

115
00:07:44,104 --> 00:07:48,210
access via API calls to the

116
00:07:48,360 --> 00:07:52,260
data at rest much more than watching

117
00:07:53,110 --> 00:07:56,558
data in transit. And at rest, there are

118
00:07:56,584 --> 00:08:00,546
a lot of mistakes you can make. And actually the cloud providers

119
00:08:00,578 --> 00:08:04,550
make it kind of easy to have a false sense of security about

120
00:08:04,620 --> 00:08:08,294
your at rest encryption. And we have classes on that

121
00:08:08,332 --> 00:08:11,434
you can find on our YouTube channel and so on. So when you're talking about

122
00:08:11,472 --> 00:08:15,702
blast radius, you're also going to be thinking about your encryption techniques,

123
00:08:15,766 --> 00:08:19,482
right, and how you're managing your keys and

124
00:08:19,616 --> 00:08:23,630
how much data any given set of keys can decrypt

125
00:08:24,610 --> 00:08:28,222
that is picked up from an at rest data source, like for example,

126
00:08:28,356 --> 00:08:32,710
a database snapshot or an s three bucket.

127
00:08:32,890 --> 00:08:36,980
Okay, let's jump into

128
00:08:38,630 --> 00:08:41,906
the whiteboard for a second here. Let me see if I have my

129
00:08:42,088 --> 00:08:45,526
screens arranged, how I think I do. No, wrong way. Okay,

130
00:08:45,628 --> 00:08:48,934
so we're going to go to the whiteboard, and I want to talk a little

131
00:08:48,972 --> 00:08:51,430
bit about conceptually,

132
00:08:52,810 --> 00:08:56,434
the notion of blast radius containment or damage

133
00:08:56,482 --> 00:09:00,074
containment. And I'm going to change to a

134
00:09:00,112 --> 00:09:03,926
non computing type of engineering,

135
00:09:03,958 --> 00:09:07,082
or in this case architecture, to maybe

136
00:09:07,136 --> 00:09:10,938
give you a mental model that isn't confused by the devils

137
00:09:10,954 --> 00:09:14,270
that live in the details of computing that we all live in,

138
00:09:14,340 --> 00:09:18,314
day in, day out. So the person who designs

139
00:09:18,362 --> 00:09:21,230
a ship is called a naval architect.

140
00:09:22,130 --> 00:09:25,518
And so I'm going to design a ship here. It's going to

141
00:09:25,524 --> 00:09:29,018
be a bad ship because I'm just in Photoshop

142
00:09:29,114 --> 00:09:32,714
and I'm not a naval architect, but let's say I've got a ship

143
00:09:32,762 --> 00:09:36,514
here. I dont know. It's an ugly

144
00:09:36,562 --> 00:09:38,840
ship, but it's a ship. Now,

145
00:09:40,250 --> 00:09:44,322
one of your principal goals in architecting

146
00:09:44,386 --> 00:09:47,570
a vessel is to not let so much water

147
00:09:47,660 --> 00:09:51,514
in that it sinks, right. The ship is

148
00:09:51,552 --> 00:09:54,906
a hole of air with a

149
00:09:55,088 --> 00:09:58,826
typically steel skin that floats in

150
00:09:58,848 --> 00:10:01,710
water. So you don't want water in. That's pretty obvious.

151
00:10:01,860 --> 00:10:03,760
So let's draw our water here.

152
00:10:04,690 --> 00:10:07,854
So how do naval architects address this?

153
00:10:08,052 --> 00:10:11,374
They do it by segmenting the

154
00:10:11,412 --> 00:10:14,018
interior of the vessel. Okay,

155
00:10:14,184 --> 00:10:18,542
so if you imagine that you've got bulkheads

156
00:10:18,606 --> 00:10:22,654
here between segmenting the compartments

157
00:10:22,702 --> 00:10:26,040
in the ship such that if,

158
00:10:27,370 --> 00:10:32,054
I don't know, an iceberg gets struck and

159
00:10:32,092 --> 00:10:36,022
it struck nose on, this compartment will fill

160
00:10:36,076 --> 00:10:40,202
with water. But the remainder of these will

161
00:10:40,256 --> 00:10:44,300
not. And so you have happy.

162
00:10:44,990 --> 00:10:48,698
Well, maybe not happy, but happier than otherwise living

163
00:10:48,864 --> 00:10:52,254
people on the ship. And it doesn't sink, right? That's the

164
00:10:52,292 --> 00:10:55,230
idea. When you think about the USS coal,

165
00:10:55,970 --> 00:10:58,794
which was, of course, suicide,

166
00:10:58,842 --> 00:11:02,490
attacked at port, and a large

167
00:11:02,580 --> 00:11:05,570
explosive set off against that youll.

168
00:11:05,990 --> 00:11:10,398
That explosive did breach a significant

169
00:11:10,574 --> 00:11:14,142
section of that youll, but the vessel did not using.

170
00:11:14,286 --> 00:11:17,986
Because the blast radius,

171
00:11:18,018 --> 00:11:21,350
if you will, that was the damage effect was

172
00:11:21,420 --> 00:11:24,790
limited. And that's what we're trying to do when we

173
00:11:24,860 --> 00:11:28,822
are talking about building computer systems

174
00:11:28,966 --> 00:11:32,906
that limit blast radius, okay? We're trying to limit it

175
00:11:33,008 --> 00:11:37,274
to a controllable part of

176
00:11:37,312 --> 00:11:40,294
our computing environments. All right,

177
00:11:40,432 --> 00:11:46,494
let's take a look real quick at this

178
00:11:46,532 --> 00:11:50,174
twitch breach. This is a really interesting breach because

179
00:11:50,292 --> 00:11:53,778
of the multiplicity of data. You know

180
00:11:53,784 --> 00:11:57,810
what, that text is small. I'm going to go to screen read mode.

181
00:11:58,630 --> 00:12:01,620
All right, so this is from Mitnick Security,

182
00:12:02,630 --> 00:12:05,766
their analysis of it. You can see here that on

183
00:12:05,788 --> 00:12:09,174
October 6, Twitch announced that

184
00:12:09,212 --> 00:12:13,334
they were, in fact, breaches, as is often the case with

185
00:12:13,372 --> 00:12:16,914
cloud breaches. I suspect Twitch

186
00:12:16,962 --> 00:12:20,262
found out, the world found out, but it when hackers

187
00:12:20,406 --> 00:12:24,074
proudly posted all the data that they took on four

188
00:12:24,112 --> 00:12:27,894
chan, and that is not atypical when you're

189
00:12:27,942 --> 00:12:31,854
talking about cloud breaches, to not have an

190
00:12:31,892 --> 00:12:36,142
understanding of what happened until the

191
00:12:36,196 --> 00:12:40,270
hackers who pulled off the hack actually

192
00:12:40,340 --> 00:12:43,886
do something with it. We see this a lot. Not in our customers.

193
00:12:43,988 --> 00:12:47,702
None of our customers actually have been hacked since using fugue,

194
00:12:47,786 --> 00:12:51,234
but we see it a lot in the industry where

195
00:12:51,352 --> 00:12:54,414
folks are just unaware that they've been breached,

196
00:12:54,462 --> 00:12:57,766
even major breaches like this until the

197
00:12:57,788 --> 00:13:01,446
hackers brag about it. So in this case, more than ones

198
00:13:01,468 --> 00:13:05,522
hundred gigabytes of leaked data was publicly

199
00:13:05,586 --> 00:13:09,640
posted online to four chan on Wednesday. All right,

200
00:13:10,170 --> 00:13:13,146
let's look at what kinds of data.

201
00:13:13,248 --> 00:13:16,794
So, so far, it's 100 gigs of data. That might not be

202
00:13:16,832 --> 00:13:20,782
a big deal, right? We're not going to measure blast radius just

203
00:13:20,836 --> 00:13:25,130
by size of bytes. If I manage to steal

204
00:13:25,210 --> 00:13:28,522
all product images

205
00:13:28,666 --> 00:13:32,074
from Amazon.com, who cares?

206
00:13:32,202 --> 00:13:35,314
That's going to be massive quantities of data.

207
00:13:35,512 --> 00:13:39,378
But it doesn't matter because it's not sensitive data.

208
00:13:39,464 --> 00:13:42,398
It's intended to be public facing, et cetera.

209
00:13:42,574 --> 00:13:45,926
On the other hand, I personally was affected by

210
00:13:45,948 --> 00:13:49,282
this when the Chinese broke

211
00:13:49,346 --> 00:13:53,670
into the database in which all of my personal details

212
00:13:54,250 --> 00:13:57,474
were kept for my security clearances that I've had in the

213
00:13:57,532 --> 00:14:01,098
past, and all that stuff was stolen. That's small data,

214
00:14:01,184 --> 00:14:05,402
but they know everything about me and just about everyone

215
00:14:05,456 --> 00:14:09,706
else who has carried a clearance over probably

216
00:14:09,808 --> 00:14:13,594
a decade or two. So small data, huge blast

217
00:14:13,642 --> 00:14:17,280
radius. An interesting story on that one.

218
00:14:17,730 --> 00:14:21,134
I was at a conference speaking with a very

219
00:14:21,172 --> 00:14:22,430
senior NiST.

220
00:14:25,510 --> 00:14:29,026
I guess he's a scientist, maybe an engineer, but he's one of

221
00:14:29,048 --> 00:14:32,706
the people who developed a lot of

222
00:14:32,728 --> 00:14:36,942
the NIST controls for security. Okay. He is central

223
00:14:37,006 --> 00:14:40,006
to that. He might be retired now, I don't know.

224
00:14:40,108 --> 00:14:43,958
And he quipped that, and I don't know if this is because he had

225
00:14:44,044 --> 00:14:48,214
specific factual information to this end or it was a speculation

226
00:14:48,262 --> 00:14:51,740
on his part, but he quipped that the reason he thought

227
00:14:52,190 --> 00:14:56,214
the Chinese had stolen

228
00:14:56,262 --> 00:15:00,640
that data and then a few weeks later, someone broke into

229
00:15:01,010 --> 00:15:04,302
a website called Ashley Madison where people

230
00:15:04,356 --> 00:15:07,614
were cheating on their partners was

231
00:15:07,652 --> 00:15:11,178
to tie those data together. Because the way you get spies,

232
00:15:11,354 --> 00:15:15,102
the way you flip people often, is by having incriminating

233
00:15:15,166 --> 00:15:18,702
information about them. So when you want to talk about blast radius,

234
00:15:18,766 --> 00:15:21,940
if his hypothesis is correct,

235
00:15:22,550 --> 00:15:26,726
we probably won't know for a decade or more if a

236
00:15:26,748 --> 00:15:30,982
number of Americans with access to sensitive information are

237
00:15:31,036 --> 00:15:34,514
being bribed into sharing it. Its size doesn't

238
00:15:34,562 --> 00:15:38,134
matter. It's the content. And what can

239
00:15:38,172 --> 00:15:41,990
be dont with the content that matters when you're talking about blast radius.

240
00:15:42,070 --> 00:15:45,398
So here, it's, I think it was 128 gigs.

241
00:15:45,414 --> 00:15:48,940
It says over 100 here, but let's look at what it was.

242
00:15:49,310 --> 00:15:53,262
So amongst the posted data included three years of

243
00:15:53,316 --> 00:15:57,322
payment information showing how much Twitch compensated

244
00:15:57,386 --> 00:16:01,166
its elite gamers, which caused quite a stir online

245
00:16:01,268 --> 00:16:04,782
over the high earnings of a few select top streamers.

246
00:16:04,846 --> 00:16:08,194
If you didn't know that streamers with millions of followers make

247
00:16:08,232 --> 00:16:11,682
a lot of money, you haven't been paying attention. I would

248
00:16:11,736 --> 00:16:16,020
argue that. Who cares? This is meaningless data.

249
00:16:16,330 --> 00:16:20,434
Tiny blast radius folks

250
00:16:20,482 --> 00:16:24,086
making a million dollars or $5 million a year. Now more people know the

251
00:16:24,108 --> 00:16:26,470
exact figure. We kind of all knew. Who cares?

252
00:16:27,530 --> 00:16:31,258
Yeah. The leak revealed that twitch paid more than 108,000

253
00:16:31,344 --> 00:16:34,300
annually to 13. Okay, well, I won't read all that.

254
00:16:34,990 --> 00:16:38,714
I think, as a security practitioner, I don't really

255
00:16:38,752 --> 00:16:42,110
care about this. I would not lose sleep

256
00:16:42,850 --> 00:16:46,480
if a client were to call me and say, oh, my God,

257
00:16:47,090 --> 00:16:50,746
our payment information to top streamers was leaked.

258
00:16:50,778 --> 00:16:54,418
What should we do? Probably nothing, right? The world will

259
00:16:54,504 --> 00:16:58,180
continue, but it gets much more interesting.

260
00:16:59,110 --> 00:17:00,020
All right,

261
00:17:02,950 --> 00:17:04,900
let's see if I can find.

262
00:17:08,680 --> 00:17:12,470
Oh, this isn't the article. Let's go to this other article I found

263
00:17:12,840 --> 00:17:17,460
that goes into more of what was actually stolen.

264
00:17:18,940 --> 00:17:20,490
Where are we?

265
00:17:22,700 --> 00:17:25,956
Yeah, this is interesting. So the twitch leak,

266
00:17:26,148 --> 00:17:32,604
which apparently motivated the disclosure and

267
00:17:32,642 --> 00:17:36,990
allegedly contains the source code from almost 6000

268
00:17:37,520 --> 00:17:41,724
internal git repositories, including the

269
00:17:41,762 --> 00:17:45,548
entirety of twitch tv, various twitch clients.

270
00:17:45,644 --> 00:17:48,348
We know that these are mobile clients,

271
00:17:48,524 --> 00:17:52,300
console clients, desktop operating system clients,

272
00:17:52,380 --> 00:17:54,320
proprietary sdks,

273
00:17:54,980 --> 00:17:58,852
internal red teaming tools, and then

274
00:17:58,986 --> 00:18:02,470
creator payout reports dating back to 2019 and more.

275
00:18:03,400 --> 00:18:07,104
Okay, this minimizing the blast radius

276
00:18:07,152 --> 00:18:10,970
of a much more interesting

277
00:18:11,500 --> 00:18:14,280
and really ugly.

278
00:18:14,860 --> 00:18:17,816
Let's go back to our whiteboard and let's erase this guy.

279
00:18:17,918 --> 00:18:22,228
So what we've got here, we don't have exactly

280
00:18:22,334 --> 00:18:26,428
all the details on this breach. I got to watch time because

281
00:18:26,514 --> 00:18:29,950
I tend to enjoy talking about this stuff and

282
00:18:31,200 --> 00:18:36,336
I will go over. All right, we're still good. So the

283
00:18:36,358 --> 00:18:38,930
breach here included payment information,

284
00:18:42,660 --> 00:18:45,760
right, for their streamers.

285
00:18:46,120 --> 00:18:49,444
Apparently most or all of this

286
00:18:49,482 --> 00:18:52,676
data we don't know was stored in

287
00:18:52,698 --> 00:18:55,956
git repositories. We know there were, according to

288
00:18:55,978 --> 00:18:59,556
that article anyway, approximately 6000 git

289
00:18:59,588 --> 00:19:00,360
repos.

290
00:19:04,090 --> 00:19:08,050
Okay, so you had payment info. We had proprietary

291
00:19:08,130 --> 00:19:11,080
sdks, source code.

292
00:19:12,590 --> 00:19:15,782
So we know from other reporting

293
00:19:15,926 --> 00:19:19,770
or it has been reported that these included

294
00:19:20,350 --> 00:19:23,820
AWS service,

295
00:19:25,250 --> 00:19:28,842
internal APIs and sdks for AWS

296
00:19:28,906 --> 00:19:32,826
services. So not just twitch here. And by the way, twitch is owned

297
00:19:32,858 --> 00:19:36,366
of course, by Amazon. So if anyone

298
00:19:36,468 --> 00:19:40,014
should be really good at security on the cloud,

299
00:19:40,212 --> 00:19:44,340
twitch should be right up there. And I don't doubt that they are

300
00:19:44,710 --> 00:19:48,002
in terms of a lot of the things most people

301
00:19:48,056 --> 00:19:51,874
think about. They clearly were not thinking though about blast

302
00:19:51,922 --> 00:19:56,082
radius as it related to this vulnerability that was exploited.

303
00:19:56,226 --> 00:20:00,226
So you've got SDK code and source

304
00:20:00,258 --> 00:20:04,666
code, including AWS services in

305
00:20:04,688 --> 00:20:07,914
the piece that I just pulled up, it didn't have this in there.

306
00:20:07,952 --> 00:20:10,700
But in other reporting on this,

307
00:20:11,550 --> 00:20:15,726
it has been claimed that there

308
00:20:15,748 --> 00:20:20,126
was a leak of Amazon source code for

309
00:20:20,228 --> 00:20:23,390
a competitor, for steps called vapor.

310
00:20:27,910 --> 00:20:31,486
Okay, so here we've got business intelligence

311
00:20:31,598 --> 00:20:35,620
here we've got highly sensitive proprietary business information

312
00:20:36,790 --> 00:20:40,530
that's being all in the same leak.

313
00:20:41,130 --> 00:20:44,694
And we know from the reporting on

314
00:20:44,732 --> 00:20:48,230
this and what Twitch said happened is

315
00:20:48,300 --> 00:20:52,310
that they had a server and that server

316
00:20:52,910 --> 00:20:55,946
was misconfigured and a

317
00:20:55,968 --> 00:20:59,450
bad actor, we'll give them some devil horns here,

318
00:20:59,600 --> 00:21:03,322
a bad actor broke into that

319
00:21:03,376 --> 00:21:07,542
server and from there got payment info

320
00:21:07,686 --> 00:21:10,958
back to 2019. Why is that

321
00:21:10,964 --> 00:21:14,362
in a git repo? I don't think that was in a git repo. I'm skeptical

322
00:21:14,506 --> 00:21:16,640
that that was in a git repo. Okay.

323
00:21:17,730 --> 00:21:21,958
Proprietary SDKs, all of Twitch

324
00:21:22,074 --> 00:21:26,338
TV, all of

325
00:21:26,504 --> 00:21:29,746
the clients, right. You see where

326
00:21:29,768 --> 00:21:33,606
I'm going with this Amazon source code

327
00:21:33,788 --> 00:21:37,826
for still secretive projects that haven't launched

328
00:21:37,858 --> 00:21:40,994
yet. So this is blast radius,

329
00:21:41,042 --> 00:21:44,506
right? This is breadth of access.

330
00:21:44,688 --> 00:21:47,820
So a couple questions I would ask

331
00:21:48,190 --> 00:21:52,742
is why in the world does this one server

332
00:21:52,886 --> 00:21:56,614
have access to all of these different kinds

333
00:21:56,662 --> 00:22:00,494
of things, right? Not just different quantities of things, but different

334
00:22:00,612 --> 00:22:03,726
kinds of things. It doesn't make much sense. There's not

335
00:22:03,748 --> 00:22:06,894
much segmentation there. Now there are a couple of ways this

336
00:22:06,932 --> 00:22:10,402
could have played out. Maybe they really

337
00:22:10,456 --> 00:22:14,580
do put all of this in git repos. A lot of this is source code.

338
00:22:16,070 --> 00:22:20,442
Why a server that was Internet facing in any capacity

339
00:22:20,606 --> 00:22:24,322
had any access to source code repos

340
00:22:24,386 --> 00:22:29,654
is another question. It probably, by the way, didn't I

341
00:22:29,692 --> 00:22:33,534
mentioned earlier that the initial penetration

342
00:22:33,602 --> 00:22:37,286
is less interesting? That's the story of this server.

343
00:22:37,478 --> 00:22:41,258
This is how the hacker penetrated, right? This is the interesting

344
00:22:41,344 --> 00:22:44,698
part of the story. It's all this blast radius stuff.

345
00:22:44,864 --> 00:22:48,606
It's not how they got in. So very often what

346
00:22:48,628 --> 00:22:51,822
we see in these scenarios is

347
00:22:51,876 --> 00:22:56,254
the hacker will get in through a misconfigured server or

348
00:22:56,452 --> 00:22:59,598
they'll find some API keys in an external repo or in

349
00:22:59,604 --> 00:23:02,782
a disk image or something. But then once they're on the server,

350
00:23:02,846 --> 00:23:06,286
they don't really care about that server. Okay, nobody cares

351
00:23:06,318 --> 00:23:09,458
about your servers anymore. They don't mean anything.

352
00:23:09,544 --> 00:23:13,586
Protecting your operating systems and so on. The only reason you're doing that anymore

353
00:23:13,698 --> 00:23:17,574
is to prevent people from perching on those to get to cloud control

354
00:23:17,612 --> 00:23:21,110
plane APIs. In this case certainly

355
00:23:21,180 --> 00:23:26,246
at least the ability to get into 6000

356
00:23:26,348 --> 00:23:29,482
get repos. So how might we segment this?

357
00:23:29,536 --> 00:23:32,620
The first thing is let's pick out the things that are.

358
00:23:34,030 --> 00:23:37,350
It's like when you're a kid and there's five animals in

359
00:23:37,360 --> 00:23:40,618
a car and which one doesn't belong? Okay, which one doesn't belong?

360
00:23:40,794 --> 00:23:44,270
Definitely this payment info leaps out. Now to me,

361
00:23:44,340 --> 00:23:47,674
this is the one data type here, the one

362
00:23:47,732 --> 00:23:51,362
collection of data that's kind of understandable that

363
00:23:51,416 --> 00:23:54,622
a server that was public facing

364
00:23:54,686 --> 00:23:57,986
would have any access to, right? Because let's say

365
00:23:58,008 --> 00:24:01,678
you're one of those streamers and you want to log into twitch

366
00:24:01,774 --> 00:24:05,334
tv and see how much money you

367
00:24:05,372 --> 00:24:08,390
made over the last year because you've got to pay taxes.

368
00:24:09,050 --> 00:24:12,962
That's wrong because you're going to get a tax document. But youll take my point.

369
00:24:13,116 --> 00:24:16,122
This is application data, right?

370
00:24:16,256 --> 00:24:20,102
This is understandable to be something breachable

371
00:24:20,246 --> 00:24:23,690
via a public facing IP address. In my opinion,

372
00:24:24,590 --> 00:24:28,622
it's not great, but it's also not the end of the world. And I've mentioned

373
00:24:28,676 --> 00:24:32,094
earlier, I think if this had been the only thing that

374
00:24:32,132 --> 00:24:36,074
was leaked and stolen, I personally

375
00:24:36,122 --> 00:24:40,354
as a practitioner, wouldn't give this much thought I'd probably look

376
00:24:40,392 --> 00:24:42,290
again at how we're doing encryption,

377
00:24:42,950 --> 00:24:46,674
right? Because, for example,

378
00:24:46,872 --> 00:24:51,442
I youll want to make sure that data,

379
00:24:51,496 --> 00:24:54,834
that we're truly sensitive, particularly PII data, things like

380
00:24:54,872 --> 00:24:58,262
that. I mean, the risk in this is more

381
00:24:58,316 --> 00:25:03,414
lawsuit honestly than it is anything practical.

382
00:25:03,462 --> 00:25:06,940
Okay? You could say getting sued is bad, that is true.

383
00:25:07,630 --> 00:25:12,730
But in terms of just the ugliness of the other data

384
00:25:12,800 --> 00:25:16,190
that were stolen here, that's the lowest item on the list.

385
00:25:16,260 --> 00:25:18,990
Okay, source code for twitch tv.

386
00:25:19,570 --> 00:25:23,278
Well, let's just start there. We've got source code here

387
00:25:23,444 --> 00:25:27,150
for twitch tv and also for clients.

388
00:25:28,630 --> 00:25:33,714
Now I suppose it is possible that

389
00:25:33,912 --> 00:25:37,410
and probably likely in some scenarios that

390
00:25:37,480 --> 00:25:40,678
certain engineers, certain programmers working

391
00:25:40,764 --> 00:25:44,342
on, say, the Xbox client, would also

392
00:25:44,396 --> 00:25:48,600
need access to the main web host resources code.

393
00:25:50,330 --> 00:25:52,520
I don't know what their architecture is,

394
00:25:52,990 --> 00:25:55,580
but I could see it.

395
00:25:56,510 --> 00:25:59,974
It feels a little bit of a stretch to me. I mean, honestly,

396
00:26:00,022 --> 00:26:02,890
if you're doing a modern services architecture,

397
00:26:03,550 --> 00:26:06,938
everything is exposed as APIs. You shouldn't be reading the source,

398
00:26:07,034 --> 00:26:10,958
necessarily needing to read the source code behind

399
00:26:11,044 --> 00:26:14,094
the internal APIs you're using to put your

400
00:26:14,132 --> 00:26:17,710
application together. I would argue even that if you have to,

401
00:26:17,780 --> 00:26:20,894
you've done a really bad job of developing APIs

402
00:26:20,942 --> 00:26:25,314
and documenting them, and that you probably shouldn't do

403
00:26:25,352 --> 00:26:29,106
that if you have lots of teams, they should live and die by

404
00:26:29,128 --> 00:26:33,570
the contract of their APIs, right? And documentation thereof.

405
00:26:36,250 --> 00:26:39,110
Let's assume for a moment that from this server,

406
00:26:40,970 --> 00:26:44,682
our bad guy, our hacker, got access to just

407
00:26:44,736 --> 00:26:47,610
one set of credentials.

408
00:26:48,110 --> 00:26:52,090
Probably, given that this is an Amazon company hosted on AWS,

409
00:26:52,670 --> 00:26:56,414
likely those are IAM credentials that have access to

410
00:26:56,612 --> 00:27:00,158
these repositories or something similar. Let's say they got a

411
00:27:00,164 --> 00:27:03,934
hold of one set that had access to both the clients and

412
00:27:03,972 --> 00:27:08,258
twitch tv. Why you

413
00:27:08,264 --> 00:27:12,270
could have segmentation there. If you're not thinking about segmentation

414
00:27:12,430 --> 00:27:15,906
within your engineering team, what you're doing

415
00:27:16,008 --> 00:27:19,570
is creating a really attractive vector.

416
00:27:20,070 --> 00:27:23,430
And that's another interesting thing about the twitch breach.

417
00:27:24,250 --> 00:27:27,878
None of this is an attack on any production systems or databases that

418
00:27:27,884 --> 00:27:31,234
we know of. A lot of times when we're

419
00:27:31,282 --> 00:27:34,426
working with folks who are just really getting their

420
00:27:34,448 --> 00:27:38,390
heads around cloud security, they think, well, my production environment

421
00:27:38,550 --> 00:27:42,038
is the one the hackers are going to go for. Very often it's

422
00:27:42,054 --> 00:27:45,818
not. The attackers prefer Dev, they prefer

423
00:27:45,914 --> 00:27:49,626
non prod, because production,

424
00:27:49,818 --> 00:27:53,086
because people think the way I was just describing, well, I have

425
00:27:53,108 --> 00:27:54,720
to protect production more.

426
00:27:55,810 --> 00:27:59,674
Dev has really nasty blast radius effects,

427
00:27:59,722 --> 00:28:03,166
depending on what kind of data you have in these dev environments. And it doesn't

428
00:28:03,198 --> 00:28:06,446
just have to be source code. Very often it's copies of databases.

429
00:28:06,638 --> 00:28:10,446
Okay, but back to our ship that we don't want to have sync.

430
00:28:10,558 --> 00:28:13,922
We should be segmenting these things if group

431
00:28:13,976 --> 00:28:17,362
A, if team a works

432
00:28:17,416 --> 00:28:20,818
on clients, and Team B, and of course, there's a

433
00:28:20,824 --> 00:28:23,994
bunch of folks here. I'm just one person per team here

434
00:28:24,032 --> 00:28:27,194
for now. Team B is working on

435
00:28:27,312 --> 00:28:31,254
the web application. Why are they allowed

436
00:28:31,302 --> 00:28:35,142
to see each other's source code? I would say dont do that

437
00:28:35,296 --> 00:28:38,670
segment. And by the way, when you're segmenting,

438
00:28:40,450 --> 00:28:43,646
you're not going to predict everything a hacker might

439
00:28:43,668 --> 00:28:47,866
think to do. So the lesson

440
00:28:47,898 --> 00:28:51,726
from this isn't, oh, man, we should have separate

441
00:28:51,918 --> 00:28:55,266
repos for source code for different parts of the system. There are

442
00:28:55,288 --> 00:28:58,958
companies that have a single git repo, okay, so there are different kinds

443
00:28:58,974 --> 00:29:02,726
of segmentation you can practice, but what

444
00:29:02,748 --> 00:29:06,662
youll want to be doing is figuring out specifically how to

445
00:29:06,796 --> 00:29:10,294
perform that segmentation. Now, we're running low

446
00:29:10,332 --> 00:29:13,562
on time here. I only have a couple more minutes.

447
00:29:13,696 --> 00:29:17,002
So these are the two

448
00:29:17,056 --> 00:29:20,186
that really are ugly, in my view. And I

449
00:29:20,208 --> 00:29:23,786
only have one color pen here. I'll get

450
00:29:23,808 --> 00:29:27,386
my whiteboard better next time with multiple colors.

451
00:29:27,498 --> 00:29:31,440
But why in the world would

452
00:29:32,050 --> 00:29:35,118
there be source code for AWS services?

453
00:29:35,204 --> 00:29:38,350
Not twitch services, but AWS services?

454
00:29:38,420 --> 00:29:40,926
And by the way, if you're pointing back at the Mitnick article and saying,

455
00:29:40,948 --> 00:29:44,418
well, they didn't say that, I've been researching this a lot, and I've read a

456
00:29:44,424 --> 00:29:48,178
lot of sources, and I can't tell you where every single one is reporting from.

457
00:29:48,264 --> 00:29:51,874
I personally did not download the archive from four

458
00:29:51,912 --> 00:29:54,902
chan. But you can do that. I don't know if it's still on four chan,

459
00:29:54,956 --> 00:29:58,006
but it's out there on the Internet. You can download it and look at it,

460
00:29:58,028 --> 00:30:01,720
and a lot of people have. So why in the world

461
00:30:02,250 --> 00:30:05,482
would that access to git repos get me

462
00:30:05,536 --> 00:30:09,210
a parent company's highly prized

463
00:30:09,870 --> 00:30:13,930
source code for public facing services that

464
00:30:14,000 --> 00:30:17,914
every hacker in the world wants to understand how they operate

465
00:30:17,962 --> 00:30:21,726
in order to try to breach them. That's madness. That should

466
00:30:21,748 --> 00:30:25,146
not be accessible with this one breach server

467
00:30:25,178 --> 00:30:29,034
and some API keys. Right? So this is now

468
00:30:29,092 --> 00:30:33,074
an iceberg that is sliding along the

469
00:30:33,112 --> 00:30:36,322
side of our ship, right? This is how the Titanic sunk, is they had a

470
00:30:36,376 --> 00:30:39,614
kind of early form of this highly

471
00:30:39,662 --> 00:30:43,174
segmented youll structure such that because

472
00:30:43,212 --> 00:30:46,886
it dragged along the iceberg, it penetrated enough of

473
00:30:46,908 --> 00:30:50,294
them, and it sank the ship. All right, Amazon will be fine.

474
00:30:50,332 --> 00:30:53,914
They're not sinking. Twitch will be fine. But my

475
00:30:53,952 --> 00:30:57,740
point here is the diversity of these data

476
00:30:58,430 --> 00:31:02,406
create. In this case, I would argue, one of the largest potential

477
00:31:02,518 --> 00:31:05,180
blast radii of breaches in recent years.

478
00:31:06,290 --> 00:31:10,462
Because who knows what state

479
00:31:10,516 --> 00:31:14,000
actors are going to do with this resources code. Who knows what

480
00:31:14,370 --> 00:31:17,600
sophisticated hacking consortia are going to do with these things?

481
00:31:19,410 --> 00:31:22,030
And what's the recovery,

482
00:31:22,610 --> 00:31:25,794
right? I'm assuming if you're here, you write

483
00:31:25,832 --> 00:31:29,326
software or are involved in the creation of software.

484
00:31:29,438 --> 00:31:32,846
It's not easy, right? It's hard. And so it's

485
00:31:32,878 --> 00:31:36,214
really hard to say, well, we're going to have to throw all that

486
00:31:36,252 --> 00:31:39,846
away. I seriously doubt that's what happened here. So that's what we

487
00:31:39,868 --> 00:31:42,920
kind of have time for today. So the moral of the story,

488
00:31:43,370 --> 00:31:46,730
and I hope I touched on a number of things you should be thinking about.

489
00:31:46,880 --> 00:31:49,994
The first thing is, and let me

490
00:31:50,032 --> 00:31:53,402
just see if I can make some notes here,

491
00:31:53,456 --> 00:31:56,910
I got to get my whiteboard game up on this machine.

492
00:31:57,330 --> 00:32:01,134
All right. The first is understand what

493
00:32:01,172 --> 00:32:02,910
you have that's valuable.

494
00:32:04,610 --> 00:32:09,038
Understand potential

495
00:32:09,134 --> 00:32:12,130
blast radius or potential damage,

496
00:32:14,070 --> 00:32:17,970
and then the things that are high in potential damage.

497
00:32:18,310 --> 00:32:19,250
Segment,

498
00:32:20,890 --> 00:32:24,690
segment access segment,

499
00:32:24,770 --> 00:32:25,960
important things.

500
00:32:30,090 --> 00:32:33,986
All right? Youll can't protect everything perfectly.

501
00:32:34,178 --> 00:32:37,254
If we did, we wouldn't have functional transactional systems.

502
00:32:37,382 --> 00:32:40,826
And so this gets into data classification to

503
00:32:40,848 --> 00:32:44,826
some degree, but it also gets into thinking like a hacker. Like, what's a

504
00:32:44,848 --> 00:32:47,200
hacker really going to do with that data?

505
00:32:48,050 --> 00:32:51,534
I'll go back to, if you think about the

506
00:32:51,572 --> 00:32:55,630
Ashley Madison breach, right? The Ashley Madison people think, well, the data

507
00:32:55,780 --> 00:32:59,538
is of a bunch of people who are

508
00:32:59,624 --> 00:33:02,782
lying to their partners. That's kind of sensitive.

509
00:33:02,846 --> 00:33:07,442
But you combine that with potentially the

510
00:33:07,496 --> 00:33:10,914
security clearance data for folks,

511
00:33:11,042 --> 00:33:14,530
clearance holders, and that becomes a truly

512
00:33:14,610 --> 00:33:18,914
ugly kind of blast radius.

513
00:33:19,042 --> 00:33:22,278
And hackers are clever like that. And of course, by the way, I've never

514
00:33:22,364 --> 00:33:26,118
used Ashley Madison. I've been married for 30 years, so that's

515
00:33:26,134 --> 00:33:29,546
not me. So three,

516
00:33:29,728 --> 00:33:32,170
you need to think about this architecturally,

517
00:33:35,890 --> 00:33:39,582
by which I mean youll developers should not

518
00:33:39,636 --> 00:33:43,450
be employing

519
00:33:43,610 --> 00:33:47,166
designs and techniques like, for example, the ability to list s

520
00:33:47,188 --> 00:33:50,882
three buckets in production environments. They shouldn't be doing

521
00:33:50,936 --> 00:33:54,286
that as a design part of the system that breaks segmentation.

522
00:33:54,478 --> 00:33:58,366
Okay? You want to limit. And so it's

523
00:33:58,398 --> 00:34:02,130
very easy to do intentional design choices

524
00:34:02,290 --> 00:34:06,374
that expand blast radius. Very often you

525
00:34:06,412 --> 00:34:08,360
see this, and this is number four,

526
00:34:09,930 --> 00:34:11,240
worry about Dev.

527
00:34:16,300 --> 00:34:19,688
Not just prod, worry about Dev and stage and test,

528
00:34:19,774 --> 00:34:23,768
because very often this is where we do things like use long

529
00:34:23,854 --> 00:34:28,380
lived, highly privileged

530
00:34:31,120 --> 00:34:34,796
accounts and tokens and so on and keys in

531
00:34:34,818 --> 00:34:38,364
order for convenience. Well, hackers like getting

532
00:34:38,402 --> 00:34:42,464
into Dev. Okay? So you need to think about segmentation in Dev as well.

533
00:34:42,662 --> 00:34:45,952
All right, I am pretty sure I am all up

534
00:34:46,006 --> 00:34:49,148
on time here, so we're

535
00:34:49,164 --> 00:34:52,864
going to go to the last of these. I am

536
00:34:52,902 --> 00:34:56,848
Josh Stella. Josh at Fugue Co. I do try hard

537
00:34:56,934 --> 00:35:00,896
to, I think I, like everyone gets spammed a bazillion times a day in email.

538
00:35:01,078 --> 00:35:04,952
But if you want to reach out and talk to me or ask a question

539
00:35:05,046 --> 00:35:08,456
or get a conversation going, feel free. And we

540
00:35:08,478 --> 00:35:11,210
are at www. Dont Fugue Co.

541
00:35:11,740 --> 00:35:15,030
Enjoy the rest of your conference and thank you for your time.

