1
00:00:25,010 --> 00:00:28,854
Learning. In this talk, we'll be talking about Qflow and

2
00:00:28,892 --> 00:00:32,834
how you can get an endtoend machine learning platform with just a few clicks.

3
00:00:32,962 --> 00:00:36,118
My name is Mophi, I'm a software engineer at IBM and a

4
00:00:36,124 --> 00:00:39,446
contributor to the Qflow project. So if

5
00:00:39,468 --> 00:00:42,774
you want to follow along and find the slides, the link to these slide is

6
00:00:42,812 --> 00:00:48,082
this slide. So the link is tiny ccml

7
00:00:48,226 --> 00:00:51,470
k eight s. So once again it's tiny tc

8
00:00:52,290 --> 00:00:55,470
e two e ML khs.

9
00:00:56,050 --> 00:00:59,358
So not too long ago, we can all remember

10
00:00:59,444 --> 00:01:03,006
machine learning and AI was a novelty, right? Like companies were

11
00:01:03,108 --> 00:01:06,306
spending a lot of time and spending a lot of money researching a lot of

12
00:01:06,328 --> 00:01:08,690
these machine learning ideas.

13
00:01:09,590 --> 00:01:13,298
And it was not necessarily a core part of your business.

14
00:01:13,464 --> 00:01:16,774
Some companies were doing it well, some companies were doing it a little bit more

15
00:01:16,812 --> 00:01:20,774
sporadically. IBM, where I work at, even ten

16
00:01:20,812 --> 00:01:24,118
years ago, machine learning was a huge research topic and we

17
00:01:24,124 --> 00:01:26,998
were spending hundreds of millions of dollars every year.

18
00:01:27,164 --> 00:01:30,918
But it wasn't directly making any business impact. It was more of a

19
00:01:31,004 --> 00:01:34,506
theoretical side of business where you have a lot of

20
00:01:34,528 --> 00:01:37,322
data, you just don't know what to do with them, and you just try different

21
00:01:37,376 --> 00:01:41,198
things out. You try to gather some information from the data.

22
00:01:41,364 --> 00:01:45,278
Well, if you look at the whole

23
00:01:45,364 --> 00:01:49,070
machine learning ecosystem, there is a lot of different things that needs to happen

24
00:01:49,140 --> 00:01:52,394
for machine learning code to become useful.

25
00:01:52,522 --> 00:01:55,922
But most of the effort is still spent on that small,

26
00:01:55,976 --> 00:01:58,962
tiny block in the middle. Machine learning code.

27
00:01:59,096 --> 00:02:02,482
Engineers love data. Scientists love their machine learning code.

28
00:02:02,536 --> 00:02:06,446
We write a lot of code in Python R and like Tensorflow

29
00:02:06,478 --> 00:02:09,542
and all of these things which like spending a lot of time in the middle

30
00:02:09,676 --> 00:02:13,442
where to make your machine learning code valuable,

31
00:02:13,506 --> 00:02:17,142
you actually need to spend a lot more time on these things around

32
00:02:17,196 --> 00:02:20,390
it, right? You need to spend bit time on data verification,

33
00:02:21,070 --> 00:02:24,874
analysis, you need to serve the model you create, you need to monitor the

34
00:02:24,912 --> 00:02:28,106
model so that you know the thing it's doing, it's the right thing

35
00:02:28,128 --> 00:02:31,598
to do. So now more and more,

36
00:02:31,684 --> 00:02:35,582
it is a core part of every business. So just the machine learning code

37
00:02:35,636 --> 00:02:39,626
is not good enough to be able to serve.

38
00:02:39,818 --> 00:02:43,374
The underlying business is trying to improve by

39
00:02:43,412 --> 00:02:47,186
using machine learning and AI. Data is everywhere. We generate more

40
00:02:47,208 --> 00:02:50,850
data now more than ever. And understanding what that data

41
00:02:50,920 --> 00:02:54,386
is and what that data means is more important than ever.

42
00:02:54,568 --> 00:02:58,360
It's estimated in the next ten to 15 years,

43
00:02:58,810 --> 00:03:02,882
our data ingestion and data creation will quadruple

44
00:03:02,946 --> 00:03:06,326
or go to an exponential number. But if we

45
00:03:06,348 --> 00:03:09,706
don't understand what data means, that data means to us, we are just like

46
00:03:09,728 --> 00:03:13,594
wasting time and money by generating more data, we're not actually getting

47
00:03:13,632 --> 00:03:17,562
anything valid out of it. So with that,

48
00:03:17,616 --> 00:03:21,174
I think because machine learning is becoming more and more mainstream

49
00:03:21,222 --> 00:03:24,080
and becoming more and more core part of our business,

50
00:03:24,450 --> 00:03:26,590
comes the rise of mlops.

51
00:03:27,250 --> 00:03:30,894
If you are not familiar with what MLOps is, well,

52
00:03:30,932 --> 00:03:35,006
you can ask, what is MlOps? So MLOps is these ability to apply DevOps

53
00:03:35,038 --> 00:03:38,510
principles to machine learning applications. And this is the definition

54
00:03:38,670 --> 00:03:42,082
given by the MLOps Special

55
00:03:42,136 --> 00:03:45,794
Interest group from CD foundation. So what MLOps is

56
00:03:45,832 --> 00:03:48,774
trying to solve is that right now, machine learning,

57
00:03:48,892 --> 00:03:52,514
even to this day in a lot of companies and a lot of organizations,

58
00:03:52,562 --> 00:03:56,626
is a sporadic thing. It's done by a data scientist. It's almost treated

59
00:03:56,658 --> 00:04:00,678
like research. It's done almost as in an educational capacity,

60
00:04:00,774 --> 00:04:04,346
and we want to make that into a core part of your model.

61
00:04:04,448 --> 00:04:07,226
If you're building software in 2021,

62
00:04:07,408 --> 00:04:10,966
I'm hoping you have embraced some of the DevOps

63
00:04:10,998 --> 00:04:14,890
practices. Where you have your code, your code is being continuously tested,

64
00:04:14,970 --> 00:04:18,126
your code is being integration tested, then your code is going

65
00:04:18,148 --> 00:04:21,070
through some sort of deployment, continuous delivery model,

66
00:04:21,140 --> 00:04:25,170
where your code goes to your version control,

67
00:04:25,240 --> 00:04:28,750
then gets tested, gets built, gets pushed to production,

68
00:04:28,830 --> 00:04:32,174
gets tested again, and you can have rollback and all that features.

69
00:04:32,302 --> 00:04:35,810
And MLOps is trying to bring those same principles into

70
00:04:35,880 --> 00:04:38,660
the lifecycle of your machine learning models as well.

71
00:04:39,030 --> 00:04:42,626
Well, with that introduction, I am MoFI. I'm a software engineer and developer

72
00:04:42,658 --> 00:04:45,990
advocate at IBM, and I mostly do container things.

73
00:04:46,060 --> 00:04:48,854
So if you haven't figured it out by now,

74
00:04:48,972 --> 00:04:52,938
I am not from these world of machine learning. I'm not coming into this

75
00:04:53,024 --> 00:04:56,474
from the perspective of a data scientist. I come from the world

76
00:04:56,512 --> 00:05:00,334
of infrastructure and containers. Most recently, I have

77
00:05:00,372 --> 00:05:04,030
been contributing to the Qflow upstream project into

78
00:05:04,100 --> 00:05:07,662
the manifest and deployment special

79
00:05:07,716 --> 00:05:11,422
interest group. And if you need to find me

80
00:05:11,476 --> 00:05:14,718
in a social media later, I can be found at movie woes in any of

81
00:05:14,724 --> 00:05:18,210
the social media above, mostly Twitter. So if you have any questions

82
00:05:18,360 --> 00:05:21,346
after the conference, you can reach out to me. Feel free to reach out to

83
00:05:21,368 --> 00:05:24,610
me at moviecodes in Twitter.

84
00:05:25,030 --> 00:05:28,626
So the title of the talks about end to

85
00:05:28,648 --> 00:05:32,054
end machine learning platform, so what does that even mean? And why do we care

86
00:05:32,172 --> 00:05:36,086
about an end to end machine learning platform? So end to

87
00:05:36,108 --> 00:05:40,406
end machine learning platform without having going deeper into

88
00:05:40,588 --> 00:05:43,786
what it means. Let's just talk about what we want an

89
00:05:43,808 --> 00:05:46,954
end to end machine learning platform to have. And when we say

90
00:05:46,992 --> 00:05:51,066
end to end machine learning platform, we're talking about something that covers everything

91
00:05:51,168 --> 00:05:55,454
from the start of the data to actually using that model into

92
00:05:55,572 --> 00:05:59,166
something useful in our application in our business,

93
00:05:59,348 --> 00:06:02,766
the very first step, or even like one of the earlier step,

94
00:06:02,788 --> 00:06:06,482
is data ingestion, right? So you have data being produced either

95
00:06:06,536 --> 00:06:09,986
by you collecting the data from your application or user just

96
00:06:10,008 --> 00:06:13,906
sending your data, or by some other mean, you're just collecting some data.

97
00:06:14,008 --> 00:06:18,126
And this is the part a lot of companies are still in trends.

98
00:06:18,158 --> 00:06:21,634
There are some graphs and machine learning and data analysis

99
00:06:21,682 --> 00:06:24,626
actually stops for a lot of people at that stage.

100
00:06:24,818 --> 00:06:28,086
But if you want to do anything useful with the data, if you want to

101
00:06:28,108 --> 00:06:31,722
build some intelligence around the data, you need to take that

102
00:06:31,776 --> 00:06:35,910
data and clean it up, transform that data into something usable,

103
00:06:36,070 --> 00:06:39,482
validate the data so that you know that this data makes

104
00:06:39,536 --> 00:06:43,846
sense for your larger subset of the larger structure

105
00:06:43,878 --> 00:06:47,406
of the whole data. Then you are just bidding the data for training.

106
00:06:47,508 --> 00:06:51,214
You are building models, you're validating models and training that

107
00:06:51,252 --> 00:06:55,454
model into like a distributed training to create this model that

108
00:06:55,492 --> 00:06:58,706
you can use. This is where we see

109
00:06:58,728 --> 00:07:02,978
a lot of these gaps in the theoretical structure of machine learning

110
00:07:03,064 --> 00:07:05,758
versus the business use cases that we have.

111
00:07:05,944 --> 00:07:08,706
Oftentimes data scientists are building these models,

112
00:07:08,738 --> 00:07:12,658
building this training into their own machine,

113
00:07:12,834 --> 00:07:16,182
and then testing out that this works. This is great.

114
00:07:16,316 --> 00:07:20,202
But the true value of machine learning only can happen when

115
00:07:20,256 --> 00:07:23,674
we are serving that model, like rolling that out into

116
00:07:23,712 --> 00:07:27,050
our application using that intelligence, and then

117
00:07:27,120 --> 00:07:30,634
continuously monitoring that model's performance and

118
00:07:30,672 --> 00:07:34,126
logging that out and making that a whole loop. Right? We're not

119
00:07:34,148 --> 00:07:36,830
just stopping at, oh, yeah, I have built a model.

120
00:07:36,900 --> 00:07:40,798
Great, now our problems are solved. We actually now have to say,

121
00:07:40,884 --> 00:07:44,500
we have built a model. We're serving this model. We are getting information

122
00:07:44,870 --> 00:07:48,306
from the serving that the data we are getting makes sense,

123
00:07:48,408 --> 00:07:51,458
the performance makes sense. We're continuously improving that model.

124
00:07:51,624 --> 00:07:55,394
So an end to end machine learning platform ideally would

125
00:07:55,432 --> 00:07:58,894
give us all these things, right? And some parts

126
00:07:58,942 --> 00:08:02,470
it will probably do better than others. And you also want to make sure

127
00:08:02,620 --> 00:08:06,374
that we have a way to continuously improve. So end to end, not just teams

128
00:08:06,412 --> 00:08:09,378
that we have all the features and we're good to go. I think end to

129
00:08:09,404 --> 00:08:12,666
end should give us a way to continuously improve in each of

130
00:08:12,688 --> 00:08:15,894
those steps. So there are many commercial

131
00:08:15,942 --> 00:08:19,770
end to end machine learning offering out there, and almost

132
00:08:19,840 --> 00:08:23,114
all major cloud providers has one. Other than that,

133
00:08:23,152 --> 00:08:26,926
you also have a bunch of third party companies just providing machine learning

134
00:08:27,028 --> 00:08:29,760
platform as a service you can use.

135
00:08:30,290 --> 00:08:33,838
For example, you have Google Cloud AI platform. I happen to

136
00:08:33,844 --> 00:08:37,934
work for IBM. We have couple, we have IBM cloud tech for data. Watson Studio,

137
00:08:38,062 --> 00:08:41,220
AWS happened to have Sagemaker and many other services,

138
00:08:41,590 --> 00:08:44,914
and you have azure machine learning platform. And again,

139
00:08:44,952 --> 00:08:48,534
as I said, there are many more third party companies providing this

140
00:08:48,572 --> 00:08:52,614
as a service. The pros of

141
00:08:52,652 --> 00:08:56,786
using end to end machine learning platforms from one of the cloud providers

142
00:08:56,818 --> 00:09:00,618
would be it is fully managed, you don't have to do

143
00:09:00,784 --> 00:09:04,266
all the bells and whistles are included with it. It works well with

144
00:09:04,288 --> 00:09:08,598
other cloud services. So if you are already a customer of Azure,

145
00:09:08,694 --> 00:09:12,074
using the Azure's machine learning service will work pretty

146
00:09:12,112 --> 00:09:16,170
well with the other Azure services that you have like Azure pipelines

147
00:09:16,250 --> 00:09:19,774
and Azure Kubernetes and all the other things will kind of

148
00:09:19,892 --> 00:09:22,720
work together. And the same goes for any other cloud services.

149
00:09:23,250 --> 00:09:27,038
And because you are already with a major cloud provider, your machine

150
00:09:27,054 --> 00:09:30,306
learning platform itself is also cloud scale. You have an easier time

151
00:09:30,328 --> 00:09:33,458
just scaling everything up. And you also have enterprise support,

152
00:09:33,544 --> 00:09:37,166
right? You are working with a cloud provider and you are taking

153
00:09:37,208 --> 00:09:40,440
an enterprise plan. You definitely have a lot more support

154
00:09:40,890 --> 00:09:44,902
with it. So if something goes wrong, you have someone to talk to or

155
00:09:45,036 --> 00:09:48,358
get support from. Some of the cons, I would say

156
00:09:48,444 --> 00:09:51,994
of an end to end machine learning platform, that if you are

157
00:09:52,112 --> 00:09:55,590
going with a cloud provider in this sense it's going to be expensive,

158
00:09:55,670 --> 00:10:00,314
obviously, because it's a pretty hefty cost.

159
00:10:00,432 --> 00:10:03,710
You have to consider if you want to go down that route,

160
00:10:04,130 --> 00:10:07,278
you definitely have these chance of getting vendor locked in.

161
00:10:07,364 --> 00:10:11,502
One of the reasons that would happen is you are not necessarily doing

162
00:10:11,556 --> 00:10:14,926
machine learning, you're doing AWS machine

163
00:10:14,958 --> 00:10:19,074
learning. You're not necessarily like

164
00:10:19,112 --> 00:10:22,850
if you're whatever vendor you go with, you will have a version of okay,

165
00:10:22,920 --> 00:10:26,482
we are doing this tool that Google thought

166
00:10:26,536 --> 00:10:30,014
that's how it should work, then you build your infrastructure

167
00:10:30,062 --> 00:10:33,862
around it and what at some point you find out that you

168
00:10:33,916 --> 00:10:37,718
can't change it without having major rework if

169
00:10:37,724 --> 00:10:40,758
you want to move out to someone else. So you have this problem of vendor

170
00:10:40,774 --> 00:10:43,894
lock in, and because your environment

171
00:10:43,942 --> 00:10:48,090
is managed by the cloud, it is not always super

172
00:10:48,160 --> 00:10:51,974
clear how you could have a local environment that replicates exactly

173
00:10:52,032 --> 00:10:56,394
how the cloud environment works. Oftentimes some of these components

174
00:10:56,442 --> 00:11:00,014
are not even open source, so you have no idea exactly how they work

175
00:11:00,052 --> 00:11:03,470
under the hood. So you have to kind of do everything

176
00:11:03,540 --> 00:11:06,674
on the cloud or you can do something on the local machine. These you run

177
00:11:06,712 --> 00:11:10,402
the risk of not having a matching environment between cloud and

178
00:11:10,456 --> 00:11:13,922
local. Obviously many of those tools are not open

179
00:11:13,976 --> 00:11:17,650
source in the vendors, so you don't really have a way

180
00:11:17,720 --> 00:11:21,046
of kind of doing it on your own or having a

181
00:11:21,068 --> 00:11:24,246
look at the source code or improve the code. If you see

182
00:11:24,268 --> 00:11:27,746
anything problematic, you are kind of dependent on the cloud to continuously

183
00:11:27,778 --> 00:11:31,594
make that improvement. And code and models are

184
00:11:31,632 --> 00:11:35,546
usually, sometimes not. Most of the times are not portable because you're building them

185
00:11:35,648 --> 00:11:39,098
in the cloud with their proprietary software. So it's going

186
00:11:39,104 --> 00:11:42,826
to be difficult for you to take your code and model and do it somewhere

187
00:11:42,858 --> 00:11:45,934
else. It's not true for every provider and not

188
00:11:45,972 --> 00:11:50,106
every cloud, but there is a high chance in a managed environment

189
00:11:50,138 --> 00:11:53,614
that could happen. So why not DyI, right, a lot of open

190
00:11:53,652 --> 00:11:56,862
source tools are out there. Tensorflow is open source.

191
00:11:56,926 --> 00:12:00,740
There are a bunch of other things, if you look at the whole

192
00:12:01,830 --> 00:12:04,978
end to end things that you need many of the tools that are out

193
00:12:04,984 --> 00:12:09,238
there that are open source. So definitely you could do something yourself

194
00:12:09,324 --> 00:12:13,398
using the open source. Or it is also possible for you to write everything

195
00:12:13,484 --> 00:12:17,074
from scratch. And it is not the first time industry in the industry

196
00:12:17,122 --> 00:12:19,622
have done so. Companies like Uber,

197
00:12:19,686 --> 00:12:23,286
Netflix, Airbnb, Lyft and many more have actually rolled

198
00:12:23,318 --> 00:12:27,626
out their own solution internally. So I

199
00:12:27,648 --> 00:12:30,982
think Uber has a software called Michelangelo

200
00:12:31,046 --> 00:12:34,798
and that kind of covers very Uber specific problems and

201
00:12:34,884 --> 00:12:38,702
in a very Uber specific way, it just solves those machine learning

202
00:12:38,756 --> 00:12:41,886
problems by building can entire platform internally at

203
00:12:41,908 --> 00:12:45,294
Uber. So if you are going down that

204
00:12:45,332 --> 00:12:48,882
route, some of the pros you can look at is you have full control

205
00:12:48,936 --> 00:12:52,306
over the platform, right? You are building the platform for your company and

206
00:12:52,328 --> 00:12:56,306
your exact needs. So everything you will build would be custom made

207
00:12:56,488 --> 00:12:59,480
for you because it's owned by you.

208
00:13:00,170 --> 00:13:03,606
Usually you would not have any vendor lock in, right? You would decide exactly how

209
00:13:03,628 --> 00:13:07,474
you can run it, even if you need to switch cloud providers.

210
00:13:07,602 --> 00:13:10,760
I think because you own the software and the platform itself,

211
00:13:11,150 --> 00:13:14,666
you will just need to pay for the infrastructure if you're not running in

212
00:13:14,688 --> 00:13:17,738
your own data center and it's customized to your needs.

213
00:13:17,824 --> 00:13:20,954
So at least initially you would feel like

214
00:13:20,992 --> 00:13:24,254
this is the perfect solution because you makes that solution for

215
00:13:24,292 --> 00:13:28,382
the problem at hand. But some of the cons are

216
00:13:28,436 --> 00:13:32,526
it's expensive. So although bit might be less expensive because you

217
00:13:32,548 --> 00:13:36,158
are not paying for the service itself, but the engineering

218
00:13:36,174 --> 00:13:39,490
hour you would spend in building something ground up like this

219
00:13:39,640 --> 00:13:42,978
would be pretty expensive over time to manage. And you are on

220
00:13:42,984 --> 00:13:46,082
these hook if something goes wrong. This is a service you made.

221
00:13:46,136 --> 00:13:49,046
You have to make sure it is up to date with the latest things.

222
00:13:49,148 --> 00:13:52,614
And as things change, things progress. You will have to have

223
00:13:52,652 --> 00:13:55,782
a continuous upkeep of engineering hours to make sure

224
00:13:55,836 --> 00:13:59,746
this thing is like up to date. So as time passes,

225
00:13:59,858 --> 00:14:03,658
a platform becomes harder and harder to manage because you've built a

226
00:14:03,664 --> 00:14:07,606
platform to do some machine learning for your business, you end up managing the machine

227
00:14:07,638 --> 00:14:11,102
learning platform and now you don't have time to maintain your business.

228
00:14:11,236 --> 00:14:15,834
So there are some difficulty with DIY

229
00:14:15,962 --> 00:14:19,806
as well. Now let's take a step back and think what

230
00:14:19,828 --> 00:14:23,646
we would want from a perfect machine learning platform. End to

231
00:14:23,668 --> 00:14:27,294
end machine learning platform. Right? So number one is bit should be built on scalable

232
00:14:27,342 --> 00:14:30,706
infrastructure. It should be something that can scale to whatever we

233
00:14:30,728 --> 00:14:34,194
need it to scale to. It should use existing tools data

234
00:14:34,232 --> 00:14:38,098
scientists already use. So we don't want to make sure we create something

235
00:14:38,264 --> 00:14:41,734
so new that our data scientists have to have a huge learning curve and learn

236
00:14:41,772 --> 00:14:45,126
new things. Again, ideally, and at least in my

237
00:14:45,148 --> 00:14:48,550
opinion, should be open source so we know the community itself is

238
00:14:48,620 --> 00:14:52,266
improving and taking these project forward that we use, that we

239
00:14:52,288 --> 00:14:56,154
depend on, supported by the industry. We want to make sure that

240
00:14:56,272 --> 00:14:59,754
not only we're not the only person using it, that's good

241
00:14:59,792 --> 00:15:03,680
for us to get long term support. Also it's good for us to get

242
00:15:04,050 --> 00:15:07,630
long teams talent that knows these tools,

243
00:15:07,970 --> 00:15:11,406
enterprise support options. So of course you should

244
00:15:11,428 --> 00:15:15,006
have the option to DYI but DIY, but you

245
00:15:15,028 --> 00:15:18,882
also want to make sure that even when you are ready to

246
00:15:19,016 --> 00:15:22,450
go to the route of, I want to just pay some company

247
00:15:22,520 --> 00:15:26,226
to deal with some of the management issues, you want to have that

248
00:15:26,248 --> 00:15:29,090
as well. And finally, it should be portable.

249
00:15:29,170 --> 00:15:32,946
Your machine learning models near code should be portable for you to take anywhere

250
00:15:33,058 --> 00:15:36,342
you want to take it. Well, a lot of the things,

251
00:15:36,396 --> 00:15:40,870
and again, I probably gave it away early on, is this QFlow?

252
00:15:40,950 --> 00:15:45,210
Is Qflow the tool that covers all of these end to end machine learning

253
00:15:45,360 --> 00:15:49,274
needs that we have. And I would like to think that is

254
00:15:49,312 --> 00:15:53,014
bit right now we're going to talk about how QFlow

255
00:15:53,062 --> 00:15:56,654
fits all of this criteria that I want to have in my

256
00:15:56,692 --> 00:16:00,506
end to end machine learning platform. So it's an open source project that contains

257
00:16:00,538 --> 00:16:04,514
a curated set of tools and frameworks for machine learning workflows on

258
00:16:04,552 --> 00:16:08,274
kubernetes. And these Kubernetes is a keyword here because that

259
00:16:08,312 --> 00:16:11,986
kind of gives us a bunch of the

260
00:16:12,008 --> 00:16:15,300
features that we see here. So because it's running on.

261
00:16:16,310 --> 00:16:20,210
So Qflow is scalable, composable, portable, is open source,

262
00:16:20,290 --> 00:16:23,366
is industry supported and it's multitenant. So you can

263
00:16:23,388 --> 00:16:26,790
have the same Qflow environment you can use for the entire

264
00:16:26,860 --> 00:16:30,442
team, give them individual spaces and so you can run your

265
00:16:30,496 --> 00:16:33,818
experiments in an environment that is going to

266
00:16:33,824 --> 00:16:37,206
be very close to what your final destination

267
00:16:37,238 --> 00:16:40,310
of that product or project is. So scalable,

268
00:16:40,390 --> 00:16:43,566
it's built on top of kubernetes so scalability is built in,

269
00:16:43,668 --> 00:16:47,454
you can get scalability of the pods. You can also get the scalability of

270
00:16:47,492 --> 00:16:51,194
nodes. So depending on your installation

271
00:16:51,242 --> 00:16:55,390
of kubernetes, if you are doing it yourself or using a managed kubernetes,

272
00:16:55,550 --> 00:17:00,062
you can scale your Kubernetes to any number of pods

273
00:17:00,206 --> 00:17:03,634
to some reasonable amount. And also because it's built

274
00:17:03,672 --> 00:17:07,682
on top of kubernetes and Kubernetes has existing

275
00:17:07,746 --> 00:17:10,914
pool of skilled

276
00:17:11,042 --> 00:17:14,726
individuals that knows how the infrastructure works.

277
00:17:14,828 --> 00:17:18,486
So either you already are using kubernetes for other

278
00:17:18,508 --> 00:17:22,394
things in your company, or it is fairly easy to find folks with

279
00:17:22,432 --> 00:17:26,442
skills on kubernetes. So you can also think of using

280
00:17:26,496 --> 00:17:30,122
kubernetes as a means of scaling your teams that needs

281
00:17:30,176 --> 00:17:33,958
to use this platform, right. You can easily find talent rather than if

282
00:17:33,984 --> 00:17:37,198
you are building something very custom in house, you would have a

283
00:17:37,204 --> 00:17:40,826
harder time finding people that just knows these system. You have to hire

284
00:17:40,858 --> 00:17:44,066
someone, train these on the system. So you're spending a lot

285
00:17:44,088 --> 00:17:48,098
of cycles on building skills up where in

286
00:17:48,264 --> 00:17:52,510
this system you already have people that just know kubernetes

287
00:17:52,590 --> 00:17:56,486
already. And also hopefully by virtue of Qflow being an

288
00:17:56,508 --> 00:18:00,134
open source project, a lot of people would also know Qflow was a system

289
00:18:00,332 --> 00:18:03,110
composed. So going back to this slide,

290
00:18:03,530 --> 00:18:07,126
Qflow has ways to manage each

291
00:18:07,148 --> 00:18:11,026
of those steps by using different tools

292
00:18:11,218 --> 00:18:13,530
under the Qflow ecosystem.

293
00:18:14,030 --> 00:18:16,380
So we're going to look at a few of these today.

294
00:18:17,230 --> 00:18:21,402
But composable basically means you can use different

295
00:18:21,456 --> 00:18:25,230
parts of the tools under Kubeflow to kind of create this

296
00:18:25,300 --> 00:18:28,766
system that covers all of these things that we want in an

297
00:18:28,788 --> 00:18:33,150
end to end machine learning platform, portable. So Kubeflow,

298
00:18:33,570 --> 00:18:36,782
you can use Kubeflow from local to training environment,

299
00:18:36,846 --> 00:18:40,562
or from training environment to cloud, or from cloud to cloud.

300
00:18:40,696 --> 00:18:44,226
And your environment of Qflow underneath stays pretty much

301
00:18:44,248 --> 00:18:48,078
the same. We like to think that when you're running experiments

302
00:18:48,094 --> 00:18:51,334
on your local machine versus when you're running your training versus when you're running

303
00:18:51,372 --> 00:18:54,806
your cloud deployment, it kind of looks the same, right? Like this is

304
00:18:54,828 --> 00:18:58,710
what we want to happen. But usually what ends up happening is that

305
00:18:58,860 --> 00:19:02,666
our experiment environment is much smaller in scope. We are

306
00:19:02,688 --> 00:19:06,134
just like running maybe a Jupyter notebook or one Python

307
00:19:06,182 --> 00:19:09,530
file. Then in our training environment we are running that,

308
00:19:09,600 --> 00:19:13,510
but in a much beefier machine with GPU and other resources.

309
00:19:13,670 --> 00:19:17,486
Finally we go to cloud. Now we are dealing with a

310
00:19:17,508 --> 00:19:20,906
lot more things like we are dealing with IBM permissions, we are dealing with models,

311
00:19:20,938 --> 00:19:24,606
we are dealing with canary deployment, rollback rollouts.

312
00:19:24,798 --> 00:19:28,786
So our environments ends up looking a lot different when

313
00:19:28,808 --> 00:19:32,306
you are just like doing it ourselves. And although we would like

314
00:19:32,328 --> 00:19:35,890
to think like, okay, we have deployed it ourselves

315
00:19:36,050 --> 00:19:38,934
and we have tested it, the model works,

316
00:19:39,132 --> 00:19:42,690
but every single minor differences in each of our environment

317
00:19:42,770 --> 00:19:46,360
would end up leading us to getting into some

318
00:19:46,890 --> 00:19:51,242
outages, right? Because we probably haven't covered the

319
00:19:51,296 --> 00:19:54,726
differences between our experiment stage versus our staging,

320
00:19:54,838 --> 00:19:58,374
versus our staging and our cloud. And each of those differences

321
00:19:58,422 --> 00:20:01,114
ends up turning into something bigger later on,

322
00:20:01,232 --> 00:20:04,766
because machine learning is no longer a novelty. Machine learning is a core part of

323
00:20:04,788 --> 00:20:08,254
our business, and machine learning is no longer just

324
00:20:08,292 --> 00:20:12,474
research. Right? We have to use machine learning now, get true

325
00:20:12,532 --> 00:20:16,850
insight into our business to be able to stay ahead of the curve.

326
00:20:17,350 --> 00:20:21,954
So machine learning used to be something that you used almost

327
00:20:22,072 --> 00:20:25,074
as like getting can advantage before.

328
00:20:25,192 --> 00:20:28,966
Now machine learning is what you have to use to stay with the

329
00:20:28,988 --> 00:20:32,258
curve, because everyone else is using it too. So it's

330
00:20:32,274 --> 00:20:35,922
part of the core business. We quality control our software.

331
00:20:35,986 --> 00:20:39,046
We make sure that our software is not regressing from version to

332
00:20:39,068 --> 00:20:42,838
version. Then we need to actually quality control our machine learning artifacts

333
00:20:42,854 --> 00:20:46,074
as well. We can't just build the model on our

334
00:20:46,112 --> 00:20:49,686
local laptop and just deploy it into production just by copying

335
00:20:49,718 --> 00:20:50,860
some files over.

336
00:20:53,070 --> 00:20:56,782
That's not how we do software, and that's not how we can do machine learning

337
00:20:56,836 --> 00:21:00,714
either. So with Qflow, you can have a local environment

338
00:21:00,762 --> 00:21:04,818
of Qflow just in your laptop, or in a dev

339
00:21:04,904 --> 00:21:08,878
Kubernetes cluster somewhere. You could have a training environment with GPU

340
00:21:08,974 --> 00:21:13,954
also running Qflow. And finally, you can have the

341
00:21:14,072 --> 00:21:17,606
deployment Qflow also in the cloud. And now you

342
00:21:17,628 --> 00:21:21,126
have kind of limited the number of differences between your

343
00:21:21,228 --> 00:21:25,062
experiment, training and cloud environments because all of them are underneath using

344
00:21:25,116 --> 00:21:28,934
Qflow. So this makes your environment pretty identical

345
00:21:28,982 --> 00:21:32,570
to each other, and thus making your environment portable.

346
00:21:32,990 --> 00:21:36,362
These are some of the Kubeflow components we usually talk about.

347
00:21:36,416 --> 00:21:39,974
So first of all, you have the platforms,

348
00:21:40,022 --> 00:21:43,274
you have your clouds. It could be on Prem Kubernetes, or local

349
00:21:43,312 --> 00:21:46,334
Kubernetes, or any of the cloud providers. On top of that,

350
00:21:46,372 --> 00:21:49,626
you have Qflow application. There are a lot of names

351
00:21:49,658 --> 00:21:52,862
here. We're not going to be deploying, talking about all of them today.

352
00:21:52,996 --> 00:21:56,274
But some of the key things are here. We have

353
00:21:56,392 --> 00:22:00,414
istio as the network layer. We have Argo or Tecton as pipelines.

354
00:22:00,462 --> 00:22:04,018
So if you want to build Qflow pipelines, you use one of

355
00:22:04,024 --> 00:22:07,202
those things for machine learning tools. You have Jupyter notebook,

356
00:22:07,266 --> 00:22:11,026
MPi, Mxnet, Tensorflow, Pytorch, xgboost,

357
00:22:11,058 --> 00:22:14,230
and all these other things. So another

358
00:22:14,300 --> 00:22:17,554
view of the components. The very first thing we have on Kubeflow is a dashboard

359
00:22:17,602 --> 00:22:21,078
that lets us look at all the things that are on our Qflow

360
00:22:21,094 --> 00:22:25,194
environment right now. Next we have Jupyter notebooks and as

361
00:22:25,232 --> 00:22:28,806
of the latest version of Qflow, we have also a bunch

362
00:22:28,838 --> 00:22:32,874
of other server there as well like code server or RStudio.

363
00:22:33,002 --> 00:22:36,506
We have some of the machine learning frameworks like Tensorflow, Xgboost,

364
00:22:36,538 --> 00:22:40,222
Pytorch. For pipelines we have choice of Tecton or

365
00:22:40,276 --> 00:22:43,806
Argo. For serving we have seldon or we

366
00:22:43,828 --> 00:22:47,626
have KF serving. For machine learning metadata

367
00:22:47,658 --> 00:22:51,102
we have MLMD. For feature store we can use fist

368
00:22:51,166 --> 00:22:53,886
and for monitoring because it's running on top of istio,

369
00:22:53,998 --> 00:22:57,614
we can make use of Prometheus and grafana dashboards.

370
00:22:57,662 --> 00:23:00,822
Look at what's happening in a cluster as well as monitoring other

371
00:23:00,876 --> 00:23:04,518
models as the traffic routing is happening. So if

372
00:23:04,524 --> 00:23:07,734
you want to deploy Kubeflow today, you can head to

373
00:23:07,772 --> 00:23:11,626
the manifest repository and you can use customize and

374
00:23:11,648 --> 00:23:15,066
kubectl. That's the latest, most recent instruction on how

375
00:23:15,088 --> 00:23:18,602
to install Kubeflow and you can use that to install

376
00:23:18,656 --> 00:23:22,590
Kubeflow on your Kubernetes cluster or your local machine and mini cube.

377
00:23:23,570 --> 00:23:27,166
So manifest repository is structured in a way now

378
00:23:27,268 --> 00:23:30,766
where it's easy to kind of find what are the extra apps, what are the

379
00:23:30,788 --> 00:23:33,966
components common things in Kubeflow and what are the contribution from

380
00:23:33,988 --> 00:23:37,842
the community to Kubeflow. Back in about

381
00:23:37,896 --> 00:23:41,506
two weeks ago, when one two release was the main release of

382
00:23:41,608 --> 00:23:45,074
Kubeflow, the repository was a little bit more

383
00:23:45,192 --> 00:23:48,934
clusters. We had a lot more things on the top level so it was difficult

384
00:23:49,052 --> 00:23:52,674
to navigate. But with the new one, these release, we have improved

385
00:23:52,722 --> 00:23:56,006
some of the Kubeflow deployment strategy by changing up

386
00:23:56,028 --> 00:23:59,654
the order of the repository. So again, if you looked

387
00:23:59,692 --> 00:24:03,210
at Kubeflow before, this is what it used to look like. On the left,

388
00:24:03,280 --> 00:24:07,082
the structure. With the latest release we kind of went

389
00:24:07,136 --> 00:24:10,746
through and changed many of the structure by restructuring the

390
00:24:10,768 --> 00:24:14,974
things around. It still does the same exact thing, but it's just restructured to

391
00:24:15,012 --> 00:24:18,206
do things a little bit more cleaner. So how can this

392
00:24:18,228 --> 00:24:21,754
help? So goal is to improve accountability for maintaining components.

393
00:24:21,802 --> 00:24:24,990
Manifests increase modularity. You can pick and choose

394
00:24:25,060 --> 00:24:28,386
the tools you want to install pretty easily and we want to make sure the

395
00:24:28,408 --> 00:24:31,890
deployment experience is smoother. So first time users,

396
00:24:32,390 --> 00:24:35,586
you should have a much smoother experience. If you had tried

397
00:24:35,688 --> 00:24:39,570
Kubeflow in can earlier time, you can also users Kubeflow operator.

398
00:24:39,650 --> 00:24:43,190
So you have the operator that you can make use of and operator

399
00:24:43,930 --> 00:24:47,126
Kubernetes operator is built so

400
00:24:47,148 --> 00:24:50,890
that we have an easier time deploying Kubernetes resources.

401
00:24:51,230 --> 00:24:54,410
Again, I'm going to just skip through the operator part for a second,

402
00:24:54,480 --> 00:24:58,678
because you can use the Qflow operator to deploy

403
00:24:58,854 --> 00:25:02,862
Qflow to Kubernetes or Openshift, and you have documentation here

404
00:25:02,916 --> 00:25:07,018
about it here. But one thing I want to mention, Kubernetes Kubeflow

405
00:25:07,034 --> 00:25:10,058
is an open source project and it's not all sunshine and rainbows.

406
00:25:10,154 --> 00:25:13,534
Some of these difficulty with Qflow is that because it's open

407
00:25:13,572 --> 00:25:17,860
source and it's rapidly growing, there are definitely growing pains that we see

408
00:25:18,390 --> 00:25:21,794
because underlying components that are a bunch of them are also

409
00:25:21,832 --> 00:25:25,074
open source and have their own release cycle. So you have some challenges these,

410
00:25:25,112 --> 00:25:28,366
right, Qflow has many moving parts, each component has their own release

411
00:25:28,398 --> 00:25:31,682
cycle and upgrade path. So as a Qflow,

412
00:25:31,826 --> 00:25:35,122
if you're maintaining Qflow as a distribution

413
00:25:35,266 --> 00:25:38,680
for your company, it is going to be something,

414
00:25:39,290 --> 00:25:42,554
at least at this point. It's quite a big challenge right now.

415
00:25:42,592 --> 00:25:46,522
And we are as the Kubeflow team trying very hard to make sure

416
00:25:46,656 --> 00:25:50,586
that doesn't usually happen. And for the most part, as an individual

417
00:25:50,688 --> 00:25:54,220
end user of Kubeflow, you don't really see a lot of these problems,

418
00:25:54,770 --> 00:25:57,390
but as a maintaining, we see that quite a lot.

419
00:25:57,460 --> 00:26:01,246
Where underlying component is updating, we have to update all of that to

420
00:26:01,268 --> 00:26:04,626
make sure we're in the latest version and we're using the greatest and

421
00:26:04,648 --> 00:26:08,386
the latest changes into these underlying changes. So each

422
00:26:08,408 --> 00:26:11,762
of EE EE EE Ee ML platform kubernetes using

423
00:26:11,816 --> 00:26:15,070
from Azure, from IBM, from AWS, from GCP,

424
00:26:15,230 --> 00:26:20,066
each of them has small differences that kind of add up into the overarching

425
00:26:20,258 --> 00:26:24,018
Qflow deployment. So if you are using Qflow

426
00:26:24,034 --> 00:26:28,006
on miniq versus you want to move your Qflow deployment to AWS per

427
00:26:28,028 --> 00:26:31,914
se, it might not be the exact one to one change as

428
00:26:31,952 --> 00:26:35,370
we like it to happen, but for the most part it is still

429
00:26:35,440 --> 00:26:39,494
very similar to how you would use Qflow

430
00:26:39,542 --> 00:26:42,538
on your local machine versus on cloud the future.

431
00:26:42,624 --> 00:26:46,686
So the Qflow under three, well, I'm saying will, here it

432
00:26:46,708 --> 00:26:50,206
is already here. It already released about one week ago. And all the

433
00:26:50,228 --> 00:26:53,514
distributions like IBM and AWS and GCP

434
00:26:53,562 --> 00:26:57,294
right now are testing to validate that it works on the newest

435
00:26:57,342 --> 00:27:00,514
release. So if you are looking at Qflow in about

436
00:27:00,552 --> 00:27:03,762
a week's time, you should be able to go and users the

437
00:27:03,816 --> 00:27:06,500
one three Qflow on your favorite cloud platform.

438
00:27:06,890 --> 00:27:10,626
And because the manifest repo is being restructured, it's much easier

439
00:27:10,658 --> 00:27:14,406
to navigate. Okay, so some of

440
00:27:14,428 --> 00:27:18,534
the references, if you want to try out Qflow, please go to Qflow manifest and

441
00:27:18,572 --> 00:27:22,310
if you want to join the community for the slack for other mailing lists

442
00:27:22,390 --> 00:27:27,338
you should go to community and

443
00:27:27,424 --> 00:27:31,006
you can learn more about the operator framework and how operator QFlow operator can

444
00:27:31,028 --> 00:27:33,950
improve our quality of installing Qflow.

445
00:27:34,370 --> 00:27:38,238
But before we finish, I want to quickly show you the

446
00:27:38,324 --> 00:27:41,786
Qflow environment. So I have a Kubeflow deployment

447
00:27:41,818 --> 00:27:45,502
on IBM cloud and I'm using app id as authentication mechanism.

448
00:27:45,646 --> 00:27:48,946
By default, Qflow comes with Dex as an

449
00:27:48,968 --> 00:27:52,830
authentication. So IBM authenticating against the Kubeflow environment.

450
00:27:52,990 --> 00:27:56,434
And once I have authenticated I would be here into

451
00:27:56,472 --> 00:28:00,054
my Kubeflow. This is a Kubeflow dashboard you would see for the first time you

452
00:28:00,172 --> 00:28:03,826
come into and on the left side you can see some of the tools Kubeflow

453
00:28:03,858 --> 00:28:06,950
has and I have some of the notebooks created and

454
00:28:07,020 --> 00:28:10,106
the notebook servers as of Kubeflow under three. As we said,

455
00:28:10,128 --> 00:28:13,754
we have the VS code code space here

456
00:28:13,872 --> 00:28:18,300
as well as rstudio as well as node Jupiter lab here.

457
00:28:19,150 --> 00:28:22,686
And this is namespaced by pari user. So right now

458
00:28:22,788 --> 00:28:26,174
I am logged in as my email here. I can also log in

459
00:28:26,212 --> 00:28:29,870
with a different email account with my Google.

460
00:28:29,940 --> 00:28:33,614
So once I do this, once I log in, it will ask me to create

461
00:28:33,652 --> 00:28:36,986
a new namespace. And once I do that, now I

462
00:28:37,028 --> 00:28:40,450
am on the same cluster, IBM a different namespace now.

463
00:28:40,520 --> 00:28:43,826
So if I go to notebooks, the other notebooks was for the other user and

464
00:28:43,848 --> 00:28:47,554
they're not these. So on the same kubernetes cluster you could have multiple

465
00:28:47,602 --> 00:28:51,462
of the team members working simultaneously together next to each other.

466
00:28:51,596 --> 00:28:56,406
I'll actually go back to the other user because I had something

467
00:28:56,508 --> 00:29:00,300
smosh to show on that other user. These I would also have

468
00:29:00,910 --> 00:29:04,746
experiments that I can run. So I have run one experiment, it's a

469
00:29:04,768 --> 00:29:08,086
simple pipeline and this does like a coin flip

470
00:29:08,118 --> 00:29:11,206
and test condition based on something. You can define

471
00:29:11,238 --> 00:29:14,734
your pipelines using a Python DSL and it will

472
00:29:14,772 --> 00:29:18,160
run that pipeline was KFP tecton. You can use that

473
00:29:19,010 --> 00:29:22,526
to build your model and then users KF serving to serve that model

474
00:29:22,628 --> 00:29:26,846
and get the full pipeline of data ingestion, data validation

475
00:29:26,958 --> 00:29:30,942
and these create the model, then serve the model and then use istio

476
00:29:31,006 --> 00:29:34,638
to monitor the information as your traffic gets routed

477
00:29:34,654 --> 00:29:38,370
to your model and traffic gets served by the model.

478
00:29:38,520 --> 00:29:41,910
You also have CaDb for hyperparameter optimization.

479
00:29:42,330 --> 00:29:45,446
If you want to do some of that, you have that option as

480
00:29:45,468 --> 00:29:48,774
well. We also have Pytorch, Mxnet and

481
00:29:48,812 --> 00:29:52,534
Xgboost installed in this. So in pipelines we can make use

482
00:29:52,572 --> 00:29:56,182
of those platforms to build

483
00:29:56,236 --> 00:30:00,030
our models in many ways. Thank you so much for joining me in

484
00:30:00,060 --> 00:30:03,326
this session. If you have any more questions, would like to learn more,

485
00:30:03,428 --> 00:30:07,562
you can go to qflow.org to learn more about qflow and get started with Qflow.

486
00:30:07,626 --> 00:30:11,354
If you have any question to me, you can reach out to me at codes

487
00:30:11,402 --> 00:30:14,202
at any of the social media. It's at codes.

488
00:30:14,266 --> 00:30:18,000
So thank you once again to the conference organizers for giving me this opportunity.

489
00:30:18,450 --> 00:30:20,780
With that, I thank you all. And until next time.

