1
00:00:25,410 --> 00:00:29,186
You. Hello everyone. I am very excited

2
00:00:29,218 --> 00:00:33,046
to talk about the hidden cost of the instrumentation at Conf 42

3
00:00:33,068 --> 00:00:36,354
DevOps 2023. My name is Prathamesh Sonpatki.

4
00:00:36,402 --> 00:00:39,846
I work at Lastnet IO as the developer, evangelist and

5
00:00:39,868 --> 00:00:43,282
the software engineer at Lastnet. We build SRE tools

6
00:00:43,346 --> 00:00:47,270
to provide visibility into Rube Goldberg of microservices

7
00:00:47,770 --> 00:00:51,422
and let's get started. So. So my first question

8
00:00:51,476 --> 00:00:55,118
is, why do we even have to care about the instrumentation? Can we

9
00:00:55,124 --> 00:00:58,926
not just ship our software to cloud and enjoy, just relax and

10
00:00:58,948 --> 00:01:02,654
chill? But that's not always the case, right? How do we even know

11
00:01:02,692 --> 00:01:06,434
that our application is running as expected? We may also have

12
00:01:06,472 --> 00:01:10,066
some customer level, service level agreements that we are committed to,

13
00:01:10,168 --> 00:01:13,410
and we may have to even give them pros that our system

14
00:01:13,480 --> 00:01:16,962
is working as expected. Even for giving that proof,

15
00:01:17,026 --> 00:01:20,406
we ourselves need to have some information about how the system is

16
00:01:20,428 --> 00:01:24,326
running. Additionally, as SREs and DevOps people,

17
00:01:24,428 --> 00:01:28,478
we also need good night's sleep. We cannot be always staring

18
00:01:28,514 --> 00:01:32,282
at our screens and debugging the information to see

19
00:01:32,336 --> 00:01:36,198
if something is even working as expected. So all of these factors

20
00:01:36,294 --> 00:01:40,086
contribute to the fact that modern software systems definitely

21
00:01:40,208 --> 00:01:44,030
need some sort of instrumentation to even know that things are working

22
00:01:44,100 --> 00:01:47,034
fine. Hope cannot be the strategy.

23
00:01:47,082 --> 00:01:50,702
As the Google SRE Bible says,

24
00:01:50,836 --> 00:01:54,454
we cannot just hope that everything is working has expected.

25
00:01:54,602 --> 00:01:58,430
We need to make sure that we take conscious efforts into measuring

26
00:01:58,510 --> 00:02:01,470
and then making sure that things are working as expected.

27
00:02:01,630 --> 00:02:05,654
So the reliability mandate basically starts with instrumenting as

28
00:02:05,692 --> 00:02:09,078
its first step, because we can only improve what

29
00:02:09,084 --> 00:02:12,774
we measure, right? We cannot even understand

30
00:02:12,892 --> 00:02:17,494
how the system is behaving if we don't measure what

31
00:02:17,532 --> 00:02:20,570
we want to measure in our software systems.

32
00:02:21,070 --> 00:02:24,854
Let's go over the landscape of the instrumentation, because modern software

33
00:02:24,902 --> 00:02:28,154
systems are very complicated. They are not

34
00:02:28,192 --> 00:02:31,818
just like our standalone application that is running on a server

35
00:02:31,914 --> 00:02:35,326
or a vm. And that's the only thing

36
00:02:35,348 --> 00:02:39,178
that is running, right. What we have is actually a burger

37
00:02:39,354 --> 00:02:42,110
because our application is like a patty,

38
00:02:42,450 --> 00:02:46,466
which is running inside the bun and that, but we

39
00:02:46,488 --> 00:02:50,114
can consider it as a cloud or a virtual machine. So there are

40
00:02:50,152 --> 00:02:52,510
variants of buns like AWS,

41
00:02:52,590 --> 00:02:56,360
TCP, Azure, and then the patty is where the

42
00:02:56,730 --> 00:02:59,480
real magic resides, which is our application.

43
00:02:59,930 --> 00:03:03,666
We throw in some mayo sauce, some external services, data stores

44
00:03:03,698 --> 00:03:06,914
as rdss and databases, along with some ketchups,

45
00:03:06,962 --> 00:03:09,942
fries and everything. And then we get a burger.

46
00:03:10,086 --> 00:03:13,546
So sometimes also, this is not just a single budget that we

47
00:03:13,568 --> 00:03:17,450
have. We may also have multiple burgers at the same time because

48
00:03:17,520 --> 00:03:20,838
our system can have different microservices talking to

49
00:03:20,864 --> 00:03:24,014
each other has, well as some other services. So this is how

50
00:03:24,052 --> 00:03:27,502
generally the landscape of the modern software systems looks

51
00:03:27,556 --> 00:03:30,942
like. So we basically deal

52
00:03:30,996 --> 00:03:34,706
with burgers every day. We may not eat them, but we have to

53
00:03:34,728 --> 00:03:38,578
at least run with them all the time. So this

54
00:03:38,584 --> 00:03:42,530
is where we lead into the rabbit hole of the full stack observability,

55
00:03:42,870 --> 00:03:46,962
because just the monitoring of the application will

56
00:03:47,016 --> 00:03:50,726
give the insights very specific to the application. But we

57
00:03:50,748 --> 00:03:54,690
may not know that some requests are getting dropped at our load balancer layer

58
00:03:54,770 --> 00:03:58,842
or our database. Read I ops and write I ops are constantly below

59
00:03:58,896 --> 00:04:02,106
the required threshold. So for knowing that,

60
00:04:02,208 --> 00:04:05,446
we need to take a cut across the burger

61
00:04:05,558 --> 00:04:09,146
and monitor all the components together so

62
00:04:09,168 --> 00:04:12,746
that we get better insights. So modern software applications,

63
00:04:12,778 --> 00:04:16,126
I like to call them, has living organisms that grow and

64
00:04:16,148 --> 00:04:19,370
shrink in all possible directions. Grow and shrink

65
00:04:19,450 --> 00:04:23,410
specifically because of the auto scaling and scaling constraints.

66
00:04:24,070 --> 00:04:27,682
We do have ephemeral infrastructure that comes into

67
00:04:27,736 --> 00:04:30,900
existence and then goes away when it is not needed.

68
00:04:32,230 --> 00:04:35,934
Another interesting point is that the applications also communicate

69
00:04:35,982 --> 00:04:39,174
with similar applications at the same time. So it's not just

70
00:04:39,212 --> 00:04:42,950
one application that we have to deal with, we have several of them

71
00:04:43,020 --> 00:04:46,280
talking and chatting with each other all the time.

72
00:04:46,810 --> 00:04:49,946
So basically how do we monitor them? Right. The only option that

73
00:04:49,968 --> 00:04:55,002
we have is basically we have this temple of observability that

74
00:04:55,136 --> 00:04:59,126
is there and we have to just bow in that temple of observability

75
00:04:59,318 --> 00:05:03,502
to make sure that everything is getting instrumenting. Generally the

76
00:05:03,556 --> 00:05:06,814
standard pillars of observability are logs, metrics and

77
00:05:06,852 --> 00:05:10,830
traces. Logs help us debug a root cause very quickly.

78
00:05:10,980 --> 00:05:14,722
They can be structured versus unstructured depending on whether

79
00:05:14,776 --> 00:05:18,094
they are like debug logs versus request scope logs,

80
00:05:18,222 --> 00:05:21,426
but they are very easy to adopt with, right. So we can

81
00:05:21,448 --> 00:05:25,490
throw in standard libraries for logging as well as

82
00:05:25,640 --> 00:05:29,446
components such as NgInx. Load balancers have standard formats for

83
00:05:29,468 --> 00:05:33,186
logging, so the adoption is extremely easy. Consistency is slightly

84
00:05:33,218 --> 00:05:36,694
tricky because every microservice and every system can have

85
00:05:36,732 --> 00:05:40,714
their own format of logging. So not necessarily you will always be able

86
00:05:40,752 --> 00:05:44,700
to have the same consistency across all services,

87
00:05:45,230 --> 00:05:48,778
whereas metrics, they are specifically giving you

88
00:05:48,864 --> 00:05:52,510
the aggregate information about how system is behaving.

89
00:05:53,330 --> 00:05:56,606
You can get a better overview of overall how

90
00:05:56,628 --> 00:05:59,822
the system is behaving using metrics and

91
00:05:59,956 --> 00:06:03,682
in case of metrics. Also there are standard tools and libraries that one can

92
00:06:03,736 --> 00:06:07,538
use for the adoption part. Adoption of

93
00:06:07,544 --> 00:06:10,946
metrics is also easy because of the proliferation of

94
00:06:10,968 --> 00:06:15,226
different tools that one can use, and also they provide certain consistency

95
00:06:15,358 --> 00:06:18,870
because of standards like open telemetry, open metrics

96
00:06:19,210 --> 00:06:22,982
that people can use. So adoption and consistency. Both are

97
00:06:23,036 --> 00:06:27,298
kind of consistent in case of metrics, whereas traces

98
00:06:27,394 --> 00:06:30,842
are helpful in case of when we want to monitoring different

99
00:06:30,896 --> 00:06:34,342
workflows. So for example, I may want to trace

100
00:06:34,406 --> 00:06:38,774
my payment transaction starting from my microservice

101
00:06:38,822 --> 00:06:42,830
where the user authentication happens to the background queue where actually

102
00:06:42,900 --> 00:06:46,206
the job gets processed for sending the notification that

103
00:06:46,228 --> 00:06:49,674
the payment was successful or unsuccessful. So in case of traces,

104
00:06:49,722 --> 00:06:53,158
I'm mostly concerned about monitoring the workflows.

105
00:06:53,274 --> 00:06:57,470
And to do that, what I do is I insert one span

106
00:06:57,630 --> 00:07:00,786
or a trace id in all the pieces where I

107
00:07:00,808 --> 00:07:04,020
want to basically monitor it. Traces are

108
00:07:04,970 --> 00:07:08,514
extremely sharp and useful

109
00:07:08,562 --> 00:07:11,974
in such scenarios, but also they can have a lot

110
00:07:12,012 --> 00:07:14,840
of information getting emitted. Basically,

111
00:07:15,370 --> 00:07:18,682
if not handled correctly, it can turn but as like your

112
00:07:18,736 --> 00:07:22,234
debug, logs are running in production. So these are the original three

113
00:07:22,272 --> 00:07:25,722
pillars of observability. But additionally we also

114
00:07:25,776 --> 00:07:28,854
have profiling, external events and exceptions.

115
00:07:28,982 --> 00:07:32,222
And Yuri Shukuro has written an excellent post

116
00:07:32,276 --> 00:07:36,030
on these six pillars of observability. It's a great post.

117
00:07:36,180 --> 00:07:40,158
So profiling is basically the continuous profiling of our application

118
00:07:40,324 --> 00:07:44,034
to capture the runtime information about how the

119
00:07:44,072 --> 00:07:47,890
application is behaving, and that can also help us in

120
00:07:47,960 --> 00:07:50,740
debugging certain solutions when needed.

121
00:07:51,270 --> 00:07:54,994
Generally, the profiling, even if it happens continuously, we may not use

122
00:07:55,032 --> 00:07:59,266
it all the time. We may use it only when it

123
00:07:59,288 --> 00:08:02,518
is needed. So while enabling it, we also have to consider

124
00:08:02,604 --> 00:08:06,166
the overhead that it will put on our production systems because we may not

125
00:08:06,188 --> 00:08:09,722
be using it all the time like we'll be using probably two, three times a

126
00:08:09,776 --> 00:08:13,126
year or something like that. The external events are extremely

127
00:08:13,158 --> 00:08:16,090
important because they can affect the state of the application.

128
00:08:16,240 --> 00:08:20,590
So while logs metric statuses are internal information

129
00:08:20,740 --> 00:08:24,026
about how the application is behaving, external events

130
00:08:24,058 --> 00:08:28,030
such as deployments, configuration changes, third party changes

131
00:08:28,100 --> 00:08:32,838
such as your AWS, instances getting restarted or reprovisioned

132
00:08:32,874 --> 00:08:36,034
or something like that can also affect your

133
00:08:36,072 --> 00:08:39,986
running application. So tracing that and then provide

134
00:08:40,168 --> 00:08:43,986
making sure that they are also visible in

135
00:08:44,008 --> 00:08:47,894
terms of the overall visibility is extremely important.

136
00:08:48,092 --> 00:08:51,894
Another important part about the external events is they are

137
00:08:52,092 --> 00:08:55,814
extremely critical in certain cases and also

138
00:08:55,932 --> 00:08:59,862
not happening all the time, right? So in case of logs metrics,

139
00:09:00,006 --> 00:09:03,610
they are constantly happening, but external events are not happening in that

140
00:09:03,680 --> 00:09:07,174
same amount of number that will happen in case of logs

141
00:09:07,222 --> 00:09:10,826
versus metrics. So they need precision

142
00:09:10,858 --> 00:09:16,494
in capturing as well as storage when

143
00:09:16,532 --> 00:09:19,742
we deal with such events. Additionally, we also have

144
00:09:19,796 --> 00:09:23,374
exceptions which can probably go to tools like sentry

145
00:09:23,422 --> 00:09:27,074
and rollbar. This can be considered has

146
00:09:27,192 --> 00:09:30,642
an advanced version of structured logging only where we have

147
00:09:30,696 --> 00:09:34,274
tools such as sentry rollbar, giving us specific log lines and

148
00:09:34,312 --> 00:09:43,062
traces where we can go and debug the issues before

149
00:09:43,116 --> 00:09:46,294
going forward. I have a curious question. How many

150
00:09:46,332 --> 00:09:49,560
of us have used more than three at the same time?

151
00:09:49,930 --> 00:09:53,814
Because I have talked to a lot of people and what I realized

152
00:09:53,862 --> 00:09:57,690
is that depending on the use cases, we tend to pick up

153
00:09:57,840 --> 00:10:01,622
at least three to four of these at any point of time, but not necessarily

154
00:10:01,686 --> 00:10:05,678
all of them at the same time. So that is a very interesting

155
00:10:05,764 --> 00:10:09,194
conversation to have, whether we have folks

156
00:10:09,242 --> 00:10:13,122
who have used multiple types of days at the same time. But we

157
00:10:13,176 --> 00:10:17,074
do capture these kind of information in our

158
00:10:17,112 --> 00:10:20,882
instrumentation processes. The most

159
00:10:20,936 --> 00:10:24,306
important point to consider is that none of this

160
00:10:24,328 --> 00:10:27,922
is free, right? And when I say about the cost,

161
00:10:27,976 --> 00:10:32,034
it is not just about the monetary cost, but it also adds

162
00:10:32,082 --> 00:10:35,442
overhead to our runtimes. It also add overhead to our processes.

163
00:10:35,506 --> 00:10:39,606
So there is no such thing as free lunch even in case of instrumentation,

164
00:10:39,718 --> 00:10:43,786
and we have to pay the cost for different factors that

165
00:10:43,888 --> 00:10:47,962
we will see a bit later. The most important point

166
00:10:48,016 --> 00:10:51,850
that generally happens in case of instrumentation is the explosion of cardinality

167
00:10:51,930 --> 00:10:55,694
or the churn of the metrics and logs information. They keep changing all

168
00:10:55,732 --> 00:11:00,634
the time and that basically prevents

169
00:11:00,682 --> 00:11:03,874
us from just shipping it and sitting there.

170
00:11:03,912 --> 00:11:07,666
We always have to capture and monitor that the data is

171
00:11:07,688 --> 00:11:11,394
not getting out of control because

172
00:11:11,432 --> 00:11:15,106
of the cardinality explosion. To just

173
00:11:15,128 --> 00:11:18,966
give a simple example, three node Kubernetes cluster with Prometheus will

174
00:11:18,988 --> 00:11:22,246
basically ship 40k active series by default. And that

175
00:11:22,268 --> 00:11:25,446
is just the default metrics. If you want to emit some

176
00:11:25,468 --> 00:11:29,398
custom metrics then obviously it will even explode. With the ephemeral

177
00:11:29,494 --> 00:11:33,260
infrastructure this can go out of control very quickly.

178
00:11:34,430 --> 00:11:38,614
We also have to do the operations for running and operating this instrumentation

179
00:11:38,662 --> 00:11:41,994
of the entire stack. So this is one more thing to operate

180
00:11:42,042 --> 00:11:45,566
besides the application. We also have to run our application,

181
00:11:45,668 --> 00:11:48,890
but we also have to run our entire observability

182
00:11:48,970 --> 00:11:52,126
and instrumentation stack. And we also have

183
00:11:52,148 --> 00:11:55,742
to make sure that not just the app scales, but with the app, the instrumentation

184
00:11:55,806 --> 00:11:59,534
processes also scale. Because we cannot be blind on a new year's

185
00:11:59,582 --> 00:12:03,218
day for 4 hours or we cannot be blind before the

186
00:12:03,304 --> 00:12:05,620
streaming of the final match between.

187
00:12:06,970 --> 00:12:09,506
I'm from India, so I'll give an example of cricket,

188
00:12:09,618 --> 00:12:13,714
but we cannot be blind before the final of the cricket

189
00:12:13,762 --> 00:12:17,554
World cup between India and Pakistan. Just because our instrumentation

190
00:12:17,602 --> 00:12:20,890
is not able to scale. That can be a very bad

191
00:12:20,960 --> 00:12:24,300
thing, not just for the engineering but also for the business.

192
00:12:24,990 --> 00:12:28,602
All of this results into constant tuning of monitoring data,

193
00:12:28,656 --> 00:12:32,538
instrumentation data and results into lot of engineering toil

194
00:12:32,634 --> 00:12:36,734
that the engineering teams have to go through. So I give

195
00:12:36,772 --> 00:12:40,494
it an acronym as a cost. The cost that we have to pay is

196
00:12:40,532 --> 00:12:43,670
basically for cardinality churn operations,

197
00:12:43,770 --> 00:12:48,114
scale tuning and toil. And all of this just

198
00:12:48,152 --> 00:12:51,300
becomes the cost of the instrumentation that we have to pay.

199
00:12:51,910 --> 00:12:55,234
But what is the hidden cost? Right? These costs that

200
00:12:55,272 --> 00:12:59,142
we talked about are slightly apparent on their face. We are

201
00:12:59,276 --> 00:13:03,202
aware of these things as well. But what is the most hidden

202
00:13:03,266 --> 00:13:06,946
cost that is there in case of such instrumentation?

203
00:13:07,058 --> 00:13:10,582
It is actually the distraction. We always get distracted

204
00:13:10,646 --> 00:13:14,010
from doing the things that we actually wanted to do, which is

205
00:13:14,160 --> 00:13:17,642
our product engineering or scaling our business, or making

206
00:13:17,696 --> 00:13:20,758
sure that our customer experience is not impacted.

207
00:13:20,934 --> 00:13:24,622
How many times you have heard terms like, okay, can you just reduce the

208
00:13:24,756 --> 00:13:28,542
data dog monitoring cost before the next

209
00:13:28,596 --> 00:13:32,094
month? It is actually going out of hand. Please can you just stop

210
00:13:32,132 --> 00:13:36,174
your feature development and focus on getting this in control or

211
00:13:36,292 --> 00:13:39,298
our logs are piling up from last two days. Can you just look at it

212
00:13:39,304 --> 00:13:43,106
as a p zero item and please fix them? Otherwise our vendor will charge us

213
00:13:43,128 --> 00:13:46,946
double and if we don't do that, then we'll be spending too much

214
00:13:46,968 --> 00:13:50,694
amount of money unnecessarily. Today is New Year's Day tour.

215
00:13:50,732 --> 00:13:54,998
Prometheus is not getting required metrics. Can you just ignore the important

216
00:13:55,084 --> 00:13:59,094
feature and bug fixes that you are pushing? Just fix on this, because otherwise

217
00:13:59,142 --> 00:14:02,794
we are completely blind before the party starts. So we

218
00:14:02,832 --> 00:14:06,762
always hear these kind of things, and that causes us

219
00:14:06,816 --> 00:14:10,346
the distraction from our actual tasks that

220
00:14:10,368 --> 00:14:13,406
we want to do in our day to day life. We always get

221
00:14:13,428 --> 00:14:17,166
distracted by the instrumentation and the information that we

222
00:14:17,188 --> 00:14:20,766
are emitting and probably not even be using. Right? So we may

223
00:14:20,788 --> 00:14:24,298
be emitting so much amount of data, but only using 10% to 20% of

224
00:14:24,324 --> 00:14:28,354
it. So we do pay for the data, not just that

225
00:14:28,392 --> 00:14:32,340
we use, but we also pay for the data that we don't use,

226
00:14:33,350 --> 00:14:36,646
which is not really a good option to have. So the

227
00:14:36,668 --> 00:14:40,342
modern software systems engineer has to not just maintain their

228
00:14:40,396 --> 00:14:43,874
software, but also has to maintain instrumentation of that software

229
00:14:43,922 --> 00:14:45,990
as well, with the same rigor,

230
00:14:47,130 --> 00:14:50,666
with the same requirements of scaling and so

231
00:14:50,688 --> 00:14:54,666
on. It is also fatigue, right? With so much amount of

232
00:14:54,688 --> 00:14:57,510
data, so much dashboard, so much panels everywhere,

233
00:14:57,670 --> 00:15:01,102
so much logs in front of our eyes,

234
00:15:01,236 --> 00:15:04,480
we always get desensitized to the information.

235
00:15:04,850 --> 00:15:08,414
There can be duplicate alarms. How many times I have seen

236
00:15:08,452 --> 00:15:12,554
that while debugging a critical issue in production, we get confused

237
00:15:12,602 --> 00:15:16,466
because the logs shows two, three pictures at the same time,

238
00:15:16,568 --> 00:15:20,066
and some of the information that we see is not even getting used in the

239
00:15:20,088 --> 00:15:25,746
code. So there can be such situations where just

240
00:15:25,768 --> 00:15:29,650
the too much of information can cause us delays in debugging.

241
00:15:29,810 --> 00:15:33,942
So because we focus on getting the data out,

242
00:15:34,076 --> 00:15:37,880
because it is easier, we don't even consider

243
00:15:38,410 --> 00:15:41,946
why do we even need them in the first place. So these are some

244
00:15:41,968 --> 00:15:45,546
of the points that can cause fatigue with too much of the

245
00:15:45,568 --> 00:15:49,434
information. While we talk about all of this, and we

246
00:15:49,472 --> 00:15:52,598
sort of are used to these things, what's the way out?

247
00:15:52,624 --> 00:15:55,726
Let's discuss that. So, if we focus on the

248
00:15:55,748 --> 00:15:59,502
data that gives us only the early warnings with least

249
00:15:59,556 --> 00:16:02,366
amount of data, and this least amount of data is important,

250
00:16:02,548 --> 00:16:06,370
then probably we can just focus on the

251
00:16:06,440 --> 00:16:09,858
warnings and then based on that, dig deeper to isolate the

252
00:16:09,864 --> 00:16:13,026
root causes as and when needed. So I would

253
00:16:13,048 --> 00:16:16,820
like to give an analogy to the Apple Watch, which is

254
00:16:17,670 --> 00:16:21,174
on my wrist. But basically what Apple Watch does is it only

255
00:16:21,212 --> 00:16:25,014
gives me the vitals, such has heart rate, or how I'm doing with

256
00:16:25,052 --> 00:16:29,014
my sleep, or it gives me if I'm walking correctly every day

257
00:16:29,052 --> 00:16:31,994
and so on. So it just gives me the vitals that are needed, right.

258
00:16:32,032 --> 00:16:35,386
And based on that, I can decide to go to the doctor for detailed x

259
00:16:35,408 --> 00:16:39,050
ray scans and ECG reports and then decide

260
00:16:39,550 --> 00:16:42,794
whether to go further with my debugging or deep

261
00:16:42,842 --> 00:16:46,346
exploration. So while I get the vitals,

262
00:16:46,538 --> 00:16:49,818
if the vitals are off, I can go for the detailed

263
00:16:49,914 --> 00:16:54,186
information about why they are off. I don't debug

264
00:16:54,298 --> 00:16:57,182
and start with the x ray scans immediately,

265
00:16:57,326 --> 00:17:01,300
or I don't start with the ECG reports as the first step

266
00:17:01,750 --> 00:17:05,106
without even checking whether my vitals are off or

267
00:17:05,128 --> 00:17:08,774
not. So a threat or a warning of something breaking is

268
00:17:08,812 --> 00:17:12,006
always better because it can give me like an

269
00:17:12,028 --> 00:17:15,622
ample amount of time to at least either fix things

270
00:17:15,756 --> 00:17:19,114
or ignore that if actually it is not off the track.

271
00:17:19,232 --> 00:17:23,526
So a threat is always better in such cases.

272
00:17:23,718 --> 00:17:26,506
So what is the plan of action to fix this?

273
00:17:26,688 --> 00:17:30,234
We can measure what we

274
00:17:30,272 --> 00:17:33,694
actually want in our instrumentation. We can plan what

275
00:17:33,732 --> 00:17:38,010
we really need. We can only emit the data that we need and skip

276
00:17:38,090 --> 00:17:41,326
the things that we don't need. We can observe and track.

277
00:17:41,428 --> 00:17:45,646
We can prune aggressively. Lot of metrics and instrumented

278
00:17:45,678 --> 00:17:49,138
data is not even used at all. Like there are a

279
00:17:49,144 --> 00:17:52,754
lot of default metrics that we keep pushing and they can

280
00:17:52,792 --> 00:17:56,066
basically slow down things at later point of time. So we

281
00:17:56,088 --> 00:17:59,814
can prune them aggressively. We can of course store lets for

282
00:17:59,852 --> 00:18:03,686
less amount of time, because the more we store for

283
00:18:03,708 --> 00:18:07,894
more amount of time, it can cause us problems and distractions and

284
00:18:07,932 --> 00:18:10,986
we can focus on what can give us the best value for the money,

285
00:18:11,088 --> 00:18:15,078
and that can help us in terms of reducing the scope

286
00:18:15,174 --> 00:18:18,682
of our instrumentation. But there can be a better plan

287
00:18:18,736 --> 00:18:22,650
of action than this as well. So, for example, what if we can define access

288
00:18:22,720 --> 00:18:26,382
policies for our data, that you can access certain amount

289
00:18:26,436 --> 00:18:29,726
of data only for this much amount of time. If you

290
00:18:29,748 --> 00:18:32,878
want to access beyond that, then you have to be okay

291
00:18:32,964 --> 00:18:36,334
with some reduced data or aggregated

292
00:18:36,382 --> 00:18:39,570
data and so on. We can also have data storage policies across

293
00:18:39,640 --> 00:18:43,330
organization, that your logs can be stored only for one day,

294
00:18:43,400 --> 00:18:47,378
and then beyond that we won't have those because otherwise

295
00:18:47,554 --> 00:18:51,282
they will basically explode in terms of storage costs.

296
00:18:51,426 --> 00:18:55,698
All of these policies can help us in defining standards for our instrumentation

297
00:18:55,794 --> 00:18:59,754
across the organization. So there is consistency and we

298
00:18:59,792 --> 00:19:03,626
get the same results across our software systems so that

299
00:19:03,728 --> 00:19:06,620
things are in a better, consistent way.

300
00:19:07,310 --> 00:19:10,678
Less is always better, even in this case of instrumentation,

301
00:19:10,774 --> 00:19:14,218
because instrumentation is not just instrumenting, it is actually a liability

302
00:19:14,394 --> 00:19:18,746
that we have to worry about as builders of software.

303
00:19:18,938 --> 00:19:22,378
Thanks. That's all that I have today. My name is Prathamesh

304
00:19:22,394 --> 00:19:25,982
Sonpatki. I work has software engineer at lastio end

305
00:19:26,036 --> 00:19:29,566
IO. I have this blog and I have posted my

306
00:19:29,588 --> 00:19:33,134
Twitter and Microsoft details. We also have a discord where

307
00:19:33,172 --> 00:19:36,902
we hang out with other SRE and DevOps folks to discuss

308
00:19:36,956 --> 00:19:41,074
about reliability, observability and a lot of other things related

309
00:19:41,122 --> 00:19:44,598
to SRE and DevOps people. So I would highly encourage to

310
00:19:44,684 --> 00:19:48,340
check it out and join if you're interested. Thanks again. Thank you.

