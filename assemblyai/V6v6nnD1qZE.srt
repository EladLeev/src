1
00:00:27,010 --> 00:00:30,962
Hi everyone, and welcome to this talk about evolutionary architectures

2
00:00:31,026 --> 00:00:35,270
with AWS, Lambda and the Katner architecture. I think everyone

3
00:00:35,420 --> 00:00:38,598
at least once blamed the way how we

4
00:00:38,684 --> 00:00:42,450
have written the code in the past on our project, because evolving

5
00:00:42,530 --> 00:00:46,246
a complex code and maybe code that has a lot of technical depth is a

6
00:00:46,268 --> 00:00:50,570
challenge. And today I would like to propose modular

7
00:00:50,650 --> 00:00:54,190
approach for structuring your serverless project using

8
00:00:54,260 --> 00:00:58,138
hexagonal architecture. My name is Luca Mezzalira.

9
00:00:58,234 --> 00:01:01,802
I'm a principal solution architect at AWS. I'm an international

10
00:01:01,866 --> 00:01:03,870
speaker and a rally author.

11
00:01:05,110 --> 00:01:08,734
So let's start with the definition of what evolutionary architecture

12
00:01:08,782 --> 00:01:12,350
means directly from the book building hexagonal architecture.

13
00:01:12,510 --> 00:01:16,426
So evolutionary architectures support guided incremental

14
00:01:16,478 --> 00:01:20,214
changes across multiple dimensions. We think about that when

15
00:01:20,252 --> 00:01:23,538
we create an architecture. When we select an architecture,

16
00:01:23,714 --> 00:01:27,638
we need to find one that will allow us to follow the business

17
00:01:27,724 --> 00:01:31,606
drift during the journey. When they happen. We cannot

18
00:01:31,638 --> 00:01:35,046
anymore select an architecture blindly just because it's

19
00:01:35,078 --> 00:01:38,682
the one we are more comfortable with. We need to really understand our

20
00:01:38,736 --> 00:01:41,820
context and then apply the right architecture for it.

21
00:01:42,370 --> 00:01:46,334
And I believe that everyone at least once has to deal with

22
00:01:46,372 --> 00:01:49,934
a free tier architecture. And usually what happens

23
00:01:49,972 --> 00:01:53,498
in free tier architecture after a while that you are dealing with it is

24
00:01:53,524 --> 00:01:56,786
that the presentation layer and the data layer starts to

25
00:01:56,808 --> 00:02:01,102
leak inside the application layer. So these three layers became,

26
00:02:01,166 --> 00:02:04,994
the lines between them became a bit blurry. And the

27
00:02:05,032 --> 00:02:08,914
challenge then in the long run, is maintaining some code that

28
00:02:08,952 --> 00:02:12,550
has a lot of technical data and some logic that should

29
00:02:12,620 --> 00:02:15,734
live inside different layers instead that are living in

30
00:02:15,772 --> 00:02:18,818
other ones. And therefore that will require,

31
00:02:18,914 --> 00:02:22,090
that will cause frustration for developers and we require time

32
00:02:22,160 --> 00:02:25,340
and effort in order to make it right.

33
00:02:25,790 --> 00:02:28,140
And it's not an easy task, definitely.

34
00:02:29,230 --> 00:02:32,782
Moreover, what happened

35
00:02:32,836 --> 00:02:37,098
once to me was we wanted to move some workloads to Lambda.

36
00:02:37,194 --> 00:02:40,714
We had the workload either on MCs Docker

37
00:02:40,762 --> 00:02:44,510
containers or in MSQ machine

38
00:02:44,670 --> 00:02:48,558
and then we wanted to move to lambda. But that wasn't

39
00:02:48,654 --> 00:02:52,690
straightforward because the code that we have written was

40
00:02:52,760 --> 00:02:56,286
really tightly coupled with the implementation infrastructure

41
00:02:56,318 --> 00:03:00,034
and everything. Therefore, decoupling that code and moved to

42
00:03:00,072 --> 00:03:04,070
multiple lambdas, it was a non trivial action.

43
00:03:04,730 --> 00:03:08,546
And finally, I believe that you have seen more than

44
00:03:08,588 --> 00:03:11,754
once in articles, blog around the web and maybe even

45
00:03:11,792 --> 00:03:15,066
in your code base lambdas that are written in this way where you

46
00:03:15,088 --> 00:03:19,926
have your handler that contains multiple functions

47
00:03:19,958 --> 00:03:24,046
inside and for instance, in this case you have submit candidate that

48
00:03:24,068 --> 00:03:27,386
is calling candidate info and he, and then returns

49
00:03:27,418 --> 00:03:30,734
a response to the client. And when you

50
00:03:30,772 --> 00:03:34,382
start to dig into those two functions,

51
00:03:34,446 --> 00:03:38,018
you discover that submit candidate p at the end

52
00:03:38,104 --> 00:03:41,566
is let's say a logic port storing

53
00:03:41,598 --> 00:03:44,978
some data inside dynamodb. And candidate info is a

54
00:03:44,984 --> 00:03:48,722
value object. So we are basically merging inside the same file,

55
00:03:48,786 --> 00:03:52,690
the entry point of our lambda, the infrastructure

56
00:03:52,770 --> 00:03:56,614
as well as the domain. So in this case the value object, that is not

57
00:03:56,652 --> 00:04:00,266
exactly the right way to structure our code, because then if you want to

58
00:04:00,288 --> 00:04:03,846
evolve that, we can introduce bugs in several areas.

59
00:04:03,878 --> 00:04:07,414
And moreover, it's quite confusing reading

60
00:04:07,462 --> 00:04:10,766
all these things altogether. And here is

61
00:04:10,788 --> 00:04:14,366
where hexagonal architecture come in

62
00:04:14,388 --> 00:04:17,706
place to help us comes to the rescue,

63
00:04:17,818 --> 00:04:22,000
as they say. And examiner architecture allow you to

64
00:04:22,770 --> 00:04:26,158
drive an application from a user point of

65
00:04:26,164 --> 00:04:29,518
view, from a program point of view, from an automated test or batch script.

66
00:04:29,614 --> 00:04:33,550
And the beauty of this is that this creating some modularization

67
00:04:33,630 --> 00:04:36,390
of your code that allows you also back and testing.

68
00:04:37,690 --> 00:04:41,494
Let's try to understand the key part of an

69
00:04:41,532 --> 00:04:45,042
examiner architecture. So the first part is the domain logic.

70
00:04:45,106 --> 00:04:48,666
The domain logic is the part where we are

71
00:04:48,688 --> 00:04:51,894
encapsulating what our, in this case AWS

72
00:04:51,942 --> 00:04:55,274
lambda should do, and therefore we are mapping where

73
00:04:55,312 --> 00:04:59,418
the real value lies of our workloads. In this way,

74
00:04:59,504 --> 00:05:02,830
we are basically using our efforts to create

75
00:05:02,900 --> 00:05:06,622
the logic that will allow us to retrieve information and

76
00:05:06,676 --> 00:05:10,350
react to requests that are coming from a client or another

77
00:05:10,420 --> 00:05:14,626
service. Then you have ports and ports, you need to imagine them

78
00:05:14,728 --> 00:05:17,934
like surrounding the domain logic

79
00:05:17,982 --> 00:05:21,246
and being the only entry point and output

80
00:05:21,278 --> 00:05:25,106
for a domain logic. So if someone else wants to

81
00:05:25,128 --> 00:05:28,786
interact with domain logic, has to pass through a port and vice versa.

82
00:05:28,818 --> 00:05:32,838
If the domain logic would like to interact with the external world, has to

83
00:05:32,844 --> 00:05:36,770
pass through a port. The ports, when we talk about coding,

84
00:05:36,850 --> 00:05:40,722
could be represented either with an interface,

85
00:05:40,786 --> 00:05:44,310
in the case that they're using Java, or a type language like typescript,

86
00:05:44,390 --> 00:05:48,282
or it could be a function like in the case of node js with

87
00:05:48,336 --> 00:05:52,334
es six, and that's what we are using to explore today. Then you have the

88
00:05:52,372 --> 00:05:56,170
third layer that are adapters. If you're familiar with adapter pattern,

89
00:05:56,250 --> 00:05:59,360
it's exactly the same thing. An adapter is basically

90
00:05:59,810 --> 00:06:03,290
a pattern that allows you to map the external interface or the

91
00:06:03,300 --> 00:06:06,834
external contract of a service with an

92
00:06:06,872 --> 00:06:12,158
internal one. And usually they are used for maintaining

93
00:06:12,334 --> 00:06:16,530
the encapsulated order logic for the external communication,

94
00:06:16,610 --> 00:06:20,034
creating the fact of an anticorruption layer between the external

95
00:06:20,082 --> 00:06:23,366
world and the internal world. And this layer is

96
00:06:23,548 --> 00:06:26,998
very useful in this case because will allow us to

97
00:06:27,164 --> 00:06:30,406
encapsulate the requests that are coming from the external

98
00:06:30,438 --> 00:06:34,394
world and translate them in a way that the business logic could

99
00:06:34,432 --> 00:06:38,010
digest and use it through the port. The same way

100
00:06:38,080 --> 00:06:42,202
adapters can be used for communicating with the external world from the domain logic.

101
00:06:42,266 --> 00:06:46,202
And that in that case will allow us to do, let's say other interaction.

102
00:06:46,266 --> 00:06:50,062
For instance, we have primary actors, usually that

103
00:06:50,116 --> 00:06:54,298
are the actors that are interacting directly with alumni

104
00:06:54,314 --> 00:06:58,402
in this case. But the exact architecture, it could be, I don't know, another service,

105
00:06:58,536 --> 00:07:01,758
it could be a front end application, it could be a queue.

106
00:07:01,854 --> 00:07:05,298
And all of these are primary actors because they are the

107
00:07:05,304 --> 00:07:08,646
ones that are triggering this case, our lambda, and forcing it

108
00:07:08,668 --> 00:07:12,258
to do something. On the other hand, we have secondary actors

109
00:07:12,354 --> 00:07:16,130
and secondary actors are the ones that are interacted

110
00:07:16,210 --> 00:07:20,010
by the lambda. So it could be that the lambda has to retrieve some information

111
00:07:20,080 --> 00:07:23,994
from a database, therefore it has to query the database or it

112
00:07:24,032 --> 00:07:28,470
has to call a third party service or even send, after computing

113
00:07:28,550 --> 00:07:32,098
some data, sending those information into a queue.

114
00:07:32,214 --> 00:07:36,030
All of them are secondary actors, because are the ones that are used

115
00:07:36,100 --> 00:07:39,150
by, in this case, our AWS client.

116
00:07:39,890 --> 00:07:43,618
Now that we understand this part, let's try to understand the benefits

117
00:07:43,704 --> 00:07:46,978
and drawback of this approach. First of all, the business

118
00:07:47,064 --> 00:07:50,980
logic is agnostic to the external world.

119
00:07:51,750 --> 00:07:55,266
What it means is basically we can change and

120
00:07:55,288 --> 00:07:58,614
evolve our business logic without caring too much how

121
00:07:58,732 --> 00:08:01,186
other things are communicating in the environment.

122
00:08:01,378 --> 00:08:04,822
As we will see in the example, you will see that

123
00:08:04,876 --> 00:08:08,406
the code of the business logic is completely decoupled from the

124
00:08:08,428 --> 00:08:12,454
interaction with the database, for instance. And in that case it means we can swap

125
00:08:12,502 --> 00:08:16,394
database easily if needed, or even change the

126
00:08:16,432 --> 00:08:18,890
way how we are interacting with the database.

127
00:08:19,710 --> 00:08:22,986
The other thing is the business logic is independent from external

128
00:08:23,018 --> 00:08:26,666
services. So if we need to change the way how we interact

129
00:08:26,698 --> 00:08:30,560
with the infrastructure, or even change the infrastructure, it's not going to matter.

130
00:08:31,810 --> 00:08:34,526
Because of this modularization and this encapsulation,

131
00:08:34,638 --> 00:08:38,350
testing became easier because we can test atomically

132
00:08:38,430 --> 00:08:42,034
part of our AWS lambda without any problem.

133
00:08:42,152 --> 00:08:46,134
And finally, we reduce the technical depth because we are encapsulating very

134
00:08:46,172 --> 00:08:48,840
well a different part of our application.

135
00:08:49,770 --> 00:08:53,286
There are also some drawbacks as everything in this

136
00:08:53,308 --> 00:08:57,090
case we need to build more layers upfront.

137
00:08:57,170 --> 00:09:00,314
That is not, let's say immediately a bad

138
00:09:00,352 --> 00:09:03,786
thing. It could be also an opportunity that we can use in

139
00:09:03,808 --> 00:09:07,322
order to structure properly our project. The same for

140
00:09:07,456 --> 00:09:11,450
the loose implementation details around the business logic.

141
00:09:11,530 --> 00:09:15,322
Examiner architecture doesn't provide a strong or opinionated

142
00:09:15,466 --> 00:09:18,730
path for structuring your business logic,

143
00:09:18,810 --> 00:09:22,462
but that again is an opportunity that we can use in order to

144
00:09:22,596 --> 00:09:25,934
structure our workload in a way that is sensible

145
00:09:25,982 --> 00:09:28,130
for our context and for our teammates.

146
00:09:29,510 --> 00:09:32,814
So if by now you are thinking, okay, why examiner architecture

147
00:09:32,862 --> 00:09:36,566
up to now we always discuss about layers, but that's a valid question and the

148
00:09:36,588 --> 00:09:40,166
answer is coming directly from Alistair cockboard. That is the creator of

149
00:09:40,268 --> 00:09:43,654
this architecture. The samurai architecture or the

150
00:09:43,772 --> 00:09:47,494
exagome was mainly used AWS a visual effect.

151
00:09:47,612 --> 00:09:51,114
What they realized is that it's not enough having let's say

152
00:09:51,152 --> 00:09:54,266
some layers or a rectangle for expressing all the

153
00:09:54,288 --> 00:09:57,914
interaction that a specific layer has, but having an XFL provide more

154
00:09:57,952 --> 00:10:01,262
surface visually for adding new interaction. That could be

155
00:10:01,316 --> 00:10:05,370
if you want to describe the interaction from multiple entry point, or interaction

156
00:10:05,530 --> 00:10:08,910
from database and caches and so on and so forth.

157
00:10:10,690 --> 00:10:14,194
Okay, so I prefer a demo. Just to give

158
00:10:14,232 --> 00:10:18,610
you an idea on how these things are interacting altogether.

159
00:10:19,430 --> 00:10:22,814
The demo is fairly simple, is a lambda

160
00:10:22,862 --> 00:10:26,486
that is called stock converter that is triggered by a

161
00:10:26,508 --> 00:10:30,646
request that is coming from the client. Then we

162
00:10:30,668 --> 00:10:33,734
have a dynamodb table that is

163
00:10:33,852 --> 00:10:37,400
used for retrieving a stock value.

164
00:10:38,270 --> 00:10:41,574
And then this stock value is kept

165
00:10:41,622 --> 00:10:44,966
in memory for the lambda. The lambda then is calling a third party

166
00:10:44,998 --> 00:10:49,158
service for retrieving the live currencies.

167
00:10:49,334 --> 00:10:52,814
For the live value of the currencies of specific,

168
00:10:53,012 --> 00:10:56,558
let's say currencies around the world, apply them to the stock value,

169
00:10:56,644 --> 00:11:00,670
and then return back the response to the client.

170
00:11:01,170 --> 00:11:04,606
So very simple, nothing too complicated. But just with this

171
00:11:04,628 --> 00:11:07,410
example we will be able to see the benefit of this approach.

172
00:11:08,710 --> 00:11:11,986
So if we want to visualize what's going to happen. So the first

173
00:11:12,008 --> 00:11:15,330
thing is there is an HTTP request that will be picked by

174
00:11:15,400 --> 00:11:18,598
can adapter. The adapter will communicate with

175
00:11:18,684 --> 00:11:21,826
the port for communicating with the business logic.

176
00:11:21,938 --> 00:11:25,446
And therefore basically it's retrieving the adapter in this case is retrieving the

177
00:11:25,468 --> 00:11:28,874
stock id and then passing that the business logic through

178
00:11:28,912 --> 00:11:32,746
the port. The business logic then takes

179
00:11:32,848 --> 00:11:36,630
the IP, communicates through the port to an adapter,

180
00:11:36,710 --> 00:11:40,686
and in that case the adapter is communicating with DynamoDB where

181
00:11:40,788 --> 00:11:44,910
we store our value of specific stock.

182
00:11:45,570 --> 00:11:49,470
Then the business logic is communicating again with another ports

183
00:11:49,620 --> 00:11:53,262
and the ports is communicated with can adapter for retrieving

184
00:11:53,326 --> 00:11:55,970
the live value of the currencies.

185
00:11:56,390 --> 00:12:00,386
When everything is finished, we return back to

186
00:12:00,408 --> 00:12:03,730
the response and therefore we fulfill our

187
00:12:03,800 --> 00:12:07,586
execution in our lambda. Okay, so let's

188
00:12:07,618 --> 00:12:11,142
jump to some code. This is

189
00:12:11,276 --> 00:12:15,254
how I structure the project. As you can see here, I have the

190
00:12:15,292 --> 00:12:18,586
adapters folder, domain and ports. Those are

191
00:12:18,608 --> 00:12:22,266
the three concepts that we have seen before when

192
00:12:22,288 --> 00:12:25,690
I was discussing about the anatomy of XML architecture.

193
00:12:26,190 --> 00:12:29,370
The interesting bit here is that

194
00:12:29,440 --> 00:12:32,686
the entry point that is this app js that you can find outside

195
00:12:32,788 --> 00:12:36,126
all the folders is the

196
00:12:36,148 --> 00:12:39,534
only thing that it does is retrieving the stock id that is

197
00:12:39,572 --> 00:12:42,830
present inside the rest API that was consumed by the client.

198
00:12:43,570 --> 00:12:46,994
It's receiving the stock id and the first thing that it does, it doesn't do

199
00:12:47,032 --> 00:12:50,834
anything, as you can see, and doesn't provide any logic outside

200
00:12:50,952 --> 00:12:54,794
our architecture. The first thing that it does after retrieving

201
00:12:54,942 --> 00:12:58,726
the stock id is passing the stock id to

202
00:12:58,828 --> 00:13:04,166
an adapters. This adapter has

203
00:13:04,188 --> 00:13:07,510
a function called get stock request, and what it does is

204
00:13:07,580 --> 00:13:11,498
retrieving the stock id and passing to a specific port

205
00:13:11,584 --> 00:13:14,726
that is used for communicating with the business logic.

206
00:13:14,838 --> 00:13:18,374
The other thing, everything is asynchronous. In this case I'm using node js

207
00:13:18,422 --> 00:13:21,786
with DS six, and here I'm preparing

208
00:13:21,818 --> 00:13:25,470
the response in case that I fulfill

209
00:13:26,690 --> 00:13:29,434
the logic and also I prepare an error.

210
00:13:29,482 --> 00:13:33,154
Obviously in this case I omitted a lot of details around

211
00:13:33,192 --> 00:13:36,900
metrics loggings, mainly to focus more the example around

212
00:13:37,590 --> 00:13:39,410
how to structure Mexagon.

213
00:13:40,550 --> 00:13:44,306
So here we go to the

214
00:13:44,328 --> 00:13:47,406
port and in the port, in this case we are using

215
00:13:47,448 --> 00:13:50,646
s six and therefore we don't have interfaces. So we can

216
00:13:50,748 --> 00:13:54,482
easily use a function in order to communicate

217
00:13:54,546 --> 00:13:57,738
from the external world to internal worlds, basically from an adapter to the

218
00:13:57,744 --> 00:14:01,306
business logic, and in this case the port. What it

219
00:14:01,328 --> 00:14:05,382
does is literally mapping the request from the adapter

220
00:14:05,446 --> 00:14:09,450
to a specific function inside my business logic.

221
00:14:10,430 --> 00:14:13,862
And when I go to stop where that is my business logic

222
00:14:14,006 --> 00:14:17,566
here I can see immediately first the currency that I want to use. Potentially it

223
00:14:17,588 --> 00:14:21,582
could be an environment variable. In this case I just map as constant inside my

224
00:14:21,636 --> 00:14:25,326
logic. Here the first thing that I do is retrieving the stock

225
00:14:25,358 --> 00:14:29,246
id. Then I'm sending

226
00:14:29,358 --> 00:14:32,706
the currencies that I'm looking for and to

227
00:14:32,728 --> 00:14:36,706
a third party service. And then I apply the value that is

228
00:14:36,728 --> 00:14:40,726
coming in euros to all the currencies and return back the

229
00:14:40,908 --> 00:14:44,870
response to the client. But the interesting part is here.

230
00:14:44,940 --> 00:14:48,338
As you can see, the business logic is not aware if we're using Panama

231
00:14:48,354 --> 00:14:51,350
DB, if we're using Aurora,

232
00:14:51,510 --> 00:14:55,494
or if we're using memorydb, anything. It doesn't matter the database

233
00:14:55,542 --> 00:14:59,194
for the business logic, because what it matters is that I'm looking for

234
00:14:59,232 --> 00:15:02,742
the value of the stock, the same for currencies,

235
00:15:02,886 --> 00:15:06,318
currencies, it doesn't matter which is the service I'm using, it doesn't even know the

236
00:15:06,324 --> 00:15:09,886
business logic which is the service that I'm using. So let's try to explore a

237
00:15:09,908 --> 00:15:12,558
bit this concept. Let's go with the repository first.

238
00:15:12,644 --> 00:15:16,434
So as we said, the business logic is calling a ports now that

239
00:15:16,472 --> 00:15:19,906
is calling an adapter once again,

240
00:15:20,008 --> 00:15:22,740
the port is nothing more than a function.

241
00:15:23,190 --> 00:15:27,346
And when I go to get a stock value here, I'm mapping the

242
00:15:27,368 --> 00:15:31,478
logic to communicate with Dynamodb. The interesting

243
00:15:31,564 --> 00:15:35,382
thing is that everything is encapsulated here. So if I need to make a change

244
00:15:35,436 --> 00:15:38,742
on dynamo in the way I'm querying in the schema, or even

245
00:15:38,796 --> 00:15:42,634
in the way of I want to potentially store value, that is not

246
00:15:42,672 --> 00:15:46,374
the case in this example, but potentially in a crud implementation

247
00:15:46,422 --> 00:15:49,114
I could. The only thing that I have to do is go into the right

248
00:15:49,152 --> 00:15:52,414
adapter and start to atomically make a change or

249
00:15:52,452 --> 00:15:56,638
improvement. When here I have

250
00:15:56,724 --> 00:16:01,054
retrieved the item in action, I return back the information to

251
00:16:01,252 --> 00:16:04,910
the business logic. Okay,

252
00:16:05,060 --> 00:16:08,720
let's go back to the business logic. The other using is the

253
00:16:09,170 --> 00:16:12,786
currency. So I want to retrieve the currencies in this case. Once again I

254
00:16:12,808 --> 00:16:16,770
have my port and in my ports I'm calling can adapters.

255
00:16:16,930 --> 00:16:21,080
The adapters. What it does is very simple, is calling

256
00:16:21,610 --> 00:16:25,126
point to point this API, and this

257
00:16:25,148 --> 00:16:28,346
API is returning a payload that contains some

258
00:16:28,448 --> 00:16:32,186
values. Everything is very simple.

259
00:16:32,288 --> 00:16:35,818
We deploy this in production and let's assume that these

260
00:16:35,904 --> 00:16:39,434
workloads start to have a certain amount of traffic. That is

261
00:16:39,472 --> 00:16:42,800
quite common if you have a very successful application.

262
00:16:43,890 --> 00:16:47,134
Now there is a new requirement. You start to

263
00:16:47,172 --> 00:16:51,102
see that there is some throttling in the third party service

264
00:16:51,236 --> 00:16:54,746
because at some point you have too many requests

265
00:16:54,778 --> 00:16:57,906
and because you have implemented the code in this way where you go point to

266
00:16:57,928 --> 00:17:01,762
point and every request goes to retrieve the real

267
00:17:01,816 --> 00:17:05,314
time value of this currency. It's not going to case very

268
00:17:05,352 --> 00:17:09,026
well. So now we need to think about how we can improve

269
00:17:09,058 --> 00:17:12,226
this. And there is a specific pattern bubbles

270
00:17:12,258 --> 00:17:15,974
in my mind that is called a cache aside pattern. So potentially what we can

271
00:17:16,012 --> 00:17:19,058
do is go into our adapter,

272
00:17:19,154 --> 00:17:23,014
sorry, go into our port and create another adapter

273
00:17:23,062 --> 00:17:26,666
that in this case is currency converter with case. So we can

274
00:17:26,688 --> 00:17:30,522
use a cache aside pattern. What it does basically is first

275
00:17:30,656 --> 00:17:34,654
looking into a cache if there are some value available, and if

276
00:17:34,692 --> 00:17:38,126
they are, they return immediately the value directly from

277
00:17:38,148 --> 00:17:41,790
the case. Instead of going to inquiry and

278
00:17:41,860 --> 00:17:45,102
consuming an API from a third party system, this basically will

279
00:17:45,156 --> 00:17:49,282
offload all the requests or bus journey of them from

280
00:17:49,416 --> 00:17:52,770
our application to a third party system. And again

281
00:17:52,840 --> 00:17:56,246
you are going to have the similar result because you have

282
00:17:56,348 --> 00:18:00,086
data that are available inside your cache. In this case I used

283
00:18:00,188 --> 00:18:03,666
elasticache, that is another AWS service that allows

284
00:18:03,698 --> 00:18:07,286
you to use redis, or in this case

285
00:18:07,388 --> 00:18:10,934
I'm using redis for creating a cluster where

286
00:18:11,132 --> 00:18:15,006
I can store retrieve first information if they are, if there aren't,

287
00:18:15,058 --> 00:18:18,246
I'm just storing them. So as you can see here, I have the logic.

288
00:18:18,358 --> 00:18:22,598
I'm using a normal node JS redis

289
00:18:22,694 --> 00:18:25,966
client and in this case I'm just looking. I have like an

290
00:18:25,988 --> 00:18:29,966
id that's currencies. If there are some can array of values for

291
00:18:29,988 --> 00:18:34,322
those currencies, I will return back immediately. And I don't even go

292
00:18:34,376 --> 00:18:38,190
through the request to a third party

293
00:18:38,270 --> 00:18:41,646
service if there isn't anything. I first retrieve

294
00:18:41,678 --> 00:18:45,446
the information on the third party service

295
00:18:45,548 --> 00:18:49,410
and then I immediately store this response

296
00:18:49,570 --> 00:18:53,046
with an expiration time of 20 seconds in

297
00:18:53,068 --> 00:18:56,678
the cache and then I return the data to the

298
00:18:56,684 --> 00:19:00,394
piece of logic. As you have seen here, I didn't have to

299
00:19:00,432 --> 00:19:04,394
change anything apart from my port just

300
00:19:04,432 --> 00:19:08,138
to change basically the import that I

301
00:19:08,144 --> 00:19:11,978
need to do. But that is more peculiar for Es six and JavaScript.

302
00:19:12,074 --> 00:19:15,354
But if you're using another type language,

303
00:19:15,402 --> 00:19:19,694
potentially the thing is you just need to be

304
00:19:19,732 --> 00:19:23,834
compliant with the interface that you have created and therefore through dependency

305
00:19:23,882 --> 00:19:27,394
injection you would be able to just create a new adapter or change the

306
00:19:27,432 --> 00:19:30,914
existing adapter that you have. I prefer to, because it's very atomic, it's very

307
00:19:30,952 --> 00:19:34,370
small, I prefer to have two adapters. So I can also,

308
00:19:34,520 --> 00:19:37,918
let's say revert back quickly if I need to make some tests and make sure

309
00:19:37,944 --> 00:19:41,046
that everything is working correctly. But the beauty of this, that is,

310
00:19:41,068 --> 00:19:44,646
atomically we were change only one file and

311
00:19:44,668 --> 00:19:47,986
the rest of the application remained exactly the same because we are not creating

312
00:19:48,028 --> 00:19:51,526
the same contract. But moreover, because the modularity provided

313
00:19:51,558 --> 00:19:55,866
by this approach allowed us really to be specific

314
00:19:55,968 --> 00:20:00,066
on the thing that we need to change. Now let's

315
00:20:00,118 --> 00:20:03,950
assume that we have another example that we want to

316
00:20:04,020 --> 00:20:07,950
pursue. Let's assume that this team, instead of starting straight with

317
00:20:08,100 --> 00:20:11,840
AWS lambda or a serverless workload, they started with

318
00:20:12,850 --> 00:20:16,846
a container. Maybe it's running on ETS

319
00:20:16,958 --> 00:20:21,262
or elastic container service ecs.

320
00:20:21,406 --> 00:20:24,866
So in this case our application, as you can see, we have the

321
00:20:24,888 --> 00:20:27,878
same structure, we have exactly the same files also.

322
00:20:28,044 --> 00:20:31,800
And the interesting approach of this is that when we map our

323
00:20:32,890 --> 00:20:36,134
endpoint in this case is a gap with passing this

324
00:20:36,172 --> 00:20:39,350
code stock and we pass the id of the stock, this is

325
00:20:39,420 --> 00:20:43,162
exactly the same entry point that we have in our lambda. What it means is

326
00:20:43,296 --> 00:20:47,562
that potentially the moment that we have a container that has

327
00:20:47,696 --> 00:20:51,662
maybe a crud operation for creating, updating, deleting and

328
00:20:51,716 --> 00:20:55,386
reading some information from a database. If we structure

329
00:20:55,498 --> 00:20:59,690
our container in this way, it becomes easier then to refactor and extract

330
00:20:59,770 --> 00:21:03,026
ports of our application

331
00:21:03,128 --> 00:21:06,210
into a new compute layer. That is great

332
00:21:06,280 --> 00:21:10,740
because it means we can really leverage the power of

333
00:21:11,270 --> 00:21:14,978
the cloud provided for moving

334
00:21:15,144 --> 00:21:19,074
our logic across multiple components based on the volumetric

335
00:21:19,122 --> 00:21:22,120
that our service is used to have.

336
00:21:23,610 --> 00:21:26,680
Okay, let's go back to the slide now.

337
00:21:27,290 --> 00:21:30,122
Now obviously someone can think,

338
00:21:30,176 --> 00:21:33,718
okay, that's great, I can test better, I have good modularization,

339
00:21:33,894 --> 00:21:37,626
I can start to have my code in a really great way.

340
00:21:37,728 --> 00:21:40,666
But what about anything else?

341
00:21:40,848 --> 00:21:44,814
What I'm gaining with exceptional architecture, I found some use

342
00:21:44,852 --> 00:21:48,366
cases that I believe are interesting to think about when we

343
00:21:48,388 --> 00:21:51,614
want to use this architecture. So the first one is testing because we

344
00:21:51,652 --> 00:21:56,222
are modularizing everything. We can really create different tests

345
00:21:56,286 --> 00:21:59,554
potentially based on tests for adapters and

346
00:21:59,592 --> 00:22:04,322
tests for business logic. And maybe probably

347
00:22:04,456 --> 00:22:07,854
more often you are going to change to your business logic

348
00:22:07,902 --> 00:22:11,814
more than the integration with the database. So in that case you can even

349
00:22:11,932 --> 00:22:15,586
set up some optimization in the way how you are running your test in CI

350
00:22:15,618 --> 00:22:19,446
CD. But even in your development environment where you are

351
00:22:19,468 --> 00:22:22,874
testing more often, maybe the business logic, and then when

352
00:22:22,912 --> 00:22:26,534
you have to test in automation and adapters on integration

353
00:22:26,582 --> 00:22:29,994
with external world, you can do that. But thanks to this

354
00:22:30,032 --> 00:22:33,998
approach, this very modular will allow you really to make this

355
00:22:34,084 --> 00:22:37,518
reasoning and also optimize your feedback loop when it

356
00:22:37,524 --> 00:22:41,454
comes to testing catches and pattern. We have seen

357
00:22:41,492 --> 00:22:45,118
that. So we have a service that is hammering our lambda in this case,

358
00:22:45,204 --> 00:22:47,854
and then the lambda is making with the database.

359
00:22:47,982 --> 00:22:52,306
Obviously sometimes all the queries that we have

360
00:22:52,488 --> 00:22:56,882
are quite common and are requested by multiple customers.

361
00:22:57,016 --> 00:23:00,214
So in this case what we can use is having a cache and they use

362
00:23:00,252 --> 00:23:04,040
this cache site pattern where first we read from the cache and then

363
00:23:05,850 --> 00:23:09,702
if the cache is expired or evicted, we can go to the case.

364
00:23:09,836 --> 00:23:13,306
The interesting part of this approach is that not only the cache button can be

365
00:23:13,328 --> 00:23:16,394
used, it's one of the pattern. It can have you have a read through

366
00:23:16,432 --> 00:23:19,914
cache or a write through case, and it's completely up to you to

367
00:23:19,952 --> 00:23:23,262
handle that. But the beauty is that if we want to change for any given

368
00:23:23,316 --> 00:23:26,894
reason specific integration with the database, the only

369
00:23:26,932 --> 00:23:31,280
thing we need to change AWS long we maintain the same contract between the

370
00:23:31,650 --> 00:23:34,686
business logic and the adapter is at

371
00:23:34,708 --> 00:23:37,746
the adapter level. So in this case, the only thing really that we

372
00:23:37,768 --> 00:23:41,634
need to change is at the adapter level for improving the performance of our

373
00:23:41,672 --> 00:23:43,700
application without touching the rest.

374
00:23:45,110 --> 00:23:48,646
Another example could be a change in trigger. Imagine that

375
00:23:48,668 --> 00:23:50,840
you have like a workload that is,

376
00:23:51,610 --> 00:23:55,602
let's say currently working with API that is triggering

377
00:23:55,746 --> 00:23:59,574
a lambda function, and at some point you realize that

378
00:23:59,612 --> 00:24:02,986
that is not needed anymore. You have a lot of traffic, you don't have to

379
00:24:03,008 --> 00:24:06,406
handle everything synchronously. You can handle

380
00:24:06,438 --> 00:24:09,786
that asynchronously, so that what you could do, instead of having

381
00:24:09,888 --> 00:24:13,358
a direct connection between API gateway and lambda function, you can have an

382
00:24:13,364 --> 00:24:17,082
API gateway that is running to AWS sqs, so a queue,

383
00:24:17,146 --> 00:24:20,906
and in that case the lambda is triggered,

384
00:24:21,018 --> 00:24:25,150
retrieving a batch of elements at the queue and then doing computation

385
00:24:25,310 --> 00:24:28,482
and so forth. On the other side, the client can start

386
00:24:28,536 --> 00:24:31,746
to pull an API for

387
00:24:31,768 --> 00:24:35,614
retrieving the computation that is done by the lambda. That is a common scenario

388
00:24:35,662 --> 00:24:38,886
when you have, let's say you can work with a venture of consistency, or you

389
00:24:38,908 --> 00:24:42,930
want to work in a way where you want to reduce

390
00:24:43,010 --> 00:24:46,834
the strain to your service and rely on the fact that infrastructure

391
00:24:46,882 --> 00:24:48,140
can handle that.

392
00:24:49,710 --> 00:24:52,742
Another approach is service migration.

393
00:24:52,886 --> 00:24:56,714
Imagine a situation where you have your application

394
00:24:56,832 --> 00:25:00,742
and you're using maybe a self managed database.

395
00:25:00,806 --> 00:25:04,342
In this case, let's assume MongoDB. Let's assume that you have MongoDB

396
00:25:04,406 --> 00:25:07,918
running on can ec two instance, and at some point,

397
00:25:08,004 --> 00:25:12,014
yes, you need to maintain, you need to update the

398
00:25:12,052 --> 00:25:14,679
cluster, you need to make sure that it's up and running and so on and

399
00:25:15,179 --> 00:25:18,226
so forth. But that is, let's say, taking a

400
00:25:18,248 --> 00:25:21,586
lot of time for maintenance. What you cloud do is

401
00:25:21,608 --> 00:25:25,086
that say, okay, listen, I'm not here for maintaining

402
00:25:25,118 --> 00:25:28,606
database. I'm not doing anything crazy with

403
00:25:28,648 --> 00:25:32,402
my database. I just want to migrate my data to a managed database.

404
00:25:32,546 --> 00:25:36,354
So in this case MongoDB. In AWs you can use documentb

405
00:25:36,402 --> 00:25:40,394
that is compatible with Mongo. And in order to do so you

406
00:25:40,432 --> 00:25:44,970
can migrate the data behind the scene and there are the migration service

407
00:25:45,040 --> 00:25:48,614
that would allow you to do so, but also the computation layer.

408
00:25:48,662 --> 00:25:51,898
You can even apply a logic where you can maintain for a

409
00:25:51,904 --> 00:25:55,194
certain period of time both databases and the adapter

410
00:25:55,242 --> 00:25:58,794
level. You are just, let's say querying primary

411
00:25:58,842 --> 00:26:02,094
on document DB. And then if you don't find specific record, you can go to

412
00:26:02,132 --> 00:26:06,180
MongoDB. The beauty of this approach is that you can even apply

413
00:26:06,630 --> 00:26:10,580
a branch by abstraction and slowly but steadily migrate away

414
00:26:11,350 --> 00:26:14,994
from MongoDB or submanage database to a new

415
00:26:15,032 --> 00:26:18,854
one, and that all the logic for doing so

416
00:26:18,892 --> 00:26:21,798
is encapsulated inside an adapter. Once again,

417
00:26:21,884 --> 00:26:25,830
all the rest of the logic and the lambda is not going to be

418
00:26:25,980 --> 00:26:29,870
change, it's not going to be affected because you are encapsulating very well using examiner

419
00:26:29,890 --> 00:26:33,494
architecture. Another approach

420
00:26:33,542 --> 00:26:37,274
is web application modernization. And when you

421
00:26:37,312 --> 00:26:41,286
have, for instance a modular moderates, therefore you identify some domains at

422
00:26:41,328 --> 00:26:45,486
your business logic, you may want to migrate from

423
00:26:45,588 --> 00:26:49,326
your instance to containers. So in

424
00:26:49,348 --> 00:26:53,220
that case you want to use microservices. And if you use

425
00:26:53,830 --> 00:26:57,710
exact architecture, you can slowly but steady retrieve portion

426
00:26:57,870 --> 00:27:01,758
of your domain and therefore bounded context encapsulated

427
00:27:01,854 --> 00:27:05,822
microservice and slowly but steady migrating your module

428
00:27:05,886 --> 00:27:09,526
only in distributed system. Moreover, you can

429
00:27:09,548 --> 00:27:13,442
do the same moving from microservices, therefore from a container to lambda.

430
00:27:13,506 --> 00:27:16,966
And in that case it's very interesting because you can have,

431
00:27:17,148 --> 00:27:20,726
let's say a decision on how you want to handle that. Imagine for instance that

432
00:27:20,748 --> 00:27:24,438
you have a cloud operation inside the microservice and you want to migrate

433
00:27:24,454 --> 00:27:28,378
to lambda. You don't have to migrate every single operation in

434
00:27:28,384 --> 00:27:31,774
a unique lambda. It depends from your world metric. Be pragmatic there.

435
00:27:31,892 --> 00:27:36,394
You can potentially say okay, in my interaction

436
00:27:36,442 --> 00:27:39,902
with a service I see that they have a lot of read but not many

437
00:27:39,956 --> 00:27:43,086
deletion and creation or update of

438
00:27:43,108 --> 00:27:46,962
a record. So what I can do initially for doing a quick

439
00:27:47,016 --> 00:27:51,026
move towards a serverless option is taking the read,

440
00:27:51,128 --> 00:27:54,274
put a logic and put inside the lambda and then the

441
00:27:54,312 --> 00:27:57,906
rest you can put inside another lambda. So you will end up with two

442
00:27:57,928 --> 00:28:01,446
lambdas, one for handling the reads and one for handling all the rest

443
00:28:01,468 --> 00:28:04,950
of the operations. The beauty of this approach is that you can

444
00:28:05,020 --> 00:28:08,530
iterate inside your workload and your architecture slowly but steady.

445
00:28:08,610 --> 00:28:12,106
And because you're using a modular approach, you will be able to

446
00:28:12,208 --> 00:28:16,490
extract pieces from a lambda or from a microservice very

447
00:28:16,560 --> 00:28:20,140
quickly without having too many headaches when you want to do so,

448
00:28:21,390 --> 00:28:24,880
another approach could be hired strategies. Imagine that you have

449
00:28:25,410 --> 00:28:29,438
some workload that has to live on prem and on cloud.

450
00:28:29,604 --> 00:28:33,214
And in that case, what you could do with a cyber architecture is something like

451
00:28:33,252 --> 00:28:36,722
that. You can have your cyber architecture that is running

452
00:28:36,776 --> 00:28:40,082
on AWS with lambda, and then you may want to use

453
00:28:40,136 --> 00:28:43,630
knative that is running maybe in AWS or on Prem,

454
00:28:43,710 --> 00:28:47,086
and the business logic will remain the same. And that's the other

455
00:28:47,128 --> 00:28:50,754
cool thing, because in this case you can only change the adapters,

456
00:28:50,802 --> 00:28:54,774
therefore the environment. Because the piece of logic is well encapsulated and

457
00:28:54,812 --> 00:28:58,630
segregated behind force, there is no issues

458
00:28:58,700 --> 00:29:02,534
as long you are maintaining the same contract between the

459
00:29:02,572 --> 00:29:06,422
adapters and the piece of logic. And the beauty that you're using the adapter,

460
00:29:06,486 --> 00:29:09,898
you can manipulate the request or the response from a

461
00:29:09,904 --> 00:29:13,246
third party service in a way that you maintain the

462
00:29:13,268 --> 00:29:16,570
same contract between the business logic and the adapters.

463
00:29:16,650 --> 00:29:19,982
So you write once and you have the possibility to have your business

464
00:29:20,036 --> 00:29:22,670
logic spread and tested everywhere.

465
00:29:24,150 --> 00:29:27,826
Finally, there is a very futuristic approach that

466
00:29:27,848 --> 00:29:31,358
is called a Petalit architecture, that is leveraging also executive

467
00:29:31,374 --> 00:29:35,334
architecture. Petalit basically is this idea where you

468
00:29:35,372 --> 00:29:40,070
maintain a microservice implementation for

469
00:29:40,140 --> 00:29:44,520
your development space, but then when you deploy, you deploy a sort of

470
00:29:45,130 --> 00:29:48,634
modular model in your infrastructure. In this

471
00:29:48,672 --> 00:29:52,074
case you are going to reduce the distribution or

472
00:29:52,112 --> 00:29:55,206
distribution system, but you have the benefit

473
00:29:55,238 --> 00:29:58,746
of modularize different things. And there is a library currently

474
00:29:58,928 --> 00:30:02,154
that is in node js

475
00:30:02,202 --> 00:30:05,370
that is trying to achieve that leveraging. Also the possibility

476
00:30:05,450 --> 00:30:09,166
to load at runtime portion of the logic of your

477
00:30:09,268 --> 00:30:12,350
microservices, or in this case method architecture.

478
00:30:13,090 --> 00:30:16,722
I think it's, let's say, still early days and there is a lot

479
00:30:16,776 --> 00:30:20,066
to digest on that side and also to see

480
00:30:20,088 --> 00:30:23,954
the drawback and the benefits. But I thought it was interesting to add

481
00:30:23,992 --> 00:30:28,174
in this talk because you can see how exciting

482
00:30:28,222 --> 00:30:32,166
architecture, despite it, only a new concept is evolving through

483
00:30:32,268 --> 00:30:35,350
different and used through different architectures.

484
00:30:36,730 --> 00:30:40,860
Obviously excavator architecture was introduced in

485
00:30:41,310 --> 00:30:44,586
2005 and since then there

486
00:30:44,608 --> 00:30:48,010
were quite a few changes. So later

487
00:30:48,080 --> 00:30:51,494
on there was introduced the onion architecture

488
00:30:51,542 --> 00:30:54,974
and right after the clean architecture, both of them are

489
00:30:55,012 --> 00:30:58,702
based on examiner architecture. And what they do,

490
00:30:58,756 --> 00:31:02,138
they solve the problem of having a more opinionated way to structure

491
00:31:02,154 --> 00:31:05,666
the business logic. So it's very important that you remember,

492
00:31:05,848 --> 00:31:09,246
if you need to structure the business logic further,

493
00:31:09,358 --> 00:31:13,394
you can use hexagonal architecture that

494
00:31:13,432 --> 00:31:16,610
are built on top of the concept of eTc architecture.

495
00:31:16,950 --> 00:31:20,546
In my opinion, I believe that if you're using lambda correctly,

496
00:31:20,578 --> 00:31:23,766
if you divide your domain correctly, it's more likely that

497
00:31:23,788 --> 00:31:27,774
you don't need to structure even further business logic, because the cognitive

498
00:31:27,842 --> 00:31:31,526
load inside a specific lambda is very small and it's

499
00:31:31,558 --> 00:31:34,410
easy to maintain and manage properly.

500
00:31:36,270 --> 00:31:39,446
After a bit that I'm talking about, that probably you're

501
00:31:39,478 --> 00:31:43,466
asking yourself, is it the definitive architecture that AWS recommends

502
00:31:43,498 --> 00:31:47,454
for working with lambda? But the answer is, it depends. As usually

503
00:31:47,492 --> 00:31:50,714
in architecture, the context is king, and based on the context

504
00:31:50,762 --> 00:31:53,854
you take these kinds of decisions. And therefore my suggestion

505
00:31:53,902 --> 00:31:58,900
is, if you have a workload that has to evolve and change often,

506
00:31:59,270 --> 00:32:03,010
please try to adopt this kind of architecture, because that will

507
00:32:03,080 --> 00:32:06,766
allow you to evolve your code without the risk

508
00:32:06,798 --> 00:32:10,214
to introduce too many issues inside it. On the other

509
00:32:10,252 --> 00:32:13,874
side, if you have something workload that has to be like maybe a POC

510
00:32:13,922 --> 00:32:17,430
or something that has to leave for a short amount of time, or a very

511
00:32:17,500 --> 00:32:20,646
small logic that I don't know, just has

512
00:32:20,668 --> 00:32:24,202
to retrieve some JSON from a third party system

513
00:32:24,256 --> 00:32:27,642
or something like that probably is an overkill. Therefore be

514
00:32:27,696 --> 00:32:31,718
pragmatic in your decision. But bear in mind that this is a very solid option

515
00:32:31,824 --> 00:32:35,438
for evolving your workload, especially when you work in system for

516
00:32:35,444 --> 00:32:38,686
a long long time. So to

517
00:32:38,708 --> 00:32:42,222
prop up what we have seen today is that separation concern is

518
00:32:42,276 --> 00:32:46,382
a key requirement for workloads now

519
00:32:46,436 --> 00:32:50,222
on the cloud and XML architecture provide a really strong separation

520
00:32:50,286 --> 00:32:53,966
concern. The infrastructure is totally decoupled from the business logic

521
00:32:54,078 --> 00:32:57,282
and we have easy to test an easy

522
00:32:57,336 --> 00:33:01,442
test path for exaggerating statue because of the modularization and the strong separation

523
00:33:01,506 --> 00:33:05,314
cluster. And finally you can use this approach

524
00:33:05,362 --> 00:33:08,840
for not only structuring your code but for many

525
00:33:09,530 --> 00:33:13,146
use cases in your day to day AWS a developer that

526
00:33:13,168 --> 00:33:16,614
are definitely simplified. In this slide

527
00:33:16,662 --> 00:33:19,930
you can find a lot of let's say link.

528
00:33:20,080 --> 00:33:23,642
And also I wrote an article that's called developing evolution

529
00:33:23,706 --> 00:33:27,102
architecture with AWS Lambda that basically walk you through

530
00:33:27,156 --> 00:33:31,006
the code example and even provide a code example that is public on

531
00:33:31,028 --> 00:33:33,390
GitHub and you can find link in this slide.

532
00:33:34,130 --> 00:33:37,306
Thank you very much for your time. I hope that you enjoyed the session.

533
00:33:37,418 --> 00:33:40,926
If you have any questions you can draw me a line that is on

534
00:33:40,948 --> 00:33:44,174
the bottom left of this slide. My personal email.

535
00:33:44,292 --> 00:33:47,526
Feel free to to contact me and

536
00:33:47,628 --> 00:33:50,982
I hope that you have a great rest of the office. Have a nice

537
00:33:51,036 --> 00:33:51,140
day.

