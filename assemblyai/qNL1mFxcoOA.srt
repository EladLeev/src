1
00:00:00,250 --> 00:00:04,830
Are you an SRE, a developer,

2
00:00:06,610 --> 00:00:10,474
a quality engineer who wants to tackle the challenge of improving

3
00:00:10,522 --> 00:00:14,254
reliability in your DevOps? You can enable your DevOps for

4
00:00:14,292 --> 00:00:17,614
reliability with chaos native create your

5
00:00:17,652 --> 00:01:17,222
free account at Chaos native Litmus Cloud day

6
00:01:17,356 --> 00:01:20,386
my name is Dave McAllister and I'm here to talk about Murphy's

7
00:01:20,418 --> 00:01:23,810
laws for observability. This is going to be covering

8
00:01:23,890 --> 00:01:27,538
a couple of interesting concepts, both of how we look at observability,

9
00:01:27,714 --> 00:01:31,514
as well as how Murphy, which were all familiar with,

10
00:01:31,632 --> 00:01:35,114
apply to what is driving our new need for this

11
00:01:35,152 --> 00:01:38,186
new paradigm of observability here.

12
00:01:38,288 --> 00:01:41,626
I'd like to thank you for joining me today to let me to listen to

13
00:01:41,648 --> 00:01:45,086
me talk about observability, as well as I'd like to

14
00:01:45,108 --> 00:01:48,382
thank Conf 42 for giving me the chance to get up here and talk about

15
00:01:48,436 --> 00:01:52,106
this. But first, I'm Dave McAllister.

16
00:01:52,218 --> 00:01:55,342
I'm the open source technology evangelist at NginX,

17
00:01:55,406 --> 00:01:58,642
part of f five, and my role is to help

18
00:01:58,696 --> 00:02:02,450
people understand both how to get involved in the

19
00:02:02,520 --> 00:02:06,402
Nginx open source projects, of which there are actually a lot of them now

20
00:02:06,536 --> 00:02:10,418
as well, has how to best make use of the open source aspects

21
00:02:10,514 --> 00:02:13,874
I am an open source geek. I started with Linux in version

22
00:02:13,922 --> 00:02:17,846
zero point 93. I've also been a standards walk,

23
00:02:18,028 --> 00:02:22,002
and as you can probably tell, I'm perfectly willing to talk. But almost anything

24
00:02:22,076 --> 00:02:26,006
at drop of a hat. Here's my LinkedIn. You can find me on LinkedIn

25
00:02:26,038 --> 00:02:29,834
at Dave Mack Davemc, and I'd love to hear from

26
00:02:29,872 --> 00:02:33,614
you. However, nobody is

27
00:02:33,652 --> 00:02:37,310
just their job role. So let me share a couple of other interesting data points,

28
00:02:37,380 --> 00:02:41,086
or interesting to me at least for things. One, I'm owned by

29
00:02:41,108 --> 00:02:44,670
three cats, maybe four, because we now have a little

30
00:02:44,740 --> 00:02:48,354
kitten who has moved into the backyard that were trying to figure out how

31
00:02:48,392 --> 00:02:51,746
we can tame her. But I am owned by cats, which means I

32
00:02:51,768 --> 00:02:55,554
am absolutely used to being ignored. I have also spent ten years

33
00:02:55,592 --> 00:02:59,862
as a soccer ref football for those of you in Europe and other

34
00:02:59,996 --> 00:03:03,286
sensible places in the world. So I'm also used

35
00:03:03,308 --> 00:03:06,806
to people disagreeing with me. So feel free to do either one

36
00:03:06,828 --> 00:03:10,540
of those things, but I'm hoping that you won't spend too much time ignoring me.

37
00:03:11,870 --> 00:03:15,418
So let's start with Murphy. Murphy's law is very simple.

38
00:03:15,504 --> 00:03:18,918
Whatever can go wrong will go wrong. And this is something we're

39
00:03:18,934 --> 00:03:22,394
all familiar with. We constantly see things that we

40
00:03:22,432 --> 00:03:25,662
think were going to go right, and all of a sudden something has changed around

41
00:03:25,716 --> 00:03:28,922
that. But when we add the first corollary

42
00:03:28,986 --> 00:03:32,910
to this at the worst possible time. Then life

43
00:03:32,980 --> 00:03:36,434
starts getting interesting. It's not just enough that something

44
00:03:36,472 --> 00:03:40,450
has gone wrong, it's always when it makes a major

45
00:03:40,600 --> 00:03:44,386
difference. And so we need to start looking at how we can sort

46
00:03:44,408 --> 00:03:48,018
of mitigate some of this impact of what Murphy

47
00:03:48,034 --> 00:03:51,430
is doing. And part of that comes into this whole

48
00:03:51,500 --> 00:03:55,506
concept around observability. There are lots

49
00:03:55,538 --> 00:03:58,374
of Murphy's categories, and in fact I'm introducing one now here.

50
00:03:58,412 --> 00:04:02,294
Murphy's for observability here. But there are things like Murphy's technologies

51
00:04:02,342 --> 00:04:05,646
laws, or Murphy's military law. The military law. One of

52
00:04:05,648 --> 00:04:08,954
my favorite ones is if you need to find an

53
00:04:08,992 --> 00:04:12,346
officer, take a nap. By the way, that works just as

54
00:04:12,368 --> 00:04:15,774
well for vps in high tech as well. Or the technology

55
00:04:15,892 --> 00:04:19,726
law logic is a way of arriving at

56
00:04:19,748 --> 00:04:23,406
an incorrect conclusion with absolute certainty. But you'll find

57
00:04:23,428 --> 00:04:26,798
them on love, on cooking, on cars. And there are spinoffs

58
00:04:26,894 --> 00:04:30,274
such as the axioms and admissions, as well

59
00:04:30,312 --> 00:04:34,142
as even into our humor environments. 70 maxims of maximally

60
00:04:34,206 --> 00:04:37,574
effective mercenaries so Murphy has a

61
00:04:37,612 --> 00:04:41,538
big impact on all sorts of things. And people are constantly

62
00:04:41,634 --> 00:04:45,046
coming up with new things that make sense for a

63
00:04:45,068 --> 00:04:48,786
Murphy's law approach. But let's jump into

64
00:04:48,828 --> 00:04:51,866
it. Murphy's law for observability number one,

65
00:04:51,968 --> 00:04:55,258
if you perceive that there are four possible ways in which a

66
00:04:55,264 --> 00:04:58,502
procedure can go wrong and circumvent these, a fifth,

67
00:04:58,566 --> 00:05:02,160
why unprepared for will promptly develop.

68
00:05:03,490 --> 00:05:07,278
So far I have yet to hear a better description of

69
00:05:07,364 --> 00:05:11,374
the life of an SRE. Our jobs are to

70
00:05:11,412 --> 00:05:15,282
try to both mitigate what could happen

71
00:05:15,416 --> 00:05:18,482
has well as be prepared for that fifth way to show

72
00:05:18,536 --> 00:05:22,302
up. So when we start looking at this, this becomes

73
00:05:22,366 --> 00:05:25,970
the necessary points to make sense of

74
00:05:26,040 --> 00:05:29,942
our environments. We need to know what's going on at all times.

75
00:05:30,076 --> 00:05:33,218
And not just the oh look, the lights are blinking approach.

76
00:05:33,314 --> 00:05:36,866
We need to be able to look and see what's going on and how it's

77
00:05:36,898 --> 00:05:40,506
impacting our users, our systems and our environments at

78
00:05:40,528 --> 00:05:44,074
any given time. And that leads us to this concept of

79
00:05:44,112 --> 00:05:48,026
observability. Observability is a hot topic in

80
00:05:48,048 --> 00:05:51,262
the SRE world, in fact, in almost all of the technology world

81
00:05:51,316 --> 00:05:54,846
here. And observability is really all around data.

82
00:05:55,028 --> 00:05:58,894
It's the deep sources of data that let us see what's going

83
00:05:58,932 --> 00:06:02,910
on inside of our systems, inside of our applications,

84
00:06:03,350 --> 00:06:06,722
all the way from the ground, all the way up to the

85
00:06:06,776 --> 00:06:10,354
user viewpoint and user journey experience going through

86
00:06:10,392 --> 00:06:13,042
this overall system basis here,

87
00:06:13,176 --> 00:06:16,838
generally speaking, you'll hear it as metrics. Do I

88
00:06:16,844 --> 00:06:20,166
have a problem traces? Where is the

89
00:06:20,188 --> 00:06:23,462
problem and locks. Why is this problem happening?

90
00:06:23,596 --> 00:06:27,422
So detect, troubleshoot or root cause analysis.

91
00:06:27,586 --> 00:06:31,254
However, observability is not limited to those classes

92
00:06:31,302 --> 00:06:34,474
of data. Observability can and should make use

93
00:06:34,512 --> 00:06:38,042
of any data that's necessary for us to be able to

94
00:06:38,096 --> 00:06:41,774
understand and infer the operation of our

95
00:06:41,812 --> 00:06:44,830
underlying system. And in fact,

96
00:06:44,980 --> 00:06:49,034
observability is about those deeper sources, the new sources

97
00:06:49,082 --> 00:06:52,430
of data, and the data that tie our environment together,

98
00:06:52,580 --> 00:06:57,060
that lets us understand at each point in time what's happening here.

99
00:06:57,510 --> 00:07:01,234
Don't limit yourself just because you have a source of

100
00:07:01,272 --> 00:07:05,010
data. Be ready to look at more sources of data inside of were.

101
00:07:05,080 --> 00:07:08,662
And interestingly enough, observability really is a proxy for

102
00:07:08,716 --> 00:07:12,470
customer happiness. If we can understand what's going on and understand

103
00:07:12,540 --> 00:07:16,134
the driving influence on our user base, then we can

104
00:07:16,172 --> 00:07:19,900
actually use observability data to help us understand their experience.

105
00:07:20,830 --> 00:07:24,806
Down at the bottom, observability has been around for a while is what the engineering

106
00:07:24,838 --> 00:07:28,346
definition is designing, defining the exposure of

107
00:07:28,368 --> 00:07:32,014
state variables in such a way to allow inference of

108
00:07:32,052 --> 00:07:35,534
internal behavior. We've expanded that our

109
00:07:35,572 --> 00:07:39,390
internal behavior now encompasses a lot of different points,

110
00:07:39,540 --> 00:07:42,560
and we need to be able to also correlate across those.

111
00:07:43,010 --> 00:07:46,398
And that leads us to Murphy's observability

112
00:07:46,494 --> 00:07:50,706
number two here. Every solution breeds new problems.

113
00:07:50,888 --> 00:07:54,370
So now that we've got this new data, we now have a whole new class

114
00:07:54,440 --> 00:07:57,990
of issues that are coming into play here. There's also

115
00:07:58,140 --> 00:08:01,654
the underlying concepts of where this data is coming

116
00:08:01,692 --> 00:08:05,558
from. Why do we have all this data here? Well, this is

117
00:08:05,564 --> 00:08:09,138
the Knievon framework. Knievon framework is a way of approaching and

118
00:08:09,164 --> 00:08:12,950
look at the transition over time of an activity

119
00:08:13,030 --> 00:08:16,918
here. And we start with simple we used to have monolithic systems,

120
00:08:17,014 --> 00:08:20,934
and we used to have single source languages,

121
00:08:21,062 --> 00:08:23,694
and we used to be able to look at the blinking lights and say,

122
00:08:23,732 --> 00:08:27,694
oh look, things are working, so things must be fine here.

123
00:08:27,892 --> 00:08:31,242
But now we've gone into a cloud environment.

124
00:08:31,386 --> 00:08:34,690
A lot of things have moved to public and private clouds here,

125
00:08:34,760 --> 00:08:38,770
which means we now have elastic and ephemeral things

126
00:08:38,840 --> 00:08:42,194
change. Things may not be were when we go to look for them.

127
00:08:42,312 --> 00:08:45,910
Therefore, failures don't exactly repeat.

128
00:08:46,250 --> 00:08:50,534
And because we now have microservices, a service that

129
00:08:50,572 --> 00:08:54,006
is as small as necessary, that's being pulled together through

130
00:08:54,028 --> 00:08:58,430
a loose communications mechanism, were we find that debugging

131
00:08:58,530 --> 00:09:02,394
is no longer as traditionally capable as

132
00:09:02,432 --> 00:09:05,994
it was. Therefore, traditional monitoring can't save us

133
00:09:06,032 --> 00:09:09,766
anymore. What we've now done is something that you would never do in math

134
00:09:09,798 --> 00:09:13,534
class. You've changed two variables at the same time here

135
00:09:13,652 --> 00:09:17,050
we've added the complicated world of microservices,

136
00:09:17,210 --> 00:09:20,766
where they run, how they run, how many of the services are running at any

137
00:09:20,788 --> 00:09:24,718
given times with the elastic ephemeral behavior of cloud environments

138
00:09:24,814 --> 00:09:28,910
or orchestrated environments here that give us a chaotic

139
00:09:28,990 --> 00:09:32,498
model. It's not there. In fact, we already planned that it

140
00:09:32,504 --> 00:09:35,598
wasn't going to be there very quickly for this. That have led

141
00:09:35,614 --> 00:09:39,942
us to this complex environments. Complex environment means

142
00:09:39,996 --> 00:09:43,638
we need to be able to probe deeper, we need able to sense

143
00:09:43,724 --> 00:09:47,850
better, and we need able to respond in ways that may not be as

144
00:09:47,920 --> 00:09:50,970
clear as they used to be. In a monolithic phrase.

145
00:09:51,550 --> 00:09:54,826
This is massively important and it is

146
00:09:54,848 --> 00:09:57,926
the driving change for what is creating this buzz

147
00:09:57,958 --> 00:10:01,406
around observability. And that leads us to

148
00:10:01,428 --> 00:10:05,422
Murphy's observability number three here. You can never

149
00:10:05,476 --> 00:10:08,640
run out of the way that things can go wrong.

150
00:10:09,010 --> 00:10:12,954
And the octopus riding a unicycle, juggling balls,

151
00:10:13,082 --> 00:10:16,802
is a perfect example of this. We got lots of things going on.

152
00:10:16,856 --> 00:10:20,766
There's lots of balls in the air at any given moment here, we're now keeping

153
00:10:20,798 --> 00:10:24,622
track of not only the virtual environments,

154
00:10:24,686 --> 00:10:28,978
the communication environments, we're keeping track of our orchestration environments.

155
00:10:29,074 --> 00:10:32,534
Kubernetes as an example for that. We're keeping track of

156
00:10:32,572 --> 00:10:36,294
the applications and the application pathways can change every

157
00:10:36,332 --> 00:10:40,090
single time that a transaction crosses those pathways.

158
00:10:40,910 --> 00:10:44,790
And that gives us this thing observability,

159
00:10:44,870 --> 00:10:48,470
lets us start monitoring for those things called unknown

160
00:10:48,550 --> 00:10:52,266
unknowns. So when we know something could happen or

161
00:10:52,288 --> 00:10:56,110
we're worried about it, we know to watch for it and we probably understand

162
00:10:56,180 --> 00:10:59,486
what caused it. This can be running out of disk space or

163
00:10:59,508 --> 00:11:02,734
running out of memory. We can watch for those things and we kind of know

164
00:11:02,772 --> 00:11:06,322
what we're doing here. We can also be looking at

165
00:11:06,456 --> 00:11:10,130
things that we are aware could happen, but we don't necessarily understand

166
00:11:10,280 --> 00:11:13,918
why they happened. These can be outside influences

167
00:11:14,014 --> 00:11:17,750
for this. When we get into the unknown capability,

168
00:11:18,250 --> 00:11:21,430
things can happen that we are not aware could happen,

169
00:11:21,500 --> 00:11:24,950
but when they happen, we can immediately understand, oh, that's why

170
00:11:25,020 --> 00:11:28,554
that happened. And that's an unknown known. But when we move into

171
00:11:28,592 --> 00:11:31,958
that last category of unknown unknowns,

172
00:11:32,054 --> 00:11:36,022
we're not even aware something could occur. And when it occurs,

173
00:11:36,086 --> 00:11:40,106
we don't understand why it occurred. And so observability gives

174
00:11:40,128 --> 00:11:43,614
us the ability to do that forensic exercise. Now let's just

175
00:11:43,652 --> 00:11:47,374
move back, in a sense in time to see what was

176
00:11:47,412 --> 00:11:51,050
going on and basically best infer

177
00:11:51,210 --> 00:11:54,514
and understand, to deduct what happened

178
00:11:54,632 --> 00:11:58,626
at that given moment. Once we've done this, we now

179
00:11:58,728 --> 00:12:02,514
can move this into the next category. We are now aware that

180
00:12:02,552 --> 00:12:06,238
something could occur, maybe move it into a known category.

181
00:12:06,414 --> 00:12:10,242
We may still be a known unknown. We may not understand why it occurred,

182
00:12:10,306 --> 00:12:13,526
but we now know to watch for it because it

183
00:12:13,548 --> 00:12:17,394
has occurred. That means it could occur. And once we've done the forensic

184
00:12:17,442 --> 00:12:21,270
exercise and the resolution, we actually want to make sure that we don't

185
00:12:21,350 --> 00:12:25,034
run into the same category of having to start over again. And so,

186
00:12:25,072 --> 00:12:28,614
observability gives us the ability to move from the unknown

187
00:12:28,662 --> 00:12:33,230
unknowns into the known unknowns, and even into the known knowns.

188
00:12:33,650 --> 00:12:36,160
Try saying that really fast, three or four times.

189
00:12:36,930 --> 00:12:40,270
So, sounds really great.

190
00:12:40,340 --> 00:12:43,954
But Murphy's number four tells us nothing is as easy as

191
00:12:43,992 --> 00:12:48,370
it looks. And that's because we're

192
00:12:48,870 --> 00:12:52,622
building in two different ways here. This is a microservices architecture.

193
00:12:52,686 --> 00:12:56,786
In fact, this is an ecommerce architecture. It's got checkout services,

194
00:12:56,888 --> 00:13:00,226
it's got the Internet coming into a front end, it's looking at cart

195
00:13:00,258 --> 00:13:04,550
services, it's emailing things out here. It could even be doing recommendations.

196
00:13:04,890 --> 00:13:09,042
There's lots of things. If you've ever touched any of the major ecommerce

197
00:13:09,106 --> 00:13:12,246
environments, you're probably seeing a front page environment

198
00:13:12,278 --> 00:13:16,646
for a single product that's somewhere in the neighborhood of but 43 microservices.

199
00:13:16,838 --> 00:13:20,114
Every one of those microservices connects to probably somewhere

200
00:13:20,182 --> 00:13:23,738
between four to eight additional microservices,

201
00:13:23,914 --> 00:13:27,290
and that's for a single transaction.

202
00:13:27,450 --> 00:13:31,114
Now imagine that you are scaling that, that you suddenly

203
00:13:31,162 --> 00:13:34,866
have 100,000 transactions going into your system at one point

204
00:13:34,888 --> 00:13:38,834
in time, and that 43 plus each

205
00:13:38,872 --> 00:13:42,498
of those additional pieces here now has to scale to manage

206
00:13:42,584 --> 00:13:45,950
the volume. We'll talk a little bit more about scale here.

207
00:13:46,040 --> 00:13:49,110
The headache is that every time we look at one of these things,

208
00:13:49,260 --> 00:13:53,014
we need to know where in the cycle we are when

209
00:13:53,052 --> 00:13:57,342
the problem occurred. That becomes incredibly

210
00:13:57,506 --> 00:14:01,306
important information. Nobody really can

211
00:14:01,328 --> 00:14:04,746
grasp the entire architecture in

212
00:14:04,768 --> 00:14:07,574
a gestalt, in a single picture viewpoint.

213
00:14:07,702 --> 00:14:11,358
And so we need to have our capabilities, our services

214
00:14:11,444 --> 00:14:14,480
and our tools help us understand that.

215
00:14:15,250 --> 00:14:19,210
And that's what's led to things like service maps,

216
00:14:19,290 --> 00:14:22,926
where we can see how the services connect, where the

217
00:14:22,948 --> 00:14:26,494
transactions go to, and what's happening in each independent

218
00:14:26,542 --> 00:14:30,338
transaction. We can also start looking at what the

219
00:14:30,424 --> 00:14:34,162
metrics are telling us. Metrics are the piece that lets us

220
00:14:34,216 --> 00:14:37,746
know when something has gone wrong. And so

221
00:14:37,768 --> 00:14:41,714
metrics are incredibly important. Were, and then even into the transaction

222
00:14:41,762 --> 00:14:45,282
level, we can look at something called red rate era duration,

223
00:14:45,346 --> 00:14:48,758
one of my favorite monitoring patterns of all times for this.

224
00:14:48,844 --> 00:14:52,102
And that will actually help us understand what the user's

225
00:14:52,166 --> 00:14:55,658
experience is. Keep in mind that we do have

226
00:14:55,744 --> 00:14:59,206
this concept where users are unique in individuals.

227
00:14:59,238 --> 00:15:02,422
They really only care about this transaction, the one

228
00:15:02,496 --> 00:15:06,334
they're looking at right now, how long it took and whether it was successful or

229
00:15:06,372 --> 00:15:09,886
failed. And so red gives us the ability to look at that

230
00:15:09,988 --> 00:15:13,326
in concrete overview, so we can look

231
00:15:13,348 --> 00:15:16,794
at the aggregate model and then we can drill into

232
00:15:16,852 --> 00:15:20,174
it should something show up. So for instance, my red environment

233
00:15:20,222 --> 00:15:23,906
here is showing a 25% error rate. I would love to know

234
00:15:23,928 --> 00:15:27,566
what's causing the 25% error rate. I would love to know who is it

235
00:15:27,608 --> 00:15:31,142
impacting my service map, if it's smart, can actually show

236
00:15:31,196 --> 00:15:34,678
me where things are not going through. That's a little red dot that

237
00:15:34,684 --> 00:15:38,598
you're seeing here, but I now understand the flow of the transaction

238
00:15:38,694 --> 00:15:42,394
and where its stoppage points are. So metrics tell me

239
00:15:42,432 --> 00:15:45,610
something not looking right. Traces are showing me

240
00:15:45,680 --> 00:15:50,522
where something might not be looking right with

241
00:15:50,576 --> 00:15:53,902
this is that added complexity? Now we've talked a little bit about

242
00:15:53,956 --> 00:15:57,450
these here with cloud based lack staticity.

243
00:15:57,610 --> 00:16:01,626
When we see a single service, that single service is not necessarily

244
00:16:01,738 --> 00:16:03,810
a single instance.

245
00:16:04,870 --> 00:16:08,594
That service could be multiplied times the

246
00:16:08,632 --> 00:16:12,034
number of elastic pieces needed to meet the

247
00:16:12,072 --> 00:16:15,934
scale. And because it's no longer necessary

248
00:16:15,982 --> 00:16:19,798
to scale the entire thing, here's my monolith. I'm running out of

249
00:16:19,804 --> 00:16:23,062
space. So here's my next two monoliths. It's now just

250
00:16:23,116 --> 00:16:26,486
scale a service that is having problems.

251
00:16:26,668 --> 00:16:30,010
And so our scaling becomes

252
00:16:30,590 --> 00:16:34,662
different. Our scaling is not random, but our scaling

253
00:16:34,726 --> 00:16:37,834
does come into play here around making sure

254
00:16:37,872 --> 00:16:41,786
that the right pieces are scaled the right time. With scaling

255
00:16:41,818 --> 00:16:45,946
up comes scaling down, and so things can disappear

256
00:16:46,058 --> 00:16:49,534
or reappear based on workloads. We're now moving

257
00:16:49,572 --> 00:16:53,306
into this thing called ephemeral behavior. This is where we get into

258
00:16:53,348 --> 00:16:56,754
serverless and serverless functions. And so you can look at this as such as

259
00:16:56,792 --> 00:17:00,206
AWS lambdas or Google functions,

260
00:17:00,318 --> 00:17:03,906
but these things are now designed to not be there.

261
00:17:04,088 --> 00:17:07,378
And when we start looking at the ephemeral

262
00:17:07,474 --> 00:17:10,390
capabilities here, the serverless capabilities,

263
00:17:10,890 --> 00:17:14,454
it's not unusual for warm start AWS lambda to be about

264
00:17:14,492 --> 00:17:17,846
30 milliseconds and for the complete

265
00:17:17,948 --> 00:17:21,350
execution time of the lambda to be about 1.2 seconds.

266
00:17:21,510 --> 00:17:25,398
And so we can see a lot of serverless behavior

267
00:17:25,494 --> 00:17:29,226
that's not there anymore by the time you look for it, it's not were

268
00:17:29,408 --> 00:17:32,682
because we're now also in multiple environments,

269
00:17:32,826 --> 00:17:35,802
multiple virtual machines, multiple containers,

270
00:17:35,866 --> 00:17:39,406
pods, worker nodes. We can also have these two concepts of

271
00:17:39,428 --> 00:17:42,974
called drift and SKU. And we'll get a little bit more into drift and

272
00:17:43,012 --> 00:17:46,258
SKU in a moment. But imagine that

273
00:17:46,264 --> 00:17:49,774
we've got to bring all these things together to be able to correlate

274
00:17:49,822 --> 00:17:53,394
them. Timestamps are the way that we try to correlate them

275
00:17:53,432 --> 00:17:57,374
the best. We can also look at transaction ids or trace

276
00:17:57,422 --> 00:18:00,966
ids and so forth. But to know what's happening at a given moment of time,

277
00:18:01,068 --> 00:18:04,166
we have to be able to align on that time. So we need to

278
00:18:04,188 --> 00:18:07,726
be able to make sure that we understand how the drift

279
00:18:07,778 --> 00:18:11,242
is happening between systems and how the systems are getting

280
00:18:11,296 --> 00:18:15,098
skewed by the changes in the data

281
00:18:15,184 --> 00:18:16,730
over a time period.

282
00:18:18,590 --> 00:18:22,538
So, okay, if life isn't more complex,

283
00:18:22,714 --> 00:18:25,966
things get worse under pressure. Murphy's number five

284
00:18:26,068 --> 00:18:29,674
for that. And that's because we're

285
00:18:29,722 --> 00:18:33,838
scaling and our scale is massive these days.

286
00:18:34,004 --> 00:18:37,906
Yes, we do tend to start off small, but I'll also tell you one

287
00:18:37,928 --> 00:18:41,186
of the things is that testing for production is not the

288
00:18:41,208 --> 00:18:45,242
same as running in production. I don't care has

289
00:18:45,326 --> 00:18:48,982
engineering whatever you want here. Testing for

290
00:18:49,036 --> 00:18:52,040
production will catch a lot of problems.

291
00:18:52,410 --> 00:18:56,086
But keep in mind, whatever can go

292
00:18:56,108 --> 00:18:59,478
wrong will go wrong and it will show up when you hit scale.

293
00:18:59,574 --> 00:19:03,740
So in this environment, I'm looking at 2247

294
00:19:04,190 --> 00:19:07,830
instances for this, and I can't

295
00:19:07,910 --> 00:19:11,786
watch 2247

296
00:19:11,888 --> 00:19:14,906
instances. And so I need to be able to look at this from a tooling

297
00:19:14,938 --> 00:19:18,234
basis here. I'm looking at this nice little picture

298
00:19:18,282 --> 00:19:21,646
viewpoint. I can tell you that I've got some hotspots that's a little sort

299
00:19:21,668 --> 00:19:25,642
of reddish dots inside of were. I can drill into any dot.

300
00:19:25,786 --> 00:19:29,458
The data is there for tell me what's going on

301
00:19:29,624 --> 00:19:33,134
when I choose to drill into it. But in the meantime,

302
00:19:33,182 --> 00:19:36,454
I've also got to be able to take a look and see all the different

303
00:19:36,492 --> 00:19:40,182
things that are happening. But thinking

304
00:19:40,236 --> 00:19:44,022
about the scale here, this is a very simple picture and it's only

305
00:19:44,076 --> 00:19:47,962
one viewpoint. This is simply the

306
00:19:48,016 --> 00:19:51,654
scale for Kubernetes. We have Kubernetes objects,

307
00:19:51,702 --> 00:19:55,814
secrets, namespaces, nodes, ingress points. We have pod

308
00:19:55,862 --> 00:19:59,642
churns and pods versus nodes. Inside of here. We actually

309
00:19:59,696 --> 00:20:02,922
have the containers now inside of pods. So our scale

310
00:20:02,986 --> 00:20:06,858
is multidimensional and our scale unfortunately

311
00:20:07,034 --> 00:20:10,542
does not decrease. So this is one

312
00:20:10,596 --> 00:20:13,826
piece of the picture of what our scale looks like.

313
00:20:13,928 --> 00:20:17,054
This is not the underlying virtual environments.

314
00:20:17,182 --> 00:20:20,434
This is not the application environments with built

315
00:20:20,472 --> 00:20:24,078
on microservices. And it's not necessarily the communication

316
00:20:24,174 --> 00:20:28,082
environments. This is just the Kubernetes led

317
00:20:28,146 --> 00:20:29,510
scale environment,

318
00:20:32,010 --> 00:20:35,320
which leads us to .6 here.

319
00:20:35,770 --> 00:20:38,650
If it's not in the computer, it doesn't exist.

320
00:20:39,150 --> 00:20:42,906
And I love dealing with this one in

321
00:20:42,928 --> 00:20:46,202
some ways, because this one is one that most

322
00:20:46,256 --> 00:20:49,082
times most people will nod their head yes,

323
00:20:49,216 --> 00:20:52,846
if you didn't keep track of it, it never existed in

324
00:20:52,868 --> 00:20:56,574
the first place. And so why does

325
00:20:56,772 --> 00:20:59,310
bad data happen to good computers for here?

326
00:20:59,460 --> 00:21:02,686
Well, one of the things you'll hear, particularly when you have

327
00:21:02,708 --> 00:21:06,446
as much data, has we're now throwing at you, is this thing called sampling.

328
00:21:06,558 --> 00:21:10,478
And sampling is very useful here. And you can have lots of sampling,

329
00:21:10,574 --> 00:21:15,118
you can have lots of capabilities for cutting down

330
00:21:15,304 --> 00:21:19,330
the amount of data that you are receiving

331
00:21:19,410 --> 00:21:22,438
or keeping. But here's an example.

332
00:21:22,604 --> 00:21:26,738
The first one is a sampled environment. The second one is a non sampled

333
00:21:26,754 --> 00:21:30,118
environment. They are the same environments. They're running reasonably

334
00:21:30,214 --> 00:21:34,122
close to the same. They are hitting about the same hot points at

335
00:21:34,176 --> 00:21:37,500
points in time. However, the first one is doing

336
00:21:38,030 --> 00:21:41,466
a traditional head based sampling approach. I'm going to

337
00:21:41,488 --> 00:21:44,686
grab a sample someplace inside of here. And it came back and told me my

338
00:21:44,708 --> 00:21:47,854
latency based on the tracing effort here, was one to 2

339
00:21:47,892 --> 00:21:52,106
seconds. Piece of cake. However, 3.7 seconds

340
00:21:52,218 --> 00:21:55,614
is considered to be where people will abandon their shopping carts,

341
00:21:55,662 --> 00:21:59,330
where people will abandon their pages and go someplace else. Here,

342
00:21:59,480 --> 00:22:03,870
when we look at the not sample data, we actually discover

343
00:22:04,030 --> 00:22:07,766
that our 95th percentile, our traces are

344
00:22:07,788 --> 00:22:11,670
running somewhere between 29 to 40 seconds.

345
00:22:12,010 --> 00:22:15,766
We have unhappy customer, at least one in

346
00:22:15,788 --> 00:22:18,966
this particular case. And so when we look at this,

347
00:22:19,068 --> 00:22:22,822
there's two things we also look at. The first one, the sampling,

348
00:22:22,966 --> 00:22:26,858
sampling didn't show us. I think they show us one error during that sampling point,

349
00:22:26,944 --> 00:22:30,378
because again, when you've sampled, you've got to grab this.

350
00:22:30,544 --> 00:22:34,014
No, sampling shows me that. I've got lots of errors showing up here,

351
00:22:34,052 --> 00:22:37,422
some of them significant. Before we get into it, however,

352
00:22:37,476 --> 00:22:41,006
you're going, well, okay, so I don't sample my metrics, so I know that

353
00:22:41,028 --> 00:22:44,238
were are errors. But what do you do then? You now know there

354
00:22:44,244 --> 00:22:47,906
was an error, but you didn't keep the data. How do you keep track of

355
00:22:47,928 --> 00:22:51,406
what's going on? Oh, well, okay, if I saw an error,

356
00:22:51,438 --> 00:22:54,766
then I saved the data. Think back to that unknown.

357
00:22:54,798 --> 00:22:58,034
Unknown. We don't even know necessarily what was an

358
00:22:58,072 --> 00:23:01,586
error until we get a chance to figure out

359
00:23:01,768 --> 00:23:05,078
post vac that were was an error, and then we need to

360
00:23:05,084 --> 00:23:08,774
be able to go back into it to figure out what's going on. So sampling

361
00:23:08,822 --> 00:23:12,330
is useful but problematic.

362
00:23:13,230 --> 00:23:17,194
Keep track of where you are and make sure that you get the data you

363
00:23:17,232 --> 00:23:20,960
need and the results you need at all those times.

364
00:23:21,410 --> 00:23:25,018
Because as Murphy seven tells us availability

365
00:23:25,114 --> 00:23:26,960
is a function of time,

366
00:23:28,450 --> 00:23:32,238
and the speed and

367
00:23:32,324 --> 00:23:35,842
resolution of our data impacts the insights you

368
00:23:35,896 --> 00:23:39,186
get. So again, I need to

369
00:23:39,208 --> 00:23:42,798
discuss something that's a little bit problematic,

370
00:23:42,894 --> 00:23:46,914
but pretty much straightforward, and that's this concept of accuracy

371
00:23:46,962 --> 00:23:50,342
and precision. Quite often in technology,

372
00:23:50,476 --> 00:23:53,426
we tend to use those terms interchangeably.

373
00:23:53,618 --> 00:23:56,934
They aren't. So accuracy is that

374
00:23:56,972 --> 00:24:01,130
the measurement is correct, that we correctly measured the results.

375
00:24:01,870 --> 00:24:05,162
Precision means it's consistent with all of the other

376
00:24:05,216 --> 00:24:08,586
measurements. So consider that you're target shooting with a bow and

377
00:24:08,608 --> 00:24:12,238
arrow, and you shoot six arrows, and one of

378
00:24:12,244 --> 00:24:15,854
them nails the bullseye and the other five are

379
00:24:15,892 --> 00:24:19,294
randomly scattered from ring three to

380
00:24:19,332 --> 00:24:22,834
ring five, maybe even outside the rings here. My God,

381
00:24:22,872 --> 00:24:26,130
you were accurate, but you weren't precise.

382
00:24:26,550 --> 00:24:29,966
And so which of those measurements was accurate

383
00:24:30,078 --> 00:24:34,462
is a challenge. For here, precision means that was consistent.

384
00:24:34,526 --> 00:24:38,470
So take those same six errors and group them within a two

385
00:24:38,540 --> 00:24:41,750
inch circle, all in the outer ring.

386
00:24:42,250 --> 00:24:45,890
Amazingly precise, completely not accurate.

387
00:24:46,050 --> 00:24:49,942
Observability needs both. It needs accuracy and precision.

388
00:24:50,086 --> 00:24:53,606
But again, that aggregation and analysis can skew

389
00:24:53,638 --> 00:24:56,822
this behavior. Remember back we talked about SKU

390
00:24:56,886 --> 00:25:00,640
drift and SKU? So when we look at that,

391
00:25:01,890 --> 00:25:05,454
come on, when we look at this, this is how

392
00:25:05,492 --> 00:25:08,974
you can actually miss the target for

393
00:25:09,012 --> 00:25:12,846
this here, I've taken pretty much 1 second at

394
00:25:12,868 --> 00:25:16,322
a time, requests coming in per second, and I think I've got ten

395
00:25:16,376 --> 00:25:20,318
of them here. My ten second average is 13.9 requests

396
00:25:20,334 --> 00:25:23,934
per second coming here. My 95th percentile over that 10 seconds

397
00:25:23,982 --> 00:25:27,526
is 27.5. The first five you

398
00:25:27,548 --> 00:25:30,982
can see, the average is 16 and 29, the second

399
00:25:31,036 --> 00:25:34,438
511 and 19. However,

400
00:25:34,524 --> 00:25:38,226
if all you looked at was at the aggregations, you would have

401
00:25:38,268 --> 00:25:41,626
missed the fact that there is a one of

402
00:25:41,648 --> 00:25:45,542
these that actually crossed my trigger

403
00:25:45,606 --> 00:25:48,890
environment that oneup of them went up to. But 32,

404
00:25:48,960 --> 00:25:52,446
31, 32, I can't remember the exact numbers off the top

405
00:25:52,468 --> 00:25:56,110
of my head here. We need to be able to look at every single data

406
00:25:56,180 --> 00:25:59,662
point, not just the aggregations in here,

407
00:25:59,796 --> 00:26:03,070
particularly when we're looking at alert capabilities.

408
00:26:03,570 --> 00:26:06,098
Yes, you need to be able to tailor your alerts. You don't want to be

409
00:26:06,104 --> 00:26:09,394
thrashed to death. But keep in mind that when

410
00:26:09,432 --> 00:26:13,902
you see an alert, you need to be able to use either AIML

411
00:26:13,966 --> 00:26:17,314
technology or your own knowledge to determine

412
00:26:17,362 --> 00:26:20,406
how critical that alert may be and get it to

413
00:26:20,428 --> 00:26:26,390
the right place. Part of the issue is that our precision

414
00:26:26,730 --> 00:26:30,042
resolution impacts actually the data

415
00:26:30,096 --> 00:26:34,138
that we're seeing in terms of that precision I'm talking about here.

416
00:26:34,224 --> 00:26:38,298
So if you're picking something that's being sampled or

417
00:26:38,384 --> 00:26:42,158
being not sampled, but bad sample is a bad word that's being

418
00:26:42,244 --> 00:26:46,206
chosen every second. Then the second that

419
00:26:46,228 --> 00:26:49,902
you're seeing this is somewhere between those two. If you report on a second

420
00:26:49,956 --> 00:26:53,266
basis here, you're not actually quite sure where in

421
00:26:53,288 --> 00:26:57,426
that second that data point is. When we actually have data

422
00:26:57,528 --> 00:27:00,862
now being produced or actually transmitted,

423
00:27:00,926 --> 00:27:04,366
telemetry wise, in the nano and picosecond

424
00:27:04,398 --> 00:27:08,566
ranges here, suddenly this becomes a very large issue. So keep

425
00:27:08,588 --> 00:27:12,710
in mind that aggregation is not your final

426
00:27:12,780 --> 00:27:16,214
point. Incredibly useful for

427
00:27:16,332 --> 00:27:19,498
your visualizations were we've got lots of

428
00:27:19,504 --> 00:27:23,482
data. Data is only as useful as you can aggregate it, analyze it,

429
00:27:23,536 --> 00:27:25,740
visualize it, and respond to it.

430
00:27:27,950 --> 00:27:31,770
So Murphy's number eight, if it can go wrong,

431
00:27:31,920 --> 00:27:32,860
it will.

432
00:27:35,550 --> 00:27:39,038
This one, this one has burned me a few times, has. Well,

433
00:27:39,124 --> 00:27:42,622
for this, and to keep track of that, we now

434
00:27:42,676 --> 00:27:46,218
have this larger, complex picture of the

435
00:27:46,244 --> 00:27:49,426
technology. We now have front end users, and we

436
00:27:49,448 --> 00:27:53,554
have web applications that are now living in the front end. We have back end

437
00:27:53,592 --> 00:27:57,110
systems, and the back end systems are made up of lots of different pieces.

438
00:27:57,610 --> 00:28:01,442
We have supply chain issues, we have packaged apps driven,

439
00:28:01,506 --> 00:28:04,806
connected to microservices. We have hybrid environments with

440
00:28:04,828 --> 00:28:08,518
on prem, with cloud. We have networks all over the place here,

441
00:28:08,604 --> 00:28:10,870
and then we have containers and orchestrations.

442
00:28:11,030 --> 00:28:14,746
Fortunately, we've got the data to allow us to

443
00:28:14,768 --> 00:28:17,866
figure out what's going on with each of these pieces. And so,

444
00:28:17,968 --> 00:28:21,534
synthetics, this helps us test our environment against a

445
00:28:21,572 --> 00:28:25,182
known pathway so that we can see if we're improving or

446
00:28:25,236 --> 00:28:28,686
worse. When we look at this, remember, the user only

447
00:28:28,708 --> 00:28:32,160
cares about his or her personal experience.

448
00:28:32,610 --> 00:28:36,302
Then we have user monitoring, real user monitoring, which lets us

449
00:28:36,356 --> 00:28:40,002
track a user's experience going through the system.

450
00:28:40,136 --> 00:28:44,286
We have endpoint monitoring, where we know where they're coming from, a mobile device

451
00:28:44,398 --> 00:28:47,906
or an IoT device in a car, going through a cave, or from a

452
00:28:47,928 --> 00:28:51,334
desktop as well, has being able to look at

453
00:28:51,372 --> 00:28:54,966
all of the different things that make up that underlying environment. But then

454
00:28:54,988 --> 00:28:57,618
we need to be able to aggregate it, analyze,

455
00:28:57,714 --> 00:29:00,954
visualize, and respond in any of the ways

456
00:29:00,992 --> 00:29:04,822
that are necessary. So here we come into dashboards,

457
00:29:04,886 --> 00:29:08,586
and here we start looking at application performance monitoring. How is

458
00:29:08,608 --> 00:29:12,366
the application performing? We look at the infrastructure monitoring, we look

459
00:29:12,388 --> 00:29:15,726
at incident response, the alerting structures here, we look at

460
00:29:15,748 --> 00:29:18,942
code profiling, what's happening inside of our code here.

461
00:29:19,076 --> 00:29:22,314
And in all of these cases, were still dependent

462
00:29:22,362 --> 00:29:26,162
on looking into that data set for the final

463
00:29:26,216 --> 00:29:29,714
thing for that root cause analysis, which is still probably going

464
00:29:29,752 --> 00:29:32,994
to be a log environment crossing. All of this is

465
00:29:33,032 --> 00:29:37,094
network performance, and so we have to have network performance monitoring that

466
00:29:37,132 --> 00:29:40,646
goes from end to end so that we can truly understand the

467
00:29:40,668 --> 00:29:44,566
user environment. So with

468
00:29:44,668 --> 00:29:47,574
fees, number nine, whenever you set out to do something,

469
00:29:47,692 --> 00:29:49,880
something else is going to have to be done first.

470
00:29:50,750 --> 00:29:54,186
I can't tell you the number of trips I've made to the local hardware store

471
00:29:54,288 --> 00:29:58,538
because I started a project and then suddenly realized that one,

472
00:29:58,624 --> 00:30:02,046
I didn't have something or two, the thing I thought I

473
00:30:02,068 --> 00:30:05,838
had wasn't any good anymore. In particular, I can tell

474
00:30:05,844 --> 00:30:09,406
you it's pvc glue and plumbers putty are my two

475
00:30:09,508 --> 00:30:12,874
nightmarish conditions that I always end up running to the hardware

476
00:30:12,922 --> 00:30:16,946
store to get. So when

477
00:30:16,968 --> 00:30:20,926
we look at this, one of the things that's happened is that we have changed.

478
00:30:21,038 --> 00:30:24,546
We had observerability 1.0. These topics have been

479
00:30:24,568 --> 00:30:27,906
around, collecting logs has been around, collecting traces have been

480
00:30:27,928 --> 00:30:31,318
around. Collecting metrics has been around. The problem is that we need to

481
00:30:31,324 --> 00:30:34,866
be able to correlate them, and each of them was being handled through a separate

482
00:30:34,898 --> 00:30:38,694
agent into a separate back end. Fortunately, now we have

483
00:30:38,812 --> 00:30:42,522
approaches, the observability 20, which does

484
00:30:42,576 --> 00:30:46,234
that correlation. And it's heavily driven by this thing

485
00:30:46,272 --> 00:30:49,974
called open telemetry. So open telemetry is the next version of both open

486
00:30:50,032 --> 00:30:54,302
tracing and open census, two open source projects that

487
00:30:54,436 --> 00:30:58,234
merge together to create a unified environment

488
00:30:58,362 --> 00:31:02,350
to produce the data necessary for observability.

489
00:31:06,950 --> 00:31:10,542
And if you want to get involved, open telemetry

490
00:31:10,606 --> 00:31:13,730
community on GitHub will get you a great

491
00:31:13,800 --> 00:31:17,750
start. It'll introduce you to the concepts, the whole works. It's the

492
00:31:17,820 --> 00:31:21,126
place you want to consider starting were. But I also want

493
00:31:21,148 --> 00:31:25,830
to talk a little bit about one specific piece. Open telemetry covers

494
00:31:26,170 --> 00:31:29,926
traces, metrics, and is in the process of covering

495
00:31:29,958 --> 00:31:32,778
logs. So it's bringing those three classes, the data together.

496
00:31:32,944 --> 00:31:36,790
But it didn't want to disrupt

497
00:31:36,870 --> 00:31:40,118
existing practices and so we had observability

498
00:31:40,214 --> 00:31:43,518
1.0. With their separate back ends and their separate agents.

499
00:31:43,684 --> 00:31:47,166
The collector architecture allows us to tie those together.

500
00:31:47,348 --> 00:31:51,342
You can bring it in in whatever protocol you want.

501
00:31:51,476 --> 00:31:54,766
You can actually process it inside the

502
00:31:54,788 --> 00:31:58,626
collector, should you decide to sample, should you decide to

503
00:31:58,648 --> 00:32:01,906
apply machine learning, any of those things can be done inside the

504
00:32:01,928 --> 00:32:05,486
collector. Keep in mind that as you add things to collector, it becomes more heavy

505
00:32:05,518 --> 00:32:09,446
weight and then you can pass them out into anything you want.

506
00:32:09,548 --> 00:32:13,126
So you can bring it into the open telemetry protocol and pass it out

507
00:32:13,148 --> 00:32:16,566
as a Jaeger protocol or as a Prometheus protocol. You can

508
00:32:16,588 --> 00:32:20,058
bring Prometheus in and send it to both to

509
00:32:20,144 --> 00:32:23,862
a tracing environment as well as to a metrics environment

510
00:32:23,926 --> 00:32:27,114
or keep the logs in. Plus you can bring in

511
00:32:27,152 --> 00:32:30,154
fluent d and bring all those pieces together.

512
00:32:30,272 --> 00:32:34,426
So the collector architecture allows me to be incredibly flexible

513
00:32:34,538 --> 00:32:38,494
about the types of data I collect, as well as the methods by

514
00:32:38,532 --> 00:32:42,330
which I collect them. This means if you already got solutions in place,

515
00:32:42,500 --> 00:32:46,798
it's very easy to pull to an open telemetry

516
00:32:46,894 --> 00:32:49,220
without disrupting your current work.

517
00:32:51,190 --> 00:32:54,914
So I want to cover a couple of axioms. We've covered nine of the

518
00:32:54,952 --> 00:32:57,700
Murphy's laws, but let's start with this one.

519
00:32:58,310 --> 00:33:01,506
This is the Ashley perry statistical axiom.

520
00:33:01,618 --> 00:33:05,186
Numbers are tools. They are not rules.

521
00:33:05,378 --> 00:33:08,822
And quite often we tend to treat numbers as

522
00:33:08,876 --> 00:33:12,278
rules, and that's dangerous. Again,

523
00:33:12,364 --> 00:33:15,638
think back to that. Prediction accuracy. But basically, we tend

524
00:33:15,654 --> 00:33:19,414
to tend to use things as predictive behavior. And honestly,

525
00:33:19,462 --> 00:33:22,862
yeah, sometimes you just want to know what's coming inside of here. The problem is

526
00:33:22,916 --> 00:33:26,298
that prediction is only as good as the data. Precision and accuracy.

527
00:33:26,474 --> 00:33:30,286
Flashback to that. Did I measure the thing? Is the measurement correct,

528
00:33:30,388 --> 00:33:33,886
and are the measurements all in the right alignment?

529
00:33:33,998 --> 00:33:37,326
So, are they both precise and accurate?

530
00:33:37,518 --> 00:33:41,102
But we find this most heavily used for things like historical

531
00:33:41,166 --> 00:33:44,546
versus sudden change, where we can look back and say,

532
00:33:44,648 --> 00:33:48,422
okay, on Mondays in the last four weeks,

533
00:33:48,556 --> 00:33:51,846
the median environment says it

534
00:33:51,868 --> 00:33:55,126
should be here. Therefore, we're out of range. Or we can look at it and

535
00:33:55,148 --> 00:33:58,298
say, hey, wait a minute, this thing's suddenly gone along. And all of a

536
00:33:58,304 --> 00:34:02,790
sudden, we've seen a jump in transaction

537
00:34:02,950 --> 00:34:06,890
request. The latency has gone up fivefold.

538
00:34:07,390 --> 00:34:11,066
So this starts giving us the ability to look at some of those things.

539
00:34:11,248 --> 00:34:14,590
If your trend is stationary, either it's a standard

540
00:34:14,660 --> 00:34:18,618
flipping line or it's a flat line. Yeah, probably pretty safe.

541
00:34:18,714 --> 00:34:21,758
But when you start looking at predictive behavior, you have to

542
00:34:21,764 --> 00:34:25,502
be ready to expect false positives and false negatives,

543
00:34:25,646 --> 00:34:29,220
and so things will not necessarily be absolutely

544
00:34:29,910 --> 00:34:33,394
precise. Extrapolation is

545
00:34:33,592 --> 00:34:36,786
better closer to the point of contact. The farther

546
00:34:36,818 --> 00:34:41,000
out you go, the less likely that you can successfully predict that.

547
00:34:45,450 --> 00:34:49,306
Baker's law, misery no longer loves company, now insists on it.

548
00:34:49,408 --> 00:34:53,190
In our SRE worlds, in our DevOps environments

549
00:34:53,270 --> 00:34:57,654
here, everybody is responsible for things running correctly.

550
00:34:57,782 --> 00:35:01,030
For that, this is now a shared issue.

551
00:35:01,200 --> 00:35:04,446
It's not. Oh, operations needs to fix that. It's where

552
00:35:04,468 --> 00:35:09,150
the devs get involved. And this leads really closely to observability,

553
00:35:09,490 --> 00:35:13,486
because we need to be able to exchange information as

554
00:35:13,508 --> 00:35:16,866
well as not repeat forensic steps. Observability gives us

555
00:35:16,888 --> 00:35:20,942
all this data. Each of the forensic steps, because we are in correlation

556
00:35:21,006 --> 00:35:24,418
mode, means people don't have to go back and rediscover things.

557
00:35:24,584 --> 00:35:27,378
So having all the data gives us that capability,

558
00:35:27,554 --> 00:35:30,678
as well as having the ability to share

559
00:35:30,764 --> 00:35:34,440
the previous environments at any given time.

560
00:35:34,810 --> 00:35:38,930
Make sure that your use of observability brings into

561
00:35:39,020 --> 00:35:42,826
the capability of sharing the data, not just

562
00:35:42,928 --> 00:35:46,518
a result, but sharing the data, its context

563
00:35:46,614 --> 00:35:48,010
and its correlation.

564
00:35:50,430 --> 00:35:53,966
Hill's commentaries pretty there are four of them here, but I love the

565
00:35:53,988 --> 00:35:57,518
fourth one. If it doesn't matter, it does not matter.

566
00:35:57,684 --> 00:36:01,146
So if something breaks and nobody cares, we don't

567
00:36:01,178 --> 00:36:04,838
care either. For know, literally, if the machine isn't

568
00:36:04,874 --> 00:36:08,482
running and we don't get any complaints, then probably nobody even

569
00:36:08,536 --> 00:36:11,890
knows the machine is not running for this. The problem is

570
00:36:11,960 --> 00:36:15,974
my corollary here, it doesn't matter. It does not matter until

571
00:36:16,092 --> 00:36:20,482
it does. Flashback to our unknown unknowns environments

572
00:36:20,546 --> 00:36:24,182
here. Flashback to that concept of we don't know when

573
00:36:24,236 --> 00:36:27,922
things are going to go wrong, we don't know why necessarily

574
00:36:27,986 --> 00:36:31,174
they're going to go wrong. And in fact, the only things we can guarantee

575
00:36:31,222 --> 00:36:34,780
is that something sooner or later is going to go wrong

576
00:36:35,230 --> 00:36:38,794
until it does. When that happens, you need

577
00:36:38,832 --> 00:36:41,946
to have all of the data,

578
00:36:42,128 --> 00:36:45,674
all of the observability data, not data that's been sampled,

579
00:36:45,722 --> 00:36:49,870
not data that's been been filtered, not data that's band bandwidth.

580
00:36:50,210 --> 00:36:54,154
Make sure that you have all of the data here. Observability gives you the ability

581
00:36:54,202 --> 00:36:57,506
to have all that data. Figure out how you can best make use of

582
00:36:57,528 --> 00:37:01,762
it. And finally, Murphy's law number ten.

583
00:37:01,896 --> 00:37:04,722
All's well that ends. And with that,

584
00:37:04,856 --> 00:37:08,194
I'd like to thank you for listening here. Again, I'm Dave

585
00:37:08,242 --> 00:37:11,414
Mack on LinkedIn and I would love to

586
00:37:11,452 --> 00:37:14,866
hear your thoughts and ideas around Murphy's laws

587
00:37:14,898 --> 00:37:18,706
on observability. If you've got a law that you believe applies

588
00:37:18,738 --> 00:37:22,434
to observability, please share it with me. Or honestly,

589
00:37:22,482 --> 00:37:25,462
if you think that I need to expand or don't agree with me,

590
00:37:25,516 --> 00:37:29,414
I'd love to hear from you that has well, so with that, thanks again for

591
00:37:29,452 --> 00:37:31,660
listening and enjoy the rest of the show.

