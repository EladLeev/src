1
00:00:00,250 --> 00:00:00,800
You.

2
00:00:21,650 --> 00:00:24,670
Hello everyone. And today we are going to talk about

3
00:00:24,740 --> 00:00:28,294
deploying machine learning models. Models. And I will tell a few

4
00:00:28,332 --> 00:00:31,606
stories from my experience, mostly from the

5
00:00:31,628 --> 00:00:35,094
beginning of my career as a data scientist. And probably

6
00:00:35,132 --> 00:00:38,810
you will find yourself in things story. So you can probably

7
00:00:38,880 --> 00:00:42,026
learn some of the things if you are lucky and

8
00:00:42,048 --> 00:00:45,846
you didn't have any failures like that in your career.

9
00:00:46,038 --> 00:00:49,354
So first of all, we all used to

10
00:00:49,472 --> 00:00:52,906
train the models because this is like the main task

11
00:00:52,938 --> 00:00:56,954
of us as a data scientists. We all know all of these stages

12
00:00:57,082 --> 00:01:00,522
like data gathering, like exploratory data analysis.

13
00:01:00,586 --> 00:01:04,094
Then we do feature engineering and we train our model.

14
00:01:04,212 --> 00:01:07,586
We can fine tune it by optimization of

15
00:01:07,688 --> 00:01:11,778
hyperparameters of our model and also we evaluate our model.

16
00:01:11,864 --> 00:01:15,202
This is something that we are so used to and into things process.

17
00:01:15,336 --> 00:01:19,618
And we have a specific mindset, I would say a researcher

18
00:01:19,714 --> 00:01:23,302
mindset. And we are focusing not just on the

19
00:01:23,436 --> 00:01:27,442
end solution like an accurate model, but also we are trying

20
00:01:27,516 --> 00:01:31,034
to keep the experiment right and checking everything at

21
00:01:31,072 --> 00:01:35,174
every stage. And basically deployment kind of requires

22
00:01:35,302 --> 00:01:39,766
another set of skills, another set of oops and another mindset

23
00:01:39,798 --> 00:01:43,182
as well. For example, in most of the cases you

24
00:01:43,236 --> 00:01:46,862
probably will be building some kind of a prediction service

25
00:01:46,996 --> 00:01:50,974
and it communicates with end user application or

26
00:01:51,012 --> 00:01:54,866
with the system. Depends what

27
00:01:54,888 --> 00:01:58,734
kind of problem do you solve and how your solution is integrated

28
00:01:58,862 --> 00:02:02,882
in the system in general. But the main idea is that during

29
00:02:02,936 --> 00:02:06,798
model training you're basically focusing on having the

30
00:02:06,824 --> 00:02:11,170
model and making it better, improving it all the time. While during deployment

31
00:02:11,250 --> 00:02:14,498
you are focusing on preserving your model because you don't

32
00:02:14,514 --> 00:02:18,146
want to get different responses and in form of prediction

33
00:02:18,178 --> 00:02:21,814
scores from the same model for the same input data.

34
00:02:21,932 --> 00:02:25,354
And this is like one of the main concerns to think about

35
00:02:25,392 --> 00:02:28,970
and to look at during deployment. And also

36
00:02:29,040 --> 00:02:32,526
there is completely different set of issues you have to

37
00:02:32,548 --> 00:02:36,490
focus on during deploying, for example infrastructure.

38
00:02:36,570 --> 00:02:40,730
And you don't really think about infrastructure when you training models

39
00:02:40,810 --> 00:02:44,526
like, yeah, you have to think about capabilities of your service

40
00:02:44,628 --> 00:02:48,002
or how you can deploying, what kind of models do you train.

41
00:02:48,136 --> 00:02:52,030
But still at that moment you don't think really, but production

42
00:02:52,190 --> 00:02:55,860
service, like what's those load on that and

43
00:02:56,810 --> 00:03:00,834
what you can do about that, how you can plan and organize

44
00:03:00,962 --> 00:03:04,294
infrastructure for your solution as well as you don't have to think

45
00:03:04,332 --> 00:03:07,862
about integration of the models with the whole

46
00:03:07,916 --> 00:03:11,814
system because you just work separately on your research and

47
00:03:11,852 --> 00:03:15,926
you're basically alone with your own environment

48
00:03:16,038 --> 00:03:19,226
and you can do all kinds of experiments that you want

49
00:03:19,328 --> 00:03:22,686
and you don't have to think about that moment, about the

50
00:03:22,708 --> 00:03:26,094
influence of what you do on other components of the system,

51
00:03:26,212 --> 00:03:29,742
as well as the risk quality of code, which is again

52
00:03:29,796 --> 00:03:32,960
not that important during research

53
00:03:33,490 --> 00:03:37,694
because I wouldn't say that it is unimportant,

54
00:03:37,822 --> 00:03:41,666
but it's more like not a focus of our research because we are

55
00:03:41,688 --> 00:03:45,214
focusing on the experiments. And sometimes it can get messy,

56
00:03:45,262 --> 00:03:49,094
especially if you are using Jupyter notebooks, as you may know that

57
00:03:49,212 --> 00:03:52,322
already. But for deployment,

58
00:03:52,466 --> 00:03:55,622
it's highly important to keep the quality

59
00:03:55,676 --> 00:03:59,386
of your code high, also to write tests. And in my

60
00:03:59,408 --> 00:04:02,758
opinion, tests for data scientists is crucial,

61
00:04:02,934 --> 00:04:06,634
especially for deployment, because again,

62
00:04:06,752 --> 00:04:10,690
during research you have this kind of luxury

63
00:04:10,790 --> 00:04:14,526
to be able to check your data set, see how the

64
00:04:14,548 --> 00:04:19,070
data changes, and if something goes wrong and the calculations

65
00:04:19,970 --> 00:04:23,966
are not working as you expected. But you don't have this luxury

66
00:04:23,998 --> 00:04:27,934
during deployment. And somehow you have to be able to evaluate

67
00:04:28,062 --> 00:04:31,346
whether your calculations conducted in

68
00:04:31,368 --> 00:04:34,818
an expected way and to save the states of your data

69
00:04:34,904 --> 00:04:37,974
somehow and to check that. Also there is logging, which is

70
00:04:38,012 --> 00:04:41,174
again, not really required during the research,

71
00:04:41,372 --> 00:04:44,822
probably because quite a lot of data scientists come

72
00:04:44,876 --> 00:04:48,774
from a research background, from applied mathematics and so

73
00:04:48,812 --> 00:04:52,454
on. Usually we don't really have a software engineering background

74
00:04:52,582 --> 00:04:55,814
and that's why we use such tools which don't

75
00:04:55,862 --> 00:04:59,482
really require login. Like for example, if all of us

76
00:04:59,536 --> 00:05:02,750
were using Pycharm, for example,

77
00:05:02,900 --> 00:05:06,254
probably we would use some kind of login to

78
00:05:06,292 --> 00:05:09,722
track the experiments. But if we use Jypton notebooks,

79
00:05:09,786 --> 00:05:13,070
we don't need that because we can look at the

80
00:05:13,140 --> 00:05:16,594
data at any moment and see what's going on in there while during

81
00:05:16,632 --> 00:05:20,114
deployment. Again, it's unfortunately impossible and

82
00:05:20,152 --> 00:05:24,420
we have to think about other ways to handle that. I might share

83
00:05:24,870 --> 00:05:28,114
of my mistakes during deploying

84
00:05:28,162 --> 00:05:32,086
of machine learning models, and unfortunately, quite a lot of

85
00:05:32,108 --> 00:05:35,686
them I did in production. But that's how you

86
00:05:35,708 --> 00:05:39,242
kind of learn a lot of things, and sometimes you learn

87
00:05:39,376 --> 00:05:43,098
them the hard way. But let's hope that we're not going

88
00:05:43,104 --> 00:05:47,114
to repeat that ever again. And you can learn by

89
00:05:47,152 --> 00:05:50,814
just listening what I'm going to talk about instead of

90
00:05:50,932 --> 00:05:54,926
going through that by yourself. And the first story is

91
00:05:54,948 --> 00:05:59,214
about scaling, and basically it's about the

92
00:05:59,252 --> 00:06:03,502
moment when I developed my first ever

93
00:06:03,636 --> 00:06:07,234
model and it was my first job

94
00:06:07,272 --> 00:06:10,386
as a data scientist and I needed to deploy that.

95
00:06:10,488 --> 00:06:14,306
And since I was working in a startup, and you know how sometimes it happens

96
00:06:14,408 --> 00:06:17,266
when they have really tight deadlines,

97
00:06:17,458 --> 00:06:20,786
things fast pacing, startup culture,

98
00:06:20,898 --> 00:06:24,502
investors coming to the office and training

99
00:06:24,556 --> 00:06:28,438
to get everything what they need in a few days.

100
00:06:28,604 --> 00:06:32,460
So it's quite a lot of pressure, and that's why

101
00:06:32,830 --> 00:06:35,994
especially if you are doing your first project as a data

102
00:06:36,032 --> 00:06:39,514
scientist in a startup, you have to at those same

103
00:06:39,552 --> 00:06:43,226
time do something valuable, but also do that fast because it's

104
00:06:43,258 --> 00:06:47,070
really hard to prove that this kind of

105
00:06:47,140 --> 00:06:51,566
investment worth it. And that's why I

106
00:06:51,588 --> 00:06:55,346
would say a lot of mistakes is happening for many

107
00:06:55,448 --> 00:06:58,706
different data scientists in their careers. And for

108
00:06:58,728 --> 00:07:02,226
me the story was but deploying my

109
00:07:02,248 --> 00:07:06,200
first model along with my teammate and we just basically

110
00:07:06,890 --> 00:07:10,582
created a prediction service which was really

111
00:07:10,716 --> 00:07:15,190
all built around just one model and it wasn't really able

112
00:07:15,260 --> 00:07:19,398
to scale ever by any other model. And scaling it

113
00:07:19,484 --> 00:07:23,446
was like super inconvenient. It wasn't

114
00:07:23,478 --> 00:07:26,858
really made for it, it was just made for one model.

115
00:07:27,024 --> 00:07:30,578
But in reality, I think I deployed

116
00:07:30,694 --> 00:07:34,254
more than 20 models using that prediction service and trying

117
00:07:34,292 --> 00:07:37,710
to scale that. And it was a big

118
00:07:37,780 --> 00:07:41,534
pain because again, it wasn't really made for

119
00:07:41,572 --> 00:07:44,954
it. I constantly had different issues related

120
00:07:45,002 --> 00:07:48,622
to the fact that I didn't really try to plan that thoroughly

121
00:07:48,686 --> 00:07:51,858
because I was out of time, I had deadlines and

122
00:07:51,864 --> 00:07:55,186
I felt like, okay, I'm going to just deploy that kind of model and I

123
00:07:55,208 --> 00:07:59,058
will think later about how I will be deploying other models.

124
00:07:59,154 --> 00:08:03,026
But in the future kind of gets harder and harder to prove

125
00:08:03,058 --> 00:08:05,654
that you need more time to change something,

126
00:08:05,852 --> 00:08:09,686
especially to do something from scratch.

127
00:08:09,878 --> 00:08:13,340
So basically the lesson that I learned there is that

128
00:08:13,790 --> 00:08:17,510
it's super important to plan your deploying

129
00:08:17,590 --> 00:08:21,882
thoroughly. Like try to communicate with different teammates

130
00:08:21,946 --> 00:08:25,806
from other teams as well. Especially if you don't really have an

131
00:08:25,908 --> 00:08:29,594
experience in architecture or experience in software

132
00:08:29,722 --> 00:08:33,838
development. Try to communicate with different

133
00:08:33,924 --> 00:08:37,700
people who are more experienced in that venue and

134
00:08:38,390 --> 00:08:41,822
they can help you to create great architecture,

135
00:08:41,886 --> 00:08:45,666
great plan, or even take some of the tasks that you

136
00:08:45,688 --> 00:08:49,206
are supposed to be doing for those first time ever and help you

137
00:08:49,228 --> 00:08:53,010
out with that too. Also, there is always a possibility

138
00:08:53,090 --> 00:08:56,194
that you probably will scale your solution.

139
00:08:56,322 --> 00:08:59,794
And even if you think that you're going to make just one

140
00:08:59,852 --> 00:09:03,034
model and you're never going to make any other model again

141
00:09:03,152 --> 00:09:07,126
other than things prediction service, probably you will have to maintain

142
00:09:07,158 --> 00:09:10,810
that. And by that it means that you will have to

143
00:09:10,960 --> 00:09:14,926
release different versions of the same model and retrain it.

144
00:09:15,028 --> 00:09:18,366
So it means you will have to add other versions to

145
00:09:18,388 --> 00:09:21,838
the same service. And if it's not made for it, it's going

146
00:09:21,844 --> 00:09:25,202
to be a huge pain for you for a long,

147
00:09:25,256 --> 00:09:29,154
long time. Also, it may seem that it

148
00:09:29,192 --> 00:09:32,420
takes quite a lot of time to plan

149
00:09:33,110 --> 00:09:36,190
a good prediction service for deployment,

150
00:09:36,350 --> 00:09:40,054
but actually if you do that later, it takes even more

151
00:09:40,092 --> 00:09:43,814
time and it gets even more expensive. Like I said in my

152
00:09:43,852 --> 00:09:47,730
story, I deployed over 20 models using this

153
00:09:47,820 --> 00:09:51,100
service. And already at that time,

154
00:09:51,950 --> 00:09:55,274
we all understood that it was our own way

155
00:09:55,312 --> 00:09:59,514
to do that, that it was inconvenient, that it was holding us down,

156
00:09:59,712 --> 00:10:02,626
that wasn't great in terms of resources,

157
00:10:02,678 --> 00:10:06,094
usage and so on and so on. And when we started to

158
00:10:06,132 --> 00:10:09,646
build another solution for that, and basically we just had

159
00:10:09,668 --> 00:10:13,234
to throw away everything that was done before and create

160
00:10:13,272 --> 00:10:16,770
something completely from scratch, which took really

161
00:10:16,840 --> 00:10:20,194
a lot of time. And especially it was hard since we

162
00:10:20,232 --> 00:10:23,902
had a lot of models already running in production

163
00:10:24,046 --> 00:10:28,310
and we had to keep them consistent,

164
00:10:28,650 --> 00:10:31,734
which was again, a big task in terms

165
00:10:31,772 --> 00:10:35,366
of testing and the implementation. And it was harder to

166
00:10:35,388 --> 00:10:38,774
move for all the models to another service. So it just

167
00:10:38,812 --> 00:10:42,810
seems in the beginning that you're having too much time to plan

168
00:10:42,880 --> 00:10:46,554
that, but it's never too much time to get rid of

169
00:10:46,592 --> 00:10:49,898
the huge headache you might have in the future.

170
00:10:50,064 --> 00:10:54,320
So another lessons that, another story that I had was

171
00:10:54,690 --> 00:10:57,966
about the time when I became a team lead in

172
00:10:57,988 --> 00:11:01,562
a team of data scientists. And I'm a perfectionist.

173
00:11:01,626 --> 00:11:05,026
And for me, it's really hard to kind of give out some of

174
00:11:05,048 --> 00:11:08,754
my tasks. And at that moment, I was just

175
00:11:08,872 --> 00:11:12,786
participating in model development as much as all

176
00:11:12,808 --> 00:11:16,226
of my other teammates. I wasn't just managing a team.

177
00:11:16,328 --> 00:11:19,686
And that's why there was quite a lot of things which I was

178
00:11:19,708 --> 00:11:23,202
just doing by myself. And because there was a lot of pressure,

179
00:11:23,266 --> 00:11:27,160
no time, and I was really worried about the quality

180
00:11:28,030 --> 00:11:31,386
of what I was doing. I was taking some

181
00:11:31,408 --> 00:11:36,634
of the things, just only not trying to

182
00:11:36,672 --> 00:11:40,266
delegate that anyhow. And there was a time when I

183
00:11:40,288 --> 00:11:43,726
went on a vacation and I remember it was like, it could

184
00:11:43,748 --> 00:11:47,034
be great to having out with my friends in Barcelona,

185
00:11:47,162 --> 00:11:50,590
in the park and have fun and enjoy

186
00:11:50,660 --> 00:11:54,106
the weather. But on the contrary,

187
00:11:54,138 --> 00:11:58,162
I had to go through the work chats and try to help my team

188
00:11:58,216 --> 00:12:02,382
debug some of those bugs that occurred in production, which I couldn't

189
00:12:02,526 --> 00:12:06,390
help them with because they were seeing them for the first time and they

190
00:12:06,460 --> 00:12:09,606
haven't had any experience with that because I

191
00:12:09,628 --> 00:12:13,062
was the one maintaining this deployment service and

192
00:12:13,116 --> 00:12:16,422
I didn't let anybody else do that because

193
00:12:16,476 --> 00:12:20,138
I was sure that I will be the one who will make it

194
00:12:20,224 --> 00:12:24,246
the best way. And that kind of taught

195
00:12:24,278 --> 00:12:28,010
me that you have to split your work

196
00:12:28,080 --> 00:12:31,866
somehow, mostly because you are human being and

197
00:12:31,968 --> 00:12:35,854
sometimes you're going on vacations, sometimes you get

198
00:12:35,892 --> 00:12:39,790
sick, and so on and so on. And when there is just one person

199
00:12:39,860 --> 00:12:43,060
responsible for something, it never ends well.

200
00:12:43,750 --> 00:12:48,222
So talking. But the lessons that I learned is that delegation

201
00:12:48,366 --> 00:12:52,434
is super important, like delegate if you can. It's more

202
00:12:52,472 --> 00:12:55,694
about managers, I would say, than people

203
00:12:55,752 --> 00:12:59,602
who just work on their tasks. But again, for data scientists,

204
00:12:59,666 --> 00:13:03,510
I would say it's also quite important because often

205
00:13:03,660 --> 00:13:07,110
we do so much work, which is usually done

206
00:13:07,180 --> 00:13:11,078
by software developers, by QA engineers,

207
00:13:11,174 --> 00:13:14,554
by DevOps, and we can just learn to

208
00:13:14,592 --> 00:13:18,458
cooperate with different types of people instead of

209
00:13:18,624 --> 00:13:22,094
trying to put all the hats on our

210
00:13:22,132 --> 00:13:25,354
head and training to do everything ourselves.

211
00:13:25,482 --> 00:13:29,454
Another important issue here is synchronization of

212
00:13:29,492 --> 00:13:33,042
tasks. And honestly, it feels great

213
00:13:33,176 --> 00:13:36,334
when you can actually delegate

214
00:13:36,462 --> 00:13:39,874
something and feel like your team is

215
00:13:39,912 --> 00:13:44,100
working as a one algorithm, I don't know,

216
00:13:44,470 --> 00:13:47,654
as a process. And even if you are not here,

217
00:13:47,772 --> 00:13:51,938
it's something that is working without your participation,

218
00:13:52,114 --> 00:13:55,080
and it's great not just for you, but also for the product.

219
00:13:56,010 --> 00:13:59,642
And again, it kind of helps to feel

220
00:13:59,696 --> 00:14:03,034
like you are part of the team instead of jugging everything by

221
00:14:03,072 --> 00:14:06,614
yourself. And as I said, you can't be everywhere

222
00:14:06,662 --> 00:14:10,018
at once. You can't

223
00:14:10,054 --> 00:14:12,926
always respond to everything, what is happening.

224
00:14:13,028 --> 00:14:16,506
So even though it's not super popular among

225
00:14:16,538 --> 00:14:20,286
data scientists, but the models, deployment services,

226
00:14:20,388 --> 00:14:24,242
they all should be shared in the team. Another story

227
00:14:24,296 --> 00:14:27,858
is about not being alone, and by that I mean

228
00:14:27,944 --> 00:14:31,442
not just being focused on having your team

229
00:14:31,496 --> 00:14:34,882
of data scientists, because there are so many people with different

230
00:14:34,936 --> 00:14:38,918
roles around you as well. And we had

231
00:14:39,004 --> 00:14:42,950
at some point a roadmap and it was like three months

232
00:14:43,020 --> 00:14:46,886
of a tough work and we had to focus on quite a lot

233
00:14:46,908 --> 00:14:50,474
of tasks. And other teams like back end

234
00:14:50,512 --> 00:14:53,814
development, front end development, they all had their own tasks

235
00:14:53,862 --> 00:14:57,526
as well. And we all were on a tight schedule

236
00:14:57,638 --> 00:15:01,514
and we didn't even thought at that moment that since

237
00:15:01,552 --> 00:15:05,194
we are cooperating just several times with those back

238
00:15:05,232 --> 00:15:09,374
end team, that we will have to include them and to

239
00:15:09,412 --> 00:15:13,506
tell them that they should be doing some of the small things for us.

240
00:15:13,688 --> 00:15:16,866
And our tasks depend on what

241
00:15:16,888 --> 00:15:21,026
they do. And so it happened that since it

242
00:15:21,048 --> 00:15:24,466
was too late to do something earlier, it was

243
00:15:24,488 --> 00:15:27,810
like just the last night of the deadline,

244
00:15:27,890 --> 00:15:31,734
and we're all sitting together and trying to do everything with

245
00:15:31,852 --> 00:15:35,602
backend engineers just because I totally

246
00:15:35,666 --> 00:15:39,122
forgot that me and my team, we are not just alone

247
00:15:39,186 --> 00:15:42,794
working on our solution. We are doing a part of the system

248
00:15:42,912 --> 00:15:45,802
and we had to cooperate with really a lot of people,

249
00:15:45,936 --> 00:15:49,210
with key engineers as well, with DevOps, and especially

250
00:15:49,280 --> 00:15:51,642
with backup engineers during deployment,

251
00:15:51,706 --> 00:15:55,470
because our component was just a part of the system

252
00:15:55,620 --> 00:15:59,294
which communicated with another part of it. And they needed to send

253
00:15:59,332 --> 00:16:02,506
us requests, we had to respond to

254
00:16:02,548 --> 00:16:06,494
those requests and they had to process somehow our responses.

255
00:16:06,622 --> 00:16:09,950
So after that, I think I always created

256
00:16:10,110 --> 00:16:13,710
a specific task in Jira, which included

257
00:16:13,870 --> 00:16:17,554
communication with the backend engineers, planning together

258
00:16:17,672 --> 00:16:21,126
a lot of stuff that where help is

259
00:16:21,228 --> 00:16:25,366
required. So basically the lessons that I learned is that you

260
00:16:25,388 --> 00:16:28,818
shouldn't just rely on your team. There is a lot of things that

261
00:16:28,844 --> 00:16:31,818
you do in a team. And again,

262
00:16:31,904 --> 00:16:35,606
taking all of the roles for yourself, it's not efficient.

263
00:16:35,718 --> 00:16:40,060
And probably you're not going to be that great in that instead of

264
00:16:40,750 --> 00:16:44,350
getting a help from someone who is more experienced in that.

265
00:16:44,420 --> 00:16:47,760
And also it's important to remember that

266
00:16:48,130 --> 00:16:52,474
you are not alone in the company and you're not just doing something like

267
00:16:52,532 --> 00:16:55,346
your part, which is, I don't know, the most important.

268
00:16:55,448 --> 00:16:58,180
Somehow you're all doing something together.

269
00:16:58,790 --> 00:17:03,074
Also, helping other people to understand

270
00:17:03,192 --> 00:17:06,914
what kind of work are you doing kind of helps

271
00:17:06,962 --> 00:17:10,518
you as well. For example, education of your team,

272
00:17:10,604 --> 00:17:13,734
and not just your team of data scientists, I mean,

273
00:17:13,772 --> 00:17:18,454
but the whole company helps

274
00:17:18,502 --> 00:17:21,994
them also to come to you when something happens and tell

275
00:17:22,032 --> 00:17:24,460
you what can we do for you?

276
00:17:24,990 --> 00:17:29,114
Instead of just being the one who forces things

277
00:17:29,152 --> 00:17:32,686
kind of cooperation and trying to push everyone to

278
00:17:32,708 --> 00:17:35,754
do something for you. You kind of, on the contrary,

279
00:17:35,802 --> 00:17:39,440
you try to build at once that kind of relationship

280
00:17:40,130 --> 00:17:43,362
and try to explain at once what is the essence of a data

281
00:17:43,416 --> 00:17:46,994
scientist work and how they can help you and how you can

282
00:17:47,032 --> 00:17:50,740
help them. So the next story is about

283
00:17:51,590 --> 00:17:55,178
data scientists and no need for tests.

284
00:17:55,374 --> 00:17:59,334
So prediction service that I was talking about in a few

285
00:17:59,372 --> 00:18:03,554
previous stories, we deployed it without tests,

286
00:18:03,682 --> 00:18:07,080
like zero tests. And since

287
00:18:07,610 --> 00:18:11,482
when we do the research again, as I said, we don't really use

288
00:18:11,536 --> 00:18:15,242
tests for that because we can check everything at any point. But during

289
00:18:15,296 --> 00:18:19,260
deploying we have so many things that we need to

290
00:18:19,630 --> 00:18:23,406
be attentive about, but not just the code itself,

291
00:18:23,508 --> 00:18:27,326
but also the data, how it

292
00:18:27,348 --> 00:18:29,790
is processed, how dispatched.

293
00:18:30,370 --> 00:18:34,274
There are so much things we should test about the states of data.

294
00:18:34,472 --> 00:18:38,162
And so what happened? It basically wasn't really

295
00:18:38,296 --> 00:18:41,346
just one story. I had quite a lot

296
00:18:41,368 --> 00:18:45,262
of cases like that when we had to debug something,

297
00:18:45,336 --> 00:18:49,334
trying to understand what went wrong. For example, a new category was

298
00:18:49,372 --> 00:18:53,346
added to the categorical variables

299
00:18:53,378 --> 00:18:56,838
that we used in the models and we didn't expect

300
00:18:56,924 --> 00:19:00,746
that. And everything just was breaking down as well

301
00:19:00,768 --> 00:19:03,914
as for example, you just get some

302
00:19:03,952 --> 00:19:07,734
recent values in the feature that didn't have any recent values

303
00:19:07,782 --> 00:19:11,710
when you trained the model. And again, something can break

304
00:19:11,780 --> 00:19:15,850
and you don't get any response from those model instead of handling

305
00:19:16,010 --> 00:19:19,886
all these cases. So the lessons that I learned is that

306
00:19:20,068 --> 00:19:24,314
basically, in my opinion, software engineering

307
00:19:24,442 --> 00:19:28,738
doesn't require as much tests as data scientists do,

308
00:19:28,904 --> 00:19:32,098
because we don't just work with those code, we work so

309
00:19:32,184 --> 00:19:35,698
often with data, and it's super important that

310
00:19:35,784 --> 00:19:39,286
everything that we do, but the data, every kind of feature is

311
00:19:39,308 --> 00:19:42,790
calculated the way it should be. Like we have to check

312
00:19:42,860 --> 00:19:46,338
different cases related to different ways, how we calculate

313
00:19:46,354 --> 00:19:50,282
the features, and there are so many things like, as well as

314
00:19:50,416 --> 00:19:53,498
testing later the distribution of the data,

315
00:19:53,584 --> 00:19:56,998
how it changes and so on. Also, it's kind of easier

316
00:19:57,094 --> 00:20:00,474
to write tests than to fix bugs in

317
00:20:00,512 --> 00:20:04,238
production, which kind of makes sense because sometimes

318
00:20:04,324 --> 00:20:08,046
when you're out of time, you have a tight schedule and you need to

319
00:20:08,068 --> 00:20:11,594
fix something really fast, and you don't have even logging,

320
00:20:11,642 --> 00:20:14,922
you don't have tests, you can't understand what is happening,

321
00:20:14,996 --> 00:20:18,242
you have to just debug through that. And it takes quite

322
00:20:18,296 --> 00:20:21,758
a lot of time, a lot of nerves, and it'd

323
00:20:21,774 --> 00:20:24,900
be better to kind of be prepared for that.

324
00:20:25,290 --> 00:20:28,902
And another story I wanted

325
00:20:28,956 --> 00:20:32,562
to talk about is about monitoring the models.

326
00:20:32,706 --> 00:20:36,614
Basically, it's about those past being in the past and

327
00:20:36,732 --> 00:20:40,614
but us just forgetting that we have to maintain

328
00:20:40,742 --> 00:20:44,746
our solutions. And it's interesting that even some

329
00:20:44,848 --> 00:20:49,050
quite big companies have this habit of not monitoring

330
00:20:49,710 --> 00:20:53,246
what they are doing with their models. And I had an experience

331
00:20:53,348 --> 00:20:57,226
like that when you come to the big company and they don't even monitor

332
00:20:57,338 --> 00:21:00,862
anything for years, and they only

333
00:21:00,916 --> 00:21:04,194
fix something when some of the clients tell them that

334
00:21:04,232 --> 00:21:07,442
something's going wrong, which I things is really

335
00:21:07,496 --> 00:21:11,266
bad approach. So one of the things that I

336
00:21:11,288 --> 00:21:14,574
did, again, things is those first time when I deployed models

337
00:21:14,702 --> 00:21:18,294
was that I didn't monitor how we perform.

338
00:21:18,492 --> 00:21:22,134
I monitored my metrics when

339
00:21:22,172 --> 00:21:26,246
I needed to. So I would say more like by request rather

340
00:21:26,268 --> 00:21:30,074
than doing it constantly. And at some point my

341
00:21:30,112 --> 00:21:33,254
models were performing worse and I didnt

342
00:21:33,302 --> 00:21:36,906
understand why because it was my first models and I was

343
00:21:36,928 --> 00:21:40,470
thinking maybe I should change something about how they are built,

344
00:21:40,560 --> 00:21:43,530
or, I don't know, change something about features.

345
00:21:43,610 --> 00:21:47,680
There were so many ways to do that, so many

346
00:21:48,850 --> 00:21:52,206
options, what could go wrong? And then I found out

347
00:21:52,228 --> 00:21:56,414
about such a thing called data, such shift, which happens if the

348
00:21:56,452 --> 00:21:59,906
data that you use for models changes over time. For example,

349
00:22:00,088 --> 00:22:04,034
patterns of users behavior are changing. Instead of

350
00:22:04,152 --> 00:22:07,702
ordering some products in a sequence a,

351
00:22:07,756 --> 00:22:11,222
they change the sequence in which they order those products,

352
00:22:11,356 --> 00:22:14,550
for example, and it breaks the model,

353
00:22:14,620 --> 00:22:18,706
but not in a way that you can see that. That's why monitoring

354
00:22:18,898 --> 00:22:22,646
is crucial for so many things. And it helps

355
00:22:22,678 --> 00:22:26,506
you to understand when you need to improve your solution, when you need to

356
00:22:26,528 --> 00:22:30,102
maybe change it completely and it's kind of another way

357
00:22:30,176 --> 00:22:34,234
to test your model and to catch some kind of errors,

358
00:22:34,282 --> 00:22:38,698
which are more logical errors rather than boxing

359
00:22:38,714 --> 00:22:42,314
the code. So basically the lesson that I learned

360
00:22:42,362 --> 00:22:45,906
is that monitoring is a lot

361
00:22:45,928 --> 00:22:49,746
about the result of your solution. And we

362
00:22:49,768 --> 00:22:53,314
as data scientists, we don't just build models for the sake of

363
00:22:53,432 --> 00:22:56,258
building models over. It's a lot of fun.

364
00:22:56,344 --> 00:22:59,974
But because we try to achieve something like that, and if

365
00:23:00,012 --> 00:23:03,490
we don't track how models work in Neverland,

366
00:23:03,650 --> 00:23:07,726
whether we took the right approach, whether we have to improve our approach

367
00:23:07,778 --> 00:23:11,434
somehow, maybe, or what can we do about that?

368
00:23:11,472 --> 00:23:14,826
In general, we don't know what to

369
00:23:14,848 --> 00:23:18,218
do with that. Basically, we don't really understand

370
00:23:18,384 --> 00:23:22,394
whether our solution is valuable enough, whether it's worth the

371
00:23:22,432 --> 00:23:26,206
efforts that we made. Another thing that we

372
00:23:26,228 --> 00:23:29,550
talked in the beginning, but the processes of

373
00:23:29,620 --> 00:23:33,546
model development. And there is this lifecycle

374
00:23:33,578 --> 00:23:37,058
of a model. And basically it doesn't just include model training.

375
00:23:37,224 --> 00:23:40,574
The next stage is usually model deployment and the stage

376
00:23:40,622 --> 00:23:44,078
after that is monitoring of a model. So basically it's

377
00:23:44,094 --> 00:23:48,086
just a part of a lifecycle. The model doesn't die when you

378
00:23:48,188 --> 00:23:51,074
deploy it. It doesn't cease to exist.

379
00:23:51,202 --> 00:23:55,254
It's still there, it's working. And all the work that you did before,

380
00:23:55,372 --> 00:23:59,690
it was just a part of all that. It's not like you

381
00:23:59,840 --> 00:24:03,162
standard the project and that's it. You have to maintain your model

382
00:24:03,216 --> 00:24:06,650
over time and to check, for example, how the data

383
00:24:06,720 --> 00:24:09,958
changes, how your model changes, what's the

384
00:24:09,984 --> 00:24:13,934
distribution of prediction stories and so on and so on. Another thing

385
00:24:13,972 --> 00:24:16,270
is that you may have tests,

386
00:24:17,010 --> 00:24:21,034
which is great, but also they don't really catch

387
00:24:21,162 --> 00:24:25,070
mistakes like the model started to work less accurately.

388
00:24:25,150 --> 00:24:28,846
You don't really have tests like that. So it basically helps

389
00:24:28,878 --> 00:24:32,338
you to see the logic of your solution and to check more,

390
00:24:32,424 --> 00:24:36,050
I would say data science errors, rather than seeing

391
00:24:36,120 --> 00:24:40,454
some just bugs in the code. And another point

392
00:24:40,652 --> 00:24:44,134
is that I genuinely think that data scientists work

393
00:24:44,172 --> 00:24:47,682
is not just about building models and predicting

394
00:24:47,746 --> 00:24:51,014
something, making something, just more efficient. It's more

395
00:24:51,052 --> 00:24:54,934
about finding the answer to questions like why is that,

396
00:24:55,052 --> 00:24:58,886
why we can use that, how we can improve that. And that

397
00:24:58,908 --> 00:25:02,654
is why when monitoring kind of helps us to answer these

398
00:25:02,692 --> 00:25:06,686
questions. So talking, but all the

399
00:25:06,708 --> 00:25:10,446
stories that I told you

400
00:25:10,628 --> 00:25:14,740
and what I learned about that is that

401
00:25:15,430 --> 00:25:19,326
you should always expect and plan that your solution

402
00:25:19,438 --> 00:25:23,138
will have to be able to be scaled later on.

403
00:25:23,224 --> 00:25:27,070
There is no such situation when it's worse

404
00:25:27,230 --> 00:25:31,494
for your solution, when you already try something to do it for that. Even now,

405
00:25:31,532 --> 00:25:35,286
when I build something and I think about scaling sometimes I

406
00:25:35,308 --> 00:25:38,838
still make some errors about that and I still see that

407
00:25:38,924 --> 00:25:42,858
I didn't predict some of the things and I should have done something better

408
00:25:43,024 --> 00:25:46,202
even when I already tried to plan for scaling and

409
00:25:46,256 --> 00:25:49,866
do some of the things. Imagine in my head that I

410
00:25:49,888 --> 00:25:53,838
will add here more of those pipelines, or for example, that I

411
00:25:53,924 --> 00:25:57,486
add here more of the models. So I will be deploying more

412
00:25:57,508 --> 00:26:01,070
of the models with things service. Also, it's super

413
00:26:01,140 --> 00:26:04,798
important to work as a team, and unfortunately

414
00:26:04,974 --> 00:26:08,994
I don't see that it's really a things in

415
00:26:09,032 --> 00:26:12,194
data science field because we are used to

416
00:26:12,232 --> 00:26:15,426
just doing our research on our own usually,

417
00:26:15,608 --> 00:26:19,126
and we don't really share the tasks that much. But in

418
00:26:19,148 --> 00:26:22,790
my opinion, it actually helps when someone can

419
00:26:22,860 --> 00:26:26,726
at least review what you are doing, because sometimes we tend to

420
00:26:26,748 --> 00:26:30,026
focus too much on some of the things and miss out something

421
00:26:30,208 --> 00:26:33,770
or we just get stuck at some point.

422
00:26:33,920 --> 00:26:37,654
Also, for managers or probably any data scientists,

423
00:26:37,702 --> 00:26:40,846
it's important to remember that you don't have to do everything.

424
00:26:40,948 --> 00:26:44,366
You should delegate, and there is a lot of people who can

425
00:26:44,388 --> 00:26:46,960
be better in that than you think.

426
00:26:47,330 --> 00:26:50,670
Another important issue is to be able

427
00:26:50,740 --> 00:26:54,186
to cooperate and to work with other teams

428
00:26:54,218 --> 00:26:58,402
as well and other departments. There is no just data scientists team

429
00:26:58,536 --> 00:27:01,986
work completely separately from everyone else, and they

430
00:27:02,008 --> 00:27:05,586
do something which is not related anyhow to

431
00:27:05,608 --> 00:27:08,742
the work of other teams. That is not true usually.

432
00:27:08,876 --> 00:27:12,854
And especially we get to cooperate quite a lot with

433
00:27:12,972 --> 00:27:16,610
software engineers, with QA engineers, with DevOps,

434
00:27:16,770 --> 00:27:20,534
and it's super important to educate your

435
00:27:20,572 --> 00:27:23,818
teammates in the company and

436
00:27:23,904 --> 00:27:28,186
also to build communications and

437
00:27:28,208 --> 00:27:32,358
to be ready to cooperate. Also, as I said, data scientists

438
00:27:32,534 --> 00:27:36,302
probably need tasks even more than software engineers or

439
00:27:36,356 --> 00:27:39,822
anyone else, because we don't just deal with code,

440
00:27:39,956 --> 00:27:43,982
which usually we don't have a software engineering background,

441
00:27:44,126 --> 00:27:48,146
which is that strong. And also we

442
00:27:48,168 --> 00:27:51,634
deal with data and it changes states all

443
00:27:51,672 --> 00:27:55,414
the time. So we have to be able to track that and to track

444
00:27:55,452 --> 00:27:58,902
those states. And another point

445
00:27:58,956 --> 00:28:03,554
is that model monitoring is a key to understanding

446
00:28:03,602 --> 00:28:07,094
whether we are doing something valuable, whether our model is

447
00:28:07,132 --> 00:28:10,406
performing in a good way, whether it's

448
00:28:10,438 --> 00:28:13,946
performing in an expected way, and how we can improve that. So it

449
00:28:13,968 --> 00:28:17,638
basically answers all of the questions for the future planning,

450
00:28:17,734 --> 00:28:21,034
and we don't have to feel

451
00:28:21,232 --> 00:28:25,326
like we don't know what's happening when the business side asks us

452
00:28:25,428 --> 00:28:29,166
what's happening, what can we fix, why it's not working that way.

453
00:28:29,268 --> 00:28:32,830
Monitoring is something that helps us to be the same control,

454
00:28:32,980 --> 00:28:36,974
to maintain the models and to remember that their life

455
00:28:37,012 --> 00:28:40,922
cycle is going on and they are not just disappear

456
00:28:40,986 --> 00:28:44,998
after we do our research, get the most accurate models that

457
00:28:45,044 --> 00:28:48,742
good. So thank you for your attention, and I hope

458
00:28:48,796 --> 00:28:52,914
that this presentation was useful

459
00:28:52,962 --> 00:28:56,614
for you. And I hope that you're not going to do

460
00:28:56,732 --> 00:29:00,326
all of those mistakes. But even if you do, you remember that all

461
00:29:00,348 --> 00:29:03,300
of them are just lessons that we learned. Thank you.

