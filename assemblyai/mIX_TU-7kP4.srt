1
00:00:22,010 --> 00:00:25,926
Hi everyone, my name is Matteo Gabrielli. I am a solution architect at

2
00:00:25,948 --> 00:00:29,446
Amazon Web Services and today I want to show you

3
00:00:29,548 --> 00:00:32,902
how you can empower your business use cases by getting

4
00:00:32,956 --> 00:00:37,542
insights from text. So I will bring

5
00:00:37,596 --> 00:00:41,078
you through the need for automating document

6
00:00:41,174 --> 00:00:45,162
processing. We will have a look at the challenges and

7
00:00:45,216 --> 00:00:48,406
how AWS can help mitigate these challenges

8
00:00:48,518 --> 00:00:51,934
and then we will have a quick look at

9
00:00:51,972 --> 00:00:55,754
a demo that is an AWS solution called document

10
00:00:55,802 --> 00:00:59,150
understanding solution. So what is the current

11
00:00:59,220 --> 00:01:03,214
state of documents? Well, for many industry,

12
00:01:03,342 --> 00:01:06,946
documents are the primary business tool and

13
00:01:07,128 --> 00:01:11,620
we can think about documents as email,

14
00:01:12,950 --> 00:01:16,034
internal documentation, it could be menus,

15
00:01:16,162 --> 00:01:20,054
invoices, technical documentation. And all

16
00:01:20,092 --> 00:01:24,470
of this data is in different data stores across

17
00:01:24,540 --> 00:01:28,230
the business, right. And is rarely

18
00:01:28,310 --> 00:01:31,562
decreasing as number of documents, right. This number

19
00:01:31,616 --> 00:01:35,260
is usually growing and growing year over year.

20
00:01:35,870 --> 00:01:39,670
Garner research claimed that the organization worldwide

21
00:01:39,750 --> 00:01:43,854
record a 25% growth in usage of paper

22
00:01:43,972 --> 00:01:47,982
each year. So I don't want to focus that much

23
00:01:48,036 --> 00:01:51,966
on that AWS, all the challenges that

24
00:01:52,068 --> 00:01:55,966
this can bring, right? So how to extract

25
00:01:56,078 --> 00:01:59,794
information at scale and how to avoid to

26
00:01:59,832 --> 00:02:03,426
be prone to errors in the

27
00:02:03,448 --> 00:02:06,770
processes, right? So let me recap,

28
00:02:06,850 --> 00:02:10,694
what are the challenges in processing documents. So first

29
00:02:10,732 --> 00:02:14,390
of all, if you are doing this manually, probably it's really time

30
00:02:14,460 --> 00:02:18,026
consuming, it could be error prone and most

31
00:02:18,048 --> 00:02:21,994
of the time expensive. It doesn't really scale well.

32
00:02:22,192 --> 00:02:25,580
And most of the time if you are doing this,

33
00:02:26,990 --> 00:02:30,734
probably we are using some rule based system

34
00:02:30,932 --> 00:02:34,206
and those are not really flexible. Most of

35
00:02:34,228 --> 00:02:38,798
the time, if we want to extract information and

36
00:02:38,884 --> 00:02:42,078
we want to leverage machine learning,

37
00:02:42,164 --> 00:02:45,986
probably we need to have a set of skills in order to

38
00:02:46,008 --> 00:02:49,810
do that. And also maybe data that is labeled

39
00:02:50,230 --> 00:02:53,522
many times. Also we want to incorporate in this

40
00:02:53,576 --> 00:02:58,402
process the human in order to verify

41
00:02:58,546 --> 00:03:02,514
and be part of this workflow. So how AWS

42
00:03:02,562 --> 00:03:06,294
can help? Well, let's focus on

43
00:03:06,332 --> 00:03:10,810
this use case of understanding documents.

44
00:03:11,150 --> 00:03:14,618
So what is the first action that we have to do?

45
00:03:14,704 --> 00:03:19,206
Well, we are given a document and we want to extract

46
00:03:19,318 --> 00:03:23,450
information from there. So extract the text that is in documents.

47
00:03:23,610 --> 00:03:27,582
Once we have this row text, we want to make sense

48
00:03:27,716 --> 00:03:31,470
out of this data and we want to loop

49
00:03:32,370 --> 00:03:36,238
to add a human in this loop to verify

50
00:03:36,414 --> 00:03:39,794
that the information extracted and the

51
00:03:39,832 --> 00:03:43,762
sense we are making out of this data makes

52
00:03:43,816 --> 00:03:47,654
sense. So who is going to help in

53
00:03:47,692 --> 00:03:51,640
implement this workflow? It will be AWS EI services.

54
00:03:52,010 --> 00:03:55,570
And let's put EI services in a context.

55
00:03:55,730 --> 00:03:59,798
So the context in this case is the AWS

56
00:03:59,894 --> 00:04:03,754
machine learning stack. As you can see, there are

57
00:04:03,792 --> 00:04:07,194
three different layers. At the bottom you can

58
00:04:07,232 --> 00:04:11,786
see the machine learning frameworks and infrastructure

59
00:04:11,978 --> 00:04:15,962
layer. This one is intended for expert practitioner,

60
00:04:16,026 --> 00:04:19,722
right? You can find in there the more common framework,

61
00:04:19,786 --> 00:04:22,874
machine learning frameworks, Tensorflow,

62
00:04:22,922 --> 00:04:25,638
Pytorch, Apache, Mxnet,

63
00:04:25,834 --> 00:04:29,410
the deep learning EMI and the containers gpus.

64
00:04:30,150 --> 00:04:34,420
Then in the middle layer, those are

65
00:04:35,130 --> 00:04:39,270
the machine learning services that make it easy for

66
00:04:39,420 --> 00:04:42,662
machine learning developers and data scientists to build,

67
00:04:42,796 --> 00:04:46,310
train and deploy machine learning models.

68
00:04:46,650 --> 00:04:51,398
And this is happening. Leveraging Amazon Sagemaker

69
00:04:51,494 --> 00:04:55,846
and its features. What we are going to concentrate

70
00:04:55,878 --> 00:04:59,722
on today and is the last layer, the top one. And those

71
00:04:59,776 --> 00:05:03,966
are, those are these

72
00:05:04,068 --> 00:05:08,234
AI services allow all developers to use pretrained

73
00:05:08,282 --> 00:05:12,080
model to add intelligence to any application

74
00:05:12,550 --> 00:05:15,810
without machine learning expertise.

75
00:05:17,350 --> 00:05:22,034
So what we are going to have

76
00:05:22,072 --> 00:05:26,050
a closer look today at it will be comprehend

77
00:05:26,210 --> 00:05:30,114
textract Kendra and comprehend

78
00:05:30,162 --> 00:05:33,970
medical. Then we will also talk about Amazon

79
00:05:34,050 --> 00:05:38,066
augmented EI. But let's

80
00:05:38,098 --> 00:05:41,698
start with the first Amazon textract.

81
00:05:41,874 --> 00:05:45,754
So Amazon texttract is a service that extracts text form and

82
00:05:45,792 --> 00:05:49,434
table from document. It could be PDF or

83
00:05:49,472 --> 00:05:52,926
images. What are the advantages? Well that

84
00:05:53,028 --> 00:05:56,494
I have an intelligent OCR tool that is able

85
00:05:56,532 --> 00:06:00,158
to extract all of this information

86
00:06:00,324 --> 00:06:04,100
starting from my input and I don't have to

87
00:06:04,710 --> 00:06:08,146
have any machine learning experience in order to do

88
00:06:08,168 --> 00:06:11,714
that. I can just invoke text track through

89
00:06:11,752 --> 00:06:16,006
an API and this means that I

90
00:06:16,028 --> 00:06:18,950
can just build my workflow. So for example,

91
00:06:19,020 --> 00:06:23,638
given an input, use text track, extract the information and

92
00:06:23,724 --> 00:06:28,078
insert this information inside a database. And this eliminates

93
00:06:28,114 --> 00:06:31,530
the manual effort of doing this and of course can

94
00:06:31,600 --> 00:06:33,980
lower the document processing cost.

95
00:06:34,590 --> 00:06:38,060
Comprehend is the service that will

96
00:06:38,830 --> 00:06:41,934
help us in discovering insights and relationship in

97
00:06:41,972 --> 00:06:46,026
text. And as you can see the input,

98
00:06:46,058 --> 00:06:50,202
it could be text in general. So email chat,

99
00:06:50,266 --> 00:06:54,338
social phone cases that are transcribed and

100
00:06:54,504 --> 00:06:58,274
we want to apply comprehend on this

101
00:06:58,312 --> 00:07:01,954
text in order to get information as what are

102
00:07:01,992 --> 00:07:05,474
the entities that comprehend recognize.

103
00:07:05,522 --> 00:07:09,480
So are there some name of people?

104
00:07:10,250 --> 00:07:13,526
Are there some name of organization? So what

105
00:07:13,548 --> 00:07:18,140
are the key phrases? Are there some personal identifiable information?

106
00:07:18,510 --> 00:07:22,262
What is the sentiment of the text you are giving me? Is positive,

107
00:07:22,326 --> 00:07:26,410
is neutral, is negative. I can use

108
00:07:26,480 --> 00:07:29,850
comprehend to train and to do document classification,

109
00:07:30,610 --> 00:07:34,350
topic recognition, detect what is the language,

110
00:07:34,850 --> 00:07:37,230
syntax and also events.

111
00:07:37,650 --> 00:07:41,470
Where is Amazon comprehend used? Well there are

112
00:07:41,540 --> 00:07:45,666
several use cases but for

113
00:07:45,688 --> 00:07:49,346
example some of that could be intelligent document processing. That is the one

114
00:07:49,368 --> 00:07:53,134
we are looking at today. But there's also customer sentiment

115
00:07:53,182 --> 00:07:56,454
analysis contact center call analysis because maybe

116
00:07:56,492 --> 00:08:00,178
we want to recognize what is the sentiment during these cases

117
00:08:00,274 --> 00:08:04,022
or maybe what is the topics they are talking

118
00:08:04,076 --> 00:08:07,454
about. And also in PII detection.

119
00:08:07,522 --> 00:08:11,306
We will see this later in the demo. There's another

120
00:08:11,488 --> 00:08:14,534
version, let's call it like that of Amazon comprehend

121
00:08:14,582 --> 00:08:18,300
and this is Amazon comprehend medical that is based

122
00:08:19,550 --> 00:08:23,082
to be specialized in the medical

123
00:08:23,226 --> 00:08:26,618
text. So you can for example detect entities

124
00:08:26,714 --> 00:08:30,110
as medication, medical condition, test,

125
00:08:30,180 --> 00:08:33,730
treatment and procedure anatomy in the text.

126
00:08:33,880 --> 00:08:35,780
So body parts for example,

127
00:08:37,270 --> 00:08:41,022
you can extract also the relation because there will be a relation

128
00:08:41,086 --> 00:08:44,722
for example between a medication and a

129
00:08:44,776 --> 00:08:48,966
dosage and entity traits. So all

130
00:08:48,988 --> 00:08:53,926
of these complex way of recognizing these

131
00:08:54,028 --> 00:08:57,970
entities or relationship between

132
00:08:58,140 --> 00:09:01,674
inside the text is abstracted to you

133
00:09:01,792 --> 00:09:05,594
through API calls. So you can just give

134
00:09:05,632 --> 00:09:09,514
your input text and decide what you want to get out

135
00:09:09,632 --> 00:09:13,534
from there. Amazon Kendra is

136
00:09:13,572 --> 00:09:16,874
an intelligent search service powered

137
00:09:16,922 --> 00:09:19,920
by machine learning. In this case,

138
00:09:20,850 --> 00:09:24,834
the idea is to do some intelligent search,

139
00:09:24,952 --> 00:09:28,542
right? So we want to move from this lexical

140
00:09:28,606 --> 00:09:32,578
so using keywords to intelligent search

141
00:09:32,664 --> 00:09:36,630
which is searching for information by meaning

142
00:09:38,010 --> 00:09:41,766
this use natural language understanding and

143
00:09:41,868 --> 00:09:45,334
other machine learning model to take advantage of

144
00:09:45,372 --> 00:09:49,450
the rich context in unstructured

145
00:09:49,870 --> 00:09:54,138
content, the one that we are providing and get much more

146
00:09:54,304 --> 00:09:58,380
accurate search results. That what we can do with a

147
00:09:58,830 --> 00:10:03,262
lexical search, let's say later

148
00:10:03,316 --> 00:10:07,310
on we will also see how this compare

149
00:10:08,050 --> 00:10:11,566
this lexical search and intelligent search in the demo that I will

150
00:10:11,588 --> 00:10:15,902
show you. The last leading

151
00:10:15,966 --> 00:10:19,714
actor that I want you to present

152
00:10:19,832 --> 00:10:23,060
is Amazon augmented AI. That is

153
00:10:23,590 --> 00:10:27,110
it allow us to easily implement human review

154
00:10:27,180 --> 00:10:30,966
of machine learning prediction. How does it work? So we

155
00:10:30,988 --> 00:10:35,240
want to incorporate our

156
00:10:36,490 --> 00:10:39,738
reviews right inside our machine learning

157
00:10:39,904 --> 00:10:43,766
workflow. So we can do that with Amazon augmented

158
00:10:43,798 --> 00:10:47,306
AI. And this allow us to reduce the time

159
00:10:47,408 --> 00:10:51,066
in order to build all of this. Because for

160
00:10:51,088 --> 00:10:54,922
example, imagine if you have to do some reviews, sometimes you have to expose

161
00:10:54,986 --> 00:10:58,654
an interface for the user to select yes,

162
00:10:58,692 --> 00:11:01,360
this is correct or no, this is not correct.

163
00:11:01,890 --> 00:11:05,874
So Amazon augmented UI is providing you

164
00:11:05,912 --> 00:11:08,530
some pre built uis.

165
00:11:09,270 --> 00:11:13,758
You can define what kind of workflows

166
00:11:13,854 --> 00:11:17,042
workforce you want to dedicate in order to run these

167
00:11:17,096 --> 00:11:21,022
reviews. It could be a private workflow for first.

168
00:11:21,096 --> 00:11:24,614
Maybe you want to use a vendor that is trained on

169
00:11:24,652 --> 00:11:27,160
how to review the data,

170
00:11:27,630 --> 00:11:31,242
the prediction, or maybe you want to leverage the

171
00:11:31,376 --> 00:11:34,278
public workforce.

172
00:11:34,374 --> 00:11:37,702
This is for example the case as Amazon mechanical Turk,

173
00:11:37,766 --> 00:11:41,434
right? And yeah, you can integrate

174
00:11:41,482 --> 00:11:44,800
it with your custom machine learning model

175
00:11:45,410 --> 00:11:50,110
and you can use prebuilt algorithms to increase accuracy.

176
00:11:50,610 --> 00:11:53,794
So for example, how does it

177
00:11:53,832 --> 00:11:58,066
work? We can think about the

178
00:11:58,088 --> 00:12:03,362
client application that is sending the data and

179
00:12:03,496 --> 00:12:06,790
our machine learning model making predictions.

180
00:12:07,210 --> 00:12:11,026
Well, what can happen is that our machine

181
00:12:11,058 --> 00:12:14,630
learning model can return a high confidence prediction.

182
00:12:15,210 --> 00:12:18,454
And so we are

183
00:12:18,652 --> 00:12:22,950
good probably with that because we know that it's

184
00:12:23,370 --> 00:12:27,426
confident in that. But what if the confidence

185
00:12:27,458 --> 00:12:31,966
is low? Maybe we want to send it to our

186
00:12:31,988 --> 00:12:36,894
human review hands. In this case is where the

187
00:12:36,932 --> 00:12:41,162
reviewer consolidated using Amazon

188
00:12:41,226 --> 00:12:45,310
augmented AI and we store

189
00:12:45,460 --> 00:12:49,086
these results, for example in a s free bucket

190
00:12:49,278 --> 00:12:53,054
hands. From there we can come back to our client

191
00:12:53,102 --> 00:12:56,822
application. Why not? Maybe we can use the data that at

192
00:12:56,876 --> 00:13:00,690
step six we have in order to improve

193
00:13:00,850 --> 00:13:04,280
our machine learning model. Right. As an example,

194
00:13:04,970 --> 00:13:09,222
I wanted to bring you an integration example between texttract and

195
00:13:09,276 --> 00:13:12,542
Amazon augmented AI. So using textract

196
00:13:12,626 --> 00:13:16,234
but also then incorporate some human reviews and this

197
00:13:16,352 --> 00:13:20,002
could happen, for example for regulatory requirements,

198
00:13:20,166 --> 00:13:23,482
but also when we have to take sensitive

199
00:13:23,546 --> 00:13:27,520
decision and we want to decide to

200
00:13:28,130 --> 00:13:31,502
have a review. Or maybe it's because

201
00:13:31,556 --> 00:13:35,458
textract is doing its best, but probably

202
00:13:35,544 --> 00:13:39,678
we really want to double check because there are hard to read documents

203
00:13:39,854 --> 00:13:43,502
and so maybe we have to incorporate some reviews

204
00:13:43,646 --> 00:13:47,030
and well, of course the goal is

205
00:13:47,100 --> 00:13:50,614
to human to review and

206
00:13:50,652 --> 00:13:54,150
to provide an oversight. Let me bring you an example

207
00:13:54,220 --> 00:13:57,978
of what condition can we define using

208
00:13:58,064 --> 00:14:01,862
Amazon augmented AI? We can play with the confidence

209
00:14:01,926 --> 00:14:05,670
score. For example, we can say if the score

210
00:14:05,750 --> 00:14:09,530
is less than 90%, send it to review.

211
00:14:09,680 --> 00:14:13,838
But we can also say, for example,

212
00:14:13,924 --> 00:14:17,326
trigger a human review if you don't find a

213
00:14:17,348 --> 00:14:21,038
field, for example, if you are not finding the name,

214
00:14:21,124 --> 00:14:24,578
or if you are not finding the account number inside the

215
00:14:24,584 --> 00:14:27,778
document. Or we can send just a

216
00:14:27,784 --> 00:14:31,650
random sample of prediction

217
00:14:33,110 --> 00:14:37,058
to Amazon augmented Di. So review for

218
00:14:37,144 --> 00:14:40,546
a 10% sample of all documents.

219
00:14:40,738 --> 00:14:44,214
Why not? Okay, now that we have

220
00:14:44,332 --> 00:14:48,826
a better understanding of what

221
00:14:48,848 --> 00:14:53,062
are the services, the EI services that will be involved

222
00:14:53,126 --> 00:14:57,734
or that can be used, you can think about these EI

223
00:14:57,782 --> 00:15:01,366
services and the AWS services in general as

224
00:15:01,408 --> 00:15:05,246
Lego blocks that you are trying to put together in

225
00:15:05,268 --> 00:15:08,862
order to create your solution. And in this case,

226
00:15:08,916 --> 00:15:12,582
what I wanted to present you is the document understanding solution.

227
00:15:12,746 --> 00:15:16,974
And as you can see, these four components

228
00:15:17,022 --> 00:15:20,466
are going to work together and

229
00:15:20,648 --> 00:15:24,414
act. So Amazon comprehend, medical Amazon

230
00:15:24,462 --> 00:15:27,654
extract kendra and comprehend. So then when

231
00:15:27,692 --> 00:15:30,070
we get some documents in input,

232
00:15:30,970 --> 00:15:34,246
they are going to extract, understand information and

233
00:15:34,268 --> 00:15:37,698
also index this data in order to

234
00:15:37,884 --> 00:15:40,566
perform OCR form extraction,

235
00:15:40,678 --> 00:15:43,370
intelligent search table extraction,

236
00:15:44,430 --> 00:15:47,574
entity detection, medical entity detection

237
00:15:47,622 --> 00:15:51,534
and reduction controls. So let's go

238
00:15:51,572 --> 00:15:54,560
and see how this looks like in a demo.

239
00:15:55,490 --> 00:15:59,418
This is the document understanding demo solution

240
00:15:59,514 --> 00:16:02,774
that I have deployed inside my AWS

241
00:16:02,842 --> 00:16:06,754
account. Later on I will tell you more about

242
00:16:06,872 --> 00:16:10,750
how and where you can find this cloudformation template

243
00:16:10,830 --> 00:16:14,498
just to launch and to deploy it inside your

244
00:16:14,584 --> 00:16:17,670
AWS account. So as you can see,

245
00:16:17,740 --> 00:16:21,174
there's three different main thing we can

246
00:16:21,212 --> 00:16:24,662
do with the document understanding solution. One is the

247
00:16:24,716 --> 00:16:28,742
discovery. We can work with compliance so redact

248
00:16:28,806 --> 00:16:32,314
information and integrate this and do some

249
00:16:32,432 --> 00:16:36,602
workflow automation. So now

250
00:16:36,656 --> 00:16:40,306
we are in the list of documents. The documents

251
00:16:40,358 --> 00:16:44,094
that you see here are example documents, but you can

252
00:16:44,212 --> 00:16:48,174
of course bring your own documents in

253
00:16:48,212 --> 00:16:51,562
there or remove or explore

254
00:16:51,706 --> 00:16:55,890
inside these documents or just search by keywords.

255
00:16:57,670 --> 00:17:01,394
What I wanted to show you is for example

256
00:17:01,512 --> 00:17:05,574
going into a document and try to find if

257
00:17:05,612 --> 00:17:09,090
there's for example some difficult elements

258
00:17:09,170 --> 00:17:12,806
to extract as for example this table, right.

259
00:17:12,988 --> 00:17:16,946
What I can do is just preview this document

260
00:17:16,978 --> 00:17:20,266
hands, maybe select some part of it to

261
00:17:20,288 --> 00:17:24,838
extract. And as you can see is detecting

262
00:17:24,934 --> 00:17:29,050
the text that I'm highlighting or I can just ask

263
00:17:29,120 --> 00:17:33,120
to search for a keyword like health.

264
00:17:33,490 --> 00:17:37,114
And what I can also do is to convert

265
00:17:37,162 --> 00:17:41,598
all of this document into row text or maybe

266
00:17:41,764 --> 00:17:46,206
as we have a table in there asking to identify

267
00:17:46,318 --> 00:17:49,934
the table and is correctly identifying the table,

268
00:17:49,982 --> 00:17:53,694
one AWS, four rows and I can download this table

269
00:17:53,822 --> 00:17:57,960
as a CSV. Another really interesting

270
00:17:58,330 --> 00:18:01,590
feature. So in this case, who is

271
00:18:01,660 --> 00:18:05,794
doing this job is textract, doing the row

272
00:18:05,842 --> 00:18:09,382
text, extracting the row text or key value pairs or the table.

273
00:18:09,526 --> 00:18:13,370
What comprehend can do is detecting entities.

274
00:18:14,030 --> 00:18:17,338
So for example on this page, page five,

275
00:18:17,424 --> 00:18:21,754
I can say detect organization and

276
00:18:21,792 --> 00:18:25,614
AWS, you can see it's going to highlight what

277
00:18:25,652 --> 00:18:29,662
are the organization as for example this or also

278
00:18:29,716 --> 00:18:33,490
the American Diabetes Association.

279
00:18:33,990 --> 00:18:37,090
I can also, since I see a lot of numbers,

280
00:18:37,240 --> 00:18:41,282
ask him to detect quantities and is

281
00:18:41,336 --> 00:18:43,330
able to detect.

282
00:18:45,110 --> 00:18:48,534
Another feature that I wanted to show you is

283
00:18:48,572 --> 00:18:52,118
the comprehend medical one. So as you can see, when I

284
00:18:52,124 --> 00:18:55,734
go to medical entities this time, I'm able

285
00:18:55,772 --> 00:18:59,782
to also identify medical conditions, test treatment

286
00:18:59,846 --> 00:19:03,500
procedure, protected health information.

287
00:19:03,870 --> 00:19:07,882
So let's have a look, for example, a medical condition and

288
00:19:07,936 --> 00:19:10,114
as you can see, diabetes,

289
00:19:10,182 --> 00:19:13,162
prediabetes, pregnant,

290
00:19:13,306 --> 00:19:17,578
those are all medical condition that comprehend

291
00:19:17,754 --> 00:19:20,830
medical is able to identify.

292
00:19:22,710 --> 00:19:27,022
Another thing that I wanted to highlight is the possibility

293
00:19:27,166 --> 00:19:31,086
of for compliance reason to redact

294
00:19:31,198 --> 00:19:35,460
this information. For example, let's think if

295
00:19:36,630 --> 00:19:40,978
for example we want to redact all of the medical condition,

296
00:19:41,074 --> 00:19:45,046
I can just click here on reduct that

297
00:19:45,068 --> 00:19:49,020
is going to remove all of these information and

298
00:19:49,390 --> 00:19:52,902
then I can download my redacted

299
00:19:52,966 --> 00:19:56,358
document or clear the reduction.

300
00:19:56,534 --> 00:20:00,874
Now there are several use cases. One of these could be

301
00:20:01,072 --> 00:20:04,538
personally identifiable information that we want to remove

302
00:20:04,634 --> 00:20:09,434
easily from a document. Well, we can just redact

303
00:20:09,482 --> 00:20:11,230
this information automatically.

304
00:20:12,470 --> 00:20:16,530
Let's see how starting for example a search between

305
00:20:16,600 --> 00:20:20,814
documents at the moment. So if I'm

306
00:20:20,862 --> 00:20:26,210
here and I'm writing diabetes.

307
00:20:29,130 --> 00:20:32,550
Okay, let's try now to search

308
00:20:32,700 --> 00:20:36,342
through documents the information I'm looking

309
00:20:36,396 --> 00:20:40,330
at. So what about if I'm searching diabetes.

310
00:20:41,470 --> 00:20:45,306
As you can see there's three different tabs. The first one

311
00:20:45,408 --> 00:20:49,098
is the result that I get

312
00:20:49,264 --> 00:20:53,274
from a keyword search and those are provided

313
00:20:53,402 --> 00:20:57,406
leveraging elasticsearch service. Then I

314
00:20:57,428 --> 00:21:00,714
can get my results. The one that Kendra,

315
00:21:00,842 --> 00:21:04,546
the service we were looking at before is providing me.

316
00:21:04,648 --> 00:21:08,354
And of course in this case we are talking about a semantic search result

317
00:21:08,552 --> 00:21:12,082
and there's also the possibility of comparing these two

318
00:21:12,136 --> 00:21:15,942
results. As you can see, Kendra and

319
00:21:15,996 --> 00:21:20,550
I really suggest to look in the product page in the feature section

320
00:21:21,050 --> 00:21:23,960
at all the capabilities that scandra has.

321
00:21:24,650 --> 00:21:28,450
For example is highlighting the frequently

322
00:21:28,530 --> 00:21:32,300
asked question. So is providing me the information

323
00:21:32,830 --> 00:21:36,822
that I need or maybe documents

324
00:21:36,886 --> 00:21:40,554
and I can also provide a feedback to these results,

325
00:21:40,602 --> 00:21:43,520
right, if they were relevant or not to me.

326
00:21:45,730 --> 00:21:49,374
Okay, let's get back to the

327
00:21:49,412 --> 00:21:53,300
presentation for the last information that I want to share with you.

328
00:21:55,190 --> 00:21:58,594
Okay, so some

329
00:21:58,632 --> 00:22:02,050
details about the document understanding solution.

330
00:22:03,590 --> 00:22:05,880
So as we saw,

331
00:22:07,850 --> 00:22:11,494
the document understanding solution is also really nice to

332
00:22:11,532 --> 00:22:15,640
demonstrate the value of intelligent search. I really

333
00:22:16,170 --> 00:22:19,702
suggest you to do some tries

334
00:22:19,766 --> 00:22:23,580
also leveraging this comparison and seeing

335
00:22:24,190 --> 00:22:28,266
how Kendra is and works in

336
00:22:28,288 --> 00:22:31,882
order to provide the results the most relevant

337
00:22:31,946 --> 00:22:36,446
resources. Well, but maybe you are wondering how

338
00:22:36,628 --> 00:22:39,760
is actually all of this assembled together.

339
00:22:40,290 --> 00:22:44,110
Well also on the AWS solution

340
00:22:44,190 --> 00:22:48,066
page you

341
00:22:48,088 --> 00:22:51,186
can find this architectural diagram and

342
00:22:51,288 --> 00:22:55,278
as you can see there's several services

343
00:22:55,384 --> 00:22:59,480
involved. Some of that were not mentioned today,

344
00:23:00,090 --> 00:23:03,394
but I was talking about extract, comprehend,

345
00:23:03,442 --> 00:23:07,494
comprehend, medical kendra. But of

346
00:23:07,532 --> 00:23:11,014
course the data is also stored inside s

347
00:23:11,052 --> 00:23:15,142
free. We have some lambda

348
00:23:15,286 --> 00:23:18,860
doing some operation so executing some code.

349
00:23:19,310 --> 00:23:23,310
We are storing the data inside dynamodb.

350
00:23:24,850 --> 00:23:29,114
There is elasticsearch as well in order to provide a comparison

351
00:23:29,162 --> 00:23:32,554
with Kendra and the application that we are going

352
00:23:32,612 --> 00:23:36,642
to deploy when we deploy the

353
00:23:36,696 --> 00:23:40,622
document understanding solution is leveraging cognito

354
00:23:40,686 --> 00:23:44,770
for the authentication and cloudfront for

355
00:23:44,840 --> 00:23:48,246
the distribution. So what

356
00:23:48,268 --> 00:23:52,070
is also really nice about having and

357
00:23:52,140 --> 00:23:56,034
starting exploring the services from AWS

358
00:23:56,082 --> 00:23:59,446
solution is that for

359
00:23:59,468 --> 00:24:03,494
example, the document understanding follows the well architected framework.

360
00:24:03,622 --> 00:24:08,166
A lot of principles, hands, a lot of best practices altogether

361
00:24:08,358 --> 00:24:11,866
and you can use it

362
00:24:11,968 --> 00:24:16,370
starting from now to process hundreds

363
00:24:16,390 --> 00:24:20,094
of thousands of documents. The code

364
00:24:20,132 --> 00:24:24,082
is open source so you can find the solution and also tweak it

365
00:24:24,136 --> 00:24:28,340
and maybe adapt it to your specific use case.

366
00:24:29,990 --> 00:24:33,262
Hands is built using popular

367
00:24:33,326 --> 00:24:37,206
technology CDK react in

368
00:24:37,228 --> 00:24:40,966
order for the front end and CDK to define the

369
00:24:40,988 --> 00:24:44,742
infrastructure. If you are wondering how

370
00:24:44,796 --> 00:24:48,620
to get started on GitHub, you will find

371
00:24:50,590 --> 00:24:54,342
the code for the solution. There are blogs

372
00:24:54,406 --> 00:24:58,490
talking about that and also the page inside the AWS solution

373
00:24:59,230 --> 00:25:02,882
you can download or directly launch

374
00:25:02,966 --> 00:25:07,034
through a cloud formation one click cloud formation template

375
00:25:07,082 --> 00:25:11,774
deploy inside your account and if

376
00:25:11,812 --> 00:25:15,582
you need any help or you want to further explore,

377
00:25:15,646 --> 00:25:19,730
feel free to reach out to AWS

378
00:25:21,510 --> 00:25:25,640
these services here just a list of

379
00:25:26,490 --> 00:25:32,374
compliance let's say certificate programs that these

380
00:25:32,412 --> 00:25:37,014
services fulfill and just to have

381
00:25:37,052 --> 00:25:40,358
an idea that these services are used

382
00:25:40,524 --> 00:25:44,834
not only for proof of concept but also in productions

383
00:25:44,962 --> 00:25:48,614
environment to fulfill all the business use case

384
00:25:48,652 --> 00:25:53,950
you need. Thank you so much and

385
00:25:54,020 --> 00:25:58,190
if you want to explore more about

386
00:25:58,260 --> 00:26:02,282
machine learning on AWS, just click on your URL

387
00:26:02,346 --> 00:26:06,206
bar ML AWS and thank you

388
00:26:06,228 --> 00:26:10,714
so much for spending time with me. I am Matteo Gabrielli

389
00:26:10,842 --> 00:26:14,220
and please if you have any questions feel free to reach out.

