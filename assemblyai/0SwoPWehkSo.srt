1
00:00:27,570 --> 00:00:30,642
Good morning, good afternoon, good evening,

2
00:00:30,706 --> 00:00:34,470
wherever you are in our virtual world, my name

3
00:00:34,540 --> 00:00:39,218
is Ron Dagdag and I will be talking about developing

4
00:00:39,394 --> 00:00:43,190
spidey senses. Anomaly detection for

5
00:00:43,260 --> 00:00:47,240
Javascript application. Let's get started.

6
00:00:49,210 --> 00:00:52,240
So what is this spidey sense?

7
00:00:52,930 --> 00:00:57,050
Most likely you've heard about Spider man. It's that stingling

8
00:00:57,130 --> 00:01:00,506
sensation on back of Peter Parker's skull

9
00:01:00,618 --> 00:01:04,738
that gives him that ability to sense or

10
00:01:04,824 --> 00:01:08,706
react to danger. It increases his ability to

11
00:01:08,808 --> 00:01:11,010
figure out and detect clones,

12
00:01:11,430 --> 00:01:15,560
navigate if he is impaired, can't see anything

13
00:01:16,570 --> 00:01:20,166
to find secret passageways and different

14
00:01:20,348 --> 00:01:23,846
hidden and lost objects. It actually helps him fire his

15
00:01:23,868 --> 00:01:27,366
web shooters and swing instinctively. And I

16
00:01:27,388 --> 00:01:30,250
think it helps him change to his costume.

17
00:01:32,270 --> 00:01:35,466
And the real amazing

18
00:01:35,568 --> 00:01:39,146
part is this real

19
00:01:39,248 --> 00:01:43,054
spidey senses that

20
00:01:43,092 --> 00:01:46,778
spiders has, it's called hyper awareness.

21
00:01:46,874 --> 00:01:52,058
It's this long thin hairs, it's called trichobotria

22
00:01:52,154 --> 00:01:56,990
that actually allows them to detect and low level vibrations

23
00:01:57,150 --> 00:02:01,026
and events from sound. And that's the interesting

24
00:02:01,128 --> 00:02:04,546
part of it, that they can even detect up

25
00:02:04,568 --> 00:02:07,846
to insects up to 3 meters away because of

26
00:02:07,868 --> 00:02:11,334
that. And every time I see spiders in all these

27
00:02:11,372 --> 00:02:12,550
different hairs,

28
00:02:16,810 --> 00:02:20,082
you feel different. It feels the Hibby GB's.

29
00:02:20,146 --> 00:02:23,578
Yes. And then of course, if you're a

30
00:02:23,664 --> 00:02:27,094
new web developer and JavaScript developer

31
00:02:27,142 --> 00:02:30,574
and you're still starting out and trying to cast your

32
00:02:30,612 --> 00:02:34,254
web out there in the World Wide Web and

33
00:02:34,292 --> 00:02:37,520
there's none coming out, it's okay. We're here to help

34
00:02:37,970 --> 00:02:42,110
you understand. What is this anomaly detection?

35
00:02:42,630 --> 00:02:46,414
Okay, what is this spidey senses? It's that gut

36
00:02:46,462 --> 00:02:49,794
feel and vibe or

37
00:02:49,832 --> 00:02:53,602
intuition that you learn through time. Right? You learn from the past.

38
00:02:53,736 --> 00:02:57,426
There are some as a developer, being a developer

39
00:02:57,458 --> 00:03:00,614
for more than 20 years now, you get that sense

40
00:03:00,652 --> 00:03:04,422
of feeling of a project, if it can

41
00:03:04,476 --> 00:03:07,974
become successful or not. I guess you learn it through time and

42
00:03:08,012 --> 00:03:12,490
you learn it through the different

43
00:03:12,560 --> 00:03:16,042
experience from the past. And you kind of build

44
00:03:16,096 --> 00:03:19,674
that intuition and what the technology can deliver in terms of

45
00:03:19,712 --> 00:03:23,598
requirements and those things. So today

46
00:03:23,764 --> 00:03:27,754
we'll be talking about what is anomaly

47
00:03:27,802 --> 00:03:31,198
detection, what is time series data?

48
00:03:31,284 --> 00:03:35,198
And we'll do anomaly detection specifically for time services.

49
00:03:35,374 --> 00:03:39,410
And then we'll do some demos and some takeaways.

50
00:03:41,030 --> 00:03:42,740
Okay, let's get started.

51
00:03:44,070 --> 00:03:48,354
What is anomaly detection? It is identifying

52
00:03:48,482 --> 00:03:52,386
unexpected items and events

53
00:03:52,578 --> 00:03:55,974
which is different from what is normal. It's so

54
00:03:56,012 --> 00:03:59,080
weird, like pandemic, right?

55
00:03:59,470 --> 00:04:02,746
It's not something that we're used to. I guess we're getting used to it by

56
00:04:02,768 --> 00:04:05,900
now. So it's becoming the new normal, right?

57
00:04:06,270 --> 00:04:10,650
So sometimes it's called an outlier. The assumptions

58
00:04:10,730 --> 00:04:15,054
are that anomalies rarely occur in your data set

59
00:04:15,252 --> 00:04:19,146
and the features differ from the normal instances

60
00:04:19,258 --> 00:04:20,510
significantly.

61
00:04:22,790 --> 00:04:26,946
So there are two causes of outliers. It's either

62
00:04:27,048 --> 00:04:30,734
artificial or non natural or natural

63
00:04:30,782 --> 00:04:35,154
cause. So one

64
00:04:35,272 --> 00:04:39,014
causes of it could be data entry errors. Think about

65
00:04:39,052 --> 00:04:43,142
it's 100,000 versus 1 million. That excerpt zero

66
00:04:43,276 --> 00:04:46,690
makes a whole lot of difference, but that is an outlier.

67
00:04:46,850 --> 00:04:53,318
Measurement errors, which is very common experimental

68
00:04:53,494 --> 00:04:57,514
error. When you start in the late of

69
00:04:57,552 --> 00:05:01,200
the sprint, you start collecting at the late of the sprint, even though

70
00:05:01,570 --> 00:05:04,942
you're supposed to collect the whole data

71
00:05:04,996 --> 00:05:08,474
set around certain interval

72
00:05:08,522 --> 00:05:12,670
levels. Intentional outlier.

73
00:05:13,110 --> 00:05:16,834
One good example of that is if you ask high

74
00:05:16,872 --> 00:05:20,818
school students or college students about their

75
00:05:20,904 --> 00:05:24,526
consumption of alcohol, most likely they may underreport

76
00:05:24,558 --> 00:05:28,566
it for any other reason. So depending on how you collect your

77
00:05:28,588 --> 00:05:31,718
data, data processing errors is where

78
00:05:31,804 --> 00:05:35,174
you extract from one service

79
00:05:35,292 --> 00:05:38,426
to put it on another service or one

80
00:05:38,448 --> 00:05:42,650
dataset and pass it to another dataset. Sometimes you may encounter

81
00:05:43,230 --> 00:05:46,170
extraction errors that may cause outliers.

82
00:05:47,390 --> 00:05:50,554
Sampling errors. In this case, you're trying

83
00:05:50,592 --> 00:05:54,446
to report the height of all the athletes, but most of

84
00:05:54,468 --> 00:05:57,534
your data set are basketball players. So your data would get

85
00:05:57,572 --> 00:06:01,294
skewed and that may cause some outliers and

86
00:06:01,332 --> 00:06:04,466
of course natural outliers when it is

87
00:06:04,568 --> 00:06:08,014
not artificial and it wasn't

88
00:06:08,062 --> 00:06:12,082
caused by data processing or

89
00:06:12,136 --> 00:06:15,720
data collection. So at the end of the day,

90
00:06:17,690 --> 00:06:21,078
you have an input data stream. This area

91
00:06:21,164 --> 00:06:24,886
right here, you're trying to detect. These are

92
00:06:24,908 --> 00:06:28,794
good data. And of course you have some defective data right there, and then

93
00:06:28,832 --> 00:06:33,014
you're trying to analyze if this data set is anomalous

94
00:06:33,062 --> 00:06:36,538
or not. So most of

95
00:06:36,544 --> 00:06:40,538
the time it's good data, but sometimes you would

96
00:06:40,704 --> 00:06:44,166
encounter it. You haven't really figured out that that is defective.

97
00:06:44,198 --> 00:06:48,282
So we'll go to this column, but hopefully,

98
00:06:48,346 --> 00:06:52,646
most of the time you'll be able to detect the things that are defective.

99
00:06:52,778 --> 00:06:57,266
But sometimes it is not really defective, but you

100
00:06:57,288 --> 00:07:01,300
would be able to catch it here. So it just depends on how

101
00:07:03,830 --> 00:07:07,350
you would implement this anomaly detector.

102
00:07:11,450 --> 00:07:15,240
Sometimes finding anomalies in a data set,

103
00:07:16,730 --> 00:07:19,894
it's kind of like finding a needle in a haystack.

104
00:07:20,022 --> 00:07:23,322
If the needle is that big. Yeah, that is easy.

105
00:07:23,456 --> 00:07:27,660
Most of the time it's not that big.

106
00:07:29,230 --> 00:07:33,402
So what are different methods and how you would do anomaly

107
00:07:33,546 --> 00:07:34,670
detection?

108
00:07:36,770 --> 00:07:40,842
Sometimes it could be rule based systems, sometimes it's statistical

109
00:07:40,906 --> 00:07:44,514
techniques. Sometimes you would use machine learning.

110
00:07:44,632 --> 00:07:48,530
And we'll go through each one of these rule based systems.

111
00:07:49,030 --> 00:07:52,862
Most likely you kind of know that it's where you specify

112
00:07:52,926 --> 00:07:56,166
the specific rules and assign a

113
00:07:56,188 --> 00:07:59,800
threshold of limits on, like for example,

114
00:08:00,170 --> 00:08:03,942
at certain temperature level, you want to

115
00:08:03,996 --> 00:08:07,978
alert when it reaches a certain threshold or

116
00:08:08,064 --> 00:08:13,226
certain limits you want to set up, can alert or if it

117
00:08:13,248 --> 00:08:16,214
goes down a certain value, send an alert.

118
00:08:16,342 --> 00:08:20,106
The advantage, in a way, advantage and

119
00:08:20,128 --> 00:08:23,918
disadvantage of it is it does require an experience of

120
00:08:24,004 --> 00:08:27,722
industry expert to detect known anomalies.

121
00:08:27,866 --> 00:08:31,214
So you have to interview people and say, what do you think is

122
00:08:31,252 --> 00:08:34,754
the possible problems that causes this

123
00:08:34,792 --> 00:08:39,010
type of issue? And if it goes to a certain threshold,

124
00:08:39,670 --> 00:08:42,798
then we can do alert for certain conditions.

125
00:08:42,894 --> 00:08:46,706
Right. The disadvantage of rule

126
00:08:46,738 --> 00:08:50,274
based systems is it does not adapt as pattern

127
00:08:50,322 --> 00:08:54,434
changes. So once you sets up the formula to calculate

128
00:08:54,482 --> 00:08:58,940
and set up the rules, then it would not

129
00:08:59,630 --> 00:09:03,194
adapt because you have to change it and modify that

130
00:09:03,232 --> 00:09:06,730
logic again. And of course, it does require data

131
00:09:06,800 --> 00:09:10,306
labeling and knowing. Okay, this data set, it is anomalous.

132
00:09:10,358 --> 00:09:16,062
This data sets is not anomalous for

133
00:09:16,116 --> 00:09:17,870
statistical techniques.

134
00:09:19,890 --> 00:09:23,074
It's where you can flag the data points

135
00:09:23,192 --> 00:09:27,394
that deviate from common statistical properties. So this

136
00:09:27,432 --> 00:09:31,422
is where you calculate the mean, the median or quantiles,

137
00:09:31,566 --> 00:09:35,574
or some other cases where you figure out rolling averages or

138
00:09:35,612 --> 00:09:39,474
moving average, most likely, if you're like buying stocks

139
00:09:39,522 --> 00:09:43,670
and it gives you the moving averages or buying and selling

140
00:09:44,730 --> 00:09:48,394
securities, those kind of things, you use a lot of

141
00:09:48,432 --> 00:09:53,866
statistical techniques to identify if

142
00:09:53,888 --> 00:09:57,526
it's out of the ordinary and of course the trends where it's

143
00:09:57,558 --> 00:10:01,950
going. Right. You can also sometimes have

144
00:10:02,020 --> 00:10:05,134
simple moving averages, sometimes be called low

145
00:10:05,172 --> 00:10:09,470
pass filters. One good example of that one is Kalman filters.

146
00:10:10,130 --> 00:10:13,962
There's a formula specifically for that. Sometimes it's

147
00:10:14,026 --> 00:10:18,034
histogram based outlier detection that can be implemented. The good

148
00:10:18,072 --> 00:10:21,650
thing, the advantage of statistical techniques is it's more

149
00:10:21,720 --> 00:10:25,614
interpretable and sometimes it's useful than machine

150
00:10:25,662 --> 00:10:29,654
learning methods. It's easy to explain to someone,

151
00:10:29,772 --> 00:10:33,158
to one of the bosses, this is the formula I use. I use the mean

152
00:10:33,244 --> 00:10:36,754
and the median, and this is how we detect anomalies

153
00:10:36,802 --> 00:10:37,640
that way.

154
00:10:39,550 --> 00:10:42,634
So for machine learning methods, sometimes you can

155
00:10:42,672 --> 00:10:45,686
do anomaly detecting as supervised,

156
00:10:45,878 --> 00:10:49,990
unsupervised, or self supervised services

157
00:10:50,070 --> 00:10:52,090
is more of decision tree.

158
00:10:53,230 --> 00:10:56,238
Unsupervised would talk about k means,

159
00:10:56,324 --> 00:10:59,754
hierarchical clustering, self supervised.

160
00:10:59,882 --> 00:11:03,426
When we start talking about auto encoder, we're not

161
00:11:03,448 --> 00:11:06,354
going to cover the formulas on each one.

162
00:11:06,392 --> 00:11:09,854
I'm just showing you different ways on how you would do machine

163
00:11:09,902 --> 00:11:14,354
learning methods here. But we

164
00:11:14,392 --> 00:11:18,946
want to know when do we use anomaly detecting

165
00:11:19,138 --> 00:11:23,590
versus supervised learning? Anomaly detection

166
00:11:24,090 --> 00:11:27,654
for machine learning, when you have very small

167
00:11:27,772 --> 00:11:31,402
positive positive examples and very large

168
00:11:31,536 --> 00:11:35,382
negative examples, you would use anomaly detection techniques.

169
00:11:35,526 --> 00:11:39,226
If it's supervised learning, most likely you have large number

170
00:11:39,328 --> 00:11:42,666
of positive and negative examples

171
00:11:42,778 --> 00:11:46,414
and you have enough positive examples for the

172
00:11:46,452 --> 00:11:48,000
algorithm to learn.

173
00:11:52,870 --> 00:11:55,060
For the anomaly detecting type.

174
00:11:56,150 --> 00:11:59,710
Sometimes it's hard to learn from positive

175
00:11:59,790 --> 00:12:02,420
examples as compared to supervised learning.

176
00:12:02,790 --> 00:12:06,786
And sometimes the anomalies have not been discovered

177
00:12:06,818 --> 00:12:10,274
yet. So you want as much as possible to do anomaly detection

178
00:12:10,322 --> 00:12:13,622
techniques for this

179
00:12:13,676 --> 00:12:17,240
rather than the services learning. Because for supervised learning,

180
00:12:17,710 --> 00:12:21,226
future positive examples may have not likely to be

181
00:12:21,248 --> 00:12:24,906
similar than your training set and it might not

182
00:12:24,928 --> 00:12:27,900
know how to detect because of that.

183
00:12:28,830 --> 00:12:32,138
So when would you use anomaly detection techniques?

184
00:12:32,314 --> 00:12:36,666
If you're doing fraud detection, manufacturing engines

185
00:12:36,698 --> 00:12:41,550
or machineries, they have a certain routine

186
00:12:42,050 --> 00:12:45,634
or a machine just goes through items cycles and if it's out

187
00:12:45,672 --> 00:12:48,850
of that cycle, that's when you know it's anomalous.

188
00:12:49,270 --> 00:12:52,866
When you're trying to monitor data centers, that would

189
00:12:52,888 --> 00:12:56,582
be a good use case for anomaly detection and Internet of things,

190
00:12:56,636 --> 00:13:00,082
which I would explain a little bit more for supervised

191
00:13:00,146 --> 00:13:04,006
learning. Email spam classification. Why is

192
00:13:04,028 --> 00:13:07,666
that? Because there's a lot of good examples of what spam and not

193
00:13:07,708 --> 00:13:11,610
spam is. And so you're detecting a certain type

194
00:13:11,680 --> 00:13:15,274
of email to detecting and use

195
00:13:15,312 --> 00:13:18,662
that for supervised learning. Weather prediction,

196
00:13:18,726 --> 00:13:22,346
there's specific criteria for weather

197
00:13:22,538 --> 00:13:26,238
to identify it. And that would be a good example for using

198
00:13:26,404 --> 00:13:29,418
supervised learning and cancer classification.

199
00:13:29,594 --> 00:13:33,362
Because an expert already knows what they're looking

200
00:13:33,416 --> 00:13:36,594
for and specific cancer cells and those

201
00:13:36,632 --> 00:13:40,514
kind of things, then it might make

202
00:13:40,552 --> 00:13:43,822
sense to use supervised learning rather than anomaly

203
00:13:43,886 --> 00:13:47,350
detection. So for machine learning,

204
00:13:47,420 --> 00:13:51,058
sometimes it could be density based anomaly detection,

205
00:13:51,154 --> 00:13:55,734
where they can cluster whenever they cluster the

206
00:13:55,772 --> 00:13:59,590
data set. So based on the kneeest neighbor,

207
00:13:59,750 --> 00:14:03,702
so where the normal data points occur around the senses neighborhood.

208
00:14:03,766 --> 00:14:08,074
So that means they're closer to each other and anything that's outside of it.

209
00:14:08,272 --> 00:14:12,378
These are the anomalous because they're

210
00:14:12,394 --> 00:14:14,560
not close to the center of your data set.

211
00:14:15,010 --> 00:14:18,046
Clustering based is the assumptions are

212
00:14:18,068 --> 00:14:22,142
that data points are similar and tend to belong to clusters from

213
00:14:22,196 --> 00:14:24,930
local centroid versus,

214
00:14:25,910 --> 00:14:29,762
and then anything outside of that, anything farther away,

215
00:14:29,896 --> 00:14:32,770
then it can be detected as anomalous.

216
00:14:35,690 --> 00:14:39,346
You can also use gaussian distribution where you calculate

217
00:14:39,538 --> 00:14:43,202
for any given data point, the probability

218
00:14:43,346 --> 00:14:47,174
of that data point being as

219
00:14:47,212 --> 00:14:51,210
normal. These are all the normal in terms of the gaussian distribution right here.

220
00:14:51,280 --> 00:14:54,794
Anything outside of that for a very far away would be

221
00:14:54,832 --> 00:15:02,670
considered anomalous or an outlier support

222
00:15:02,740 --> 00:15:05,498
vector. Machine based anomaly detection,

223
00:15:05,674 --> 00:15:09,278
that's also a good formula. At the end of the day, what it's trying to

224
00:15:09,284 --> 00:15:12,378
do, it tries to split your data into two.

225
00:15:12,564 --> 00:15:16,786
This side is these

226
00:15:16,808 --> 00:15:20,846
are your normal data anything outside of that line, most likely it's

227
00:15:20,878 --> 00:15:24,434
anomalous. That's one way on how you would

228
00:15:24,472 --> 00:15:28,550
do different anomaly detecting techniques.

229
00:15:29,930 --> 00:15:34,194
All right, so let's try to do a simple anomaly detection

230
00:15:34,242 --> 00:15:37,706
and we're going to focus it on our javascript. So let

231
00:15:37,728 --> 00:15:41,740
me try to pull in my data set.

232
00:15:45,070 --> 00:15:48,620
Am using, right now I'm using this

233
00:15:49,230 --> 00:15:52,986
Jupyter notebook, and I have under Jupyter notebook I'm

234
00:15:53,018 --> 00:15:57,006
running typescript application. I think

235
00:15:57,028 --> 00:15:59,790
this is more javascript application right here.

236
00:15:59,940 --> 00:16:03,634
And the reason why I'm showing this so I can execute line

237
00:16:03,672 --> 00:16:06,786
by line and be able to show you the results. So in

238
00:16:06,808 --> 00:16:10,558
this case I'm using stats analysis.

239
00:16:10,734 --> 00:16:14,642
There's an NPM package and I have this array of

240
00:16:14,776 --> 00:16:18,342
numbers right here. And what I would like

241
00:16:18,396 --> 00:16:22,200
to do is to filter out the outliers on this

242
00:16:22,650 --> 00:16:26,514
and just keep the ones that are normal. So in a way they cluster

243
00:16:26,562 --> 00:16:30,074
together, right. They're kind of close to each other and this is so

244
00:16:30,112 --> 00:16:33,130
far away from the rest of the data set,

245
00:16:33,200 --> 00:16:37,834
so they are considered outliers. So run

246
00:16:37,872 --> 00:16:41,662
it this way too. So it gives you the results. So the results here

247
00:16:41,796 --> 00:16:45,502
is that all the outliers are taken away

248
00:16:45,556 --> 00:16:49,130
in just the good data. So that's the simplest

249
00:16:49,290 --> 00:16:52,426
explanation, simplest code that I can find

250
00:16:52,548 --> 00:16:57,774
that we can start, how to start using outlier

251
00:16:57,822 --> 00:17:00,740
detection in our javascript application.

252
00:17:01,910 --> 00:17:04,370
Okay, let's go back to the presentation.

253
00:17:05,770 --> 00:17:09,970
Okay, so let's talk about time series

254
00:17:10,130 --> 00:17:13,862
data. Time series data is

255
00:17:13,916 --> 00:17:17,560
a series of data points indexed in time order.

256
00:17:18,250 --> 00:17:22,378
One good example of that are logs or stock market data

257
00:17:22,464 --> 00:17:26,506
or sales data or senses related to

258
00:17:26,608 --> 00:17:30,458
at the end of day. What we're talking about here is any data

259
00:17:30,544 --> 00:17:34,366
captured with the timestamp. So you have your timestamp data and

260
00:17:34,388 --> 00:17:37,934
then the value timestamp, then value timestamp and value,

261
00:17:38,052 --> 00:17:40,874
right. And you can have multiple values,

262
00:17:40,922 --> 00:17:44,766
or however those values are, as long as they're

263
00:17:44,798 --> 00:17:48,494
indexed against time. Most likely

264
00:17:48,542 --> 00:17:51,854
this is very common because if you start looking at log files,

265
00:17:51,982 --> 00:17:54,820
you'll see it's all time series based.

266
00:17:57,910 --> 00:18:01,046
Of course, Internet of Things has a lot

267
00:18:01,068 --> 00:18:04,982
of time services data because of whatever data

268
00:18:05,036 --> 00:18:08,380
you collect from sensors, it's from specific

269
00:18:08,830 --> 00:18:12,854
time, right? So because Internet

270
00:18:12,902 --> 00:18:16,986
things is happening, because you have increased data volume, you can start detecting data

271
00:18:17,088 --> 00:18:21,566
from these senses. The sensor are getting cheaper and of course there

272
00:18:21,588 --> 00:18:25,546
are increased data speed, meaning the networking

273
00:18:25,578 --> 00:18:28,990
to collect this data and send it to the cloud or get processed,

274
00:18:29,730 --> 00:18:32,802
it's possible, but it's very

275
00:18:32,856 --> 00:18:36,226
important that the data that

276
00:18:36,248 --> 00:18:39,618
you're collecting from these sensors are moving very fast.

277
00:18:39,784 --> 00:18:42,846
But failures are, these systems

278
00:18:42,878 --> 00:18:46,262
are becoming more and more critical day to day.

279
00:18:46,396 --> 00:18:50,022
Right. Tell me about that.

280
00:18:50,076 --> 00:18:54,294
Because sometimes whenever our Google home

281
00:18:54,412 --> 00:18:57,318
or Alexa device are down,

282
00:18:57,484 --> 00:19:00,954
we're having trouble how to turn off the tv, and we have to find that

283
00:19:00,992 --> 00:19:04,442
remote again, the remote control, those kind of things,

284
00:19:04,576 --> 00:19:07,914
little things here or there. But it's becoming critical at

285
00:19:07,952 --> 00:19:11,206
our household. So whenever the Internet

286
00:19:11,238 --> 00:19:14,858
of broken things, it feels something like this. It's trying to debug,

287
00:19:14,954 --> 00:19:18,240
like, what actually happens on that data stream that

288
00:19:19,090 --> 00:19:20,670
you are receiving.

289
00:19:22,550 --> 00:19:26,654
So there are different time series anomaly

290
00:19:26,702 --> 00:19:30,462
types. It could be outlier spike

291
00:19:30,526 --> 00:19:34,954
and level shift, pattern change and seasonality.

292
00:19:35,102 --> 00:19:37,400
And we'll go through each one of these.

293
00:19:37,770 --> 00:19:41,480
Outlier would look something like this, right? You have

294
00:19:41,930 --> 00:19:46,040
your data set, your time services data

295
00:19:46,650 --> 00:19:50,314
through time as you received it, and of course, the values of each

296
00:19:50,352 --> 00:19:54,106
one. And then, of course, there is a spike here or an

297
00:19:54,128 --> 00:19:57,434
outlier, and this is out of

298
00:19:57,472 --> 00:20:00,686
that ordinary. So this

299
00:20:00,708 --> 00:20:04,554
is what you want to detect. It could be spidey

300
00:20:04,602 --> 00:20:08,302
and level shift. One good example of this one

301
00:20:08,436 --> 00:20:12,522
goes through this level, and then suddenly

302
00:20:12,586 --> 00:20:16,786
it shifted up. And what happened? Sometimes you

303
00:20:16,808 --> 00:20:20,914
want to detect this area right here where

304
00:20:21,032 --> 00:20:24,930
you're detecting that spike. And of course, the level shift

305
00:20:25,610 --> 00:20:27,480
can also be possible.

306
00:20:31,770 --> 00:20:35,062
Notice how the data is flowing through like this,

307
00:20:35,116 --> 00:20:38,786
and now it's lower. And why was that level shift

308
00:20:38,898 --> 00:20:42,746
changed? Pattern changes

309
00:20:42,848 --> 00:20:47,014
look something like this, where the way I kind of imagine

310
00:20:47,062 --> 00:20:50,206
this is you have, you're watering your

311
00:20:50,228 --> 00:20:53,598
garden and there's specific flow of water

312
00:20:53,764 --> 00:20:59,482
as it flows

313
00:20:59,546 --> 00:21:03,454
out of the hose. And suddenly someone stepped or

314
00:21:03,492 --> 00:21:07,780
there's a kink in the hose, and then suddenly water just

315
00:21:09,430 --> 00:21:12,242
slowed down. And you want to know when that happened,

316
00:21:12,296 --> 00:21:15,778
where it happened, those kind of things. And so you're trying to detect

317
00:21:15,874 --> 00:21:18,040
pattern changes because of that.

318
00:21:19,370 --> 00:21:22,840
And, of course, seasonality, you have to consider that, too,

319
00:21:23,610 --> 00:21:27,430
whenever you're detecting anomalies.

320
00:21:28,350 --> 00:21:31,260
If you think about it, certain times of the year,

321
00:21:32,110 --> 00:21:35,354
there's seasonality, like around

322
00:21:35,552 --> 00:21:37,420
summertime, of course,

323
00:21:39,630 --> 00:21:45,054
ice cream sales are higher compared to the

324
00:21:45,092 --> 00:21:48,814
winter months. There's also, like here

325
00:21:48,852 --> 00:21:52,974
in the United States when we have football

326
00:21:53,022 --> 00:21:57,010
season or around Super bowl,

327
00:21:57,590 --> 00:22:00,660
pizza sales are higher compared to anywhere else.

328
00:22:01,030 --> 00:22:04,050
Everyone wants to watch their favorite,

329
00:22:06,250 --> 00:22:09,510
favorite game, those kind of things. So you have to consider

330
00:22:09,580 --> 00:22:13,586
that as part of your data sets and identify if there's seasonality

331
00:22:13,698 --> 00:22:14,760
around that.

332
00:22:16,250 --> 00:22:20,346
So what you're trying to do here in

333
00:22:20,368 --> 00:22:24,774
terms of time series is to detect these type of instances

334
00:22:24,822 --> 00:22:27,958
where it's out of the ordinary. So this is the pattern.

335
00:22:28,054 --> 00:22:31,406
And suddenly these data is outside of its pattern, what you

336
00:22:31,428 --> 00:22:35,054
can expect, and this one too. And through time

337
00:22:35,172 --> 00:22:38,462
you have the series of time and based

338
00:22:38,516 --> 00:22:42,330
from these data set identify if the last part is

339
00:22:42,500 --> 00:22:45,746
an anomaly or not. So it depends on how far and

340
00:22:45,768 --> 00:22:49,454
you have to specify sensitivity to how sensitive

341
00:22:49,582 --> 00:22:53,490
you are to trigger an anomaly.

342
00:22:55,290 --> 00:22:58,854
Okay, so far

343
00:22:58,892 --> 00:23:02,294
what I've been talking about is it's called univariates where

344
00:23:02,332 --> 00:23:05,990
you have one variable and through

345
00:23:06,060 --> 00:23:09,926
time series data set, but there's

346
00:23:09,958 --> 00:23:13,914
also a concept of multivariate variant where you have

347
00:23:14,032 --> 00:23:17,674
different time series data and you're trying

348
00:23:17,712 --> 00:23:20,906
to identify if this lot is this out of the

349
00:23:20,928 --> 00:23:24,174
ordinary or this lot is out of the ordinary. This is more

350
00:23:24,212 --> 00:23:27,930
complex to implement as compared to a univariate.

351
00:23:28,010 --> 00:23:31,406
So we're going to focus on the univariate today. But I just

352
00:23:31,428 --> 00:23:34,786
want to let you know that sometimes depending on what the

353
00:23:34,808 --> 00:23:38,574
needs are, you might need to implement a multivariate

354
00:23:38,622 --> 00:23:39,220
system.

355
00:23:41,590 --> 00:23:45,640
Okay. Azure cognitive services

356
00:23:46,010 --> 00:23:50,806
is AI for every developer without

357
00:23:50,908 --> 00:23:54,630
the need or expertise for machine learning

358
00:23:54,700 --> 00:23:58,134
expertise at the end of the day what it is, it's an API

359
00:23:58,182 --> 00:24:01,820
call. So each azure cognitive services have different

360
00:24:05,710 --> 00:24:09,890
capabilities in terms of this. And today we're focusing on decision

361
00:24:09,990 --> 00:24:14,394
capability and there's this anomaly detector

362
00:24:14,442 --> 00:24:17,726
right here which identifies potential problems

363
00:24:17,828 --> 00:24:21,582
early on. So that's where it's more of a decision make

364
00:24:21,636 --> 00:24:24,706
time. So we're going to focus on the

365
00:24:24,728 --> 00:24:29,250
anomaly detection detecting. So anomaly detector

366
00:24:30,710 --> 00:24:34,626
can detect anomalies as they occur in real time

367
00:24:34,808 --> 00:24:37,954
and also you can detect anomalies as a batch.

368
00:24:38,002 --> 00:24:41,618
So you have a choice if you want to pass your data to this API,

369
00:24:41,794 --> 00:24:45,618
do you want it real time or you want it as batch.

370
00:24:45,794 --> 00:24:49,334
It automatically adapts and learns

371
00:24:49,382 --> 00:24:53,782
from newt data set and you can fine tune its sensitivity

372
00:24:53,926 --> 00:24:58,806
for it to detecting anomalies. So there's settings

373
00:24:58,838 --> 00:25:02,766
that you can do. These are rest APIs. It does

374
00:25:02,788 --> 00:25:06,126
not require machine learning expertise and it does

375
00:25:06,148 --> 00:25:09,454
not need labeled data. That's the crazy part about

376
00:25:09,492 --> 00:25:13,330
this is because you don't need training data to send.

377
00:25:13,400 --> 00:25:17,054
You just call the API, send your data and it would detect

378
00:25:17,102 --> 00:25:20,402
anomalies based from a time series data set.

379
00:25:20,536 --> 00:25:24,526
It automatically identifies and applies the best fitting

380
00:25:24,558 --> 00:25:28,262
model for you at the back. And it actually has

381
00:25:28,316 --> 00:25:31,446
these gallery of algorithms and a lot of

382
00:25:31,468 --> 00:25:35,190
these I do not know how to implement. It's using sometimes

383
00:25:35,260 --> 00:25:38,774
Fourier transform, which is kind of like in the computer vision

384
00:25:38,822 --> 00:25:42,714
side. You would do extremes, all these

385
00:25:42,752 --> 00:25:46,506
different algorithms that it's implemented. But the

386
00:25:46,528 --> 00:25:50,430
interesting part of the anomaly detector is it

387
00:25:50,500 --> 00:25:53,978
classifies what type of algorithms it's

388
00:25:53,994 --> 00:25:57,102
going to use. So if it figures out your data

389
00:25:57,156 --> 00:26:01,386
set has some seasonality in it, it would have these algorithms

390
00:26:01,498 --> 00:26:04,510
related for seasonalities. If it has course,

391
00:26:04,580 --> 00:26:08,306
granularity without seasonality would have different set of

392
00:26:08,328 --> 00:26:11,906
algorithms. And it's doing this every time you call the

393
00:26:11,928 --> 00:26:15,462
API. So that's the interesting part. It's trying out different

394
00:26:15,516 --> 00:26:18,040
algorithms all at the same time too.

395
00:26:20,090 --> 00:26:23,906
There are some limitations on how you would use the anomaly

396
00:26:23,938 --> 00:26:28,502
detector API. The data granularity,

397
00:26:28,566 --> 00:26:31,462
it's either daily, hourly, minutely,

398
00:26:31,606 --> 00:26:33,690
monthly, weekly, yearly.

399
00:26:34,510 --> 00:26:38,054
And the series

400
00:26:38,102 --> 00:26:41,502
data points that you have to pass in looks something like this,

401
00:26:41,556 --> 00:26:45,806
where it says series. And this JSON file where

402
00:26:45,828 --> 00:26:49,322
you have the time series data and the value, the minimum

403
00:26:49,386 --> 00:26:52,650
is twelve items, so twelve on this array

404
00:26:52,810 --> 00:26:56,114
and maximum is 8640. And you

405
00:26:56,152 --> 00:26:59,554
specify that granularity. The interesting part

406
00:26:59,592 --> 00:27:03,826
is if you want every five minutes, you have to specify this custom

407
00:27:03,928 --> 00:27:07,400
interval that it would know that, hey,

408
00:27:09,770 --> 00:27:11,640
this is every five minutes.

409
00:27:13,690 --> 00:27:17,302
Okay, so there are two ways

410
00:27:17,356 --> 00:27:21,002
in how you would call anomaly detector API. It's either

411
00:27:21,056 --> 00:27:25,098
through a client SDK, a c sharp python node, which I'm going

412
00:27:25,104 --> 00:27:29,370
to demo today, how to use the client SDK node,

413
00:27:30,050 --> 00:27:34,074
or it's through rest API, so it can support any language

414
00:27:34,122 --> 00:27:38,750
as long as you can call HTTP or rest calls.

415
00:27:40,290 --> 00:27:42,960
So let's start with our demo.

416
00:27:49,570 --> 00:27:54,974
So I have here actually,

417
00:27:55,092 --> 00:27:58,350
this Jupyter notebook right here

418
00:27:58,420 --> 00:28:02,100
is actually running on one of my

419
00:28:03,990 --> 00:28:07,934
raspberry PI's right here. And this raspberry PI

420
00:28:08,062 --> 00:28:12,310
has this sense hat so I can

421
00:28:12,380 --> 00:28:15,830
get temperature data of the room and also have

422
00:28:15,900 --> 00:28:19,910
some led pixels so I can display

423
00:28:21,370 --> 00:28:24,434
if the data that we've collected is anomalous.

424
00:28:24,482 --> 00:28:26,700
And then we display something here.

425
00:28:27,790 --> 00:28:31,306
Okay, so before we start, I can show you

426
00:28:31,328 --> 00:28:35,626
the package JSon that I'm using for this in

427
00:28:35,648 --> 00:28:39,290
order to call anomaly detector NPM package.

428
00:28:39,370 --> 00:28:43,210
There's azure AI anomaly detector,

429
00:28:43,290 --> 00:28:46,798
and of course Ms. Rest js. We would need.

430
00:28:46,964 --> 00:28:50,290
This env allows us to read

431
00:28:50,440 --> 00:28:54,610
environment variables. Then this spidey senses hat,

432
00:28:55,030 --> 00:29:03,446
which allows me to talk to the

433
00:29:03,468 --> 00:29:07,666
raspberry PI hat. It's called the senses hat.

434
00:29:07,778 --> 00:29:11,222
And then this was the stat analysis I did demo a few minutes

435
00:29:11,276 --> 00:29:14,426
ago. Okay, let's look at

436
00:29:14,448 --> 00:29:18,234
this senses hat right here. And what we'll do is

437
00:29:18,272 --> 00:29:20,650
I'm going to clear all my outputs.

438
00:29:22,430 --> 00:29:25,626
Not yet. Well, I just wanted to

439
00:29:25,648 --> 00:29:29,520
show you how I did run it a while ago. And like right here,

440
00:29:30,050 --> 00:29:32,800
see how I'm running it.

441
00:29:34,850 --> 00:29:39,606
This typescript kernel, I'm actually using Tslab

442
00:29:39,738 --> 00:29:43,698
to be able to have typescript running

443
00:29:43,864 --> 00:29:47,742
Javascript running into Jupyter

444
00:29:47,806 --> 00:29:52,370
notebooks. So right here is the version I'm using for tSlab.

445
00:29:53,850 --> 00:29:57,170
So this one right here is node sense hat.

446
00:29:57,250 --> 00:30:01,026
I would like to get the leds on that matrix.

447
00:30:01,138 --> 00:30:04,794
And then I wanted to read some

448
00:30:04,832 --> 00:30:08,474
data from that acceleration data. So I'll show you

449
00:30:08,512 --> 00:30:11,660
what the output does look like right here.

450
00:30:15,470 --> 00:30:19,402
Let me try to run that. So, notice how the acceleration

451
00:30:19,466 --> 00:30:22,974
data looks something like this. It reads it. So I was

452
00:30:23,012 --> 00:30:26,590
able to get, in this case, I was able to get this temperature

453
00:30:27,730 --> 00:30:32,562
of my raspberry PI right here and

454
00:30:32,616 --> 00:30:36,434
to display that value. And then I

455
00:30:36,472 --> 00:30:39,460
went through here and actually get this.

456
00:30:40,790 --> 00:30:44,822
What I'm doing here is I read every minute, and every

457
00:30:44,876 --> 00:30:48,680
minute I will push it into an array, and then

458
00:30:49,850 --> 00:30:53,640
after that I will have something like this.

459
00:30:56,670 --> 00:31:00,538
So I will have this value with this timestamp I get the value.

460
00:31:00,624 --> 00:31:04,618
So this is my time services data

461
00:31:04,704 --> 00:31:06,010
that I collected.

462
00:31:08,610 --> 00:31:12,542
So this is where I was running it and I would like to

463
00:31:12,596 --> 00:31:17,006
get it every minute and then make

464
00:31:17,028 --> 00:31:18,880
it look something like this.

465
00:31:21,970 --> 00:31:25,326
So once I got my time series data, now it's

466
00:31:25,358 --> 00:31:29,490
time to process it and send it to anomaly detector.

467
00:31:30,790 --> 00:31:34,754
So that requires me to use this AI

468
00:31:34,802 --> 00:31:38,614
anomaly detecting client SDK. I need

469
00:31:38,652 --> 00:31:42,386
this core auth to be able to get the credentials.

470
00:31:42,578 --> 00:31:47,274
Before I can do this or before I can use

471
00:31:47,392 --> 00:31:51,274
anomaly detector, I need to create an

472
00:31:51,312 --> 00:31:56,154
instance of anomaly detecting through

473
00:31:56,352 --> 00:31:59,694
Azure ClI. And these are the commands I did

474
00:31:59,812 --> 00:32:04,014
to create the resource group, the cognitive services

475
00:32:04,132 --> 00:32:07,566
instance, and then to get the keys. So there

476
00:32:07,588 --> 00:32:11,410
are two things that you need. In order to call the API,

477
00:32:11,910 --> 00:32:15,374
you need the endpoint, that means the URL

478
00:32:15,502 --> 00:32:20,370
where you would read the call,

479
00:32:20,440 --> 00:32:24,326
and also you need the access key or the API key. So that's what

480
00:32:24,348 --> 00:32:27,922
I'm doing here. I have that in this config

481
00:32:27,986 --> 00:32:31,510
or this environment file that

482
00:32:31,660 --> 00:32:34,230
just loaded it to memory.

483
00:32:35,150 --> 00:32:38,422
So in order to call the anomaly detector

484
00:32:38,486 --> 00:32:41,782
API, you need to use this anomaly detector

485
00:32:41,846 --> 00:32:44,874
client. You specify the endpoint and then you

486
00:32:44,912 --> 00:32:48,090
pass the key to this azure key credential.

487
00:32:48,250 --> 00:32:52,186
And then it would give you this anomaly detector client.

488
00:32:52,378 --> 00:32:55,982
And once you have that anomaly detector client, now you can

489
00:32:56,036 --> 00:32:59,826
pass things to it. This one right here,

490
00:32:59,928 --> 00:33:04,514
what it's doing is it's sending a

491
00:33:04,552 --> 00:33:08,798
data set, right? And it's

492
00:33:08,894 --> 00:33:12,274
detecting the last entry of that data set.

493
00:33:12,312 --> 00:33:15,300
So I have to send certain set of data,

494
00:33:15,910 --> 00:33:19,774
a time series data set, and that's why I'm

495
00:33:19,902 --> 00:33:23,780
putting this into the body and

496
00:33:24,590 --> 00:33:27,722
I'm identifying my data set

497
00:33:27,776 --> 00:33:29,130
is every minute.

498
00:33:31,310 --> 00:33:33,180
And what this one does,

499
00:33:34,830 --> 00:33:37,950
it would give me a response that if the last

500
00:33:38,020 --> 00:33:41,166
items on my list is anomalous or

501
00:33:41,188 --> 00:33:45,310
not. So you would say true if it's anomalous or

502
00:33:45,380 --> 00:33:49,054
false if it's not anomalous. So you can

503
00:33:49,092 --> 00:33:50,420
actually run this.

504
00:33:54,230 --> 00:33:58,386
Of course. The important part is to run this first.

505
00:33:58,488 --> 00:34:01,966
Right. Initialize the anomaly detector

506
00:34:01,998 --> 00:34:04,662
client. Now I can call it right here.

507
00:34:04,716 --> 00:34:08,918
And that's what I did. So it tells me right here, the last point

508
00:34:09,004 --> 00:34:12,902
on my list, which is row 15, is not detecting as

509
00:34:12,956 --> 00:34:16,460
anomaly. And then

510
00:34:17,870 --> 00:34:21,114
I will create. So what I did here

511
00:34:21,152 --> 00:34:24,454
is I'm creating a new instance. This one's

512
00:34:24,502 --> 00:34:27,750
new points. And what I want to do is I want to

513
00:34:27,760 --> 00:34:31,114
get the last item. This is the last item

514
00:34:31,162 --> 00:34:35,440
on my list, right? So 34.275.

515
00:34:35,810 --> 00:34:39,130
And I just want to force it to be anomalous,

516
00:34:39,290 --> 00:34:43,860
right. So in this case it has to be 134 instead of 34.

517
00:34:44,550 --> 00:34:47,970
So now my new points would look something like this,

518
00:34:48,120 --> 00:34:52,006
where this one is the normal and

519
00:34:52,028 --> 00:34:56,178
this one is outside of the normal abnormal.

520
00:34:56,274 --> 00:34:59,430
So this one should be detected as anomalous.

521
00:35:00,410 --> 00:35:04,998
So this one right here, if it's

522
00:35:05,014 --> 00:35:09,020
just some constant that I want to pass in to

523
00:35:14,030 --> 00:35:19,840
what you call these, let's go back there to

524
00:35:20,610 --> 00:35:24,560
my leds and I want to put an x,

525
00:35:25,330 --> 00:35:28,110
if it detecting as anomalous.

526
00:35:28,770 --> 00:35:32,626
Okay, let's go back and I would like to show you

527
00:35:32,808 --> 00:35:36,930
how that would look like. Let me try to set it up real quick.

528
00:35:37,080 --> 00:35:41,726
I want to make sure that you can actually see what

529
00:35:41,768 --> 00:35:42,840
it's going to do.

530
00:35:45,290 --> 00:35:48,280
So let's try to run this one again.

531
00:35:50,010 --> 00:35:51,000
Come on,

532
00:35:57,900 --> 00:36:01,428
set it up. See if we can fit all

533
00:36:01,454 --> 00:36:05,068
that data set. So when I run this,

534
00:36:05,234 --> 00:36:07,820
if it's the last detection,

535
00:36:09,440 --> 00:36:13,424
if the last item on my list is anomalous, I would

536
00:36:13,462 --> 00:36:17,184
set the pixel to cross. So this one would have an x in it.

537
00:36:17,302 --> 00:36:21,148
And let's see what happens. Boom.

538
00:36:21,244 --> 00:36:25,112
There is, well, it's kind of harder to see, but there's a letter.

539
00:36:25,276 --> 00:36:28,916
The leds right there is a little bit, it's too bright if

540
00:36:28,938 --> 00:36:31,910
you ask me. That has an x.

541
00:36:32,280 --> 00:36:35,430
That means there is anomalous there. Let me clear that up.

542
00:36:35,900 --> 00:36:39,704
And there you go. So it kind of cleared it. Okay.

543
00:36:39,822 --> 00:36:43,672
Isn't that cool? What just happened? What we did was

544
00:36:43,726 --> 00:36:48,684
to read data from

545
00:36:48,722 --> 00:36:52,748
our sensor. Right here, I'm using JavaScript to read data

546
00:36:52,834 --> 00:36:56,524
from the temperature sensor of this

547
00:36:56,562 --> 00:37:00,308
raspberry PI. And then I collected some array.

548
00:37:00,424 --> 00:37:04,364
I used anomaly detector API

549
00:37:04,492 --> 00:37:08,384
to send my data set that I collected, and then it

550
00:37:08,422 --> 00:37:11,984
gave me a result that says the last item on my list is

551
00:37:12,022 --> 00:37:15,604
anomalous. And then I send an alert and

552
00:37:15,642 --> 00:37:20,144
say, hey, there's something wrong. With my data set and set the pixels

553
00:37:20,272 --> 00:37:24,436
on these raspberry PI and set an x in it

554
00:37:24,618 --> 00:37:27,770
and I cleared it out. Cool.

555
00:37:28,620 --> 00:37:32,360
All right, so let's go back to the presentation.

556
00:37:33,660 --> 00:37:37,370
So where can you use anomaly detector API? It has

557
00:37:38,480 --> 00:37:42,408
C sharp JavaScript or Python SDK clients.

558
00:37:42,584 --> 00:37:46,136
There's docker containers. You can actually integrate

559
00:37:46,168 --> 00:37:49,676
it with power Bi or Azure databricks if you

560
00:37:49,698 --> 00:37:53,104
want streaming data. So there's a lot of use

561
00:37:53,142 --> 00:37:56,796
cases where you could integrate anomaly

562
00:37:56,828 --> 00:38:00,064
detector. So where

563
00:38:00,102 --> 00:38:04,320
can. We already talked about that. Those are just different links.

564
00:38:05,320 --> 00:38:08,752
The cool thing is there's docker containers so you can easily

565
00:38:08,816 --> 00:38:12,932
integrate it into your application

566
00:38:13,066 --> 00:38:17,192
too and running it at the edge. There is

567
00:38:17,246 --> 00:38:21,588
also another Azure cognitive service called Metrics Advisor.

568
00:38:21,684 --> 00:38:27,784
And this metrics advisor is specifically has

569
00:38:27,822 --> 00:38:32,024
a web portal that you can actually diagnose anomalies

570
00:38:32,072 --> 00:38:35,276
and help with root cause analysis. It's more of a

571
00:38:35,298 --> 00:38:40,652
software as a service application where

572
00:38:40,706 --> 00:38:44,656
you can collect time series data from different data sources and

573
00:38:44,678 --> 00:38:48,716
detecting anomalies from there, and then you can configure

574
00:38:48,748 --> 00:38:52,636
it where it would send alerts and it would help you find the root

575
00:38:52,668 --> 00:38:55,830
cause of that issue.

576
00:38:57,160 --> 00:39:00,480
All right, so the best superpower

577
00:39:00,560 --> 00:39:05,356
that you can give to your project is anomaly

578
00:39:05,408 --> 00:39:09,160
detecting, which sometimes it's called Spidey.

579
00:39:10,460 --> 00:39:13,610
So if you're interested in learning more about

580
00:39:14,140 --> 00:39:18,172
what I did today, if you want to get the

581
00:39:18,226 --> 00:39:22,444
code, this is the GitHub link where you can

582
00:39:22,642 --> 00:39:26,430
get and download the code.

583
00:39:27,920 --> 00:39:31,600
So just to recap what is anomaly detecting? It is the process

584
00:39:31,670 --> 00:39:35,772
of identifying unexpected items or events

585
00:39:35,836 --> 00:39:39,840
in our data set. What is time series data?

586
00:39:39,990 --> 00:39:43,448
It's a series of data points indexed

587
00:39:43,484 --> 00:39:47,600
by time order. And then today I did demonstrate

588
00:39:47,680 --> 00:39:50,660
what is anomaly detector API?

589
00:39:53,160 --> 00:39:57,652
It's can API to detect anomalies automatically

590
00:39:57,716 --> 00:40:01,480
adapts and learn from new data sets without

591
00:40:01,630 --> 00:40:03,690
needing training data.

592
00:40:05,260 --> 00:40:08,684
Cool. If you're interested in learning more about me, my name is

593
00:40:08,722 --> 00:40:12,840
Ron Dagdag. I'm a lead software engineer at Spacee.

594
00:40:13,000 --> 00:40:16,300
I'm a fifth year Microsoft MVP awardee.

595
00:40:16,960 --> 00:40:20,152
The best way to contact me is through Twitter

596
00:40:20,216 --> 00:40:23,980
at Ron Dagdag or LinkedIn. Connect me through LinkedIn.

597
00:40:25,360 --> 00:40:28,956
Ron Dagdag thanks for geeking out with

598
00:40:28,978 --> 00:40:32,592
me about spidey senses and anomaly detecting.

599
00:40:32,776 --> 00:40:36,560
End now that you got bitten off by these virtual

600
00:40:36,640 --> 00:40:40,228
spider, feel free to test out your new

601
00:40:40,314 --> 00:40:43,764
superpowers that you just learned today.

602
00:40:43,962 --> 00:40:47,348
Thank you very much. I appreciate your time and

603
00:40:47,434 --> 00:40:49,490
have a good day.

