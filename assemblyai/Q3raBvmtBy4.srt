1
00:01:41,970 --> 00:01:45,466
Hello everyone. Welcome to my talk. My name is Ricardo

2
00:01:45,498 --> 00:01:48,670
Castro and today we're going to talk about reliability.

3
00:01:51,010 --> 00:01:54,398
So what do we have on the menu for today? We're going to start

4
00:01:54,484 --> 00:01:57,694
by giving some context about this talk. So we're going to use

5
00:01:57,732 --> 00:02:01,262
an example from the real world and then we're going to translate this into

6
00:02:01,316 --> 00:02:04,966
our techie reality. We will then talk about

7
00:02:05,028 --> 00:02:08,342
reliability. We are going to start step to start,

8
00:02:08,396 --> 00:02:11,974
step by step, and we're going to develop a framework that many

9
00:02:12,012 --> 00:02:15,350
of you already have heard about that surrounds

10
00:02:15,770 --> 00:02:19,402
around slos. We will then see where the real

11
00:02:19,456 --> 00:02:22,970
value of having such a framework in place comes from.

12
00:02:23,120 --> 00:02:26,506
And at the end we're going to conclude this on why all of this is

13
00:02:26,528 --> 00:02:30,022
important. So let's start

14
00:02:30,096 --> 00:02:32,080
with an example from the real world.

15
00:02:33,570 --> 00:02:36,000
So can example from the real world.

16
00:02:37,250 --> 00:02:39,550
I'm going to be using a supermarket.

17
00:02:41,170 --> 00:02:44,354
If you think a little bit about it, a supermarket, it's kind

18
00:02:44,392 --> 00:02:48,098
of a microservices architecture. Why do

19
00:02:48,104 --> 00:02:52,094
I say this? So the idea for me as a consumer,

20
00:02:52,142 --> 00:02:55,606
I go to a supermarket, I do my shopping, I pay and I get

21
00:02:55,628 --> 00:02:59,494
out. But underneath the covers there's a lot that

22
00:02:59,532 --> 00:03:03,414
needs to happen so that my consumer experience is

23
00:03:03,452 --> 00:03:07,510
actually reliable. So there are many

24
00:03:07,580 --> 00:03:10,986
different pieces that need to fit into place, so that

25
00:03:11,088 --> 00:03:14,282
when I go to the supermarket, everything is there for me to buy.

26
00:03:14,336 --> 00:03:18,140
So someone has to make purchase orders to actually get

27
00:03:18,750 --> 00:03:22,354
products into the supermarket. Someone has to transport

28
00:03:22,502 --> 00:03:26,030
those products, someone has to unload those products

29
00:03:26,100 --> 00:03:29,386
into the supermarket, someone has to stock the shelves,

30
00:03:29,498 --> 00:03:32,986
someone needs to be at a counter. If I need some kind of assistance,

31
00:03:33,098 --> 00:03:36,514
someone needs to be at a counter so that I need to pay. So as

32
00:03:36,552 --> 00:03:40,930
we can see, there are a lot of moving pieces inside the supermarket

33
00:03:41,430 --> 00:03:45,066
that have to be successful so that my simple user

34
00:03:45,118 --> 00:03:47,350
experience is actually reliable.

35
00:03:48,970 --> 00:03:52,706
So how can I assess

36
00:03:52,818 --> 00:03:56,438
if a supermarket is being reliable or not?

37
00:03:56,604 --> 00:04:00,006
Let's see a couple of examples of how we can assess

38
00:04:00,038 --> 00:04:01,930
the reliability of a supermarket.

39
00:04:05,630 --> 00:04:09,334
So it says, imagine that we did all of our shopping

40
00:04:09,382 --> 00:04:12,718
and we want to pay. How can this experience be

41
00:04:12,804 --> 00:04:16,382
not reliable? So if it takes too long to pay,

42
00:04:16,436 --> 00:04:20,190
I may assess this experience as not being reliable.

43
00:04:21,490 --> 00:04:24,174
By the same token, I go into a shell, I go to a shelf,

44
00:04:24,222 --> 00:04:27,842
I pick up the product, and the product expiration date

45
00:04:27,896 --> 00:04:32,434
has passed, right? So I might assess this

46
00:04:32,552 --> 00:04:36,002
supermarket as not being reliable. If I go try and buy a product

47
00:04:36,056 --> 00:04:38,790
and I can't because the product expiration has passed.

48
00:04:39,130 --> 00:04:43,080
And we can draw a parallel here into our techie world.

49
00:04:43,930 --> 00:04:47,926
When something takes too long to pay, we can equate that to latency. So if

50
00:04:47,948 --> 00:04:51,366
I send a request to a service, it takes too long to receive a response

51
00:04:51,398 --> 00:04:55,174
back. And the same thing, if a product expiration date has passed,

52
00:04:55,222 --> 00:04:58,810
I can use this as an example of an error.

53
00:05:00,430 --> 00:05:03,918
So as an example, I'm going to use my own company as

54
00:05:03,924 --> 00:05:07,886
an example. So I work at a company called Anova, and we operate in

55
00:05:07,908 --> 00:05:11,566
the industrial IoT space. So essentially we develop

56
00:05:11,668 --> 00:05:15,390
solutions for our customers to have industrial sensors. We ingest

57
00:05:15,470 --> 00:05:19,058
data from those sensors and we create

58
00:05:19,144 --> 00:05:22,850
meaningful services that help them manage their own infrastructure.

59
00:05:23,590 --> 00:05:27,286
So essentially, this is our main focus.

60
00:05:27,388 --> 00:05:30,934
So we collect high reliability data

61
00:05:30,972 --> 00:05:33,830
from high reliability sensors. We collect that,

62
00:05:33,900 --> 00:05:37,914
process those services, and then provide solutions to our

63
00:05:37,952 --> 00:05:41,034
customers. So for

64
00:05:41,152 --> 00:05:45,098
all of this to be successful, we actually need to ensure that

65
00:05:45,184 --> 00:05:48,330
all of our services are actually reliable.

66
00:05:49,310 --> 00:05:51,360
What does reliability mean?

67
00:05:52,770 --> 00:05:56,926
So if we go into the Cambridge dictionary, it has a

68
00:05:56,948 --> 00:06:00,622
definition of reliability as being the quality of being able

69
00:06:00,676 --> 00:06:04,334
to be trusted or believed because of working or behaving.

70
00:06:04,462 --> 00:06:08,994
And this gets me a little bit confused, but essentially it

71
00:06:09,032 --> 00:06:12,242
says that something is reliable if it's behaving well,

72
00:06:12,296 --> 00:06:16,054
right? But I prefer the definition from

73
00:06:16,092 --> 00:06:20,274
Alexey Dalgo in his great book, implementing service level objectives,

74
00:06:20,402 --> 00:06:23,894
which essentially asks those question, is my service

75
00:06:24,012 --> 00:06:27,830
reliable? And how can I assess that? And basically

76
00:06:27,980 --> 00:06:31,686
I can say that is my service doing what its users

77
00:06:31,718 --> 00:06:35,306
needed to do. So this is a little bit of shift. So it

78
00:06:35,328 --> 00:06:38,954
says, we're not saying that something is reliable if it's behaving well,

79
00:06:38,992 --> 00:06:43,006
we say that something is reliable. A service, for example, if it

80
00:06:43,028 --> 00:06:46,400
is doing what its users expected it to do.

81
00:06:46,930 --> 00:06:50,126
So how can we go about developing a framework to

82
00:06:50,148 --> 00:06:53,786
actually ensure that services are doing what its users

83
00:06:53,818 --> 00:06:57,378
needed to do? We're going to start to build this,

84
00:06:57,464 --> 00:07:01,950
building this step by step, and we're going to start with those most basic component

85
00:07:02,030 --> 00:07:05,826
in our system, which are metrics, very well known to

86
00:07:05,848 --> 00:07:09,670
all of us. And essentially a metric is a measurement about

87
00:07:09,740 --> 00:07:13,462
a system. It doesn't tell us anything other

88
00:07:13,516 --> 00:07:16,726
than a measurement. So a few examples of what

89
00:07:16,748 --> 00:07:20,840
a metric can be at the amount of memory that

90
00:07:21,930 --> 00:07:25,786
the service server is using, for example, in terms of percentage of

91
00:07:25,808 --> 00:07:29,046
available memory, the time it takes for an HTTP

92
00:07:29,078 --> 00:07:32,430
request to be fulfilled, for example, in milliseconds or seconds,

93
00:07:33,810 --> 00:07:37,354
the number of errors, HTTP response errors,

94
00:07:37,402 --> 00:07:41,134
for example, a natural number or the age

95
00:07:41,172 --> 00:07:44,820
of a message arriving at a Kafka cluster in terms of minutes.

96
00:07:45,750 --> 00:07:49,266
So with metrics, we can start building on this and

97
00:07:49,368 --> 00:07:52,846
start evolving this concept. And the next concept

98
00:07:52,878 --> 00:07:56,870
is the concept of a service level indicator and

99
00:07:56,940 --> 00:08:00,214
a service level indicator indicator is a

100
00:08:00,252 --> 00:08:03,826
quantifiable measure of service reliability,

101
00:08:03,938 --> 00:08:07,842
and it helps us separate good events

102
00:08:07,906 --> 00:08:11,322
from bad events. So how can we define service level

103
00:08:11,376 --> 00:08:14,714
indicators to actually say if an event is

104
00:08:14,752 --> 00:08:18,854
good or bad? So here are a few examples.

105
00:08:18,902 --> 00:08:22,422
We're going to take the examples of metrics, and we're going to use that metric

106
00:08:22,486 --> 00:08:26,286
and actually define SLis. That tells us if

107
00:08:26,388 --> 00:08:30,026
when we look at a metric or an event described

108
00:08:30,058 --> 00:08:33,198
by a metric, you can say that if that metric is good or not.

109
00:08:33,364 --> 00:08:37,234
So we need for a binary state to be achieved, right? So we need for

110
00:08:37,272 --> 00:08:40,606
something to be good or bad, even if the underlying

111
00:08:40,638 --> 00:08:44,002
magic doesn't provide that binary state. So how can we define that?

112
00:08:44,056 --> 00:08:47,502
So, using the previous example, we can say a request

113
00:08:47,566 --> 00:08:51,202
needs to be responded within 200 milliseconds.

114
00:08:51,346 --> 00:08:54,806
So every time we take a measurement, if it takes more than

115
00:08:54,828 --> 00:08:58,326
200 milliseconds, we can say that this is not good. If it takes 200

116
00:08:58,348 --> 00:09:01,386
milliseconds or less, we can say that those is good.

117
00:09:01,488 --> 00:09:05,610
And the same is analogous to the other example. So a request

118
00:09:06,190 --> 00:09:09,370
to a service must not be responded with a 500 code,

119
00:09:09,440 --> 00:09:12,842
right? If it's responded with a 500 code, it's not okay.

120
00:09:12,896 --> 00:09:16,078
If it's responded with a code different than 500, it is okay.

121
00:09:16,164 --> 00:09:19,614
And again, same thing for messages arriving to Kafka. If the

122
00:09:19,652 --> 00:09:23,534
message is not older than five minutes, everything is okay. If those

123
00:09:23,572 --> 00:09:27,426
message is older than five minutes, things are not okay. You need

124
00:09:27,448 --> 00:09:30,994
to do, might need to do something. So we started with

125
00:09:31,032 --> 00:09:34,642
metrics. We went to slis. What comes next?

126
00:09:34,776 --> 00:09:38,706
So, next is an SLO. And an SLO

127
00:09:38,738 --> 00:09:42,402
is nothing more than how many times one SLA

128
00:09:42,466 --> 00:09:45,954
has to be achieved, so that I can be sure that my users

129
00:09:46,002 --> 00:09:49,722
are happy with my service. And that, of course, needs to be measured within

130
00:09:49,776 --> 00:09:53,386
a time interval. So, using the same examples again,

131
00:09:53,488 --> 00:09:57,194
we're going to evolve an SLI into an SLO. So we

132
00:09:57,232 --> 00:10:01,114
can say 99% of requests to a service need

133
00:10:01,152 --> 00:10:04,894
to be responded within 200 milliseconds within a 30

134
00:10:04,932 --> 00:10:08,926
day period. So we define an interval which is 30 days.

135
00:10:09,028 --> 00:10:12,590
We look at all requests, and we say that 99%

136
00:10:12,660 --> 00:10:16,126
of them need to be responded within 200 milliseconds.

137
00:10:16,238 --> 00:10:20,046
If not, I can say that my users are not being satisfied

138
00:10:20,078 --> 00:10:23,454
with my service. Same thing with those other examples.

139
00:10:23,502 --> 00:10:27,046
99% of requests to a service need to be responded with a code different from

140
00:10:27,068 --> 00:10:30,018
500 within a seven day period.

141
00:10:30,194 --> 00:10:34,710
And exactly the same thing with the four messages arriving to Kafka.

142
00:10:36,170 --> 00:10:39,638
But how can we create good slos so

143
00:10:39,724 --> 00:10:43,546
here are a few tips on how to create good slos. So first and

144
00:10:43,568 --> 00:10:47,498
foremost, and if you forget all the other tips, is the first one, always,

145
00:10:47,584 --> 00:10:50,706
always and always focus on the users.

146
00:10:50,838 --> 00:10:54,378
Users are the one who will be defining

147
00:10:54,394 --> 00:10:57,646
the reliability of my service. So it makes sense for us

148
00:10:57,668 --> 00:11:01,326
to actually know what the user expects, expect and

149
00:11:01,428 --> 00:11:04,020
track our reliability according to that.

150
00:11:05,670 --> 00:11:09,074
Going a little bit deeper. One good option to actually start

151
00:11:09,112 --> 00:11:13,074
defining slos is to list out critical users journeys and

152
00:11:13,112 --> 00:11:17,302
order them by business impact. Maybe is your search catalog, maybe is

153
00:11:17,356 --> 00:11:21,240
checkouts, whatever makes sense within your company.

154
00:11:22,170 --> 00:11:26,214
Then we need to determine which metrics we will be using as

155
00:11:26,252 --> 00:11:30,194
service level indicators to most accurately track

156
00:11:30,252 --> 00:11:33,626
that user experience. So we need to define a few metrics or measure a

157
00:11:33,648 --> 00:11:37,740
few things and be sure that we have slis that actually track

158
00:11:38,990 --> 00:11:41,130
what we know that the user is valuable.

159
00:11:42,350 --> 00:11:46,814
Also, try not not to to get too

160
00:11:46,852 --> 00:11:51,194
overboard with slos. For most cases, three or four slos

161
00:11:51,242 --> 00:11:55,054
should be enough and we can use a composable

162
00:11:55,102 --> 00:11:58,466
metrics to do that. Also important is

163
00:11:58,488 --> 00:12:02,018
to have SLO documents. We'll see an example in a second,

164
00:12:02,184 --> 00:12:05,714
but it's essentially a document that

165
00:12:05,752 --> 00:12:09,560
describes what the SLO is when it was last reviewed, and so on.

166
00:12:10,490 --> 00:12:13,458
Very important is to review SLOS periodically.

167
00:12:13,554 --> 00:12:17,042
SLOS is not something that is set in stone,

168
00:12:17,106 --> 00:12:20,554
and every once in a while it needs to be reviewed and to be sure

169
00:12:20,592 --> 00:12:24,410
that it's still actually tracking user satisfaction

170
00:12:25,390 --> 00:12:29,302
and also determine SLO targets and goals and those SLO measurement

171
00:12:29,366 --> 00:12:32,878
period. Don't try to be too reliable. And we see

172
00:12:33,044 --> 00:12:36,686
what I mean by this in a bit. So just a

173
00:12:36,708 --> 00:12:40,522
quick glance on an example of an SLO document.

174
00:12:40,666 --> 00:12:44,350
This example was taken from the Google icre book,

175
00:12:44,420 --> 00:12:47,450
so you can use it as a reference to build your own and adapt to

176
00:12:47,460 --> 00:12:50,718
your own reality. So essentially it has a description of the slO.

177
00:12:50,814 --> 00:12:53,698
So this is an SLO for the example game service.

178
00:12:53,784 --> 00:12:57,270
It has the authors, when it was defined, who reviewed it,

179
00:12:57,340 --> 00:13:00,870
when it was approved, and when it should be revisited.

180
00:13:01,290 --> 00:13:04,870
It also has an overview of the

181
00:13:04,940 --> 00:13:08,040
service that this SLO applies to.

182
00:13:09,630 --> 00:13:13,306
Then it comes down to slis. So these are the definition of

183
00:13:13,328 --> 00:13:16,906
the Slis that we've seen previously, but here are the

184
00:13:16,928 --> 00:13:20,250
ones who actually inform this slo.

185
00:13:21,730 --> 00:13:25,246
Then there's a section for rationale. Maybe there's something that you need

186
00:13:25,268 --> 00:13:30,302
to make clear to whoever is using this

187
00:13:30,356 --> 00:13:34,458
slO, and this should be explained here. Effort budgets we're

188
00:13:34,474 --> 00:13:38,402
going to see in a bit. But here we can describe what

189
00:13:38,456 --> 00:13:42,302
the effort budget is for this particular slO.

190
00:13:42,366 --> 00:13:45,526
And of course, you can have a section that has clarifications and

191
00:13:45,548 --> 00:13:49,510
caveats, something that needs to be explained, something or maybe

192
00:13:49,580 --> 00:13:53,542
some constraints that need to be taken into consideration when using this

193
00:13:53,596 --> 00:13:57,754
slO. So, going back to

194
00:13:57,792 --> 00:14:01,814
our previous point, what is an exoplasmable

195
00:14:01,862 --> 00:14:05,018
target? 90%, 95%?

196
00:14:05,184 --> 00:14:09,638
100%? Of course, it depends.

197
00:14:09,734 --> 00:14:13,054
It will depend on your user needs. It can depend on

198
00:14:13,092 --> 00:14:16,558
your business needs. For instance, you might be in a

199
00:14:16,564 --> 00:14:20,666
highly regulated business that has many constraints. It can be informed

200
00:14:20,698 --> 00:14:23,906
by cost and many other things. But the point here is

201
00:14:23,928 --> 00:14:27,986
that it depends. But just for us to have

202
00:14:28,008 --> 00:14:31,970
an idea, let's see, can slo

203
00:14:32,550 --> 00:14:36,318
for uptime. Let's say that we define three

204
00:14:36,344 --> 00:14:40,134
nines, right? So the number of nines is something that

205
00:14:40,172 --> 00:14:43,682
it spread across the industry. But for example, for an slo

206
00:14:43,746 --> 00:14:46,806
of three nines, this means that

207
00:14:46,828 --> 00:14:50,502
I can have 8 hours of downtime

208
00:14:50,566 --> 00:14:53,980
per year. Just by adding a nine,

209
00:14:54,350 --> 00:14:57,898
those 8 hours go down to 25

210
00:14:57,984 --> 00:15:01,662
to 52 minutes. And if I add another nine or

211
00:15:01,716 --> 00:15:05,806
five nines of reliability, this means that I can only be down for

212
00:15:05,828 --> 00:15:09,502
five minutes a year. So just by adding one

213
00:15:09,556 --> 00:15:12,726
nine to my uptime slo,

214
00:15:12,858 --> 00:15:16,626
I drastically reduce those downtime. So I

215
00:15:16,648 --> 00:15:20,082
have to put things in place so that I can ensure that

216
00:15:20,136 --> 00:15:23,060
I'm not down more than the allowed amount.

217
00:15:24,230 --> 00:15:28,550
So just to conclude this point, let's just do some back of the envelope

218
00:15:29,690 --> 00:15:32,950
calculations to see what does this mean. So I mentioned

219
00:15:33,020 --> 00:15:36,694
that you need to put things in place to

220
00:15:36,732 --> 00:15:40,314
actually assure this type of reliability. So let's just go through

221
00:15:40,352 --> 00:15:44,038
a couple of scenarios and see how much this could cost us. So let's

222
00:15:44,054 --> 00:15:47,994
see, scenario one. Let's imagine that I want to

223
00:15:48,192 --> 00:15:51,578
increase my reliability from three nines to four nines,

224
00:15:51,674 --> 00:15:56,894
right? So I'm increasing my reliability 0.9.

225
00:15:57,012 --> 00:16:00,942
And those means. And let's imagine that my service does 1

226
00:16:00,996 --> 00:16:05,026
million of revenue. Those means that if

227
00:16:05,048 --> 00:16:06,690
I improve my reliability,

228
00:16:08,230 --> 00:16:12,514
the value of improvement is actually $900.

229
00:16:12,632 --> 00:16:16,326
So does this make sense? Maybe this will

230
00:16:16,348 --> 00:16:19,938
be up to you. But these are important to do these calculations

231
00:16:20,034 --> 00:16:23,670
to see if it makes sense. Scenario two,

232
00:16:23,740 --> 00:16:27,494
let's use as rule of thumb, we can see

233
00:16:27,612 --> 00:16:31,350
a lot in documentations, and I believe it's also in the SRE book that each

234
00:16:31,420 --> 00:16:35,034
additional nine of reliability costs us ten times to achieve that.

235
00:16:35,072 --> 00:16:38,646
So if I go from two, from three to four nines,

236
00:16:38,678 --> 00:16:42,634
this means that whatever it costs me to run my services, it will increase

237
00:16:42,682 --> 00:16:46,702
by a factor of ten. So let's use exactly the same example going

238
00:16:46,756 --> 00:16:50,666
from three nines to four nines.

239
00:16:50,778 --> 00:16:54,174
And let's imagine that it costs us to run 1

240
00:16:54,212 --> 00:16:57,954
million. $1 million. That means that by

241
00:16:57,992 --> 00:17:01,666
adding a new nine, it's going to cost me around $10 million.

242
00:17:01,768 --> 00:17:05,250
So these, of course, are back of the envelope

243
00:17:05,830 --> 00:17:09,526
calculations. But it's important to do those type of calculations for us to have an

244
00:17:09,548 --> 00:17:13,174
idea. If I want to increase my reliability, how much

245
00:17:13,212 --> 00:17:16,630
will it cost me and the amount of value that it can maybe

246
00:17:16,700 --> 00:17:19,930
get me. So, moving forward,

247
00:17:20,080 --> 00:17:23,894
we touched briefly before about error

248
00:17:23,942 --> 00:17:27,574
budgets, but essentially can error budget is what it's

249
00:17:27,622 --> 00:17:31,354
left from an SLO. So if I consider that 100%

250
00:17:31,392 --> 00:17:34,906
is that my service is always reliable, the error

251
00:17:34,938 --> 00:17:38,474
budget will be 100% minus what I define can SLO.

252
00:17:38,522 --> 00:17:42,334
So if it was two nines, it will mean that I'll have 1% of

253
00:17:42,532 --> 00:17:46,146
error budget left. So it's effectively the

254
00:17:46,168 --> 00:17:50,702
percentage of reliability left, and it can help us make educated decisions

255
00:17:50,766 --> 00:17:54,162
on whether, for example, to release a new feature or not.

256
00:17:54,216 --> 00:17:56,420
Based on the amount of risk that we can take.

257
00:17:57,510 --> 00:18:01,186
They help make sure the operability process, for example, incident response,

258
00:18:01,218 --> 00:18:04,886
is appropriate to the budget available for the service being provided. What this means is

259
00:18:04,908 --> 00:18:07,986
that with the amount of reactor budget that we have left, we can

260
00:18:08,028 --> 00:18:10,250
inform our incident response.

261
00:18:11,470 --> 00:18:15,210
And last but not least, we have service level agreements that are

262
00:18:15,280 --> 00:18:18,874
well known to us. But essentially, an SLA is nothing more

263
00:18:18,912 --> 00:18:23,386
than an SLO that has some kind of penalty attached.

264
00:18:23,578 --> 00:18:27,262
For example, let's use the same examples that we've been

265
00:18:27,316 --> 00:18:31,198
using up until this point. So if I have,

266
00:18:31,284 --> 00:18:34,666
I can define an SLA that says that 99 95%

267
00:18:34,708 --> 00:18:38,878
of requests to a service need to be responded within 200 milliseconds

268
00:18:38,974 --> 00:18:42,146
within a 30 day period. If that doesn't happen,

269
00:18:42,248 --> 00:18:45,698
the customer will get a 30% discount. And the

270
00:18:45,704 --> 00:18:49,270
same thing for the other example. But the basic idea here is that

271
00:18:49,340 --> 00:18:53,238
an SLA is an SLO that actually has some

272
00:18:53,324 --> 00:18:57,186
type of penalty attached. They are usually looser

273
00:18:57,218 --> 00:19:00,898
than slos, so that if we breach an

274
00:19:00,924 --> 00:19:04,298
SLO, we actually still have some time before breaking the

275
00:19:04,304 --> 00:19:07,594
SLA. So looking at the first example, if we had an SLO of

276
00:19:07,632 --> 00:19:11,482
29, so 99%, this meant that if I breached

277
00:19:11,546 --> 00:19:15,614
that SLO, I still had 4% of

278
00:19:15,652 --> 00:19:19,374
unreliability to burn, so to speak, until my

279
00:19:19,412 --> 00:19:21,070
SLA was breached.

280
00:19:22,210 --> 00:19:25,460
So what can we build with this? All of this?

281
00:19:26,630 --> 00:19:30,500
So, of course, we can build visualizations. So here is an example

282
00:19:31,350 --> 00:19:35,266
of how we can track and put on a dashboard a

283
00:19:35,288 --> 00:19:38,310
visualization of an SLO. Here we have the objective, for example,

284
00:19:38,380 --> 00:19:41,750
99%, how much slo is being burned,

285
00:19:42,090 --> 00:19:45,622
how much I still have left. If something is burning or not.

286
00:19:45,676 --> 00:19:49,922
So this is very interesting and we can see and can do can historical analysis

287
00:19:49,986 --> 00:19:52,920
of how my SLO is actually going.

288
00:19:53,470 --> 00:19:56,762
But we don't want to be looking at dashboards all day.

289
00:19:56,816 --> 00:20:00,398
This is very interesting, but what we actually want

290
00:20:00,484 --> 00:20:04,318
is to be informed if something is not

291
00:20:04,404 --> 00:20:07,310
going okay, right? So that we can take the appropriate measures.

292
00:20:08,530 --> 00:20:10,190
So we come to alerts.

293
00:20:11,010 --> 00:20:14,618
So if we think about the traditional

294
00:20:14,714 --> 00:20:17,966
relative methods, we usually use metric

295
00:20:17,998 --> 00:20:21,474
thresholds, right? So we define some kind of threshold and see if

296
00:20:21,512 --> 00:20:24,702
something goes anova that threshold,

297
00:20:24,766 --> 00:20:28,754
we need to trigger an alert so that someone can investigate

298
00:20:28,802 --> 00:20:32,034
and see if everything is okay. So here are just a couple of examples.

299
00:20:32,082 --> 00:20:35,174
If a cpu goes above 80%,

300
00:20:35,292 --> 00:20:38,694
if a certain number of requests is taking more than 200

301
00:20:38,732 --> 00:20:42,070
milliseconds, if we have x amount of 500 responses,

302
00:20:42,150 --> 00:20:45,594
we just trigger an alert and someone needs to investigate what's going

303
00:20:45,632 --> 00:20:49,466
on. We can take the same approach with the

304
00:20:49,488 --> 00:20:53,150
slO. With an slO. So we can say that if latency,

305
00:20:53,730 --> 00:20:57,438
if we have an SLO of 99% and latency goes below that,

306
00:20:57,524 --> 00:21:00,800
those is SLO, we mean we need to do something.

307
00:21:01,570 --> 00:21:05,314
This is better because if we define our slos in

308
00:21:05,352 --> 00:21:08,786
a meaningful way, it's actually tracking users experience,

309
00:21:08,968 --> 00:21:12,830
but it only alerts us when we are already in trouble,

310
00:21:12,910 --> 00:21:16,120
right? So how can we do better than this?

311
00:21:17,610 --> 00:21:21,094
So we can alert on the amount of

312
00:21:21,132 --> 00:21:24,866
error budget that we still have available, or the amount of error

313
00:21:24,898 --> 00:21:27,350
budget that we have already burned.

314
00:21:28,410 --> 00:21:32,214
So we can set alerts when available error budget reaches

315
00:21:32,262 --> 00:21:35,638
a critical level, or when a critical amount of error

316
00:21:35,654 --> 00:21:39,654
budget has been burned. And we can set different trigger levels

317
00:21:39,702 --> 00:21:43,562
to different alert channels. For example, if I have already burned

318
00:21:43,626 --> 00:21:47,166
25% of my budget, I can send an

319
00:21:47,188 --> 00:21:50,602
email 50%, I can alert someone on teams or on slack.

320
00:21:50,666 --> 00:21:54,602
And if 75% of my budget has been burned, I can trigger

321
00:21:54,666 --> 00:21:58,100
pager duty or ops genie for someone to actually look into it.

322
00:21:59,190 --> 00:22:03,182
This is better than the alternative because we are being alerted

323
00:22:03,246 --> 00:22:06,566
before we get into trouble and we need to do something.

324
00:22:06,668 --> 00:22:10,466
But we have no idea how fast this error

325
00:22:10,498 --> 00:22:14,454
budget is being consumed. So it begs the question, if my

326
00:22:14,492 --> 00:22:17,586
error budget, if my slo is well defined,

327
00:22:17,698 --> 00:22:21,466
and if I know, or if I could know if

328
00:22:21,488 --> 00:22:25,994
by the end of the evaluation period we would still have some error budget left,

329
00:22:26,192 --> 00:22:28,410
would you like to receive desolate?

330
00:22:29,150 --> 00:22:33,306
Probably not, because I will still be within my bounds

331
00:22:33,418 --> 00:22:37,054
of the amount of reliability that I have. So I can

332
00:22:37,092 --> 00:22:39,680
make the decision to actually, I don't know,

333
00:22:40,050 --> 00:22:43,342
release more features or do other

334
00:22:43,396 --> 00:22:47,006
type of work because I still

335
00:22:47,028 --> 00:22:50,980
have some reliability that I can account for.

336
00:22:51,430 --> 00:22:55,214
So the next evolution will actually be would actually tackle

337
00:22:55,262 --> 00:22:58,520
this problem. And it is the burn rate.

338
00:22:58,890 --> 00:23:02,226
So burn rate actually tells us how fast an error

339
00:23:02,258 --> 00:23:05,922
the error budget is being consumed. When I make this calculation,

340
00:23:06,066 --> 00:23:09,526
if the error budget, those burn rate of one means that

341
00:23:09,628 --> 00:23:13,046
all my error budget will be consumed within the interval

342
00:23:13,078 --> 00:23:16,474
that I define, for example 30 days or a week, let's see those example.

343
00:23:16,672 --> 00:23:19,978
If I have a window of evaluation of four weeks

344
00:23:20,144 --> 00:23:23,654
and I'll calculate my error budget,

345
00:23:23,702 --> 00:23:27,674
my burn rate, and it's two, this means that I will consume

346
00:23:27,722 --> 00:23:31,390
all my effort budget in half the time. So in this example, two weeks,

347
00:23:31,540 --> 00:23:35,662
this is a lot better. But it still has a slight

348
00:23:35,726 --> 00:23:39,054
problem, which is if the effort budget burns

349
00:23:39,102 --> 00:23:42,530
too fast and we evaluated,

350
00:23:43,190 --> 00:23:46,882
and for example it is consumed within my evaluation period,

351
00:23:46,946 --> 00:23:50,150
I might not even receive an alert. So we can do here

352
00:23:50,220 --> 00:23:53,862
a small tweak to have excellent alerts based

353
00:23:53,916 --> 00:23:57,814
on burn rate. And these

354
00:23:57,852 --> 00:24:01,322
are alerts on effort budget available. I'm sorry,

355
00:24:01,456 --> 00:24:04,582
these are alerts on multi window multiburn rate alerts.

356
00:24:04,726 --> 00:24:08,214
So we will use multiple windows and multiple

357
00:24:08,262 --> 00:24:11,100
burn rates to inform us of different problems.

358
00:24:11,470 --> 00:24:14,714
We will inform fast burn alerts that will alert

359
00:24:14,762 --> 00:24:18,480
us on sudden changes in the consumption of burn rate.

360
00:24:18,850 --> 00:24:22,206
We can think of this as an example. We have a huge spike in

361
00:24:22,228 --> 00:24:26,014
errors in our API, for example, and slow burn alerts

362
00:24:26,062 --> 00:24:30,034
that alerts us on less urgent issues. But is something

363
00:24:30,072 --> 00:24:33,746
that is consuming over time a lot of error budget? So here are

364
00:24:33,768 --> 00:24:37,266
just a few examples I can define that. I have

365
00:24:37,288 --> 00:24:41,174
a window of evaluation of 2 hours. I evaluate every five

366
00:24:41,212 --> 00:24:44,518
minutes, and if my burn rate is ten, I know that something

367
00:24:44,604 --> 00:24:48,582
is not okay. And the same thing for a slow burn. I define

368
00:24:48,646 --> 00:24:52,620
evaluation period of 4 hours, so longer. And if my burn rate

369
00:24:53,630 --> 00:24:57,850
is two, I actually have a problem and I need to investigate.

370
00:24:59,070 --> 00:25:02,462
And our last concept is the concept of the Akar budget policy.

371
00:25:02,596 --> 00:25:06,730
And those budget policy is nothing more than a document or a set of documents

372
00:25:06,810 --> 00:25:10,586
where we define what happens when certain conditions

373
00:25:10,618 --> 00:25:14,286
of my echo budget have been breached. So here

374
00:25:14,388 --> 00:25:17,726
are just an example. So if a service

375
00:25:17,828 --> 00:25:20,914
has exceeded its echo budget for the preceding four week

376
00:25:20,952 --> 00:25:24,398
window, we will halt all changes and releases

377
00:25:24,494 --> 00:25:28,578
other than p zero or security feed security fixes

378
00:25:28,674 --> 00:25:31,590
until the service is back within its slO.

379
00:25:32,330 --> 00:25:35,794
And depending upon the cause of the SLO miss, the team may devote

380
00:25:35,842 --> 00:25:39,618
additional resources to working on reliability instead of feature work.

381
00:25:39,724 --> 00:25:43,366
So this is a concrete definition of what happens when my Slo

382
00:25:43,398 --> 00:25:46,586
is breached. This of course will be highly contextual and

383
00:25:46,608 --> 00:25:50,586
will be dependent on your organization, of course. But it's

384
00:25:50,618 --> 00:25:54,654
something that it's predefined and it's agreed by everyone involved that

385
00:25:54,772 --> 00:25:58,046
if certain thing, certain things happen,

386
00:25:58,148 --> 00:26:00,560
those are the actions that we are going to take.

387
00:26:02,550 --> 00:26:06,190
So to recap, let's see this concept of the reliability

388
00:26:06,270 --> 00:26:09,314
stack in his extended way.

389
00:26:09,432 --> 00:26:13,214
We started by looking at metrics, which are measurements

390
00:26:13,262 --> 00:26:16,990
about those system. We then evolved those to an SLI,

391
00:26:17,070 --> 00:26:20,486
which tells us if a metric is good or bad or an

392
00:26:20,508 --> 00:26:24,082
event is good or bad. We then evolved into slos,

393
00:26:24,146 --> 00:26:27,762
and slos can tell us how many times the SLI

394
00:26:27,826 --> 00:26:32,026
needs to be good so that my customers are

395
00:26:32,128 --> 00:26:35,622
actually happy. The other budget

396
00:26:35,686 --> 00:26:38,970
is nothing more than what it's left from the slO.

397
00:26:39,870 --> 00:26:43,790
And then with slos, what can we build? We can build visualizations

398
00:26:44,530 --> 00:26:48,160
so that we can use to assess if the SLO is

399
00:26:49,090 --> 00:26:52,334
okay or not. We can build minifill alerts that

400
00:26:52,372 --> 00:26:56,466
track user experience and tell us if something is not okay.

401
00:26:56,648 --> 00:26:59,922
We can define effort budget policies that actually can inform

402
00:26:59,976 --> 00:27:03,458
us what we need to do if certain conditions happen. And of

403
00:27:03,464 --> 00:27:07,606
course we can users those slos to define slas that those

404
00:27:07,628 --> 00:27:10,870
are nothing more than an SLO with a penalty.

405
00:27:12,490 --> 00:27:15,080
And why is all of this important?

406
00:27:15,930 --> 00:27:19,594
For starters, we start measuring reliability from the eyes of

407
00:27:19,632 --> 00:27:23,590
our users. They are the most important actors

408
00:27:23,670 --> 00:27:26,860
that will help us define the reliability. It doesn't matter

409
00:27:27,390 --> 00:27:30,846
if I think if my system is performant, if my users are

410
00:27:30,868 --> 00:27:33,280
not happy with the way that it's working.

411
00:27:34,610 --> 00:27:37,774
Also, reliability work.

412
00:27:37,892 --> 00:27:40,602
Reliability work ties directly to business goals.

413
00:27:40,666 --> 00:27:43,854
So happy users are usually good for business. And if

414
00:27:43,892 --> 00:27:47,118
I'm tracking reliability and my users are happy, and I'm

415
00:27:47,134 --> 00:27:50,830
ensuring that my users are happy through a reliability framework,

416
00:27:50,910 --> 00:27:54,610
this is good for business and we can tie this directly to business goals.

417
00:27:55,610 --> 00:27:58,994
It also creates a shared language to talk about reliability.

418
00:27:59,122 --> 00:28:03,270
There's no more some engineers defining

419
00:28:03,610 --> 00:28:07,154
how reliability should be tracked or measured.

420
00:28:07,202 --> 00:28:10,982
Other reliability engineers doing it another way, product people

421
00:28:11,036 --> 00:28:13,738
saying it another way, business people doing it another way. So now we have a

422
00:28:13,744 --> 00:28:16,954
framework that will help us assess, measure and

423
00:28:16,992 --> 00:28:21,298
define reliability. And of course this facilitates prioritization.

424
00:28:21,414 --> 00:28:24,606
So if we have a reliability framework in place and

425
00:28:24,628 --> 00:28:28,080
we have can error budget policy that tells us what needs to happen

426
00:28:30,050 --> 00:28:33,706
when setting conditions apply. This help us facilitate,

427
00:28:33,818 --> 00:28:37,594
prioritize work and makes it easier to make decisions

428
00:28:37,642 --> 00:28:41,134
on when we should we focus our efforts into reliability work or

429
00:28:41,172 --> 00:28:45,158
on product work, for example. And this

430
00:28:45,164 --> 00:28:48,840
is all from my part. I hope this was informative for you.

431
00:28:49,610 --> 00:28:52,978
Don't hesitate to contact me through my social links.

432
00:28:53,074 --> 00:28:56,450
I hope you enjoyed my talk and have a great conference.

