1
00:00:00,890 --> 00:00:03,680
It's. It's pretty early, right?

2
00:00:04,050 --> 00:00:06,862
Feels early to me. I come to London once a year at the moment.

3
00:00:06,916 --> 00:00:08,720
This is the only time in 2020.

4
00:00:09,330 --> 00:00:13,386
And I had the issue of living on the south coast of England,

5
00:00:13,578 --> 00:00:16,574
which, if anyone's familiar with that, it's about. Takes about as long as it takes

6
00:00:16,612 --> 00:00:19,920
to get to the east or west of London from here.

7
00:00:21,090 --> 00:00:24,966
About 2 hours door to door. So it's been an early start, which means

8
00:00:25,108 --> 00:00:28,406
ready and very awake, and I imagine you may not

9
00:00:28,428 --> 00:00:32,210
be quite so. So I'm going to try and make this as easier

10
00:00:32,290 --> 00:00:35,154
a way of getting into the day as possible because there's a lot of fantastic

11
00:00:35,202 --> 00:00:38,614
talks coming. Okay, I'm going to do that because

12
00:00:38,652 --> 00:00:42,202
I can't see anything unless I do that. Has anyone seen me speak before?

13
00:00:42,256 --> 00:00:45,594
Raise your hand if you have. Excellent. So some of you have seen me speak

14
00:00:45,632 --> 00:00:48,602
before. That's great. I can't completely reinvent myself then.

15
00:00:48,736 --> 00:00:52,106
Damn it. So I'll actually have to keep to the story.

16
00:00:52,208 --> 00:00:54,926
I can't see my slides yet. Is there a reason they're not up on here

17
00:00:54,948 --> 00:00:59,022
yet? I plugged everything in. They are now.

18
00:00:59,076 --> 00:01:02,734
They are brilliant. You're a star. Thank youre. Right. So this

19
00:01:02,772 --> 00:01:05,794
talk is a slight adjustment on a talk I've been doing for a little while

20
00:01:05,832 --> 00:01:10,130
now. And it's pretty useful to sort of box

21
00:01:10,280 --> 00:01:14,766
chaos engineering and to talk about two things, really. One, what chaosiq engineering

22
00:01:14,798 --> 00:01:18,902
is and how we should approach it, and two, how we might

23
00:01:18,956 --> 00:01:23,046
go beyond it. That's the new part today. Now, I'm not

24
00:01:23,068 --> 00:01:26,338
saying that youre come to a chaos engineering conference and somebody's

25
00:01:26,354 --> 00:01:29,574
already saying, go beyond it. And you're probably sitting there going,

26
00:01:29,612 --> 00:01:33,114
I don't know what it is yet. Or if you do know what it is,

27
00:01:33,152 --> 00:01:35,580
you're probably going, I hope he says it's what I'm being,

28
00:01:36,590 --> 00:01:40,074
but that's all good. I'm actually not going to say, oh, youre do

29
00:01:40,112 --> 00:01:43,374
this. And then here's the really good part. At the end, I'm going to be

30
00:01:43,412 --> 00:01:46,958
saying, okay, everything you're doing is right, but there is

31
00:01:46,964 --> 00:01:50,558
a different way of packaging it that just might

32
00:01:50,644 --> 00:01:54,542
make it easier for your company to endorse and explore

33
00:01:54,606 --> 00:01:57,602
and be happy to put a budget on. So,

34
00:01:57,656 --> 00:02:01,026
okay, let's get going. Me, for those that don't know

35
00:02:01,048 --> 00:02:04,546
you, I am quite happy with risk as a

36
00:02:04,568 --> 00:02:07,906
motorcyclist. That's what I intend to embrace. I embrace risk on roads.

37
00:02:07,938 --> 00:02:11,042
Anyone here a motorcyclist? Excellent, brother.

38
00:02:11,106 --> 00:02:14,518
How youre doing? Okay, so I ride a Harley Davidson. So it's sort of a

39
00:02:14,524 --> 00:02:18,454
motorcyclist. It's not really. It's a couch on two

40
00:02:18,492 --> 00:02:21,654
wheels, but it's a lovely bike. And this was actually me

41
00:02:21,692 --> 00:02:25,334
on a much smaller bike. I was over in Tibet riding to Mount

42
00:02:25,382 --> 00:02:28,218
Everest. You have to do it on the north side, you have to do it

43
00:02:28,224 --> 00:02:30,700
in Tibet because on the south side there is no road.

44
00:02:31,310 --> 00:02:34,394
So I rode a motorcycle to Mount Everest. And on my way to Mount Everest,

45
00:02:34,442 --> 00:02:37,838
I got some wonderful opportunities, some beautiful pictures. And all of them

46
00:02:37,924 --> 00:02:41,434
led me to a greater understanding of this troublesome activity

47
00:02:41,482 --> 00:02:45,150
that we're involved in called system delivery and system development.

48
00:02:45,730 --> 00:02:47,490
Someone's died next door.

49
00:02:49,990 --> 00:02:53,314
It's not as bad as. I've had some great analogies in my talks where something

50
00:02:53,352 --> 00:02:56,530
goes on in the background and we actually had a fire alarm go off once.

51
00:02:56,600 --> 00:03:00,038
And I thought, that's perfect for chaos engineering. It's a fire alarm and you just

52
00:03:00,044 --> 00:03:03,186
watch everyone's reaction. Quick detour in a fire alarm,

53
00:03:03,218 --> 00:03:07,014
what do you think everyone's first reaction is? Check their

54
00:03:07,052 --> 00:03:09,980
watches. Is it 11:00 a.m.

55
00:03:10,990 --> 00:03:15,014
If it is, it's a drill. Very few fires have spontaneously

56
00:03:15,062 --> 00:03:18,442
started on the dots of 11:00 a.m. So usually

57
00:03:18,496 --> 00:03:21,786
go, oh, yeah, it's a drill. Even if it's not, even if

58
00:03:21,808 --> 00:03:25,726
they see smoke, it's a drill. So, yeah, I've had that. That's actually

59
00:03:25,748 --> 00:03:29,354
a good little starting point. Fire drills are a terrible analogy for chaos

60
00:03:29,402 --> 00:03:33,006
engineering. It's often used, you practice these

61
00:03:33,028 --> 00:03:36,626
things because they matter, because when it actually happens, you'll be prepared. Does anyone know

62
00:03:36,648 --> 00:03:40,402
the basic problem with fire drills? They make you

63
00:03:40,456 --> 00:03:43,726
complacent. They make you think you know how it's

64
00:03:43,758 --> 00:03:47,240
all going to go. I'll tell you a very, very quick, tragic story.

65
00:03:51,610 --> 00:03:55,560
Very much. Very much, sir. I've got the most interesting heckler in the world.

66
00:03:56,490 --> 00:03:59,830
Brilliant. Don't normally get heckling in tech talks.

67
00:04:00,890 --> 00:04:04,794
So this is all the story. This is about a lady who had absolutely no

68
00:04:04,832 --> 00:04:08,058
ability in her brain to become complacent. Whatever the Wiring was in,

69
00:04:08,064 --> 00:04:11,562
the brain could become complacent. And she happened to work

70
00:04:11,616 --> 00:04:15,262
very, very high up on one of the twin towers. And obviously

71
00:04:15,316 --> 00:04:18,894
the fire alarm went off. The yellow tower had got a problem. Everyone was told

72
00:04:18,932 --> 00:04:22,062
to leave. She did. She got up,

73
00:04:22,116 --> 00:04:25,278
she walked the stairs, and she walked from the very top of the tower to

74
00:04:25,284 --> 00:04:28,754
the bottom. And she survived. While she was going there,

75
00:04:28,792 --> 00:04:32,526
everyone else on her floor didn't have this different wiring

76
00:04:32,558 --> 00:04:35,810
in their brain. What were they doing? They were finishing their phone calls.

77
00:04:36,230 --> 00:04:40,022
They were looking at their screens and wondering if it was for real. They were

78
00:04:40,076 --> 00:04:43,494
picking up their photos of the family. One person walked with her down a few

79
00:04:43,532 --> 00:04:46,646
flights of stairs and then came back because they've forgotten something

80
00:04:46,668 --> 00:04:50,298
at their desk. They've forgotten their laptop. None of

81
00:04:50,304 --> 00:04:54,074
those people, none of those people made

82
00:04:54,112 --> 00:04:57,386
it out of that building. So complacency is

83
00:04:57,408 --> 00:05:00,726
dangerous. When I talk about today, I talk, but how

84
00:05:00,768 --> 00:05:04,666
chaos engineering should be viewed. And I'm very careful because I call it a practice.

85
00:05:04,858 --> 00:05:09,034
Youre a practitioner of this, but be very sensitive

86
00:05:09,162 --> 00:05:11,920
to complacency when you practice something,

87
00:05:12,690 --> 00:05:15,886
just because that's what happens in fire drills, is we get so used

88
00:05:15,908 --> 00:05:19,358
to them going off, we literally go, right. All those things you're

89
00:05:19,374 --> 00:05:23,026
told what youre told. Absolutely don't do, don't pick up your laptop, don't just leave

90
00:05:23,048 --> 00:05:27,102
it all go. And you won't because you're complacent.

91
00:05:27,246 --> 00:05:30,594
So, yeah, just, that's the downside. That's the flip side, the nasty side of chaos

92
00:05:30,642 --> 00:05:34,374
injuring. Right. Back to the story. Back in Tibet, I saw

93
00:05:34,412 --> 00:05:36,920
some wonderful things. I saw this.

94
00:05:37,850 --> 00:05:41,254
Now, that looks like it's going along a plain, but actually it's going down a

95
00:05:41,292 --> 00:05:44,454
very, very steep hill. It's just one of those photos that's a bit confusing.

96
00:05:44,582 --> 00:05:47,974
The beautiful thing about this is it gives me several analogies for software

97
00:05:48,022 --> 00:05:51,694
delivery and system delivery. Number one, that's the

98
00:05:51,732 --> 00:05:54,640
best analogy for a software roadmap I've ever seen.

99
00:05:55,970 --> 00:05:59,822
And actually, I go further. Most software roadmaps I've got have got lots more

100
00:05:59,876 --> 00:06:03,674
dead ends, like side roads that go off a cliff.

101
00:06:03,802 --> 00:06:06,818
A lot of those, but they're not on this one. So it's not perfect,

102
00:06:06,904 --> 00:06:10,146
but it's not bad. The other thing that you can't seen so well on this

103
00:06:10,168 --> 00:06:14,274
beauty is that some of those corners doesn't have tarmac on

104
00:06:14,312 --> 00:06:17,670
it. Now, I'm a motorcyclist.

105
00:06:18,010 --> 00:06:21,878
Your biggest fear about going around a corner, leaning over is

106
00:06:21,964 --> 00:06:25,714
lack of grip. And they've taken the tarmac

107
00:06:25,762 --> 00:06:29,046
off on the corners. Okay, so why have they done that?

108
00:06:29,068 --> 00:06:32,682
It's because the water, when in the rainy season, when there's lots of water,

109
00:06:32,736 --> 00:06:36,474
tunnels its way down, this actually takes off that top

110
00:06:36,512 --> 00:06:40,140
layer. And so what they've done is make it safer. We'll remove it completely.

111
00:06:40,910 --> 00:06:43,500
Not sure about that thinking, but it was there.

112
00:06:43,870 --> 00:06:46,446
The other thing is, you go around those corners and what they've done is the

113
00:06:46,468 --> 00:06:49,520
Tibetans, in their absolute wisdom, have looked at this and gone,

114
00:06:50,050 --> 00:06:53,886
it's a bit dangerous. We need to let people know

115
00:06:53,908 --> 00:06:57,634
we've taken the tarmac off. What should we do? Should we create a sign

116
00:06:57,752 --> 00:07:01,186
maybe 100 yards before it? No, what we should

117
00:07:01,208 --> 00:07:05,174
do is create. Put little rocks about that big little

118
00:07:05,212 --> 00:07:09,560
boulders around it like it's dangerous here.

119
00:07:10,810 --> 00:07:14,806
They've turned a mildly dangerous chunk of road into a

120
00:07:14,828 --> 00:07:18,230
lethal hazard. Brilliance.

121
00:07:18,570 --> 00:07:21,240
And we do that in software all the time.

122
00:07:21,930 --> 00:07:25,306
We go, oh, it's a bit difficult here, you mustn't change it. So what will

123
00:07:25,328 --> 00:07:29,100
we do? We're putting a readme in a repo somewhere. No one will see that

124
00:07:29,470 --> 00:07:33,342
we're constantly leaving traps in our world. And interestingly enough,

125
00:07:33,396 --> 00:07:37,246
there's lots of funny things with safety when it comes to

126
00:07:37,268 --> 00:07:40,606
chaos engineering and how it relates to safety and how we're building safety in

127
00:07:40,628 --> 00:07:44,930
our systems. And this theory of making something safer

128
00:07:45,670 --> 00:07:49,250
means we can often make it a lot more dangerous

129
00:07:49,590 --> 00:07:52,306
through complacency, or as in this case,

130
00:07:52,408 --> 00:07:56,066
rocks around a hazard. Anyway, that was part of it.

131
00:07:56,088 --> 00:07:59,494
I learned that. But what I learned even better is I learned what people think

132
00:07:59,532 --> 00:08:02,630
production looks like. Serene,

133
00:08:03,050 --> 00:08:06,786
beautiful. I took this photo from the foothills opposite Mount

134
00:08:06,818 --> 00:08:09,400
Everest. So lucky it was a clear day.

135
00:08:09,930 --> 00:08:12,858
Now, you could argue if this was an analogy for production. There's a lot of

136
00:08:12,864 --> 00:08:16,460
cloud there. Hiding a lot of sins. That's also true,

137
00:08:17,070 --> 00:08:21,082
but that is what we think we've got. You must have seen the PowerPoint slides

138
00:08:21,146 --> 00:08:24,670
that someone puts in front of you and says, look, here's production.

139
00:08:25,330 --> 00:08:28,430
Three boxes, straight arrows.

140
00:08:29,010 --> 00:08:32,446
Gorgeous. Where's the complexity? It's not

141
00:08:32,468 --> 00:08:36,398
even there. It's perfect. And then I got

142
00:08:36,404 --> 00:08:39,966
the real analogy for production, though. So that was in front of me and admittedly

143
00:08:39,998 --> 00:08:43,294
not immediately behind me, because when you get to seen the picture, you'll realize

144
00:08:43,342 --> 00:08:46,690
that would be disgusting. But there was behind

145
00:08:46,760 --> 00:08:50,146
me, in about 20 or 30 meters behind. Good distance

146
00:08:50,178 --> 00:08:53,106
from it, by the way. Again, it makes sense in a minute.

147
00:08:53,298 --> 00:08:57,030
There was the real production because this is what was behind

148
00:08:57,100 --> 00:09:00,266
me, some distance behind me. This is the

149
00:09:00,288 --> 00:09:02,810
toilet at Mount Everest,

150
00:09:03,630 --> 00:09:07,162
not to be gotten near for about 23

151
00:09:07,216 --> 00:09:11,098
and a half hours of the day. There's one half hour period you

152
00:09:11,104 --> 00:09:14,654
can go near production. I mean, the toilet. And I will not

153
00:09:14,692 --> 00:09:18,186
tell you now why that half hour period exists,

154
00:09:18,298 --> 00:09:22,190
but needless to say, it has a lot to do with burnt yak poo.

155
00:09:22,850 --> 00:09:26,946
And it becomes safe. You can actually see it. It's completely

156
00:09:27,048 --> 00:09:29,906
and utterly. You could own that toilet all day long.

157
00:09:30,008 --> 00:09:33,730
And then the moment the yak poo goes on, the queue forms.

158
00:09:34,070 --> 00:09:37,586
The queue can be up to half a mile long. So, yeah,

159
00:09:37,608 --> 00:09:40,774
you don't get the end. Okay, so that's the truth, right? Most people on

160
00:09:40,812 --> 00:09:44,374
stage don't explain what production is like. They say,

161
00:09:44,412 --> 00:09:47,686
oh yes, look what we did. I remember going to talks over

162
00:09:47,708 --> 00:09:51,018
and over again at big conferences where people say,

163
00:09:51,184 --> 00:09:54,634
this is production. We've done this, we've learned this, we've learned that.

164
00:09:54,672 --> 00:09:58,010
It's been wonderful, it's been great. They're lying.

165
00:09:58,750 --> 00:10:02,380
It's been hell and they need to tell you that.

166
00:10:03,230 --> 00:10:06,766
And so I'm hoping that more do and chaosiq engineering helps with that because it

167
00:10:06,788 --> 00:10:10,922
makes our hell much more shareable and much more comparable.

168
00:10:11,066 --> 00:10:15,022
So let's get into it a bit more. Okay, so what

169
00:10:15,076 --> 00:10:18,274
happens usually, and let's talk a little bit about

170
00:10:18,312 --> 00:10:22,434
the trends at the moment because everyone in this industry absolutely loves new terminology for

171
00:10:22,472 --> 00:10:25,550
old stuff. Okay, we're going to do microservices.

172
00:10:25,630 --> 00:10:28,866
No, it's not, no, no, it's not Corba. It's RPC, but it's not

173
00:10:28,888 --> 00:10:32,258
Corba. We're going to call it Google something. Those sorts

174
00:10:32,274 --> 00:10:34,534
of things happen. So we're going to do something new. It's going to be different.

175
00:10:34,572 --> 00:10:37,862
We're following new trend. New trend at the moment is cloud native. Let's go cloud

176
00:10:37,916 --> 00:10:40,460
native. Because then it's someone else's problem, right?

177
00:10:42,030 --> 00:10:45,638
It's someone else's. If we've got people from aws here, they'll tell you it's

178
00:10:45,654 --> 00:10:49,690
their problem and then they'll explain why much of it is yours.

179
00:10:51,310 --> 00:10:54,598
I'm glad he's laughing and not looking at me with evils, although I couldn't

180
00:10:54,614 --> 00:10:57,966
tell. Okay, so you're going to go and do

181
00:10:57,988 --> 00:11:00,606
something new. You're going to build something new perhaps. Or if it means youre got

182
00:11:00,628 --> 00:11:03,946
an existing system that you need to improve the reliability of, either way you've

183
00:11:03,978 --> 00:11:06,818
got something and you're going to try and do something cool. And chaos engineering is

184
00:11:06,824 --> 00:11:10,050
in the same bracket. Right? Quick message. Can we stop

185
00:11:10,120 --> 00:11:13,582
inventing terminology? We're terrible

186
00:11:13,646 --> 00:11:16,978
at it. Okay, let's talk about some

187
00:11:16,984 --> 00:11:18,930
of this stuff. Services,

188
00:11:20,550 --> 00:11:23,254
I'm not going to ask you what you think of microservices because I don't know

189
00:11:23,292 --> 00:11:26,806
and I teach a class on it. Very first thing I do is

190
00:11:26,828 --> 00:11:30,566
say, I don't care how big they are. So what does

191
00:11:30,588 --> 00:11:33,506
that leave us with? Services? We're doing SoA, no, we're not. We can't do that

192
00:11:33,548 --> 00:11:37,162
because that has really screwed up. So now we're doing something different.

193
00:11:37,216 --> 00:11:39,258
We know it's something different, but we don't really know what it is, so we

194
00:11:39,264 --> 00:11:42,094
call it services because that's a good idea.

195
00:11:42,292 --> 00:11:46,350
That is not the worst, though. My personal nemesis

196
00:11:46,930 --> 00:11:50,878
is we took a beautiful renaissance in data access

197
00:11:50,964 --> 00:11:54,638
and persistence technologies, and we did a beautiful

198
00:11:54,724 --> 00:11:58,782
number on it. We turned it from being a renaissance,

199
00:11:58,846 --> 00:12:02,786
a wonderful realization that we had all of this pleasure of different ways of

200
00:12:02,808 --> 00:12:06,454
storing and retrieving data. And we called it by what

201
00:12:06,492 --> 00:12:10,310
it isn't. No SQL.

202
00:12:11,050 --> 00:12:14,166
Worse than that, we didn't even call it by what it isn't. We call it

203
00:12:14,268 --> 00:12:17,240
by what it isn't some of the time,

204
00:12:19,150 --> 00:12:22,060
and SQL was never the problem in the first place.

205
00:12:22,750 --> 00:12:26,074
So, yes, what a wonderful group of namers we

206
00:12:26,112 --> 00:12:29,718
are. Chaos engineering. Let's talk about that one.

207
00:12:29,904 --> 00:12:34,234
Okay. How many people here have been in conversation and thought, for the 80th

208
00:12:34,282 --> 00:12:37,722
time, I've now got to say, no, I'm not engineering

209
00:12:37,786 --> 00:12:41,070
chaos because youre not.

210
00:12:41,140 --> 00:12:44,862
That's easy. It's called delivery.

211
00:12:44,926 --> 00:12:48,894
In some companies, it's called release

212
00:12:48,942 --> 00:12:53,038
day. I work with one company, they said, we do continuous delivery.

213
00:12:53,134 --> 00:12:56,142
We deliver continuously. Brilliant.

214
00:12:56,206 --> 00:12:59,906
My job is done. This is easy. I'm here to help you do great software

215
00:12:59,938 --> 00:13:03,254
development practices, and you're doing continuous delivery already. You must be very good at this.

216
00:13:03,292 --> 00:13:06,626
He said, yes, we are. We continuously deliver

217
00:13:06,738 --> 00:13:08,360
once a year,

218
00:13:10,810 --> 00:13:14,120
continuously. Oh, man.

219
00:13:14,650 --> 00:13:18,962
Anyway, so naming things chaosiq

220
00:13:19,026 --> 00:13:22,560
engineering, we're not engineering chaos. Let me explain what we are doing.

221
00:13:22,930 --> 00:13:25,998
Okay. The problem with anything you're doing at the moment, what's the problem with any

222
00:13:26,004 --> 00:13:29,130
of the systems we're working on, is if you go in something like cloud native,

223
00:13:29,210 --> 00:13:32,238
there's a lot of moving parts. Now, this is a diagram that I have to

224
00:13:32,244 --> 00:13:35,486
admit I haven't read all of, but it has an awful lot of stuff in

225
00:13:35,508 --> 00:13:38,562
it that says, this is exactly how you approach cloud native. And there are other

226
00:13:38,616 --> 00:13:42,686
things that you could approach. Waterfall's got plenty in there. If you're doing waterfall,

227
00:13:42,798 --> 00:13:46,478
if you're doing continuous waterfall, a waterfall

228
00:13:46,494 --> 00:13:49,746
is basically Arkansas. Anyway, it doesn't matter. So you've got all

229
00:13:49,768 --> 00:13:52,006
those things that you could be doing, and there's a lot of moving parts in

230
00:13:52,028 --> 00:13:55,154
anything you adopt in our industry. So there's lots of movement

231
00:13:55,202 --> 00:13:58,890
and lots of possibilities for interesting surprises.

232
00:14:00,350 --> 00:14:04,282
Okay. And even when you do everything right, because I imagine everyone

233
00:14:04,336 --> 00:14:08,106
here does everything right all the time. I'm sure they

234
00:14:08,128 --> 00:14:11,878
do. I do. No, I don't. Even when

235
00:14:11,904 --> 00:14:15,578
you think you've done everything right, this is production.

236
00:14:15,754 --> 00:14:19,482
Nothing like a good game of Thrones meme for production. It's dark,

237
00:14:19,546 --> 00:14:23,006
it's full of terrors. Anyone who worked in operations can tell

238
00:14:23,028 --> 00:14:26,238
you this. I can tell you exactly what that's like at 06:00 a.m. When it

239
00:14:26,244 --> 00:14:29,938
goes wrong. 06:00 a.m. On a Sunday happens to be their birthday. That sort of

240
00:14:29,944 --> 00:14:33,182
level of 06:00 a.m. It's dark and it's full of terrors.

241
00:14:33,246 --> 00:14:35,874
Okay. Why? If we do everything right,

242
00:14:36,072 --> 00:14:39,394
surely we should be avoiding this. I get this a lot from business owners.

243
00:14:39,522 --> 00:14:43,334
Look, I've spent a lot of money on really great engineering talent and

244
00:14:43,372 --> 00:14:46,440
you're telling me this we're still going to end up with that?

245
00:14:46,970 --> 00:14:51,286
Yes, you are. It's essential

246
00:14:51,398 --> 00:14:54,380
in what you're going to have. So why is that?

247
00:14:55,150 --> 00:14:59,178
This, this is my analogy for production. This is my preferred one.

248
00:14:59,264 --> 00:15:03,150
In the foreground is what you designed. You have a field,

249
00:15:03,220 --> 00:15:06,858
the bunnies could, you can imagine bunnies running around that field. You can imagine

250
00:15:06,874 --> 00:15:10,494
it being a calm, beautiful day. And the background there is

251
00:15:10,532 --> 00:15:13,614
your users. In the background

252
00:15:13,662 --> 00:15:17,502
is your cloud provider. In the background

253
00:15:17,566 --> 00:15:21,026
is your administrators. It's all

254
00:15:21,048 --> 00:15:24,434
of the factors that can be surprising in your world.

255
00:15:24,472 --> 00:15:28,002
And I'm very careful with that word surprising because people use the word incident

256
00:15:28,066 --> 00:15:31,334
a lot. And incident is a dangerous word

257
00:15:31,452 --> 00:15:35,394
because it doesn't recognize the unpredictable natural occurrence

258
00:15:35,442 --> 00:15:39,642
that it can be. Let me talk about that briefly. Right. Has anyone here

259
00:15:39,696 --> 00:15:42,460
had that moment where a boss comes up to you and says, right,

260
00:15:42,990 --> 00:15:46,714
you are responsible for this incident? Why did this

261
00:15:46,752 --> 00:15:50,614
incident happen? Now if you're pretty professional,

262
00:15:50,662 --> 00:15:54,862
your reaction to that would be, I screwed up.

263
00:15:54,996 --> 00:15:59,054
We must have done something wrong. Okay, I must have an answer why this

264
00:15:59,092 --> 00:16:02,866
incident happened. Therefore I must be able to tell you what

265
00:16:02,888 --> 00:16:06,786
did we do wrong? Okay, don't use the word incident ever.

266
00:16:06,888 --> 00:16:09,410
It's gone from your minds.

267
00:16:10,150 --> 00:16:12,290
Use surprise.

268
00:16:15,370 --> 00:16:18,886
Imagine that boss turning around to you this next time going,

269
00:16:18,988 --> 00:16:21,000
why did that surprise happen?

270
00:16:22,650 --> 00:16:26,840
It's a surprise. They do happen.

271
00:16:27,210 --> 00:16:30,290
We could call it shit, but we're not allowed to. Sorry for the camera.

272
00:16:30,450 --> 00:16:34,810
Okay, so we call them surprises. Refer to these things as surprise because they're surprising.

273
00:16:36,190 --> 00:16:39,562
No one sits there and go, yeah, I knew that incident was going to happen.

274
00:16:39,696 --> 00:16:43,798
If they do, they're a sadist. Eject them from your team,

275
00:16:43,984 --> 00:16:47,466
okay? Or talk to them about it. So this is what production

276
00:16:47,498 --> 00:16:51,146
looks like. You've got turbulence in the background. That's your users, it's your admins,

277
00:16:51,178 --> 00:16:54,962
it's you, it's everyone involved in your system. And when I refer to system,

278
00:16:55,016 --> 00:16:58,302
I mean the whole sociotechnical system, I mean the people the practices,

279
00:16:58,366 --> 00:17:02,510
the processes, the infrastructure, the applications, the platforms,

280
00:17:02,590 --> 00:17:04,420
the whole merry mess.

281
00:17:05,510 --> 00:17:08,466
When you add all that up, I don't care if you're doing the simplest piece

282
00:17:08,488 --> 00:17:12,246
of software in the world. Well, maybe if you're doing hello world, you're probably okay.

283
00:17:12,428 --> 00:17:16,706
But if you're doing the simplest piece of production software that makes money, then you've

284
00:17:16,738 --> 00:17:19,894
probably got a complex world and turbulence is part

285
00:17:19,932 --> 00:17:22,982
of the game. And the beautiful thing about turbulence

286
00:17:23,126 --> 00:17:26,826
and the chaos that goes with it is you can't predict it. You have to

287
00:17:26,848 --> 00:17:29,100
react and get good at reacting to it.

288
00:17:29,870 --> 00:17:34,414
Okay, so I'm going to completely abuse Kinevin now to

289
00:17:34,452 --> 00:17:38,046
explain what sort of systems we're dealing with, just to make sure we all

290
00:17:38,148 --> 00:17:41,870
understand the problem, the challenge we're facing. Number one,

291
00:17:41,940 --> 00:17:45,394
you do not have an obvious system unless you are

292
00:17:45,432 --> 00:17:49,230
writing hello world for a living. And if you are fabulous,

293
00:17:49,310 --> 00:17:52,866
well done, keep doing it. Someone's paying you for that. You've got it

294
00:17:52,888 --> 00:17:56,210
right somehow. Your career path has been brilliant.

295
00:17:56,550 --> 00:18:00,086
Most of us don't get away with that. But it's really attractive to be

296
00:18:00,108 --> 00:18:03,334
down and obvious because it's best practices. I can turn around to you,

297
00:18:03,372 --> 00:18:06,520
just say, just do this and you'll be better.

298
00:18:07,050 --> 00:18:10,610
How wonderful is that? How many agile coaches

299
00:18:10,690 --> 00:18:13,658
have you had? Turn around and go, just do this, you'll be better. By the

300
00:18:13,664 --> 00:18:16,986
way, they shouldn't have the label agile coach at that point because they're not

301
00:18:17,008 --> 00:18:19,830
really helping you or coaching you. But set that aside,

302
00:18:19,990 --> 00:18:23,534
okay? We see that a lot in our industry. Just do this. It worked for

303
00:18:23,572 --> 00:18:27,134
me, therefore it will work for you. I don't need to know

304
00:18:27,172 --> 00:18:30,960
your context. Just do it. You'll be better.

305
00:18:31,490 --> 00:18:34,160
So few examples of that in our world,

306
00:18:34,610 --> 00:18:38,626
let alone in software. Okay, so forget that. Leave that behind.

307
00:18:38,728 --> 00:18:42,098
Maybe you'd be forgiven at a dinner party. To describe what you do for a

308
00:18:42,104 --> 00:18:45,950
living has complicated what do you do? I work on complicated

309
00:18:46,030 --> 00:18:50,374
stuff, software. And you watch their eyes begin to say,

310
00:18:50,412 --> 00:18:53,474
and they say, do you work on Netflix? No. Do you work at Apple?

311
00:18:53,522 --> 00:18:57,190
No. Or do you work on bank trading systems

312
00:18:58,730 --> 00:19:01,898
and you know they're gone. Right. And it's complicated what you do. You don't want

313
00:19:01,904 --> 00:19:05,942
to explain it. Dinner party applications are usually gross simplifications.

314
00:19:06,006 --> 00:19:09,898
So youre be forgiven for thinking you're there. And maybe good practices would be a

315
00:19:09,904 --> 00:19:13,146
good thing. Okay, you've got good practices. What a good practice

316
00:19:13,178 --> 00:19:16,974
is for me is something you can apply. You could try

317
00:19:17,012 --> 00:19:20,926
it and it will probably work. Experiment with

318
00:19:20,948 --> 00:19:23,726
it, play with it, see if it works for your world, it's got a bit

319
00:19:23,748 --> 00:19:27,300
of context sprinkled on like salt. Okay,

320
00:19:27,670 --> 00:19:31,086
bad news for you though. If you're building any sort of distributed

321
00:19:31,118 --> 00:19:34,866
system, and frankly you are, this is one of the few things I don't need

322
00:19:34,888 --> 00:19:37,810
to see. You're running a production system. I don't care if it's a monolith,

323
00:19:37,890 --> 00:19:42,054
parts of it are distributed. Unless you're actually embedding the database into your

324
00:19:42,092 --> 00:19:45,286
code, which is relatively unlikely in production, but can

325
00:19:45,308 --> 00:19:48,502
be done, then you have a distributed system of some sort.

326
00:19:48,556 --> 00:19:52,570
And if you have any distribution that makes things more complex.

327
00:19:53,230 --> 00:19:56,330
If you've got external dependencies, well, if you're running on the cloud,

328
00:19:56,400 --> 00:19:59,958
you do. It's called the cloud. Everything there is an

329
00:19:59,984 --> 00:20:03,358
external dependency. Well done. You've increased your

330
00:20:03,444 --> 00:20:07,610
surface area for failure. God, I love Siri.

331
00:20:07,770 --> 00:20:10,430
You've increased the surface area of failure.

332
00:20:11,010 --> 00:20:13,600
Okay, so you're in complex, probably,

333
00:20:13,970 --> 00:20:17,718
and that's okay. When you've got the sociotechnical system, all the people, the practices,

334
00:20:17,754 --> 00:20:21,570
the processes, the distribution, the external dependencies, you're in complex

335
00:20:22,230 --> 00:20:25,586
difficulty with complex. We've all seen it. When someone comes in and says,

336
00:20:25,608 --> 00:20:28,338
just do this to the system and it will be better. And it isn't,

337
00:20:28,514 --> 00:20:31,926
you know, that better has to emerge over time.

338
00:20:32,108 --> 00:20:35,762
You have to try something in there for probably an extended period

339
00:20:35,906 --> 00:20:39,210
to see if it really does have the impact you want. You have to apply

340
00:20:39,360 --> 00:20:42,300
such thought processes as systems thinking.

341
00:20:42,670 --> 00:20:45,866
It's a harder thing to work with and you know, you can't just

342
00:20:45,888 --> 00:20:48,220
go in and go tinker. It's better.

343
00:20:48,750 --> 00:20:52,940
You have to assess it over time, verify it over time.

344
00:20:53,330 --> 00:20:56,894
But I got bad news for you. You see, if we were just in

345
00:20:56,932 --> 00:21:00,286
complex, we could still logically rationalize about it.

346
00:21:00,308 --> 00:21:03,658
We could still look at it and go with enough time. We could look

347
00:21:03,684 --> 00:21:07,554
at all the different pathways through it and prove it works under quite

348
00:21:07,592 --> 00:21:11,134
a lot, if not all, conditions. The difficulty

349
00:21:11,182 --> 00:21:13,650
we have is that usually if you're agile,

350
00:21:14,470 --> 00:21:17,060
you have a system that should be evolving quickly,

351
00:21:17,430 --> 00:21:20,946
frequently changing. Not those people I mentioned earlier who do continuous delivery

352
00:21:20,978 --> 00:21:24,546
once a year. Youre usually are delivering

353
00:21:24,578 --> 00:21:27,846
more frequently than that, which means your system is changing more frequently than

354
00:21:27,868 --> 00:21:31,466
that. And again, when I say system, I don't just mean the software or

355
00:21:31,488 --> 00:21:35,046
the technical aspects, I mean the people, the practices and processes that surround

356
00:21:35,078 --> 00:21:38,586
it. All of that is changing frequently or can

357
00:21:38,608 --> 00:21:42,218
be changing frequently. And when you've got that,

358
00:21:42,304 --> 00:21:46,206
you are in chaos where the smallest change can have

359
00:21:46,228 --> 00:21:49,678
a big impact. And even then you may not be able to assess all

360
00:21:49,764 --> 00:21:52,080
of the impacts a change might have.

361
00:21:52,850 --> 00:21:56,514
So with that level of complexity and chaosiq present in your

362
00:21:56,552 --> 00:22:00,254
world, and I can almost guarantee if you're running production systems,

363
00:22:00,302 --> 00:22:03,522
you have this, because if you have incidents, sorry,

364
00:22:03,576 --> 00:22:06,866
surprises. If you have those, then you're

365
00:22:06,898 --> 00:22:10,710
seeing the outcomes of it. Okay.

366
00:22:10,780 --> 00:22:14,130
The difficulty here in chaos is that novel

367
00:22:14,210 --> 00:22:17,462
changes. You can do something and be surprised by how much better it is,

368
00:22:17,516 --> 00:22:21,002
or worse, you can make that small, simple change to how people

369
00:22:21,056 --> 00:22:24,614
operate and suddenly see a massive and dramatic impact on everything you've

370
00:22:24,662 --> 00:22:28,026
done. So it's a difficult place to

371
00:22:28,048 --> 00:22:31,118
be. So wouldn't it be great, right? Wouldn't it be great if we had a

372
00:22:31,124 --> 00:22:34,270
way of engineering ourselves out of chaosiq?

373
00:22:34,770 --> 00:22:37,886
Wouldn't it be great? Although we shouldn't call

374
00:22:37,908 --> 00:22:40,574
it chaos engineering because that sounds like we're creating it,

375
00:22:40,612 --> 00:22:44,830
right? So chaos engineering is engineering ourselves

376
00:22:44,910 --> 00:22:47,490
out of chaos through practice.

377
00:22:48,470 --> 00:22:51,842
So let's talk about that. It's about

378
00:22:51,896 --> 00:22:55,282
learning chaos engineering doesn't exist, shouldn't exist unless you

379
00:22:55,336 --> 00:22:58,726
emphasize the need to learn. We're doing these

380
00:22:58,748 --> 00:23:01,430
things for reasons. Actually,

381
00:23:01,500 --> 00:23:04,870
recently, I've started to call chaos engineering by a slightly different

382
00:23:04,940 --> 00:23:07,910
name. I've started to call it system verification.

383
00:23:08,490 --> 00:23:11,874
I want to verify how my system reacts

384
00:23:11,922 --> 00:23:14,620
to certain conditions because I don't know yet,

385
00:23:15,150 --> 00:23:17,546
and I want some proof of it, and I want to be able to turn

386
00:23:17,568 --> 00:23:20,694
that into actions where I might be able to experiment with improvements

387
00:23:20,742 --> 00:23:24,506
on my world. So it's a learning loop. It's a double loop learning loop

388
00:23:24,538 --> 00:23:27,120
because you're actually assessing your assumptions to begin with.

389
00:23:28,130 --> 00:23:31,498
And this is my favorite. Youre got to watch good. Anyone here watch good omens?

390
00:23:31,674 --> 00:23:34,894
Yes, absolutely. Everyone should watch it. It's brilliant. But, yeah,

391
00:23:34,932 --> 00:23:38,274
the idea here, it's the old idea with chaos that the smallest change can cause

392
00:23:38,312 --> 00:23:42,306
the most dramatic and surprising impacts. It's the stuff we deal

393
00:23:42,328 --> 00:23:45,602
with, and it's in our systems all the time. Okay, you are working,

394
00:23:45,656 --> 00:23:49,794
if you want a technical phrase, youre working with nonlinear dynamic systems.

395
00:23:49,842 --> 00:23:52,230
That's the sort of stuff that gets you a PhD.

396
00:23:53,290 --> 00:23:56,326
So it's useful to have that in mind, because if you say we're dealing with

397
00:23:56,348 --> 00:23:59,674
a chaotic system, most people look at it and go, it's not really.

398
00:23:59,872 --> 00:24:03,530
But if you say it's got properties of being nonlinear and dynamic,

399
00:24:04,190 --> 00:24:07,926
then that makes more sense. Yes, it does. Pretty much inarguable

400
00:24:07,958 --> 00:24:11,274
in most systems. The only systems I know of that are not,

401
00:24:11,392 --> 00:24:14,858
don't follow these sort of properties and are making people money tend to be systems

402
00:24:14,874 --> 00:24:18,078
that are no longer changing at all. They're very few,

403
00:24:18,164 --> 00:24:21,726
and they're usually being retired rather quickly. But even when you're retiring a

404
00:24:21,748 --> 00:24:24,500
system, you end up changing it. So that goes back here too.

405
00:24:24,950 --> 00:24:28,386
Okay. And as engineers, one of the things we

406
00:24:28,408 --> 00:24:31,794
love to know is that the system will work. We're not here to create

407
00:24:31,832 --> 00:24:35,090
systems that don't work. Usually, maybe,

408
00:24:35,160 --> 00:24:37,430
but that'd be an odd part of your degree.

409
00:24:38,890 --> 00:24:42,614
And it's the same with physicists. We like to think under

410
00:24:42,652 --> 00:24:46,194
these conditions we know what's going to happen next. But if you have a nonlinear,

411
00:24:46,242 --> 00:24:49,914
dynamic system, you don't know what's going to happen next.

412
00:24:50,112 --> 00:24:54,026
You cannot predict its behavior in a

413
00:24:54,048 --> 00:24:57,494
variety of conditions. You have to apply the conditions

414
00:24:57,542 --> 00:24:59,500
to see what happens.

415
00:25:02,510 --> 00:25:05,994
So, incidents of surprises. Let's go back to the theme

416
00:25:06,042 --> 00:25:09,806
being wrong. Now, it's obviously a bit tongue in cheek, because no one trains to

417
00:25:09,828 --> 00:25:12,480
be wrong, do they? Interestingly enough,

418
00:25:12,790 --> 00:25:16,226
I do a short module at Oxford University on

419
00:25:16,248 --> 00:25:20,110
this, and I call it the how to be wrong. As a software developers

420
00:25:20,270 --> 00:25:25,186
course, very few people come on it and

421
00:25:25,208 --> 00:25:28,514
I try not to depress them in 10 seconds. But I essentially say everything

422
00:25:28,552 --> 00:25:31,466
you know, everything you've been taught, you're going to hit the real world, it's going

423
00:25:31,468 --> 00:25:34,726
to be wrong. You're going to find it's very different when you get out

424
00:25:34,748 --> 00:25:38,294
there and things are icky, things will not work, people will not

425
00:25:38,332 --> 00:25:41,466
listen. Doesn't matter how many times you turn around and say, this is a good

426
00:25:41,488 --> 00:25:44,682
way of doing this, they won't listen. I still

427
00:25:44,736 --> 00:25:47,900
have to now tell people to do TDD. I don't know why,

428
00:25:48,270 --> 00:25:51,530
and sometimes I lose the will to live, but this is the way

429
00:25:51,600 --> 00:25:55,002
the real world is now, I in that module,

430
00:25:55,066 --> 00:25:57,726
when I proposed it to Oxford, I said, I'm going to teach people how to

431
00:25:57,748 --> 00:26:01,546
be wrong. I has looked at like I was a madman.

432
00:26:01,738 --> 00:26:05,454
Maybe I am, but I thought it was a great skill.

433
00:26:05,582 --> 00:26:09,490
To me, it's a superpower. I am regularly wrong.

434
00:26:09,640 --> 00:26:13,522
At university, I was supposed to never be wrong. You're rewarded for being

435
00:26:13,576 --> 00:26:17,426
right all the time. I teach people how

436
00:26:17,448 --> 00:26:21,510
to be wrong for a living and so let's talk about that.

437
00:26:21,660 --> 00:26:24,726
So what is it to be wrong and why are we scared of

438
00:26:24,748 --> 00:26:28,422
it? If you look at the dictionary definitions, it's about not being

439
00:26:28,476 --> 00:26:31,320
correct or true. Already I'm not liking it.

440
00:26:31,870 --> 00:26:35,386
You're being incorrect. Most the students on my course, they sit

441
00:26:35,408 --> 00:26:38,042
there and go, this is horrible. Now I don't want it. This is like a

442
00:26:38,096 --> 00:26:41,200
cross versus a tick, okay?

443
00:26:42,210 --> 00:26:45,550
Gets worse. It could be injurious, unfair or unjust.

444
00:26:46,130 --> 00:26:49,870
Now borderline. You're being very naughty.

445
00:26:50,290 --> 00:26:54,026
Okay, go one step further. Inflicting harm

446
00:26:54,058 --> 00:26:57,742
without due provocation or just cause. Now you're hurting

447
00:26:57,806 --> 00:27:01,294
somebody. This is what being wrong means to us in the english

448
00:27:01,342 --> 00:27:04,786
language. And it gets one step worse because now the last

449
00:27:04,808 --> 00:27:08,258
one is a violation or invasion of legal rights of another. Now you're

450
00:27:08,274 --> 00:27:11,634
going to jail for it. So we've really packaged

451
00:27:11,682 --> 00:27:15,080
being wrong as a terrible, terrible, terrible, terrible thing,

452
00:27:15,690 --> 00:27:19,240
and yet it's a superpower. So let me explain why that is.

453
00:27:20,090 --> 00:27:23,254
First of all, when are we ever wrong, right? I told you, you're all geniuses.

454
00:27:23,302 --> 00:27:26,986
Youre all here early doors for a chaos engineering day.

455
00:27:27,008 --> 00:27:31,174
So clearly you're passionate about what you do for a living, and therefore

456
00:27:31,222 --> 00:27:33,120
you're never wrong, ever.

457
00:27:35,570 --> 00:27:38,906
It's a state of being mistaken or incorrect. So we know how it relates

458
00:27:38,938 --> 00:27:42,526
back to the word wrong. And I've got some really bad news for you.

459
00:27:42,548 --> 00:27:45,540
Dr. Russ has got some bad news for you.

460
00:27:46,230 --> 00:27:49,460
Everyone is wrong all the time.

461
00:27:50,310 --> 00:27:53,586
All the time. Every system but is wrong. But I

462
00:27:53,608 --> 00:27:56,622
used to tell people has a developer, I want you to have a mantra.

463
00:27:56,766 --> 00:27:59,798
I want you to have this in your head at all times. We don't know

464
00:27:59,804 --> 00:28:03,320
what we're doing. They don't know what they want,

465
00:28:03,850 --> 00:28:07,542
and that's normal. If youre could just have that rather than

466
00:28:07,596 --> 00:28:11,090
I know exactly what I'm building today, then you might

467
00:28:11,180 --> 00:28:15,494
build things a little differently and you'll certainly embrace production slightly differently.

468
00:28:15,542 --> 00:28:18,954
And that's what I want you to do. It's a mindset switch to be working

469
00:28:18,992 --> 00:28:23,100
in chaos engineering, and it starts with recognizing we're always wrong.

470
00:28:24,510 --> 00:28:27,646
Okay, don't take my word for it. Just go out there and

471
00:28:27,668 --> 00:28:30,522
look for incidents. Yeah, you have to search for incidents. If you search for surprises

472
00:28:30,586 --> 00:28:34,186
online, you get different answers. But if you search for incidents,

473
00:28:34,218 --> 00:28:37,506
you might find them and you find a whole plethora of different things out

474
00:28:37,528 --> 00:28:40,866
there. Some great incident reports, some of them are terrible. Some of them

475
00:28:40,888 --> 00:28:44,114
read like, we knew what was happening. We knew

476
00:28:44,152 --> 00:28:47,398
exactly how this was going to go from the moment it happened.

477
00:28:47,564 --> 00:28:51,206
Those are called lies. They're not called incident reports. The best ones

478
00:28:51,228 --> 00:28:55,094
are the ones that involve some sort of swearing and

479
00:28:55,132 --> 00:28:59,170
a window on the people involved, the incredibly

480
00:28:59,250 --> 00:29:02,822
complex cognitive processes that go around, oh, my goodness,

481
00:29:02,886 --> 00:29:06,620
something's happened and we didn't see that coming. Those are the ones to look for.

482
00:29:07,630 --> 00:29:10,938
Okay, but why is wrong scary? If we know it happens all the

483
00:29:10,944 --> 00:29:13,854
time and we're going to be wrong, we are always wrong. That's why we have

484
00:29:13,892 --> 00:29:17,214
agile agility is about being able to

485
00:29:17,252 --> 00:29:20,718
adjust. Why would you need to adjust? Because you're not going

486
00:29:20,724 --> 00:29:24,014
to go straight to the answer straight away. So why

487
00:29:24,052 --> 00:29:27,818
is wrong scary? Okay, risk, maybe it's risk.

488
00:29:27,914 --> 00:29:31,570
We feel at risk. Risk is a terrible term, though. I mean, most people understand

489
00:29:31,640 --> 00:29:34,626
risk to a certain degree, but risk has got a whole lot of baggage with

490
00:29:34,648 --> 00:29:37,570
it. What we really care about is consequences.

491
00:29:37,990 --> 00:29:41,174
When someone says you're worried about the risk, youre actually saying, well, yeah, that sounds

492
00:29:41,212 --> 00:29:44,866
like a nice phrase of I don't want to go to prison. Yeah, I'm worried

493
00:29:44,898 --> 00:29:49,162
about consequences for things I've done. And that's fair because

494
00:29:49,216 --> 00:29:51,740
wrong is attached to consequences. We believe,

495
00:29:52,750 --> 00:29:56,122
okay, and why are we so susceptible to it?

496
00:29:56,256 --> 00:29:59,100
Two factors. You want to move quick.

497
00:30:00,190 --> 00:30:02,474
Most of the companies I go to, I say, do you want to deliver things

498
00:30:02,512 --> 00:30:06,334
faster? They say, yes, most of them, some don't. I have one

499
00:30:06,372 --> 00:30:09,546
that said, no, we don't want to at all. That's a story for a conversation

500
00:30:09,578 --> 00:30:13,226
over coffee later. But most of us want to move quickly, want feature velocity,

501
00:30:13,258 --> 00:30:16,382
and we also want reliability because feature velocity without

502
00:30:16,436 --> 00:30:19,698
reliability is nothing. I don't

503
00:30:19,704 --> 00:30:22,514
know how quickly you can ship a product and say, look at this amazing thing,

504
00:30:22,552 --> 00:30:24,946
and if it doesn't ever work for them, do you reckon you've got customers?

505
00:30:25,048 --> 00:30:28,280
No, they always want both and that's fair.

506
00:30:29,370 --> 00:30:33,510
Okay. And we think there's a conflict relationship. I've lost

507
00:30:34,010 --> 00:30:37,394
count of the number of times I've heard we don't have time to do

508
00:30:37,452 --> 00:30:40,490
testing. We're working on features.

509
00:30:40,990 --> 00:30:44,166
What? Really? How do you know you've

510
00:30:44,198 --> 00:30:47,526
got any? Oh, well, no one's complained

511
00:30:47,558 --> 00:30:51,034
yet. Actually, I heard that once for someone telling me how they knew a system

512
00:30:51,072 --> 00:30:54,158
was working. I said, how do you know your system is working right now?

513
00:30:54,324 --> 00:30:57,200
And they said, our customers are not calling us.

514
00:30:57,730 --> 00:31:00,654
I thought, what an impressive metric that is.

515
00:31:00,772 --> 00:31:04,000
It's a real one, unless the phone systems are down.

516
00:31:05,410 --> 00:31:08,818
But equally, don't you think you'd be a bit more proactive about this?

517
00:31:08,984 --> 00:31:11,986
But anyway, we end up thinking these two things are in conflict now. It's a

518
00:31:12,008 --> 00:31:15,346
great body of work out there now on this that proves this is not the

519
00:31:15,368 --> 00:31:19,346
case. The good news is that there is no, absolutely no conflict

520
00:31:19,378 --> 00:31:22,438
between these two factors. The faster you move,

521
00:31:22,604 --> 00:31:25,560
the more reliable you can be.

522
00:31:26,490 --> 00:31:29,782
In fact, the people that move the fastest are the ones that are also paying

523
00:31:29,836 --> 00:31:33,562
down the reliability as they go. So this is,

524
00:31:33,616 --> 00:31:36,860
don't take my word for it. Go and read a book called accelerate, please.

525
00:31:37,390 --> 00:31:40,778
Read it. If you haven't read it already. It's not really a bedtime book.

526
00:31:40,944 --> 00:31:44,350
It's a scientific book. A lot of data, a lot of graphs.

527
00:31:46,210 --> 00:31:49,706
Yes. So it depends. If you have trouble falling asleep, then it's

528
00:31:49,738 --> 00:31:53,338
perfect. But no. Generally speaking, if you wanted an exciting

529
00:31:53,434 --> 00:31:56,398
change of mind sort of thing before you go to bed, I won't recommend a

530
00:31:56,404 --> 00:31:59,634
novel, but this is pretty good. You can always read Jim Kin's novels, of course,

531
00:31:59,672 --> 00:32:03,170
the Unicorn project. That might send you to sleep as well, but with better dreams.

532
00:32:03,670 --> 00:32:06,754
Okay, so it's actually the two things

533
00:32:06,792 --> 00:32:10,034
working in tandem. And these are some of the charts that come from accelerate.

534
00:32:10,082 --> 00:32:13,734
I won't go over them in too much detail, but the point here

535
00:32:13,772 --> 00:32:17,490
to make is that the faster you go. Let's look at one that really matters.

536
00:32:17,650 --> 00:32:20,966
Yeah. The change failure rate. That one there. Okay. The faster

537
00:32:20,998 --> 00:32:23,900
you go, which is the high performers, which is down the bottom.

538
00:32:26,270 --> 00:32:29,546
The fact that they put less failures into production as

539
00:32:29,568 --> 00:32:32,542
they go. So they've already got less to deal with than anybody else.

540
00:32:32,596 --> 00:32:35,360
They'll move quicker. Okay,

541
00:32:36,370 --> 00:32:39,902
so it's not versus. It's plus. Let's go through.

542
00:32:40,036 --> 00:32:43,086
Okay, but I hear this a lot. But we're doing microservices. We've just invested in

543
00:32:43,108 --> 00:32:46,514
microservices. And you could change services to anything you like. You could change it to.

544
00:32:46,552 --> 00:32:48,786
But we're doing agile now, or the, one of the ones I love at the

545
00:32:48,808 --> 00:32:51,540
moment. But we're digitally transformed now.

546
00:32:52,310 --> 00:32:55,622
What does that even mean? We've transformed things

547
00:32:55,676 --> 00:32:57,960
digitally. Yeah. Right. Okay.

548
00:32:58,810 --> 00:33:02,130
But we're doing that. So we've got tests, gates,

549
00:33:02,210 --> 00:33:05,926
pipelines, isolation. Oh, my. We've got the

550
00:33:05,948 --> 00:33:10,410
lot. We are absolutely covered.

551
00:33:10,750 --> 00:33:13,798
I've had this meeting, board level meetings

552
00:33:13,974 --> 00:33:17,210
in banks. You'd think they knew, but chaos.

553
00:33:17,790 --> 00:33:21,754
But no, we're covered. Believe me. We are doing everything.

554
00:33:21,952 --> 00:33:25,822
And I'm sitting there going, you could still do everything and it will still have

555
00:33:25,956 --> 00:33:29,418
failures. I actually asked a room full of bankers. I don't

556
00:33:29,434 --> 00:33:33,226
know what that collective noun is. A room full of bankers.

557
00:33:33,258 --> 00:33:36,622
I asked them, how many here have had a systems failure

558
00:33:36,686 --> 00:33:40,290
in the last two months? Almost all the hands went up. Okay,

559
00:33:40,360 --> 00:33:43,762
so we agree it happens. Then I asked, okay,

560
00:33:43,816 --> 00:33:46,834
who here has got a disaster recovery program

561
00:33:47,032 --> 00:33:50,278
that they've exercised in the last month? And a

562
00:33:50,284 --> 00:33:53,526
lot of hands went up and said, yes, absolutely. And I said, how many of

563
00:33:53,548 --> 00:33:57,174
you did it on purpose? Most of the hands went

564
00:33:57,212 --> 00:34:00,918
down. So all of those disaster recovery plans

565
00:34:00,934 --> 00:34:04,282
are not exercised apart from in the moment when you don't want to exercise something

566
00:34:04,336 --> 00:34:06,970
new. The moment when you're surprised?

567
00:34:09,070 --> 00:34:13,198
That's like getting on a plane and then saying, look, in the event of a

568
00:34:13,204 --> 00:34:16,000
crash or something, wing it.

569
00:34:16,610 --> 00:34:19,806
You know where the windows are, right? Get out. Or something like

570
00:34:19,828 --> 00:34:22,480
that. It's just help yourself and hope.

571
00:34:22,930 --> 00:34:26,174
Okay? There's a strong relationship between disasters,

572
00:34:26,222 --> 00:34:29,170
incidents, surprises, and chaosiq for engineering.

573
00:34:30,390 --> 00:34:33,586
Okay, so here's a quick story for you, and I hope

574
00:34:33,608 --> 00:34:37,078
this isn't a story you've heard many, many times before. Does anyone know who

575
00:34:37,084 --> 00:34:40,870
that is? Margaret Hamilton.

576
00:34:41,610 --> 00:34:45,238
This is her featured in Wired not long ago. She has a

577
00:34:45,244 --> 00:34:47,798
great story, the beginning of the SRE book. There's a great story right in the

578
00:34:47,804 --> 00:34:50,210
preface, which no one reads, by the way. When I wrote one of my books,

579
00:34:50,290 --> 00:34:53,500
I put in the preface, it was a book on Uml. Don't judge me.

580
00:34:54,990 --> 00:34:57,642
Everyone does things in their youth, right?

581
00:34:57,776 --> 00:35:01,110
I wrote a book on UmL. In the preface, I said, uml is for sketching.

582
00:35:01,190 --> 00:35:04,510
No one reads that. I still get emails from people saying,

583
00:35:04,580 --> 00:35:07,726
I can't make rational rows. Whatever it is. Do the

584
00:35:07,748 --> 00:35:11,098
diagram you're showing me. I'm like, that's okay, because it's

585
00:35:11,114 --> 00:35:13,680
a tool that's not great at that.

586
00:35:14,450 --> 00:35:17,358
So, yeah, people don't read prefaces, but there's a great thing in this preface of

587
00:35:17,364 --> 00:35:19,778
the SRE book where it talks about Margaret. And that's the story I'm going to

588
00:35:19,784 --> 00:35:23,218
share with you now, the story here is quite straightforward. I'm going to paraphrase quite

589
00:35:23,224 --> 00:35:26,120
a bit of it. So Margaret worked as the lead,

590
00:35:26,570 --> 00:35:30,870
essentially, on the system software for the Apollo spacecraft.

591
00:35:31,210 --> 00:35:34,866
Fabulous job. But this story isn't about her. She is not the world's

592
00:35:34,898 --> 00:35:38,534
first chaosiq engineer. The world's first chaos engineer was

593
00:35:38,572 --> 00:35:42,514
Lauren Hamilton. Lauren Hamilton used to get taken to work sometimes,

594
00:35:42,652 --> 00:35:46,314
and like any responsible parent, when youre kid's there and you're trying to work

595
00:35:46,352 --> 00:35:49,786
and I do this, now, what do you do? You get them there. You sit

596
00:35:49,808 --> 00:35:53,406
with them. You go, I've got to do some work now can

597
00:35:53,428 --> 00:35:57,054
you go away and not bother me? And that's what Margaret did. She gave

598
00:35:57,092 --> 00:36:00,234
Lauren a toy to play with the Apollo mission

599
00:36:00,282 --> 00:36:03,280
simulator. What a lucky kid.

600
00:36:04,130 --> 00:36:07,598
She had no idea how lucky she was. Okay, so she's playing

601
00:36:07,614 --> 00:36:10,270
with this thing, and she does what any kid does with a new toy.

602
00:36:10,350 --> 00:36:13,998
She breaks it. Breaks it almost immediately,

603
00:36:14,174 --> 00:36:17,558
she finds a key combo, manages to flush the mission navigation information

604
00:36:17,644 --> 00:36:20,710
out of it, and Margaret does

605
00:36:20,780 --> 00:36:24,262
what anyone would do when a chaosiq engineer has done that, says,

606
00:36:24,316 --> 00:36:28,306
okay, we should learn from this. She goes to NASA, bigwigs NASA

607
00:36:28,338 --> 00:36:31,722
bigwigs turn around and say what every manager says. When you say,

608
00:36:31,776 --> 00:36:34,698
we found potentially a flaw in the system, maybe some technical debt, we want to

609
00:36:34,704 --> 00:36:37,930
pay it down, what do they say? That'll never

610
00:36:38,000 --> 00:36:41,574
happen. I'm glad you found that. That's fine.

611
00:36:41,632 --> 00:36:45,280
But in their words, they said, our astronauts are made of the right stuff.

612
00:36:45,730 --> 00:36:48,766
They've been trained for months, sometimes years,

613
00:36:48,948 --> 00:36:52,950
to be perfect. They will never cause this failure.

614
00:36:53,130 --> 00:36:57,010
Just because your daughter has created it and found it

615
00:36:57,160 --> 00:37:00,482
surfaced, it doesn't mean it'll ever happen,

616
00:37:00,536 --> 00:37:04,850
because we have. We are perfect. The very next mission,

617
00:37:05,350 --> 00:37:08,806
Murphy's law comes into effect. Murphy's law is a law of

618
00:37:08,828 --> 00:37:12,198
software development and delivery. Don't ever kid yourselves. It's not

619
00:37:12,204 --> 00:37:15,270
just a law of life. It's firmly embedded in our psyche.

620
00:37:15,690 --> 00:37:19,266
So Murphy's law kicked into action, and this picture

621
00:37:19,298 --> 00:37:22,746
would never have happened. Although technically, I suppose it could have happened. But as the

622
00:37:22,768 --> 00:37:26,586
spacecraft shot past the moon, maybe because those

623
00:37:26,688 --> 00:37:30,554
well trained, right staffed astronauts on not

624
00:37:30,592 --> 00:37:34,086
long after takeoff, hit exactly that key combo

625
00:37:34,198 --> 00:37:37,614
and managed to flush the information out system. Fortunately, there was

626
00:37:37,652 --> 00:37:41,166
a backup strategy because Margaret had learned from the situation,

627
00:37:41,268 --> 00:37:44,550
she'd put something in place. She hadn't completely ignored the big wigs,

628
00:37:44,570 --> 00:37:48,562
but she also had a compensating strategy in there

629
00:37:48,616 --> 00:37:51,998
for it. So the world's first chaos engineer,

630
00:37:52,094 --> 00:37:55,678
at least I think it is, is Lauren Hamilton, the world's

631
00:37:55,694 --> 00:37:58,658
first resilience engineer? Perhaps not the first.

632
00:37:58,744 --> 00:38:01,240
Is Mahgret in this story at least.

633
00:38:02,650 --> 00:38:06,050
Okay, but it gets worse for us because youre

634
00:38:06,130 --> 00:38:09,574
be forgiven for thinking you don't work on spacecraft. Anyone here

635
00:38:09,612 --> 00:38:13,046
do? Oh, damn it. Okay. I've got a friend who

636
00:38:13,068 --> 00:38:14,858
used to work on spacecraft, and I used to love that. I used to be

637
00:38:14,864 --> 00:38:17,660
able to say, no one works on spacecraft. And you go, actually,

638
00:38:18,110 --> 00:38:21,626
fair enough. But it gets worse for us because actually, our systems

639
00:38:21,658 --> 00:38:25,290
are vastly more complex than a spacecraft,

640
00:38:25,450 --> 00:38:29,034
bizarrely enough. And we have, because of that complexity,

641
00:38:29,082 --> 00:38:32,990
something present. And I love the phrase dark debt.

642
00:38:35,970 --> 00:38:38,658
The first time I used this phrase was on Halloween, and I can't tell you

643
00:38:38,664 --> 00:38:42,306
how much fun I have with it. So dark debt is different than

644
00:38:42,328 --> 00:38:44,882
technical debt. Technical debt is something, you know,

645
00:38:44,936 --> 00:38:48,590
youre accruing usually. Okay, you can recognize it

646
00:38:48,600 --> 00:38:52,402
and go, yeah, we knew we were doing that. We knew it has a shortcut.

647
00:38:52,546 --> 00:38:56,482
That's technical debt. If you find that you've made a mistake, that's called surprise

648
00:38:56,546 --> 00:38:59,730
debt. And that also is a factor. You can

649
00:38:59,740 --> 00:39:02,538
then call it technical debt when you've recognized it. But generally speaking,

650
00:39:02,624 --> 00:39:05,020
technical debt is something you plan to do.

651
00:39:05,790 --> 00:39:09,754
Dark debt is the evil, evil, evil cousin of

652
00:39:09,792 --> 00:39:12,942
technical debt, because dark debt is there. No matter

653
00:39:12,996 --> 00:39:16,462
what you do, no matter how right you think you are,

654
00:39:16,596 --> 00:39:19,390
it's in that system lurking,

655
00:39:20,210 --> 00:39:23,278
and you don't see it. It's the unknown.

656
00:39:23,374 --> 00:39:26,146
Unknowns. Okay,

657
00:39:26,328 --> 00:39:29,300
so I got asked once, at this point in the talk,

658
00:39:29,830 --> 00:39:32,900
how do I measure how much dark debt there is in my system?

659
00:39:34,810 --> 00:39:39,190
Right. Let me explain again. It's unknown.

660
00:39:40,010 --> 00:39:44,038
Unknown. It's not like dark matter

661
00:39:44,124 --> 00:39:47,698
or dark energy that could be measured by the fact we don't know why the

662
00:39:47,724 --> 00:39:51,526
measurements don't work. And so we can estimate there's an error and say there's

663
00:39:51,558 --> 00:39:54,970
something there. No, dark debt is

664
00:39:55,040 --> 00:39:59,046
completely unknown. It's completely building. It's camouflaged.

665
00:39:59,078 --> 00:40:02,974
It looks like working software so

666
00:40:03,012 --> 00:40:06,894
you can't measure it, but it's there. And there's enough

667
00:40:06,932 --> 00:40:10,160
people that have done enough papers now to prove it's there.

668
00:40:11,010 --> 00:40:14,218
Okay. Those sort of people are John Osborne.

669
00:40:14,394 --> 00:40:16,306
Aaron was going to be here today, so I was going to point out that

670
00:40:16,328 --> 00:40:19,966
Aaron got in early and liked that particular tweet, but unfortunately,

671
00:40:19,998 --> 00:40:23,346
he couldn't make it today. So there's a whole group of

672
00:40:23,368 --> 00:40:27,086
people that have found what this manifestation looks like. And it's the surprising

673
00:40:27,118 --> 00:40:30,866
stuff. The bad news is you can't design it out because you don't know you're

674
00:40:30,898 --> 00:40:34,742
designing it in. You can't sit there in a design

675
00:40:34,796 --> 00:40:37,734
review meeting and go, aha, youre doing that wrong.

676
00:40:37,772 --> 00:40:41,402
I see some dark debt. That's not how it works. You can do

677
00:40:41,456 --> 00:40:45,260
what you think is absolutely everything, right? And you will still be wrong.

678
00:40:45,950 --> 00:40:49,180
So get used to it. We have a plan for that.

679
00:40:50,030 --> 00:40:53,558
And over to the business in this regard. This is why they

680
00:40:53,584 --> 00:40:58,222
care. 1 hour of downtime costs about $100,000 for 95%

681
00:40:58,276 --> 00:41:01,646
of enterprise systems. Not even the jazzy stuff. This isn't your

682
00:41:01,668 --> 00:41:04,474
Netflix. This isn't your Disney pluses or anything like that.

683
00:41:04,612 --> 00:41:09,106
This is your Jira going down. This is your

684
00:41:09,128 --> 00:41:12,770
email systems going down. This is your back office systems going down. This is nothing

685
00:41:12,840 --> 00:41:16,614
sexy. This is how much it costs to a business if

686
00:41:16,652 --> 00:41:19,510
things go down. And they don't like that, understandably.

687
00:41:22,010 --> 00:41:25,554
And that's just in lost revenue and end user productivity.

688
00:41:25,682 --> 00:41:29,254
It's got nothing to do with being sued. That's on top of

689
00:41:29,292 --> 00:41:32,778
that. So there you go. That's what threatens the business,

690
00:41:32,944 --> 00:41:35,450
is this feeling that there's a lot of risk.

691
00:41:35,790 --> 00:41:39,194
And you've just told me there's dark debt, which is

692
00:41:39,232 --> 00:41:43,134
more risk. And you've told me you actually can't see

693
00:41:43,172 --> 00:41:46,750
it till it happens. Okay,

694
00:41:46,820 --> 00:41:50,830
so the bad news is, forget Donald Trump. You're not covered.

695
00:41:51,250 --> 00:41:54,880
We're not covered. You can't be covered for this,

696
00:41:55,670 --> 00:42:00,114
but you can be better at dealing with it because

697
00:42:00,152 --> 00:42:03,694
these systems tend to look like, even if you try and fully describe your systems,

698
00:42:03,742 --> 00:42:07,558
there's lots of moving parts, there's lots of details. Rate of change is high.

699
00:42:07,644 --> 00:42:11,266
Components, functions can change. This is just reinforcing

700
00:42:11,378 --> 00:42:15,430
the fact that what you've got is hard to rationalize about.

701
00:42:15,580 --> 00:42:19,430
Okay. Reactions to this risk avoidance.

702
00:42:20,090 --> 00:42:23,242
Well, okay, we were going to do a cloud native transformation, but actually

703
00:42:23,376 --> 00:42:27,002
now we're going to go back to the mainframe. Bad news,

704
00:42:27,136 --> 00:42:30,860
mainframes are full of dark debt. They are.

705
00:42:31,550 --> 00:42:35,034
They wouldn't break if they didn't. So that's all there,

706
00:42:35,072 --> 00:42:39,458
too. Doesn't matter what technologies youre use. Don't get mistaken

707
00:42:39,494 --> 00:42:42,974
into thinking that this is just for the new stuff. This is

708
00:42:43,012 --> 00:42:46,260
there. In any sufficiently complex or chaotic system,

709
00:42:47,750 --> 00:42:51,346
blame is another beautiful one. Right? So I

710
00:42:51,368 --> 00:42:53,826
was on stage a couple of years ago now, and I love this story because

711
00:42:53,928 --> 00:42:57,378
this is really cool. I asked the entire room, and I

712
00:42:57,384 --> 00:43:01,366
won't ask you now because it's an intimate question, but I asked,

713
00:43:01,388 --> 00:43:04,566
who here would like to share a post mortem? Who here would like

714
00:43:04,588 --> 00:43:08,342
to share an incident they were part of? And this

715
00:43:08,396 --> 00:43:12,330
person, it was like I had offered a glass of water to someone

716
00:43:12,400 --> 00:43:16,490
wandering across the sahara. They wanted to confess.

717
00:43:16,910 --> 00:43:20,506
He shot his hand up. He then shot up himself. He can to the

718
00:43:20,528 --> 00:43:23,100
stage. Now, I'm a very short individual,

719
00:43:24,590 --> 00:43:28,334
and this has, in Norway, where there are not many short

720
00:43:28,372 --> 00:43:31,626
individuals, he ran to the stage, and the stage

721
00:43:31,658 --> 00:43:34,626
was about five foot off the ground. So I'm looking down,

722
00:43:34,648 --> 00:43:39,010
thinking I could die. And he leapt onto the stage,

723
00:43:40,310 --> 00:43:43,506
and he's up there, so I'm not going to get in the way.

724
00:43:43,688 --> 00:43:47,186
I step right back and I go after youre. And he turns

725
00:43:47,218 --> 00:43:50,758
around to the entire room, about 300 people, and says, it was

726
00:43:50,924 --> 00:43:51,640
me.

727
00:43:55,530 --> 00:43:59,146
At that moment, you ask youre, what could

728
00:43:59,168 --> 00:44:03,420
possibly go wrong next? Do his colleagues know?

729
00:44:04,110 --> 00:44:07,594
Has he just done it? Is he going to get

730
00:44:07,632 --> 00:44:11,066
arrested? Is he going to be sued? What's going to

731
00:44:11,088 --> 00:44:15,150
happen now? And anyway, fortunately, his colleagues started laughing,

732
00:44:15,490 --> 00:44:19,006
so I hope they knew. Anyway, he turned around to say, it was

733
00:44:19,028 --> 00:44:23,034
me. I destroyed the master node of a grid computing cluster

734
00:44:23,162 --> 00:44:27,150
and lost about three weeks of processing and research work for a university.

735
00:44:27,310 --> 00:44:30,722
I did it. It was me. Okay,

736
00:44:30,856 --> 00:44:34,322
step back from that. Your first reaction to that story,

737
00:44:34,376 --> 00:44:37,470
to that person, would have gone something like this, I think it

738
00:44:37,480 --> 00:44:41,026
would have gone well. There's an easy answer to this. He doesn't

739
00:44:41,058 --> 00:44:44,120
get to touch the keyboard anymore. Done.

740
00:44:44,490 --> 00:44:47,798
Problem solved. How do we make this not happen again? He doesn't

741
00:44:47,814 --> 00:44:51,670
have a job. Okay, that's one reaction.

742
00:44:51,830 --> 00:44:55,226
Not the best. The best reaction, though, is to step back

743
00:44:55,248 --> 00:44:59,226
and go, hang on a second. Blame. He's just

744
00:44:59,248 --> 00:45:02,938
blamed himself, which is why we shortcut to. He doesn't

745
00:45:03,034 --> 00:45:07,178
want to need to touch the keyboard anymore. He's not allowed blame

746
00:45:07,274 --> 00:45:10,000
shortcuts to. The solution is that person.

747
00:45:10,930 --> 00:45:15,274
So whether you're blaming someone else or they're blaming themselves, the shortcut

748
00:45:15,322 --> 00:45:18,722
is too sweet not to take. So that's why.

749
00:45:18,776 --> 00:45:21,250
One of the reasons, just one of the reasons, we don't like blame.

750
00:45:22,950 --> 00:45:26,290
The way the story went, though, is I asked him, okay, what did you do?

751
00:45:26,440 --> 00:45:29,110
Show me the command you wrote. So he wrote it up on the screen,

752
00:45:29,260 --> 00:45:32,566
and I showed him, said, show me the command you wanted to write.

753
00:45:32,748 --> 00:45:34,920
He showed me the one he wanted to write.

754
00:45:35,450 --> 00:45:39,082
One character difference between these two

755
00:45:39,136 --> 00:45:42,060
commands. He didn't do it any wrong.

756
00:45:42,510 --> 00:45:46,166
It was a trap. This was a grid.

757
00:45:46,278 --> 00:45:49,674
How many people here check a grid to make sure it's right?

758
00:45:49,792 --> 00:45:53,866
Has there any dialogue that said, are you sure that's

759
00:45:53,898 --> 00:45:57,086
going to take down the whole cluster? No, nothing like that.

760
00:45:57,108 --> 00:46:00,458
It was just a grid. Nonsensical grid. Kill grid.

761
00:46:00,634 --> 00:46:03,826
Wow. Okay, you did. And it took the

762
00:46:03,848 --> 00:46:07,026
whole thing down. And we build traps into our systems all

763
00:46:07,048 --> 00:46:10,834
the time, and we don't know their traps until we

764
00:46:10,952 --> 00:46:12,980
trick them, trip them.

765
00:46:13,750 --> 00:46:16,866
So blame, though, leads us in

766
00:46:16,888 --> 00:46:19,734
completely the wrong direction. The truth here is there's many,

767
00:46:19,772 --> 00:46:22,994
many changes we could make to the systems to help avoid

768
00:46:23,042 --> 00:46:25,922
the human, natural human error that always occurs.

769
00:46:25,986 --> 00:46:29,286
We're human. We make errors. That's how we work.

770
00:46:29,468 --> 00:46:32,954
And in this case, just a little bit of a dialogue that

771
00:46:32,992 --> 00:46:36,394
might have just said, are you sure that's going to take

772
00:46:36,432 --> 00:46:40,540
down the world? Would have perhaps helped him do the right thing.

773
00:46:41,250 --> 00:46:45,114
Okay. There's a whole pantheon

774
00:46:45,162 --> 00:46:49,194
of papers on blame, guilt, and everything that goes with it psychologically.

775
00:46:49,242 --> 00:46:52,478
So please go out there and look at those. Okay. A bit of

776
00:46:52,484 --> 00:46:56,318
reaction, though. Let's turn it around. Let's say being wrong is a

777
00:46:56,324 --> 00:46:59,838
super skill. So this person has written a command and gone, oh, I've just killed

778
00:46:59,854 --> 00:47:03,134
the entire cluster. Right. Say they were a chaos engineer.

779
00:47:03,182 --> 00:47:06,866
Now switch to the mindset of chaos engineering. The mindset is different. The mindset

780
00:47:06,898 --> 00:47:09,190
is the mindset of a motorcyclist.

781
00:47:10,490 --> 00:47:13,746
Okay, so who here drives a car now, in London.

782
00:47:13,778 --> 00:47:17,698
This can be iffy. All right. Most people drive cars legally,

783
00:47:17,794 --> 00:47:21,174
I hope when you legally learn to drive

784
00:47:21,212 --> 00:47:24,106
a car in this country, there are other countries where you don't have to do

785
00:47:24,128 --> 00:47:27,910
this, but in this country usually they teach you to drive defensively.

786
00:47:28,070 --> 00:47:32,042
What they say is when you get out on the roads, treat the world

787
00:47:32,176 --> 00:47:35,334
as something that can't really see you. So drive

788
00:47:35,392 --> 00:47:38,926
like everyone's blind and then you'll be okay. Give them the

789
00:47:38,948 --> 00:47:41,806
space because you don't think they can see you. Even if they're looking at you

790
00:47:41,828 --> 00:47:45,326
with their eyes, they're probably thinking about something else. So drive defensively

791
00:47:45,358 --> 00:47:48,754
and you'll be better. And we all forget that about six weeks after

792
00:47:48,792 --> 00:47:52,878
we passed. But that's what we're told usually is. Drive defensively.

793
00:47:52,974 --> 00:47:55,638
Assume that everyone can't see you.

794
00:47:55,804 --> 00:47:59,334
As a motorcyclist, you're taught something else. You are

795
00:47:59,372 --> 00:48:02,902
taught that they can see you and they want you

796
00:48:02,956 --> 00:48:03,670
dead.

797
00:48:06,650 --> 00:48:09,734
It's not paranoia if it's true and

798
00:48:09,772 --> 00:48:13,526
it keeps you alive longer. You literally ride like everything's

799
00:48:13,558 --> 00:48:17,414
out to get you. That's one of the reasons that riding a motorcycle

800
00:48:17,462 --> 00:48:20,154
is so calming. I know, sounds wrong, right?

801
00:48:20,272 --> 00:48:24,030
But it's calming because you can't focus on anything else.

802
00:48:24,180 --> 00:48:27,646
You can't think about what's happening at home, you can't think about what's happentm at

803
00:48:27,668 --> 00:48:31,146
work. You just have to stay alive and everything's

804
00:48:31,178 --> 00:48:34,894
out to get you. And that's why it's so wonderfully zen to be

805
00:48:34,932 --> 00:48:38,046
on a motorcycle. Okay, so you ride

806
00:48:38,078 --> 00:48:41,714
along and everything, the weather, the little old lady with the little

807
00:48:41,752 --> 00:48:45,394
dog, they're out to get you. And that's how you live longer.

808
00:48:45,592 --> 00:48:49,446
That's the mindset of a chaos engineer. Every system is

809
00:48:49,468 --> 00:48:53,320
out to get you. It's not passive. Production hates you.

810
00:48:53,690 --> 00:48:57,320
It knows where you live, it knows when you're on a date,

811
00:48:57,690 --> 00:49:01,542
knows when you're trying to sleep. It's a bit like Santa Claus,

812
00:49:01,606 --> 00:49:06,540
but really evil. It's watching you at all times and

813
00:49:07,070 --> 00:49:10,239
you're going to be wrong with it. So it's a threatening environment. You're going to

814
00:49:10,739 --> 00:49:13,722
get things wrong. So you're going to make sure you have as many compensating practices

815
00:49:13,786 --> 00:49:17,134
involved so that youre can at least survive longer.

816
00:49:17,332 --> 00:49:21,162
Production can survive longer, you can survive longer, has a participant

817
00:49:21,226 --> 00:49:24,554
in it. So being wrong is actually a key software

818
00:49:24,602 --> 00:49:27,620
skill. And I'm going to invent a new methodology right here today.

819
00:49:28,070 --> 00:49:31,394
Forget agile, we're going to do get better at being wrong.

820
00:49:31,432 --> 00:49:34,974
Hang on, is that a rude acronym, no. Get better at being

821
00:49:35,032 --> 00:49:38,774
wrong. Okay. No, it's never good. I'm a big

822
00:49:38,972 --> 00:49:42,466
hater, I suppose, of all certified

823
00:49:42,578 --> 00:49:45,942
programs. So if anyone here is inclined to create

824
00:49:45,996 --> 00:49:50,726
a certified chaosiq engineering program, I will find you and

825
00:49:50,748 --> 00:49:53,654
I know where I can hide the bodies. So,

826
00:49:53,692 --> 00:49:56,602
yes, we don't need a certification program. So get better at being wrong is obviously

827
00:49:56,656 --> 00:49:59,980
a joke, but we can make it safer to be wrong.

828
00:50:00,510 --> 00:50:03,866
And that's what we're going to do with chaos engineering. We're making it safer for

829
00:50:03,888 --> 00:50:07,134
us to get things wrong with our system. We know we care about

830
00:50:07,172 --> 00:50:11,166
our system. We know we care what it can do, but we also know there

831
00:50:11,188 --> 00:50:14,306
are conditions under which that might not happen.

832
00:50:14,488 --> 00:50:18,002
So we're going to make it safer to be in those

833
00:50:18,056 --> 00:50:20,660
situations. When that does happen,

834
00:50:21,830 --> 00:50:25,394
we inject technical robustness. So I'm careful with my terminology here.

835
00:50:25,432 --> 00:50:27,954
I hear a lot of people saying I'm going to make my system more resilient,

836
00:50:28,002 --> 00:50:31,430
and they mean they're going to make their software more robust.

837
00:50:32,330 --> 00:50:36,294
It's a slight technical difference. Robustness is for the stuff you know

838
00:50:36,332 --> 00:50:39,898
can happen. Resilience is for the stuff you don't know is going

839
00:50:39,904 --> 00:50:43,034
to happen. Resilience is the learning loop that says that when

840
00:50:43,072 --> 00:50:46,620
that occurs, we know how to learn from it and get better at it.

841
00:50:49,150 --> 00:50:52,686
We practice zero blame, because, as I say, blame is a shortcut to the

842
00:50:52,708 --> 00:50:55,150
wrong answer in many, many cases.

843
00:50:55,650 --> 00:50:58,874
So we go way beyond blame. We look at dark debt.

844
00:50:58,922 --> 00:51:02,282
Dark debt is what we care about as technical chaosiq engineers.

845
00:51:02,426 --> 00:51:05,962
We look for dark debt, we surface it. We surface evidence

846
00:51:06,026 --> 00:51:09,474
of it. I had this recently. I was writing this book

847
00:51:09,512 --> 00:51:12,754
on Chaosiq engineering, and one of the things I kept coming back to is,

848
00:51:12,792 --> 00:51:16,126
why do we do chaos engineering? And I get this from users

849
00:51:16,158 --> 00:51:20,486
as well. I've created this thing called the chaos toolkit with my best friend and

850
00:51:20,668 --> 00:51:24,354
this open source project. It helps you do experiments in chaos engineering,

851
00:51:24,482 --> 00:51:28,166
but I get loads of companies saying, okay, we kind of get that.

852
00:51:28,268 --> 00:51:32,230
What experiment should we run first? What should we do? We've got kubernetes.

853
00:51:32,310 --> 00:51:36,540
What should we do apart from run to the hills? Now, what should we do?

854
00:51:37,550 --> 00:51:40,906
I'm not a Kubernetes hater. I actually quite like kubernetes. But,

855
00:51:40,928 --> 00:51:44,110
yeah, we've got kubernetes. A lot of moving parts,

856
00:51:44,450 --> 00:51:48,154
generally. How do we know that our system will survive

857
00:51:48,202 --> 00:51:50,560
certain conditions? What experiments should we run?

858
00:51:51,090 --> 00:51:54,618
And it's a fair question. And our usually response

859
00:51:54,634 --> 00:51:58,606
is, what do you care about? Do you care about availability?

860
00:51:58,718 --> 00:52:02,514
Do you care about durability do you care about the fact your home

861
00:52:02,552 --> 00:52:05,682
page is there or not at all times? At most

862
00:52:05,736 --> 00:52:08,962
times? If you care about one of those things, you have an objective.

863
00:52:09,106 --> 00:52:12,150
If you have an objective, you can start to measure that objective.

864
00:52:12,490 --> 00:52:16,134
Okay, so we're starting there, right? If you can measure your

865
00:52:16,172 --> 00:52:19,878
objective and you have a target, an objective for it being up

866
00:52:19,964 --> 00:52:23,414
perhaps 99% of the time. Great. We've got the ability

867
00:52:23,462 --> 00:52:26,778
to have a bit of leeway there. Okay, now we

868
00:52:26,784 --> 00:52:29,578
can say, what conditions do you want to put the system under? What do you

869
00:52:29,584 --> 00:52:33,054
think could happen? Could it be a pod dying? Well,

870
00:52:33,092 --> 00:52:36,474
yeah, probably. Can your network degrade? If it can't,

871
00:52:36,522 --> 00:52:40,286
I want that network. What the sort of conditions do

872
00:52:40,308 --> 00:52:44,154
you want to get knowledge of that? Your objective

873
00:52:44,282 --> 00:52:48,594
will stay within its parameters of being, okay, 99% if

874
00:52:48,632 --> 00:52:51,906
that happens. Right, let's do that. Now, you notice there,

875
00:52:51,928 --> 00:52:55,886
not once have I said chaos, not once have I said experiment. I haven't

876
00:52:55,928 --> 00:52:59,506
really said test, although it is one. What I'm

877
00:52:59,538 --> 00:53:03,298
doing is verifying objective. That's the language I'm

878
00:53:03,314 --> 00:53:07,122
now using when I help people define chaos experiments.

879
00:53:07,266 --> 00:53:11,226
What is the overall business objective that you care about? Make sure you

880
00:53:11,248 --> 00:53:16,806
can measure it. Right now we can look at introducing

881
00:53:16,838 --> 00:53:20,366
conditions to the system, and we can see what impact on the

882
00:53:20,388 --> 00:53:22,880
objective that might have.

883
00:53:24,210 --> 00:53:26,830
No one cares or wants chaos.

884
00:53:27,650 --> 00:53:31,002
Everyone wants something else and wants to verify

885
00:53:31,066 --> 00:53:34,386
it. So that's what the language I tend to use for that, and that

886
00:53:34,408 --> 00:53:37,186
helps us with dark debt in that book. What I say in the book is

887
00:53:37,208 --> 00:53:41,250
chaos engineering provides evidence of system weaknesses.

888
00:53:41,750 --> 00:53:45,074
Verification says what you found is useful because

889
00:53:45,112 --> 00:53:46,870
it helps me with an objective.

890
00:53:48,890 --> 00:53:52,674
Okay, so chaos engineering could be better phrased

891
00:53:52,722 --> 00:53:56,166
as deliberately practicing being wrong. We're going to get

892
00:53:56,188 --> 00:53:59,558
better at it and do it more proactively. We're going to verify

893
00:53:59,654 --> 00:54:03,114
something all the time. We might continuously. Is that word

894
00:54:03,152 --> 00:54:06,982
again overused in our industry. We're going to continuously verify

895
00:54:07,046 --> 00:54:10,842
youre system with experiments to see how our system

896
00:54:10,896 --> 00:54:14,318
responds, because there's something we care about about that system,

897
00:54:14,484 --> 00:54:16,080
and we can measure it.

898
00:54:17,490 --> 00:54:21,102
We can prepare for the undesirable circumstances by, in small ways,

899
00:54:21,156 --> 00:54:22,800
making them happen all the time.

900
00:54:24,630 --> 00:54:28,114
And that's what chaos engineering really is,

901
00:54:28,152 --> 00:54:30,420
is deliberately practicing being wrong,

902
00:54:31,270 --> 00:54:34,514
and it's an investment in resilience. Now, there's that other r word.

903
00:54:34,552 --> 00:54:37,590
So, robustness, resilience, they often get confused.

904
00:54:38,650 --> 00:54:42,502
You're resilient if when something unexpected happens, you can

905
00:54:42,556 --> 00:54:46,280
respond to it, learn from it, and improve the system.

906
00:54:47,130 --> 00:54:51,254
If you have an objective that is measurable and you do chaos

907
00:54:51,302 --> 00:54:55,446
experiments against the system, and you can see what that impact on that objective

908
00:54:55,558 --> 00:55:00,214
would be. Then you have all of the ammunition to analyze

909
00:55:00,342 --> 00:55:04,510
and produce actions out of what you're doing, prioritized actions.

910
00:55:05,170 --> 00:55:08,874
This is important because if you just broke a system, so say you did chaos

911
00:55:08,922 --> 00:55:12,366
engineering in the smallest possible capacity, where you said, actually,

912
00:55:12,388 --> 00:55:14,974
I'm just going to go in and I'm going to screw around with the pods,

913
00:55:15,022 --> 00:55:18,866
see what happens. All right, you do that and

914
00:55:18,888 --> 00:55:22,354
you go, okay, well, things didn't seem to go very

915
00:55:22,392 --> 00:55:25,714
well, but we don't know what the impact was on what we care about,

916
00:55:25,752 --> 00:55:29,606
and we don't know how to prioritize any work that we might do out the

917
00:55:29,628 --> 00:55:33,174
back of it. Without the objective, you don't know

918
00:55:33,212 --> 00:55:36,406
what to improve. You need to be able to

919
00:55:36,428 --> 00:55:40,266
say, we did this, it affected this,

920
00:55:40,448 --> 00:55:44,518
we care about this. Therefore, we can prioritize

921
00:55:44,614 --> 00:55:48,186
these improvements on the back of that. This is why I tend to use

922
00:55:48,288 --> 00:55:51,946
the phrase verification of a system rather than merely

923
00:55:52,058 --> 00:55:54,030
turbulence and chaos,

924
00:55:56,930 --> 00:56:00,426
because it enables the learning loop, it enables

925
00:56:00,458 --> 00:56:03,310
us to be able to join things up and go, we know why we're doing

926
00:56:03,380 --> 00:56:06,626
this stuff in the first place, and we know what we're actually going to do

927
00:56:06,648 --> 00:56:10,018
in response to it tends to look like this.

928
00:56:10,104 --> 00:56:13,854
So this is my very rudimentary how things happen. You have a normal

929
00:56:13,902 --> 00:56:16,530
system, something goes kablui.

930
00:56:18,570 --> 00:56:21,686
Now, I love this detection, diagnosis and fix. Sounds so

931
00:56:21,708 --> 00:56:25,880
calm, doesn't it? It's easy. In there is hell.

932
00:56:26,810 --> 00:56:29,974
In there is someone being woken up at the wrong time of day. In there

933
00:56:30,012 --> 00:56:32,940
is someone going, we don't know how to do this.

934
00:56:33,950 --> 00:56:37,354
In there is someone staring out the window, wondering why they are still in this

935
00:56:37,392 --> 00:56:40,954
job. Eventually you get round to something you can learn

936
00:56:40,992 --> 00:56:44,638
from if you avoid the blame shortcut, for example,

937
00:56:44,804 --> 00:56:48,734
and then you can improve the robustness of the system to something that is

938
00:56:48,772 --> 00:56:52,154
now known. Now, in this case, it was an outage.

939
00:56:52,202 --> 00:56:55,426
It was a surprise. It was a big deal. Wouldn't it

940
00:56:55,448 --> 00:56:59,074
be great if we could do that in a predictive way? We can

941
00:56:59,112 --> 00:57:02,674
convert it into pre mortem learning rather

942
00:57:02,712 --> 00:57:06,446
than post mortem learning, which is chaos engineering.

943
00:57:06,478 --> 00:57:10,034
And it looks like this, you do a game day or an automated chaos

944
00:57:10,082 --> 00:57:13,398
experiment. It's only two things in chaos engineering. Another reason we don't need a

945
00:57:13,404 --> 00:57:17,526
certification program, two things we

946
00:57:17,548 --> 00:57:20,406
can do, game days, which is great fun. I've got so many stories about game

947
00:57:20,428 --> 00:57:22,394
days, I don't know if I've got enough time to share them, but they are

948
00:57:22,432 --> 00:57:26,422
great stories about game days. Okay. Automated chaos experiments.

949
00:57:26,486 --> 00:57:29,370
Again, you're doing this in a small way. Small fires.

950
00:57:29,790 --> 00:57:34,270
Small fires require less fire hoses,

951
00:57:34,690 --> 00:57:37,866
detection, diagnosis, and fix. You can figure out how we've reacted

952
00:57:37,898 --> 00:57:41,486
to it before. It actually is a massive problem. Turn it to learning. Turn it

953
00:57:41,508 --> 00:57:45,742
into robustness. You do it across the entire sociotechnical

954
00:57:45,806 --> 00:57:49,362
system. And this way,

955
00:57:49,416 --> 00:57:52,894
we can learn before outages happen, because we can't

956
00:57:52,942 --> 00:57:56,854
design them out, but we can learn about them before they

957
00:57:56,892 --> 00:58:00,630
become the big catastrophe that we're trying to avoid.

958
00:58:01,690 --> 00:58:05,094
So this is the truth. Being wrong is a superpower. Well done.

959
00:58:05,132 --> 00:58:09,186
As software engineers, we're wrong all the time. It's a good thing because

960
00:58:09,228 --> 00:58:11,260
we can turn it into something being great.

961
00:58:12,990 --> 00:58:16,314
And you can have a platform for deliberate practice of being

962
00:58:16,352 --> 00:58:19,526
wrong, which is a platform of chaos engineering,

963
00:58:19,558 --> 00:58:23,100
and you will. Or verification, as I tend to call it.

964
00:58:23,550 --> 00:58:26,958
Okay? So if you want to have a play, have a play with

965
00:58:26,964 --> 00:58:30,958
chaos toolkit. That's a nice way to start. Lots of companies stay there.

966
00:58:31,124 --> 00:58:34,494
You can do amazing stuff with it. People can talk, but other tools later

967
00:58:34,532 --> 00:58:37,950
on. There's truckloads of tools out there in chaos engineering. It's fabulous.

968
00:58:38,110 --> 00:58:41,506
The richness of open youre and free chaos engineering tools is

969
00:58:41,528 --> 00:58:44,370
a brilliant thing, and we're happy to be part of it. Frankly,

970
00:58:44,950 --> 00:58:47,538
Chaos IQ is the thing I work on. If anyone wants to use something like

971
00:58:47,544 --> 00:58:51,298
that, it's a verification tool. So it's a software as a

972
00:58:51,304 --> 00:58:54,006
service verification tool. If anyone wants to give that a spin, come and give me

973
00:58:54,028 --> 00:58:56,886
a shout. I'll be around till lunch. And then, unfortunately, I have to get on

974
00:58:56,908 --> 00:59:00,470
a jet. That sounds really, really posh, doesn't it?

975
00:59:00,620 --> 00:59:04,186
I have to get on with about 300 others on a jet. Let's point this

976
00:59:04,208 --> 00:59:07,498
out. And I'm not at the front. Okay,

977
00:59:07,664 --> 00:59:10,858
so these are the books out there, if you want to grab them. One of

978
00:59:10,864 --> 00:59:13,802
them. I wrote one of them, actually, I wrote both of them. Both of those.

979
00:59:13,856 --> 00:59:16,926
Great. There are other ones. There's a chaos engineering book by the

980
00:59:16,948 --> 00:59:20,574
Netflix team, which is fabulous. There's also another chaos engineering book coming out later

981
00:59:20,612 --> 00:59:23,918
on this year that I've contributed a chapter to, as well as a few others

982
00:59:24,084 --> 00:59:27,006
speaking today. And out there in the wild, learning chaos engineering,

983
00:59:27,038 --> 00:59:30,142
I'm told, is a fabulous place to get started in chaos engineering.

984
00:59:30,206 --> 00:59:34,034
I'm totally unbiased in that. And, yeah, if anyone does actually

985
00:59:34,072 --> 00:59:36,546
buy that, or if anyone asks me very, very nicely, I'll send you a copy.

986
00:59:36,578 --> 00:59:39,160
Anyway, it's a 40 quid book.

987
00:59:40,250 --> 00:59:43,782
I'll send youre it. And if you want a signature you can.

988
00:59:43,836 --> 00:59:47,618
Otherwise, thank you so much for being here today. Chaos engineering

989
00:59:47,634 --> 00:59:51,378
is a superpower. I mentioned earlier very quickly. I mentioned earlier

990
00:59:51,474 --> 00:59:55,350
that there is no best practices in our world where it's complex and chaosiq.

991
00:59:55,770 --> 00:59:58,966
I lied. Chaos engineering is the only one

992
00:59:58,988 --> 01:00:03,086
I know of. I can tell you. Just do it and

993
01:00:03,108 --> 01:00:03,820
you'll probably be better.

