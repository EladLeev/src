1
00:00:34,530 --> 00:00:38,374
Today, I'm going to talk about service weaver new programming framework for

2
00:00:38,412 --> 00:00:43,174
writing distributed applications in go based

3
00:00:43,212 --> 00:00:46,840
on our experience of writing distributed applications at Google,

4
00:00:47,210 --> 00:00:50,390
teams usually organize their applications into microservice,

5
00:00:51,250 --> 00:00:55,280
where a microservice is a piece of code that exports an RPC service.

6
00:00:56,530 --> 00:01:00,494
A team usually owns multiple microservices and based

7
00:01:00,532 --> 00:01:04,610
on our analysis, teams frequently add new microservices.

8
00:01:05,350 --> 00:01:09,154
Finally, they use an internal tool to manage their

9
00:01:09,192 --> 00:01:12,942
microservices. There are many reasons

10
00:01:13,006 --> 00:01:16,070
why people split their applications into microservices,

11
00:01:16,650 --> 00:01:20,086
for example, to achieve fault tolerance and

12
00:01:20,108 --> 00:01:21,830
to scale their applications.

13
00:01:23,530 --> 00:01:27,014
Another reason is to improve the development velocity or

14
00:01:27,052 --> 00:01:30,314
to make it easier to maintain. However,

15
00:01:30,432 --> 00:01:33,930
we did some analysis and we found out that teams often

16
00:01:34,000 --> 00:01:38,330
split into microservices without having valid concerns.

17
00:01:38,830 --> 00:01:42,810
For example, they claim that they want to use different programming languages

18
00:01:42,890 --> 00:01:46,462
for different microservices. However, we found

19
00:01:46,516 --> 00:01:50,590
out that the vast majority of the teams use only one language.

20
00:01:52,390 --> 00:01:56,974
Another argument to split is that the team wants to release microservice

21
00:01:57,102 --> 00:02:00,658
using different rollout schedules. However,

22
00:02:00,744 --> 00:02:05,466
our analysis shows that a significant fraction of the teams release all microservice

23
00:02:05,598 --> 00:02:09,574
altogether. And finally, developers claim that

24
00:02:09,612 --> 00:02:13,410
they want to release some microservices very often, like subdaily.

25
00:02:13,570 --> 00:02:17,206
However, we found out that only a tiny fraction of

26
00:02:17,228 --> 00:02:19,740
the microservice are released very often.

27
00:02:20,830 --> 00:02:24,886
So the takeaway here is that teams split their applications

28
00:02:24,918 --> 00:02:28,630
into microservices for some good reasons,

29
00:02:28,710 --> 00:02:31,390
but often also not valid reasons.

30
00:02:33,490 --> 00:02:37,130
However, splitting into an application into microservices

31
00:02:37,210 --> 00:02:40,494
is challenging. For example, the developers now

32
00:02:40,532 --> 00:02:44,590
have to deal with multiple versions of microservices,

33
00:02:44,750 --> 00:02:48,462
and they have to implement logic to ensure different running instances

34
00:02:48,526 --> 00:02:51,250
at different versions are backward compatible.

35
00:02:52,550 --> 00:02:56,390
One implication of versioning is API hardening.

36
00:02:57,290 --> 00:03:01,266
That means that once a developer splits into microservices and deploys

37
00:03:01,298 --> 00:03:05,122
them, it is incredibly difficult to change the APIs

38
00:03:05,186 --> 00:03:08,842
because of versioning concerns. Also,

39
00:03:08,896 --> 00:03:13,210
to deploy a microservice, it requires complicated configuration files

40
00:03:13,550 --> 00:03:17,386
and the developer has to add logic to connect microservices together

41
00:03:17,488 --> 00:03:22,010
and organize application code into low level interactions through an ideal

42
00:03:22,990 --> 00:03:26,474
and finally, end to end testing and local testing becomes incredibly

43
00:03:26,522 --> 00:03:27,120
difficult.

44
00:03:30,530 --> 00:03:34,530
Another popular paradigm to write distributed applications is to

45
00:03:34,600 --> 00:03:38,146
organize your application into a monolith that consists of

46
00:03:38,168 --> 00:03:42,050
a single binary, and usually it is deployed with a single config.

47
00:03:43,590 --> 00:03:46,774
With the monolithic architecture, it's easier to address many

48
00:03:46,812 --> 00:03:49,670
of the challenges introduced to using microservice,

49
00:03:50,010 --> 00:03:52,550
for example, drano versioning concerns.

50
00:03:53,290 --> 00:03:56,674
However, monoliths suffer from challenges

51
00:03:56,722 --> 00:03:59,270
that microservice are designed to handle,

52
00:04:00,890 --> 00:04:04,214
so service weaver bridges a gap between the

53
00:04:04,252 --> 00:04:07,626
two models. It provides a programming model of

54
00:04:07,648 --> 00:04:11,950
a monolith and enables the flexibility of using microservices.

55
00:04:13,250 --> 00:04:17,018
If we have to remember only one thing about service Weaver,

56
00:04:17,194 --> 00:04:21,214
then you should remember that service Weaver allows you to write your application as a

57
00:04:21,252 --> 00:04:24,658
modular binary while is deploying the application as a

58
00:04:24,664 --> 00:04:26,370
set of connected microservices.

59
00:04:27,430 --> 00:04:31,294
Finally, service Weaver enables writing high performance

60
00:04:31,342 --> 00:04:34,130
applications and enables portability.

61
00:04:35,050 --> 00:04:38,498
This means it allows you to deploy the same application binary

62
00:04:38,594 --> 00:04:42,294
into different cloud environments and can

63
00:04:42,332 --> 00:04:45,106
support applications written in multiple languages,

64
00:04:45,298 --> 00:04:47,640
although we don't support that for now.

65
00:04:49,610 --> 00:04:53,206
So at a glance, service Weaver allows

66
00:04:53,238 --> 00:04:56,966
you to develop applications using native language constructs

67
00:04:57,158 --> 00:05:01,070
and organize your code around native language interfaces.

68
00:05:02,690 --> 00:05:07,066
While writing your application business logic, you don't have to worry about versioning

69
00:05:07,178 --> 00:05:10,334
and finally, you can use some embedded fields to

70
00:05:10,452 --> 00:05:14,100
vivify the application. As I'm going to show slightly later,

71
00:05:15,670 --> 00:05:19,106
to deploy your service weaver application, you will have a

72
00:05:19,128 --> 00:05:21,890
single binary and a tiny config.

73
00:05:22,790 --> 00:05:26,198
Service Weaver will run your application as a set of microservices at the

74
00:05:26,204 --> 00:05:29,554
same code version and provides multiple deployment

75
00:05:29,602 --> 00:05:33,062
environments. For now, you can deploy your application on the local

76
00:05:33,116 --> 00:05:37,094
machine, in a cluster of machines or in Google Cloud.

77
00:05:37,292 --> 00:05:41,274
However, we can add new deployers for AWS and Azure and

78
00:05:41,392 --> 00:05:45,066
other cloud providers to roll out a new application

79
00:05:45,168 --> 00:05:49,030
version. Service Weaver will ensure your rollout is safe,

80
00:05:49,110 --> 00:05:52,586
and it does bluegrain deployments, a widely popular technique

81
00:05:52,618 --> 00:05:56,030
to deploy new application versions in a distributed environment.

82
00:05:57,890 --> 00:06:01,722
One nice thing about service Weaver is that it provides

83
00:06:01,786 --> 00:06:05,586
observability, like logging metrics and tracing that

84
00:06:05,608 --> 00:06:08,530
can be easily integrated with different monitoring tools.

85
00:06:08,950 --> 00:06:12,770
Also, it allows easy testing and debugging.

86
00:06:14,550 --> 00:06:18,146
Finally, service weaver runtime implements various high

87
00:06:18,168 --> 00:06:21,590
performance mechanisms that enable high performance applications.

88
00:06:22,410 --> 00:06:26,226
In the following slides, we'll go into more details into how service Weaver

89
00:06:26,258 --> 00:06:28,570
handled each of these topics.

90
00:06:30,350 --> 00:06:34,806
So, development a service Weaver application consists

91
00:06:34,918 --> 00:06:38,506
of a set of components that call each other, where a

92
00:06:38,528 --> 00:06:42,014
component is somehow similar to actors. For those familiar with the

93
00:06:42,052 --> 00:06:45,306
actor model under the hood,

94
00:06:45,498 --> 00:06:49,118
service Weaver uses a code generator to vivify the

95
00:06:49,124 --> 00:06:52,110
application, for example, to generate,

96
00:06:52,930 --> 00:06:55,540
you know, registration and so on.

97
00:06:56,790 --> 00:07:00,734
To write your service weaver application, you write a modeler binary

98
00:07:00,782 --> 00:07:04,414
and then you can deploy it on your local machine where components

99
00:07:04,462 --> 00:07:08,386
can run in the same process or in multiple processes,

100
00:07:08,578 --> 00:07:12,226
and then you can run it distributed on different machines pods,

101
00:07:12,258 --> 00:07:16,002
it can be replicated, traffic is load balanced between replicas

102
00:07:16,066 --> 00:07:17,080
and so on.

103
00:07:20,270 --> 00:07:23,750
To define a service weaver component, you simply define

104
00:07:23,830 --> 00:07:27,206
a go interface. Here we define a cache

105
00:07:27,238 --> 00:07:30,894
component with a put method, and of course you can have other

106
00:07:30,932 --> 00:07:34,446
methods as well. Next to implement the

107
00:07:34,468 --> 00:07:38,366
component, you write a ghost struct, except that you have to add

108
00:07:38,468 --> 00:07:42,630
weaver implements embedding. This allows the service Weaver

109
00:07:42,650 --> 00:07:45,570
framework to identify that this is a component.

110
00:07:47,110 --> 00:07:51,106
To instantiate a service weaver application in the main function,

111
00:07:51,208 --> 00:07:54,898
you can simply call Weaver init and to get a client to

112
00:07:54,904 --> 00:07:58,326
a component, you call Weaver get.

113
00:07:58,508 --> 00:08:02,322
And finally, once you got a handle on the component,

114
00:08:02,466 --> 00:08:06,470
you can interact with the component by simply doing method calls.

115
00:08:09,930 --> 00:08:14,550
To deploy a service weaver application, you release a single binary

116
00:08:14,710 --> 00:08:17,914
and a tiny config. You just

117
00:08:17,952 --> 00:08:20,730
have to specify the name of the application binary.

118
00:08:21,390 --> 00:08:25,118
Optionally, you can also choose whether to collocate certain components in the

119
00:08:25,124 --> 00:08:28,190
same process for performance or other reasons.

120
00:08:28,610 --> 00:08:32,126
Also, you can specify how long you want to roll out

121
00:08:32,148 --> 00:08:33,620
a new instance of the application.

122
00:08:36,230 --> 00:08:39,394
Once you write this tiny config, you can simply execute go

123
00:08:39,432 --> 00:08:43,220
run on your local machine to run the application in a single process.

124
00:08:43,590 --> 00:08:47,658
Or you can call Weaver multideeploy

125
00:08:47,774 --> 00:08:51,510
to run the application on the same machine, but in multiple processes.

126
00:08:52,490 --> 00:08:56,182
Now, if you want to deploy in a distributed environment, you can add a per

127
00:08:56,236 --> 00:08:59,350
deployment information in the config file.

128
00:09:00,350 --> 00:09:03,574
For example, to run on multiple machines via SSH,

129
00:09:03,702 --> 00:09:07,526
you just need to specify a file that contains the names of the machines,

130
00:09:07,718 --> 00:09:12,714
and then you can run Weaver SSH deploy to

131
00:09:12,752 --> 00:09:17,150
run the same application binary that you run locally, but now on multiple machines,

132
00:09:18,050 --> 00:09:21,326
if you want to run in the Google Cloud, you have to specify the

133
00:09:21,348 --> 00:09:25,726
regions where you want to run the application and some public listeners

134
00:09:25,838 --> 00:09:29,266
that enable you to get access to the application. Then you

135
00:09:29,288 --> 00:09:32,418
can simply run Weaver GKE deploy to run the application

136
00:09:32,504 --> 00:09:35,842
in the cloud. Under the hood,

137
00:09:35,986 --> 00:09:39,010
the deployer will automatically create containers,

138
00:09:39,090 --> 00:09:42,118
place the components into pods, replicate them,

139
00:09:42,284 --> 00:09:46,120
load balance the traffic among different replicas, and so on.

140
00:09:46,730 --> 00:09:50,614
Let's look a little bit in more detail about on how

141
00:09:50,652 --> 00:09:54,426
a serviceiver application is deployed. As mentioned before,

142
00:09:54,528 --> 00:09:57,994
you write the application as a monolith that consists of a set of

143
00:09:58,032 --> 00:10:01,694
components. Service Weaver bill place these

144
00:10:01,732 --> 00:10:05,514
components into processes. By default, it places each component

145
00:10:05,562 --> 00:10:09,354
in a different process. However, if you specify any colocation

146
00:10:09,402 --> 00:10:12,958
in the config, as we saw before, then service weaver

147
00:10:12,974 --> 00:10:15,570
will respect those constraints.

148
00:10:17,030 --> 00:10:20,820
Next, service Weaver will attach corresponding libraries to the application

149
00:10:21,510 --> 00:10:25,198
that are responsible to manage the interaction between the application and the

150
00:10:25,224 --> 00:10:29,138
runtime environment. Finally, service weaver

151
00:10:29,154 --> 00:10:32,646
runtime can have different implementation. As mentioned before, for now we have

152
00:10:32,668 --> 00:10:35,890
deployers for the local machine for a set of machines

153
00:10:35,970 --> 00:10:39,206
and Google Cloud. However, service weaver

154
00:10:39,238 --> 00:10:42,918
enables relatively easy to write new deployers, for example for AWS

155
00:10:43,014 --> 00:10:46,934
or Azure. Now let's talk about telemetry

156
00:10:46,982 --> 00:10:50,902
and testing. Service Weaver provides integrated

157
00:10:50,966 --> 00:10:54,422
login with service weaver, each component

158
00:10:54,486 --> 00:10:57,806
comes with an associated logger, and it's pretty straightforward to log in

159
00:10:57,828 --> 00:10:59,310
to manipulate logs.

160
00:11:01,010 --> 00:11:05,490
Also, it provides metrics like counters, gouges, and histograms.

161
00:11:06,150 --> 00:11:09,886
One interesting observation is that service viewer generates some metrics by default

162
00:11:09,918 --> 00:11:13,506
for your application. For example, metrics that capture the

163
00:11:13,528 --> 00:11:16,930
throughput and the latency between various components.

164
00:11:18,790 --> 00:11:22,962
For tracing, service viewer relies on open telemetry,

165
00:11:23,106 --> 00:11:27,646
and to enable tracing, you simply have to create an autel handler

166
00:11:27,778 --> 00:11:32,090
in your main function. Once tracing is enabled,

167
00:11:33,070 --> 00:11:36,886
service Weaver will trace for you all the HTTP requests and component metal

168
00:11:36,918 --> 00:11:41,134
calls. And finally, service Weaver allows you to

169
00:11:41,252 --> 00:11:44,590
with a single command weaver GK profile, for example,

170
00:11:44,740 --> 00:11:48,670
to capture the performance of your application as a whole

171
00:11:48,820 --> 00:11:52,814
by profiling each individual process and aggregating into

172
00:11:52,852 --> 00:11:54,110
a single profile.

173
00:11:57,650 --> 00:12:01,566
In terms of monitoring, service weaver provides dashboards

174
00:12:01,598 --> 00:12:04,946
for our application. One nice feature of service viewer is

175
00:12:04,968 --> 00:12:08,230
that it can provide a bird's eye view into your application.

176
00:12:08,380 --> 00:12:11,718
For example, as you can see on this slide, it can

177
00:12:11,804 --> 00:12:15,522
display the call graph and interactions between all the components,

178
00:12:15,586 --> 00:12:19,370
along with various metrics to reflect interaction between these components

179
00:12:19,870 --> 00:12:23,302
and also to provide more insight into the behavior

180
00:12:23,366 --> 00:12:27,702
of each component. Service Weaver also provides integration

181
00:12:27,766 --> 00:12:31,626
with various monitoring frameworks. For example,

182
00:12:31,728 --> 00:12:35,914
you can run your application on multiple machines with the SSH deployer,

183
00:12:36,042 --> 00:12:40,266
and then you can open the dashboard on your local machine and click on tracing,

184
00:12:40,458 --> 00:12:43,854
and you can see all the traces across all components

185
00:12:43,902 --> 00:12:47,170
across all the machines in your local chrome browser.

186
00:12:47,510 --> 00:12:51,086
And here is a list of all the monitoring frameworks

187
00:12:51,118 --> 00:12:56,582
service Weaver integrates so far for

188
00:12:56,636 --> 00:13:00,178
testing. Service Weaver provides a weaver test package

189
00:13:00,354 --> 00:13:04,310
that allows you to run unit tests that can run in a single and

190
00:13:04,380 --> 00:13:07,846
multi process mode. Writing unit test is as

191
00:13:07,868 --> 00:13:11,450
easy as writing a service weaver application. The only difference

192
00:13:11,520 --> 00:13:14,906
is that instead of using Weaver init to instantiate an

193
00:13:14,928 --> 00:13:18,438
application, you have to use weavertest init in your unit

194
00:13:18,454 --> 00:13:21,946
tests. For end

195
00:13:21,968 --> 00:13:25,086
to end testing, service Weaver provides status commands and you also

196
00:13:25,108 --> 00:13:28,720
can check the logs, metrics, traces, and the dashboards we provide.

197
00:13:29,410 --> 00:13:33,054
For example, if you want to make a change to your application

198
00:13:33,172 --> 00:13:36,820
and see if the application is still running, you can simply do go run.

199
00:13:37,830 --> 00:13:41,742
Now, if you want to test whether your changes make any assumptions

200
00:13:41,806 --> 00:13:44,260
about the distributed nature of the application,

201
00:13:44,870 --> 00:13:49,010
you can run Weaver multideeploy.

202
00:13:50,330 --> 00:13:54,214
And finally, if you want to make sure that the application still

203
00:13:54,252 --> 00:13:57,314
works in the presence of multiple application versions running,

204
00:13:57,452 --> 00:14:01,766
you can run Weaver GKE local let's

205
00:14:01,798 --> 00:14:03,050
talk about performance.

206
00:14:04,910 --> 00:14:08,762
Service Weaver provides a highly efficient runtime that

207
00:14:08,816 --> 00:14:12,286
enables high performance applications for example,

208
00:14:12,388 --> 00:14:15,854
it provides an efficient encoding decoding mechanism that has no

209
00:14:15,892 --> 00:14:19,386
versioning overheads. It uses an efficient

210
00:14:19,418 --> 00:14:23,082
transport protocol built on top of tcp that embeds

211
00:14:23,146 --> 00:14:27,054
custom load balancing. It provides collocation that

212
00:14:27,092 --> 00:14:30,626
enables flexibility on how components are complicated. For example,

213
00:14:30,728 --> 00:14:34,322
chatty components can be placed together in the same process, and they can use simple

214
00:14:34,376 --> 00:14:36,760
local method calls to interact with each other.

215
00:14:37,850 --> 00:14:41,494
And finally, service people provides routing that

216
00:14:41,532 --> 00:14:45,542
helps to balance the load across multiple component replicas and

217
00:14:45,596 --> 00:14:48,826
also increases the cache hit ratio in case you

218
00:14:48,848 --> 00:14:52,490
want to collocate caches with your components. For performance reasons,

219
00:14:54,430 --> 00:14:58,250
we benchmarked a popular application called online boutique

220
00:14:58,590 --> 00:15:00,990
that contains eleven microservices.

221
00:15:02,450 --> 00:15:06,394
We ran the application using the Google Cloud deployer and compared

222
00:15:06,442 --> 00:15:09,146
the performance using three different approaches.

223
00:15:09,338 --> 00:15:12,526
Nonweaver, which is the microservice version of the application,

224
00:15:12,628 --> 00:15:16,462
except that we rewrote all the microservice in go for a fair

225
00:15:16,516 --> 00:15:19,854
comparison. Weaver split

226
00:15:19,982 --> 00:15:23,346
which is the application written with service Weaver, except that all

227
00:15:23,368 --> 00:15:27,506
the components run in a single process. And finally we

228
00:15:27,528 --> 00:15:31,106
were merged, which is the applications written with service Weaver,

229
00:15:31,218 --> 00:15:34,630
except that all the components run in separate processes.

230
00:15:36,170 --> 00:15:39,834
Our results show that with service Weaver you

231
00:15:39,872 --> 00:15:43,194
write less code into your application up to

232
00:15:43,232 --> 00:15:47,194
1.25 x. And this is because you don't have to write

233
00:15:47,312 --> 00:15:50,418
boilerplate code related to encoding decoding,

234
00:15:50,614 --> 00:15:54,378
you don't have to add service discovery,

235
00:15:54,474 --> 00:15:57,838
you don't have to define protos, you don't have to integrate to

236
00:15:57,844 --> 00:16:00,000
the cloud provider, and so on.

237
00:16:01,170 --> 00:16:04,798
Also with service Weaver you just write a tiny config,

238
00:16:04,974 --> 00:16:08,578
while if you deploy as microservice, there are many configurations in

239
00:16:08,584 --> 00:16:10,850
their very complicated YAML files.

240
00:16:12,790 --> 00:16:16,566
Because of a high performancean runtime, service Weaver can handle the

241
00:16:16,588 --> 00:16:20,054
same throughput as a nonweaver version of the application, but with

242
00:16:20,092 --> 00:16:23,974
less resources. Hence it can reduce the cost by up to four

243
00:16:24,012 --> 00:16:28,022
x. And finally, the application latency

244
00:16:28,086 --> 00:16:32,198
significantly reduces service Weaver. In our benchmarking

245
00:16:32,374 --> 00:16:36,426
it's up to 37 x better at 99

246
00:16:36,448 --> 00:16:39,706
percentile before I

247
00:16:39,728 --> 00:16:43,134
conclude the talk, I want to address briefly some of the common questions we

248
00:16:43,172 --> 00:16:47,402
get with service Weaver. You write a single modular binary

249
00:16:47,466 --> 00:16:51,066
and you can postpone the decisions on how to split

250
00:16:51,098 --> 00:16:54,862
into microservices for later. A nice

251
00:16:54,916 --> 00:16:58,494
property of service viewer is that you don't have to worry about the underlying

252
00:16:58,542 --> 00:17:01,970
network transport or the underlying serialization mechanisms.

253
00:17:02,630 --> 00:17:06,066
Also, by decoupling of the application code from RPC

254
00:17:06,098 --> 00:17:09,814
bindings, service Weaver allows cross component calls within

255
00:17:09,852 --> 00:17:13,110
the same process to be optimized down to local method calls.

256
00:17:14,490 --> 00:17:18,246
However, service Weaver doesn't hide the network and the application

257
00:17:18,348 --> 00:17:21,930
developers should treat method calls as remote by default.

258
00:17:23,070 --> 00:17:26,694
Also, with service Weaver, you don't have to organize

259
00:17:26,742 --> 00:17:30,010
the application code and low level interactions through an IDL.

260
00:17:30,370 --> 00:17:35,902
And finally, you don't have to worry about code versioning issues and

261
00:17:35,956 --> 00:17:39,840
rollouts. Service Weaver take care of these things for you.

262
00:17:41,250 --> 00:17:45,130
So I presented service Weaver a framework

263
00:17:45,210 --> 00:17:49,546
for writing distributed

264
00:17:49,578 --> 00:17:53,502
applications. With service Weaver, it's easy to develop,

265
00:17:53,636 --> 00:17:56,578
deploy, and monitor performance applications.

266
00:17:56,754 --> 00:18:00,486
We are looking for community contributions. We want people

267
00:18:00,508 --> 00:18:04,278
to get involved with us, give us feedback, and contribute to the project.

268
00:18:04,364 --> 00:18:07,366
And so please don't hesitate to contact us.

269
00:18:07,548 --> 00:18:10,100
With this I conclude my talk. Thank you.

