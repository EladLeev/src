1
00:02:14,930 --> 00:02:17,822
Hello everyone. Thanks for attending my talk today.

2
00:02:17,956 --> 00:02:20,830
My name is Andrew Knight and I'm the automation panda.

3
00:02:21,490 --> 00:02:24,734
I work as a developer advocate at Applitools, where I help

4
00:02:24,772 --> 00:02:28,874
folks get the most value but of their QA work with automated visual testing.

5
00:02:29,002 --> 00:02:32,794
I'm also director of Test Automation University, which offers several

6
00:02:32,842 --> 00:02:36,306
online courses to help you learn testing and automation, and it's

7
00:02:36,338 --> 00:02:39,558
completely free. Today,

8
00:02:39,644 --> 00:02:43,446
I'm super excited to introduce a somewhat new idea to you and to our

9
00:02:43,468 --> 00:02:47,046
industry. Open testing. What if

10
00:02:47,068 --> 00:02:50,010
we open our tests like we open our source?

11
00:02:50,670 --> 00:02:54,246
I'm not merely talking about creating open source test frameworks,

12
00:02:54,358 --> 00:02:57,100
I'm talking about opening the tests themselves.

13
00:02:57,870 --> 00:03:02,178
What if it became normal to share tests and automate new procedures?

14
00:03:02,374 --> 00:03:06,506
What if it became normal for companies to publicly share their test results?

15
00:03:06,698 --> 00:03:09,770
And what are the degrees of openness in testing

16
00:03:09,850 --> 00:03:14,002
for which we should strive as an industry? I think that

17
00:03:14,056 --> 00:03:17,970
anybody in software, whether they're testers, developer advocate,

18
00:03:18,040 --> 00:03:20,782
reliability engineers, managers,

19
00:03:20,926 --> 00:03:24,766
whoever, can greatly improve the quality of our testing

20
00:03:24,798 --> 00:03:28,850
work if we adopt principles of openness in our testing practices.

21
00:03:29,450 --> 00:03:32,614
To help me explain, I'd like to share how I learned about the main

22
00:03:32,652 --> 00:03:36,390
benefits of open source software and that we can cross those benefits over

23
00:03:36,460 --> 00:03:40,194
into testing work. So let's

24
00:03:40,242 --> 00:03:43,386
go way back in time to when I first encountered open

25
00:03:43,408 --> 00:03:47,414
source software. I first started programming

26
00:03:47,462 --> 00:03:51,126
when I was in high school. At 13 years old, I was an incoming

27
00:03:51,158 --> 00:03:54,874
freshman at Parkville High School in their magnet school for math, science,

28
00:03:54,922 --> 00:03:58,874
and computer science in good old Baltimore,

29
00:03:58,922 --> 00:04:01,374
Maryland. Fun fact,

30
00:04:01,492 --> 00:04:05,220
Parkville's mascots were the Knights, which is my last name.

31
00:04:06,070 --> 00:04:09,874
All students in the magnet program needed to have a Ti 83

32
00:04:09,912 --> 00:04:13,602
plus graphing calculator. Now, mind you,

33
00:04:13,656 --> 00:04:17,486
this was back in the day, before smartphones existed. Flip phones

34
00:04:17,518 --> 00:04:21,458
were the could trend. The Ti 83 plus was cutting edge

35
00:04:21,474 --> 00:04:24,962
handheld technology at that time. It was so advanced

36
00:04:25,026 --> 00:04:28,246
that when I first got it, it took me five minutes to figure out how

37
00:04:28,268 --> 00:04:32,266
to turn it off. Pro tip, hit the second key

38
00:04:32,368 --> 00:04:35,718
and then the on button. I quickly learned

39
00:04:35,734 --> 00:04:39,318
that the TI 83 plus was just a mini computer in disguise.

40
00:04:39,494 --> 00:04:43,054
Did you know that this thing had a full programming language built into

41
00:04:43,092 --> 00:04:45,870
it? Ti basic.

42
00:04:46,290 --> 00:04:50,062
Within the first two weeks of my freshman intro to computer science class,

43
00:04:50,196 --> 00:04:54,446
our teacher taught us how to program math formulas. Things like slope,

44
00:04:54,638 --> 00:04:59,230
circle, circumference, an area, even these quadratic formula.

45
00:04:59,390 --> 00:05:03,710
You name it, I programmed it. Even if it wasn't a frameworks assignment,

46
00:05:03,870 --> 00:05:07,026
it felt awesome. It was more fun to me than

47
00:05:07,048 --> 00:05:10,470
playing video games, and I was a huge Nintendo fan.

48
00:05:11,290 --> 00:05:14,726
These were two extra features of the TI 83 plus. That made it

49
00:05:14,748 --> 00:05:18,434
ideal for programming. First, it had a link cable

50
00:05:18,482 --> 00:05:22,346
for sharing programs. Two people could connect their calculators and

51
00:05:22,368 --> 00:05:26,058
copy programs from one to the other. Needless to say,

52
00:05:26,144 --> 00:05:30,042
with all my formulas, I became quite popular around test

53
00:05:30,096 --> 00:05:34,014
time. Second, anyone could open any

54
00:05:34,052 --> 00:05:37,962
program file on the calculator and read its code. The Ti

55
00:05:38,026 --> 00:05:41,678
basic source code could not be hidden by design.

56
00:05:41,844 --> 00:05:45,506
It was open source. This is

57
00:05:45,528 --> 00:05:49,010
how I learned my very first lesson about open source software.

58
00:05:50,150 --> 00:05:53,586
Open source helps me learn. Whenever I

59
00:05:53,608 --> 00:05:56,718
would copy programs from others, including games,

60
00:05:56,814 --> 00:06:00,120
I would open the program and read the code to see how it worked.

61
00:06:00,650 --> 00:06:03,560
Sometimes I would make changes to improve it.

62
00:06:03,930 --> 00:06:07,830
More importantly, though, many times I would learn something new

63
00:06:07,900 --> 00:06:11,466
that would help me write better programs in the future. This is how

64
00:06:11,488 --> 00:06:14,954
I taught myself to code all on this tiny screen,

65
00:06:15,152 --> 00:06:19,066
all through ripping open other people's code and learning it. And all because the

66
00:06:19,088 --> 00:06:22,686
code was open to me. From the moment I wrote my

67
00:06:22,708 --> 00:06:26,714
first calculator program, I knew I wanted to be a software engineer.

68
00:06:26,842 --> 00:06:30,702
I had that spark. Let's fast forward

69
00:06:30,756 --> 00:06:34,878
to college. I entered the computer science program at Rochester Institute

70
00:06:34,894 --> 00:06:37,730
of Technology. Go tigers.

71
00:06:38,790 --> 00:06:41,726
By my freshman year in college, I had learned Java,

72
00:06:41,838 --> 00:06:45,234
c, a little python, and of all things,

73
00:06:45,352 --> 00:06:49,126
cobalt. All the code in all my projects until that

74
00:06:49,148 --> 00:06:52,918
point had been written entirely by me. Sometimes I

75
00:06:52,924 --> 00:06:56,790
would look at examples in books as a guide, but I never based

76
00:06:56,860 --> 00:06:59,926
other people's code. In fact, if I

77
00:06:59,948 --> 00:07:03,674
had copied code and got caught by a professor, I would have failed these

78
00:07:03,712 --> 00:07:06,954
assignment. Then, in my

79
00:07:06,992 --> 00:07:10,554
first software engineering course, we learned how to write unit tests using

80
00:07:10,592 --> 00:07:13,150
a library called Junit.

81
00:07:13,650 --> 00:07:16,640
We downloaded junit from somewhere online.

82
00:07:17,010 --> 00:07:20,366
This was before Maven became big and we hooked it into our

83
00:07:20,388 --> 00:07:23,742
Java path. Then we shared writing test

84
00:07:23,796 --> 00:07:27,710
classes with test cases as methods, and somehow

85
00:07:27,790 --> 00:07:31,380
it all ran magically in ways I couldn't figure out. At the time,

86
00:07:31,830 --> 00:07:35,362
I was astounded that I could use software that I didn't write myself

87
00:07:35,416 --> 00:07:38,946
in a project. Permission from a professor was one thing,

88
00:07:39,048 --> 00:07:42,694
but the fact that somebody out there in the world was giving away good code

89
00:07:42,732 --> 00:07:46,182
for free just blew my mind. I saw the value

90
00:07:46,236 --> 00:07:49,466
in unit tests, and I immediately saw the value in a simple

91
00:07:49,568 --> 00:07:52,858
free test framework like Junit. That's when

92
00:07:52,864 --> 00:07:55,770
I learned my second lesson about open source software.

93
00:07:57,070 --> 00:08:00,090
Open source helps me become a better developer.

94
00:08:00,510 --> 00:08:04,046
I could have written my own test framework, but that would have taken me a

95
00:08:04,068 --> 00:08:07,310
lot of time. Junit was ready to go

96
00:08:07,380 --> 00:08:11,246
and free to use. Plus, since several individuals had

97
00:08:11,268 --> 00:08:14,462
already spent years developing Junit, it would have

98
00:08:14,596 --> 00:08:18,130
had more features and fewer bugs. Than anything I could develop

99
00:08:18,200 --> 00:08:21,774
on my own. For a college project, using a package

100
00:08:21,822 --> 00:08:25,426
like Junit helped me write and run my unit tests without needing to

101
00:08:25,448 --> 00:08:28,150
become an expert in test automation frameworks.

102
00:08:28,730 --> 00:08:32,790
I could build cool things without needing to build every single component.

103
00:08:33,530 --> 00:08:36,150
That revelation felt empowering.

104
00:08:36,490 --> 00:08:39,562
Within a few years of taking that software engineering course,

105
00:08:39,696 --> 00:08:43,500
suites for hosting open source projects like GitHub became big.

106
00:08:44,270 --> 00:08:48,150
Programming languages had package indexes like Maven,

107
00:08:48,310 --> 00:08:51,170
Nuget, PYPI, and NPM,

108
00:08:51,270 --> 00:08:55,226
which all became mainstays of software development.

109
00:08:55,418 --> 00:08:58,686
The running joke within Python was that you could import

110
00:08:58,788 --> 00:09:02,430
anything. I was living in a future far

111
00:09:02,500 --> 00:09:05,330
from swapping calculator games with link cables.

112
00:09:07,430 --> 00:09:11,022
When I graduated college, I was zealous for open source software.

113
00:09:11,166 --> 00:09:14,926
I believed in it. I was an ardent supporter,

114
00:09:15,118 --> 00:09:17,810
but I was mostly a consumer.

115
00:09:18,790 --> 00:09:22,310
As a software engineer in test I used many major

116
00:09:22,380 --> 00:09:26,306
test tools and frameworks. Junit tests

117
00:09:26,418 --> 00:09:29,626
cucumber, Nunit, Xunit net,

118
00:09:29,728 --> 00:09:32,470
Specflow, Pytest, Jasmine,

119
00:09:32,550 --> 00:09:36,454
Mocha, Selenium, Webdriver, Restsharp rest assured

120
00:09:36,582 --> 00:09:39,580
playwright the list roles on and on.

121
00:09:40,350 --> 00:09:43,834
As a Python developers, I used many modules and frameworks

122
00:09:43,882 --> 00:09:47,182
aside from testing within the Python ecosystem like

123
00:09:47,236 --> 00:09:50,510
Django, requests and flask.

124
00:09:51,650 --> 00:09:54,000
Then I got a chance to give back.

125
00:09:55,010 --> 00:09:58,590
I launched an open source project called Boa Constrictor.

126
00:09:59,010 --> 00:10:02,366
Boa Constrictor is a. Net implementation of these screenplay

127
00:10:02,398 --> 00:10:05,970
pattern helps you make better interactions for better automation

128
00:10:06,490 --> 00:10:10,034
out of the box. It provides Web UI interactions using selenium,

129
00:10:10,082 --> 00:10:13,762
Webdriver and Rest API interactions using rest shared.

130
00:10:13,906 --> 00:10:17,640
But you can use it to implement any interactions that you want.

131
00:10:18,570 --> 00:10:22,454
My company and I released Bo constrictor publicly in October

132
00:10:22,502 --> 00:10:25,930
of 2020. You can check out the code on GitHub.

133
00:10:26,670 --> 00:10:30,186
Originally, my team and I at Q two developers all these code.

134
00:10:30,368 --> 00:10:34,046
We released it as an open source project, hoping that it could help others in

135
00:10:34,068 --> 00:10:37,598
the industry. But then something cool happened.

136
00:10:37,764 --> 00:10:41,466
Folks in the industry helped us. We started receiving

137
00:10:41,498 --> 00:10:44,994
pull requests for new features. In fact, we even

138
00:10:45,032 --> 00:10:49,070
started using some new interactions developed by community members internally

139
00:10:49,150 --> 00:10:52,786
in our company's test automation project. That's when I

140
00:10:52,808 --> 00:10:55,490
learned my third lesson about open source software.

141
00:10:56,390 --> 00:10:59,350
Open source helps me become a better maintainer.

142
00:10:59,770 --> 00:11:02,520
Large projects need all the help they can get.

143
00:11:02,970 --> 00:11:06,520
Even a team of core maintainers can always handle all the work.

144
00:11:07,210 --> 00:11:10,874
However, when a project is open source, anyone who users it

145
00:11:10,912 --> 00:11:14,890
can help out. Each little contribution can add value

146
00:11:14,960 --> 00:11:18,422
for the whole user base. Maintaining software

147
00:11:18,486 --> 00:11:22,730
these becomes easier and the project can become more impactful.

148
00:11:23,330 --> 00:11:26,894
As a software engineer in test, I found myself caught between two

149
00:11:26,932 --> 00:11:30,430
worlds. In one world, I'm a developer at heart

150
00:11:30,500 --> 00:11:34,834
who loves to write code and to solve problems in the other world.

151
00:11:34,952 --> 00:11:38,606
I'm a software quality professional who tests software and advocates

152
00:11:38,638 --> 00:11:42,514
for improvements. These worlds come together primarily through

153
00:11:42,552 --> 00:11:45,090
tests, automation and continuous integration.

154
00:11:46,730 --> 00:11:50,582
However, throughout my entire career, I keep hitting one major

155
00:11:50,636 --> 00:11:53,798
problem. Software quality has a

156
00:11:53,804 --> 00:11:57,320
problem with quality. Let that sink in.

157
00:11:57,690 --> 00:12:01,180
Software quality has a big problem with quality.

158
00:12:01,870 --> 00:12:05,322
Every manual test case repository and every

159
00:12:05,376 --> 00:12:08,566
test automation project I've ever seen is riddled

160
00:12:08,598 --> 00:12:11,654
with duplication. Duplication in the steps,

161
00:12:11,782 --> 00:12:15,630
duplication in the patterns, and duplication in the flaws.

162
00:12:16,450 --> 00:12:20,234
How many times have I seen the same 23 setup steps copy pasted

163
00:12:20,282 --> 00:12:23,806
across 149 test cases? How many

164
00:12:23,828 --> 00:12:27,826
times have I seen automation code use static variables or singletons to

165
00:12:27,848 --> 00:12:30,770
share things globally instead of dependency injection?

166
00:12:31,510 --> 00:12:35,074
How many times have I seen a 90% success rate treated as

167
00:12:35,112 --> 00:12:37,910
a good day with limited flakiness?

168
00:12:39,210 --> 00:12:43,110
How many tests actually cover something valuable and meaningful?

169
00:12:43,930 --> 00:12:47,702
And how can we call ourselves quality professionals when our own work

170
00:12:47,756 --> 00:12:49,340
suffers from poor quality?

171
00:12:51,230 --> 00:12:55,066
Why are all these problems so pervasive? I think they

172
00:12:55,088 --> 00:12:58,294
build up over time. Things like copying and pasting

173
00:12:58,342 --> 00:13:02,170
one time feels innocuous or a rogue variable dont be noticed

174
00:13:02,250 --> 00:13:04,400
or a flaky test is not a big deal.

175
00:13:05,410 --> 00:13:09,006
Once this starts happening, teams instantly keep repeating these

176
00:13:09,028 --> 00:13:10,880
practices until they make a mess.

177
00:13:12,530 --> 00:13:16,640
The developer in me desperately wants to solve these problems, but how?

178
00:13:17,010 --> 00:13:20,194
I can do it in my own projects, but because my

179
00:13:20,232 --> 00:13:23,554
tests are sealed behind company doors, I can't use it to show

180
00:13:23,592 --> 00:13:27,258
others how to do it at scale. And a lot of the articles and courses

181
00:13:27,294 --> 00:13:30,950
and tutorials out there are full of toy examples.

182
00:13:32,330 --> 00:13:35,654
So how do we get teams to break bad habits? I think

183
00:13:35,692 --> 00:13:39,366
our industry needs a culture change. If we could be more open with

184
00:13:39,388 --> 00:13:43,066
testing, like we are open with our source, then perhaps we

185
00:13:43,088 --> 00:13:46,282
could bring many of the benefits we see from open source into

186
00:13:46,336 --> 00:13:49,734
testing. Things like helping people learn testing,

187
00:13:49,862 --> 00:13:53,902
helping people become better testers, and helping people become better test

188
00:13:53,956 --> 00:13:57,326
maintainers. If we cultivate a culture of

189
00:13:57,348 --> 00:14:00,400
openness, then we can lead better practices by example.

190
00:14:01,250 --> 00:14:04,974
Furthermore, if we become transparent about our quality, it could

191
00:14:05,012 --> 00:14:09,006
bolster our users confidence in our products while simultaneously keeping

192
00:14:09,038 --> 00:14:11,300
us motivated to keep quality high.

193
00:14:12,550 --> 00:14:16,174
For the rest of this talk, I'm going to suggest multiple ways to start pushing

194
00:14:16,222 --> 00:14:19,942
for this idea of open testing. Not every

195
00:14:19,996 --> 00:14:23,366
possibility may be applicable for every circumstance, but my

196
00:14:23,388 --> 00:14:27,254
goal for today is to get you all thinking about it. Hopefully these

197
00:14:27,292 --> 00:14:30,300
ideas can inspire better practices for better quality.

198
00:14:31,870 --> 00:14:35,734
For a starting dont of reference, let's consider the least open context

199
00:14:35,782 --> 00:14:39,162
for testing. Imagine a team where testing work is

200
00:14:39,216 --> 00:14:42,446
entirely siloed by role in this

201
00:14:42,468 --> 00:14:46,430
type of team. There is a harsh line between developers and testers.

202
00:14:47,170 --> 00:14:51,210
Only the testers ever see the test cases, access test repositories

203
00:14:51,290 --> 00:14:55,390
or touch automation. Test cases and test plans are essentially

204
00:14:55,470 --> 00:14:59,346
closed to testers due to access readability or

205
00:14:59,368 --> 00:15:02,846
even apathy. The only output

206
00:15:02,878 --> 00:15:06,110
from testers are failure percentages and bug reports.

207
00:15:06,270 --> 00:15:09,430
Results are based more on trust than evidence.

208
00:15:10,090 --> 00:15:13,574
This kind of team sounds pretty bleak. I hope

209
00:15:13,612 --> 00:15:16,600
this isn't the kind of team you're on, but maybe it is.

210
00:15:17,130 --> 00:15:19,660
Let's see how openness can make things better.

211
00:15:21,390 --> 00:15:25,850
The first step towards openness is internal openness.

212
00:15:26,270 --> 00:15:30,006
Let's break down some silos. Testers don't exclusively

213
00:15:30,038 --> 00:15:33,674
own quality. Not everyone needs to be a tester

214
00:15:33,722 --> 00:15:37,790
by title, but everyone on the team should be quality conscious.

215
00:15:38,530 --> 00:15:41,774
In fact, any software development team has three

216
00:15:41,812 --> 00:15:45,314
major roles, business developers and

217
00:15:45,352 --> 00:15:48,722
testing. Business looks

218
00:15:48,776 --> 00:15:52,334
for what problems to solve. Development addresses

219
00:15:52,382 --> 00:15:56,218
how to implement solutions, and testing provides feedback

220
00:15:56,254 --> 00:15:59,974
on these solution. These three roles together are

221
00:16:00,012 --> 00:16:03,494
known as the three amigos, or sometimes also called the

222
00:16:03,532 --> 00:16:06,994
three hats. Each role

223
00:16:07,042 --> 00:16:10,250
offers a valuable perspective with unique expertise.

224
00:16:11,070 --> 00:16:14,906
When the three amigos stay apart, features under development don't have

225
00:16:14,928 --> 00:16:18,214
the benefit of multiple perspectives. They might have serious

226
00:16:18,262 --> 00:16:21,898
design flaws, they might be unreasonable to implement, or they

227
00:16:21,904 --> 00:16:26,026
might be difficult to test. Misunderstandings could also cause developers

228
00:16:26,058 --> 00:16:29,710
to build the wrong things or testers to write useless tests.

229
00:16:30,690 --> 00:16:33,822
On the other hand, when the three amigos get together,

230
00:16:33,956 --> 00:16:37,170
they can jointly contribute to the design of product features.

231
00:16:37,510 --> 00:16:41,154
Everyone can get on the same page. The team can

232
00:16:41,192 --> 00:16:43,780
build quality into the product from the start.

233
00:16:44,310 --> 00:16:48,610
They can do activities like question storming and example mapping

234
00:16:48,690 --> 00:16:50,710
to help them define behaviors.

235
00:16:52,490 --> 00:16:56,178
As part of this collaboration, not everyone may end up writing tests,

236
00:16:56,274 --> 00:16:58,680
but everyone will be thinking about quality.

237
00:16:59,630 --> 00:17:03,286
Testing then becomes easier because expected behaviors are well defined

238
00:17:03,318 --> 00:17:06,806
and well understood, testers get deeper insights

239
00:17:06,838 --> 00:17:10,134
into what is important to cover. When testers

240
00:17:10,182 --> 00:17:13,690
share results in open bugs, other teams members are more receptive

241
00:17:13,770 --> 00:17:16,510
because the feedback is more meaningful and valuable.

242
00:17:17,410 --> 00:17:20,606
We practiced three Amigos collaboration at my previous company.

243
00:17:20,708 --> 00:17:23,950
Q two, I'd like you to meet my friend Steve.

244
00:17:24,310 --> 00:17:28,126
Steve was a developer who saw value in example mapping.

245
00:17:28,318 --> 00:17:31,586
Many times he'd pick up poorly defined user stories with

246
00:17:31,608 --> 00:17:34,770
conflicting information or missing acceptance criteria.

247
00:17:35,350 --> 00:17:38,482
Sometimes he'd burn a whole sprint just trying to figure out

248
00:17:38,536 --> 00:17:42,102
things. Once he learned about example mapping, he started

249
00:17:42,156 --> 00:17:45,734
setting up half hour sessions with the other two amigos, one of whom was

250
00:17:45,772 --> 00:17:49,962
me, to better understand users stories from the start. And he

251
00:17:50,016 --> 00:17:53,510
got into it. Thanks to proactive collaboration,

252
00:17:53,670 --> 00:17:55,930
he could develop the stories more smoothly.

253
00:17:56,670 --> 00:18:00,362
One time I remember we stopped working on a story because

254
00:18:00,416 --> 00:18:04,302
we couldn't justify its business value, which saved Steve. But two

255
00:18:04,356 --> 00:18:08,734
weeks worth of pointless work story doesn't end there.

256
00:18:08,932 --> 00:18:12,986
Steve is now a software engineer in test. He shifted

257
00:18:13,018 --> 00:18:16,450
left so hard that he shifted into a whole new role.

258
00:18:17,030 --> 00:18:20,354
He's become a champion for quality in our products and I was

259
00:18:20,392 --> 00:18:24,594
blessed to work with him. Another step

260
00:18:24,632 --> 00:18:28,434
toward open testing is living documentation through specification

261
00:18:28,482 --> 00:18:31,942
by example. Collaboration like we saw

262
00:18:31,996 --> 00:18:35,378
with the three amigos is great, but the value it provides

263
00:18:35,474 --> 00:18:38,120
can be fleeting if it is not written down.

264
00:18:38,910 --> 00:18:42,502
Teams need artifacts to record designs, examples,

265
00:18:42,566 --> 00:18:46,326
and eventually test cases. One of the reasons

266
00:18:46,358 --> 00:18:50,026
why I love example mapping is because it facilitates a

267
00:18:50,048 --> 00:18:52,714
teams to spell, but stories, rules,

268
00:18:52,842 --> 00:18:56,654
examples and questions onto color coded cards that they

269
00:18:56,692 --> 00:18:58,590
can keep for future refinement.

270
00:18:59,730 --> 00:19:04,070
Stories become work items, rules become acceptance criteria,

271
00:19:04,250 --> 00:19:07,602
examples become test cases, and questions become

272
00:19:07,656 --> 00:19:11,314
suites or future stories. To learn

273
00:19:11,352 --> 00:19:14,980
more about example mapping, check out this article after my talk.

274
00:19:16,170 --> 00:19:20,120
During example mapping, folks typically write cards quickly.

275
00:19:20,490 --> 00:19:24,070
An example card describes a behavior to test, but it might not

276
00:19:24,140 --> 00:19:27,462
carefully design these scenario. It needs

277
00:19:27,516 --> 00:19:31,274
further refinement. Defining behaviors using

278
00:19:31,312 --> 00:19:35,014
a clear, concise format like given when then makes behaviors

279
00:19:35,062 --> 00:19:37,580
easy to understand and easy to test.

280
00:19:39,150 --> 00:19:42,894
For example, let's say we wanted to test a web search engine.

281
00:19:43,092 --> 00:19:46,430
The example could be to search for a phrase like panda.

282
00:19:47,170 --> 00:19:51,182
We could write this example as the following scenario given

283
00:19:51,236 --> 00:19:55,086
the search engine page is displayed when the user searches

284
00:19:55,118 --> 00:19:58,914
for the phrase panda. Then the result page shows a

285
00:19:58,952 --> 00:20:02,562
list of links for panda. This special given

286
00:20:02,616 --> 00:20:06,126
when then format is known as the Gerkin language.

287
00:20:06,318 --> 00:20:10,578
Gerkin comes from behavior driven development tools like cucumber,

288
00:20:10,754 --> 00:20:13,510
but it can be helpful for any kind of testing.

289
00:20:13,930 --> 00:20:17,414
Gerkin defines testable behaviors in a concise way that

290
00:20:17,452 --> 00:20:21,114
follows the arrange act assert pattern. You set things up,

291
00:20:21,232 --> 00:20:24,650
you interact with the feature and you verify the outcomes.

292
00:20:25,630 --> 00:20:29,660
Furthermore, Gerkin encourages specification by example.

293
00:20:30,270 --> 00:20:33,486
This scenario provides clear instructions on how to perform a

294
00:20:33,508 --> 00:20:37,338
search. It has real data, which is the search phrase,

295
00:20:37,514 --> 00:20:40,862
and clear results. Using real

296
00:20:40,916 --> 00:20:44,862
world examples and specifications like this helps all three amigos

297
00:20:44,926 --> 00:20:47,090
understand the precise behavior.

298
00:20:49,430 --> 00:20:52,770
Behavior specifications are multifaceted artifacts.

299
00:20:53,350 --> 00:20:56,770
These are requirements that define how a feature should behave.

300
00:20:57,590 --> 00:21:01,126
These are acceptance criteria that must be met for a deliverable to be

301
00:21:01,148 --> 00:21:04,614
complete. They are test cases with clear

302
00:21:04,652 --> 00:21:08,558
instructions. They could become automated scripts

303
00:21:08,594 --> 00:21:12,554
with the right kind of test framework and ultimately these

304
00:21:12,592 --> 00:21:14,780
are living documentation for the product.

305
00:21:15,470 --> 00:21:18,646
Living documentation is open and powerful.

306
00:21:18,838 --> 00:21:22,526
Anyone on the team or outside the team can read it to learn about

307
00:21:22,548 --> 00:21:26,458
the product. Refining ideas into example cards

308
00:21:26,634 --> 00:21:30,282
into behavior specs becomes a pipeline that delivers

309
00:21:30,346 --> 00:21:34,350
living doc as a byproduct of the software development cycle.

310
00:21:36,470 --> 00:21:40,030
Specflow is one of the best frameworks that supports this type of openness,

311
00:21:40,110 --> 00:21:43,250
with specification by example and living documentation.

312
00:21:43,830 --> 00:21:47,030
Specflow is a free and open source automation framework for.

313
00:21:47,100 --> 00:21:50,626
Net. In Specflow, you write your test cases as Gerkin

314
00:21:50,658 --> 00:21:54,358
scenarios and you automate each given one then step using

315
00:21:54,444 --> 00:21:58,306
C sharp methods. One of Specflow's niftiest

316
00:21:58,338 --> 00:22:02,314
features, however, is Specflow plus living doc. Most test

317
00:22:02,352 --> 00:22:05,866
frameworks focus exclusively on automation code. When a

318
00:22:05,888 --> 00:22:09,994
test is automated, then only a programmer can read it and understand it.

319
00:22:10,192 --> 00:22:14,190
Gherkin makes this easier because steps are written in plain language,

320
00:22:14,530 --> 00:22:18,430
but Gerkin scenarios are nevertheless stored in the automation repository,

321
00:22:18,770 --> 00:22:20,800
inaccessible to many team members.

322
00:22:21,970 --> 00:22:25,274
Speclow plus living doc breaks that pattern. It turns

323
00:22:25,322 --> 00:22:28,514
gherkin scenarios into a searchable doc site accessible to all

324
00:22:28,552 --> 00:22:32,110
three amigos. It makes test cases and test automation

325
00:22:32,190 --> 00:22:35,882
much more open. Furthermore,

326
00:22:35,966 --> 00:22:39,510
notice how living doc provides test results for each scenario.

327
00:22:39,930 --> 00:22:43,954
Green check marks indicate passing tests, while Red X's indicate

328
00:22:44,002 --> 00:22:47,782
failures. Historically, testers use reports like this

329
00:22:47,836 --> 00:22:51,050
to provide feedback in house to their managers and developers.

330
00:22:51,630 --> 00:22:55,050
Results indicate what works and what needs to be fixed.

331
00:22:55,790 --> 00:22:59,354
However, test results can be useful to more people than just

332
00:22:59,472 --> 00:23:03,498
internal team members. What if test results were shared with users

333
00:23:03,514 --> 00:23:07,294
and customers? I'm going to pause and say that again because

334
00:23:07,332 --> 00:23:11,534
it might seem shocking. What if users and customers

335
00:23:11,652 --> 00:23:15,554
could see test results? Think about it.

336
00:23:15,752 --> 00:23:18,930
Open test results have very positive effects.

337
00:23:19,430 --> 00:23:22,020
Transparency with users builds trust.

338
00:23:22,470 --> 00:23:25,714
If users can see that things are tested and working,

339
00:23:25,912 --> 00:23:29,000
then they will gain confidence in the quality of the product.

340
00:23:29,690 --> 00:23:33,094
If they could peer into these living documentation, then they

341
00:23:33,132 --> 00:23:35,800
could learn how to use the product even better.

342
00:23:36,570 --> 00:23:40,614
On the flip side, transparency holds development teams accountable

343
00:23:40,662 --> 00:23:44,186
to keeping quality high both in the product and in

344
00:23:44,208 --> 00:23:47,722
the testing. Open test results offer

345
00:23:47,776 --> 00:23:50,646
these benefits only if the results can be trusted.

346
00:23:50,838 --> 00:23:54,782
If test results are useless or failures are rampant, then public test

347
00:23:54,836 --> 00:23:57,840
results could actually hurt the ones developing the product.

348
00:23:59,810 --> 00:24:04,266
This type of radical transparency would require an enormous culture shift.

349
00:24:04,458 --> 00:24:08,494
May not be appropriate for every single company to create public dashboards

350
00:24:08,542 --> 00:24:12,514
with all their test results, but it could be a strategic differentiator when used

351
00:24:12,552 --> 00:24:15,714
wisely. For example, when I worked at Q

352
00:24:15,752 --> 00:24:19,666
two, we shared this very living doc report with specific precision

353
00:24:19,698 --> 00:24:22,390
lender customers every two week release.

354
00:24:23,050 --> 00:24:25,640
It built trust and kept the contracts moving.

355
00:24:26,410 --> 00:24:29,530
Plus, because the living doc report included only

356
00:24:29,600 --> 00:24:32,998
high level behavior specifications with simple results,

357
00:24:33,174 --> 00:24:36,970
even a vice president could read it. We could share these

358
00:24:37,040 --> 00:24:40,140
tests without sharing automation code.

359
00:24:42,590 --> 00:24:46,490
Let's keep extending open testing outward. In addition to

360
00:24:46,560 --> 00:24:50,254
sharing test results in living documentation, folks can also

361
00:24:50,292 --> 00:24:54,090
share test tools, frameworks, and other parts of their tests.

362
00:24:54,250 --> 00:24:57,570
This is where open testing truly is. Open source

363
00:24:58,950 --> 00:25:02,450
we already saw a bunch of open source projects for test automation.

364
00:25:02,870 --> 00:25:07,410
As an industry, we are truly blessed with so many incredible projects.

365
00:25:07,830 --> 00:25:11,206
Every single one of these logos represents a team of testers who

366
00:25:11,228 --> 00:25:14,646
not only solved a problem, but decided to share their solution with

367
00:25:14,668 --> 00:25:18,166
the world. Each solution is abstract enough to

368
00:25:18,188 --> 00:25:21,434
apply to many circumstances, but concrete enough to

369
00:25:21,472 --> 00:25:24,822
provide a helpful implementation. Collectively,

370
00:25:24,886 --> 00:25:28,506
the projects on this page have probably been downloaded more than a

371
00:25:28,528 --> 00:25:31,910
billion times, and that's no joke. And if

372
00:25:31,920 --> 00:25:35,600
you want, you could read the open source code for any of them.

373
00:25:37,810 --> 00:25:40,974
So far, all the ways of approaching open testing are

374
00:25:41,012 --> 00:25:45,246
things we could do today. Many of us are probably already doing these things,

375
00:25:45,348 --> 00:25:48,846
even if we didn't think of them under the phrase open testing.

376
00:25:49,038 --> 00:25:52,674
But where can these ideas go in the future? My mind

377
00:25:52,712 --> 00:25:56,130
goes back to one of the big problems in testing that I mentioned earlier,

378
00:25:56,650 --> 00:26:00,118
duplication. Opening up

379
00:26:00,204 --> 00:26:03,842
collaboration fixes some based habits and sharing components

380
00:26:03,906 --> 00:26:07,266
eliminates some duplication in the plumbing of test automation.

381
00:26:07,458 --> 00:26:11,174
But so many of our tests across the industry repeat

382
00:26:11,222 --> 00:26:14,806
the same kinds of steps and follow the same types

383
00:26:14,838 --> 00:26:18,474
of patterns. For example,

384
00:26:18,672 --> 00:26:21,790
think. But anytime you've ordered something from an online store,

385
00:26:21,940 --> 00:26:24,618
it could be Amazon, Walmart,

386
00:26:24,794 --> 00:26:28,814
Target, whatever. Every single online store

387
00:26:28,852 --> 00:26:33,006
has a virtual shopping cart. Whenever you want to buy something,

388
00:26:33,108 --> 00:26:36,594
you add it to your cart. Then, when you're done

389
00:26:36,632 --> 00:26:39,890
shopping, you proceed to pay for all the items in your cart.

390
00:26:40,230 --> 00:26:43,858
If you decide you don't want something more, you remove it

391
00:26:43,864 --> 00:26:47,746
from your cart. Easy peasy. As I

392
00:26:47,768 --> 00:26:51,286
describe this type of shopping cart, I don't need to show you screenshots from the

393
00:26:51,308 --> 00:26:54,486
store website to explain it. Y'all have done so much

394
00:26:54,508 --> 00:26:57,366
online shopping that you intuitively know how it works,

395
00:26:57,468 --> 00:27:01,126
regardless of the store. Heck, I recently ordered

396
00:27:01,158 --> 00:27:04,790
a bunch of parts from an old Volkswagen beetle from a site named JBugs,

397
00:27:04,870 --> 00:27:06,780
and the shopping cart was the same.

398
00:27:07,870 --> 00:27:11,294
If so many applications have the same parts these,

399
00:27:11,332 --> 00:27:14,590
why do we keep duplicating the same test in different places?

400
00:27:15,250 --> 00:27:19,134
Think about it. Think about how many times different teams have

401
00:27:19,172 --> 00:27:21,950
written nearly identical shopping cart tests.

402
00:27:22,370 --> 00:27:26,066
Ouch. Think about how much time was wasted on

403
00:27:26,088 --> 00:27:29,586
that duplication of effort. I think

404
00:27:29,608 --> 00:27:33,060
these is something where artificial intelligence and machine learning could help.

405
00:27:33,510 --> 00:27:37,126
What if we could develop machine learning models to learn common behaviors for

406
00:27:37,148 --> 00:27:41,030
apps and services? The learning agents

407
00:27:41,100 --> 00:27:44,562
would look for things like standard icons and typical workflows.

408
00:27:44,706 --> 00:27:48,190
We could essentially create test suites for things like login,

409
00:27:48,370 --> 00:27:52,454
search, shopping, and payment that could run successfully

410
00:27:52,502 --> 00:27:55,690
on most apps. These types of tests probably

411
00:27:55,760 --> 00:27:59,494
couldn't cover everything in a given application, but they could cover basic

412
00:27:59,542 --> 00:28:03,054
common behaviors. Maybe that could cover a

413
00:28:03,092 --> 00:28:06,400
quarter of all behaviors worth testing, maybe a third,

414
00:28:06,930 --> 00:28:10,830
maybe even a half. Hey, every little bit helps.

415
00:28:12,210 --> 00:28:15,978
Now imagine sharing those generic test suites publicly.

416
00:28:16,154 --> 00:28:19,586
In the same way developers have open source projects to help expedite their

417
00:28:19,608 --> 00:28:23,474
coding, and in the same way data scientists have open data sets used

418
00:28:23,512 --> 00:28:27,234
for modeling. Testers could have open test suites

419
00:28:27,282 --> 00:28:30,902
that they could pick up and run as applicable, not test

420
00:28:30,956 --> 00:28:34,946
tools, but actual runnable tests

421
00:28:35,138 --> 00:28:38,886
that could run against any application. If these kinds of test

422
00:28:38,908 --> 00:28:42,442
suites proved to be valuable, then prominent ones could become

423
00:28:42,496 --> 00:28:46,090
universally accepted bars of quality for software apps.

424
00:28:46,510 --> 00:28:49,574
For example, in the future, companies could download

425
00:28:49,622 --> 00:28:52,702
and execute run on any system tests for

426
00:28:52,756 --> 00:28:56,494
the apps that they're developing, in addition to these tests that they develop in

427
00:28:56,532 --> 00:29:00,320
house. I think that could be a really cool opportunity.

428
00:29:03,570 --> 00:29:06,770
So as we've covered, open testing could take

429
00:29:06,840 --> 00:29:10,382
many forms. It could be openings in collaboration

430
00:29:10,446 --> 00:29:13,666
to build better quality from the start. It could

431
00:29:13,688 --> 00:29:17,430
be openness in specification by example and living documentation.

432
00:29:18,650 --> 00:29:22,870
It could be openness in sharing tests and their results with customers and users.

433
00:29:23,930 --> 00:29:27,910
It could be openness in sharing tools, frameworks and platforms.

434
00:29:28,970 --> 00:29:33,370
It could be openings in building shared test sets for common application behaviors.

435
00:29:34,670 --> 00:29:38,438
Some of these ideas may seem far fetched or aspirational,

436
00:29:38,614 --> 00:29:42,430
but quite honestly, I think each of them could add lets of value to

437
00:29:42,500 --> 00:29:46,414
existing testing practices. I think every testers and every

438
00:29:46,452 --> 00:29:49,040
test team should look at this list and ask,

439
00:29:49,410 --> 00:29:52,240
hmm, could we try some of these?

440
00:29:52,770 --> 00:29:56,162
Perhaps a team could take baby steps with better collaboration and better

441
00:29:56,216 --> 00:29:59,906
specification. Perhaps a team has a cool project they

442
00:29:59,928 --> 00:30:03,666
built in house that they could release as an open source project, like I

443
00:30:03,688 --> 00:30:07,126
did with BoA constrictor. Perhaps there's a

444
00:30:07,148 --> 00:30:11,778
startup idea in using machine learning to generate tests. Who knows?

445
00:30:11,954 --> 00:30:15,814
Could be cool. Perhaps there are other ways

446
00:30:15,852 --> 00:30:18,886
to achieve open testing that aren't covered here.

447
00:30:19,068 --> 00:30:21,990
What do y'all think? These are just my ideas.

448
00:30:22,150 --> 00:30:24,540
I'm sure y'all out there have even better ones.

449
00:30:26,430 --> 00:30:30,166
We should also consider the flip side. Are there certain aspects

450
00:30:30,198 --> 00:30:33,726
of testing that should remain closed? My mind goes to

451
00:30:33,748 --> 00:30:37,594
security. Could fully open testing inadvertently reveal

452
00:30:37,642 --> 00:30:41,214
security vulnerabilities? Could lack of coverage in some

453
00:30:41,252 --> 00:30:44,370
areas? Welcome expedited exploitation?

454
00:30:45,110 --> 00:30:48,834
I don't know, but I think we should consider negative consequences like

455
00:30:48,872 --> 00:30:49,460
these.

456
00:30:52,150 --> 00:30:56,202
My goal in today's talk is to inspire conversations about open testing.

457
00:30:56,366 --> 00:31:00,310
So here are these questions to jumpstart those conversations.

458
00:31:01,370 --> 00:31:04,360
Number one, how is your testing today?

459
00:31:04,810 --> 00:31:08,278
In what ways is it already open, and in what ways is

460
00:31:08,284 --> 00:31:09,290
it closed?

461
00:31:11,230 --> 00:31:14,566
Question two how could you improve your testing

462
00:31:14,598 --> 00:31:18,326
with incremental openness? We're talking baby steps

463
00:31:18,358 --> 00:31:22,254
here. Small improvements that you could easily achieve today

464
00:31:22,452 --> 00:31:25,978
could be as small as trying example mapping or joining

465
00:31:25,994 --> 00:31:29,760
a mob programming session in question three,

466
00:31:30,210 --> 00:31:33,470
how could your testing improve with radical openness?

467
00:31:33,830 --> 00:31:38,030
Shoot the moon. Dream big. Get creative.

468
00:31:38,190 --> 00:31:41,060
In the world of software, anything is possible.

469
00:31:43,030 --> 00:31:46,806
We should also remember that open testing isn't a goal unto itself,

470
00:31:46,988 --> 00:31:51,000
it's a means to an end. And that end is higher quality,

471
00:31:51,530 --> 00:31:54,946
quality in our practices, quality in our artifacts,

472
00:31:55,058 --> 00:31:58,360
and ultimately, quality in the software we create.

473
00:31:58,890 --> 00:32:02,502
We shouldn't seek openness in testing just because I'm up here on stage

474
00:32:02,566 --> 00:32:05,850
or behind the zoom sessions spouting a ton of buzzwords

475
00:32:06,350 --> 00:32:09,340
these same time. Don't be so quick to brush them off.

476
00:32:10,110 --> 00:32:13,790
We should always be seeking ways for perpetual improvement.

477
00:32:14,370 --> 00:32:17,950
Remember that this whole idea of open testing came from the benefits

478
00:32:18,100 --> 00:32:21,680
of open source code, and they have been tried and true.

479
00:32:23,410 --> 00:32:26,846
So thank you for listening to my talk today. Again, my name

480
00:32:26,868 --> 00:32:30,186
is Andy Dyte and I'm the automation Panda. I'm a developer advocate

481
00:32:30,218 --> 00:32:33,966
at app tools and director of Test Automation University. Be sure

482
00:32:33,988 --> 00:32:37,206
to read my blog and follow me on Twitter at automation and Panda. I hope

483
00:32:37,228 --> 00:32:40,326
you feel inspired to pursue open testing, and I'd love to

484
00:32:40,348 --> 00:32:44,630
spark up a conversation, so enjoy the rest of comp 42 suites.

485
00:32:44,700 --> 00:32:46,930
Reliability engineering bye.

