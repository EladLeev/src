1
00:02:11,170 --> 00:02:11,920
Youll.

2
00:02:15,010 --> 00:02:18,762
Hello, everyone. Welcome to Conf 42 site Reliability

3
00:02:18,826 --> 00:02:22,446
Engineering. My name is Ricardo Castro, and today we're going

4
00:02:22,468 --> 00:02:26,554
to talk about alerting on slos and what are error budget policies

5
00:02:26,602 --> 00:02:30,126
and how we can leverage them. So what we have on the

6
00:02:30,148 --> 00:02:33,774
menu, for starters, we're going to set up some

7
00:02:33,812 --> 00:02:37,334
context. So we're going to talk about slos. Slos are all about

8
00:02:37,372 --> 00:02:41,334
reliability. So it's easier if we have some ground knowledge to

9
00:02:41,372 --> 00:02:45,334
actually build on top of these concepts of reliability and then talk about

10
00:02:45,372 --> 00:02:48,534
alerts and effort budget policies. We'll then

11
00:02:48,572 --> 00:02:52,118
talk about some reliability concepts. So we're going to talk about slos, but we

12
00:02:52,124 --> 00:02:55,306
need to talk about all the things that encompass slos. So we need

13
00:02:55,328 --> 00:02:58,646
to talk about the foundation that gives us slos.

14
00:02:58,678 --> 00:03:02,282
We need to talk about metrics and slis, and we will then talk about

15
00:03:02,336 --> 00:03:05,470
company concepts like error budget and slos.

16
00:03:06,130 --> 00:03:09,246
We'll then get to the good part where we are going to talk about how

17
00:03:09,268 --> 00:03:12,954
we can alert on slos and what are error budget policies

18
00:03:13,002 --> 00:03:16,526
and how can we leverage them. And at the end, we're just going to conclude

19
00:03:16,558 --> 00:03:18,660
on why all of this is important.

20
00:03:19,510 --> 00:03:23,650
So let's start by setting some context to our discussion.

21
00:03:24,710 --> 00:03:27,974
An example from the real world that we can think

22
00:03:28,012 --> 00:03:31,654
of and draw parallel to our reality is

23
00:03:31,772 --> 00:03:35,890
a supermarket. So if we think a little bit about it, a supermarket

24
00:03:35,970 --> 00:03:39,574
is kind of a microservices architecture. So the idea is

25
00:03:39,612 --> 00:03:43,334
that me as a user go into a supermarket, I do my shopping

26
00:03:43,382 --> 00:03:47,142
and I go out. What happens in reality

27
00:03:47,206 --> 00:03:50,998
is that there are many, many things that happen underneath the covers

28
00:03:51,014 --> 00:03:54,714
that make it possible for me to do this transaction. So for me

29
00:03:54,752 --> 00:03:58,030
as a user, I just want to go in, select the things that I want,

30
00:03:58,100 --> 00:04:01,674
I pay, and I get out. But that means thats there is a cashier

31
00:04:01,722 --> 00:04:04,846
to register everything and receive payments. That means there

32
00:04:04,868 --> 00:04:08,338
are people that get stuff from the warehouse and put stuff available for me to

33
00:04:08,344 --> 00:04:12,718
do my shopping. There's also people that need to put orders to ensure

34
00:04:12,814 --> 00:04:16,674
thats stuff gets at the supermarket. There's people that do

35
00:04:16,712 --> 00:04:20,302
the unloading from trucks to inside the supermarket. There's butchers,

36
00:04:20,366 --> 00:04:23,622
there's people that work on the Fisher stand. So there's a lot of stuff

37
00:04:23,676 --> 00:04:27,206
that's going on underneath the covers that actually make it possible that

38
00:04:27,228 --> 00:04:30,698
I can do this transaction. So, like a microservice, I interact with

39
00:04:30,784 --> 00:04:34,586
an application, and that means there are maybe a lot of services that

40
00:04:34,608 --> 00:04:37,930
are working together to provide the functionalities that are required.

41
00:04:40,910 --> 00:04:44,282
So what does that mean exactly? To be reliable?

42
00:04:44,346 --> 00:04:48,122
Let's still look at this example of a supermarket.

43
00:04:48,186 --> 00:04:52,030
So I did my shopping, I want to pay, how can thats

44
00:04:52,100 --> 00:04:55,646
action might not be reliable. So if it's taking too long to

45
00:04:55,668 --> 00:04:58,866
pay, if I have to stay half an hour on a queue just to be

46
00:04:58,888 --> 00:05:02,690
able to pay, I might consider that thats service is not being reliable.

47
00:05:04,710 --> 00:05:09,314
One other aspect for example is when I go into pick

48
00:05:09,352 --> 00:05:12,994
up some product, if the product expiration date has passed,

49
00:05:13,042 --> 00:05:16,326
I might say that this service is not being reliable. And we

50
00:05:16,348 --> 00:05:19,826
can draw a quick parallel between this reality and the reality

51
00:05:19,858 --> 00:05:23,286
of the tech world by saying that an analogous

52
00:05:23,318 --> 00:05:26,906
concept for taking too long to pay is that of

53
00:05:26,928 --> 00:05:30,634
latency. Whether a request for example, takes too long to be served and

54
00:05:30,672 --> 00:05:34,314
a product expiration date being passed might mean can error.

55
00:05:34,362 --> 00:05:36,160
So this wasn't supposed to happen.

56
00:05:37,250 --> 00:05:41,390
So going a bit further on what reliability means,

57
00:05:41,460 --> 00:05:45,246
and looking at our reality more into the tech side. So I

58
00:05:45,268 --> 00:05:49,426
work at a company called AnovA, and at Anova we

59
00:05:49,448 --> 00:05:52,546
work in industrial IoT service. So we provide services

60
00:05:52,648 --> 00:05:56,226
to our customers. These numbers are a little bit outdated, but we have more

61
00:05:56,248 --> 00:05:59,846
than 2000 customers worldwide, we operate in more than 80 countries and

62
00:05:59,868 --> 00:06:03,686
we monitor more than 1 million assets. So what

63
00:06:03,708 --> 00:06:06,866
we do is that we get data from industrial sensors,

64
00:06:06,898 --> 00:06:10,874
we process them, we store them, and then we apply things like machine learning and

65
00:06:10,992 --> 00:06:15,178
AI, and build applications that allow our customers

66
00:06:15,264 --> 00:06:18,060
to actually provide good service to their customers.

67
00:06:19,630 --> 00:06:22,846
And this means that we need a way and

68
00:06:22,868 --> 00:06:26,298
a framework to actually ensure thats our systems

69
00:06:26,314 --> 00:06:30,494
are being reliable. And ideally we want to be alerted when something is

70
00:06:30,532 --> 00:06:34,478
not being reliable in us. So what does reliability mean

71
00:06:34,564 --> 00:06:38,810
exactly? If we look at the dictionary,

72
00:06:38,970 --> 00:06:42,674
the Cambridge dictionary, in this example, we can see a definition that says

73
00:06:42,712 --> 00:06:46,706
that the quality of being able to be trusted or believed because

74
00:06:46,808 --> 00:06:50,134
of working or behaving well. So in essence this means

75
00:06:50,172 --> 00:06:54,198
that something is reliable if it's behaving well. And this

76
00:06:54,284 --> 00:06:57,814
is a bit rough. So I like the definition from

77
00:06:57,852 --> 00:07:01,430
Alex Giftalgov's book, implementing service level objectives,

78
00:07:01,510 --> 00:07:04,694
actually a better way to define reliability. So in essence,

79
00:07:04,742 --> 00:07:08,742
what Alex says is that reliability

80
00:07:08,806 --> 00:07:12,506
can be defined by our users. So the answer to

81
00:07:12,528 --> 00:07:16,814
the question is my service being reliable? Is my service doing thats

82
00:07:16,932 --> 00:07:20,798
its users needed to do? So? If we look at reliability from the point of

83
00:07:20,804 --> 00:07:25,022
view of our users, if they are satisfied, my service is being reliable.

84
00:07:25,166 --> 00:07:27,620
So how can you actually measure this?

85
00:07:28,550 --> 00:07:32,046
And now let's start our discussion about the founding concepts

86
00:07:32,078 --> 00:07:35,410
that will actually lead us to slos and the other concepts.

87
00:07:36,710 --> 00:07:39,842
And the most fundamental concept is the concept of the metric.

88
00:07:39,986 --> 00:07:43,350
And the metric is nothing more than a measurement about something

89
00:07:43,420 --> 00:07:46,582
in my system. So if an event happens,

90
00:07:46,636 --> 00:07:49,958
and I take a measurement on that. So let's imagine a

91
00:07:49,964 --> 00:07:53,402
few examples that we have here. So the amount of memory that the server is

92
00:07:53,456 --> 00:07:56,774
using, the time it takes for an HTTP request

93
00:07:56,822 --> 00:07:59,718
to be fulfilled. So for example, in milliseconds,

94
00:07:59,894 --> 00:08:03,034
the number of HTTP responses that

95
00:08:03,072 --> 00:08:06,506
are can error, or how old the message is when it arrives

96
00:08:06,538 --> 00:08:10,302
at a Kafka cluster. So these are just measurements. An event happens and we take

97
00:08:10,356 --> 00:08:12,480
some kind of measurement about that event.

98
00:08:15,010 --> 00:08:18,174
Building on top of metrics, we have the concept of an SLI,

99
00:08:18,302 --> 00:08:22,350
and an SLI is a quantifiable measure of service reliability.

100
00:08:22,510 --> 00:08:26,754
So an SLI is what's going to allow us to say that if

101
00:08:26,792 --> 00:08:30,374
a measurement is actually good or bad, or an event is good or

102
00:08:30,412 --> 00:08:32,840
bad. But how can we define that?

103
00:08:33,370 --> 00:08:37,074
So we need to achieve a binary state, even if the metric

104
00:08:37,122 --> 00:08:40,440
itself doesn't gives us that out of the box.

105
00:08:41,070 --> 00:08:44,886
So here are a few examples of how we can define

106
00:08:44,918 --> 00:08:48,394
an SLI. So we can say that requests to a service

107
00:08:48,512 --> 00:08:52,234
need to be responded within 200 milliseconds. So thats

108
00:08:52,272 --> 00:08:55,774
means if I serve a request, I can measure how long

109
00:08:55,812 --> 00:08:59,486
it took. If it was more than 200 milliseconds, I can say

110
00:08:59,508 --> 00:09:02,954
that it wasn't a good event. If it was 200 milliseconds

111
00:09:03,002 --> 00:09:05,700
or less, I can say that it was a good event.

112
00:09:06,390 --> 00:09:10,034
In analogous we can say that if a response got

113
00:09:10,072 --> 00:09:13,282
a 500 code, it is not good.

114
00:09:13,336 --> 00:09:16,898
If it got another code, it's actually a good event. And the

115
00:09:16,904 --> 00:09:20,534
same thing for Kafka messages. If the Kafka message that arrived is

116
00:09:20,572 --> 00:09:23,874
older than five minutes, we might say that it's not a good event. If it's

117
00:09:23,922 --> 00:09:26,600
younger than five minutes, it is actually a good event.

118
00:09:28,410 --> 00:09:31,830
Building on top of slis, we have the concept of slos,

119
00:09:31,990 --> 00:09:36,010
and slos actually define how many times an SLI needs

120
00:09:36,080 --> 00:09:39,546
to actually be good, so that my

121
00:09:39,568 --> 00:09:43,050
users are happy and thats needs to be time bound.

122
00:09:43,630 --> 00:09:47,662
So here are a few examples. We can say that 99%

123
00:09:47,716 --> 00:09:52,282
of requests to a service need to be responded within 200 milliseconds

124
00:09:52,346 --> 00:09:56,174
within a 30 day period. The same way

125
00:09:56,212 --> 00:10:00,350
we can say that 95% of requests to a services need to be responded

126
00:10:00,430 --> 00:10:04,078
with a code thats is different, thats 500 within a seven day period.

127
00:10:04,254 --> 00:10:07,506
And same thing, 99.99% of

128
00:10:07,528 --> 00:10:10,694
messages arriving at a Kafka cluster must

129
00:10:10,732 --> 00:10:14,898
not be older than five minutes within a 24 hours period. So essentially

130
00:10:14,994 --> 00:10:19,142
what an SLO gives us is a way that within a time bound

131
00:10:19,206 --> 00:10:22,618
I can say how many times my SLI needs to be

132
00:10:22,704 --> 00:10:25,930
achieved so that my users are not unhappy.

133
00:10:27,550 --> 00:10:30,882
So exactly what is exactly an echo budget?

134
00:10:30,966 --> 00:10:34,942
An echo budget is nothing more than what is left from

135
00:10:34,996 --> 00:10:38,350
my slO. So if I consider 100%

136
00:10:38,420 --> 00:10:41,646
and I remove what

137
00:10:41,668 --> 00:10:45,130
is the slO, I get my budget.

138
00:10:45,210 --> 00:10:48,978
So if I have an sLO of 99%, I can say that I have 1%

139
00:10:49,064 --> 00:10:52,786
of her budget. So it's effectively the

140
00:10:52,808 --> 00:10:56,322
percentage of reliability left, and it help us make us

141
00:10:56,376 --> 00:11:00,194
educated decisions on whether, for example, to release a new feature

142
00:11:00,242 --> 00:11:03,862
or not. We're going to see that in a bit. And of course, they make

143
00:11:03,916 --> 00:11:08,550
the operability process for incident response to have an appropriate budget

144
00:11:09,370 --> 00:11:11,340
for us to know what we need to do.

145
00:11:12,990 --> 00:11:16,266
And last but not least, the last concept is the concept of an SLI that

146
00:11:16,288 --> 00:11:19,450
most of us are already familiar with.

147
00:11:19,520 --> 00:11:22,250
So when we sign, for example,

148
00:11:22,400 --> 00:11:25,546
sign up for a service, let's imagine that we sign up for a cloud provider,

149
00:11:25,578 --> 00:11:29,086
like Amazon or AWS or whatever cloud provider you are

150
00:11:29,108 --> 00:11:31,930
using. They all usually provide us with an SLA.

151
00:11:32,010 --> 00:11:35,538
So what is an SLA? It's usually

152
00:11:35,624 --> 00:11:39,554
a commitment between a service provider and a client. But in

153
00:11:39,592 --> 00:11:43,506
practice, slas are nothing more than an

154
00:11:43,528 --> 00:11:46,706
SLO that has consequences when that SLO is

155
00:11:46,728 --> 00:11:49,906
not met. So here are examples of what an SLA

156
00:11:49,938 --> 00:11:53,766
can say can be. So, if I can say that 99% of

157
00:11:53,788 --> 00:11:57,654
requests to a service need to be responded within 200

158
00:11:57,692 --> 00:12:01,526
milliseconds within a 30 day period if that doesn't happen.

159
00:12:01,628 --> 00:12:05,162
So if the SLA is not met, the client will get a 30%

160
00:12:05,216 --> 00:12:08,586
discount. Same way we can say that 90% of

161
00:12:08,608 --> 00:12:12,762
requests to a service must be responded with a come different from 500 within

162
00:12:12,816 --> 00:12:16,110
a seven day period. If not, the client can get a 50%

163
00:12:16,180 --> 00:12:19,486
of its money back. And last but not least,

164
00:12:19,508 --> 00:12:23,326
we can say that 99% of measures arriving at the Kafka cluster must

165
00:12:23,348 --> 00:12:27,038
not be older than five minutes within a 24 hours period.

166
00:12:27,134 --> 00:12:31,010
If not, we can be fine for €100,000.

167
00:12:34,150 --> 00:12:37,762
Slas are usually looser than slos so that

168
00:12:37,896 --> 00:12:41,574
we know when an SLO is broken. We still have some

169
00:12:41,612 --> 00:12:44,854
buffer to actually fix things before an SLA is

170
00:12:44,972 --> 00:12:48,246
actually broken. But thats means that we need the way to

171
00:12:48,268 --> 00:12:51,980
actually know if an SLOS is at risk or not.

172
00:12:53,710 --> 00:12:57,674
And of course, we can put that in the visualization. We can

173
00:12:57,712 --> 00:13:02,710
create some graphs thats we can look at, and we can see what

174
00:13:02,720 --> 00:13:06,286
is the slO, what is the objective that we are trying to

175
00:13:06,308 --> 00:13:09,886
achieve. In this case, it's 99% if we

176
00:13:09,908 --> 00:13:12,990
are or not burning budget,

177
00:13:13,410 --> 00:13:16,660
how much error budget I have left

178
00:13:17,990 --> 00:13:21,714
for the period. So visualization is a nice way for me to understand

179
00:13:21,912 --> 00:13:25,714
if an SLO is at risk or not. But we

180
00:13:25,752 --> 00:13:29,942
would ideally be alerted, right? So we don't want to stay our

181
00:13:29,996 --> 00:13:33,794
whole day of work looking at these thats.

182
00:13:33,842 --> 00:13:37,334
And even worse, if something happens during the night that is going to put

183
00:13:37,532 --> 00:13:41,034
my services at risk. I need to be alerted. So this is where

184
00:13:41,072 --> 00:13:43,180
alerting on slos comes through.

185
00:13:44,990 --> 00:13:48,502
So traditionally we did metric thresholds.

186
00:13:48,566 --> 00:13:52,234
So what we would do is that we would send an alert if some

187
00:13:52,272 --> 00:13:56,734
threshold about a metric is

188
00:13:56,772 --> 00:14:00,046
met. So we can say that if a cpu goes above 80%, I want to

189
00:14:00,068 --> 00:14:03,738
receive an alert. If a request takes more than 200 milliseconds,

190
00:14:03,754 --> 00:14:07,070
I want to receive an alert. If an effort,

191
00:14:07,570 --> 00:14:11,038
if a request is served with a 500 error, I received alert.

192
00:14:11,054 --> 00:14:14,226
And the same thing for a Kafka message. Of course all of thats can be

193
00:14:14,248 --> 00:14:17,686
combined. And I can receive an alert and receive an

194
00:14:17,708 --> 00:14:20,360
alert if a combination of these things happen.

195
00:14:21,130 --> 00:14:25,560
So we can take the same approach with slos. So we can say that.

196
00:14:26,890 --> 00:14:30,454
We can say that the latency threshold goes below 99%,

197
00:14:30,492 --> 00:14:33,786
which is my target, I can receive an alert. And we can

198
00:14:33,808 --> 00:14:37,962
say the same thing for an NFL rate that achieves the 99 95%

199
00:14:38,016 --> 00:14:41,466
and I receive an alert. So this is similar to what some

200
00:14:41,488 --> 00:14:45,294
of us had already been doing, because we could say like, okay, if I want

201
00:14:45,412 --> 00:14:49,066
x amount of requests to be more than 200 milliseconds,

202
00:14:49,098 --> 00:14:52,366
we receive an alert. So this is good.

203
00:14:52,468 --> 00:14:56,174
This is better than actually the metric threshold.

204
00:14:56,302 --> 00:14:59,902
But I would only receive an alert when I'm already in trouble.

205
00:14:59,966 --> 00:15:03,694
So if I define the 99% as the threshold

206
00:15:03,822 --> 00:15:07,490
where my users are happy, if I go below that,

207
00:15:07,640 --> 00:15:11,634
basically what I'm saying is that my users are unhappy. So ideally

208
00:15:11,682 --> 00:15:15,366
what I would want is to be alerted before this happens. And if

209
00:15:15,388 --> 00:15:18,766
we are relying on this to fix things before an SLA is breached,

210
00:15:18,818 --> 00:15:20,940
this is exactly what we want.

211
00:15:23,150 --> 00:15:27,242
So how can we improve on this? So we actually can improve on

212
00:15:27,296 --> 00:15:30,602
how much error budget I have available, or how much

213
00:15:30,656 --> 00:15:34,638
error budget has been burned. So the idea is that I

214
00:15:34,644 --> 00:15:38,682
will trigger an alert when the available error budget

215
00:15:38,826 --> 00:15:43,194
reaches a critical level, or when an amount of error

216
00:15:43,242 --> 00:15:46,090
budget has already been burned.

217
00:15:46,250 --> 00:15:51,006
We can actually set different levels and trigger different messages

218
00:15:51,038 --> 00:15:54,846
to different channels. So I can say, for example, that if I have burned

219
00:15:54,878 --> 00:15:58,386
25% of my her budget, I can send an email to

220
00:15:58,408 --> 00:16:01,878
my team. If half of it has been burned, I can put a

221
00:16:01,884 --> 00:16:05,686
message on teams and if for example 75% of

222
00:16:05,708 --> 00:16:09,026
the Akar budget thats already been burned, I want to send a message to pager

223
00:16:09,058 --> 00:16:12,890
duty and I want to tell the team that needs to do something immediately.

224
00:16:14,030 --> 00:16:17,514
This is better than the solution that we have before, but at this

225
00:16:17,552 --> 00:16:22,010
point we have no clue about how fast the echo budget is being consumed.

226
00:16:22,350 --> 00:16:25,966
So a question actually can arise. If by the end of

227
00:16:25,988 --> 00:16:29,642
the evaluation period we would still have some effort budget

228
00:16:29,706 --> 00:16:33,630
left, would I would like to receive this alert, for example on pager duty?

229
00:16:34,290 --> 00:16:37,714
Probably not. Because if we consider that we are still within

230
00:16:37,752 --> 00:16:42,786
the bounds of what my users consider to

231
00:16:42,808 --> 00:16:46,354
be reliable, I wouldn't want to be woken up at 03:00 a.m. In the morning

232
00:16:46,392 --> 00:16:50,178
to fix something that is actually not being need to be fixed.

233
00:16:50,274 --> 00:16:53,734
But yet we still don't have a clue about how fast

234
00:16:53,772 --> 00:16:57,302
my budget is being consumed. And this means that maybe

235
00:16:57,356 --> 00:17:00,826
I received an alert thats 75% of the

236
00:17:00,848 --> 00:17:04,634
effort budget has been burned. Burning so fast that

237
00:17:04,672 --> 00:17:06,730
is actually we're going to get in trouble.

238
00:17:09,310 --> 00:17:13,082
So if we think about it, we can actually alert

239
00:17:13,146 --> 00:17:16,462
on burn rate. So basically alerting on burn rate

240
00:17:16,516 --> 00:17:20,270
tells us how fast the effort budget is being consumed

241
00:17:20,690 --> 00:17:24,318
when we have a burn rate of one. This essentially means

242
00:17:24,404 --> 00:17:27,534
that if we are burning rate at this at a constant

243
00:17:27,582 --> 00:17:30,642
pace, and thats burn rate is one, at the end

244
00:17:30,696 --> 00:17:34,402
of my period, the periods that we've seen previously, like 30 days,

245
00:17:34,456 --> 00:17:38,082
one week, 24 hours, I will have burned

246
00:17:38,146 --> 00:17:41,446
all my FR budget. Here's an example for

247
00:17:41,468 --> 00:17:45,030
the window of evaluation of for example four weeks an alert.

248
00:17:46,650 --> 00:17:50,438
If the burden rate reaches two, why would I want this?

249
00:17:50,524 --> 00:17:54,406
Because this would mean that with a burden rate of two, which is the double,

250
00:17:54,598 --> 00:17:58,426
what is the maximum burden rate that I

251
00:17:58,448 --> 00:18:02,058
want would mean that I will consume all my effort budget in half the time.

252
00:18:02,144 --> 00:18:05,530
So for a period of four weeks, if I'm ensuring,

253
00:18:05,610 --> 00:18:09,294
if my burden rate is two, would mean that after two weeks I would have

254
00:18:09,332 --> 00:18:12,350
no effort budget left. So I would want to receive an alert.

255
00:18:14,610 --> 00:18:18,074
This is also better. But this has one slight

256
00:18:18,122 --> 00:18:22,014
issue, which is that if the burden rate is too

257
00:18:22,052 --> 00:18:25,566
high, it might not be picked up. For example,

258
00:18:25,668 --> 00:18:29,030
if we evaluate the burn rate

259
00:18:29,100 --> 00:18:32,790
every hour, but the error budget is all consumed within 30 minutes,

260
00:18:32,860 --> 00:18:36,150
we won't receive, but we would receive no alerts.

261
00:18:38,730 --> 00:18:42,406
So the last evolution of our alerting on slos is the

262
00:18:42,428 --> 00:18:45,674
multi window multiburn rate alerts. So this is the

263
00:18:45,712 --> 00:18:49,338
idea where we will combine the previous alerted that

264
00:18:49,344 --> 00:18:52,686
we've seen using multiple windows. And what

265
00:18:52,708 --> 00:18:56,240
we want is to alert on fast burn when

266
00:18:57,250 --> 00:19:00,714
the burn rate is too high and that will alert us on sudden

267
00:19:00,762 --> 00:19:03,754
changes, something that actually catastrophic event that happened.

268
00:19:03,812 --> 00:19:07,346
And it's ensuring stuff really, really fast. But at

269
00:19:07,368 --> 00:19:10,526
the same time, we also want slow burn rates.

270
00:19:10,558 --> 00:19:13,954
We want something that's consuming our

271
00:19:13,992 --> 00:19:17,954
effort, but thats consistently over a longer period of time. We also

272
00:19:17,992 --> 00:19:21,254
want to alert on those. So here are a few

273
00:19:21,292 --> 00:19:24,806
examples. So for fast burn, we youll say that for

274
00:19:24,828 --> 00:19:28,502
a period of two windows, in periods of five minutes, if the burn rate

275
00:19:28,556 --> 00:19:32,006
reaches ten, we want to receive an alert. So this would actually alert

276
00:19:32,038 --> 00:19:36,086
us if we had like a spike on our budget consumption.

277
00:19:36,198 --> 00:19:40,106
And we will have a similar one, but that would be slower. So we

278
00:19:40,128 --> 00:19:44,154
would evaluate a 24 hours period window for every

279
00:19:44,192 --> 00:19:47,642
five minutes. If the burn rate reaches two, we would receive

280
00:19:47,706 --> 00:19:51,754
an alert. So this is an evolution where we can go from magic thresholds

281
00:19:51,802 --> 00:19:55,554
to thresholds. On alerts, we actually have something that we can

282
00:19:55,672 --> 00:19:59,106
say with some confidence that when we receive an

283
00:19:59,128 --> 00:20:02,020
alert, we actually need to do something.

284
00:20:02,630 --> 00:20:05,890
But what is that something, and thats something

285
00:20:05,960 --> 00:20:09,762
can be defined on the error budget policy. So the error budget

286
00:20:09,826 --> 00:20:13,122
policy determines the alerting thresholds and the actions

287
00:20:13,186 --> 00:20:16,402
to take to ensuring that the error budget depletion is addressed.

288
00:20:16,466 --> 00:20:20,326
So what does this mean? The error budget policy is actually a

289
00:20:20,348 --> 00:20:23,434
policy that is defined beforehand, where we say

290
00:20:23,472 --> 00:20:27,340
that if x action happens, we will take the

291
00:20:27,790 --> 00:20:31,226
action a, B and C. So here are a few examples, and I'm going

292
00:20:31,248 --> 00:20:34,782
to see a document more detailed in a second. So we can say that

293
00:20:34,836 --> 00:20:38,426
if the service has exceeded its error budget for the preceding

294
00:20:38,458 --> 00:20:41,726
four week window, we will hold all changes on

295
00:20:41,748 --> 00:20:45,330
our service and releases, and we will only do

296
00:20:45,400 --> 00:20:49,250
p zero issues or security fixes until the service is within

297
00:20:49,320 --> 00:20:53,310
the SLO. Depending upon the cause of the SLO

298
00:20:53,390 --> 00:20:57,210
miss, the team may devote additional resources to working on reliability

299
00:20:57,310 --> 00:21:00,406
instead of feature work. So basically here what we

300
00:21:00,428 --> 00:21:04,086
are defining is a concrete measure for if the

301
00:21:04,108 --> 00:21:07,494
error budget has been depleted at some point

302
00:21:07,532 --> 00:21:11,594
within our four week period, we will not be releasing measures apart from,

303
00:21:11,632 --> 00:21:15,206
of course, p zero issues or security fixes. And we're

304
00:21:15,238 --> 00:21:18,934
also saying that depending on what caused the SLO

305
00:21:18,982 --> 00:21:22,742
to be missed, we might need to add additional

306
00:21:22,806 --> 00:21:26,602
resources to work on reliability instead of releasing more features.

307
00:21:26,746 --> 00:21:30,314
Another example could be that if a single incident consumes

308
00:21:30,362 --> 00:21:33,854
more than 20% of our effort budget over the same four week

309
00:21:33,892 --> 00:21:36,954
period, then the team must conduct a postmortem,

310
00:21:37,082 --> 00:21:40,178
and that post mortem must have at least one p zero action. So a

311
00:21:40,184 --> 00:21:43,762
p zero action would be something that is really ugly. So again,

312
00:21:43,896 --> 00:21:47,734
this actually defines the actions that are going to be made

313
00:21:47,852 --> 00:21:51,830
when the effort budget policy is at risk, who has been consumed.

314
00:21:52,250 --> 00:21:56,514
So this should actually go into documents agreed with multiple

315
00:21:56,562 --> 00:22:00,278
parts so that everyone is on the same page regarding

316
00:22:00,454 --> 00:22:03,574
what is being done when the SLO is actually consumed

317
00:22:03,702 --> 00:22:05,900
and taken from the Google book,

318
00:22:07,870 --> 00:22:11,130
from the SRE book, from Google, we have an example

319
00:22:11,200 --> 00:22:14,186
of such kind of document. This is just an example.

320
00:22:14,288 --> 00:22:17,758
You can of course define your error budget policy

321
00:22:17,924 --> 00:22:21,726
any way that you want, but it gives you a good starting point

322
00:22:21,828 --> 00:22:25,680
into how to define alerting alerting slos error budget

323
00:22:26,050 --> 00:22:29,294
policies. In this example we see that we have the authors of the Echo budget

324
00:22:29,342 --> 00:22:32,686
policy, when it was defined, who reviewed

325
00:22:32,718 --> 00:22:36,034
it, who approved it, when it was approved, and when it should

326
00:22:36,072 --> 00:22:39,286
be revised. We then have a service of review. So it

327
00:22:39,308 --> 00:22:42,646
will be the service or group of service that this

328
00:22:42,828 --> 00:22:44,950
air budget policy applies.

329
00:22:45,770 --> 00:22:49,206
We would then have the goals and non goals. So these are the goals that

330
00:22:49,228 --> 00:22:52,874
the air budget policy tries to achieve and what are not

331
00:22:52,992 --> 00:22:57,030
the goals that it's trying to achieve. Then we have a definition

332
00:22:57,110 --> 00:23:00,474
of what it means to actually miss the

333
00:23:00,512 --> 00:23:03,934
slO. So here's a detailed description that what does

334
00:23:03,972 --> 00:23:07,294
it mean for the SLO to be

335
00:23:07,332 --> 00:23:11,434
missed and basically means when this budget

336
00:23:11,482 --> 00:23:15,074
policy will be enforced. We can also have other

337
00:23:15,112 --> 00:23:18,226
sections like an outage policy, an escalation policy,

338
00:23:18,328 --> 00:23:20,770
and come background that it is necessary.

339
00:23:22,150 --> 00:23:26,014
So to quickly sum up all the concepts that we have seen, we started

340
00:23:26,072 --> 00:23:29,510
with metrics. With metrics we can build

341
00:23:29,580 --> 00:23:33,330
slos and slos is what will help us define

342
00:23:33,410 --> 00:23:37,030
if a metric is good or bad within our context.

343
00:23:37,450 --> 00:23:40,634
An SLO is how many times an SLI needs

344
00:23:40,672 --> 00:23:44,602
to be achieved so that we can be sure that our users are happy

345
00:23:44,656 --> 00:23:48,620
with our services. Can effort budget is the amount of

346
00:23:48,990 --> 00:23:52,618
reliability that is left from the SLO.

347
00:23:52,794 --> 00:23:56,686
And with SLO and her budget we can build visualizations that

348
00:23:56,708 --> 00:23:59,886
are good, but ideally thats we want is to actually be

349
00:23:59,908 --> 00:24:03,566
alerted when our SLO is

350
00:24:03,588 --> 00:24:08,174
at risk. And of course SLO alerts can trigger

351
00:24:08,222 --> 00:24:12,066
an effort budget policy. For example, if I'm consuming too much of

352
00:24:12,088 --> 00:24:15,700
my slo, I can enforce an effort budget policy that has been

353
00:24:16,950 --> 00:24:20,726
pre discussed and agreed with all parties. And of course we have the concept of

354
00:24:20,748 --> 00:24:23,190
an SLA which is an SLO with penalties.

355
00:24:24,010 --> 00:24:27,158
But why is all of this important? This is important

356
00:24:27,244 --> 00:24:30,746
because this way we can define reliability in the eyes of our

357
00:24:30,768 --> 00:24:32,970
users. We stopped measuring,

358
00:24:34,350 --> 00:24:37,350
we stopped alerting and defining reliability,

359
00:24:37,430 --> 00:24:41,286
something that doesn't really is defined by our users.

360
00:24:41,318 --> 00:24:44,874
So I don't want to be alerted when I have a threshold of a cpu,

361
00:24:44,922 --> 00:24:48,126
for example, going up at three in the morning

362
00:24:48,228 --> 00:24:51,854
and my users are not being affected. This of course,

363
00:24:51,892 --> 00:24:55,322
ties in into reducing alert fatigue. So now I will receive,

364
00:24:55,386 --> 00:24:59,202
ideally I will receive alerts only when my users are

365
00:24:59,256 --> 00:25:02,510
being affected or they are at risk of being affected.

366
00:25:02,670 --> 00:25:05,918
Of course, this also creates a shared language to talk about reliability.

367
00:25:06,014 --> 00:25:09,958
So now with all of this, we have a framework in place that

368
00:25:10,044 --> 00:25:14,114
can actually tell us if our systems are being reliable or not, and it's

369
00:25:14,162 --> 00:25:17,682
understood by everyone. And of course it facilitates prioritization.

370
00:25:17,826 --> 00:25:21,674
So we have a way to see if we're being reliable or

371
00:25:21,712 --> 00:25:25,274
not. And we have can effort budget policy that

372
00:25:25,312 --> 00:25:28,714
actually can help us define when more work needs to be put

373
00:25:28,752 --> 00:25:32,062
on top of reliability. And before

374
00:25:32,116 --> 00:25:35,466
I go, I want to leave a shameless plug. I'm writing

375
00:25:35,498 --> 00:25:38,862
a book on overcoming SRE antipatterns and

376
00:25:38,916 --> 00:25:42,798
we'll have a couple of chapters in the book speaking

377
00:25:42,884 --> 00:25:46,554
precisely about this, speaking about how to measure

378
00:25:46,602 --> 00:25:50,538
reliability edis of our users, and how we can leverage alerts

379
00:25:50,554 --> 00:25:53,674
on slos and budget policies

380
00:25:53,722 --> 00:25:57,078
to actually improve our day to day operations. It and

381
00:25:57,164 --> 00:26:00,374
this is all from my part. I hope you enjoyed and

382
00:26:00,412 --> 00:26:05,494
this talk was informative for all of you. You can find me at

383
00:26:05,532 --> 00:26:07,780
these links. Thank you very much and have a great day.

