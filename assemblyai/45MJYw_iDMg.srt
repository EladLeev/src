1
00:00:39,370 --> 00:00:43,066
Welcome to my lecture, anomaly detects with Apache,

2
00:00:43,098 --> 00:00:45,040
Pinot and Thirdeye.

3
00:00:47,250 --> 00:00:51,070
By the end of this lecture, I want you to be able to

4
00:00:51,140 --> 00:00:53,942
solve this, well,

5
00:00:54,116 --> 00:00:57,654
this, or at least recognize this as

6
00:00:57,692 --> 00:01:01,430
soon as possible. So what happened was I was working

7
00:01:01,500 --> 00:01:05,574
at this big data company, an ad tech company, and we were

8
00:01:05,612 --> 00:01:08,700
dealing with 1 million events per second.

9
00:01:09,230 --> 00:01:12,998
And all I needed to do was add a new parameter

10
00:01:13,094 --> 00:01:16,762
to the data. The problem was that

11
00:01:16,816 --> 00:01:20,634
there was a misconfiguration or a misunderstanding

12
00:01:20,682 --> 00:01:24,062
about the data type. See, it was

13
00:01:24,116 --> 00:01:27,838
sent as a string, but I implementing it as

14
00:01:27,924 --> 00:01:29,200
a long value,

15
00:01:30,290 --> 00:01:34,194
and this was only relevant for

16
00:01:34,392 --> 00:01:38,580
any mobile phone of type. IPhone V seven.

17
00:01:39,430 --> 00:01:43,410
Needless to say, that this problem went

18
00:01:43,480 --> 00:01:46,520
unrecognized for 12 hours,

19
00:01:47,370 --> 00:01:51,238
after which we lost about $10,000

20
00:01:51,324 --> 00:01:55,430
of billing data, and we wasted five

21
00:01:55,500 --> 00:01:58,250
days to try to remedy the lost data,

22
00:01:58,400 --> 00:02:01,260
to no avail. So,

23
00:02:02,430 --> 00:02:06,474
what I'm actually talking to you about today could

24
00:02:06,512 --> 00:02:10,154
have saved all of this mess, because we

25
00:02:10,272 --> 00:02:13,790
would have recognized the problem immediately.

26
00:02:14,850 --> 00:02:18,970
Let me introduce myself. My name is Yoav Nordmann.

27
00:02:19,130 --> 00:02:23,042
I am a technology enthusiast. I love

28
00:02:23,176 --> 00:02:25,970
working with new and emerging technologies.

29
00:02:26,790 --> 00:02:30,722
You can call me either a nerd or geek, or both. It is

30
00:02:30,776 --> 00:02:34,326
definitely a compliment. At the

31
00:02:34,348 --> 00:02:37,874
clients, I usually work as a tech lead or architect.

32
00:02:38,002 --> 00:02:40,998
And at Tikal, the company I'm working for,

33
00:02:41,164 --> 00:02:44,946
I am a group leader and mentor for fellow

34
00:02:45,058 --> 00:02:47,080
workers in the back end.

35
00:02:48,030 --> 00:02:52,602
So, let's start and talk about what

36
00:02:52,656 --> 00:02:56,330
is anomaly detection. But in order

37
00:02:56,400 --> 00:03:00,318
to understand what anomaly detects is, let's try

38
00:03:00,404 --> 00:03:04,174
actually to first define what is an

39
00:03:04,212 --> 00:03:08,250
anomaly. Right? So, an anomaly

40
00:03:08,410 --> 00:03:12,050
is defined as deviation from the common rule,

41
00:03:12,470 --> 00:03:14,750
something different, abnormal,

42
00:03:14,910 --> 00:03:19,182
peculiar, and even not easily

43
00:03:19,246 --> 00:03:23,454
classified. Now that we have an understanding

44
00:03:23,582 --> 00:03:27,362
of what an anomalies is, we can define

45
00:03:27,506 --> 00:03:30,166
anomaly detection. So,

46
00:03:30,268 --> 00:03:34,038
anomalies detection is understood to be

47
00:03:34,124 --> 00:03:37,350
the identification and or observation

48
00:03:37,510 --> 00:03:41,430
of data points and events that deviate

49
00:03:41,590 --> 00:03:44,810
from a data set's normal behavior.

50
00:03:45,790 --> 00:03:49,100
Simple enough, right? So, what is the problem?

51
00:03:49,490 --> 00:03:52,270
Well, the problem is quite complex.

52
00:03:53,410 --> 00:03:57,102
Let's say an issue occurs just

53
00:03:57,156 --> 00:04:00,766
as the issue occurred at the company I was working for.

54
00:04:00,948 --> 00:04:05,278
So many, many times, if an issue occurs,

55
00:04:05,454 --> 00:04:09,598
it just ends up in a black hole, because nobody even recognizes

56
00:04:09,694 --> 00:04:13,470
the issue. Let's say somebody actually recognized

57
00:04:13,550 --> 00:04:16,790
there is an issue and invests time

58
00:04:16,860 --> 00:04:19,480
and effort to research the problem.

59
00:04:20,170 --> 00:04:23,478
So he was able to identify the issue,

60
00:04:23,564 --> 00:04:27,750
but then again, it might not be able to

61
00:04:27,820 --> 00:04:31,210
find a root cause. So again,

62
00:04:31,360 --> 00:04:35,274
it'll end up in the black hole, and it might

63
00:04:35,312 --> 00:04:40,026
occur again. Let's say there are many people who try to identify

64
00:04:40,218 --> 00:04:44,030
the root cause, and we found it so after

65
00:04:44,100 --> 00:04:46,560
that, actually we can fix the issue.

66
00:04:47,490 --> 00:04:51,794
So what we are trying to do today with

67
00:04:51,832 --> 00:04:55,118
apache Pinot and third eye is first of all eliminate

68
00:04:55,214 --> 00:04:58,802
the black hole. There is no more issue

69
00:04:58,936 --> 00:05:02,514
which will occur undetected. There is no

70
00:05:02,552 --> 00:05:05,846
more identifying an issue and not being able to get to

71
00:05:05,868 --> 00:05:09,350
the root cause. So there is no more black hole.

72
00:05:09,770 --> 00:05:13,654
Second of all, we are trying to

73
00:05:13,692 --> 00:05:17,594
reduce time to detect. We are

74
00:05:17,632 --> 00:05:21,370
also reducing time to resolution.

75
00:05:22,830 --> 00:05:26,234
So let me take you on this journey through

76
00:05:26,272 --> 00:05:30,094
the twilight zone. We are the thirdeye of rules and

77
00:05:30,132 --> 00:05:34,430
let's talk about star Tree's third eye.

78
00:05:35,250 --> 00:05:37,710
So what is third eye?

79
00:05:38,530 --> 00:05:41,810
Third eye is an anomaly detection, monitors and

80
00:05:41,880 --> 00:05:45,220
interactive root cause analysis platform.

81
00:05:46,630 --> 00:05:49,826
Remember I said star tree thirdeye. So what

82
00:05:49,848 --> 00:05:53,562
is startree? Or rather who is startree?

83
00:05:53,726 --> 00:05:57,622
So startree is a company and

84
00:05:57,676 --> 00:06:01,314
they are the ones who are offering Apache

85
00:06:01,362 --> 00:06:04,706
pinot and thirdeye as a SaaS solution.

86
00:06:04,898 --> 00:06:08,470
But Apache Pinot of course is open source

87
00:06:08,550 --> 00:06:12,506
and can be used freely. Thirdeye is

88
00:06:12,608 --> 00:06:16,570
not open source, it is actually given out

89
00:06:16,640 --> 00:06:19,934
with a community license, which means you

90
00:06:19,972 --> 00:06:23,434
cannot take third eye and create a sauce

91
00:06:23,482 --> 00:06:26,654
product with it. Other than that, you are

92
00:06:26,692 --> 00:06:31,130
allowed to use it at your own discretion and enjoy

93
00:06:31,300 --> 00:06:34,100
the full benefits of this great platform.

94
00:06:35,030 --> 00:06:38,402
If we look at the architecture of third

95
00:06:38,456 --> 00:06:41,826
eye, we can see that this platform is

96
00:06:41,848 --> 00:06:45,814
not just a simple tool or a simple UI. There is

97
00:06:45,852 --> 00:06:49,302
some more to this application or to this

98
00:06:49,356 --> 00:06:52,854
architecture, but the interesting part is

99
00:06:52,972 --> 00:06:56,826
that it actually is working against a

100
00:06:56,848 --> 00:07:00,954
data source. It is actually always querying this

101
00:07:00,992 --> 00:07:05,210
data source. So this data source has to be very, very efficient

102
00:07:05,630 --> 00:07:09,834
for all of these queries to be run

103
00:07:09,952 --> 00:07:13,466
and return in a sub second response

104
00:07:13,498 --> 00:07:17,182
time, right? And this data source is none other than

105
00:07:17,236 --> 00:07:20,398
Apache Pinot. So let's talk a little bit about

106
00:07:20,484 --> 00:07:24,930
Apache Pinot. What exactly is Apache Pinot?

107
00:07:25,270 --> 00:07:29,054
So Apache Pinot is a real time distributed OLap

108
00:07:29,102 --> 00:07:32,702
data store, purpose built to provide ultra

109
00:07:32,766 --> 00:07:36,022
low latency analytics even at

110
00:07:36,076 --> 00:07:38,310
extremely high throughput.

111
00:07:39,610 --> 00:07:43,462
Let us try to put all of this into context and

112
00:07:43,516 --> 00:07:44,840
explain the problem.

113
00:07:46,510 --> 00:07:50,378
In the analytics world, we usually talk about

114
00:07:50,544 --> 00:07:53,660
dimensions and metrics, right?

115
00:07:54,030 --> 00:07:57,558
Dimensions are the labels used to describe

116
00:07:57,654 --> 00:08:01,738
data and metrics are the quantitative

117
00:08:01,834 --> 00:08:05,040
measurements of the data. So for example,

118
00:08:05,410 --> 00:08:09,354
dimensions would be device type could be Android

119
00:08:09,402 --> 00:08:12,706
or iPhone, or the dimension could be country,

120
00:08:12,808 --> 00:08:14,820
which would be Israel, us,

121
00:08:15,190 --> 00:08:18,818
Mexico, or any other country. On the

122
00:08:18,824 --> 00:08:22,446
other hand, the metrics that would be, for instance,

123
00:08:22,558 --> 00:08:25,590
temperature, which has a value or views,

124
00:08:25,930 --> 00:08:28,680
which also is a value.

125
00:08:29,770 --> 00:08:33,094
And all we want to do with the dimensions and

126
00:08:33,132 --> 00:08:35,990
metrics is slice and dice.

127
00:08:36,830 --> 00:08:39,914
So slice and dice might be

128
00:08:39,952 --> 00:08:43,740
easy with three dimensions and as you can see here,

129
00:08:44,190 --> 00:08:47,210
this would be seven permutations.

130
00:08:48,770 --> 00:08:52,938
What happens if we have five dimensions?

131
00:08:53,114 --> 00:08:56,494
That's already a little bit harder, because those are 31

132
00:08:56,532 --> 00:09:00,574
permutations. And what about seven dimensions, which has

133
00:09:00,612 --> 00:09:03,970
127 permutations?

134
00:09:04,390 --> 00:09:08,082
And of course, we would like to have many, many more

135
00:09:08,136 --> 00:09:09,090
dimensions.

136
00:09:12,310 --> 00:09:14,360
To understand the problem,

137
00:09:15,610 --> 00:09:18,630
let's see how the data is usually kept.

138
00:09:19,290 --> 00:09:23,174
So, data is usually kept either in raw data

139
00:09:23,372 --> 00:09:26,666
and it is being processed going down

140
00:09:26,688 --> 00:09:31,078
the processing

141
00:09:31,174 --> 00:09:35,034
line. It might be after raw data, it might be

142
00:09:35,072 --> 00:09:38,314
joined and aggregated, and in the end it

143
00:09:38,352 --> 00:09:39,950
might be cubed.

144
00:09:41,090 --> 00:09:45,200
So why would we do this to data?

145
00:09:46,930 --> 00:09:50,526
The more we keep data

146
00:09:50,628 --> 00:09:54,226
in raw format, the more flexibility we have to

147
00:09:54,248 --> 00:09:57,982
do certain calculations. The more we preprocess

148
00:09:58,046 --> 00:10:01,694
the data, the less flexibility we have. But on the flip

149
00:10:01,742 --> 00:10:05,078
side, the more we keep the data

150
00:10:05,164 --> 00:10:08,710
in raw format, we have a very high

151
00:10:08,780 --> 00:10:12,710
latency. It'll take a long time for those computations.

152
00:10:13,210 --> 00:10:16,242
And the more we preprocess the data,

153
00:10:16,396 --> 00:10:19,734
we could have low latency. So Apache

154
00:10:19,782 --> 00:10:23,610
Pinot is right in the middle between

155
00:10:23,680 --> 00:10:26,954
joint data and aggregated data, trying to

156
00:10:26,992 --> 00:10:30,798
have maximum flexibility and

157
00:10:30,884 --> 00:10:32,670
minimum latency.

158
00:10:34,290 --> 00:10:38,110
But why would Apache Pinot be better than its

159
00:10:38,180 --> 00:10:40,960
competitors, of which there are a few?

160
00:10:41,430 --> 00:10:45,998
Well, this has to do with the history of Apache Pinot.

161
00:10:46,174 --> 00:10:49,954
See, Apache Pinot was actually invented and

162
00:10:49,992 --> 00:10:53,694
written at LinkedIn. And first it was used as

163
00:10:53,752 --> 00:10:57,350
can internal analytics database for the business

164
00:10:57,420 --> 00:11:00,774
users to see what is happening. As soon

165
00:11:00,812 --> 00:11:04,754
as those business users saw the immense

166
00:11:04,802 --> 00:11:08,780
potential of Apache Pinot, they actually

167
00:11:09,150 --> 00:11:12,730
said it should be expanded to be used

168
00:11:12,800 --> 00:11:16,890
by all 500 million users on LinkedIn.

169
00:11:17,230 --> 00:11:21,166
And if you go on LinkedIn today, you might even see all

170
00:11:21,188 --> 00:11:25,054
the queries which are being sent to Apache Pinot at any

171
00:11:25,092 --> 00:11:28,862
given time. As you can see just on this

172
00:11:28,916 --> 00:11:32,594
page, I have seven queries, and there might be

173
00:11:32,632 --> 00:11:36,690
more which are being run for each user

174
00:11:37,430 --> 00:11:40,386
with a low latency, most of the time,

175
00:11:40,488 --> 00:11:44,406
subsecond latency response time for any

176
00:11:44,428 --> 00:11:46,710
given user on LinkedIn.

177
00:11:48,490 --> 00:11:51,766
Some of the statistics on LinkedIn. So as you can see,

178
00:11:51,868 --> 00:11:55,474
there is 200,000 queries

179
00:11:55,522 --> 00:11:59,258
per second. Those statistics are

180
00:11:59,424 --> 00:12:03,514
actually a year old, so there might be more. They have

181
00:12:03,552 --> 00:12:07,194
a max ingestion rate of about 1 million

182
00:12:07,312 --> 00:12:11,306
events per second, and when querying,

183
00:12:11,418 --> 00:12:15,146
they have about 20 billion records which are scanned

184
00:12:15,258 --> 00:12:18,606
each second. So as

185
00:12:18,628 --> 00:12:21,734
you can see, Apache Pinot is a database

186
00:12:21,802 --> 00:12:25,170
built for speed and efficiency.

187
00:12:25,750 --> 00:12:29,060
Now, this speed and efficiency especially is

188
00:12:29,510 --> 00:12:33,006
being delivered by a pluggable indexing

189
00:12:33,038 --> 00:12:36,982
technology. And as you can see, they implemented a lot

190
00:12:37,036 --> 00:12:40,774
of indexes in order to help

191
00:12:40,972 --> 00:12:44,882
to try to create a minimum

192
00:12:44,946 --> 00:12:47,100
latency response time.

193
00:12:48,350 --> 00:12:52,106
So let's get back to

194
00:12:52,128 --> 00:12:53,850
what I'm trying to solve.

195
00:12:56,670 --> 00:13:00,254
So at the same company there was another problem.

196
00:13:00,452 --> 00:13:04,414
We had a lot of data, right? And what

197
00:13:04,452 --> 00:13:07,994
happened was usually there was this odd

198
00:13:08,042 --> 00:13:12,130
user which every day would enter the system

199
00:13:12,280 --> 00:13:15,380
and would download a lot of data.

200
00:13:16,630 --> 00:13:20,242
The problem was that when this person could

201
00:13:20,296 --> 00:13:22,900
initiate his query to download the data,

202
00:13:23,270 --> 00:13:26,534
all other queries, for some

203
00:13:26,572 --> 00:13:30,226
reason there was heavy

204
00:13:30,258 --> 00:13:33,474
usage on the system, so all the other queries

205
00:13:33,522 --> 00:13:37,322
had a higher response time. Basically other

206
00:13:37,376 --> 00:13:41,450
people had to wait longer for their data to arrive.

207
00:13:42,670 --> 00:13:46,154
And the funny thing was that, do you know when

208
00:13:46,192 --> 00:13:50,046
we knew about this problem? Actually only a day later,

209
00:13:50,228 --> 00:13:54,014
because there was a batch job which would go

210
00:13:54,052 --> 00:13:57,966
over the log files of the day before and extract all the

211
00:13:57,988 --> 00:14:01,986
query latency response times. And only a day later we

212
00:14:02,008 --> 00:14:05,714
would know that there were certain queries at

213
00:14:05,752 --> 00:14:08,974
a certain point which had a high latency response

214
00:14:09,022 --> 00:14:12,020
time. So again,

215
00:14:13,510 --> 00:14:17,302
the problem we are trying to solve is this,

216
00:14:17,436 --> 00:14:20,966
what happens if at a certain point

217
00:14:21,148 --> 00:14:24,694
there is a sudden degradation of

218
00:14:24,732 --> 00:14:28,122
performance and we do not know about it in

219
00:14:28,176 --> 00:14:31,850
real time. So the way Apache Pinot works

220
00:14:31,920 --> 00:14:35,882
or the way third eye works is actually using an

221
00:14:35,936 --> 00:14:39,898
alerting template. The alerting template

222
00:14:39,994 --> 00:14:44,202
is actually the detects logic or boilerplate

223
00:14:44,346 --> 00:14:48,078
that can be used to create an alert. An example

224
00:14:48,164 --> 00:14:51,842
could be we would like to create an anomalies if a certain

225
00:14:51,896 --> 00:14:55,426
metric is bigger than a

226
00:14:55,528 --> 00:14:57,460
certain maximum value.

227
00:14:58,950 --> 00:15:03,010
Using this alert template, we can then create an alert.

228
00:15:03,590 --> 00:15:07,042
So alert is an anomaly

229
00:15:07,106 --> 00:15:11,106
detection rule configuration, right? That would be our anomalies

230
00:15:11,138 --> 00:15:14,994
detection. So an example for this would be create an anomaly

231
00:15:15,042 --> 00:15:18,102
if revenue, that is our metric,

232
00:15:18,166 --> 00:15:21,850
is bigger than 20,000 and

233
00:15:21,920 --> 00:15:26,154
we would like to check every hour and

234
00:15:26,192 --> 00:15:30,590
the anomalies would occur if this

235
00:15:30,660 --> 00:15:34,222
alert would be triggered. So at

236
00:15:34,276 --> 00:15:37,854
a certain time when querying the data, we would

237
00:15:37,892 --> 00:15:41,746
see that revenue is 30,000, which is above the

238
00:15:41,768 --> 00:15:45,794
threshold of 20,000 on Thursday, the third between

239
00:15:45,912 --> 00:15:48,820
09:00 p.m. And 10:00 p.m.

240
00:15:49,990 --> 00:15:53,618
The interface looks as follows. As you

241
00:15:53,624 --> 00:16:00,294
can see, we have a view of certain

242
00:16:00,412 --> 00:16:03,910
metrics, and for those with great

243
00:16:03,980 --> 00:16:07,622
eyesight can see that on February

244
00:16:07,686 --> 00:16:11,980
20 eigth, there is a dotted line

245
00:16:12,510 --> 00:16:16,134
and there is a solid line. And the solid

246
00:16:16,182 --> 00:16:19,902
line is the actual data and the dotted line is

247
00:16:19,956 --> 00:16:23,998
the expected data. So as you can see here,

248
00:16:24,164 --> 00:16:27,578
this is an anomaly which can be traced

249
00:16:27,754 --> 00:16:31,554
in third eye. There are

250
00:16:31,592 --> 00:16:34,500
multiple detector algorithms which can be used.

251
00:16:34,870 --> 00:16:38,050
In the example you saw, the threshold rule,

252
00:16:38,790 --> 00:16:42,494
there is also a mean variance rule. There is a percentage

253
00:16:42,542 --> 00:16:46,774
rule, an absolute change rule. And if you

254
00:16:46,892 --> 00:16:51,090
want to get the services from Thirdeye from Star Tree,

255
00:16:51,170 --> 00:16:54,690
there is also a hold winters rule. This is proprietary

256
00:16:54,770 --> 00:16:58,394
to Star Tree. If you are using this

257
00:16:58,512 --> 00:17:01,910
for free, the non commercial license,

258
00:17:01,990 --> 00:17:04,698
then you will not have the hold winter took.

259
00:17:04,864 --> 00:17:08,154
But you want to write

260
00:17:08,192 --> 00:17:11,662
your own. This platform is actually

261
00:17:11,716 --> 00:17:15,470
pluggable. So if you want you can write your own

262
00:17:15,540 --> 00:17:18,320
detector algorithms based on your needs.

263
00:17:19,010 --> 00:17:22,930
Now this is all great and nice and

264
00:17:23,000 --> 00:17:25,890
we could know when there is an anomaly.

265
00:17:26,230 --> 00:17:29,762
But as I said before, third eye is also

266
00:17:29,816 --> 00:17:32,180
a root cause analysis platform.

267
00:17:33,510 --> 00:17:37,970
So you can see when there is an anomaly

268
00:17:38,130 --> 00:17:42,022
you will be able to create or go into the root cause

269
00:17:42,076 --> 00:17:45,510
analysis and see what exactly the problem

270
00:17:45,580 --> 00:17:49,594
is. For those again with great eyesight might see the

271
00:17:49,632 --> 00:17:52,874
difference that on the left we have

272
00:17:52,912 --> 00:17:56,922
the current data range and on the right

273
00:17:56,976 --> 00:18:00,254
side we have the baseline. And so we

274
00:18:00,292 --> 00:18:04,462
could see what exactly the difference is why there

275
00:18:04,516 --> 00:18:08,094
is an anomaly. Now as you can see, I have

276
00:18:08,132 --> 00:18:10,462
different colors. I have blue, I have red,

277
00:18:10,596 --> 00:18:14,514
reddish. So pretty simple. If we

278
00:18:14,552 --> 00:18:18,322
have a certain metric as a

279
00:18:18,376 --> 00:18:21,570
deep red, that would be a big change down.

280
00:18:21,640 --> 00:18:25,462
And if we have an intense blue, it is a big change

281
00:18:25,516 --> 00:18:29,062
up. So now looking

282
00:18:29,116 --> 00:18:33,238
back at this root cause analysis in third eye, we can see

283
00:18:33,324 --> 00:18:37,194
that there are certain values which are higher

284
00:18:37,312 --> 00:18:41,434
than the baseline and certain values which are lower than

285
00:18:41,472 --> 00:18:44,906
the baseline. All of this to help us with our

286
00:18:44,928 --> 00:18:46,890
root cause analysis.

287
00:18:47,390 --> 00:18:51,006
Now what

288
00:18:51,028 --> 00:18:55,182
about alerts, right? I mean, any company

289
00:18:55,316 --> 00:18:59,310
has its own alerting system. So how could

290
00:18:59,380 --> 00:19:03,310
I integrate those anomaly detections, those anomalies

291
00:19:03,390 --> 00:19:05,922
with my alerting system?

292
00:19:06,056 --> 00:19:09,902
Well, there is a possibility to have a subscription

293
00:19:09,966 --> 00:19:13,378
group if we would like to create a subscription group.

294
00:19:13,464 --> 00:19:17,206
In third eye, as you can see at the moment the channels are

295
00:19:17,308 --> 00:19:21,190
either email slack. There is also an option for

296
00:19:21,260 --> 00:19:25,362
webhook. So we can definitely integrate the anomalies

297
00:19:25,426 --> 00:19:30,326
which occur in third eye with our alerting

298
00:19:30,358 --> 00:19:34,874
system. But still there

299
00:19:34,912 --> 00:19:38,758
are a few skeptics. The baseline. Remember,

300
00:19:38,864 --> 00:19:42,538
what if the baseline was a holiday?

301
00:19:42,714 --> 00:19:46,014
Or even more, what if

302
00:19:46,132 --> 00:19:49,550
the baseline did

303
00:19:49,620 --> 00:19:54,290
occur on a day where we had a

304
00:19:54,360 --> 00:19:58,098
change in the system or a new version of the product?

305
00:19:58,184 --> 00:20:01,986
Well, so this is one of the greatest issues. We can create

306
00:20:02,088 --> 00:20:05,430
events. So we would create

307
00:20:05,500 --> 00:20:09,462
an event on certain dates. For instance, for each

308
00:20:09,516 --> 00:20:12,934
time we would actually update a new version of the

309
00:20:12,972 --> 00:20:17,110
product. That could be an event. If there are holidays,

310
00:20:17,190 --> 00:20:20,506
that would be an event. This is a

311
00:20:20,528 --> 00:20:24,106
very simple took to create events. And this

312
00:20:24,208 --> 00:20:27,942
would be integrated into our baseline

313
00:20:28,086 --> 00:20:31,866
and into our anomaly detection. And with our root

314
00:20:31,898 --> 00:20:35,374
cause analysis we will be able to see that there

315
00:20:35,412 --> 00:20:39,294
were specific or special circumstances at

316
00:20:39,332 --> 00:20:43,026
any gives point. So let's remember

317
00:20:43,128 --> 00:20:46,100
why we are here. As I said,

318
00:20:48,070 --> 00:20:51,394
at the end of this session, I want you

319
00:20:51,432 --> 00:20:54,440
to be able to, if not find,

320
00:20:55,370 --> 00:20:59,560
understand this, at least find it as soon as possible.

321
00:21:00,730 --> 00:21:04,550
When I say as soon as possible, I mean within

322
00:21:04,620 --> 00:21:06,310
minutes, if not seconds.

323
00:21:07,870 --> 00:21:11,274
I really hope I gave you an option to do

324
00:21:11,312 --> 00:21:14,634
just that. Now I would like to

325
00:21:14,672 --> 00:21:18,010
demo Apache Pinot and especially third eye.

326
00:21:19,170 --> 00:21:22,862
So something

327
00:21:22,916 --> 00:21:26,574
short about the demo. I will demo this I

328
00:21:26,612 --> 00:21:30,490
have on my computer. I've set up a kubernetes

329
00:21:30,570 --> 00:21:35,226
cluster using k three s. I am running Kafka,

330
00:21:35,338 --> 00:21:39,394
Pinot and third eye on my Kubernetes cluster from

331
00:21:39,432 --> 00:21:43,786
my own laptop. I'm sending via telegraph,

332
00:21:43,838 --> 00:21:48,022
I'm sending metrics of my cpu performance to

333
00:21:48,076 --> 00:21:51,446
kafka which will be ingested into Apache P

334
00:21:51,468 --> 00:21:54,738
zero. And thirdeye is going to query

335
00:21:54,834 --> 00:21:58,342
this data every minute. The lowest

336
00:21:58,406 --> 00:22:01,910
we can get actually using Thirdeye is every minute,

337
00:22:02,070 --> 00:22:06,154
and it will try and decipher, or it will try

338
00:22:06,272 --> 00:22:09,994
to see whether there is an anomalies in the data which I'm

339
00:22:10,042 --> 00:22:10,830
sending.

340
00:22:14,050 --> 00:22:17,598
So let me show you the demo of

341
00:22:17,684 --> 00:22:21,222
Apache Pinot and Star Tree third eye.

342
00:22:21,386 --> 00:22:26,050
First of all, I'm going to spin up my canines

343
00:22:26,470 --> 00:22:29,410
and we can have a look at kubernetes.

344
00:22:30,150 --> 00:22:33,730
So everything is in the Pinot Quickstart

345
00:22:34,170 --> 00:22:37,638
namespace. As you can see I have a small

346
00:22:37,804 --> 00:22:41,574
Kafka cluster and then I have Star

347
00:22:41,612 --> 00:22:45,702
Tree mySql, I have all

348
00:22:45,756 --> 00:22:49,594
the different pinot servers, and then here

349
00:22:49,712 --> 00:22:53,622
we have the different Star Tree components

350
00:22:53,766 --> 00:22:57,546
at the end. Zookeeper also is being used

351
00:22:57,648 --> 00:23:01,470
for Star Tree. As you can see,

352
00:23:01,620 --> 00:23:05,706
Pinot itself has many components,

353
00:23:05,898 --> 00:23:08,942
Star Tree as well. And if you want you can run

354
00:23:08,996 --> 00:23:12,674
Apache Pinot straight away. There's a helm chart for

355
00:23:12,712 --> 00:23:16,754
Apache Pinot, the open source. I just used the

356
00:23:16,792 --> 00:23:21,214
quick start guide from Star Tree, which includes Pinot

357
00:23:21,262 --> 00:23:23,940
as well, just for ease of use.

358
00:23:24,810 --> 00:23:28,120
So going ahead,

359
00:23:29,530 --> 00:23:32,934
looking at the UI, I now entered the Ui of

360
00:23:32,972 --> 00:23:34,390
Apache Pinot.

361
00:23:36,010 --> 00:23:40,380
This is what you get, as you can see again,

362
00:23:41,470 --> 00:23:44,982
a lot of components. Let's go to the tables.

363
00:23:45,126 --> 00:23:47,846
There's this one table I have host metrics,

364
00:23:47,878 --> 00:23:51,354
cpu real time. This is the table

365
00:23:51,402 --> 00:23:55,258
I configured in Apache Pinot to receive

366
00:23:55,434 --> 00:23:59,262
all the events I'm sending using telegraph to

367
00:23:59,396 --> 00:24:03,042
Kafka. And this is ingesting straight away from

368
00:24:03,096 --> 00:24:06,674
Kafka so we can have a look at the data. As you can see

369
00:24:06,712 --> 00:24:10,980
at the moment I have over 10,000 data points.

370
00:24:11,990 --> 00:24:15,302
I can run different queries. Now if I run

371
00:24:15,356 --> 00:24:18,646
a query, it doesn't matter what I have in here, as you

372
00:24:18,668 --> 00:24:21,778
can see, the total number of documents

373
00:24:21,874 --> 00:24:25,880
just there were some additions because

374
00:24:26,190 --> 00:24:29,834
every five to 10 seconds more documents are

375
00:24:29,872 --> 00:24:33,178
being entered into this table. This is

376
00:24:33,264 --> 00:24:37,434
a real time table, meaning it

377
00:24:37,472 --> 00:24:41,374
receives data from Kafka and it

378
00:24:41,412 --> 00:24:44,240
is updated at real time.

379
00:24:45,170 --> 00:24:48,430
So let's go and have a look at third eye.

380
00:24:50,210 --> 00:24:53,362
This is Star Tree third eye. This is what you get

381
00:24:53,416 --> 00:24:57,042
when you enter. As you can see, I have this

382
00:24:57,176 --> 00:25:00,914
one alert and I have

383
00:25:01,112 --> 00:25:04,694
ten different anomalies if I would like to look

384
00:25:04,732 --> 00:25:08,178
at the alerts. So this is a cpu alert.

385
00:25:08,354 --> 00:25:11,878
This is what's going on on my laptop as we speak.

386
00:25:12,044 --> 00:25:15,682
Let's go first into configurations. I have configured

387
00:25:15,746 --> 00:25:19,180
the data source which is my Apache P zero.

388
00:25:20,750 --> 00:25:24,566
I have a data set which I configured the host metrics

389
00:25:24,678 --> 00:25:28,874
cpu and these are all the

390
00:25:28,912 --> 00:25:32,754
parameters in the data set, host metrics

391
00:25:32,822 --> 00:25:36,186
cpu. This can be seen also in Apache

392
00:25:36,218 --> 00:25:39,726
Pinot in the table. Then these are all

393
00:25:39,748 --> 00:25:43,530
the alert templates that exist in Star Tree.

394
00:25:43,610 --> 00:25:47,474
Again, there are many which come out of the box and you can always add

395
00:25:47,592 --> 00:25:51,202
yourself. Here are the subscription groups. I didn't add

396
00:25:51,256 --> 00:25:54,526
anything because there is nothing for me to add.

397
00:25:54,648 --> 00:25:58,680
And here are events. Again, I didn't add here anything

398
00:25:59,370 --> 00:26:02,850
either. So let's take a look at the anomalies.

399
00:26:03,010 --> 00:26:06,530
As you can see, I have a lot of anomalies going on

400
00:26:06,620 --> 00:26:10,122
on my computer at the moment. Let's first take a look

401
00:26:10,176 --> 00:26:13,130
at my alert. The alert I configured.

402
00:26:16,510 --> 00:26:19,802
So there are two views. There's a simple view,

403
00:26:19,856 --> 00:26:23,258
there is an advanced view which is basically all the JSON.

404
00:26:23,354 --> 00:26:27,086
I will take a look at the simple view. I configured the name to

405
00:26:27,108 --> 00:26:30,762
be cpu alert. I would like to run it every minute,

406
00:26:30,826 --> 00:26:34,066
every hour, every day. It is based on

407
00:26:34,088 --> 00:26:37,634
the template type start free threshold and again

408
00:26:37,752 --> 00:26:41,074
it is using some I would

409
00:26:41,112 --> 00:26:46,022
like to do the aggregation of a sum on the usage system and

410
00:26:46,076 --> 00:26:49,560
I defined a threshold of 170.

411
00:26:50,970 --> 00:26:54,086
If I do a reload preview I can see actually

412
00:26:54,188 --> 00:26:57,814
the data and I can see the rule being happened

413
00:26:57,942 --> 00:27:00,220
to the data which I have.

414
00:27:02,030 --> 00:27:05,820
So I have this already configured. Let's cancel this,

415
00:27:06,510 --> 00:27:10,238
let's go back to the dashboard. So at the moment I have

416
00:27:10,324 --> 00:27:13,966
14 anomalies. I can go into the anomalies. Let's take

417
00:27:13,988 --> 00:27:16,618
a look at the last anomaly.

418
00:27:16,794 --> 00:27:20,702
I would like to. Let's see the last 1 hour.

419
00:27:20,836 --> 00:27:24,570
I think that's enough. Okay. And the anomaly

420
00:27:24,650 --> 00:27:28,414
just happened. Right now I'm already at the threshold

421
00:27:28,462 --> 00:27:31,774
of 170. Again you can see the dotted

422
00:27:31,822 --> 00:27:35,506
line which is the expected, and you can see the solid

423
00:27:35,538 --> 00:27:39,302
line which is what's happening. So let's go

424
00:27:39,356 --> 00:27:42,710
and investigate our anomalies.

425
00:27:43,290 --> 00:27:47,350
So this is the anomaly. It's right here on the right side.

426
00:27:47,500 --> 00:27:51,430
And here we have the heat map as we seen

427
00:27:51,580 --> 00:27:55,020
in prior. As I've shown you,

428
00:27:55,550 --> 00:27:59,114
you can look at the top contributors, but there's not much

429
00:27:59,152 --> 00:28:02,782
going to be in here. Again, I don't have a lot of data and

430
00:28:02,836 --> 00:28:05,230
I would be able to look at the events.

431
00:28:05,970 --> 00:28:09,258
First of all, I can also change the baseline.

432
00:28:09,354 --> 00:28:13,426
So this is a week. Let's look at the baseline of

433
00:28:13,528 --> 00:28:16,980
one day, which again is not

434
00:28:17,430 --> 00:28:20,978
something I have because I don't have a day's worth of data.

435
00:28:21,064 --> 00:28:24,870
I just collected data for the past maybe

436
00:28:24,940 --> 00:28:28,870
2 hours. Let's go back to see my anomalies.

437
00:28:29,290 --> 00:28:32,440
Let's take something a little before that.

438
00:28:34,250 --> 00:28:37,500
Again, let's take a look at the last 1 hour.

439
00:28:38,350 --> 00:28:40,650
Okay, so this is the anomaly.

440
00:28:42,270 --> 00:28:45,450
And then I can also

441
00:28:45,520 --> 00:28:52,398
say, okay, no, this is not an Anomaly and

442
00:28:52,484 --> 00:28:55,434
this is a Feedback which has been received.

443
00:28:55,562 --> 00:28:58,702
Let's go back and as you can see, before it was on

444
00:28:58,756 --> 00:29:02,066
16, now it is on 15

445
00:29:02,248 --> 00:29:08,146
again, I can also view all the anomalies here and

446
00:29:08,248 --> 00:29:12,130
I can preview this, I can look at it,

447
00:29:12,280 --> 00:29:14,680
there are also a lot of more,

448
00:29:15,930 --> 00:29:16,710
um,

449
00:29:20,410 --> 00:29:23,586
I can also change a lot of parameters.

450
00:29:23,698 --> 00:29:27,580
For instance, I am able to

451
00:29:28,830 --> 00:29:32,762
say, let's say I would like for those

452
00:29:32,816 --> 00:29:35,578
two anomalies to be counted as one.

453
00:29:35,744 --> 00:29:39,680
This is all within the configuration of

454
00:29:40,530 --> 00:29:43,630
here. Merge, Max duration, how many minutes?

455
00:29:43,700 --> 00:29:46,586
I would like it to merge, for instance,

456
00:29:46,778 --> 00:29:49,440
and gap at.

457
00:29:52,210 --> 00:29:56,094
So, well, this is not a new alert, so it's not going to change this

458
00:29:56,132 --> 00:30:00,062
on the fly. But again, if I would create the alert to begin

459
00:30:00,116 --> 00:30:03,638
with like this, it would count these two

460
00:30:03,764 --> 00:30:07,446
as one. Thank you

461
00:30:07,468 --> 00:30:11,106
very much for joining this lecture. I hope you've

462
00:30:11,138 --> 00:30:14,518
learned something today and I hope I can

463
00:30:14,604 --> 00:30:18,342
help you or I help you to

464
00:30:18,396 --> 00:30:22,902
achieve better data consistency and

465
00:30:22,956 --> 00:30:23,890
data integrity.

