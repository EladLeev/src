1
00:00:34,530 --> 00:00:37,634
Azure Container apps is one of many cloud native offerings

2
00:00:37,682 --> 00:00:41,266
in Microsoft Azure, which enables you to run microservices

3
00:00:41,378 --> 00:00:44,440
and containerized applications on a serverless platform.

4
00:00:44,890 --> 00:00:48,342
Azure Container apps enables executing application code

5
00:00:48,396 --> 00:00:52,080
package in any container with any runtime or programming model.

6
00:00:52,530 --> 00:00:55,802
With container apps, you enjoy the benefits of running container

7
00:00:55,866 --> 00:00:59,482
while leaving behind the concerns of managing cloud infrastructure and complex

8
00:00:59,546 --> 00:01:03,226
container orchestrators. My name is Bojan Vrhovnik,

9
00:01:03,258 --> 00:01:06,606
senior Cloud solution architect working for Microsoft,

10
00:01:06,718 --> 00:01:10,114
and in this session we will explore Azure container apps, going from

11
00:01:10,152 --> 00:01:13,394
simple demos to more complex requirements. By moving our

12
00:01:13,432 --> 00:01:17,910
application to container, deploying them on our private registry

13
00:01:18,330 --> 00:01:21,842
manually, or by using command line, and then leveraging automatic

14
00:01:21,906 --> 00:01:25,634
deployments via GitHub, we will improve our applications

15
00:01:25,682 --> 00:01:29,514
gradually and explore different features and options provided by

16
00:01:29,552 --> 00:01:31,930
Azure Container apps solution.

17
00:01:32,990 --> 00:01:36,422
When saying part of cloud native, we mean by integrating

18
00:01:36,486 --> 00:01:39,914
different building blocks to achieve your business goals. You can build

19
00:01:39,952 --> 00:01:43,360
your cloud native apps with Azure fully managed services,

20
00:01:43,730 --> 00:01:47,514
seamlessly integrated development tools and built in enterprise

21
00:01:47,562 --> 00:01:51,182
grade security. You can use the tool and techniques and

22
00:01:51,236 --> 00:01:54,902
technologies of your choice while implementing a microservices

23
00:01:54,986 --> 00:01:58,386
based cloud native architecture that makes it easier to

24
00:01:58,408 --> 00:02:02,434
develop and scale your applications. You can work efficiently through

25
00:02:02,472 --> 00:02:06,050
an end to end development experience, coding, debugging,

26
00:02:06,130 --> 00:02:09,474
deployment, monitoring and management with integrated

27
00:02:09,522 --> 00:02:13,174
tools and DevOps as a process. For example, you can

28
00:02:13,212 --> 00:02:16,946
build container apps, connect to SQL database store files

29
00:02:16,978 --> 00:02:20,570
to Azure storage, audit access and react based on policy

30
00:02:20,720 --> 00:02:24,278
use services to translate text, recognize objects,

31
00:02:24,374 --> 00:02:27,498
get transcripts and more from cognitive services,

32
00:02:27,664 --> 00:02:31,294
enable just in time access verify container images for

33
00:02:31,332 --> 00:02:34,926
vulnerabilities set up continuously delivery integration with

34
00:02:34,948 --> 00:02:38,602
enterprise grade solutions, plugin proven community plugins

35
00:02:38,666 --> 00:02:42,634
to efficiently scale and manage app and much more which is added

36
00:02:42,682 --> 00:02:45,886
each month. In short, it enables you to build not

37
00:02:45,908 --> 00:02:49,106
just container apps, but enterprise grade solutions with focus on

38
00:02:49,128 --> 00:02:53,234
the logic and application itself. The rest is covered by Microsoft and

39
00:02:53,272 --> 00:02:56,882
Azure by having multiple options

40
00:02:56,936 --> 00:03:00,486
to run containers in Azure. Where does our Azure container apps or

41
00:03:00,508 --> 00:03:03,586
short ACA fit in? You can run any containers

42
00:03:03,698 --> 00:03:07,074
in aka its ability to scale down to zero to reduce

43
00:03:07,122 --> 00:03:10,598
cost can be quite useful in background scenarios. For example,

44
00:03:10,764 --> 00:03:14,122
you can execute jobs scale to many instances and after

45
00:03:14,176 --> 00:03:17,466
execution is finished you scale down to zero automatically. Or you

46
00:03:17,488 --> 00:03:20,550
want to host web applications with your own domain certificates,

47
00:03:20,630 --> 00:03:24,446
integrated authentication with multiple versions for users or

48
00:03:24,468 --> 00:03:28,206
you decide to host APIs for your customers to consume by

49
00:03:28,228 --> 00:03:32,190
having an easy way to do bluegreen deployments or a b testing scenarios.

50
00:03:32,530 --> 00:03:35,826
Or perhaps you need a dynamic scale based on the

51
00:03:35,848 --> 00:03:39,374
cpu load or HTTP request or any other factors

52
00:03:39,422 --> 00:03:43,134
which is important for our needs without configuring complex environment

53
00:03:43,182 --> 00:03:46,406
behind the scenes. Or maybe you have multiple teams which

54
00:03:46,428 --> 00:03:50,002
is each building their own microservice and you need integrated

55
00:03:50,066 --> 00:03:53,266
support for failures, the tries, timeouts, distributed calls

56
00:03:53,298 --> 00:03:56,630
over the network, service to service, invocation, pub sub,

57
00:03:56,780 --> 00:04:00,326
different internal and external services and much more. Or maybe

58
00:04:00,348 --> 00:04:03,334
you decided to build a game and you need to scale, you need to spawn

59
00:04:03,382 --> 00:04:07,018
actors, you need to state management with different services and you

60
00:04:07,024 --> 00:04:10,854
need to support without creating all of the infrastructure behind the scenes.

61
00:04:10,982 --> 00:04:14,826
This is just a tip of the iceberg of possible scenarios

62
00:04:14,858 --> 00:04:18,506
with ACA, but we already have solution for that in Azure

63
00:04:18,538 --> 00:04:22,382
which is called Azure Kubernetes service. So how does that compare to

64
00:04:22,436 --> 00:04:26,206
ACA? AKS is infrastructure

65
00:04:26,238 --> 00:04:30,302
focused, which means that you are being highly flexible

66
00:04:30,366 --> 00:04:33,886
where aka is more focused on application and scenes infrastructure

67
00:04:33,918 --> 00:04:37,234
as an obstruction. Now what does that exactly mean now in terms

68
00:04:37,272 --> 00:04:41,202
of control and cost? With aks you have full access to APS server,

69
00:04:41,266 --> 00:04:44,774
you have high level control over the cluster configuration and you pay

70
00:04:44,812 --> 00:04:48,690
for the nodes that you're using. Arca, on the other hand, is an abstraction

71
00:04:48,770 --> 00:04:51,946
built on top of Kubernetes. Without access to APS server you

72
00:04:51,968 --> 00:04:56,198
pay based on what you consume in terms of deployment and developers.

73
00:04:56,294 --> 00:05:00,226
On AKS you deploy via Kubernetes deployment manifests

74
00:05:00,278 --> 00:05:04,206
or YAML or helm charts or CLI. On ACA you

75
00:05:04,228 --> 00:05:08,218
can use the portal CLI or infrastructure as code templates

76
00:05:08,314 --> 00:05:11,866
to deploy container apps. If we look at integration

77
00:05:11,978 --> 00:05:15,902
on aks, you can install, but what you need to also do is maintain

78
00:05:15,966 --> 00:05:19,582
components like Keda, DAPr service mesh.

79
00:05:19,646 --> 00:05:23,550
You need to bootstrap them. On ACA that is fully managed and supported,

80
00:05:23,630 --> 00:05:27,042
you're using the features without having to bootstrap them in the environment.

81
00:05:27,106 --> 00:05:28,870
Let's see this in action.

82
00:05:30,810 --> 00:05:34,146
Let's start by creating a resource inside Azure portal.

83
00:05:34,258 --> 00:05:37,442
Let's select containers as a category

84
00:05:37,586 --> 00:05:40,870
and then find container app. Let's press create

85
00:05:40,940 --> 00:05:44,586
to start with the visit. In this visit we select the

86
00:05:44,608 --> 00:05:48,650
resource group where our application will reside, select some name,

87
00:05:48,800 --> 00:05:52,446
and then we configure the application environment. We will talk

88
00:05:52,468 --> 00:05:56,126
about the application environment a little bit later. Let's leave this as

89
00:05:56,148 --> 00:05:59,822
a default. Next, what we do is set up the

90
00:05:59,956 --> 00:06:03,294
container application. What we define here is what

91
00:06:03,332 --> 00:06:06,626
kind of container we'll be using. What you can do here you can basically

92
00:06:06,728 --> 00:06:11,022
select either Quickstart image which is a sample

93
00:06:11,086 --> 00:06:14,962
container application which is running just a simple web

94
00:06:15,016 --> 00:06:18,706
app, but we can also select our own container registries.

95
00:06:18,818 --> 00:06:22,450
This is by default enabled to accept traffic from anywhere,

96
00:06:22,530 --> 00:06:25,778
which means that this will be publicly available on port 80.

97
00:06:25,954 --> 00:06:29,866
So let's go to the next step where we define text, which are

98
00:06:29,888 --> 00:06:33,622
really nice feature to basically define

99
00:06:33,766 --> 00:06:37,334
value and name pairs to categorize resources,

100
00:06:37,382 --> 00:06:41,470
which can be really handy that we do some billing purposes or we apply

101
00:06:41,540 --> 00:06:44,640
some policies on the subscription level.

102
00:06:45,010 --> 00:06:49,146
So when we press create, what this will do will kick off a deployment.

103
00:06:49,338 --> 00:06:53,102
And what will happen is that if we refresh the

104
00:06:53,236 --> 00:06:57,282
process, it will give us the success of,

105
00:06:57,416 --> 00:07:01,390
it will give us a successful deployment. What we can then do is simply

106
00:07:01,470 --> 00:07:04,750
go to the application URL which we configured.

107
00:07:04,830 --> 00:07:08,162
Let's go back to the slides to learn a little bit more about environments.

108
00:07:08,306 --> 00:07:11,894
So let's go a little bit more into detail. So what happened behind

109
00:07:11,932 --> 00:07:15,606
the scenes? First we filled out a few information about the

110
00:07:15,628 --> 00:07:18,806
container apps, resource groups, in which region we would

111
00:07:18,828 --> 00:07:22,214
like to host application, name of the application and then we needed to specify

112
00:07:22,262 --> 00:07:25,926
an environment. We'll have the default options which created default

113
00:07:25,958 --> 00:07:28,886
settings. But what is an environment,

114
00:07:28,998 --> 00:07:32,102
what are they? In short, they are the virtual boundary

115
00:07:32,166 --> 00:07:35,686
around a collection of container apps. In Kubernetes, we achieve

116
00:07:35,718 --> 00:07:39,134
the same logic with the use of namespaces. We define what we need

117
00:07:39,172 --> 00:07:42,954
and configure the environment based on the requirements. Let's see this

118
00:07:43,092 --> 00:07:46,814
in action. Let's navigate to the container

119
00:07:46,862 --> 00:07:50,462
environment. You can find the container environment in the overview tab.

120
00:07:50,526 --> 00:07:54,638
Let's click it and it will redirect us to the settings.

121
00:07:54,734 --> 00:07:58,690
It will redirect us to the page where we can then set up additional

122
00:07:58,770 --> 00:08:02,450
managed services like DAPR certificates, azure files,

123
00:08:02,530 --> 00:08:06,118
and where we can also configure streaming and monitoring options

124
00:08:06,204 --> 00:08:10,262
for our containers. Here we can see how dapper can be configured

125
00:08:10,406 --> 00:08:13,994
without us putting up or bootstrapping everything from

126
00:08:14,032 --> 00:08:17,466
scratch. We can just use the services. What we can

127
00:08:17,488 --> 00:08:21,018
also do is define where our logs should be

128
00:08:21,104 --> 00:08:24,654
and metrics should be stored. Either we choose Azure log

129
00:08:24,692 --> 00:08:28,430
analytics or Asia monitor and here we can also define what

130
00:08:28,500 --> 00:08:32,378
log analytics should we use. What we can then do is have one source

131
00:08:32,554 --> 00:08:36,274
for all of logs and metrics from our services that we have there,

132
00:08:36,392 --> 00:08:40,302
and we can even go and then search custom tables

133
00:08:40,366 --> 00:08:43,822
with specific information about the containers.

134
00:08:43,886 --> 00:08:48,200
What is the revision, what is the name? And of course additional information

135
00:08:48,730 --> 00:08:52,146
is it is available which ports and so on which can be reviewed.

136
00:08:52,178 --> 00:08:55,590
So when we are debugging our application from scratch,

137
00:09:00,580 --> 00:09:04,196
environment is up and running, we can define services which

138
00:09:04,218 --> 00:09:07,764
will be available to our containers. And in this case what we saw, we were

139
00:09:07,802 --> 00:09:10,948
running a simple container which was provided by the Arca team.

140
00:09:11,034 --> 00:09:14,416
What if we want to run different containers? What if we need to test

141
00:09:14,458 --> 00:09:17,896
out features with subset of users to get a feedback. Or maybe I

142
00:09:17,918 --> 00:09:21,592
want to apply changes without runtime. Or maybe

143
00:09:21,646 --> 00:09:25,188
I want to go back to the previous versions of the container.

144
00:09:25,284 --> 00:09:29,084
How to tackle that challenge? This is where revisions come

145
00:09:29,122 --> 00:09:32,652
into a play. What revisions enables us to do is to have

146
00:09:32,706 --> 00:09:35,804
different versions available, so called snapshots, and we can

147
00:09:35,842 --> 00:09:39,344
decide how the flow of the traffic will go from us

148
00:09:39,382 --> 00:09:42,240
to services. Let's see this in action.

149
00:09:43,540 --> 00:09:47,884
We have a simple ASP. Net core web application with two pages environment

150
00:09:47,932 --> 00:09:51,604
and second page. First contains the code which

151
00:09:51,642 --> 00:09:55,140
reads an environment variable named message. That message

152
00:09:55,210 --> 00:09:59,056
is not in the system. Then it basically outputs

153
00:09:59,088 --> 00:10:02,824
environment variable not set. And then we have a second page which

154
00:10:02,862 --> 00:10:06,644
just displays some text. I built two containers,

155
00:10:06,692 --> 00:10:10,744
one with the link which contains MV files and the second one which

156
00:10:10,782 --> 00:10:12,600
container both of the links.

157
00:10:14,780 --> 00:10:18,636
Let's go to the revision management and create a new revision where we

158
00:10:18,658 --> 00:10:22,424
will use our container which we specified locally.

159
00:10:22,552 --> 00:10:26,556
So what I do in this case is select container image, name it

160
00:10:26,578 --> 00:10:30,208
so that I know how and what I'm basically working on.

161
00:10:30,374 --> 00:10:34,384
Then in this case we will select the web application that

162
00:10:34,422 --> 00:10:38,480
we deployed in. This web applications has a tag name simple

163
00:10:38,550 --> 00:10:41,812
web app environment. In this case only environment link

164
00:10:41,866 --> 00:10:45,312
will be displayed and here we can then add environment

165
00:10:45,376 --> 00:10:48,912
variables. In this case we will use the manual entry

166
00:10:49,056 --> 00:10:52,752
to showcase how this can be done by injecting the environment

167
00:10:52,816 --> 00:10:55,912
variables in. We don't need the simple hello workload demo.

168
00:10:55,966 --> 00:10:59,752
So we will delete this and we will name it with some name

169
00:10:59,806 --> 00:11:03,540
so that we know the revision that we can easily find it in the revision

170
00:11:03,620 --> 00:11:06,988
management. Let's create the revision. After a

171
00:11:06,994 --> 00:11:10,204
few seconds it will provision and it will take all

172
00:11:10,242 --> 00:11:13,916
of the traffic that is available on this website.

173
00:11:14,098 --> 00:11:17,932
And now what we can do is go and click on this link and

174
00:11:17,986 --> 00:11:21,504
select the revision URL, which means it's a pros URL which you can then

175
00:11:21,542 --> 00:11:25,772
check if everything is okay. And now if you click there's an environment variable

176
00:11:25,836 --> 00:11:29,296
which we set is defined there. Now what

177
00:11:29,318 --> 00:11:32,756
we want to do is use the link with second page. So we

178
00:11:32,778 --> 00:11:36,790
want to create a new revision. So what we can do is go and select

179
00:11:37,160 --> 00:11:41,172
container. We want to change this to the second page. In this case

180
00:11:41,226 --> 00:11:44,664
we want to also change the value so that we can know what this

181
00:11:44,702 --> 00:11:49,320
value will be and we save all of the changes appropriately.

182
00:11:50,060 --> 00:11:53,544
Now of course we name it in a way that we understand

183
00:11:53,742 --> 00:11:57,692
so that we can then refer to it when we need it and click

184
00:11:57,746 --> 00:12:02,060
create to basically create the second revision.

185
00:12:03,280 --> 00:12:06,760
When this will finish you will see that we now have two revisions.

186
00:12:06,840 --> 00:12:11,312
One is the simple web and the second one is simple web with

187
00:12:11,366 --> 00:12:15,712
second page. And now that one received 100%

188
00:12:15,766 --> 00:12:19,708
of the traffic. And let's test out to see if this works as expected.

189
00:12:19,804 --> 00:12:23,556
Now we have two links environment valid second page which we see

190
00:12:23,578 --> 00:12:27,236
here with updated environment variable. But what if you want

191
00:12:27,258 --> 00:12:31,140
to do traffic splitting? What if you want to

192
00:12:31,210 --> 00:12:34,600
set, for example, 30% or 50%

193
00:12:34,670 --> 00:12:38,276
or 40% of the traffic to go to a specific URL

194
00:12:38,308 --> 00:12:41,912
to a specific revision? So this is where we can

195
00:12:42,046 --> 00:12:45,384
choose a revision mode multiple where we can then define how

196
00:12:45,422 --> 00:12:49,336
much percent of the traffic will go to this case. For the demo purposes,

197
00:12:49,368 --> 00:12:52,664
we will use 50 50 so that you can see on each second request,

198
00:12:52,712 --> 00:12:56,316
it will basically display a different web page.

199
00:12:56,498 --> 00:13:04,736
So let's save all of these changes and

200
00:13:04,758 --> 00:13:08,016
when these changes will be saved, what we

201
00:13:08,038 --> 00:13:11,776
can then do is check if the revision still works. So we can go to

202
00:13:11,798 --> 00:13:15,330
that revision, check if everything is as it should be.

203
00:13:15,940 --> 00:13:19,108
We can test out the solution. We can either send this link to the customer

204
00:13:19,194 --> 00:13:23,092
to test out the application so we know that everything is as

205
00:13:23,146 --> 00:13:26,484
it should be. And now we can basically see if this

206
00:13:26,522 --> 00:13:30,424
works. So we go to the application URL. The application URL will then hit

207
00:13:30,542 --> 00:13:33,864
the envoy ingress, and then the envoy ingress will then

208
00:13:33,902 --> 00:13:37,704
showcase what is possible or not. So let's refresh a few

209
00:13:37,742 --> 00:13:41,052
times so that you can see the result. As you can see,

210
00:13:41,106 --> 00:13:45,230
second page is now displayed and after refresh that is gone.

211
00:13:47,120 --> 00:13:50,524
In essence, what happened is that container app now has

212
00:13:50,562 --> 00:13:53,724
a multiple version or snapshot of the workload.

213
00:13:53,852 --> 00:13:57,904
And we can then decide by the business rules how to apply our logic and

214
00:13:57,942 --> 00:14:01,804
need without configuring helm chairs or any infrastructure

215
00:14:01,852 --> 00:14:04,450
behind the scenes. Our app is now running,

216
00:14:05,140 --> 00:14:08,516
but then we receive a lot of requests and system is

217
00:14:08,538 --> 00:14:11,984
not handling the load based on what we expect. We need to scale

218
00:14:12,032 --> 00:14:16,180
the solution horizontally to handle the load. Even though we split the traffic,

219
00:14:16,260 --> 00:14:19,912
requests are still coming in and we're not handling the approach of

220
00:14:19,966 --> 00:14:23,796
having a resilient application. So how to configure auto

221
00:14:23,828 --> 00:14:27,400
scaling? Let's check this in azure.

222
00:14:31,660 --> 00:14:36,264
So let's go to the scale and replicas option and

223
00:14:36,302 --> 00:14:40,104
then select the revision that we want to work with. So we will work with

224
00:14:40,142 --> 00:14:44,056
a revision which has the second application both links

225
00:14:44,168 --> 00:14:48,076
and click edit and deploy. We have a tab option which is

226
00:14:48,098 --> 00:14:51,996
called scale. Now this part we can then decide how

227
00:14:52,018 --> 00:14:55,564
much replicas we will have. Now since there is a requirement,

228
00:14:55,612 --> 00:14:59,264
there is a lot of HTTP requests coming in we can

229
00:14:59,302 --> 00:15:02,636
then add a scale rule with concurrent

230
00:15:02,668 --> 00:15:06,836
requests which will handle and which will scale based on that specific

231
00:15:07,018 --> 00:15:10,704
request. So when those requests will be met, it will scale

232
00:15:10,752 --> 00:15:14,550
the replicas accordingly up and down.

233
00:15:16,440 --> 00:15:22,094
Let's create the scale rule and

234
00:15:22,132 --> 00:15:25,902
when the scale rule will be created, we can see that the traffic

235
00:15:25,966 --> 00:15:29,762
now because we created a new revision is

236
00:15:29,816 --> 00:15:33,538
zero. So we need to basically change the revision to

237
00:15:33,704 --> 00:15:37,794
single. We can leave it as is and define the traffic.

238
00:15:37,842 --> 00:15:41,938
But in our case we want to have a support for automatic scaling

239
00:15:42,034 --> 00:15:45,654
based on our app URL. And in this case now

240
00:15:45,692 --> 00:15:49,034
that it's successfully updated, we can then go and

241
00:15:49,072 --> 00:15:52,586
check the application if everything is working. And what we can

242
00:15:52,608 --> 00:15:56,186
see that now the replicas, now the configuration in

243
00:15:56,208 --> 00:15:59,562
this case is that we have minimum two and maximum

244
00:15:59,626 --> 00:16:02,958
ten replicas. And now the system

245
00:16:03,044 --> 00:16:06,458
is provisioned to have all hundred requests

246
00:16:06,554 --> 00:16:08,880
coming in on that side.

247
00:16:13,890 --> 00:16:17,794
Now that we have the basics covered, let us use this knowledge and deploy a

248
00:16:17,832 --> 00:16:21,854
little bit more complex solution to Azure container apps. We will explore

249
00:16:21,902 --> 00:16:25,054
solution on local machine and then set up the environment

250
00:16:25,102 --> 00:16:29,062
in the cloud. Solution is already containerized and is located in

251
00:16:29,116 --> 00:16:32,758
our Azure Container registry. If you want to follow along you

252
00:16:32,764 --> 00:16:36,038
can use scripts in the repositories link is provided on the

253
00:16:36,044 --> 00:16:40,186
screen and go to the scripts folder where you will find various scripts for

254
00:16:40,208 --> 00:16:44,650
various tasks. Let's see the complex application in action.

255
00:16:45,310 --> 00:16:49,482
I built an application, a web application which represents work

256
00:16:49,536 --> 00:16:53,020
tasks which can be private, which can be public,

257
00:16:53,550 --> 00:16:57,658
which you can basically comment on, export to pdf,

258
00:16:57,754 --> 00:17:01,278
get statistic and much more. The idea here is to have a

259
00:17:01,284 --> 00:17:04,674
web application, you have a database. In this case

260
00:17:04,712 --> 00:17:08,354
the database is a SQL database. You're connecting to

261
00:17:08,392 --> 00:17:12,382
that database directly through a repository

262
00:17:12,446 --> 00:17:16,146
pattern. But then again you have a web API

263
00:17:16,258 --> 00:17:20,066
which is exposed internally, which means this application is connecting

264
00:17:20,098 --> 00:17:23,446
to that specific API, getting back the

265
00:17:23,468 --> 00:17:26,706
results about statistics specifically for the sign in users

266
00:17:26,818 --> 00:17:30,210
about the work task, about daily tasks,

267
00:17:30,290 --> 00:17:33,770
public tasks and so on. But then again you also have a public

268
00:17:33,840 --> 00:17:37,866
access which means that user can basically access the application through

269
00:17:37,888 --> 00:17:41,886
a web browser directly through web applications, or he can basically

270
00:17:41,988 --> 00:17:45,722
directly connect to the API that is exposed

271
00:17:45,786 --> 00:17:49,086
publicly to the outside world. Then we have

272
00:17:49,108 --> 00:17:53,018
a background application, a background service which collects

273
00:17:53,034 --> 00:17:56,846
the data out of SQL database and then stores

274
00:17:56,878 --> 00:18:00,754
that data to a file which is located on the file system.

275
00:18:00,872 --> 00:18:04,814
In this case, this file is basically JSON file with all of the statistics

276
00:18:04,862 --> 00:18:08,694
which is daily saved to a specific folder and

277
00:18:08,732 --> 00:18:12,710
then this can be retrieved via API or

278
00:18:12,780 --> 00:18:15,906
via SDK library back to the user

279
00:18:16,018 --> 00:18:19,322
on the system. So how does this look like in

280
00:18:19,376 --> 00:18:22,902
code. Let's go check inside of our developers environment.

281
00:18:22,966 --> 00:18:27,286
The structure here we have UI user interface which contains

282
00:18:27,318 --> 00:18:31,118
the web application, the API and then we also have

283
00:18:31,204 --> 00:18:35,102
the background service. Then we have generators which are generating some data

284
00:18:35,156 --> 00:18:38,590
so they populate database with some bogus data.

285
00:18:38,660 --> 00:18:42,778
Then we have the data layer which basically represents

286
00:18:42,874 --> 00:18:46,706
our models, our repository patterns to connect to

287
00:18:46,728 --> 00:18:50,562
the database behind the scenes and many other useful services.

288
00:18:50,696 --> 00:18:54,034
So let's see this in action application to showcase how

289
00:18:54,072 --> 00:18:57,234
this application looks like and how does it work.

290
00:18:57,272 --> 00:19:00,530
This application will now run on the web server.

291
00:19:00,610 --> 00:19:03,734
You see below that we are running two applications so one

292
00:19:03,772 --> 00:19:07,058
is local web and then we have the report API.

293
00:19:07,234 --> 00:19:10,842
Now when we go here you see that I'm running on my

294
00:19:10,976 --> 00:19:19,354
operating system. If I log in into the system what

295
00:19:19,392 --> 00:19:22,822
I will get is now I'll be redirected to the dashboard

296
00:19:22,886 --> 00:19:26,922
and here I have basically options to see my tasks that are located

297
00:19:26,986 --> 00:19:31,280
here and I can go inside of the task see the comments of this specific

298
00:19:31,810 --> 00:19:35,130
task. What I can then do is go to home. And when I

299
00:19:35,140 --> 00:19:38,674
go to home you'll see that here the API call was

300
00:19:38,712 --> 00:19:42,334
done. This stuff here that you see is basically retrieved

301
00:19:42,462 --> 00:19:46,334
from the report API that is available there giving me latest

302
00:19:46,382 --> 00:19:50,238
stats about my own achievement. If I'm logged

303
00:19:50,254 --> 00:19:53,862
in, if I'm not logging, I don't receive this information back.

304
00:19:53,916 --> 00:19:57,382
And then what I can do as well is go to the task, for example

305
00:19:57,516 --> 00:20:01,098
the public task and say that I would like to download PDF and

306
00:20:01,104 --> 00:20:05,034
this is also issuing a call to the rest API giving me

307
00:20:05,072 --> 00:20:08,614
back the public statistics about tasks

308
00:20:08,662 --> 00:20:12,506
which are available for a specific period of time. Okay, so let's

309
00:20:12,538 --> 00:20:16,586
deploy this application to Azure. Let's create a new resource,

310
00:20:16,698 --> 00:20:20,554
let's go to the containers, create a new container app let's

311
00:20:20,602 --> 00:20:24,334
name our container application with some meaningful

312
00:20:24,382 --> 00:20:28,094
name like conf web and then create a new container

313
00:20:28,142 --> 00:20:31,182
apps environment where we'll specify additional

314
00:20:31,246 --> 00:20:34,786
settings. Let's name that conf n and

315
00:20:34,808 --> 00:20:39,014
then select for monitoring or created local

316
00:20:39,052 --> 00:20:42,354
analytics. Before let's specify the container

317
00:20:42,402 --> 00:20:46,134
app in our container registry, I used a web

318
00:20:46,252 --> 00:20:49,654
for the application with the latest tag

319
00:20:49,782 --> 00:20:53,494
and let us enable the application to be accessible

320
00:20:53,542 --> 00:20:57,782
from the outside workload with a port 80

321
00:20:57,926 --> 00:21:01,434
on top. Let's review and

322
00:21:01,472 --> 00:21:05,610
create the solution and enter

323
00:21:05,760 --> 00:21:08,910
some tags which will help us with the billing purposes.

324
00:21:09,330 --> 00:21:12,670
Let's review and create a deployment.

325
00:21:13,170 --> 00:21:16,434
Let's repeat the same story for the reports and

326
00:21:16,472 --> 00:21:20,254
also for the stats and all other applications

327
00:21:20,302 --> 00:21:23,986
that will be available for us to run. Let's repeat this for

328
00:21:24,008 --> 00:22:09,716
the report API and

329
00:22:09,738 --> 00:22:13,228
let's do the same with our filestat

330
00:22:13,264 --> 00:22:16,904
server. The only difference here is that instead of

331
00:22:17,102 --> 00:22:20,428
accessing it from external we don't need external access.

332
00:22:20,514 --> 00:22:24,284
So we won't be configuring load balancer in this case

333
00:22:24,322 --> 00:22:28,444
because we don't need external access. Let's go and

334
00:22:28,482 --> 00:22:32,092
create some tags for the billing purposes and then review

335
00:22:32,146 --> 00:22:36,240
and create and we are ready to start with the application itself

336
00:22:36,390 --> 00:22:37,920
when this is finished.

337
00:22:50,380 --> 00:22:53,000
Let's go to the container apps.

338
00:22:55,020 --> 00:22:59,368
Let's click on our container

339
00:22:59,464 --> 00:23:02,860
conf web. Let's check

340
00:23:02,930 --> 00:23:06,044
if the container is up and running by

341
00:23:06,082 --> 00:23:09,376
clicking on the application link and we can see that

342
00:23:09,398 --> 00:23:12,672
the application is there. Let's try to create

343
00:23:12,726 --> 00:23:16,480
a new user type in some details

344
00:23:21,650 --> 00:23:25,266
and what we will see is a deployment error because we don't have a

345
00:23:25,288 --> 00:23:28,850
SQL defined we can try the same stuff

346
00:23:28,920 --> 00:23:32,354
with the reports API, but because we don't have

347
00:23:32,392 --> 00:23:36,526
an API endpoint, what we can do is check in the log stream

348
00:23:36,638 --> 00:23:39,766
to see if the application is up and running and we can see that

349
00:23:39,788 --> 00:23:43,458
there are some errors regarding environment variables.

350
00:23:43,634 --> 00:23:47,154
What kind of variables do we need? So in our user

351
00:23:47,202 --> 00:23:50,966
interface web application we have a few variables which we

352
00:23:50,988 --> 00:23:54,234
need to set up. So if you go and check inside of the

353
00:23:54,272 --> 00:23:57,562
application itself, we have an app option,

354
00:23:57,696 --> 00:24:01,254
the URL to the report service. We have the connection

355
00:24:01,302 --> 00:24:05,134
string for a SQL database and then we have some authentication options.

356
00:24:05,252 --> 00:24:08,894
Here below you see an Azure storage settings which

357
00:24:08,932 --> 00:24:12,894
is something that we will implement in the later stages and the same is

358
00:24:12,932 --> 00:24:16,386
with the report API. So if we go here. So here we have the

359
00:24:16,408 --> 00:24:20,610
same options that you saw on the web application and the same

360
00:24:20,760 --> 00:24:24,818
goes for stats service where we have only one option which

361
00:24:24,824 --> 00:24:27,910
is SQL connection string. So let us first fix

362
00:24:27,980 --> 00:24:31,606
the connection string. Connection strings are sensitive data so what

363
00:24:31,628 --> 00:24:35,240
we need to provide is a way to secure that data.

364
00:24:36,010 --> 00:24:39,798
And we will use secrets inside of our container apps in

365
00:24:39,804 --> 00:24:43,770
order to secure our connection string so that malicious users cannot see

366
00:24:43,840 --> 00:24:47,514
the value. Otherwise they will be able to connect to our database. Let us

367
00:24:47,552 --> 00:24:50,874
fix the web application here you will see that we have an option to add

368
00:24:50,912 --> 00:24:54,586
secrets and we will add secrets which are required in our application.

369
00:24:54,688 --> 00:24:58,362
So the first secret that we will be adding is SQL connection string.

370
00:24:58,426 --> 00:25:02,074
So we will name a SQL connection string as a key Sqlcon

371
00:25:02,122 --> 00:25:05,650
so that we can reference it later on and we will add that

372
00:25:05,800 --> 00:25:09,074
to the system itself. What we'll also add is two

373
00:25:09,112 --> 00:25:12,894
things which will then be ready for the later stages.

374
00:25:13,022 --> 00:25:16,180
First will be the API key because

375
00:25:16,550 --> 00:25:20,694
what we need in order to access the application from

376
00:25:20,732 --> 00:25:24,742
our web application is a key because based on that key the

377
00:25:24,796 --> 00:25:28,770
API will know that we are authenticated. So let us copy

378
00:25:28,850 --> 00:25:32,442
some key and then we also

379
00:25:32,496 --> 00:25:36,410
add another secret which is consult. Let me add

380
00:25:36,480 --> 00:25:37,660
this as well.

381
00:25:42,070 --> 00:25:45,814
Hash salt hash is used to

382
00:25:45,932 --> 00:25:49,526
hash the route values. Let me add

383
00:25:49,548 --> 00:25:53,286
this as well. Now we have the secrets added. Let us first check the

384
00:25:53,308 --> 00:25:56,586
application so that we see what is the problem again. So let

385
00:25:56,608 --> 00:25:59,834
me open this web application and as we saw before,

386
00:26:00,032 --> 00:26:03,580
when we go to the web application will run.

387
00:26:04,830 --> 00:26:08,590
So let's go to the login page, register new user,

388
00:26:09,650 --> 00:26:14,862
say enter

389
00:26:14,916 --> 00:26:18,558
subdata, then register and you know that this application

390
00:26:18,644 --> 00:26:22,654
is not working. So let's use the secrets that we added

391
00:26:22,702 --> 00:26:25,918
to the system. Let's go to the release and management.

392
00:26:26,094 --> 00:26:29,860
Let's open this web application and then choose

393
00:26:30,230 --> 00:26:33,970
containers and then set, edit and deploy.

394
00:26:34,550 --> 00:26:38,886
And in this case we can then select the container image that was used.

395
00:26:39,068 --> 00:26:42,658
In this case we are selecting the web and with the latest

396
00:26:42,754 --> 00:26:46,394
version all others is the same. The only stuff that you will add here is

397
00:26:46,432 --> 00:26:50,182
environment variables. First thing that we need to add is the connection string.

398
00:26:50,326 --> 00:26:54,490
So SQL options connection string

399
00:26:56,750 --> 00:27:00,478
and let me add reference a secret and this secret will

400
00:27:00,484 --> 00:27:04,270
be SQL connection string. So we added the SQL connection string.

401
00:27:04,610 --> 00:27:08,558
Let me save the data and

402
00:27:08,644 --> 00:27:11,746
write it here so that we know what we are

403
00:27:11,768 --> 00:27:15,250
referring to and then create the revision.

404
00:27:16,470 --> 00:27:19,902
Now we can go back to the revision. So provision

405
00:27:19,966 --> 00:27:23,970
was successful. So let me go to the overview

406
00:27:24,310 --> 00:27:27,686
and let me run the application again. And now if we

407
00:27:27,708 --> 00:27:31,426
go to the login say that we would like to register

408
00:27:31,538 --> 00:27:34,920
connection string. Let's say that we want to add

409
00:27:35,290 --> 00:27:39,434
boen@outlook.com some

410
00:27:39,552 --> 00:27:43,130
password and when we do register it basically goes through

411
00:27:43,200 --> 00:27:46,730
and regular access to the pages. And now we can go to the tasks,

412
00:27:47,070 --> 00:27:50,910
public tasks, see all of the tasks and basically perform

413
00:27:50,980 --> 00:27:54,766
all of the application that we want. So if we go to the home,

414
00:27:54,868 --> 00:27:58,158
you see that we don't have anything there.

415
00:27:58,244 --> 00:28:02,174
Now it takes a little bit time because we have a try policy enabled

416
00:28:02,222 --> 00:28:05,698
with poly net zero result.

417
00:28:05,784 --> 00:28:09,058
So here you see that page is

418
00:28:09,144 --> 00:28:12,660
presented to us but there's missing something because we didn't provide

419
00:28:13,270 --> 00:28:16,980
any connection string to the reporting service

420
00:28:17,670 --> 00:28:21,382
we fixed the connection string. Now what we need to do is fix

421
00:28:21,436 --> 00:28:24,986
our reporting service access. So let's go to

422
00:28:25,008 --> 00:28:29,114
conf report and copy the application URL and

423
00:28:29,152 --> 00:28:33,206
go back to the conf web, select the containers

424
00:28:33,398 --> 00:28:37,530
and then choose edit and deploy and select

425
00:28:37,600 --> 00:28:40,560
the container that you would like to fix.

426
00:28:41,170 --> 00:28:44,654
And here you see that we have the latest version. What I did

427
00:28:44,692 --> 00:28:48,622
was I added API key and hash salt from

428
00:28:48,676 --> 00:28:52,674
the reference secret. What we need to do now is

429
00:28:52,872 --> 00:28:57,460
add a new option API options

430
00:28:59,030 --> 00:29:03,430
and then underscore report API URL

431
00:29:04,090 --> 00:29:08,006
and in this case it will be manual entry. And this value that we have

432
00:29:08,108 --> 00:29:11,400
here, let's save the

433
00:29:12,170 --> 00:29:15,914
revision, the container changes and let's put in the

434
00:29:15,952 --> 00:29:20,330
name which will be report app

435
00:29:20,910 --> 00:29:22,650
and then create the revision.

436
00:29:26,550 --> 00:29:30,310
Let's go to the overview tab, open the web browser

437
00:29:30,730 --> 00:29:37,160
login with buoyan@outlook.com

438
00:29:38,970 --> 00:29:42,406
log in when we log in what

439
00:29:42,428 --> 00:29:46,710
we can now do is create your task, for example test task

440
00:29:46,870 --> 00:29:52,374
at publicly

441
00:29:52,422 --> 00:29:56,126
available some data safe and we can

442
00:29:56,148 --> 00:29:57,470
add some comments.

443
00:29:59,570 --> 00:30:02,974
And now when we press the home button, what you will see is

444
00:30:03,012 --> 00:30:07,146
we get back result which is the call from the API

445
00:30:07,178 --> 00:30:10,930
itself. So we fix the web application and report service.

446
00:30:11,080 --> 00:30:14,274
Now we need to fix the stats service as well.

447
00:30:14,392 --> 00:30:18,510
So we have a stat service which stores the data inside of file.

448
00:30:18,590 --> 00:30:22,166
Since we didn't configure any volumes or something like that to

449
00:30:22,188 --> 00:30:25,446
store the data, what we get is an exception. When we

450
00:30:25,468 --> 00:30:29,254
go to the lock stream and get an exception that something is wrong.

451
00:30:29,452 --> 00:30:33,214
Now here we explicitly said because this is a background

452
00:30:33,282 --> 00:30:36,746
service, we don't have ingress, right? So ingress is

453
00:30:36,768 --> 00:30:40,490
disabled. But what we want to do now is fix

454
00:30:40,640 --> 00:30:44,970
the specific problem. In order to fix the problem, I already provisioned

455
00:30:45,050 --> 00:30:48,538
in the secrets tab a storage connection string

456
00:30:48,714 --> 00:30:52,478
for the Azure storage. So what we'll be doing is basically

457
00:30:52,564 --> 00:30:56,666
saving all of the files, all of the statistics regularly

458
00:30:56,778 --> 00:31:00,510
each day to a file which will be located in Azure storage.

459
00:31:00,590 --> 00:31:03,954
Now in order for us to use this, I built a new

460
00:31:03,992 --> 00:31:07,342
container which has attack storage

461
00:31:07,486 --> 00:31:11,654
which we can then leverage in order to fix this specific problem in

462
00:31:11,692 --> 00:31:15,282
code. I basically provided an interface, an implementation

463
00:31:15,346 --> 00:31:18,630
which uses blob storage behind the scenes to store the data inside

464
00:31:18,700 --> 00:31:22,822
of the Azure storage. All that code is located on my GitHub.

465
00:31:22,966 --> 00:31:27,546
So let's go to the containers and edit and deploy the containers and

466
00:31:27,568 --> 00:31:31,654
let us change this container to use the connection

467
00:31:31,702 --> 00:31:35,274
string. So in our image

468
00:31:35,322 --> 00:31:38,526
I have a storage option and now what I will do

469
00:31:38,548 --> 00:31:42,682
is I will add the Azure storage

470
00:31:42,826 --> 00:31:47,070
options connection string,

471
00:31:49,030 --> 00:31:51,330
reference the secret that we provided,

472
00:31:55,000 --> 00:31:59,380
save name it storage

473
00:32:00,280 --> 00:32:04,216
and then create the revision when

474
00:32:04,238 --> 00:32:08,392
the revision will be created, let's check if this application is running.

475
00:32:08,526 --> 00:32:12,472
And now what we can do is go to the lock stream and

476
00:32:12,526 --> 00:32:15,808
see our output from the lock.

477
00:32:15,924 --> 00:32:19,100
And after this will connect, we will see that everything

478
00:32:19,170 --> 00:32:22,936
is okay. And here you see that the stats was completed.

479
00:32:23,128 --> 00:32:26,540
Storing the data inside of that file

480
00:32:27,040 --> 00:32:30,704
we fixed the start report, but what is the

481
00:32:30,742 --> 00:32:34,450
challenge? In order to understand that, let's see the implementation itself.

482
00:32:35,060 --> 00:32:38,960
So in the task report controller we have one

483
00:32:39,110 --> 00:32:42,980
app which returns the most active task and this

484
00:32:43,050 --> 00:32:47,360
uses a repository pattern and in this case workloads repository.

485
00:32:47,440 --> 00:32:51,424
So if I go into the details, this is an interface and this interface

486
00:32:51,472 --> 00:32:55,130
has only three methods. So generatestates, gets all

487
00:32:55,980 --> 00:32:59,560
and gets stats based on some defined range.

488
00:32:59,980 --> 00:33:03,884
So what is the problem? So the filestat service

489
00:33:04,002 --> 00:33:07,756
uses on localhost it uses file system to

490
00:33:07,778 --> 00:33:11,144
store the statistics in Azure.

491
00:33:11,192 --> 00:33:14,844
What we did, we implemented this interface with

492
00:33:14,882 --> 00:33:18,416
a blob storage. So if I go to the data you see here that I

493
00:33:18,438 --> 00:33:22,992
have storage data which is just one class which

494
00:33:23,046 --> 00:33:26,736
implements this workload repository. And here you can see that

495
00:33:26,758 --> 00:33:30,916
we have different parameters that we need to provide in

496
00:33:30,938 --> 00:33:34,804
order for it to work with Azure storage. Now if

497
00:33:34,842 --> 00:33:39,136
we wanted to save this to another, for example storage

498
00:33:39,248 --> 00:33:42,724
in order to support another storage, for example SQL

499
00:33:42,772 --> 00:33:46,584
or Cosmos DB, what we need to do is create a new

500
00:33:46,702 --> 00:33:51,124
library and then implement this workload interface

501
00:33:51,252 --> 00:33:54,232
and register this in the reporting service.

502
00:33:54,286 --> 00:33:57,916
So in the reporting service we can go inside of the

503
00:33:57,938 --> 00:34:01,020
program CS and here we have the configuration itself.

504
00:34:01,170 --> 00:34:04,860
Now in my case I configured dapper already, but here for example,

505
00:34:04,930 --> 00:34:09,004
what we could do is then for example say let's copy

506
00:34:09,052 --> 00:34:12,204
this one and we could for example iwork

507
00:34:12,252 --> 00:34:15,852
stats. And let's say that we would like to use blob

508
00:34:15,996 --> 00:34:19,332
work starts repository and then work

509
00:34:19,386 --> 00:34:22,688
starts repository.

510
00:34:22,784 --> 00:34:26,064
The problem here is that now we have three parameters

511
00:34:26,112 --> 00:34:30,196
that we need to provide, which means that we need to then configure the

512
00:34:30,218 --> 00:34:33,472
application settings so that we can then inject

513
00:34:33,536 --> 00:34:37,096
into the application. And then what we need to do is build a

514
00:34:37,118 --> 00:34:40,916
new container. So in this case you see that we have specific settings

515
00:34:40,948 --> 00:34:44,964
that's related to azure storage and then what we need to do in the docker

516
00:34:45,012 --> 00:34:48,600
file. So in the containers folder you'll find all of the docker files.

517
00:34:48,680 --> 00:34:52,556
We need to then provide basically support for that and

518
00:34:52,738 --> 00:34:56,844
tag it appropriately. So how can we solve this problem? This is

519
00:34:56,882 --> 00:35:00,176
where Dapper comes into the play. But what

520
00:35:00,198 --> 00:35:03,724
if we want to change the storage and we don't want to change the container

521
00:35:03,772 --> 00:35:07,628
with new settings, new configuration, new environment, vulnerable snoop

522
00:35:07,644 --> 00:35:11,090
tags and so on. We could create generic service,

523
00:35:11,460 --> 00:35:15,668
but then we can get different requirements for business or customers and

524
00:35:15,754 --> 00:35:19,328
we need to adopt to that change. Maybe we need to observe

525
00:35:19,344 --> 00:35:22,408
the calls or we need to securely communicate between the services.

526
00:35:22,574 --> 00:35:24,920
This is where DAPR shines.

527
00:35:25,740 --> 00:35:29,624
Dapper is portable, event driven, non time that makes it easy

528
00:35:29,662 --> 00:35:33,464
for any developer to build resilient, stateless and stateful applications that

529
00:35:33,502 --> 00:35:37,736
run on the cloud and the edge. It provides best practices for common capabilities

530
00:35:37,848 --> 00:35:41,324
when building microservices application the developer can use

531
00:35:41,362 --> 00:35:44,876
in a standard way and deploy to any environment. It does this by providing a

532
00:35:44,898 --> 00:35:48,896
distributed system building blocks. Each of these building blocks APIs is

533
00:35:48,918 --> 00:35:52,224
independent meaning that you can use one some of them in your

534
00:35:52,262 --> 00:35:55,948
application. So how does it work? It uses sitecar

535
00:35:56,044 --> 00:36:00,076
container pattern. When enabled it will run sidecar container

536
00:36:00,188 --> 00:36:04,320
listening for our request either via HTTP or ViagrPC.

537
00:36:04,400 --> 00:36:07,796
We issue command that we will need state or event and then the

538
00:36:07,818 --> 00:36:11,124
upper side container gets the data and returns info to us.

539
00:36:11,242 --> 00:36:14,856
What we need to do is configure the sidecar container to use the

540
00:36:14,878 --> 00:36:18,964
different stores and our app is then calling in same signature API

541
00:36:19,092 --> 00:36:22,820
without us needed to change all of the structure behind the scenes.

542
00:36:22,900 --> 00:36:26,604
Let's see this in action. Let us first see the implementation in

543
00:36:26,642 --> 00:36:30,616
code. So this DAPR workload repository,

544
00:36:30,808 --> 00:36:34,104
what it does is basically just calls

545
00:36:34,152 --> 00:36:38,524
the DAPR client. It builds the connection

546
00:36:38,572 --> 00:36:42,672
string, everything that is needed and then we call get

547
00:36:42,726 --> 00:36:46,144
state async with state that we want to achieve or we

548
00:36:46,182 --> 00:36:49,700
want to save state on a specific data store

549
00:36:49,850 --> 00:36:53,556
with a specific key and the values that will be stored on

550
00:36:53,578 --> 00:36:57,524
the system. So let's see now how we configure DAPR in

551
00:36:57,562 --> 00:36:59,460
our container apps.

552
00:37:01,320 --> 00:37:04,964
Let us enable DAPR in our environment. So let's go to the container

553
00:37:05,012 --> 00:37:08,440
apps environment. Here we have DAPR components option

554
00:37:08,590 --> 00:37:12,456
and let's click add. So when we add the component we need

555
00:37:12,478 --> 00:37:16,172
to first provide a name state store for example. And then we need to provide

556
00:37:16,226 --> 00:37:19,484
a state type which means a component which

557
00:37:19,522 --> 00:37:23,484
will then receive the state and store the state. In our

558
00:37:23,522 --> 00:37:27,228
case we'll be using blob storage version

559
00:37:27,324 --> 00:37:31,020
one. And then we need to provide some additional metadata.

560
00:37:31,100 --> 00:37:35,010
So for example, first one needs to be account name.

561
00:37:35,540 --> 00:37:38,772
So which account will be using. In this case we have

562
00:37:38,826 --> 00:37:42,772
conf 24 data storage. So this is the

563
00:37:42,906 --> 00:37:46,656
storage that we'll be using. Then we need to provide container

564
00:37:46,688 --> 00:37:50,390
name so which containers will be

565
00:37:51,420 --> 00:37:55,464
accessing. So we have everything stored inside of

566
00:37:55,502 --> 00:37:58,392
files. So let's go and enter that one.

567
00:37:58,526 --> 00:38:02,644
And then we will need to provide some authentication mechanism asian

568
00:38:02,692 --> 00:38:05,836
client id with specific value.

569
00:38:05,938 --> 00:38:10,652
So let's put in just some of the values inside because

570
00:38:10,706 --> 00:38:14,030
we need to configure this later on. Which means

571
00:38:16,320 --> 00:38:20,370
what we need to provide to the DAPR side car container is

572
00:38:20,740 --> 00:38:23,964
authentication mechanism so that he can authenticate

573
00:38:24,012 --> 00:38:28,416
to azure storage. In this case the blob storage container name.

574
00:38:28,518 --> 00:38:31,656
And next, what we need to provide is the scope.

575
00:38:31,708 --> 00:38:35,172
So which application will be able to load this

576
00:38:35,226 --> 00:38:38,884
component inside of their apps. So let me add this, we will

577
00:38:38,922 --> 00:38:42,292
change this later on because we need to configure the application yet.

578
00:38:42,346 --> 00:38:45,268
So let's go back to the apps,

579
00:38:45,364 --> 00:38:49,652
let's go to the app. And now what we need to do is enable DAPR.

580
00:38:49,796 --> 00:38:53,464
So we will enable Dapper in this case and provide some information

581
00:38:53,582 --> 00:38:57,492
so we can provide the name. So in this case conf reports

582
00:38:57,636 --> 00:39:01,276
which protocol we'll be using. In this case we'll be

583
00:39:01,298 --> 00:39:05,500
using HTTP. So how will our application communicate to

584
00:39:05,570 --> 00:39:09,136
this sidecar container? And then we will save

585
00:39:09,238 --> 00:39:13,024
these settings. So when we save this, we configured our

586
00:39:13,062 --> 00:39:16,988
application to use DAPR, this will be saved. We need to define

587
00:39:17,164 --> 00:39:20,976
which application will be able to use the components that we are configure

588
00:39:21,088 --> 00:39:24,468
inside of our container environment. So let's go now back to the

589
00:39:24,554 --> 00:39:28,708
container environment in

590
00:39:28,714 --> 00:39:32,570
the DAPR components and then click the state store.

591
00:39:32,940 --> 00:39:36,330
And what we should see now is an ability to add

592
00:39:36,700 --> 00:39:40,024
apps. And let's add conf reports ad

593
00:39:40,062 --> 00:39:43,224
which we configured earlier and

594
00:39:43,262 --> 00:39:46,652
now basically save the DAPR component. So this state store

595
00:39:46,706 --> 00:39:50,296
will now be available to our application. So let's

596
00:39:50,328 --> 00:39:54,204
go inside of our application and on the dapper you will see

597
00:39:54,242 --> 00:39:58,176
that now this application can use state store

598
00:39:58,278 --> 00:40:02,050
component which we configure in the environment itself.

599
00:40:03,140 --> 00:40:07,024
Let us save all of the changes and when

600
00:40:07,062 --> 00:40:10,596
these changes are saved let's configure our component to be

601
00:40:10,618 --> 00:40:13,940
able to communicate to azure storage.

602
00:40:14,600 --> 00:40:18,516
I compiled a new container which I need to configure to

603
00:40:18,538 --> 00:40:22,356
use DAPR. So let's go to the containers,

604
00:40:22,468 --> 00:40:26,964
edit and deploy and click on the conf report storage

605
00:40:27,092 --> 00:40:31,268
and change this to dapper. Let me use image

606
00:40:31,284 --> 00:40:35,240
tag which is DAPR which uses the aps that we saw earlier.

607
00:40:35,400 --> 00:40:39,032
And what you need to do now is configure some settings.

608
00:40:39,096 --> 00:40:43,790
First what we need to do is define tapper options,

609
00:40:45,040 --> 00:40:48,320
underscore store name. So the name that we

610
00:40:48,390 --> 00:40:52,028
specified in our case is what stays stored.

611
00:40:52,204 --> 00:40:55,840
And then we also need to provide a key, right? So we need to provide

612
00:40:55,910 --> 00:41:01,910
a key which is tapper options key

613
00:41:02,520 --> 00:41:07,140
manual entry and then work stats

614
00:41:10,120 --> 00:41:12,410
and let us save these changes.

615
00:41:13,420 --> 00:41:16,728
Define here dapper and then

616
00:41:16,814 --> 00:41:20,696
create the revision why

617
00:41:20,798 --> 00:41:25,052
work starts? Because in storage account under

618
00:41:25,106 --> 00:41:28,856
the files container we have the work starts

619
00:41:28,888 --> 00:41:32,444
file which component will be basically reading and

620
00:41:32,482 --> 00:41:36,190
writing to. So let's go back to see if this

621
00:41:36,560 --> 00:41:39,356
finished, when this will refresh.

622
00:41:39,468 --> 00:41:42,912
You see that we have solution up and running.

623
00:41:43,046 --> 00:41:46,236
But if we click in the containers tab,

624
00:41:46,428 --> 00:41:50,396
what we can see is that we have now DApr D and Dapper D

625
00:41:50,438 --> 00:41:53,796
is now configured to basically listen. So this is

626
00:41:53,818 --> 00:41:57,396
a site container that is basically listening to requests that are

627
00:41:57,418 --> 00:42:01,350
coming in. So let's create a request. So let me clear this

628
00:42:02,440 --> 00:42:05,876
and connect. So let me go to the, let's copy

629
00:42:05,908 --> 00:42:09,336
this URL, open a new tab and execute the

630
00:42:09,358 --> 00:42:12,520
request. So when we go to the lock stream,

631
00:42:13,100 --> 00:42:16,844
what we then found out is that Dapper is

632
00:42:16,882 --> 00:42:20,428
basically getting an exception. And you

633
00:42:20,434 --> 00:42:24,456
can see here that it has a problem with the identity because we didn't configure

634
00:42:24,568 --> 00:42:27,880
the identity, failed to acquire a token. So if we

635
00:42:27,890 --> 00:42:31,904
go to the DAPR as is here inside

636
00:42:32,022 --> 00:42:35,612
what you can see that ifidconf

637
00:42:35,756 --> 00:42:39,044
instance specific instance scope and

638
00:42:39,082 --> 00:42:43,264
so on. So it basically communicated between the replicas,

639
00:42:43,312 --> 00:42:47,396
but it didn't executed the request to

640
00:42:47,418 --> 00:42:50,596
the file storage. So let's configure the DAPR component to

641
00:42:50,618 --> 00:42:54,200
be able to authenticate to azure storage.

642
00:42:55,020 --> 00:43:02,394
Let's create a user identity and

643
00:43:02,432 --> 00:43:06,006
provide some information. 24 source

644
00:43:06,038 --> 00:43:09,338
group specify the region and of course the name that you'll

645
00:43:09,354 --> 00:43:12,826
be using. And let's define also environment variables

646
00:43:12,858 --> 00:43:16,350
for billing purposes. Let's wait for this to finish,

647
00:43:16,500 --> 00:43:20,754
then go to Conf 24 to basically add access

648
00:43:20,872 --> 00:43:24,414
and rights to be able to access the storage.

649
00:43:24,462 --> 00:43:27,602
Let's use data contributor in this case and select

650
00:43:27,656 --> 00:43:30,690
the principals which will have the access. This case,

651
00:43:30,760 --> 00:43:34,210
our principal will be user assigned identity with

652
00:43:34,280 --> 00:43:37,714
report tamper user identity as we selected.

653
00:43:37,842 --> 00:43:41,480
Let's review and assign when we did this,

654
00:43:41,850 --> 00:43:44,846
let's go back to that user identity,

655
00:43:44,978 --> 00:43:48,234
copy the client id because this is something that we will need in order

656
00:43:48,272 --> 00:43:51,398
to set up our component.

657
00:43:51,574 --> 00:43:55,594
Let's go to that component and we had

658
00:43:55,792 --> 00:43:58,910
Azure client id which will now populate and

659
00:43:58,980 --> 00:44:00,830
edit the details.

660
00:44:01,890 --> 00:44:05,466
Now we need to go back to the application and configure

661
00:44:05,498 --> 00:44:08,778
the identity so that it will be aware of that identity.

662
00:44:08,954 --> 00:44:13,022
Let's go inside of user assigned identity and add the identity

663
00:44:13,086 --> 00:44:17,026
that we configured and save to changes.

664
00:44:17,208 --> 00:44:21,650
When this will be saved, let's go to the revision management

665
00:44:22,010 --> 00:44:24,070
and since there were some changes,

666
00:44:24,220 --> 00:44:27,670
let's restart the revision

667
00:44:29,930 --> 00:44:31,800
to pick up all of the changes.

668
00:44:44,060 --> 00:44:47,420
And now check if the application is up and running. Yes,

669
00:44:47,570 --> 00:44:50,604
now let's go and issue another request to see if

670
00:44:50,642 --> 00:44:54,808
everything is working expected. So let's refresh the URL.

671
00:44:54,904 --> 00:44:58,190
And now what we should see is a result back.

672
00:44:59,460 --> 00:45:03,152
Now the application is up and running. If you want, we can also

673
00:45:03,286 --> 00:45:06,528
define continuous deployment. So if we have our application

674
00:45:06,614 --> 00:45:09,948
on GitHub. We can easily signup in in GitHub,

675
00:45:10,044 --> 00:45:13,604
use a repository, and then define where those

676
00:45:13,642 --> 00:45:17,716
images should be stored, when the application will execute the build process.

677
00:45:17,898 --> 00:45:21,744
In our case 24 the GitHub action

678
00:45:21,792 --> 00:45:25,156
will tag the images with the GitHub commit id, but we

679
00:45:25,178 --> 00:45:28,628
can modify that action based on our needs.

680
00:45:28,794 --> 00:45:32,516
To recap, what we saw is just a glimpse of what is possible with

681
00:45:32,538 --> 00:45:36,620
Azure container apps and how we can focus on the application business,

682
00:45:36,690 --> 00:45:40,590
lodging, and making sure we don't lose time on the infrastructure itself.

683
00:45:41,040 --> 00:45:44,524
For more details, check out these great resources and

684
00:45:44,562 --> 00:45:45,400
thank you for listening.

