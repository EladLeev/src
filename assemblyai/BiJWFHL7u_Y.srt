1
00:00:22,970 --> 00:00:26,194
Hi everybody, my name is Julian, I'm chief evangelist

2
00:00:26,242 --> 00:00:29,414
for hugging face. In this presentation, I would like to

3
00:00:29,452 --> 00:00:33,186
introduce you to building natural language processing applications

4
00:00:33,298 --> 00:00:37,126
with transformers. A few years ago,

5
00:00:37,228 --> 00:00:40,498
deep learning exploded onto the stage.

6
00:00:40,674 --> 00:00:44,178
And this was based by can alignment of planets,

7
00:00:44,274 --> 00:00:47,958
so to speak. So the first planet was the

8
00:00:48,124 --> 00:00:52,080
resurrection of neural networks pretty could technology,

9
00:00:52,770 --> 00:00:56,858
but brought back and applied

10
00:00:56,954 --> 00:01:00,394
to computer vision, natural language processing

11
00:01:00,442 --> 00:01:03,666
and generally working with unstructured data.

12
00:01:03,768 --> 00:01:06,050
And that proved to be very efficient.

13
00:01:07,510 --> 00:01:10,754
What made it possible also for companies to use

14
00:01:10,792 --> 00:01:14,082
deep learning was these availability of a few open

15
00:01:14,136 --> 00:01:17,846
data sets. As we know, deep learning is very data hungry. You need a

16
00:01:17,868 --> 00:01:21,622
lot of data to train deep learning models. And obviously having

17
00:01:21,676 --> 00:01:25,426
those freely available data sets like imagenet

18
00:01:25,458 --> 00:01:27,910
for computer vision was a big boost.

19
00:01:29,950 --> 00:01:34,810
Computer is critical when working with deep learning. And gpus

20
00:01:35,390 --> 00:01:39,498
became available and applicable for

21
00:01:39,664 --> 00:01:43,550
other things that 3d games, and they became available

22
00:01:43,620 --> 00:01:46,906
on the cloud as well. So all of a sudden it was easier

23
00:01:47,018 --> 00:01:50,910
to grab the compute power that you needed and apply

24
00:01:50,980 --> 00:01:54,482
it to deep learning problems and putting

25
00:01:54,536 --> 00:01:58,130
everything together. A collection of tools,

26
00:01:58,470 --> 00:02:02,098
open resources tools mostly also become available.

27
00:02:02,264 --> 00:02:05,658
Libraries like Theano Torch,

28
00:02:05,854 --> 00:02:09,590
later Tensorflow became available for

29
00:02:09,740 --> 00:02:12,902
experts, mostly because if you remember these

30
00:02:12,956 --> 00:02:16,454
days, it was not so easy to build your

31
00:02:16,492 --> 00:02:19,674
models and train them, et cetera. So you still

32
00:02:19,712 --> 00:02:22,234
needed to know quite a bit about machine learning.

33
00:02:22,432 --> 00:02:26,426
And developers and generally people

34
00:02:26,608 --> 00:02:30,010
without a machine learning background found it difficult to

35
00:02:30,080 --> 00:02:33,982
actually train models. But still, this was all a very nice step

36
00:02:34,036 --> 00:02:37,118
forward. And so a few years later,

37
00:02:37,284 --> 00:02:40,346
this is what a typical machine learning and deep

38
00:02:40,378 --> 00:02:43,540
learning project looks like. And although we like to

39
00:02:43,910 --> 00:02:47,570
pretend it's very agile and it looks like a flywheel,

40
00:02:48,230 --> 00:02:52,194
again, let's be honest, it's really a waterfall project where

41
00:02:52,232 --> 00:02:56,420
a lot of time is spent preparing data, cleaning data,

42
00:02:57,030 --> 00:03:01,078
and that's going to be at least 50%, maybe up to 80%

43
00:03:01,244 --> 00:03:04,534
of the time you spend on your project, and then

44
00:03:04,572 --> 00:03:07,910
you move on to training and evaluating results,

45
00:03:08,730 --> 00:03:11,926
training again and again, managing infrastructure in the

46
00:03:11,948 --> 00:03:15,882
process, and then eventually deploying your model

47
00:03:15,936 --> 00:03:19,114
in production, which is typically the hardest part, because now

48
00:03:19,152 --> 00:03:23,290
you have to live with that model in production, monitor it, et cetera, et cetera,

49
00:03:23,370 --> 00:03:25,600
scale it. Not an easy thing.

50
00:03:26,130 --> 00:03:29,870
So quite a few hurdles to clear. And unfortunately,

51
00:03:31,170 --> 00:03:34,866
the inevitable happened, which is that a lot

52
00:03:34,888 --> 00:03:38,626
of companies, a lot of organizations found it really

53
00:03:38,728 --> 00:03:42,862
difficult to actually deliver deep learning projects in production.

54
00:03:43,006 --> 00:03:46,662
And you can see those numbers. Over 80% of data

55
00:03:46,716 --> 00:03:49,910
science projects actually don't make it into production,

56
00:03:50,410 --> 00:03:53,078
which is really a shame. A POC is nice,

57
00:03:53,164 --> 00:03:56,866
but business value means you have to deploy

58
00:03:56,898 --> 00:04:00,106
in prod, and very few companies manage to

59
00:04:00,128 --> 00:04:03,654
do that. Again, only a fraction

60
00:04:03,702 --> 00:04:07,210
of companies today actually say that they get business

61
00:04:07,280 --> 00:04:10,986
value and adoption on deep learning.

62
00:04:11,088 --> 00:04:15,410
So that's a shame because it's really cool technology, but it's

63
00:04:15,430 --> 00:04:18,846
still very challenging to work with, so something a

64
00:04:18,868 --> 00:04:23,570
little different is needed. And this is what I call deep training 20.

65
00:04:23,720 --> 00:04:27,860
Hopefully it's not deep learning 1.1, but I guess we'll find out.

66
00:04:28,310 --> 00:04:32,030
And so we see similar planets

67
00:04:32,110 --> 00:04:36,386
aligning, except the technologies have evolved.

68
00:04:36,498 --> 00:04:40,242
So neural networks and neural network

69
00:04:40,386 --> 00:04:43,862
architectures like cnns and stms are

70
00:04:43,916 --> 00:04:47,858
actually being replaced by a new type of neural architecture

71
00:04:47,874 --> 00:04:51,270
called transformers. And I'm sure you've heard about Bert

72
00:04:51,430 --> 00:04:55,254
released by Google a few years ago, 2017 to be precise.

73
00:04:55,382 --> 00:04:59,606
Well, this is pretty much the birth of transformers,

74
00:04:59,718 --> 00:05:02,938
and now transformers are evolving and we'll

75
00:05:02,954 --> 00:05:07,310
see some examples. Instead of building data sets,

76
00:05:07,730 --> 00:05:10,842
practitioners now rely more and more on these technical

77
00:05:10,906 --> 00:05:13,906
transfer learning, which we'll discuss in a little more detail.

78
00:05:14,088 --> 00:05:18,638
In a nutshell, transfer learning means starting from pretrained models

79
00:05:18,814 --> 00:05:22,846
and applying these knowledge, so to speak, that those models

80
00:05:22,878 --> 00:05:26,958
have learned to your own business problem, potentially training

81
00:05:26,974 --> 00:05:30,374
a little bit in the process. But that's a much simpler thing than

82
00:05:30,412 --> 00:05:33,030
just building a huge data set from scratch.

83
00:05:33,610 --> 00:05:36,726
Gpus, of course, are still around, but now

84
00:05:36,748 --> 00:05:39,942
we see some companies building machine learning hardware.

85
00:05:40,006 --> 00:05:43,674
So chips for prediction and training that

86
00:05:43,712 --> 00:05:47,370
have been built for machine learning from the ground up.

87
00:05:47,440 --> 00:05:50,220
And as you can guess, these deliver quite a few benefits.

88
00:05:51,410 --> 00:05:55,178
And now tools have become friendlier. You don't

89
00:05:55,194 --> 00:05:58,666
need to be an expert to get good results.

90
00:05:58,858 --> 00:06:03,158
If you're a developer, an application developer, back end developer,

91
00:06:03,354 --> 00:06:07,454
you can train and deploy these models

92
00:06:07,502 --> 00:06:10,786
in a much easier way than before

93
00:06:10,968 --> 00:06:14,970
without having to know all the nitty gritty details

94
00:06:15,150 --> 00:06:18,870
that used to come with deep training. So definitely the training

95
00:06:18,940 --> 00:06:21,720
curve is much flatter now.

96
00:06:22,330 --> 00:06:26,150
So let's look at all those four new planets. So Transformers

97
00:06:26,970 --> 00:06:30,646
is both a new model architecture, as I mentioned, but it's

98
00:06:30,678 --> 00:06:34,486
also an open source libraries that hugging

99
00:06:34,518 --> 00:06:38,234
face, my company is the steward for, with the help of

100
00:06:38,352 --> 00:06:41,242
the community, obviously. And in fact,

101
00:06:41,296 --> 00:06:44,606
it's one of these fastest growing open source project

102
00:06:44,708 --> 00:06:48,346
in history. You can see the GitHub stars on this slide.

103
00:06:48,458 --> 00:06:52,786
Hugging face transformers are actually the yellow line, and you can see it

104
00:06:52,808 --> 00:06:55,998
has the steepest slope,

105
00:06:56,174 --> 00:06:59,826
which we're really proud of. And it's pretty funny to

106
00:06:59,848 --> 00:07:04,020
see that we're actually growing faster than very

107
00:07:04,970 --> 00:07:08,802
popular projects like Kubernetes or Node

108
00:07:08,866 --> 00:07:12,646
or Pytorch. So we're really grateful. We see

109
00:07:12,668 --> 00:07:16,246
a ton of adoption from the community. And it's not

110
00:07:16,268 --> 00:07:20,570
just the community. We also see analysts

111
00:07:21,230 --> 00:07:25,158
and generally the IT community acknowledging

112
00:07:25,334 --> 00:07:29,260
that transformers are become a thing.

113
00:07:29,630 --> 00:07:33,054
So transformers are not just for NLP. They started for

114
00:07:33,092 --> 00:07:36,990
NLP, but now they're expanding into computer vision,

115
00:07:37,890 --> 00:07:41,306
speech and audio and reinforcement learning and all kinds

116
00:07:41,338 --> 00:07:44,654
of areas. And the Kaggle

117
00:07:44,702 --> 00:07:49,090
report shows, as mentioned, that traditional deep learning

118
00:07:49,240 --> 00:07:52,926
architectures, if there is such a thing like RNNs

119
00:07:52,958 --> 00:07:57,778
and CNNs, are actually less and less popular, while transformers

120
00:07:57,874 --> 00:08:01,906
are more and more popular. So all these point at the fact that transformers

121
00:08:01,938 --> 00:08:06,294
are really rising and are become the

122
00:08:06,332 --> 00:08:09,340
next standard way for a lot of machine training problems.

123
00:08:11,070 --> 00:08:14,698
And just to give you some numbers, on our website

124
00:08:14,784 --> 00:08:18,106
called the hugging face. Hugging face Co.

125
00:08:18,288 --> 00:08:22,106
We see about 1 million model downloads

126
00:08:22,138 --> 00:08:26,830
every day. That's a good number and it's rising. So transformers,

127
00:08:27,170 --> 00:08:31,406
the next big thing. We think transfer

128
00:08:31,508 --> 00:08:35,330
learning. It's the second planet. So transfer learning again means instead

129
00:08:35,400 --> 00:08:39,554
of training from scratch on a huge data set

130
00:08:39,592 --> 00:08:42,740
that was very painful to build and clean,

131
00:08:43,270 --> 00:08:47,010
you start from a pretrained model that

132
00:08:47,080 --> 00:08:50,486
matches the business problem you're trying to solve. And you can see

133
00:08:50,508 --> 00:08:54,600
on this slide the list of task types that are available today

134
00:08:55,130 --> 00:08:58,754
on the hugging face hub. So as mentioned, lots of NLP,

135
00:08:58,802 --> 00:09:02,398
but also computer vision, audio and some newer task

136
00:09:02,434 --> 00:09:05,930
types. So you find something here that

137
00:09:06,000 --> 00:09:09,498
matches your business problem, you go and select

138
00:09:09,664 --> 00:09:12,846
a few models for this. They've been pretrained on

139
00:09:12,868 --> 00:09:16,890
a very, very large data set, I think Wikipedia

140
00:09:16,970 --> 00:09:20,254
or even bigger, billions and billions of words,

141
00:09:20,452 --> 00:09:23,966
millions and millions of images, and you can test it in

142
00:09:23,988 --> 00:09:27,842
a few seconds. I'll show you how on the next slide. So you can very

143
00:09:27,896 --> 00:09:31,714
quickly run some tests and figure out does this model work

144
00:09:31,752 --> 00:09:35,282
for me out of the box? And a lot of times

145
00:09:35,336 --> 00:09:38,790
it will. So for example, if you need to do, let's say organizations

146
00:09:39,850 --> 00:09:42,390
or you need to do sentiment analysis,

147
00:09:43,290 --> 00:09:45,958
most of the time it's going to work out of the box and it's going

148
00:09:45,964 --> 00:09:48,794
to be just fine, right? So that's it.

149
00:09:48,832 --> 00:09:52,186
You're done. You can take the model and move on

150
00:09:52,208 --> 00:09:55,100
to deploying it. So that was fast.

151
00:09:55,470 --> 00:09:58,842
Now sometimes you will need to fine tune these model.

152
00:09:58,896 --> 00:10:02,478
So you will need to specialize the model on your data.

153
00:10:02,564 --> 00:10:05,326
And that's the transfer learning part.

154
00:10:05,508 --> 00:10:08,750
Okay, you're going to say, well, now I'm training

155
00:10:08,820 --> 00:10:12,250
again, right? So how is that simpler? Well, it is simpler because

156
00:10:12,420 --> 00:10:16,034
a, you need just a little bit of data,

157
00:10:16,152 --> 00:10:19,854
right? It's one or two orders of magnitude

158
00:10:19,982 --> 00:10:23,700
less data than training from scratch. And so

159
00:10:24,630 --> 00:10:28,440
that's going to be faster, to build faster, to train,

160
00:10:29,450 --> 00:10:32,982
less expensive. And you

161
00:10:33,036 --> 00:10:36,534
need just a few lines of code, thanks to

162
00:10:36,572 --> 00:10:39,702
the transformers library. We'll see an example in a minute.

163
00:10:39,766 --> 00:10:43,386
Okay. Transfer learning is much, much faster than training from

164
00:10:43,408 --> 00:10:46,970
scratch because you don't have to build that huge data set,

165
00:10:47,040 --> 00:10:51,038
basically. So here's an example of

166
00:10:51,124 --> 00:10:53,722
working with the hugging face library,

167
00:10:53,866 --> 00:10:56,910
Transformers library, using the high level object

168
00:10:56,980 --> 00:11:00,160
called pipeline. And you can see in one line of code,

169
00:11:00,530 --> 00:11:04,560
I can build a model for

170
00:11:05,810 --> 00:11:09,762
translation. And it's a multi language model

171
00:11:09,816 --> 00:11:13,010
in this case. So you can see the first token is actually

172
00:11:13,080 --> 00:11:17,266
the name of the target language from starting from English.

173
00:11:17,458 --> 00:11:21,110
So here I'm translating from English to Hungarian.

174
00:11:21,690 --> 00:11:25,606
And all it takes is that one line of code here and I can

175
00:11:25,628 --> 00:11:29,590
see the result. And then I can build a second pipeline to classify

176
00:11:29,670 --> 00:11:32,970
the tokens in my translation. Again, I'm using

177
00:11:33,040 --> 00:11:38,582
an off the shelf model. So this one is built for token

178
00:11:38,646 --> 00:11:42,170
classifications in Hungarian. Okay. I did not train

179
00:11:42,240 --> 00:11:45,726
anything here. So that shows you the depth of models that

180
00:11:45,748 --> 00:11:49,054
we have on the hugging face hub. And again, I can

181
00:11:49,092 --> 00:11:52,454
predict and you can see the results. Right. So dates,

182
00:11:52,522 --> 00:11:56,494
persons, ordinals, and GPE means geopolitical

183
00:11:56,542 --> 00:11:59,330
entity. So it's a country name in this case.

184
00:11:59,480 --> 00:12:03,262
So five lines of code. And I'm doing entity extraction

185
00:12:03,326 --> 00:12:06,866
with translation in English, from English to

186
00:12:06,888 --> 00:12:10,326
Hungarian. Right. So that's pretty cool. That's not going

187
00:12:10,348 --> 00:12:13,766
to take a lot of time to try and not a lot of time to

188
00:12:13,788 --> 00:12:16,440
deploy either. Okay, so pretty nice.

189
00:12:17,290 --> 00:12:20,554
Let me show you a more complex demo. So here

190
00:12:20,592 --> 00:12:24,566
I'm skills using off the shelf models, no training involved.

191
00:12:24,758 --> 00:12:28,614
And I'm going to do voice queries on financial documents.

192
00:12:28,742 --> 00:12:32,110
Okay, so the two models I'm using is first

193
00:12:32,260 --> 00:12:35,834
a speech to text model with built in translation.

194
00:12:35,882 --> 00:12:39,786
This is a very cool model from Facebook. So I'm

195
00:12:39,818 --> 00:12:43,566
going to record a sentence in French.

196
00:12:43,678 --> 00:12:47,730
It's going to be translated to English, and that

197
00:12:47,800 --> 00:12:51,810
text query is going to be used by the second model

198
00:12:51,960 --> 00:12:54,274
to run semantic search.

199
00:12:54,472 --> 00:12:58,722
Right. Trying to match the close sentences

200
00:12:58,866 --> 00:13:02,342
in that document corpus again, which is built from

201
00:13:02,476 --> 00:13:06,406
SEC filings, annual reports from large american

202
00:13:06,508 --> 00:13:09,830
companies. Okay. Okay, so here's my app.

203
00:13:09,980 --> 00:13:13,830
Let's give it a try. Okay, so I'm going to record something here in French

204
00:13:13,990 --> 00:13:17,450
and we're going to run the query and then I'll show you

205
00:13:17,520 --> 00:13:21,660
the code real quick. Okay, so let's try this

206
00:13:23,310 --> 00:13:25,470
keylo CFO the gap.

207
00:13:27,330 --> 00:13:31,306
Okay, so I have my clip now key yellow CF

208
00:13:31,338 --> 00:13:35,102
for the gap. Okay. And now if I click on submit

209
00:13:35,166 --> 00:13:39,298
here again, this speech is going to be turned into text

210
00:13:39,384 --> 00:13:42,980
and translated. And we're using to run the query. All right,

211
00:13:43,350 --> 00:13:47,414
so we can see the clock ticking. These should

212
00:13:47,452 --> 00:13:50,870
take a few seconds. And if I scroll down,

213
00:13:51,020 --> 00:13:54,662
I can see. So I can see what I actually

214
00:13:54,716 --> 00:13:58,682
said, which is, who's the CFO at gap? And I can see the top

215
00:13:58,736 --> 00:14:02,506
matching documents here, which obviously are the

216
00:14:02,528 --> 00:14:06,374
annual report for gap. Right? And we see the top matching

217
00:14:06,422 --> 00:14:09,690
sentences in decreasing order. Okay.

218
00:14:09,760 --> 00:14:13,790
And that ran for just a few seconds. Right. So this is actually public.

219
00:14:13,860 --> 00:14:17,790
You can try it for yourself and have fun with it.

220
00:14:17,860 --> 00:14:20,990
Let me show you what it entails. So,

221
00:14:21,060 --> 00:14:24,618
a space. It's a git repo. These I

222
00:14:24,644 --> 00:14:28,034
store code, and that code is automatically run

223
00:14:28,072 --> 00:14:31,380
into a docker container. So if we look at the app here,

224
00:14:31,830 --> 00:14:34,878
we can see it's about 100 lines of code,

225
00:14:34,984 --> 00:14:38,514
right? And half of that is really for the user

226
00:14:38,562 --> 00:14:42,306
interface. So what I'm doing here is I'm

227
00:14:42,338 --> 00:14:46,114
loading my models. I'm loading my document

228
00:14:46,162 --> 00:14:49,610
corpus, which I processed

229
00:14:50,110 --> 00:14:53,814
for semantic search using that sentence transformers

230
00:14:53,862 --> 00:14:57,850
model. And then basically, I just grab the wave

231
00:14:58,590 --> 00:15:02,554
speech and do speech to text and translation

232
00:15:02,602 --> 00:15:06,702
on it. And then I run my semantic search

233
00:15:06,756 --> 00:15:10,640
on things. Right? And that's all there is to it, as you can see.

234
00:15:11,250 --> 00:15:14,466
Process the speech and find sentences based on

235
00:15:14,488 --> 00:15:18,354
the text. Nothing hidden and no

236
00:15:18,392 --> 00:15:22,078
training whatsoever. So that's

237
00:15:22,094 --> 00:15:25,362
a pretty cool app. Imagine what you would have to do to build

238
00:15:25,416 --> 00:15:29,046
everything yourself. It would definitely take a little more than

239
00:15:29,068 --> 00:15:32,326
100 lines of code. Okay. All right, let's keep

240
00:15:32,348 --> 00:15:35,970
exploring transformers. So, the next planet that's

241
00:15:36,050 --> 00:15:38,566
aligning is machine learning hardware.

242
00:15:38,758 --> 00:15:42,714
So, so far, we've mostly relied on gpus for

243
00:15:42,752 --> 00:15:46,586
training, and they're still very nice. But I

244
00:15:46,608 --> 00:15:50,590
guess it's good to have more options. And we see companies like

245
00:15:50,660 --> 00:15:53,802
Habana, graphcore, intel,

246
00:15:53,866 --> 00:15:58,334
Qualcomm, AWS, and a few more building

247
00:15:58,532 --> 00:16:02,302
specialized chips for training or

248
00:16:02,356 --> 00:16:06,082
inference. And in fact, accelerating both makes

249
00:16:06,136 --> 00:16:09,410
sense, because if you accelerate training, you can obviously

250
00:16:09,480 --> 00:16:12,754
iterate quicker, right? During the same day, you can

251
00:16:12,792 --> 00:16:16,886
run your series of training jobs. Instead of

252
00:16:16,908 --> 00:16:20,166
having to wait for 12 hours or 24 hours, you can

253
00:16:20,188 --> 00:16:23,602
make decisions quicker and converge

254
00:16:23,666 --> 00:16:26,914
quicker to a great model that creates

255
00:16:26,962 --> 00:16:30,490
business value. Accelerating inference, obviously,

256
00:16:30,560 --> 00:16:34,662
is critical for low latency applications like conversational apps

257
00:16:34,726 --> 00:16:38,314
or search. But generally, everybody wants to go

258
00:16:38,352 --> 00:16:41,914
fast. And of course, if you can predict faster,

259
00:16:42,042 --> 00:16:45,966
you increase throughput, you decrease latency, and you

260
00:16:45,988 --> 00:16:49,802
can just predict more with the same amount of infrastructure.

261
00:16:49,866 --> 00:16:53,474
So your cost performance ratio will be

262
00:16:53,592 --> 00:16:56,674
quite nicer as well. So we

263
00:16:56,712 --> 00:16:59,220
at hugging face are partnering with those companies,

264
00:17:00,150 --> 00:17:03,826
and we actually have a dedicated libraries which you

265
00:17:03,848 --> 00:17:07,814
can find on GitHub called Optimum, which makes it really easy to

266
00:17:07,852 --> 00:17:11,062
work with those chips. You can start

267
00:17:11,116 --> 00:17:14,086
from your vanilla hugging face code.

268
00:17:14,268 --> 00:17:18,122
Generally it's going to use the trainer API, which is the high level

269
00:17:18,176 --> 00:17:20,778
API to fine tune models in.

270
00:17:20,864 --> 00:17:24,682
Again, very little code and you can just

271
00:17:24,736 --> 00:17:28,346
replace a few objects with the hardware specific

272
00:17:28,448 --> 00:17:32,174
projects and accelerate training or

273
00:17:32,212 --> 00:17:36,154
accelerate inference. So that's pretty cool because no one wants to rewrite

274
00:17:36,202 --> 00:17:39,934
everything. Go and take a look at the optimum repo. You'll find

275
00:17:39,972 --> 00:17:44,210
some code samples and we also have getting

276
00:17:44,280 --> 00:17:48,014
started post for all those chips on our blog.

277
00:17:48,142 --> 00:17:48,820
Okay.

278
00:17:51,750 --> 00:17:55,118
And these last planet is basically

279
00:17:55,224 --> 00:17:59,080
putting everything together with developer tools, right?

280
00:17:59,530 --> 00:18:03,430
Don't get me wrong, we still need experts and

281
00:18:03,500 --> 00:18:06,758
for these really hard problems, but for a lot of

282
00:18:06,924 --> 00:18:11,702
problems for a lot of projects, we think developers

283
00:18:11,766 --> 00:18:15,226
can build it all by themselves, right? So we're trying to come up

284
00:18:15,248 --> 00:18:19,014
with tools and solutions that are developer friendly and don't

285
00:18:19,062 --> 00:18:22,170
require a lot of machine learning expertise,

286
00:18:22,250 --> 00:18:26,174
if any. So again, as mentioned, startup from

287
00:18:26,212 --> 00:18:28,880
hugging face hub, hugging Face Co.

288
00:18:29,330 --> 00:18:32,846
You can go and look for data sets if you

289
00:18:32,868 --> 00:18:36,878
need to start from scratch because you don't

290
00:18:36,894 --> 00:18:39,986
have data for your problem, or maybe you want to augment the

291
00:18:40,008 --> 00:18:43,698
data that you have with third party data. So we

292
00:18:43,704 --> 00:18:47,666
have over 4000 data sets out there. So slightly

293
00:18:47,698 --> 00:18:51,414
you'll find something that you can use and

294
00:18:51,452 --> 00:18:55,000
then has mentioned before. You can go and look for

295
00:18:55,450 --> 00:18:58,786
the models that make sense for your task

296
00:18:58,818 --> 00:19:02,170
type and your business problems. We have over 40,000. The number changes

297
00:19:02,240 --> 00:19:05,514
every day. By the time you're watching this, it's going to be more than

298
00:19:05,552 --> 00:19:08,842
40,000. And from then

299
00:19:08,896 --> 00:19:12,234
on you can obviously test these models as

300
00:19:12,272 --> 00:19:15,838
is, fine tune the models either on a

301
00:19:15,844 --> 00:19:19,214
hugging face data set, on your own data, maybe both.

302
00:19:19,412 --> 00:19:22,254
And you can do this in a number of ways. Of course you can run

303
00:19:22,292 --> 00:19:27,150
this on your own servers in your Jupyter notebooks.

304
00:19:27,970 --> 00:19:31,422
If you have on prem infrastructure you can

305
00:19:31,476 --> 00:19:35,602
run it in auto train, which is our ML

306
00:19:35,666 --> 00:19:39,862
service that lets you very easily train on

307
00:19:39,916 --> 00:19:43,000
tabular data and NLp data.

308
00:19:43,530 --> 00:19:47,254
And this is totally no code, right? You can just click in the UI or

309
00:19:47,292 --> 00:19:50,486
use these simple Cli zero line of

310
00:19:50,508 --> 00:19:53,894
code needed. And as mentioned before,

311
00:19:54,012 --> 00:19:57,506
you can use transformers, the trainer API,

312
00:19:57,538 --> 00:20:01,070
you can use optimum to accelerate training, et cetera.

313
00:20:01,890 --> 00:20:04,958
Once you have a model that you like, you can, as mentioned,

314
00:20:05,044 --> 00:20:09,086
very easily showcases in spaces, you just

315
00:20:09,108 --> 00:20:12,618
saw an example of that. And these you can deploy it again,

316
00:20:12,724 --> 00:20:16,130
you can deploying it anywhere you like on your infrastructure.

317
00:20:17,190 --> 00:20:21,326
You can deploy it on the inference API, which is our very own managed

318
00:20:21,438 --> 00:20:24,210
API with hardware acceleration.

319
00:20:25,030 --> 00:20:28,722
And you can still use optimum if you'd like to optimize

320
00:20:28,786 --> 00:20:32,102
for your own underlying platform. Okay,

321
00:20:32,156 --> 00:20:35,638
and you have a model in prod. The last thing I want

322
00:20:35,644 --> 00:20:39,354
to mention is we have a deep engineering partnership with

323
00:20:39,392 --> 00:20:42,570
AWS. We collaborate at the product

324
00:20:42,640 --> 00:20:46,774
level, at the engineering level on Amazon Sagemaker,

325
00:20:46,902 --> 00:20:50,670
which is, if you're not familiar with it, it's these

326
00:20:50,740 --> 00:20:53,806
machine learning service, these managed machine learning service at

327
00:20:53,828 --> 00:20:57,374
AWS, and we makes it pretty

328
00:20:57,412 --> 00:21:01,262
easy to run to train. And deploying your

329
00:21:01,316 --> 00:21:05,678
hugging face code on sage makes using managed infrastructure.

330
00:21:05,774 --> 00:21:10,050
Okay? So either way, whether you want to go on prem

331
00:21:10,470 --> 00:21:14,386
or on EC two, or on

332
00:21:14,488 --> 00:21:18,022
other virtual machine services, or on sage makes, or,

333
00:21:18,156 --> 00:21:22,354
we think we have a solution and we think we can help you fly

334
00:21:22,402 --> 00:21:25,960
through that development cycle much faster than before.

335
00:21:26,410 --> 00:21:29,686
Okay, so let me quickly show you how to do this on

336
00:21:29,708 --> 00:21:33,254
Sagemaker. In the interest of time, I won't go through all the details,

337
00:21:33,302 --> 00:21:36,854
I'll just show you the highlights, but you can find the URL

338
00:21:36,902 --> 00:21:40,542
to this repo in my slides and replay everything.

339
00:21:40,676 --> 00:21:44,938
Okay, so what I'm doing here is I'm

340
00:21:45,034 --> 00:21:48,782
fine using a distillbert model.

341
00:21:48,916 --> 00:21:52,574
Distillbert is a condensed, smaller version of

342
00:21:52,612 --> 00:21:56,754
Bert. I'm fine tuning this model on

343
00:21:56,872 --> 00:22:00,466
a product review data set that I found on the hub. And you can see

344
00:22:00,488 --> 00:22:03,250
the URL to this data set here.

345
00:22:03,320 --> 00:22:05,810
Okay, so installing some dependencies,

346
00:22:07,210 --> 00:22:11,640
downloading these data set, and in fact, this data set has

347
00:22:12,330 --> 00:22:16,470
english reviews and a thai language translation

348
00:22:17,370 --> 00:22:20,620
with a flag saying is the thai translation correct?

349
00:22:21,150 --> 00:22:25,190
So I'll just ignore the thai part, I'll just keep the english

350
00:22:25,270 --> 00:22:28,218
part and the stars rating. Okay,

351
00:22:28,304 --> 00:22:32,174
so here I'm just simplifying the problem by

352
00:22:32,212 --> 00:22:35,374
mapping sentiment to positive or

353
00:22:35,412 --> 00:22:38,634
negative. So anything that's four and five stars is a positive

354
00:22:38,682 --> 00:22:42,442
review. Anything lower than four is a negative review.

355
00:22:42,516 --> 00:22:46,260
So just challenging the label here

356
00:22:46,790 --> 00:22:50,958
and using some of the APIs in the data sets library

357
00:22:51,134 --> 00:22:54,546
to get this done really quickly, right, so you

358
00:22:54,568 --> 00:22:56,790
can see after a few steps,

359
00:22:57,930 --> 00:23:01,702
this is what my data set looks like. The text and

360
00:23:01,756 --> 00:23:05,110
a label that says zero, one,

361
00:23:05,260 --> 00:23:09,194
and text and labels are exactly the feature makes that

362
00:23:09,232 --> 00:23:13,180
D Silbert expects, which is why I renamed them.

363
00:23:14,990 --> 00:23:17,180
Then I'm tokenizing that text,

364
00:23:18,030 --> 00:23:21,710
turning words into integer tokens,

365
00:23:23,570 --> 00:23:27,434
and finally uploading the training set and the validation

366
00:23:27,482 --> 00:23:31,646
set to s three. Okay, so by now

367
00:23:31,828 --> 00:23:35,220
I've got a data set ready to go in s three,

368
00:23:35,750 --> 00:23:39,442
and I can actually run my hugging face code. Okay,

369
00:23:39,576 --> 00:23:42,580
so I've got a training script. You can see it here.

370
00:23:43,350 --> 00:23:46,566
It's vanilla transformers code.

371
00:23:46,748 --> 00:23:50,390
I could actually run this script on my local machine,

372
00:23:50,970 --> 00:23:55,074
passing the appropriate hyperparameters or commandlet

373
00:23:55,122 --> 00:23:58,966
arguments, et cetera. This is a sagemaker feature called script mode, which is

374
00:23:58,988 --> 00:24:02,582
really handy because you can write the code locally on your machine,

375
00:24:02,726 --> 00:24:06,294
test it, and then you can move it as is to sage

376
00:24:06,342 --> 00:24:09,706
maker. Okay? So if you're not familiar with this, just look it

377
00:24:09,728 --> 00:24:12,640
up. Script mode in sage makes, okay,

378
00:24:13,490 --> 00:24:17,182
and then I'm loading the data sets inside

379
00:24:17,236 --> 00:24:21,486
the script from the training and validation locations in

380
00:24:21,508 --> 00:24:25,570
s three. And then

381
00:24:25,640 --> 00:24:29,374
using the trainer API, I'm setting up the training arguments.

382
00:24:29,422 --> 00:24:32,500
So where's the data, how many epochs to train for,

383
00:24:32,950 --> 00:24:35,970
where to log learning rate, et cetera.

384
00:24:36,130 --> 00:24:39,558
And then the training object is where I put everything together,

385
00:24:39,724 --> 00:24:43,606
the model, the arguments, and the location of the

386
00:24:43,628 --> 00:24:47,494
data sets. And then I call train to

387
00:24:47,532 --> 00:24:51,050
fine tune the model. I call evaluate to compute

388
00:24:51,550 --> 00:24:54,746
the validation metrics, and then I save the

389
00:24:54,768 --> 00:24:58,566
model and I'm done. Okay, so that code runs inside a hugging

390
00:24:58,598 --> 00:25:02,042
face container on sagemaker manage infrastructure.

391
00:25:02,186 --> 00:25:05,454
Okay, so I just set those

392
00:25:05,492 --> 00:25:09,246
hyperparameters one epoch, batch size, name of the model,

393
00:25:09,428 --> 00:25:13,198
and then I use this really central object in the sagemaker

394
00:25:13,214 --> 00:25:16,846
SDK, which is called the estimator. And here I'm using obviously the hugging

395
00:25:16,878 --> 00:25:20,622
face estimator, passing my script, passing versions

396
00:25:20,686 --> 00:25:24,740
of transformers and Pytorch and

397
00:25:26,470 --> 00:25:30,066
the infrastructure that I want here. So I'm running on a p, these two XL

398
00:25:30,098 --> 00:25:32,390
instance, which is a single GPU instance,

399
00:25:32,810 --> 00:25:36,262
and that's all I have to do, right? Then I called fit

400
00:25:36,396 --> 00:25:40,374
on this estimator, processing the location of the training and validation

401
00:25:40,422 --> 00:25:43,686
set. The training starts automatically, the instance starts,

402
00:25:43,798 --> 00:25:47,014
code is downloaded, data is downloads, and then it trains,

403
00:25:47,062 --> 00:25:50,300
okay? And after a little while, training is complete.

404
00:25:50,830 --> 00:25:54,750
And then in one line of code I can just deploy my model.

405
00:25:54,900 --> 00:25:58,650
And here I'm deploying on an m five excel, so cpu instance,

406
00:25:58,730 --> 00:26:02,174
okay, so after a few minutes, the endpoint is up, I can test,

407
00:26:02,212 --> 00:26:05,554
it has, you can see here, and when I'm done, I can

408
00:26:05,592 --> 00:26:08,260
delete, right? And then it's gone.

409
00:26:08,790 --> 00:26:13,490
And if I want to redeploy the model, assuming that I pushed

410
00:26:13,830 --> 00:26:17,206
the model to the hugging face hub, I can do

411
00:26:17,228 --> 00:26:20,662
this very easily, right? So I can just refer

412
00:26:20,796 --> 00:26:23,030
to the model on the hub,

413
00:26:24,330 --> 00:26:28,454
create this hugging face model object with the sagemaker SDK,

414
00:26:28,582 --> 00:26:31,846
and call deploy again, right? And then my endpoint

415
00:26:31,878 --> 00:26:35,082
is up again and I can predict again, right?

416
00:26:35,216 --> 00:26:38,666
So you could even deploy straight from

417
00:26:38,688 --> 00:26:42,506
the hub any of the models that are there, right. For the

418
00:26:42,528 --> 00:26:45,920
supported task types, that works. So that's a

419
00:26:46,290 --> 00:26:49,758
super simple way to deploy models on AWS. If you don't want to

420
00:26:49,764 --> 00:26:53,022
manage any infrastructure, and if you want to fine tune the model,

421
00:26:53,076 --> 00:26:56,046
then you can run an example like this one. Just fine tune,

422
00:26:56,238 --> 00:27:00,286
deploy, predict, take the endpoint down, redeployed, et cetera,

423
00:27:00,318 --> 00:27:03,714
et cetera. Super simple. Okay, again, I went a little

424
00:27:03,752 --> 00:27:06,918
faster, but go and check out the repo, run the example.

425
00:27:07,084 --> 00:27:10,738
It's very straightforward. All right, well, I think it's

426
00:27:10,754 --> 00:27:14,358
time to wrap up. So the key takeaways here are

427
00:27:14,524 --> 00:27:17,930
that ML tends to be complicated because

428
00:27:18,000 --> 00:27:22,470
we love to make it complicated. Right. We love to build complex

429
00:27:22,550 --> 00:27:26,118
solutions when they're not really needed, and we're

430
00:27:26,134 --> 00:27:29,766
all guilty of this, myself included. So let's

431
00:27:29,798 --> 00:27:33,726
focus on the right things and keep machine learning simple. So first, find a

432
00:27:33,748 --> 00:27:37,738
pretrained model that fits the task and the business problem we're

433
00:27:37,754 --> 00:27:41,290
trying to solve. Identify a business KPI

434
00:27:41,370 --> 00:27:45,122
that will show success. Machine learning KPIs are nice.

435
00:27:45,176 --> 00:27:48,818
You need them, but metrics will only go so far.

436
00:27:48,904 --> 00:27:52,318
You need to have some kind of business KPI that tells

437
00:27:52,334 --> 00:27:55,874
you yes things.

438
00:27:55,912 --> 00:27:59,782
Predictive application works, and it's actually performing better than

439
00:27:59,916 --> 00:28:04,034
whatever we has before. That's really important, and your business stakeholders

440
00:28:04,082 --> 00:28:07,734
will want to see that anyway. You can measure the model on

441
00:28:07,772 --> 00:28:11,306
real life data, so go and grab whatever data you have. It shouldn't be

442
00:28:11,328 --> 00:28:14,698
too clean, it shouldn't be too neat. Sandbox data

443
00:28:14,784 --> 00:28:18,220
test sets. They always look nice, they always perform

444
00:28:18,670 --> 00:28:21,914
in a pleasant way, but that's not what you're going to get in real life.

445
00:28:21,952 --> 00:28:25,518
So run your real life data on the model, see what happens there.

446
00:28:25,684 --> 00:28:28,942
If accuracy or whatever metric you're interested in is good enough,

447
00:28:28,996 --> 00:28:32,186
then fine, you're done. Move on to deployment,

448
00:28:32,378 --> 00:28:35,586
and that's it. These end of the project if

449
00:28:35,608 --> 00:28:39,406
you need to fine tune, because maybe you have an NLP

450
00:28:39,598 --> 00:28:43,454
application and you have very domain specific vocabulary

451
00:28:43,502 --> 00:28:47,154
that doesn't work nice enough in the pretrained

452
00:28:47,202 --> 00:28:50,694
model, then go and fine tune. You've seen how to do

453
00:28:50,732 --> 00:28:53,270
it. It's not complicated.

454
00:28:54,090 --> 00:28:57,986
And once you have the accuracy that you like, then you can deploy

455
00:28:58,018 --> 00:29:01,174
the model. And for many workloads, you need to pay attention

456
00:29:01,222 --> 00:29:04,762
to prediction latency. So make sure you have some form

457
00:29:04,816 --> 00:29:08,666
of hardware acceleration. Either you use the inference API or

458
00:29:08,688 --> 00:29:12,606
you use ML hardware, or you have your

459
00:29:12,628 --> 00:29:16,590
own solution with the optimum, maybe, but you

460
00:29:16,740 --> 00:29:20,430
probably cannot ignore that optimization task.

461
00:29:20,770 --> 00:29:24,126
And once you have the latency that you're good with,

462
00:29:24,148 --> 00:29:27,234
these, you're done and you can move on to the next

463
00:29:27,272 --> 00:29:30,770
project. Tools,

464
00:29:31,190 --> 00:29:35,250
libraries, machine learning platforms and infrastructure,

465
00:29:36,490 --> 00:29:40,200
I think they're all there, right? So I don't think it's needed

466
00:29:40,730 --> 00:29:44,600
that you go and reinvent that stuff and spend months,

467
00:29:45,130 --> 00:29:49,122
sometimes more, rebuilding stuff that's just readily

468
00:29:49,186 --> 00:29:52,666
available. And again, we love to build stuff. We love

469
00:29:52,688 --> 00:29:56,218
to say that, oh, it's different here. And no, we can't use off the

470
00:29:56,224 --> 00:30:00,054
shelf stuff. But seriously, that usually doesn't hold.

471
00:30:00,192 --> 00:30:03,914
So focus on the business problem. Focus on creating

472
00:30:03,962 --> 00:30:07,310
value for customers and

473
00:30:07,380 --> 00:30:12,494
users and just go straight to

474
00:30:12,532 --> 00:30:15,646
the result, which is, hey, I'm going to use whatever's available now. I'm going to

475
00:30:15,668 --> 00:30:19,186
find models, fine tune them and deploy. And if you do that, you can be

476
00:30:19,208 --> 00:30:22,770
in production in a matter of, I'm not going to say days.

477
00:30:22,920 --> 00:30:27,198
That would be boasting, even though I know some folks who do that.

478
00:30:27,384 --> 00:30:31,110
But in a matter of weeks, you have a production ready solution out there,

479
00:30:31,180 --> 00:30:35,186
right? And it won't take again months or years to solve

480
00:30:35,218 --> 00:30:37,400
that problem, which is great.

481
00:30:38,810 --> 00:30:42,566
So if you want to get started, if you're completely new to transformers,

482
00:30:42,598 --> 00:30:45,994
I recommend you join our community at Huggingface Co. You can sign

483
00:30:46,032 --> 00:30:49,706
up in minutes. It's totally free. All you need is a username and can

484
00:30:49,728 --> 00:30:53,278
email. So super simple. If you want to learn,

485
00:30:53,364 --> 00:30:56,462
I recommend following the hugging face

486
00:30:56,516 --> 00:30:59,918
course, which again is completely free. You don't need to be

487
00:30:59,924 --> 00:31:03,502
a machine learning expert at all. It's really targeted at developers.

488
00:31:03,646 --> 00:31:07,074
You can ask questions in the forums. The team will be happy

489
00:31:07,112 --> 00:31:10,980
to help. And for companies out there who have

490
00:31:11,750 --> 00:31:15,726
strong business use cases and ongoing projects

491
00:31:15,758 --> 00:31:19,334
and need help with transformers, they should

492
00:31:19,372 --> 00:31:23,510
take a look at what we call the expert acceleration program, which basically

493
00:31:23,580 --> 00:31:27,094
is advanced consulting that we provide end to end on

494
00:31:27,132 --> 00:31:31,062
your projects. From modeling all the way to production concerns.

495
00:31:31,206 --> 00:31:35,660
And for companies who have very strong privacy security

496
00:31:36,270 --> 00:31:39,914
concerns, who cannot run on the public cloud or

497
00:31:39,952 --> 00:31:44,094
on multitenant platforms, we can also do

498
00:31:44,132 --> 00:31:47,306
private deployments. So we can deploy the hugging face hub

499
00:31:47,338 --> 00:31:51,262
with models and data sets and the tools that you've heard about today on your

500
00:31:51,316 --> 00:31:54,930
own infra. Okay? So talk to us and we can

501
00:31:55,080 --> 00:31:58,180
see how to do that. Nice and easy, right?

502
00:31:59,510 --> 00:32:03,266
Thank you very much. In every language out

503
00:32:03,288 --> 00:32:06,838
there. Now we know how to do translation. If you

504
00:32:06,844 --> 00:32:09,618
have questions, if I can help you with projects,

505
00:32:09,714 --> 00:32:13,318
if you need anything from hugging face, you can contact me

506
00:32:13,484 --> 00:32:16,760
this email address and you'll find more content

507
00:32:17,450 --> 00:32:20,966
on Twitter, medium, YouTube, et cetera. Okay,

508
00:32:21,068 --> 00:32:24,774
hope this was useful. Hope you has a good time too. And thanks

509
00:32:24,812 --> 00:32:28,118
again for listening to me today. And I hope to see you maybe on

510
00:32:28,124 --> 00:32:30,622
the road at some point. All right, have a great day.

