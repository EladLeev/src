1
00:01:44,750 --> 00:01:47,954
Hey everyone, thanks for joining. I'll be talking about

2
00:01:47,992 --> 00:01:52,046
the future of observabilitys following Opentelemetry's path.

3
00:01:52,158 --> 00:01:56,334
By end of this talk, you will learn about how opentelemetry

4
00:01:56,382 --> 00:01:59,854
can satisfy the need of observability. I'm Siddharthakhare

5
00:01:59,902 --> 00:02:03,566
Khari. I'm working as a technical account manager with Newrelic.

6
00:02:03,678 --> 00:02:07,078
Prior to joining Newrelic, I was working with Citrix as a software

7
00:02:07,134 --> 00:02:10,118
developer. I like working with mobile apps,

8
00:02:10,214 --> 00:02:13,386
especially enterprise mobile apps. And after joining new

9
00:02:13,408 --> 00:02:17,050
Relic, I'm more focused on mobile app observability.

10
00:02:17,630 --> 00:02:21,118
This is the agenda for today, where we will be talking about

11
00:02:21,204 --> 00:02:25,002
what and why observabilitys, what is opentelemetry

12
00:02:25,066 --> 00:02:28,974
and what are its core concepts? How industry is

13
00:02:29,012 --> 00:02:32,822
adopting opentelemetry and what is the future of opentelemetry.

14
00:02:32,986 --> 00:02:36,222
But before we start, let me clarify

15
00:02:36,286 --> 00:02:40,434
one question for you, which comes in everyone's mind when we talk

16
00:02:40,472 --> 00:02:43,406
about observability or monitoring.

17
00:02:43,598 --> 00:02:47,314
How many tools any company uses to collect the telemetry

18
00:02:47,362 --> 00:02:51,186
data? And the answer is somewhere around four to six tools.

19
00:02:51,378 --> 00:02:54,870
First, let's discuss about the difference between

20
00:02:54,940 --> 00:02:58,546
monitoring and observability. So traditional monitoring

21
00:02:58,578 --> 00:03:01,946
is all about the hiccups which you face in your system in day

22
00:03:01,968 --> 00:03:06,042
to day work. And mostly it's all about whether

23
00:03:06,096 --> 00:03:09,306
the service is red, or it's green, or it's up or

24
00:03:09,328 --> 00:03:12,714
down. And it can trigger some alerts

25
00:03:12,762 --> 00:03:15,978
around the response times, the application crashes,

26
00:03:16,074 --> 00:03:19,326
et cetera. However, observabilitys is a

27
00:03:19,348 --> 00:03:22,962
lot more than that, and it is based on three major

28
00:03:23,016 --> 00:03:26,210
pillars, which is metrics, logs and traces.

29
00:03:26,790 --> 00:03:30,530
So what is observabilitys? Observability is

30
00:03:30,600 --> 00:03:34,226
all about understanding the internal state of your system

31
00:03:34,328 --> 00:03:37,110
based upon the output which it generates.

32
00:03:37,530 --> 00:03:41,142
So this is something which everyone is familiar of where

33
00:03:41,196 --> 00:03:44,326
things works perfectly fine in your system.

34
00:03:44,428 --> 00:03:47,378
However, as you push it to production,

35
00:03:47,554 --> 00:03:50,666
it fails and that's where we consider it as

36
00:03:50,688 --> 00:03:53,990
an ops problem. In some scenarios,

37
00:03:54,070 --> 00:03:58,054
people even say that it's working fine in my container.

38
00:03:58,102 --> 00:04:01,182
Maybe you are not deploying the container correctly. Again,

39
00:04:01,236 --> 00:04:05,182
that is not the case. That's where observability comes

40
00:04:05,236 --> 00:04:08,590
to the rescue. And it can help different

41
00:04:08,660 --> 00:04:12,154
personas in your organizations. Let's take a look into

42
00:04:12,212 --> 00:04:16,014
it. So for developers, they can use observability to debug

43
00:04:16,062 --> 00:04:20,078
their code, to identify the performance bottlenecks, and to ensure

44
00:04:20,174 --> 00:04:24,050
that their features are working as expected in production.

45
00:04:24,570 --> 00:04:28,102
For DevOps, they can use observability to monitor their

46
00:04:28,156 --> 00:04:31,842
systems for health and performance, to identify

47
00:04:31,906 --> 00:04:35,062
and fix problems quickly, and to automate their

48
00:04:35,116 --> 00:04:39,206
deployments and performance operations for sres.

49
00:04:39,318 --> 00:04:43,034
They can use observability to manage the reliability of

50
00:04:43,072 --> 00:04:47,366
their systems. Product managers can use observability

51
00:04:47,478 --> 00:04:51,600
to understand how users are interacting with their products.

52
00:04:52,130 --> 00:04:56,234
They can use it to identify the areas of improvement

53
00:04:56,362 --> 00:05:00,640
and to make better decisions about future features and

54
00:05:01,090 --> 00:05:04,434
functionalities. Observability not

55
00:05:04,472 --> 00:05:07,922
only helps these individual personas, but it also

56
00:05:07,976 --> 00:05:11,506
helps you to run your business. Let's take a

57
00:05:11,528 --> 00:05:15,234
look about the background of opentelemetry and what

58
00:05:15,272 --> 00:05:18,930
it offers. Opentelemetry is an incubating

59
00:05:19,830 --> 00:05:23,238
project of CNCF. It is formed by

60
00:05:23,404 --> 00:05:27,042
merging opensenses and opentracing. So if you have

61
00:05:27,116 --> 00:05:30,918
used eager or zipkin, you have already experienced

62
00:05:31,014 --> 00:05:34,662
the flavor of opentracing. It has multiple

63
00:05:34,726 --> 00:05:38,118
set of APIs, libraries and integrations

64
00:05:38,214 --> 00:05:41,882
available which make it vendor agnostic

65
00:05:41,946 --> 00:05:46,090
so you don't have to dependent on any specific backend

66
00:05:46,250 --> 00:05:51,306
and more about all this observabilitys opentelemetry

67
00:05:51,338 --> 00:05:55,646
is setting a standard of how you should be collecting

68
00:05:55,678 --> 00:05:59,378
the telemetry data. Let's see about

69
00:05:59,464 --> 00:06:03,154
some of the features which are behind the rise of

70
00:06:03,272 --> 00:06:07,874
opentelemetry. First is ubiquity. So opentelemetry

71
00:06:07,922 --> 00:06:11,910
is designed to be highly accessible and commonly used

72
00:06:11,980 --> 00:06:16,550
across a wide range of programming languages, platforms and ecosystem.

73
00:06:16,890 --> 00:06:20,966
Second is its vendor neutral nature, where opentelemetry

74
00:06:20,998 --> 00:06:24,394
is intentionally vendor neutral and does

75
00:06:24,432 --> 00:06:27,770
not favor or promote any specific vendor.

76
00:06:28,270 --> 00:06:31,454
It is interoperable in nature, which means it

77
00:06:31,492 --> 00:06:34,782
has different libraries and sdks for

78
00:06:34,836 --> 00:06:39,470
each and every language, but with same specifications.

79
00:06:39,810 --> 00:06:43,454
And last but not the least, is configurable.

80
00:06:43,582 --> 00:06:47,582
So instrumentation can be done via

81
00:06:47,646 --> 00:06:51,470
automatic method or via manual method. You can leverage

82
00:06:51,550 --> 00:06:54,770
the sampling strategies, you can leverage exporters,

83
00:06:55,350 --> 00:06:59,126
you can leverage the context propagation and many more.

84
00:06:59,308 --> 00:07:03,254
And based upon the study of Gartner, it says that

85
00:07:03,292 --> 00:07:07,926
by 2025, 70% of the cloud native application monitoring

86
00:07:07,958 --> 00:07:11,530
will use open source instrumentation.

87
00:07:11,950 --> 00:07:16,598
Here you see the graph from CNCF

88
00:07:16,694 --> 00:07:20,638
project where Opentelemetry is the second most

89
00:07:20,724 --> 00:07:24,798
active project in CNCF space. First, one is obviously

90
00:07:24,884 --> 00:07:28,894
Kubernetes. Let's talk about the

91
00:07:28,932 --> 00:07:33,070
core concepts of opentelemetry. So opentelemetry

92
00:07:33,670 --> 00:07:37,138
is a lot and it is built

93
00:07:37,224 --> 00:07:41,598
on some specific building blocks. So with Opentelemetry

94
00:07:41,694 --> 00:07:45,442
the data is annotated. It depends on implementer

95
00:07:45,506 --> 00:07:49,638
to annotate the data in a meaningful way. It has certain

96
00:07:49,724 --> 00:07:52,402
specifications that software performs,

97
00:07:52,546 --> 00:07:56,642
for example HTTP calls, database operations,

98
00:07:56,786 --> 00:08:00,346
et cetera. So for all these operations there is a

99
00:08:00,368 --> 00:08:04,246
semantic convention. It has been providing

100
00:08:04,278 --> 00:08:07,786
the APIs and sdks with which you will be

101
00:08:07,808 --> 00:08:11,034
able to collect the data types

102
00:08:11,082 --> 00:08:14,042
for tracing metrics, logs,

103
00:08:14,106 --> 00:08:18,906
et cetera. It also offers automatic instrumentation

104
00:08:19,098 --> 00:08:23,194
and the last one is OTLP which is open telemetry

105
00:08:23,242 --> 00:08:26,894
line protocol which is used for sending the data to

106
00:08:26,932 --> 00:08:30,626
the backend observability platform of your choice where

107
00:08:30,648 --> 00:08:34,654
you can visualize the data, you can set alerts and

108
00:08:34,792 --> 00:08:38,470
many more things. Here what you see is

109
00:08:38,620 --> 00:08:41,622
the opentelemetry instrumentation way,

110
00:08:41,756 --> 00:08:45,126
right? So on the left what you

111
00:08:45,148 --> 00:08:48,554
see is automatic instrumentation where the number

112
00:08:48,592 --> 00:08:52,010
of lines of code is less. On the right you see

113
00:08:52,080 --> 00:08:55,674
the manual instrumentation where the number of lines are

114
00:08:55,712 --> 00:08:59,814
more. So it is always recommended that you

115
00:08:59,952 --> 00:09:03,598
should go with automatic instrumentation if it's a start

116
00:09:03,684 --> 00:09:07,070
of your journey with observability.

117
00:09:07,730 --> 00:09:12,166
Now once the data is instrumented, it is collected,

118
00:09:12,298 --> 00:09:15,506
and when the data is being collected, this is how it

119
00:09:15,528 --> 00:09:19,410
will look like. You will be able to get the deeper

120
00:09:20,230 --> 00:09:23,460
understanding about the application stack because

121
00:09:24,070 --> 00:09:27,494
when you instrument it, you will be building some blocks around

122
00:09:27,532 --> 00:09:31,538
it. Once you have that, you will be able to pinpoint

123
00:09:31,714 --> 00:09:35,222
the errors and even you will be

124
00:09:35,276 --> 00:09:38,250
able to understand where the problem relies.

125
00:09:38,750 --> 00:09:43,142
Now we have discussed about how the instrumentation

126
00:09:43,206 --> 00:09:46,394
works, what type of instrumentation we should go,

127
00:09:46,512 --> 00:09:50,620
but here comes the most important part

128
00:09:51,150 --> 00:09:54,746
which is open telemetry collector. We can consider the

129
00:09:54,768 --> 00:09:58,110
open telemetry collector as a superpower.

130
00:09:58,770 --> 00:10:02,754
So the opentelemetry collector is perhaps one of the

131
00:10:02,792 --> 00:10:06,162
most exciting tools in opentelemetry which

132
00:10:06,216 --> 00:10:10,094
it has to offer. It's meant to be running as a standalone

133
00:10:10,142 --> 00:10:14,650
process, providing a central place to receive,

134
00:10:14,750 --> 00:10:17,938
process and export the data which we are collecting.

135
00:10:18,114 --> 00:10:21,654
It's completely vendor agnostic and support many of

136
00:10:21,692 --> 00:10:25,026
the most common open formats for telemetry

137
00:10:25,058 --> 00:10:28,730
data. So here what you see on

138
00:10:28,880 --> 00:10:32,934
this slide is that the collector centers

139
00:10:32,982 --> 00:10:36,570
around three primary types of components. The first one

140
00:10:36,640 --> 00:10:39,798
is receiver for receiving the opentelemetry data.

141
00:10:39,984 --> 00:10:44,222
Second one is processor for processing the opentelemetry data,

142
00:10:44,356 --> 00:10:48,186
and finally exporters for exporting the telemetry

143
00:10:48,218 --> 00:10:51,790
data to the back end like new relic or

144
00:10:51,860 --> 00:10:54,990
any other observability backend.

145
00:10:55,410 --> 00:10:58,754
Just like the Opentelemetry sdks for

146
00:10:58,792 --> 00:11:02,862
each language, the collector is also designed to be extensible.

147
00:11:03,006 --> 00:11:06,914
So if you visit the opentelemetry's collector GitHub

148
00:11:06,962 --> 00:11:10,850
repository, you will find that there are already many components

149
00:11:10,930 --> 00:11:14,290
developed that you can use in your environment.

150
00:11:14,450 --> 00:11:18,262
So collector is not just the data exporter

151
00:11:18,326 --> 00:11:22,154
or the data middleman. The collector has all

152
00:11:22,192 --> 00:11:25,914
of these multiple components that can help you to

153
00:11:25,952 --> 00:11:29,290
do the filtering, the batching part,

154
00:11:29,440 --> 00:11:33,030
and even adding some of the attributes.

155
00:11:33,110 --> 00:11:36,842
And then these processes are the key

156
00:11:36,896 --> 00:11:40,220
parts of the whole collector process.

157
00:11:40,910 --> 00:11:44,846
In this process. If you are using the Prometheus

158
00:11:44,878 --> 00:11:48,082
and Grafana, you might be wondering what will happen to them.

159
00:11:48,216 --> 00:11:52,142
So Prometheus and Grafanas is also supported,

160
00:11:52,206 --> 00:11:55,334
but it's in an experimental phase so you can

161
00:11:55,372 --> 00:11:58,982
check their official documents. And before

162
00:11:59,036 --> 00:12:02,822
you start here, what you see is that

163
00:12:02,876 --> 00:12:07,240
opentelemetry is not just restricted to your application

164
00:12:07,950 --> 00:12:11,706
data. The collector can help you to scrape the

165
00:12:11,728 --> 00:12:14,966
metrics from your infrastructure. In this sample

166
00:12:15,078 --> 00:12:18,326
we are capturing the cpu, memory and the networking

167
00:12:18,358 --> 00:12:21,790
details from one of my infrastructure and

168
00:12:21,860 --> 00:12:25,290
you can just define what metrics you want to capture

169
00:12:25,450 --> 00:12:29,390
and this is how it will look like once the data is collected.

170
00:12:29,810 --> 00:12:34,194
Let's ideas deeper into sampling process

171
00:12:34,392 --> 00:12:37,540
where different sampling process are available.

172
00:12:38,390 --> 00:12:42,194
First one is head based, then we have tail based and

173
00:12:42,232 --> 00:12:46,166
we have probabilistic sampling. Head and tail based

174
00:12:46,268 --> 00:12:48,770
sampling are the commonly used samplings.

175
00:12:48,930 --> 00:12:52,354
Headbase sampling upfront samples, all the requests

176
00:12:52,402 --> 00:12:56,040
and the spans that are generated by the individual services.

177
00:12:56,490 --> 00:12:59,958
It takes the statistics of all the requests

178
00:13:00,054 --> 00:13:03,850
generated from services and keeps all the spans

179
00:13:04,510 --> 00:13:08,310
and it takes the decision at a very initial

180
00:13:08,390 --> 00:13:11,786
stage. The main issue with headbase

181
00:13:11,818 --> 00:13:15,038
sampling is that when the sampling decision is being made,

182
00:13:15,124 --> 00:13:18,814
the root span has a limited visibility and does not

183
00:13:18,852 --> 00:13:22,878
know what will happen in the future. With tailbase sampling,

184
00:13:22,974 --> 00:13:27,266
the sampling process happens at

185
00:13:27,288 --> 00:13:30,974
the end where it waits after receiving

186
00:13:31,022 --> 00:13:34,754
the first spans until the period of time to

187
00:13:34,792 --> 00:13:38,100
collect the spans for other services which

188
00:13:38,470 --> 00:13:42,722
has the same trace id. After all the

189
00:13:42,856 --> 00:13:46,166
elected spans are grouped together based on

190
00:13:46,188 --> 00:13:50,074
their trace id, iterates over to check for

191
00:13:50,112 --> 00:13:54,234
the error status and the duration of the spans. Based on

192
00:13:54,272 --> 00:13:58,010
those analysis, high value traces are selectively sent

193
00:13:58,080 --> 00:14:01,742
to the next process, such as your

194
00:14:01,876 --> 00:14:04,462
observability back end.

195
00:14:04,596 --> 00:14:08,426
So I'll show you the sample of how a tailbase

196
00:14:08,458 --> 00:14:11,594
sampling will look like. So this is a sample configuration

197
00:14:11,642 --> 00:14:15,486
where I am leveraging the tailbase

198
00:14:15,518 --> 00:14:19,282
sampling and I have multiple policies. One of such

199
00:14:19,336 --> 00:14:23,586
policy is only collect the trace which has a latency of

200
00:14:23,768 --> 00:14:27,906
5000 milliseconds. If you see the output

201
00:14:27,938 --> 00:14:31,906
which it generates is very helpful

202
00:14:32,018 --> 00:14:35,970
because before leveraging the tailbase sampling,

203
00:14:36,050 --> 00:14:39,802
the throughput was very high and the data

204
00:14:39,856 --> 00:14:43,034
ingestion was very high. But as

205
00:14:43,072 --> 00:14:47,306
soon as I implemented the test policy two which you see

206
00:14:47,488 --> 00:14:49,770
around the latency,

207
00:14:50,370 --> 00:14:54,078
it dropped. So the answer is because the policy

208
00:14:54,164 --> 00:14:58,062
is only collecting the spans that took over 5

209
00:14:58,116 --> 00:15:01,774
seconds to complete and because of

210
00:15:01,812 --> 00:15:05,250
which I'm able to save some cost of ingesting the data

211
00:15:05,320 --> 00:15:09,326
as well. So this is where how you can leverage

212
00:15:09,518 --> 00:15:13,746
the tailbase sampling process in your collector. Yamls this

213
00:15:13,848 --> 00:15:17,282
is what we call it as a probabilistic sampling

214
00:15:17,346 --> 00:15:22,022
where you can define the probability of how

215
00:15:22,156 --> 00:15:25,734
much percentage of trace you need and

216
00:15:25,772 --> 00:15:29,114
the configuration is as what it is

217
00:15:29,152 --> 00:15:33,020
showing here. Now we have understood a way of

218
00:15:33,390 --> 00:15:37,462
instrumenting the app. We have understood the way of sampling

219
00:15:37,606 --> 00:15:41,278
the traces. Now once the data is sampled, how you

220
00:15:41,284 --> 00:15:44,702
can export that data, right? So that's where

221
00:15:44,756 --> 00:15:48,414
you see these three examples where first,

222
00:15:48,612 --> 00:15:51,760
I have used a zipkin as an

223
00:15:52,070 --> 00:15:56,014
exporter where I am exporting the telemetry

224
00:15:56,062 --> 00:15:59,186
data with the help of Zipkin. Second,

225
00:15:59,368 --> 00:16:02,994
I have leveraged Prometheus to extract that data

226
00:16:03,112 --> 00:16:06,278
and in the third example I have used

227
00:16:06,444 --> 00:16:09,954
Newrelic to extract the data where I am leveraging

228
00:16:10,002 --> 00:16:14,134
new relics, OTLP URL to extract the data and

229
00:16:14,172 --> 00:16:18,078
these are the attributes which it requires.

230
00:16:18,274 --> 00:16:21,674
Let's talk about how the industry is

231
00:16:21,712 --> 00:16:25,002
adopting opentelemetry. So here you

232
00:16:25,056 --> 00:16:28,922
see the top industry adopters. These are

233
00:16:28,976 --> 00:16:33,826
some of the big names which are leveraging opentelemetry

234
00:16:33,958 --> 00:16:37,054
at a production scale. Let me share one

235
00:16:37,092 --> 00:16:41,070
such success story where one of the industry adopter pairs open

236
00:16:41,140 --> 00:16:44,894
standard with observabilitys and that industry's adopter

237
00:16:44,942 --> 00:16:47,986
is Skyscanner. The results are really great.

238
00:16:48,088 --> 00:16:51,438
They were able to retire twelve internal and external systems.

239
00:16:51,534 --> 00:16:55,142
They were able to reduce approximately 15 minutes on

240
00:16:55,196 --> 00:16:58,918
each merge request for mobile build pipeline and

241
00:16:59,004 --> 00:17:02,502
they were able to create slos from any

242
00:17:02,556 --> 00:17:06,038
metric event or telemetry data, regardless of

243
00:17:06,124 --> 00:17:09,866
whether it comes from the back end or the front end.

244
00:17:10,048 --> 00:17:13,350
Let's talk about the future of opentelemetry.

245
00:17:13,510 --> 00:17:16,780
There are lots of contributions which are happening

246
00:17:17,150 --> 00:17:21,150
throughout in the opentelemetry space. You can

247
00:17:21,220 --> 00:17:24,798
look at this particular table where you will find the detail about

248
00:17:24,884 --> 00:17:29,002
what type of telemetry data is stable with respect

249
00:17:29,066 --> 00:17:32,750
to the language. All the major cloud

250
00:17:32,820 --> 00:17:37,266
providers are adopting and contributing the opentelemetry project.

251
00:17:37,448 --> 00:17:41,550
Amazon has built their Amazon distro for opentelemetry.

252
00:17:41,710 --> 00:17:45,414
You can also call it as ADOT which can be used as

253
00:17:45,452 --> 00:17:49,586
a lambda layer. Microsoft has natively opentelemetry

254
00:17:49,618 --> 00:17:53,634
capabilities in. Net framework and supports opentelemetry

255
00:17:53,682 --> 00:17:57,390
tracing on Azure. Newrelic is one of the proud

256
00:17:57,490 --> 00:18:01,542
enabler and contributor for Opentelemetry and fully compatible

257
00:18:01,606 --> 00:18:05,414
with Opentelemetry line protocol or OTLP.

258
00:18:05,542 --> 00:18:09,558
Kubernetes and containers are natively supported and

259
00:18:09,664 --> 00:18:13,850
many companies are building native integrations to support and export

260
00:18:14,010 --> 00:18:16,522
telemetry in opentelemetry format.

261
00:18:16,666 --> 00:18:20,298
Even next, JS, which is a web framework,

262
00:18:20,394 --> 00:18:25,382
has included a custom SDK to export Opentelemetry

263
00:18:25,546 --> 00:18:30,114
out of the box. Let's recap what

264
00:18:30,152 --> 00:18:34,114
we have discussed so there is no doubt that Opentelemetry is

265
00:18:34,152 --> 00:18:37,522
growing at a rapid pace. We have to be sure

266
00:18:37,576 --> 00:18:40,666
about our maturity before adopting opentelemetry.

267
00:18:40,718 --> 00:18:43,560
That is what type of telemetry data we need.

268
00:18:44,090 --> 00:18:47,830
Only collecting the telemetry data is not useful.

269
00:18:48,270 --> 00:18:52,298
The instrumentation should be including the contextual data

270
00:18:52,384 --> 00:18:55,942
to make more sense. With Opentelemetry

271
00:18:56,006 --> 00:18:59,418
standard, it's easy to gather the telemetry data.

272
00:18:59,584 --> 00:19:02,954
If you invest in Opentelemetry, it will help

273
00:19:02,992 --> 00:19:06,586
you to run your business on data and not just on

274
00:19:06,608 --> 00:19:09,866
opinion. That is why we say load data.

275
00:19:09,968 --> 00:19:13,954
Eject opinion with this us. Thanks for

276
00:19:13,992 --> 00:19:17,842
attending my session. These are my credentials. If you want to talk

277
00:19:17,896 --> 00:19:21,106
about Opentelemetry observability or mobile app,

278
00:19:21,208 --> 00:19:24,498
I'm happy to connect and answer all your queries. Once again,

279
00:19:24,584 --> 00:19:24,960
thank you.

