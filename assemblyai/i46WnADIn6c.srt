1
00:00:34,530 --> 00:00:37,750
Hi and welcome to our presentation and demo about building

2
00:00:37,820 --> 00:00:41,394
a self service database as a service for your internal

3
00:00:41,442 --> 00:00:44,918
developer platform. My name is Dan McKean and I'm a product manager at

4
00:00:44,924 --> 00:00:48,994
Mongre DB, and I'm joined by George Hanzaris, who's an engineering director

5
00:00:49,042 --> 00:00:52,430
also at MongoDB. We're responsible for enabling our customers

6
00:00:52,500 --> 00:00:56,366
and users to run MongoDB in two ways, self hosted in

7
00:00:56,388 --> 00:01:00,730
Kubernetes, using our enterprise or community Kubernetes operators,

8
00:01:00,890 --> 00:01:04,878
or using our Atlas Kubernetes operator, which is designed

9
00:01:04,894 --> 00:01:08,370
to manage and configure our atlas developer data

10
00:01:08,440 --> 00:01:11,566
platform. In this we're going to cover a range of non

11
00:01:11,598 --> 00:01:15,586
MongoDB specific considerations, starting with Kubernetes as

12
00:01:15,608 --> 00:01:18,850
the platform of platforms, building and managing a dbas

13
00:01:18,930 --> 00:01:22,402
in your internal developer platform, also known as an IDP.

14
00:01:22,546 --> 00:01:26,226
Why? To build a DBaas and the risks and the criticality

15
00:01:26,258 --> 00:01:29,914
of enabling self service in a dbas. Then we're going to use our

16
00:01:29,952 --> 00:01:33,846
own Atlas developer data platform and our Kubernetes operator

17
00:01:33,958 --> 00:01:37,930
to demonstrate how this can work, covering what Atlas is and how

18
00:01:38,000 --> 00:01:41,406
our operator works and how to put it all together

19
00:01:41,508 --> 00:01:45,390
in theory and in a demo. We're going to start with Kubernetes as a platform

20
00:01:45,460 --> 00:01:49,706
of platforms. According to internal developerplatforms.org,

21
00:01:49,818 --> 00:01:53,638
95% of internal developer platforms idps

22
00:01:53,834 --> 00:01:57,314
are built on top of Kubernetes. Many of you already know of

23
00:01:57,352 --> 00:02:01,550
Kubernetes as an open source container orchestration system for automating,

24
00:02:01,630 --> 00:02:05,022
application development, scaling and management. In recent years,

25
00:02:05,096 --> 00:02:08,674
Kubernetes has become nearly synonymous with container

26
00:02:08,722 --> 00:02:12,802
orchestration and with so many services being built as microservices

27
00:02:12,866 --> 00:02:16,882
and designed to be automatically scaled containers and kubernetes

28
00:02:16,946 --> 00:02:21,014
are reigning supreme. So what does Kubernetes offer? It offers

29
00:02:21,142 --> 00:02:25,414
highly flexible networking, including options like directly exposing

30
00:02:25,462 --> 00:02:29,306
pods, load balancing connections and ingress services.

31
00:02:29,488 --> 00:02:32,654
Storage orchestration to provide either ephemeral or

32
00:02:32,692 --> 00:02:36,874
persistent storage, high availability and high levels of resiliency

33
00:02:37,002 --> 00:02:40,682
by making it easy to deploy many copies of a service across many physical

34
00:02:40,746 --> 00:02:44,026
or virtual machines. Self healing by monitoring the state

35
00:02:44,068 --> 00:02:48,606
of objects in Kubernetes and keeping those aligned with the declarative configuration

36
00:02:48,718 --> 00:02:52,302
and a low degree of vendor lock in. Thanks to the many standardized

37
00:02:52,366 --> 00:02:56,162
flavors of kubernetes available for either self hosting or

38
00:02:56,216 --> 00:03:00,034
as a cloud based platform, as a service and finally, and arguably

39
00:03:00,082 --> 00:03:02,950
most critically, when it comes to an internal developer platform,

40
00:03:03,100 --> 00:03:06,754
it provides a high degree of customization and extensibility,

41
00:03:06,882 --> 00:03:10,726
particularly in the form of Kubernetes operators and custom resources.

42
00:03:10,838 --> 00:03:14,102
An operator extends the native Kubernetes control plane

43
00:03:14,166 --> 00:03:18,186
with custom logic that helps manage a lot of the essential tasks that

44
00:03:18,208 --> 00:03:22,026
are bespoke to a specific product. Like MongoDB, it's usually paired

45
00:03:22,058 --> 00:03:25,310
with custom resources defined in Kubernetes using

46
00:03:25,380 --> 00:03:28,714
custom resource definitions. These custom resources

47
00:03:28,762 --> 00:03:32,126
allow for the creation of new types of kubernetes objects, which can be

48
00:03:32,148 --> 00:03:35,390
monitored by the operator and allows the operator to take action.

49
00:03:35,470 --> 00:03:38,974
The actions taken can vary massively, but some of the common ones include

50
00:03:39,022 --> 00:03:42,786
deploying an application, taking a backup, upgrading an

51
00:03:42,808 --> 00:03:46,606
application, or exposing a service to applications that

52
00:03:46,648 --> 00:03:50,326
do not support the Kubernetes. API. Operators can also be

53
00:03:50,348 --> 00:03:53,298
used to manage resources external to kubernetes.

54
00:03:53,474 --> 00:03:57,430
Most commonly, this is done by using the APIs of the external service

55
00:03:57,580 --> 00:04:01,674
in which the objects are actually being run. Custom resources within

56
00:04:01,712 --> 00:04:05,674
the Kubernetes cluster can be used to represent the desired configuration of

57
00:04:05,712 --> 00:04:09,450
those external resources, allowing the operator to monitor the custom

58
00:04:09,520 --> 00:04:13,066
resources and then use the external service APIs to make

59
00:04:13,088 --> 00:04:17,166
the required changes. The value here is that those custom resources can

60
00:04:17,188 --> 00:04:21,210
then be managed in the same way as the services in the local Kubernetes cluster,

61
00:04:21,290 --> 00:04:24,366
benefiting from using the same tooling, processes,

62
00:04:24,478 --> 00:04:28,050
permissions and automation. Now we're going to dig into

63
00:04:28,120 --> 00:04:31,682
databases as a service within an internal developer platform,

64
00:04:31,816 --> 00:04:35,690
but first a brief recap on what an IDP is and offers.

65
00:04:35,790 --> 00:04:39,154
Internal developer platforms are built to enable developer

66
00:04:39,202 --> 00:04:41,906
self service of platform infrastructure.

67
00:04:42,018 --> 00:04:45,426
They're typically built by an Ops team and used by developers.

68
00:04:45,538 --> 00:04:49,610
They provide a common process and method of engaging with the platform,

69
00:04:49,760 --> 00:04:53,674
often via templates. This automates recurring tasks such

70
00:04:53,712 --> 00:04:57,494
as spinning up environments and resources, and helps enforce

71
00:04:57,542 --> 00:05:01,574
standards such as security requirements. IDPs often abstract

72
00:05:01,622 --> 00:05:04,506
away the complexity of the underlying platform technologies,

73
00:05:04,618 --> 00:05:08,026
saving everyone from needing to be an expert. Development teams

74
00:05:08,058 --> 00:05:11,626
can gain autonomy by being empowered to spin up fully provisioned

75
00:05:11,658 --> 00:05:15,390
environments and manage them with a minimum of effort or complexity.

76
00:05:15,550 --> 00:05:19,282
Idbs can be built or bought, or some combination of

77
00:05:19,336 --> 00:05:23,170
both. A dbAs or database as a service is often

78
00:05:23,240 --> 00:05:26,882
one of the most critical components of an internal developer platform.

79
00:05:27,016 --> 00:05:30,530
Most applications need a database at some point, and databases

80
00:05:30,610 --> 00:05:34,102
can be some of the most complex services to deploy and manage.

81
00:05:34,236 --> 00:05:37,574
A company's choice of database can make a dramatic difference on

82
00:05:37,612 --> 00:05:40,982
not only the success of the application, but also on the speed,

83
00:05:41,046 --> 00:05:44,874
success and happiness or unhappiness of a development team.

84
00:05:44,992 --> 00:05:49,158
All this makes simplifying the consumption, use and management of databases

85
00:05:49,254 --> 00:05:52,938
incredibly valuable. This is especially true for day two operations

86
00:05:53,034 --> 00:05:56,174
such as upgrades, where developers can be spared a huge amount

87
00:05:56,212 --> 00:06:00,554
of ongoing work through the centralization and automation that a DBAs

88
00:06:00,602 --> 00:06:04,218
can offer, especially when a Kubernetes operator has been used to

89
00:06:04,244 --> 00:06:07,938
handle those sort of day two operations. But building a

90
00:06:07,944 --> 00:06:11,214
database as a service is not without risk or complexity.

91
00:06:11,342 --> 00:06:14,922
Databases can vary a lot, even from a single manufacturer,

92
00:06:15,006 --> 00:06:19,014
and one of the key questions to identify is how much customization and

93
00:06:19,052 --> 00:06:23,186
configuration to expose to development teams. Security sizing,

94
00:06:23,298 --> 00:06:27,586
performance, backup, sharding and resilience are all major considerations,

95
00:06:27,698 --> 00:06:31,466
and that's without taking into account any of the specifics of the underlying platform

96
00:06:31,568 --> 00:06:35,434
technologies that underpin the IDP itself. We see

97
00:06:35,472 --> 00:06:39,926
many companies turning to fairly strictly defined templates that predetermine

98
00:06:39,958 --> 00:06:43,638
many of those things and give minimal customization to the end users.

99
00:06:43,734 --> 00:06:47,354
An example of this could be t shirt sizes for the database deployments,

100
00:06:47,482 --> 00:06:51,002
with guidance about which sizes suit which use cases,

101
00:06:51,146 --> 00:06:55,034
troubleshooting is often a challenge. Security best practices encourage

102
00:06:55,082 --> 00:06:58,766
a minimum number of people to have a minimum level of rights

103
00:06:58,798 --> 00:07:01,858
and permissions. But how do you avoid a central team being a

104
00:07:01,864 --> 00:07:04,994
blocker to development teams? Many companies opt to have

105
00:07:05,032 --> 00:07:08,946
far fewer restrictions on preprod environments. This enables

106
00:07:08,978 --> 00:07:12,406
developer to try new things and have some hope of fixing it when

107
00:07:12,428 --> 00:07:16,914
it goes wrong. But for production environments, this is often heavily restricted

108
00:07:16,962 --> 00:07:20,902
as far more damage can be done by a wrong move. This divided approach

109
00:07:20,966 --> 00:07:24,694
works well to allow a balance of self service whilst protecting

110
00:07:24,742 --> 00:07:28,426
production services. Both of the above items touch on the topic of

111
00:07:28,448 --> 00:07:31,926
balancing developer empowerment with central oversight.

112
00:07:32,038 --> 00:07:35,246
Self service is nearly always faster, as we haven't got to wait for

113
00:07:35,268 --> 00:07:38,586
someone else to become free to do what we need them to. It frees

114
00:07:38,618 --> 00:07:42,286
up any central teams to deal with support and improving the services

115
00:07:42,388 --> 00:07:46,382
of the IDP or DBaas. Self service empowers users,

116
00:07:46,446 --> 00:07:49,742
particularly by allowing us to try new things without worrying

117
00:07:49,806 --> 00:07:53,394
about wasting someone else's time. There's a few common methods for

118
00:07:53,432 --> 00:07:57,086
achieving this publishing assets such as helm charts that users

119
00:07:57,118 --> 00:08:00,594
can then customize and deploy themselves a Gitops workflow

120
00:08:00,642 --> 00:08:04,738
where the configuration of all resources, whether local or remote, are stored

121
00:08:04,754 --> 00:08:08,726
in a git repository and tools such as ArgoCd or flux are

122
00:08:08,748 --> 00:08:13,190
used to deploy those resources in kubernetes, a portal or marketplace.

123
00:08:13,270 --> 00:08:17,306
Even further abstracting the complexity and allowing users to see what's possible and

124
00:08:17,328 --> 00:08:20,938
select what they need. All of these have tradeoffs, in particular

125
00:08:21,024 --> 00:08:24,238
in terms of the level of investment and maintenance for a

126
00:08:24,244 --> 00:08:27,614
central team versus the level of knowledge needed by the end

127
00:08:27,652 --> 00:08:30,926
user. So now we've seen the

128
00:08:30,948 --> 00:08:34,926
importance, we've seen the value of building a database

129
00:08:34,958 --> 00:08:38,814
as a service offering for your internal developer

130
00:08:38,862 --> 00:08:44,114
platform. But we've also seen the difficulties and

131
00:08:44,152 --> 00:08:48,262
we've also seen the importance of making these

132
00:08:48,316 --> 00:08:51,970
platform features available through a self service approach

133
00:08:52,050 --> 00:08:55,430
and we've seen possibilities of how you can do that.

134
00:08:55,580 --> 00:08:59,386
So let's now explore the tools and

135
00:08:59,408 --> 00:09:02,666
the architecture of how we can actually go on and

136
00:09:02,688 --> 00:09:03,740
implement this.

137
00:09:06,430 --> 00:09:09,834
So initially the first

138
00:09:09,872 --> 00:09:13,294
step on a really high level, the first step is that

139
00:09:13,332 --> 00:09:17,742
we want each developer to be able to define what

140
00:09:17,796 --> 00:09:21,022
database requirements they have. The second

141
00:09:21,076 --> 00:09:24,514
step is we want this definition to be

142
00:09:24,552 --> 00:09:28,034
translated into resources that our platform can

143
00:09:28,072 --> 00:09:31,906
understand. And then finally we

144
00:09:31,928 --> 00:09:35,650
want to give our platform the ability of deploying and managing

145
00:09:35,810 --> 00:09:37,510
and managing databases.

146
00:09:39,370 --> 00:09:43,186
Now let's start looking into the tool. So initially we're

147
00:09:43,218 --> 00:09:46,550
going to look into the Kubernetes operators we're going to be using.

148
00:09:46,700 --> 00:09:52,570
So on a very high level, the user defines

149
00:09:53,310 --> 00:09:57,340
what type of database deployments they need

150
00:09:57,950 --> 00:10:02,400
through a Kubectl command. They apply this to a cluster and then

151
00:10:02,850 --> 00:10:07,178
the operator in that cluster makes the necessary API calls

152
00:10:07,354 --> 00:10:10,826
in the Atlas API node to deploy those managed

153
00:10:10,858 --> 00:10:11,710
databases.

154
00:10:14,150 --> 00:10:18,562
What happens now under the hood is

155
00:10:18,616 --> 00:10:22,194
that you define a new custom resource and we're going to see

156
00:10:22,232 --> 00:10:25,830
in a bit more detail what that is exactly. And that custom

157
00:10:25,900 --> 00:10:29,602
resource is managed by the operators. And then the operator

158
00:10:29,666 --> 00:10:33,682
interacts with Kubernetes and makes the necessary

159
00:10:33,746 --> 00:10:36,966
call, sees what is the current state, what kind of

160
00:10:36,988 --> 00:10:40,506
adjustments the Kubernetes states needs, and then goes on

161
00:10:40,528 --> 00:10:42,730
and creates this custom resource.

162
00:10:44,030 --> 00:10:48,166
And the custom resource here we can see is the Atlas

163
00:10:48,198 --> 00:10:52,430
deployment resource. And to define this, it's pretty straightforward.

164
00:10:53,490 --> 00:10:57,680
You can just add the name you want for the database, the instance size,

165
00:10:58,370 --> 00:11:01,902
the provider and the region you care about

166
00:11:01,956 --> 00:11:03,760
and that's pretty much it.

167
00:11:05,830 --> 00:11:09,570
This is a good way, this is an easy way to deploy and manage databases.

168
00:11:10,070 --> 00:11:13,826
But still, in this scenario, using just the

169
00:11:13,848 --> 00:11:17,894
operator, you would need the developer, you would need anyone who needs

170
00:11:17,932 --> 00:11:21,282
to spin up a database to have this definition

171
00:11:21,346 --> 00:11:24,854
file locally, this yAml file locally, and you would have them to run

172
00:11:24,892 --> 00:11:28,470
Kubectl manually and deploy the database.

173
00:11:28,810 --> 00:11:31,850
So what we want to do is to automate this process.

174
00:11:32,000 --> 00:11:35,334
And instead of having this YAML files locally,

175
00:11:35,382 --> 00:11:39,226
instead of running commands locally, we would like to do

176
00:11:39,248 --> 00:11:43,306
this in a kind of a different way. So we

177
00:11:43,328 --> 00:11:47,086
have a developer, the YaML is developed and

178
00:11:47,108 --> 00:11:50,894
then the YaMl is pushed to a repo which is

179
00:11:51,012 --> 00:11:55,442
specifically designed to have our infrastructure as

180
00:11:55,496 --> 00:12:00,354
code files. From that point what

181
00:12:00,392 --> 00:12:04,446
we do is we pull the files from this repository, ArgocD pulls

182
00:12:04,478 --> 00:12:10,134
those files and ArgoCd is responsible for

183
00:12:10,172 --> 00:12:13,938
applying the changes in our Kubernetes cluster.

184
00:12:14,114 --> 00:12:17,846
And the way it does that is by creating a simple application

185
00:12:17,948 --> 00:12:21,126
like this, we define exactly the repo URL that we

186
00:12:21,148 --> 00:12:24,490
want Argocd to be watching, exactly which revision,

187
00:12:24,910 --> 00:12:29,830
and we see again the sync policy, whether we want automated

188
00:12:29,910 --> 00:12:33,550
sync and some other conditions.

189
00:12:36,410 --> 00:12:40,166
So let's kind of put all of these together and see how this

190
00:12:40,188 --> 00:12:44,040
is going to work. So to get started,

191
00:12:44,650 --> 00:12:48,058
you need to set up some prerequisites. Initially you

192
00:12:48,064 --> 00:12:50,938
would need an Atlas account and an API key.

193
00:12:51,104 --> 00:12:55,002
You want to run in Kubernetes cluster and you want to

194
00:12:55,056 --> 00:12:58,670
install the Atlas Kubernetes operator in that cluster.

195
00:12:59,410 --> 00:13:02,058
You would then go on and install Argocd,

196
00:13:02,234 --> 00:13:05,114
create a dedicated infrastructure as code repository,

197
00:13:05,242 --> 00:13:08,910
and then create an ArgoCD application towards that repository.

198
00:13:10,450 --> 00:13:14,746
And finally, this is what our

199
00:13:14,868 --> 00:13:18,466
service database as a service looks like. So initially the

200
00:13:18,488 --> 00:13:21,746
developer develops the file, pushes it in the

201
00:13:21,768 --> 00:13:25,462
git repo, when usually we would have a pr open.

202
00:13:25,516 --> 00:13:28,966
At that point when that's merged to the specific branch that we

203
00:13:28,988 --> 00:13:32,338
have Argo looking, then Argo would be triggered,

204
00:13:32,434 --> 00:13:36,994
it would pull the changes, apply the changes in Kubernetes,

205
00:13:37,122 --> 00:13:40,470
and then as a new custom resource

206
00:13:40,810 --> 00:13:44,806
is deployed, then the Kubernetes operator would take on

207
00:13:44,908 --> 00:13:48,714
and of call the Atlas API and create the resources,

208
00:13:48,762 --> 00:13:52,014
the users, the databases that we need and so on.

209
00:13:52,212 --> 00:13:55,918
And this is pretty much how our database as a

210
00:13:55,924 --> 00:13:59,310
service offering for our internal developer platform

211
00:13:59,380 --> 00:14:02,140
is going to look like. Thank you for watching.

