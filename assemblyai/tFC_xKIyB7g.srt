1
00:00:38,850 --> 00:00:42,326
Hi, welcome to addressing security concerns in every stage of

2
00:00:42,348 --> 00:00:46,626
the software supply chain. My name is Melissa McKay. I'm a developer advocate

3
00:00:46,658 --> 00:00:50,414
at JFrog and just some quick background on me. Me,

4
00:00:50,532 --> 00:00:53,854
for the past well over 20 years now, primarily I've been a

5
00:00:53,892 --> 00:00:57,646
developer all the way from a lowly intern to a principal engineer. And the

6
00:00:57,668 --> 00:01:00,442
last few years of my career as a developer advocate,

7
00:01:00,586 --> 00:01:04,586
I've been going to conferences, talking and sharing about these experiences.

8
00:01:04,778 --> 00:01:08,226
A lot of this talk will be that. Exactly. Just things that I

9
00:01:08,248 --> 00:01:11,570
found over the course of my time as a developer.

10
00:01:12,150 --> 00:01:15,586
My contact information is here if you have any questions, and I'll share that with

11
00:01:15,608 --> 00:01:19,126
you again at those end. So one of the things that I've been able

12
00:01:19,148 --> 00:01:22,742
to do as a developer advocate is have a lot of interactions with other people,

13
00:01:22,796 --> 00:01:26,326
other people that work at other places, deal with lots of

14
00:01:26,348 --> 00:01:29,994
different things. And one gentleman I had the pleasure of meeting and working with was

15
00:01:30,032 --> 00:01:34,006
Damien Curry. He is the business development technical

16
00:01:34,038 --> 00:01:37,530
director at F five and with Nginx originally.

17
00:01:38,030 --> 00:01:41,558
And with him we decided to

18
00:01:41,584 --> 00:01:45,040
get together and just kind of explain the journey of an application.

19
00:01:46,050 --> 00:01:50,014
Basically what we wanted to talk about was a

20
00:01:50,052 --> 00:01:54,110
series of just going through each of the stages that you plan

21
00:01:54,180 --> 00:01:57,810
for and discuss as you're running through all of this,

22
00:01:57,960 --> 00:02:01,426
necessary steps that you need to take to get an application,

23
00:02:01,528 --> 00:02:05,726
all the way from just the very beginnings of development all the way into production.

24
00:02:05,838 --> 00:02:09,590
And we have a list of episodes that we've created,

25
00:02:10,250 --> 00:02:13,766
each of them varying time, maybe 30 45 minutes each.

26
00:02:13,868 --> 00:02:18,114
And the one that was really interesting was the one where we considered

27
00:02:18,162 --> 00:02:21,914
security. This talk I'll be focusing more on during

28
00:02:22,032 --> 00:02:25,306
those episode or in this talk. It was really interesting to

29
00:02:25,328 --> 00:02:28,426
get a developer's perspective myself, as well as an

30
00:02:28,448 --> 00:02:32,266
ops perspective on those, which was more in Damien's

31
00:02:32,298 --> 00:02:36,062
field. So I don't know how many of you have seen this.

32
00:02:36,116 --> 00:02:40,122
This is just a typical default web server

33
00:02:40,186 --> 00:02:44,206
page. And way back this was my very first experience

34
00:02:44,308 --> 00:02:47,714
even thinking about security during my

35
00:02:47,752 --> 00:02:51,186
time in school and when I was learning in the very beginning as a

36
00:02:51,208 --> 00:02:54,498
junior, it just didn't cross my mind how many things we need

37
00:02:54,504 --> 00:02:57,846
to be concerned with in addition to just writing good code.

38
00:02:57,948 --> 00:03:01,734
But there's other things about our environments that we really need to pay attention to

39
00:03:01,772 --> 00:03:05,378
as developers. And one thing that was introduced

40
00:03:05,394 --> 00:03:08,386
to me was security through obsofuscation.

41
00:03:08,498 --> 00:03:11,866
I didn't even say that word correctly. And this was

42
00:03:11,968 --> 00:03:15,306
funny because we can go on and on about

43
00:03:15,328 --> 00:03:19,500
whether this is a good strategy or not. It was my first experience

44
00:03:20,030 --> 00:03:23,578
touching on security at all. So basically, my first step was to

45
00:03:23,584 --> 00:03:27,534
go through and make sure that this default page didn't show up because we

46
00:03:27,572 --> 00:03:30,958
didn't really want to reveal what version of Apache we were using,

47
00:03:31,044 --> 00:03:34,818
just in case someone had any clever ideas of attacking that particular

48
00:03:34,904 --> 00:03:37,220
version. So obviously,

49
00:03:37,670 --> 00:03:40,180
lots of reasons to be concerned with security.

50
00:03:41,750 --> 00:03:45,058
All over the news we hear about theft of private customer and

51
00:03:45,064 --> 00:03:48,194
or company data. I just got a letter in the mail,

52
00:03:48,242 --> 00:03:52,770
as probably a lot of you have gotten from various

53
00:03:52,930 --> 00:03:56,978
banking places and other places

54
00:03:56,994 --> 00:04:00,438
that use my credit, things like that. So lots of reasons and lots

55
00:04:00,454 --> 00:04:03,946
of money in this business. Talking about that, the loss of

56
00:04:03,968 --> 00:04:07,226
money for an organization, if they're not taking their security seriously or

57
00:04:07,248 --> 00:04:09,974
they suffer from some intrusion,

58
00:04:10,102 --> 00:04:13,486
there can be a loss of money not only on their side, but on their

59
00:04:13,508 --> 00:04:17,550
customer side, and also loss of credibility. We can all agree that

60
00:04:17,620 --> 00:04:21,546
downtime as well, for any reason, is a problem in your production environment.

61
00:04:21,658 --> 00:04:25,380
So yet another reason to be concerned with security issues.

62
00:04:25,990 --> 00:04:29,698
I'm just going to whip through some famous hacks. This one, probably most of

63
00:04:29,704 --> 00:04:33,646
you are familiar with those equifax data breach.

64
00:04:33,838 --> 00:04:36,226
This happened march through July of 2017,

65
00:04:36,248 --> 00:04:39,702
and there was a lot of money involved in this.

66
00:04:39,756 --> 00:04:43,942
1.4 billion in cleanup costs, estimated 1.38

67
00:04:43,996 --> 00:04:48,118
billion in consumer claims, and 143,000,000 customers

68
00:04:48,284 --> 00:04:51,974
were affected. For those of you familiar with this, this was an Apache

69
00:04:52,022 --> 00:04:55,418
struts vulnerability. Unfortunately for this company, this was a

70
00:04:55,424 --> 00:04:59,114
vulnerability that was known, but just wasn't patched in time

71
00:04:59,232 --> 00:05:02,826
before something happened. What happens,

72
00:05:02,928 --> 00:05:06,090
in a nutshell on this one, this next one log for shell,

73
00:05:06,170 --> 00:05:09,678
is that one chain trigger a remote code execution by providing a

74
00:05:09,684 --> 00:05:13,418
string in a certain format that ends up being logged. And that turns

75
00:05:13,434 --> 00:05:16,990
out that that opens up the ability to initiate an LDAP lookup,

76
00:05:17,150 --> 00:05:21,326
fetch some compiled code, and execute it. And just about every Java

77
00:05:21,358 --> 00:05:25,070
developer out there cringed their way through. Fixing this vulnerability

78
00:05:25,230 --> 00:05:28,100
took a lot of time, lots of money as well.

79
00:05:28,890 --> 00:05:32,214
When we're talking about money, we're not talking about just claims. We're talking about the

80
00:05:32,252 --> 00:05:36,182
time that developers need to spend and ops need to spend fixing these

81
00:05:36,236 --> 00:05:38,410
problems. Stephen Miguel,

82
00:05:39,550 --> 00:05:43,142
the vice president of product innovation at Sonotype, he estimated

83
00:05:43,206 --> 00:05:46,954
that approximately 70,000 open source projects use

84
00:05:46,992 --> 00:05:51,670
log for j as a direct dependency and 174,000

85
00:05:51,760 --> 00:05:55,018
projects use it as a transitive dependencies.

86
00:05:55,114 --> 00:05:58,766
That means a dependency of a dependency. All right,

87
00:05:58,788 --> 00:06:01,886
here's another one. This is just interesting to me. I just

88
00:06:01,908 --> 00:06:05,818
went looking just to see what the most recent attacks were. We hear

89
00:06:05,844 --> 00:06:09,058
this stuff in the news all of the time, kind of addressing a lot

90
00:06:09,064 --> 00:06:12,366
of those have to do with data breaches, and this website attracts

91
00:06:12,398 --> 00:06:14,530
the latest data breaches.

92
00:06:15,270 --> 00:06:19,478
It's of course a huge motivator for hackers due to its immense value,

93
00:06:19,644 --> 00:06:23,670
and there's several of those each month, and there's already

94
00:06:23,740 --> 00:06:27,350
some new ones that have come out, but there were a few

95
00:06:27,500 --> 00:06:31,046
that really caught my attention, mainly because of the commonality

96
00:06:31,158 --> 00:06:34,922
of the move it hack between all of these. So in

97
00:06:34,976 --> 00:06:38,566
June 1, 2023, the move it hack

98
00:06:38,678 --> 00:06:40,910
affected zealous British Airways,

99
00:06:42,130 --> 00:06:45,920
BBC, and others. It's a popular file transfer tool.

100
00:06:46,610 --> 00:06:50,526
Again, in July 20, it reared its ugly head.

101
00:06:50,628 --> 00:06:54,814
There was a poker stars data breach. This is the world's largest

102
00:06:54,862 --> 00:06:58,546
online poker platform, and it suffered this data breach which exposed the

103
00:06:58,568 --> 00:07:01,220
information of 110,000 customers.

104
00:07:01,670 --> 00:07:05,534
The attackers, they exploited that move it zero day

105
00:07:05,592 --> 00:07:09,346
vulnerability to gain access to the poker site systems,

106
00:07:09,458 --> 00:07:12,806
and they're no longer using the move it transfer application.

107
00:07:12,988 --> 00:07:15,650
But there was a lot of data stolen in the meantime,

108
00:07:15,730 --> 00:07:19,522
unfortunately last 1 August 11,

109
00:07:19,586 --> 00:07:23,562
that I'll just point out also in 2023,

110
00:07:23,696 --> 00:07:27,706
this is the IBM move it data breach. There were 4.1 million

111
00:07:27,808 --> 00:07:31,526
patients in Colorado that had sensitive healthcare data stolen

112
00:07:31,558 --> 00:07:35,194
during another that exploited that same vulnerability. In those move

113
00:07:35,232 --> 00:07:38,878
it transfer software, the systems affected were

114
00:07:38,964 --> 00:07:42,222
managed by large companies like IBM, so this was

115
00:07:42,276 --> 00:07:45,706
serious business. There's a featured article on TechCrunch

116
00:07:45,738 --> 00:07:49,134
that was put out on August 25, described the moveit hack

117
00:07:49,182 --> 00:07:52,450
as the biggest hack of the year by the numbers. It's an interesting

118
00:07:52,520 --> 00:07:55,870
one to check out. Included a QR code here for you if you want

119
00:07:55,880 --> 00:07:59,746
to go read that yourself. The global average

120
00:07:59,778 --> 00:08:03,670
cost of a data breach was $4.45

121
00:08:03,740 --> 00:08:07,462
million in 2023. That's a 15%

122
00:08:07,516 --> 00:08:11,034
increase over three years. This is serious business, so we

123
00:08:11,072 --> 00:08:14,426
do need to sit back and figure out what we can do to

124
00:08:14,448 --> 00:08:18,870
help mitigate these problems. And as a developer,

125
00:08:19,030 --> 00:08:23,194
it does sound reasonable to say that if you're developing software,

126
00:08:23,242 --> 00:08:27,182
you're writing software, it is your responsibility to write code

127
00:08:27,316 --> 00:08:29,998
that is secure. This is absolutely true.

128
00:08:30,084 --> 00:08:32,880
But as we talk a little bit further about this,

129
00:08:33,270 --> 00:08:36,882
there's something that you need to understand. It's not all about the code

130
00:08:36,936 --> 00:08:40,180
that's written itself. So just for fun,

131
00:08:40,790 --> 00:08:43,730
I discovered this essay,

132
00:08:44,790 --> 00:08:48,310
how to write insecure code. For those of you that like sarcasm,

133
00:08:48,730 --> 00:08:52,134
you'll really enjoy this one. There's quite a few

134
00:08:52,252 --> 00:08:55,522
third party organizations that can be hired by corporations

135
00:08:55,586 --> 00:08:59,334
to train their developers internally, and I'd highly recommend that

136
00:08:59,372 --> 00:09:02,570
approach. But if you're on your own learning these things, this is a really good

137
00:09:02,640 --> 00:09:06,026
research for you even just this essay itself, even though it's kind of

138
00:09:06,048 --> 00:09:09,194
a joke, there's some things in here that are really good to point

139
00:09:09,232 --> 00:09:12,826
out and lots of detailed information on how to protect your systems,

140
00:09:12,858 --> 00:09:16,314
how to protect your container images,

141
00:09:16,362 --> 00:09:20,174
for example, the environments that they're running in. It's pretty

142
00:09:20,212 --> 00:09:23,822
amazing. And OASP, the open web application security project,

143
00:09:23,876 --> 00:09:27,298
that's where this essay is. That's the resource that has a lot of

144
00:09:27,304 --> 00:09:31,186
this information for free. So there's a lot of opportunity for you

145
00:09:31,208 --> 00:09:33,460
to go out and learn on your own.

146
00:09:34,390 --> 00:09:37,686
Some of the things that were included in this essay I thought were important to

147
00:09:37,708 --> 00:09:41,042
point out. Always using default. Deny.

148
00:09:41,186 --> 00:09:44,934
This is kind of silly. Denying that your code can't ever

149
00:09:44,972 --> 00:09:49,766
be broken. Deny unless there's

150
00:09:49,798 --> 00:09:53,786
something that can be proven that it's actually broken. Just pretend that

151
00:09:53,808 --> 00:09:57,562
everything's fine. Secure languages who

152
00:09:57,696 --> 00:10:01,434
writes in secure languages? I think we all have a tendency to

153
00:10:01,472 --> 00:10:05,130
adore the language that we were brought up with. My background is in Java.

154
00:10:05,210 --> 00:10:09,146
I enjoy writing a lot of Java. That's basically where I'm

155
00:10:09,178 --> 00:10:12,938
most familiar. But we all know that all of our languages have pros

156
00:10:12,954 --> 00:10:16,354
and cons, and there are some things that we need to pay attention to that,

157
00:10:16,392 --> 00:10:18,660
some weaknesses that we need to learn.

158
00:10:19,270 --> 00:10:22,418
Mixing different languages. This is kind of funny being a

159
00:10:22,424 --> 00:10:26,274
Java developer. It's important to point out that these days,

160
00:10:26,392 --> 00:10:29,526
rarely are you going to find a Java developer where all they program is in

161
00:10:29,548 --> 00:10:33,046
Java. There's lots of other languages that you need to learn in

162
00:10:33,068 --> 00:10:36,486
order to get things like web apps out there, be able to

163
00:10:36,508 --> 00:10:39,410
write scripts in shell,

164
00:10:39,570 --> 00:10:43,846
things like that, lots of python these days there's

165
00:10:43,878 --> 00:10:47,386
a lot of opportunities to learn and work with other languages as well.

166
00:10:47,488 --> 00:10:50,234
And one of the jokes in this essay is that if you mix as many

167
00:10:50,272 --> 00:10:53,998
as possible, you'll be fine. They all have different security

168
00:10:54,084 --> 00:10:58,000
rules, so it'll be difficult to break into any of them.

169
00:10:58,690 --> 00:11:01,838
Pretty silly idea. A few more before I just let you

170
00:11:01,844 --> 00:11:05,738
go. Read the rest on your own. Relying on security checks done elsewhere.

171
00:11:05,834 --> 00:11:09,746
This is a big one for developers, right? Because we often were

172
00:11:09,768 --> 00:11:12,866
on teams. If you're in a larger company, you may be on a team that

173
00:11:12,888 --> 00:11:16,466
has a whole nother separate security team that is dealing with a lot

174
00:11:16,488 --> 00:11:20,054
of these issues. So it's easy to kind of sit back and think

175
00:11:20,092 --> 00:11:23,126
that, oh, well, that's already being taken care of by someone else, so I don't

176
00:11:23,148 --> 00:11:27,030
really need to think about it. Obviously, learning about a security

177
00:11:27,100 --> 00:11:30,538
problem much later in the development process is a lot more expensive and difficult

178
00:11:30,624 --> 00:11:34,314
to mitigate than dealing with it or preventing it up

179
00:11:34,352 --> 00:11:38,314
from in front of the developer. So anything that

180
00:11:38,352 --> 00:11:41,658
we can do to help this process is valuable,

181
00:11:41,754 --> 00:11:44,974
and we do need to learn what is in our

182
00:11:45,012 --> 00:11:48,400
developers toolbox to help us prevent some of these things from happening.

183
00:11:49,010 --> 00:11:52,734
On trusting insiders malicious input only

184
00:11:52,772 --> 00:11:56,354
comes from the Internet. You can trust that all data in your databases is

185
00:11:56,392 --> 00:11:59,966
perfectly validated, encoded and sanitized for your purposes. Anyone who's

186
00:11:59,998 --> 00:12:03,778
been dealing with, especially if you switch back and forth between a

187
00:12:03,784 --> 00:12:07,240
production or a test system, you know that there's opportunity sometimes

188
00:12:08,090 --> 00:12:11,846
if you're allowed too many permissions, or maybe the systems aren't set up in such

189
00:12:11,868 --> 00:12:15,606
a way to prevent accidents. Obviously you

190
00:12:15,628 --> 00:12:19,850
can get problems from within. It doesn't always come externally

191
00:12:20,670 --> 00:12:24,266
and then code wants to be free. This last one, dropping your source code into

192
00:12:24,288 --> 00:12:26,940
repositories that are accessible by all within the company,

193
00:12:28,910 --> 00:12:31,946
especially back when I was a junior, I used to want to have access to

194
00:12:31,968 --> 00:12:35,306
everything. I wanted to see everything, mainly just because I was curious.

195
00:12:35,418 --> 00:12:38,586
But oftentimes that's not the best. It's for your own protection

196
00:12:38,618 --> 00:12:42,400
to only have access to what you actually need to have access to.

197
00:12:43,430 --> 00:12:47,278
Being able to update a repository

198
00:12:47,374 --> 00:12:50,658
or make changes to code that maybe isn't even in

199
00:12:50,664 --> 00:12:54,210
your project, not a real safe way to operate.

200
00:12:54,870 --> 00:12:58,674
And we have to remember a lot of times errors

201
00:12:58,722 --> 00:13:02,694
happen or issues happen, that it

202
00:13:02,732 --> 00:13:06,086
wasn't on purpose, it wasn't malicious intent, it could have been just

203
00:13:06,108 --> 00:13:09,366
an accident. So we have permissions to kind

204
00:13:09,388 --> 00:13:13,260
of give us comes guardrails to prevent things like that from happening.

205
00:13:13,950 --> 00:13:16,954
So educating developers is really important. I talked about this,

206
00:13:16,992 --> 00:13:20,826
and I was lucky enough to be involved with an organization that did have

207
00:13:20,848 --> 00:13:24,282
one of these third party organizations that was hired

208
00:13:24,346 --> 00:13:28,794
to train us a little bit. And depending on your particular language,

209
00:13:28,842 --> 00:13:32,526
that was your focus. You had some specialized activities to

210
00:13:32,548 --> 00:13:36,274
learn about all of these things. We had learned about what SQL injection was,

211
00:13:36,312 --> 00:13:39,986
what cross site request forgery was, what LDAP injection was,

212
00:13:40,088 --> 00:13:43,922
how to prevent these things. And after taking those

213
00:13:43,976 --> 00:13:46,882
courses, I really thought I knew my stuff. I thought,

214
00:13:46,936 --> 00:13:50,342
well, I'm going to write the most secure code ever. This is all

215
00:13:50,396 --> 00:13:53,878
I really need. And as long as I do that, everything's going to

216
00:13:53,884 --> 00:13:57,398
be fine. What I didn't understand at that time

217
00:13:57,484 --> 00:14:00,826
and quickly learned thereafter is even though I was

218
00:14:00,848 --> 00:14:04,970
confident in writing strong code myself, it turns out there's so

219
00:14:05,040 --> 00:14:07,340
much open source code that we use.

220
00:14:07,950 --> 00:14:11,002
Part of being a responsible developer is to not

221
00:14:11,056 --> 00:14:14,190
continuously reinvent the wheel if it's not required.

222
00:14:14,610 --> 00:14:18,478
Being able to go out there and find resources that you can build off of

223
00:14:18,564 --> 00:14:22,090
is going to help you get your applications out to production faster,

224
00:14:22,170 --> 00:14:25,674
deal with issues faster. If you have

225
00:14:25,812 --> 00:14:29,154
these frameworks that work really well for you, you're going to be able to just

226
00:14:29,192 --> 00:14:32,446
develop your applications more efficiently. So it turns

227
00:14:32,478 --> 00:14:36,242
out there is a ton of code that you may not have ever

228
00:14:36,296 --> 00:14:39,622
written and may never look at and don't know much

229
00:14:39,676 --> 00:14:43,286
about, other than they are just the building blocks that you're building on

230
00:14:43,308 --> 00:14:46,886
top of. So it turns out there's a lot of code, like this

231
00:14:46,908 --> 00:14:50,730
iceberg picture that is pulled in during your build

232
00:14:50,800 --> 00:14:53,978
that you've never touched or looked at before. And when

233
00:14:53,984 --> 00:14:58,090
I was working with Damien on our

234
00:14:58,160 --> 00:15:01,658
series, there was a little project we were working on. There was

235
00:15:01,664 --> 00:15:03,390
a number of different components,

236
00:15:03,970 --> 00:15:07,646
and I just did a maven tree just to

237
00:15:07,668 --> 00:15:11,390
look and see what all of the dependencies were. And it turns out, just in

238
00:15:11,460 --> 00:15:15,186
single component that we were looking at, there were 114 direct

239
00:15:15,288 --> 00:15:19,038
and indirect dependencies, and they went seven layers deep.

240
00:15:19,134 --> 00:15:22,814
So dependencies of dependencies of dependencies. And these were all just brought

241
00:15:22,862 --> 00:15:26,434
in as I was doing a build from Maven Central.

242
00:15:26,562 --> 00:15:30,610
And again, that entire application consisted of seven microservices.

243
00:15:30,690 --> 00:15:33,960
So this is multiplied by seven.

244
00:15:34,890 --> 00:15:38,290
There are a lot of security reports out there that you

245
00:15:38,300 --> 00:15:41,722
can take a look at. This one is particularly interesting, open source security

246
00:15:41,776 --> 00:15:45,260
and risk analysis report. In this 1117

247
00:15:45,710 --> 00:15:49,702
o, three commercial code bases across 17

248
00:15:49,766 --> 00:15:53,354
different industries were scanned. And one thing,

249
00:15:53,392 --> 00:15:56,990
when you're reading reports like this, always look at the methodology.

250
00:15:57,890 --> 00:16:01,374
This number is kind of buried in the report just to give you an idea

251
00:16:01,412 --> 00:16:04,606
of where this information is actually coming from. And I'm always impressed when

252
00:16:04,628 --> 00:16:08,740
that is upfront for you to see. This one was,

253
00:16:09,510 --> 00:16:12,914
and they have a number of different graphs of the different industries. I liked how

254
00:16:12,952 --> 00:16:16,246
they categorized all of these things, because sometimes when we work

255
00:16:16,268 --> 00:16:20,178
in a silo, we don't realize all of the code that's being written everywhere

256
00:16:20,274 --> 00:16:24,280
in every industry. These three were pretty important.

257
00:16:25,370 --> 00:16:28,506
I just took these three graphs directly from the

258
00:16:28,528 --> 00:16:32,422
section on the use of open source and the three industries

259
00:16:32,566 --> 00:16:35,020
that I thought were most interesting.

260
00:16:35,870 --> 00:16:39,466
Also interesting. And maybe this can be a

261
00:16:39,488 --> 00:16:42,686
fun talk with your colleagues or whatever, is why there's such a peak in

262
00:16:42,708 --> 00:16:46,400
2020. I chain only imagine maybe

263
00:16:47,410 --> 00:16:50,654
the peak in vulnerabilities. I don't know if they're just more being

264
00:16:50,692 --> 00:16:54,110
discovered in 2020 or more being introduced.

265
00:16:54,270 --> 00:16:56,820
You can go round and round with your colleagues on that one.

266
00:16:57,270 --> 00:17:00,100
If every developer that writes code,

267
00:17:00,470 --> 00:17:05,566
writes secure code and doesn't make mistakes,

268
00:17:05,758 --> 00:17:09,494
then we shouldn't have any of these problems, right? And is it

269
00:17:09,532 --> 00:17:13,640
really all up to developers? And I think you already know the answer to that.

270
00:17:14,250 --> 00:17:17,590
There is a lot that we can do, but there's actually a lot

271
00:17:17,740 --> 00:17:21,130
that we aren't involved with, like the code that we've written.

272
00:17:21,550 --> 00:17:24,666
It doesn't matter how well we've written it, there's still some issues we

273
00:17:24,688 --> 00:17:28,666
need to be aware of. This is a perfect example of it.

274
00:17:28,848 --> 00:17:32,670
Solar winds. So this involved 18,000

275
00:17:32,740 --> 00:17:36,714
customers that received an update that included malicious code with a backdoor.

276
00:17:36,842 --> 00:17:40,430
And basically 4000

277
00:17:40,500 --> 00:17:44,430
lines of code was written to the Orion platform DLL.

278
00:17:44,590 --> 00:17:48,546
But it was done after compilation, which suggests that

279
00:17:48,568 --> 00:17:52,100
the binary may have been switched in the CI system

280
00:17:52,470 --> 00:17:55,894
internally. And what made this foolproof is the fact that

281
00:17:55,932 --> 00:17:59,394
that file was even digitally signed. So it's

282
00:17:59,442 --> 00:18:03,814
possible that attackers had access to the SolarWinds software development or

283
00:18:03,932 --> 00:18:07,334
the distribution pipeline. So after the code

284
00:18:07,372 --> 00:18:11,194
is written and sent off to be built and then

285
00:18:11,232 --> 00:18:14,634
to be delivered, something happened in there. So it's just way

286
00:18:14,672 --> 00:18:18,134
more complicated than just developers themselves writing secure

287
00:18:18,182 --> 00:18:22,314
code. This is a corporate slide that I see often in

288
00:18:22,352 --> 00:18:25,854
decks within JFrog. And this just kind of gives you a view

289
00:18:25,892 --> 00:18:29,550
of the world of all of the environments that we work with,

290
00:18:29,620 --> 00:18:33,838
all of these components that we put together when we build our software.

291
00:18:33,934 --> 00:18:37,134
And you can see the whole process here of a developer

292
00:18:37,182 --> 00:18:40,670
initially writing code, pulling in packages and libraries

293
00:18:40,750 --> 00:18:44,130
from remote repositories or public repositories,

294
00:18:44,630 --> 00:18:48,582
going all the way through building it on your CI servers, whichever tool you choose

295
00:18:48,636 --> 00:18:52,594
to use. And I just want to highlight all of these red arrows

296
00:18:52,722 --> 00:18:56,038
everywhere where we refer

297
00:18:56,124 --> 00:18:59,466
to artifacts and dependencies. There's a

298
00:18:59,488 --> 00:19:03,514
lot of places in here that are weak points that

299
00:19:03,632 --> 00:19:07,366
if an attacker has access to, they can interrupt this flow

300
00:19:07,478 --> 00:19:11,166
and basically cause you to put out

301
00:19:11,188 --> 00:19:14,906
a vulnerability into production. One organization

302
00:19:15,018 --> 00:19:18,526
that has been helping define all of

303
00:19:18,548 --> 00:19:22,282
these areas where there can be issues is the supply chain levels for software

304
00:19:22,346 --> 00:19:26,290
artifacts. Salsa. This is basically

305
00:19:26,360 --> 00:19:29,954
an attempt to measure an organization's progress and to help give

306
00:19:29,992 --> 00:19:33,906
them goals to improve. Just to kind of give you a

307
00:19:33,928 --> 00:19:37,670
baseline to start with and give you ideas on

308
00:19:37,740 --> 00:19:41,026
what different areas of your software development

309
00:19:41,058 --> 00:19:44,102
process you can improve. So between

310
00:19:44,156 --> 00:19:47,366
your source code and the delivery of your product, or the

311
00:19:47,388 --> 00:19:51,386
deployment of your service, there are places you really do need to take extra care

312
00:19:51,488 --> 00:19:55,654
to protect your supply chain. And each one of these red triangles

313
00:19:55,702 --> 00:19:58,890
represents an opportunity for an attacker to disrupt.

314
00:19:59,310 --> 00:20:02,954
So let's talk about a few more examples of things that developers

315
00:20:03,082 --> 00:20:07,040
need to be aware of that we can have some control over,

316
00:20:07,650 --> 00:20:11,566
and one of these is called a dependency confusion attack. This was

317
00:20:11,588 --> 00:20:15,730
described by Alex Burson in a blog post on medium a couple of years ago.

318
00:20:15,880 --> 00:20:19,246
It turns out that most projects have a collection of dependencies,

319
00:20:19,358 --> 00:20:22,862
and they include open source or publicly available packages

320
00:20:22,926 --> 00:20:26,706
as well as internal packages. And this example, the highlighted

321
00:20:26,738 --> 00:20:30,150
yellow, are internal package names.

322
00:20:30,570 --> 00:20:33,654
Note that the version requirements for these are just

323
00:20:33,692 --> 00:20:36,870
that, the version is either the one specified or greater.

324
00:20:37,290 --> 00:20:41,402
Those package names when you build are not secret either.

325
00:20:41,456 --> 00:20:44,774
It turns out that NPM requests inform about internal

326
00:20:44,822 --> 00:20:48,266
package names. So what exactly is the problem here?

327
00:20:48,368 --> 00:20:51,386
Well, let's take a look at what it means. In the diagram,

328
00:20:51,498 --> 00:20:56,350
a request is made for a corporate library, an internally built

329
00:20:56,420 --> 00:20:59,726
library, something that may be proprietary and

330
00:20:59,748 --> 00:21:03,498
it's expected to come from some internal repository.

331
00:21:03,674 --> 00:21:06,926
But what happens instead is that the package manager

332
00:21:06,958 --> 00:21:10,754
sees that there's a greater version available publicly, and it will pull

333
00:21:10,792 --> 00:21:14,450
that one instead. So who knows what's in that package?

334
00:21:15,110 --> 00:21:17,970
Havoc ensues. You'll find out pretty quick, probably.

335
00:21:18,040 --> 00:21:21,542
Or if it's something maybe not,

336
00:21:21,596 --> 00:21:24,482
maybe you won't find out pretty quick. It could be something running in the background

337
00:21:24,546 --> 00:21:28,294
that you don't see right away. But one way to protect yourself from

338
00:21:28,332 --> 00:21:32,246
a scenario like that is to control your requests for internal packages.

339
00:21:32,358 --> 00:21:36,010
And using an artifact management system, you can specify

340
00:21:36,510 --> 00:21:40,278
internal package requests to only be resolved with internal repositories.

341
00:21:40,374 --> 00:21:43,834
It's important to remember to do this because this isn't the default

342
00:21:43,882 --> 00:21:47,518
setup, right? By default, you pretty much have access to anything.

343
00:21:47,684 --> 00:21:51,550
I don't know. Depending on how your organization works, you may be

344
00:21:51,620 --> 00:21:55,374
in a position where you don't have access to the Internet other

345
00:21:55,412 --> 00:21:58,302
than through proxies provided by your employer.

346
00:21:58,366 --> 00:22:01,618
You may be behind a firewall of some sort, but most of the time,

347
00:22:01,704 --> 00:22:05,414
especially when you're developing pet projects at comes or in any other

348
00:22:05,452 --> 00:22:09,010
environments, you're going to be pulling directly from public repositories.

349
00:22:09,170 --> 00:22:12,646
So it's important to understand that that's what's happening and the

350
00:22:12,668 --> 00:22:16,534
default behavior of your build

351
00:22:16,572 --> 00:22:20,506
software so that you know exactly what

352
00:22:20,528 --> 00:22:24,538
you're pulling in, where it is coming from. This particular attack

353
00:22:24,704 --> 00:22:28,060
$130,000.

354
00:22:29,550 --> 00:22:33,250
Alex did a really good job of employing

355
00:22:33,270 --> 00:22:37,002
himself with these bug bounties. There's quite a few details

356
00:22:37,066 --> 00:22:40,666
that he discusses in his article that I didn't talk about, so here's another QR

357
00:22:40,698 --> 00:22:44,160
code for you to read his original article about those.

358
00:22:44,610 --> 00:22:48,450
All right, here's another fun one. Managing open source dependencies. I think

359
00:22:48,520 --> 00:22:51,538
many of you, if you like Xkcd it's one of my

360
00:22:51,544 --> 00:22:54,946
favorite cartoons. You probably have seen this one. The problem has

361
00:22:54,968 --> 00:22:58,454
more to do with managing open source packages and libraries themselves. Not really

362
00:22:58,492 --> 00:23:01,634
about a malicious package or a vulnerable package.

363
00:23:01,762 --> 00:23:05,574
It just illustrates a trap that we fall into when we solely rely on

364
00:23:05,612 --> 00:23:09,290
public repositories for our builds, things that other people have written.

365
00:23:09,870 --> 00:23:13,206
And the best example of where those problem rears

366
00:23:13,238 --> 00:23:15,530
its head is the leftpad incident.

367
00:23:16,270 --> 00:23:19,466
Basically, a developer had an NPM package out

368
00:23:19,488 --> 00:23:22,906
there named Kick, and it was just a pet

369
00:23:22,938 --> 00:23:26,174
project that helped developers set up templates for their projects. It wasn't really

370
00:23:26,212 --> 00:23:30,270
widely known, but there was also a kick organization.

371
00:23:31,250 --> 00:23:34,910
It was a chat app and they owned the domain kick.

372
00:23:35,060 --> 00:23:38,818
So they had trouble with this kick package being out

373
00:23:38,824 --> 00:23:42,402
there in NPM because it just seemed like when someone wanted to pull

374
00:23:42,456 --> 00:23:46,466
in kick, they were expecting to get something associated with Kick.

375
00:23:46,648 --> 00:23:49,480
Also, Kick had a registered trademark on the.

376
00:23:50,010 --> 00:23:53,682
You know, there were some issues. Those they contacted, those developer

377
00:23:53,746 --> 00:23:57,518
tried to come to an agreement. They were not able to come to an agreement.

378
00:23:57,714 --> 00:24:01,962
So NPM came in. And because

379
00:24:02,016 --> 00:24:05,354
of that policy of making sure that users get

380
00:24:05,392 --> 00:24:09,126
a package that they expect in order to eliminate

381
00:24:09,238 --> 00:24:12,366
typo, squatting, that kind of thing, they sided with

382
00:24:12,388 --> 00:24:15,694
the kick organization. And under that policy,

383
00:24:15,812 --> 00:24:19,406
usually what happens is the existing package with the

384
00:24:19,428 --> 00:24:23,326
disputed name, it stays where it is, it remains

385
00:24:23,358 --> 00:24:27,202
on the NPM registry, but the new owner of that

386
00:24:27,256 --> 00:24:31,166
name publishes their package with a breaking version

387
00:24:31,198 --> 00:24:33,060
number. So that's what happened.

388
00:24:34,470 --> 00:24:38,466
But unfortunately, the developer

389
00:24:38,578 --> 00:24:41,830
unpublished his package and

390
00:24:41,900 --> 00:24:45,490
along with that, 272 other packages

391
00:24:45,570 --> 00:24:49,618
that he wrote. So obviously he was pretty miffed about the decision,

392
00:24:49,794 --> 00:24:53,434
did not support that at all. And one of those packages was

393
00:24:53,472 --> 00:24:57,290
left pad. This is a pretty big deal because it turned out that a lot

394
00:24:57,360 --> 00:25:00,650
of software out there relied on Leftpad,

395
00:25:01,090 --> 00:25:05,070
not even directly, but as a transitive dependency.

396
00:25:05,490 --> 00:25:08,826
So things were broken right away. There was a developer who stepped

397
00:25:08,858 --> 00:25:12,186
in, Cameron Westland, who published

398
00:25:12,378 --> 00:25:16,194
in order to help with this problem, he published an identical version of

399
00:25:16,312 --> 00:25:19,650
the package, labeled it as version 10.

400
00:25:19,800 --> 00:25:23,154
But many of those pieces of software that relied on it

401
00:25:23,192 --> 00:25:26,974
originally were following best practices and they were explicitly requesting

402
00:25:27,022 --> 00:25:30,370
version zero, zero, three. So it was still a big problem.

403
00:25:30,440 --> 00:25:33,858
People had to figure out exactly where in the code that they were relying

404
00:25:33,874 --> 00:25:37,078
on this and make sure they were getting the right package. Now, the most interesting

405
00:25:37,164 --> 00:25:40,374
thing about that story is this is it. These are the

406
00:25:40,412 --> 00:25:43,462
lines of code that were an issue and caused

407
00:25:43,526 --> 00:25:47,494
so much trouble. And if any of you know, deal or work in JavaScript,

408
00:25:47,542 --> 00:25:51,402
you might be familiar with React. React was broken because of this

409
00:25:51,536 --> 00:25:54,734
that's widely used and created by Facebook and used

410
00:25:54,772 --> 00:25:58,234
by Facebook. And many of these projects actually relied

411
00:25:58,282 --> 00:26:01,966
on kick as a transitive dependency. So just a

412
00:26:01,988 --> 00:26:05,506
tiny little piece of code. And such a big problem when it

413
00:26:05,528 --> 00:26:09,858
got removed from a public repository. Now here's another one.

414
00:26:10,024 --> 00:26:13,694
I am a docker captain,

415
00:26:13,742 --> 00:26:17,106
so I deal a lot with containers, but I

416
00:26:17,128 --> 00:26:20,694
do remember back when I was first learning how containers are built

417
00:26:20,732 --> 00:26:24,246
and combing through Docker files. There were a lot of issues that

418
00:26:24,268 --> 00:26:27,842
I didn't understand. I didn't know what was going on under the covers.

419
00:26:27,906 --> 00:26:31,622
And this file, this is very contrived file, but something

420
00:26:31,676 --> 00:26:35,206
you might find when you're looking for examples of how to write a Docker

421
00:26:35,238 --> 00:26:37,626
file. And there's just a couple of things that I'm going to point out here.

422
00:26:37,648 --> 00:26:41,066
I won't go through everything, but just a couple. So the first line, first of

423
00:26:41,088 --> 00:26:44,206
all, a lot of docker images rely on

424
00:26:44,228 --> 00:26:47,934
base images. Where are these base images coming from? Think about that.

425
00:26:48,052 --> 00:26:51,950
They by default are coming from Docker hub unless you are explicitly

426
00:26:52,390 --> 00:26:56,130
asking for it from another registry. So make sure you understand

427
00:26:56,200 --> 00:26:59,954
where your base images are coming from. There's a lot out there.

428
00:26:59,992 --> 00:27:03,554
There's a lot that

429
00:27:03,672 --> 00:27:07,314
are trusted, that are well maintained, so make

430
00:27:07,352 --> 00:27:10,662
sure that you're using those. Also, there's no tag or

431
00:27:10,716 --> 00:27:14,374
Shaw identifier. So I would argue that even a tag isn't enough to

432
00:27:14,412 --> 00:27:18,294
actually pin an exact version because it's more of a pointer than

433
00:27:18,332 --> 00:27:21,766
anything. It can be overwritten, a tag itself can be overwritten,

434
00:27:21,798 --> 00:27:25,382
and you might get something completely different than what you were expecting.

435
00:27:25,526 --> 00:27:29,430
We see this a lot with when you rely on latest, you'll get the latest

436
00:27:29,510 --> 00:27:33,258
of the image. Sometimes that's appropriate, like if

437
00:27:33,264 --> 00:27:35,918
you're in an R and D environment or something, you always want to get the

438
00:27:35,924 --> 00:27:38,698
latest build. But in other times in production,

439
00:27:38,794 --> 00:27:42,446
I wouldn't rely on latest. I would pin that version down to make

440
00:27:42,468 --> 00:27:46,226
sure you don't get any surprises. All right, another one.

441
00:27:46,408 --> 00:27:50,478
Lines two through four. So these are packages that are updating

442
00:27:50,654 --> 00:27:53,874
packages in the base image. And you can see some

443
00:27:53,912 --> 00:27:57,198
don't have line three. There's no

444
00:27:57,224 --> 00:28:00,502
version number at all. Line four is a particularly old

445
00:28:00,556 --> 00:28:03,798
version. It could be bad. It could have a vulnerability in it.

446
00:28:03,964 --> 00:28:07,574
I see people discover this most often when a new

447
00:28:07,612 --> 00:28:11,306
developer joins the team and they are building this from scratch on

448
00:28:11,328 --> 00:28:14,954
their fresh environment. They don't have the

449
00:28:15,072 --> 00:28:18,762
advantages of having a full cache already. And so they might come into

450
00:28:18,816 --> 00:28:22,014
a lot of different problems where some of these packages are coming in that are

451
00:28:22,052 --> 00:28:24,574
not the same as what everyone else has.

452
00:28:24,772 --> 00:28:29,198
So good to pin those versions down. What else next?

453
00:28:29,284 --> 00:28:32,878
Oh, line seven. So, referring to external

454
00:28:32,894 --> 00:28:36,946
resources, this is just a curl script. There was a situation

455
00:28:37,048 --> 00:28:41,090
I once had where our team needed

456
00:28:41,240 --> 00:28:44,946
a proprietary piece of software installed, and so we

457
00:28:44,968 --> 00:28:48,738
did exactly this. We got those shell script that was provided

458
00:28:48,754 --> 00:28:51,880
by the company, brought it in, ran it. Well,

459
00:28:52,410 --> 00:28:55,606
what happened was it worked fine for

460
00:28:55,628 --> 00:28:59,350
a while, but then that company decided to move it or change it.

461
00:28:59,500 --> 00:29:02,726
The first thing that happened was it was changed to an incompatible version. Well,

462
00:29:02,748 --> 00:29:05,866
obviously that wasn't going to work for us. Next it moved to

463
00:29:05,888 --> 00:29:09,338
a completely different location. So each of those times we had broken builds and

464
00:29:09,344 --> 00:29:12,854
we had to figure out what it was. So rather than rely on an external

465
00:29:12,902 --> 00:29:16,174
resource like this, the best thing you can do is to bring it in to

466
00:29:16,212 --> 00:29:20,094
your internal environment and manage it there. Make sure that updates you

467
00:29:20,132 --> 00:29:24,034
have control of when it's updated or when it's moved, rather than trying

468
00:29:24,072 --> 00:29:26,980
to coordinate with an external source like that.

469
00:29:27,510 --> 00:29:30,926
Lastly, number nine, images running as a root.

470
00:29:31,118 --> 00:29:34,530
This is big. I feel bad sometimes

471
00:29:34,600 --> 00:29:37,654
about saying that. It seems like an obvious thing now, it's talked about a lot

472
00:29:37,692 --> 00:29:41,560
not to run images of root, always make sure that you

473
00:29:42,090 --> 00:29:46,066
pay attention to obeying

474
00:29:46,098 --> 00:29:49,462
that policy of least privilege. But even

475
00:29:49,516 --> 00:29:52,954
in 2022, cystic puts out this report every year.

476
00:29:53,072 --> 00:29:56,426
This cloud native security and usage report, they discovered that out

477
00:29:56,448 --> 00:29:59,946
of 3 million containers they were observing, 76% of them were run

478
00:29:59,968 --> 00:30:03,970
as root. Now sometimes that's legitimate,

479
00:30:04,070 --> 00:30:07,550
but the important thing to know here is make sure you know

480
00:30:07,620 --> 00:30:11,502
why you're running as root. If you're just doing it by default, probably not

481
00:30:11,556 --> 00:30:15,134
a good situation to be in. I'm going to hammer on this a little more

482
00:30:15,172 --> 00:30:18,466
because there's a more recent report that just came out and we're not getting better

483
00:30:18,488 --> 00:30:21,906
at this, we're getting worse. There's now 83%. This was out

484
00:30:21,928 --> 00:30:25,394
of 7 million containers that were being observed, 83% of

485
00:30:25,432 --> 00:30:29,158
these containers were running as root. So lots of problems.

486
00:30:29,324 --> 00:30:33,206
Is there any hope? Let's talk about some solutions, some things that we

487
00:30:33,228 --> 00:30:36,914
can put in actual actionable

488
00:30:36,962 --> 00:30:39,894
items where we can improve our situation here.

489
00:30:40,092 --> 00:30:43,706
First thing, educate ourselves. I'm going to hammer on

490
00:30:43,728 --> 00:30:46,522
this a lot. I know that developers are already,

491
00:30:46,656 --> 00:30:49,434
we have a full plate, there's already a lot that we need to know.

492
00:30:49,552 --> 00:30:53,646
But as developers, we also understand that this is a career where you're constantly learning,

493
00:30:53,748 --> 00:30:57,674
things are constantly changing, you constantly need to keep up. So adding

494
00:30:57,722 --> 00:31:01,566
things to your toolbox, around security, extremely important.

495
00:31:01,748 --> 00:31:05,794
No one is ever going to know everything at

496
00:31:05,832 --> 00:31:09,890
first. So it's important to have a combination of teams where you have more senior

497
00:31:11,030 --> 00:31:13,250
folks on the team as well as juniors.

498
00:31:14,230 --> 00:31:17,794
It can be very difficult if all you have are juniors on your team.

499
00:31:17,992 --> 00:31:21,682
We really do need to work on mentorship and making sure that we're

500
00:31:21,826 --> 00:31:25,142
guiding the next generation up so that we don't fall

501
00:31:25,196 --> 00:31:28,786
into the same old traps over and over again. Some ideas

502
00:31:28,818 --> 00:31:32,730
for education I brought this up earlier in the talk. OWAsp resources.

503
00:31:33,070 --> 00:31:36,506
They have some cheat sheets out there on their website. There's a QR code for

504
00:31:36,528 --> 00:31:40,186
you here. All kinds of stuff that

505
00:31:40,208 --> 00:31:44,126
you can learn. All the things I mentioned earlier that

506
00:31:44,148 --> 00:31:47,866
I learned through a third party, things like cross site scripting, SQL injection,

507
00:31:47,898 --> 00:31:51,514
they go through all of these things. Very detailed section

508
00:31:51,562 --> 00:31:55,360
on containers too, and environments for those. So always

509
00:31:56,230 --> 00:31:59,854
very good references here for developers

510
00:31:59,902 --> 00:32:03,790
to take advantage of. Another one. The OpensSF

511
00:32:03,870 --> 00:32:06,850
organization has a trio of free courses.

512
00:32:07,430 --> 00:32:10,642
These three are part of the secure software development fundamentals

513
00:32:10,706 --> 00:32:14,230
professional certificate program. So if you pay some money,

514
00:32:14,300 --> 00:32:17,670
you can actually get a certificate for taking these courses, but they also provide

515
00:32:17,740 --> 00:32:20,646
them for you to audit. You can audit these for free.

516
00:32:20,828 --> 00:32:23,642
All of them are available on those EDX platform.

517
00:32:23,776 --> 00:32:27,098
So another easy resource for you to take advantage of.

518
00:32:27,264 --> 00:32:30,646
All right, I'm going to go through the rest of these pretty quickly. Don't rely

519
00:32:30,678 --> 00:32:34,638
solely on public repos. Remember the left pad incident that I talked about?

520
00:32:34,724 --> 00:32:38,526
That's one reason I'm not going to say public repos are

521
00:32:38,548 --> 00:32:42,362
bad to use. Obviously they're valuable. You need them to get the initial packages

522
00:32:42,426 --> 00:32:46,254
that you need, right? And that's our location for where developers

523
00:32:46,302 --> 00:32:50,654
can share open source software. Just make sure that you save every artifact

524
00:32:50,702 --> 00:32:54,046
that you need for your builds in a local artifact management

525
00:32:54,078 --> 00:32:58,054
system, something that you have control over, that you can manage and

526
00:32:58,092 --> 00:33:01,666
take inventory on. And there's

527
00:33:01,698 --> 00:33:06,098
lots of tools out there. Obviously, my employer is JFrog. I could recommend artifactory,

528
00:33:06,194 --> 00:33:09,606
but there are other tools available out there that you can start with that

529
00:33:09,628 --> 00:33:13,546
are open source. Even. The important point here is just to have one.

530
00:33:13,648 --> 00:33:17,254
Make sure that you're keeping track of your dependencies so that you don't have broken

531
00:33:17,302 --> 00:33:21,334
builds for unknown reasons. All right, manage your dependencies

532
00:33:21,462 --> 00:33:23,934
again, I recommend an artifact management system.

533
00:33:24,052 --> 00:33:27,946
Any, just have one. But make sure that you specify explicit

534
00:33:27,978 --> 00:33:31,518
versions in your software so you know exactly what packages that you

535
00:33:31,524 --> 00:33:34,994
are getting. And in the cases of docker images using

536
00:33:35,032 --> 00:33:38,334
a Shaw, some of your NPM packages using a Shaw

537
00:33:38,382 --> 00:33:41,700
is appropriate. So make sure that you're doing this.

538
00:33:42,150 --> 00:33:45,880
Manage permissions so important. This is

539
00:33:46,250 --> 00:33:49,910
probably more controlled under an ops environment,

540
00:33:50,250 --> 00:33:53,762
but developers need to pay attention to this. Two, they need to enforce

541
00:33:53,826 --> 00:33:57,186
least privilege access. That requires

542
00:33:57,218 --> 00:34:00,854
an understanding of which permissions are actually needed that

543
00:34:00,892 --> 00:34:04,726
are actually going to be in use. And that brings me to the latest sysdig

544
00:34:04,758 --> 00:34:08,470
report as well. They pointed out that 90% of granted permissions

545
00:34:08,550 --> 00:34:12,074
are not even used. This is dangerous. It can set yourself up for

546
00:34:12,112 --> 00:34:16,426
not only malicious activity, but it can set yourself up for some serious accidents.

547
00:34:16,618 --> 00:34:19,886
Not a good thing to go through, especially as a junior developer if you

548
00:34:19,908 --> 00:34:24,318
accidentally wipe out your production database, for example. So these are things that

549
00:34:24,484 --> 00:34:27,666
we need to be paying attention to. Okay? Managing your

550
00:34:27,688 --> 00:34:31,694
dependencies, your permissions. That's not enough. You need to regularly scan your libraries

551
00:34:31,742 --> 00:34:34,978
and packages. It's not a one and done thing to say, oh, I brought in

552
00:34:34,984 --> 00:34:38,110
this package. It's good. I've got it stored locally. This is what I'm going to

553
00:34:38,120 --> 00:34:41,398
use forever and ever. Things come out all of the time.

554
00:34:41,484 --> 00:34:44,854
New vulnerabilities are discovered all of the time. So it's important

555
00:34:44,892 --> 00:34:48,842
to stay up with the latest. Make sure that you're regularly scanning them

556
00:34:48,896 --> 00:34:52,554
so that you discover them to begin with and have a

557
00:34:52,592 --> 00:34:57,354
process where your developers can fix those issues and

558
00:34:57,392 --> 00:35:00,406
that involves keeping up with maintenance. So not

559
00:35:00,448 --> 00:35:04,394
only your packages need to be updated periodically, reviewed periodically,

560
00:35:04,522 --> 00:35:08,314
but your systems, the environments that your software

561
00:35:08,362 --> 00:35:11,402
runs in. They also need to be updated regularly.

562
00:35:11,546 --> 00:35:15,166
Don't let things get stale. And lastly, make sure you

563
00:35:15,188 --> 00:35:18,098
have a plan in place for when it comes time to dealing with a security

564
00:35:18,184 --> 00:35:21,986
threat in production. Because it will happen. It will. It's important to

565
00:35:22,008 --> 00:35:25,826
have a plan that makes sense where you can efficiently and quickly

566
00:35:25,928 --> 00:35:29,874
mitigate the problems so you don't have a huge delay between discovering

567
00:35:29,922 --> 00:35:33,542
a vulnerability and then mitigating it with a patch. So having

568
00:35:33,596 --> 00:35:37,110
those automated systems in place, having CI in place,

569
00:35:37,260 --> 00:35:41,606
having automatic scanning in place, and then also being able to

570
00:35:41,788 --> 00:35:45,734
deploy a new version, making sure that that process is

571
00:35:45,772 --> 00:35:49,014
as clean as possible. So that's all I have

572
00:35:49,052 --> 00:35:52,640
for you. If you have any questions, feel free to reach out for me,

573
00:35:53,730 --> 00:35:57,098
both on Twitter or LinkedIn. I'm available in both places.

574
00:35:57,194 --> 00:36:00,606
And just remember that there's always something new to be learned as

575
00:36:00,628 --> 00:36:03,966
a developer. We all go through that process and these are

576
00:36:03,988 --> 00:36:07,642
just more tools and more awareness in your toolbox

577
00:36:07,706 --> 00:36:11,242
as a developer to make your projects

578
00:36:11,306 --> 00:36:13,900
more secure. Thank you.

