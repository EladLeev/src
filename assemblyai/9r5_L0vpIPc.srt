1
00:00:27,570 --> 00:00:30,834
Let me first introduce myself. My name is Denys Makogon.

2
00:00:30,882 --> 00:00:34,598
I'm a principal member of technical staff, a member of Java platform

3
00:00:34,684 --> 00:00:37,938
group who's responsible for Java development at Oracle.

4
00:00:38,034 --> 00:00:41,414
So as many of you, I'm a software engineer, meaning I

5
00:00:41,452 --> 00:00:44,694
write code for a living alongside with my work. On my spare time,

6
00:00:44,732 --> 00:00:48,966
I do the landscape photography as a hobby. People on the Internet call me

7
00:00:49,068 --> 00:00:52,414
some kind of a pro level landscaper, maybe because one

8
00:00:52,452 --> 00:00:56,222
of my photos won very prestige awards and the latest one is

9
00:00:56,276 --> 00:00:59,642
the best photo of 2019 for bloody annual pilot whale

10
00:00:59,706 --> 00:01:03,486
massacre at the Faroe Islands. Maybe that's why. So what's

11
00:01:03,518 --> 00:01:07,250
this all about? You're here to listen a quite interesting story

12
00:01:07,320 --> 00:01:10,510
of how mybo's skill sets in software development

13
00:01:10,590 --> 00:01:14,450
and professional landscape photography aligned together, and how

14
00:01:14,520 --> 00:01:18,078
such a great collision turned into a great story of the northern

15
00:01:18,094 --> 00:01:21,494
lights hunt it's all started with a very simple question from

16
00:01:21,532 --> 00:01:24,994
a friend of mine. Which country is the best to visit to witness

17
00:01:25,042 --> 00:01:28,806
the northern lights? And I was kinda uncertain to what to tell him, so I

18
00:01:28,828 --> 00:01:32,374
told him the following. Pick the one you like the most. Go to Alaska.

19
00:01:32,422 --> 00:01:35,990
Go to Swalbard, Iceland, Norway, Finland, Canada,

20
00:01:36,070 --> 00:01:40,234
Sweden and Greenland, or north of Scotland and Faroe islands or

21
00:01:40,272 --> 00:01:43,646
Shetland islands. If you haven't been to any of those, pick the

22
00:01:43,668 --> 00:01:46,986
one upon your budget. But it made me think about the neural

23
00:01:47,018 --> 00:01:50,782
lights as a phenomena that can be described by numbers from the

24
00:01:50,836 --> 00:01:53,886
point of view of physics. The fact of the neural lights presence in

25
00:01:53,908 --> 00:01:57,854
the sky is a coincidence of multiple factors. The neural lights

26
00:01:57,902 --> 00:02:00,974
phenomenon, a lovely dancing color waves in the sky,

27
00:02:01,022 --> 00:02:04,558
is something that can be described as a set of measures.

28
00:02:04,654 --> 00:02:08,806
I ask myself whether I can answer a friend's question in

29
00:02:08,828 --> 00:02:12,102
a manner of software engineer with a certain background in data

30
00:02:12,156 --> 00:02:15,702
analysis. And from that moment, the answer to this

31
00:02:15,756 --> 00:02:19,498
question, which country to visit, was nothing but the

32
00:02:19,584 --> 00:02:23,114
ideal state of a system defined by a set of

33
00:02:23,152 --> 00:02:26,630
measures and expectations that can be combined

34
00:02:26,710 --> 00:02:30,106
into a set of mass equation and the

35
00:02:30,128 --> 00:02:33,566
result would be the exact place to go. So I

36
00:02:33,588 --> 00:02:37,262
decided to write a theory, but haven't been doing so since

37
00:02:37,316 --> 00:02:41,134
the university. So sorry on that. As you see, the study is all

38
00:02:41,172 --> 00:02:44,938
about matching the data by certain criteria,

39
00:02:45,034 --> 00:02:49,086
doing math, and a bit of assumption based on the years of northern

40
00:02:49,118 --> 00:02:52,606
Lights observation. In 2019, the idea of northern lights

41
00:02:52,638 --> 00:02:56,386
was born. It's a great attempt to give an answer in

42
00:02:56,408 --> 00:03:00,326
the simplest form consumable by nontech people, because the

43
00:03:00,348 --> 00:03:03,606
whole theory of the northern lights is quite complex and

44
00:03:03,628 --> 00:03:06,802
you need to know a lot about our sun, earth,

45
00:03:06,866 --> 00:03:10,778
magnetic fields and a bit of electromagnetics in general.

46
00:03:10,944 --> 00:03:14,300
I don't want to waste your time on how all of this works

47
00:03:15,390 --> 00:03:19,194
and what the exact algorithm is. You can read bit by yourself,

48
00:03:19,312 --> 00:03:23,162
but I'd like to highlight some key aspects of it. But before we'll go

49
00:03:23,216 --> 00:03:26,734
and do the deep dive into technical aspects, I'd like to

50
00:03:26,772 --> 00:03:30,458
acknowledge two organizations. First is a dark sky

51
00:03:30,634 --> 00:03:34,874
weather service who provides a very great structured historical

52
00:03:34,922 --> 00:03:38,686
weather forecast. And also I'd like to acknowledge the

53
00:03:38,708 --> 00:03:42,082
home hall center of podesdam who provided the data

54
00:03:42,136 --> 00:03:46,082
set with the solar activity and magnetic fields yearly. The visibility

55
00:03:46,146 --> 00:03:50,082
of northern lights is very dependent on when season matters,

56
00:03:50,146 --> 00:03:53,830
where far north or far south, and what

57
00:03:53,900 --> 00:03:58,706
are the weather conditions. These are three things that we're

58
00:03:58,738 --> 00:04:02,614
not in control of, but as an engineers we do make decisions

59
00:04:02,662 --> 00:04:05,898
which technology to use to accomplish our tasks in

60
00:04:05,904 --> 00:04:08,954
the most comfortable way. The terms comfortable is

61
00:04:08,992 --> 00:04:13,102
kind of tricky here as it actually declares a set of demands to the technology

62
00:04:13,236 --> 00:04:16,794
and it has to comply on 100% rather than just go above

63
00:04:16,842 --> 00:04:21,242
some abstract desired threshold. So let's speak about those requirements.

64
00:04:21,386 --> 00:04:24,958
The technology must be comfortable enough to work with sequences

65
00:04:25,054 --> 00:04:28,782
in the case study, each country is represented by a set of GPS

66
00:04:28,846 --> 00:04:32,274
locations, nine or more. Each GPS location is

67
00:04:32,312 --> 00:04:35,978
described by eight daily measures. Each daily measure described

68
00:04:36,014 --> 00:04:39,734
by an hourly weather forecast during autumn, winter and

69
00:04:39,772 --> 00:04:43,078
spring seasons within like 226 days.

70
00:04:43,164 --> 00:04:46,642
Bit means we have 3000 measures at minimum

71
00:04:46,706 --> 00:04:49,962
per single location. So the amount of data, even for a

72
00:04:50,016 --> 00:04:53,130
single country is quite big. Alongside with

73
00:04:53,200 --> 00:04:56,822
sequences we have pipelines. Ability to build reusable

74
00:04:56,886 --> 00:05:00,026
data pipelines is quite critical feature as the

75
00:05:00,048 --> 00:05:03,622
whole problem solving algorithm is a set of sequence

76
00:05:03,686 --> 00:05:07,302
perceptrons that process multiple point connected

77
00:05:07,366 --> 00:05:11,166
data sets from the dark sky and homehold center into a

78
00:05:11,188 --> 00:05:14,646
compressed joint. Country based statistics

79
00:05:14,778 --> 00:05:17,982
since the case study is some sort of a yearly challenge,

80
00:05:18,046 --> 00:05:21,566
the technology must be capable to run perceptrons

81
00:05:21,598 --> 00:05:25,406
in parallel. The good thing is that the data is quite effectively

82
00:05:25,438 --> 00:05:28,902
splittable because at most of the times the data points

83
00:05:28,956 --> 00:05:32,322
are not dependent and can be executed in parallel.

84
00:05:32,386 --> 00:05:35,842
Technically speaking, each country can have its own pipeline

85
00:05:35,906 --> 00:05:39,466
that must be capable to be paralleled to run perceptions for

86
00:05:39,488 --> 00:05:42,986
each gps location for each weather forecast on the

87
00:05:43,008 --> 00:05:46,934
location within nightly hours through the autumn, winter spring

88
00:05:46,982 --> 00:05:50,406
seasons. So as you can see, all of this can be

89
00:05:50,448 --> 00:05:54,110
performed in parallel and this is very critical for the case study

90
00:05:54,180 --> 00:05:58,458
to make it go really fast. Both Homehonter

91
00:05:58,554 --> 00:06:02,442
and Darksky providing their data through the API's

92
00:06:02,506 --> 00:06:06,146
endpoint HTTP rest in particular. So in

93
00:06:06,168 --> 00:06:09,726
the context of parallel pipelines, it's very important to reduce

94
00:06:09,758 --> 00:06:13,506
the time on blocking HTTP calls ideally with some

95
00:06:13,528 --> 00:06:16,990
kind of a nonblocking technique. As for software engineer,

96
00:06:17,070 --> 00:06:20,486
type system of a programming language is quite important bit in

97
00:06:20,508 --> 00:06:23,942
the case study type system is not very critical but still

98
00:06:23,996 --> 00:06:27,074
quite important as there are some data types that require

99
00:06:27,122 --> 00:06:30,486
additional manipulations. So all I wanted to see is the

100
00:06:30,508 --> 00:06:33,946
same APIs to work with because I don't really want to pull out the

101
00:06:33,968 --> 00:06:37,226
hair of my head because something is not supported, require me

102
00:06:37,248 --> 00:06:40,526
to write a ton of a code to get a simple value that I

103
00:06:40,548 --> 00:06:44,526
can work with and the winning technology for me is

104
00:06:44,708 --> 00:06:47,978
yeah, Java. Java for data science.

105
00:06:48,074 --> 00:06:51,886
Don't say you're surprised, aren't you? There are multiple whys and

106
00:06:51,908 --> 00:06:55,842
I'm gonna list out some of them that I found critical for

107
00:06:55,896 --> 00:06:59,358
such tasks. One of the greatest things that happened to Java

108
00:06:59,374 --> 00:07:02,878
collection framework was the introduction of streams API.

109
00:07:02,974 --> 00:07:06,466
First iteration of streams were introduced in JDK

110
00:07:06,578 --> 00:07:10,086
eight release as per docs. Essentially streams are

111
00:07:10,188 --> 00:07:14,034
classes to support functional style operations on streams of elements

112
00:07:14,162 --> 00:07:17,602
such as Mapreduce transformation on collections.

113
00:07:17,666 --> 00:07:21,218
Well, it may sound a bit complex true, but on a practice it's

114
00:07:21,234 --> 00:07:24,938
fairly easy to understand. The JDK doc says about

115
00:07:25,024 --> 00:07:28,682
presence of intermediate and terminal operations which

116
00:07:28,736 --> 00:07:32,442
are combined into a form of a pipeline that contain a source

117
00:07:32,506 --> 00:07:35,946
followed by intermediate step and a terminal state operation.

118
00:07:36,058 --> 00:07:39,902
Worth saying that all intermediate operations against streams are lazy ones,

119
00:07:39,956 --> 00:07:43,950
meaning they wouldn't execute unless the terminal operation is declared.

120
00:07:44,030 --> 00:07:47,646
Here are a few examples of intermediate and terminal operations

121
00:07:47,758 --> 00:07:51,186
in the case study. Streams used as a

122
00:07:51,208 --> 00:07:55,378
pipeline of a set of intermediate operations like

123
00:07:55,464 --> 00:07:59,106
providing the mapping of three hour frames for highest

124
00:07:59,138 --> 00:08:03,074
magnetic field disturbance. But essentially they are used to do effective

125
00:08:03,122 --> 00:08:06,630
and fast filtering, doing some data processing. So basically

126
00:08:06,700 --> 00:08:10,502
some both I O and CPU bound operations.

127
00:08:10,646 --> 00:08:14,650
No doubt streams are really cool, I totally agree with that,

128
00:08:14,720 --> 00:08:18,506
but that's not all streams API also utilizes common

129
00:08:18,608 --> 00:08:21,738
fork join pool to run processing units against

130
00:08:21,824 --> 00:08:25,230
a number of threads in a pool. So no matter what you do,

131
00:08:25,300 --> 00:08:29,166
as long as the data can be effectively distributed with a

132
00:08:29,188 --> 00:08:32,558
parallel stream, the workload could be divided within

133
00:08:32,644 --> 00:08:36,078
a consumable amount of threads that potentially

134
00:08:36,174 --> 00:08:39,582
can give you a boost in the performance. No doubt

135
00:08:39,646 --> 00:08:42,754
streams are cool, but that's not all, as the JVM can

136
00:08:42,792 --> 00:08:46,894
run multiple threads, stream can do that either. Stream's API utilizes

137
00:08:46,942 --> 00:08:50,686
common fork join pool to run operations against a number of threads

138
00:08:50,718 --> 00:08:54,006
in the pool. So no matter what you do, as long as the data in

139
00:08:54,028 --> 00:08:57,394
your collection can be effectively distributed with a parallel stream,

140
00:08:57,442 --> 00:09:01,394
the workload against it could be divided within a configurable amount

141
00:09:01,452 --> 00:09:05,110
of threads that potentially can give you a boost in a performance.

142
00:09:05,190 --> 00:09:08,858
To understand how the runtime executes the parallel streams, I highly recommend

143
00:09:08,944 --> 00:09:12,522
you to look at the source code of the JDK. But there are two ways

144
00:09:12,576 --> 00:09:15,994
to define the forkjoin pool for a streams API,

145
00:09:16,042 --> 00:09:20,042
there are two possible scenarios where the pool can come from a common pool,

146
00:09:20,106 --> 00:09:24,398
the one that is provisioned by the runtime with a customizable parallelism

147
00:09:24,494 --> 00:09:28,130
level defined by a number less by one of the available

148
00:09:28,200 --> 00:09:31,422
cpus on a machine or a custom fork. Join pool,

149
00:09:31,486 --> 00:09:35,098
a developer defined pool with a customizable parallelism

150
00:09:35,214 --> 00:09:38,966
value that basically defines the number of threads in a

151
00:09:38,988 --> 00:09:42,694
pool. Running streams in parallel is totally fun. However,

152
00:09:42,812 --> 00:09:46,646
streams executes in parallel, and the runtime partitions the

153
00:09:46,668 --> 00:09:50,182
streams into multiple substreams. Aggregate operations

154
00:09:50,326 --> 00:09:53,866
iterate over the process of these substreams in

155
00:09:53,888 --> 00:09:57,770
parallel and then combine the result. So these operations could

156
00:09:57,840 --> 00:10:01,134
actually be quite expensive. But the trick here is that

157
00:10:01,172 --> 00:10:04,442
parallel streams may not serve its purpose most effectively,

158
00:10:04,506 --> 00:10:08,362
and there is a reason for that. While aggregate operations enable

159
00:10:08,426 --> 00:10:11,806
you more easily implement parallelism, it's still the

160
00:10:11,828 --> 00:10:15,582
developer responsibility to determine if the application is suitable

161
00:10:15,646 --> 00:10:19,522
for parallelism. We all know that runtime is fast.

162
00:10:19,656 --> 00:10:23,106
The only slow thing is your code, and the effectiveness of

163
00:10:23,128 --> 00:10:27,042
the parallel execution can be expressed in a pretty simple

164
00:10:27,176 --> 00:10:30,674
way. As long as the computational cost of a single item

165
00:10:30,722 --> 00:10:34,066
processing through the whole data set is higher than the overall

166
00:10:34,098 --> 00:10:38,034
infrastructure provisioning overhead, and the data set is effectively splittable,

167
00:10:38,082 --> 00:10:42,342
then a data set processing should be considered to be executed in parallel.

168
00:10:42,406 --> 00:10:45,914
Let me explain this. If the operation is so simple and the

169
00:10:45,952 --> 00:10:50,326
execution cost is lower than the overhead of a thread provisioning

170
00:10:50,518 --> 00:10:54,286
the thread provisioning, then the data set must be very big in order

171
00:10:54,308 --> 00:10:57,806
to make the parallel processing worthless. It works in the

172
00:10:57,828 --> 00:11:01,274
other way as well. If the computational cost of a single item

173
00:11:01,322 --> 00:11:05,022
processing is higher and the data set is effectively splittable,

174
00:11:05,086 --> 00:11:08,866
then the size of a data set may not matter in order to make the

175
00:11:08,888 --> 00:11:12,210
parallel execution worthless. As we all know,

176
00:11:12,280 --> 00:11:15,326
the most affectionately splittable collections include

177
00:11:15,358 --> 00:11:19,362
array lights and hashmap. Data structures tend to be effectively splittable

178
00:11:19,426 --> 00:11:23,238
if they internally support random access, efficient search,

179
00:11:23,324 --> 00:11:27,094
or both. On the other side, if it takes longer to partition the

180
00:11:27,132 --> 00:11:30,598
data than process it, then the effort is kind of wasted.

181
00:11:30,694 --> 00:11:34,266
So as you can see, streams could be very efficient in terms of

182
00:11:34,288 --> 00:11:37,994
threading. But what about memory footprint? A stream itself

183
00:11:38,112 --> 00:11:41,434
just stores its own metadata, it doesn't store anything about

184
00:11:41,472 --> 00:11:44,874
the collection. The only moment when your application starts gaining

185
00:11:44,922 --> 00:11:48,446
in memory because of overstream is when a stream turns into a

186
00:11:48,468 --> 00:11:52,426
collection through the terminal operation. So what we already covered

187
00:11:52,458 --> 00:11:56,010
here we have that streams are efficient in terms of memory.

188
00:11:56,090 --> 00:11:59,774
They can do things in parallel, but still relies on Java threads

189
00:11:59,822 --> 00:12:02,994
that are pretty heavy, and we all know about that. So is

190
00:12:03,032 --> 00:12:06,998
there a way to improve threading in Java? And the answer is

191
00:12:07,084 --> 00:12:10,966
yes. OpengDK project Loom intends to eliminate the

192
00:12:10,988 --> 00:12:15,014
frustration trade off between efficiently running concurrent programs and

193
00:12:15,052 --> 00:12:18,486
efficiently writing, maintaining and observing them. It leans

194
00:12:18,518 --> 00:12:21,642
into strengths of the platform rather than fight them,

195
00:12:21,696 --> 00:12:25,334
and also into strengths of efficient components

196
00:12:25,382 --> 00:12:29,094
of asynchronous programming. Project Loom lets you write programs

197
00:12:29,142 --> 00:12:32,406
in a familiar style, using familiar APIs in

198
00:12:32,448 --> 00:12:36,446
harmony with the platform in its tools, but also with the hardware to

199
00:12:36,468 --> 00:12:40,430
reach a balance of write time and the runtime codes that we hope

200
00:12:40,500 --> 00:12:43,946
we will widely appealing. It does so without changing

201
00:12:43,978 --> 00:12:47,166
the language. With the only minor changes to the core library's

202
00:12:47,198 --> 00:12:50,946
APIs, a simple synchronous web server will be able to

203
00:12:50,968 --> 00:12:54,594
handle many more requests without requiring more hardware. In terms

204
00:12:54,632 --> 00:12:58,350
of data processing, a new concept of future threads

205
00:12:58,430 --> 00:13:02,170
will make us people who work with data to rethink

206
00:13:02,270 --> 00:13:05,222
stages when we retrieve the data and process bit,

207
00:13:05,276 --> 00:13:08,502
as loom will help us to increase the productivity of

208
00:13:08,556 --> 00:13:12,118
any I O bound tasks by executing more operation

209
00:13:12,214 --> 00:13:16,074
at the same time, because the virtual thread itself and the blocking on

210
00:13:16,112 --> 00:13:20,422
them is pretty cheap. However, with loom, data extractions

211
00:13:20,486 --> 00:13:23,998
should come beforehand. Any cpu bound operations as the

212
00:13:24,004 --> 00:13:27,626
number of actual OS threads used by forkjoin

213
00:13:27,658 --> 00:13:31,242
pool is way smaller than the number of mutual threads.

214
00:13:31,306 --> 00:13:34,542
It means that if you have any IO operations within

215
00:13:34,596 --> 00:13:37,582
your stream and you'd like to process in parallel,

216
00:13:37,646 --> 00:13:41,986
it's highly recommended to extract the data and run to

217
00:13:42,008 --> 00:13:45,566
retrieve the data through loom, but not through Java threads

218
00:13:45,598 --> 00:13:49,234
that still will remain in Java and will serve its purposes

219
00:13:49,282 --> 00:13:52,946
within loom internally. So going back to other features

220
00:13:52,978 --> 00:13:56,598
that Rkstad required and what I found very important

221
00:13:56,684 --> 00:13:59,942
in Java is a new HTTP API framework.

222
00:14:00,006 --> 00:14:03,834
A new HTTP client incubated in GDK nine will and

223
00:14:03,872 --> 00:14:07,126
fully released in GDK eleven. A new client provides

224
00:14:07,158 --> 00:14:10,710
asynchronous and asynchronous request mechanics. It also supports

225
00:14:10,790 --> 00:14:14,558
HTTP one one HTTP 20, both in

226
00:14:14,564 --> 00:14:17,866
asynchronous programming long models, handles requests and response

227
00:14:17,898 --> 00:14:21,162
bodies as a reactive streams, and follows the familiar

228
00:14:21,226 --> 00:14:24,686
builder patterns. So why it's very important this

229
00:14:24,708 --> 00:14:28,862
is the optimized number of the HTTP request required

230
00:14:28,926 --> 00:14:32,306
to be obtained to obtain the weather forecast for

231
00:14:32,328 --> 00:14:35,942
the case study. These HTTP calls are performed within the data

232
00:14:35,996 --> 00:14:40,150
processing pipeline, which technically means nearly 55k

233
00:14:40,220 --> 00:14:43,366
possible blockings while waiting for the response from the

234
00:14:43,388 --> 00:14:47,062
resource utilization standpoint, it is unacceptable to have all that

235
00:14:47,116 --> 00:14:50,326
possible time wasted for just idling. In the

236
00:14:50,348 --> 00:14:53,562
case of the GDK HTTP framework, we would no longer

237
00:14:53,616 --> 00:14:57,370
need to write asynchronous code, but just simple synchronous code.

238
00:14:57,440 --> 00:15:00,826
No more async anywhere. Virtual thread scheduler will

239
00:15:00,848 --> 00:15:04,234
handle all the blocking. That is way cheaper than blocking

240
00:15:04,282 --> 00:15:07,726
on the OS threads, but still, a choice of

241
00:15:07,748 --> 00:15:10,922
the back end of threads is a responsibility of a developer.

242
00:15:10,986 --> 00:15:15,050
Would an app will run within virtual or os

243
00:15:15,130 --> 00:15:18,382
threads. You write your own code, then somebody chooses

244
00:15:18,446 --> 00:15:22,222
whether to run the code in a virtual thread or on the OS

245
00:15:22,286 --> 00:15:25,758
thread. Virtual threads are still threads. They are the same construct,

246
00:15:25,854 --> 00:15:29,266
just the runtime that allow you to make more of them. More threads

247
00:15:29,298 --> 00:15:32,886
mean more request execution. Running in parallel would

248
00:15:32,908 --> 00:15:36,530
be a thing. If there is a need to run multiple threads in parallel,

249
00:15:36,610 --> 00:15:39,942
then it's highly recommended to use new virtual thread

250
00:15:40,006 --> 00:15:43,418
executor to do multiple parallel requests with Project

251
00:15:43,504 --> 00:15:47,622
Loom. Let's get to the point when people start talking about data analysis

252
00:15:47,686 --> 00:15:51,674
data science, they mostly talk about tools they've got used

253
00:15:51,712 --> 00:15:54,910
to work with, but Java wasn't one of them,

254
00:15:54,980 --> 00:15:58,634
except those cases when some of the apps written with Java are involved,

255
00:15:58,682 --> 00:16:01,902
like Hadoop, Spark, etc. However, Java is

256
00:16:01,956 --> 00:16:05,674
one of the most powerful tools for concurrent data processing,

257
00:16:05,722 --> 00:16:09,442
so no matter whether the processing would be a CPU bound or

258
00:16:09,576 --> 00:16:12,898
an IO bound, if there is a need to process the data of

259
00:16:12,904 --> 00:16:16,862
the same time of the same nature, it's highly recommended to use parallel streams

260
00:16:16,926 --> 00:16:20,566
because it's like the most comfortable and the most efficient way to process in

261
00:16:20,588 --> 00:16:24,134
the data of the same nature. When it's necessary to retrieve some

262
00:16:24,172 --> 00:16:27,298
data through the I O channels. The new HTTP framework

263
00:16:27,394 --> 00:16:30,874
will do its job at its best by providing necessary features for

264
00:16:30,912 --> 00:16:34,026
both synchronous and asynchronous routing, and also taking into

265
00:16:34,048 --> 00:16:37,274
account project loom that will be released anytime in the future.

266
00:16:37,392 --> 00:16:40,886
That will also improve threading by default within the Java

267
00:16:40,918 --> 00:16:44,414
runtime. Moreover, as I said, things will get

268
00:16:44,452 --> 00:16:47,722
better when we apply project loom against threaded apps,

269
00:16:47,786 --> 00:16:51,150
not just because of a new concept of a virtual thread, but because

270
00:16:51,220 --> 00:16:54,814
of the way we treat threads. Project loom will help to

271
00:16:54,852 --> 00:16:58,374
reduce the overhead of threads for an IO bone operation

272
00:16:58,442 --> 00:17:02,734
that will allow developers to execute more parallel operations, HTTP requests,

273
00:17:02,782 --> 00:17:07,390
in particular for retrieving more data within a reasonable, time consuming,

274
00:17:07,470 --> 00:17:11,506
less sources for me, as for hobbiesist, Java served

275
00:17:11,538 --> 00:17:15,366
a great job with very little effort. It was more complicated to write a

276
00:17:15,388 --> 00:17:19,094
theory and define the data processing pipeline on the paper than code

277
00:17:19,132 --> 00:17:22,806
bit. Java streams played well for data processing. Sync and

278
00:17:22,828 --> 00:17:26,566
a sync HTTP API helped to reduce the time and consume the resources

279
00:17:26,598 --> 00:17:30,774
while working with the data coming from the dark sky APIs or homeholds

280
00:17:30,822 --> 00:17:34,602
center. And also the project loom just skyrocketed the thread performance

281
00:17:34,666 --> 00:17:38,446
and make the whole execution be even more efficient than it

282
00:17:38,468 --> 00:17:41,886
is right now. At this point, you may have a question regarding why

283
00:17:41,908 --> 00:17:45,266
I haven't picked anything like Python that is pitched as the

284
00:17:45,288 --> 00:17:49,106
best tool for data science and the machine learning. Well, the answer would

285
00:17:49,128 --> 00:17:52,942
be the nature of Python. It's technically slow,

286
00:17:53,006 --> 00:17:56,806
the single threaded runtime, and most of the data science and

287
00:17:56,828 --> 00:18:00,582
machine learning code that exists right now is nothing but a

288
00:18:00,636 --> 00:18:04,962
c or c code with a very thin Python wrapper

289
00:18:05,026 --> 00:18:08,534
plus interpreter as a dependency. But Java has

290
00:18:08,572 --> 00:18:12,106
a lot to offer to data science and the data analysis and the

291
00:18:12,128 --> 00:18:16,086
ecosystem of Java is still growing and more tools being developed

292
00:18:16,118 --> 00:18:19,434
and introduced to the community like Tribio, that will

293
00:18:19,472 --> 00:18:23,306
occur in a market share that will occupy its market share of the

294
00:18:23,328 --> 00:18:26,766
specific tool for the machine learning and data science in Java. But there

295
00:18:26,788 --> 00:18:30,030
is no point to bit and wait for that moment. As you can see,

296
00:18:30,100 --> 00:18:33,982
even with JDK only it is possible to do as many

297
00:18:34,036 --> 00:18:37,362
cool things as possible. Just look at what I did just

298
00:18:37,416 --> 00:18:41,202
for fun, going back to the very beginning of where it all

299
00:18:41,256 --> 00:18:44,514
started, to a simple question that my friend asked, what is

300
00:18:44,552 --> 00:18:48,086
the best country to visit to witness the nerd lights? And the

301
00:18:48,108 --> 00:18:51,702
answer is on your screen. But as I said

302
00:18:51,756 --> 00:18:55,766
before, pick the one you like the most and just go there because

303
00:18:55,868 --> 00:18:59,766
traveling right now is very critical for

304
00:18:59,868 --> 00:19:03,174
well being and kind of we're done. Hope you find this

305
00:19:03,212 --> 00:19:06,242
talk interesting, even though it wasn't packed with so many technical

306
00:19:06,306 --> 00:19:09,966
stuff. Anyway, thank you for listening and if you have any questions you can

307
00:19:10,028 --> 00:19:13,530
at me on Twitter and just subscribe to our Twitter

308
00:19:13,610 --> 00:19:17,166
handles. Subscribe to our inside Java blog, which is kind

309
00:19:17,188 --> 00:19:21,194
of cool and is one of the most reading Java blogs on the Internet

310
00:19:21,242 --> 00:19:22,940
right now. Thank you.

