1
00:00:17,450 --> 00:00:20,554
Hi there, my name is Dmitry Kudryavtsev. I'm a senior software

2
00:00:20,602 --> 00:00:24,174
engineer and I'm passionate about two things, JavaScript and

3
00:00:24,212 --> 00:00:28,066
Rust. And so today I want to talk two you how you can supercharge

4
00:00:28,098 --> 00:00:31,234
your nodejs and Javascript experience using Rust.

5
00:00:31,362 --> 00:00:34,598
Wait, what? Javascript? Yes,

6
00:00:34,684 --> 00:00:38,006
I know this is a rust conference, and don't worry, we will get

7
00:00:38,028 --> 00:00:41,594
into rust code in just a minute. But before that, let's talk a little

8
00:00:41,632 --> 00:00:45,002
bit about JavaScript. We can't ignore the fact JavaScript has taken

9
00:00:45,056 --> 00:00:48,410
the world by storm. It's the de facto standard language for

10
00:00:48,480 --> 00:00:52,118
anything HTML related. If you want to make your web pages

11
00:00:52,214 --> 00:00:55,774
dynamic. JavaScript is the only language you can use AWS of today,

12
00:00:55,892 --> 00:00:59,786
and thanks to frameworks like nodeJs, it's becoming increasingly

13
00:00:59,818 --> 00:01:03,838
popular in the backend as well. And there are even tools like Electron

14
00:01:03,934 --> 00:01:07,486
and Tauri, which is written in rust by the way, that allows

15
00:01:07,518 --> 00:01:11,730
you to make so called native desktop applications.

16
00:01:12,070 --> 00:01:16,002
So yes, JavaScript is very popular, and whether you like

17
00:01:16,056 --> 00:01:18,820
it or not, it's probably here to stay.

18
00:01:19,190 --> 00:01:22,902
So aws, you know, as they say, if you can win

19
00:01:22,956 --> 00:01:27,110
them, join them. So JavaScript and Node Js are great,

20
00:01:27,260 --> 00:01:30,586
but they are sometimes slow, for example if you

21
00:01:30,608 --> 00:01:34,746
want to do like cpu bound tasks, maybe image processing or

22
00:01:34,848 --> 00:01:38,442
3d rendering. And luckily there are ways

23
00:01:38,496 --> 00:01:42,206
to speed up JavaScript, especially node JS, with the

24
00:01:42,228 --> 00:01:46,014
use of native modules, which are written mainly in C or C plus

25
00:01:46,052 --> 00:01:50,014
plus or rust. Now you

26
00:01:50,052 --> 00:01:53,522
probably want to ask, why do

27
00:01:53,576 --> 00:01:59,598
we want to use rust? So let's do a little comparison between Rust

28
00:01:59,774 --> 00:02:03,780
and C. Well, C and C,

29
00:02:04,630 --> 00:02:07,666
they are very mature, they're very old languages and they're

30
00:02:07,698 --> 00:02:11,014
showing their edge, so we can't ignore this fact.

31
00:02:11,132 --> 00:02:15,010
Also they lack any modern tooling, so you don't have decent dependency

32
00:02:15,090 --> 00:02:18,886
manager has a relatively poor standard library.

33
00:02:19,078 --> 00:02:22,122
From my memory you almost always

34
00:02:22,176 --> 00:02:26,090
need to include third party libraries like boost if you want to get

35
00:02:26,240 --> 00:02:29,722
fancy iterators or collections, maybe changing the new

36
00:02:29,776 --> 00:02:32,590
C plus plus versions. I don't follow it anymore.

37
00:02:33,250 --> 00:02:36,858
And the biggest problem with those languages

38
00:02:37,034 --> 00:02:40,686
is that they are not memory safe. So you get into Sec votes a

39
00:02:40,708 --> 00:02:44,740
lot. You probably saw this one, but why rust then?

40
00:02:45,110 --> 00:02:47,982
Well it's strongly typed and compiled language,

41
00:02:48,046 --> 00:02:51,774
so it has the same performance

42
00:02:51,822 --> 00:02:56,146
as a native C or C has a rich standard library,

43
00:02:56,338 --> 00:02:59,074
smart pointers, containers, iterators,

44
00:02:59,122 --> 00:03:02,454
mutexes, everything you want for it's there

45
00:03:02,652 --> 00:03:06,354
has modern tooling, so you have cargo for dependency management

46
00:03:06,402 --> 00:03:09,814
and task execution. And the most important thing

47
00:03:09,852 --> 00:03:12,998
is that it's memory safe, so you don't get any SeC votes.

48
00:03:13,094 --> 00:03:16,506
I know youve can write unsafe rust as well, but let's stay in

49
00:03:16,528 --> 00:03:20,426
the safe world of rust. Youve say great, but how

50
00:03:20,528 --> 00:03:23,902
do we do that? So we will look at two different

51
00:03:23,956 --> 00:03:27,486
approaches and we will compare them. And the first approach that I want to

52
00:03:27,508 --> 00:03:30,974
start with is writing native models, especially for

53
00:03:31,012 --> 00:03:34,286
nodejs. So meet Neon. Neon is a

54
00:03:34,388 --> 00:03:37,970
library in the toolchain for embedded rust into JavaScript.

55
00:03:38,310 --> 00:03:42,546
And so we will take a look now at a Fibonacci function

56
00:03:42,728 --> 00:03:46,306
that we can write in pure rust and see how we can use it from

57
00:03:46,328 --> 00:03:49,762
JavaScript. Below is the code. Don't get overwhelmed,

58
00:03:49,826 --> 00:03:52,870
we will go over the code just in a minute. So first

59
00:03:52,940 --> 00:03:56,966
we have our requires like we always do. This is all

60
00:03:56,988 --> 00:04:00,346
the code that we need from neon. You need to understand the

61
00:04:00,368 --> 00:04:04,074
row of neon in this neon is more like a glue layer between

62
00:04:04,112 --> 00:04:08,394
the JavaScript world and the rust world. So we have all

63
00:04:08,432 --> 00:04:12,398
the different types like js numbers and js strings maybe.

64
00:04:12,564 --> 00:04:15,598
So neon provides all this as well.

65
00:04:15,604 --> 00:04:19,370
Aws the context for function execution and model execution.

66
00:04:19,530 --> 00:04:23,666
Then we have our Fibonacci logic, simple recursive fibonacci function,

67
00:04:23,768 --> 00:04:27,406
nothing special in here. And then we have the glue layer. The glue

68
00:04:27,438 --> 00:04:31,202
layer is responsible for converting JavaScript and

69
00:04:31,256 --> 00:04:34,914
rust and vice versa. So if you have like

70
00:04:35,032 --> 00:04:38,898
JavaScript number, which is just a number, and you

71
00:04:38,904 --> 00:04:42,726
want to convert it maybe to an Int 32 bit

72
00:04:42,748 --> 00:04:46,406
or a float. So this is the conversion layer. When you get

73
00:04:46,428 --> 00:04:49,794
a result from rust and you want to pass it back into JavaScript,

74
00:04:49,922 --> 00:04:53,546
this is the glue layer. This is what Neon is doing. And this is the

75
00:04:53,568 --> 00:04:57,306
most important part between connecting the JavaScript and

76
00:04:57,328 --> 00:05:00,766
the rust worlds together. And then we have the main function.

77
00:05:00,868 --> 00:05:04,782
Like all executables we have a main

78
00:05:04,836 --> 00:05:08,702
function. The main function is responsible into exporting all the

79
00:05:08,836 --> 00:05:12,714
functions that we want to access from the JavaScript

80
00:05:12,762 --> 00:05:16,002
world. So in this case we are executing the Fibonacci API function

81
00:05:16,056 --> 00:05:19,346
and we are naming it as Fibonacci Rs in

82
00:05:19,368 --> 00:05:23,346
our JavaScript world. And in just in a minute we will see how

83
00:05:23,368 --> 00:05:27,410
we actually use it in JavaScript. Before importing into JavaScript,

84
00:05:27,490 --> 00:05:30,886
we obviously need to compile rust code into the

85
00:05:30,908 --> 00:05:34,546
native node modules. The neon team maintains

86
00:05:34,658 --> 00:05:39,430
a package called Cargo CP Artifact, which essentially

87
00:05:39,590 --> 00:05:43,894
once you run this command it will produce a dynamic library.

88
00:05:44,022 --> 00:05:47,754
So if you're familiar with dlls from the Windows world or

89
00:05:47,792 --> 00:05:50,958
so files from Unix world.

90
00:05:51,044 --> 00:05:53,870
So this is essentially what it produces,

91
00:05:55,330 --> 00:05:59,146
but it wraps it into the node API

92
00:05:59,258 --> 00:06:01,710
so that it will be accessible from nodejs.

93
00:06:02,450 --> 00:06:06,050
And so in order to access this code from node js.

94
00:06:07,030 --> 00:06:10,574
Don't worry, the code is pretty readable. If you don't know JavaScript,

95
00:06:10,702 --> 00:06:14,954
we just require the Fibonacci Rs from the previous file that we've compiled,

96
00:06:15,102 --> 00:06:17,880
and we simply execute it as a regular function.

97
00:06:18,410 --> 00:06:22,738
So this is one way we can incorporate

98
00:06:22,914 --> 00:06:26,486
rust as a native extension into the

99
00:06:26,508 --> 00:06:30,810
Nodejs world. Now some of you who probably worked with

100
00:06:30,880 --> 00:06:35,110
maybe JavaScript or high performance JavaScript,

101
00:06:35,270 --> 00:06:38,618
you probably heard about WaSm. For those of

102
00:06:38,624 --> 00:06:41,974
you who didn't heard about WaSm, let's talk a little bit about

103
00:06:42,032 --> 00:06:45,178
what is Wasm, which is an abbreviation for webassembly.

104
00:06:45,274 --> 00:06:48,558
So webassembly is a portable binary format, and it's a

105
00:06:48,564 --> 00:06:52,646
corresponding text format. You can think of it as the assembly

106
00:06:52,698 --> 00:06:56,606
language. We have the text format which is the assembly

107
00:06:56,638 --> 00:07:00,334
that you write, and the binary format which is converted

108
00:07:00,382 --> 00:07:03,806
into the specific architecture of your machine,

109
00:07:03,918 --> 00:07:07,586
be it ex 80, 86 or arm

110
00:07:07,698 --> 00:07:11,106
whatever youve running on, it's executing by a virtual machine.

111
00:07:11,218 --> 00:07:15,394
So there is a VM that's doing the translation between the wasm binary

112
00:07:15,442 --> 00:07:19,666
into the actual architecture. It's supported in all major browsers

113
00:07:19,698 --> 00:07:23,626
and nodejs, so the VM is implemented in all the

114
00:07:23,648 --> 00:07:27,462
major browsers as of today, except for Internet Explorer.

115
00:07:27,606 --> 00:07:31,674
And in node js it can be written in a special language

116
00:07:31,722 --> 00:07:34,954
called assembly script. If you're familiar with typescript,

117
00:07:35,082 --> 00:07:39,006
it's a bit similar to the assembly script is a bit similar to

118
00:07:39,028 --> 00:07:42,954
JavaScript, but there are some differences

119
00:07:43,002 --> 00:07:46,914
because webassembly is actually typed. But the

120
00:07:46,952 --> 00:07:50,706
biggest pro, in my opinion, is that

121
00:07:50,808 --> 00:07:54,414
Webassembly is actually a compilation target for other languages.

122
00:07:54,542 --> 00:07:58,390
So we can take other languages and rust among them and actually

123
00:07:58,460 --> 00:08:02,022
compile them into webassembly. In order to do that,

124
00:08:02,076 --> 00:08:05,234
we have another crate called Wassenbindgan.

125
00:08:05,362 --> 00:08:09,046
And let's now look at an example how we can compile a Fibonacci

126
00:08:09,078 --> 00:08:13,354
function using webassembly. It's way simpler than the neon example,

127
00:08:13,472 --> 00:08:17,100
so we only have one macro that is responsible for

128
00:08:17,790 --> 00:08:20,582
converting the code into the webassembly.

129
00:08:20,726 --> 00:08:24,958
It's then compiled with the special output target as

130
00:08:25,044 --> 00:08:28,254
webAssembly. So you get a native webassembly that you can

131
00:08:28,292 --> 00:08:31,070
then load into browser or nodejs.

132
00:08:31,730 --> 00:08:35,410
Now when we have two or more different

133
00:08:35,480 --> 00:08:39,042
tools, the obvious question that you probably ask is that okay,

134
00:08:39,096 --> 00:08:42,610
but what about performance? So let's take a look at

135
00:08:42,680 --> 00:08:45,846
performant. Don't be overwhelmed by the

136
00:08:45,868 --> 00:08:48,950
table and we will go over the numbers here.

137
00:08:49,020 --> 00:08:52,678
As you can see, I've run benchmark with the two code

138
00:08:52,764 --> 00:08:56,182
hyperfine and I try to compute different

139
00:08:56,236 --> 00:08:59,546
Fibonacci numbers. The thing with recursive Fibonacci is

140
00:08:59,568 --> 00:09:02,742
that the higher you go with the numbers, the more intensive

141
00:09:02,806 --> 00:09:06,300
the computation becomes, because it's a recursive function

142
00:09:07,310 --> 00:09:10,010
and it relies on the previous computations.

143
00:09:10,350 --> 00:09:13,834
So you can see that the 30th Fibonacci number is relatively

144
00:09:13,882 --> 00:09:17,642
fast in all the tree. Actually, you can see that JavaScript is managing

145
00:09:17,706 --> 00:09:21,642
pretty good, although native rust is the fastest

146
00:09:21,706 --> 00:09:25,402
and wasn't being the second. The changes

147
00:09:25,476 --> 00:09:28,786
are not that important. By the way, the green numbers you

148
00:09:28,808 --> 00:09:32,770
can see is the performance increase you get from the base nodejs.

149
00:09:33,590 --> 00:09:37,126
But then as we look at higher numbers such as the 44th or

150
00:09:37,148 --> 00:09:40,834
the 35th Fibonacci numbers, we can see that JavaScript

151
00:09:40,882 --> 00:09:43,640
is becoming two struggle really much.

152
00:09:44,090 --> 00:09:47,990
While native rust is the performance is increasing,

153
00:09:49,130 --> 00:09:52,586
the latency, the time that it takes to compute is increasing as well.

154
00:09:52,688 --> 00:09:56,182
But you can see that also it's way, way faster,

155
00:09:56,246 --> 00:09:59,494
in some instances around 60% faster

156
00:09:59,542 --> 00:10:02,750
than the JavaScript solution.

157
00:10:03,490 --> 00:10:07,070
And same can be said about the webassembly version which

158
00:10:07,140 --> 00:10:10,506
was compiled from Rust. We can see that it's also faster,

159
00:10:10,538 --> 00:10:14,446
it's slower than the native rust, but it's still way faster than

160
00:10:14,468 --> 00:10:17,730
the JavaScript. And so if we analyze the data,

161
00:10:17,800 --> 00:10:20,834
we can come to two solutions. Number one is that

162
00:10:20,872 --> 00:10:24,526
rust increases the performance roughly by 60% compared to node

163
00:10:24,558 --> 00:10:28,406
js, while webassembly increases the performance for around

164
00:10:28,508 --> 00:10:31,410
45% compared to the JavaScript.

165
00:10:31,570 --> 00:10:35,346
The second conclusion is that rust is around 45% faster

166
00:10:35,378 --> 00:10:38,938
than webAssembly, which should not be a

167
00:10:38,944 --> 00:10:42,186
surprise because webassembly is executed by

168
00:10:42,208 --> 00:10:45,514
a virtual machine in the end. And there

169
00:10:45,552 --> 00:10:49,242
is also a third conclusion is that benchmarks like this are

170
00:10:49,296 --> 00:10:52,334
useless. They are made to

171
00:10:52,372 --> 00:10:55,854
demonstrate a point, but you should always run youve

172
00:10:55,892 --> 00:10:59,498
own benchmarks against the real case scenarios.

173
00:10:59,674 --> 00:11:03,818
So it's good as a reference point, but don't rely

174
00:11:03,834 --> 00:11:07,380
on it when you are making a decision, because as you saw in the example,

175
00:11:07,910 --> 00:11:11,620
if you don't go up too much in the Fibonacci numbers,

176
00:11:12,310 --> 00:11:16,498
the performance increase you gain might not be worth the hassle

177
00:11:16,674 --> 00:11:20,226
in introducing native models or even webAssembly,

178
00:11:20,338 --> 00:11:23,714
because as you can see, the forter Fibonacci number is computed

179
00:11:23,762 --> 00:11:27,722
relatively fast, even in JavaScript itself. So always

180
00:11:27,776 --> 00:11:31,302
run your own benchmarks. Let's do a little comparison.

181
00:11:31,366 --> 00:11:35,990
So when to choose native models, when to choose webassembly

182
00:11:36,150 --> 00:11:39,850
there are some nuances and let's cover them.

183
00:11:40,000 --> 00:11:43,258
The first point I want to touch is if youve

184
00:11:43,434 --> 00:11:47,674
talking about maximizing every output, getting the best performance

185
00:11:47,722 --> 00:11:51,230
you can get. Youve should absolutely choose native models.

186
00:11:51,570 --> 00:11:55,186
It's no surprise native will always be faster than the VM you

187
00:11:55,208 --> 00:11:59,054
can see. Look at Java versus

188
00:11:59,102 --> 00:12:02,674
C of C Plus Plus. C and C Plus plus will always be faster because

189
00:12:02,712 --> 00:12:05,926
they compile natively even though the Java VM is

190
00:12:06,028 --> 00:12:09,874
very optimized. Very good. If you want to squeeze

191
00:12:09,922 --> 00:12:13,590
every possible performance, then you should

192
00:12:13,740 --> 00:12:17,522
go to the native solution as well. Having said that,

193
00:12:17,596 --> 00:12:21,386
I want to point out that webassembly is relatively fast,

194
00:12:21,568 --> 00:12:25,210
so if you don't need the absolute best performance,

195
00:12:26,430 --> 00:12:29,746
consider webassembly. It's a good middle ground

196
00:12:29,878 --> 00:12:34,206
between going fully native versus rewriting some

197
00:12:34,228 --> 00:12:37,502
of the application parts into webassembly. Let's talk about

198
00:12:37,556 --> 00:12:42,366
reusability when we talk about reusability when

199
00:12:42,388 --> 00:12:45,778
I talk about reusability, I mean taking your code and using it in a

200
00:12:45,784 --> 00:12:49,234
different environment. It's a but complicated with both of

201
00:12:49,272 --> 00:12:53,874
these. Let's try to unwrap it and see where the complication comes.

202
00:12:54,072 --> 00:12:57,714
Now, native libraries can be reused in other languages through

203
00:12:57,752 --> 00:13:01,010
foreign function interfaces. So a classic example,

204
00:13:01,080 --> 00:13:03,862
let's say you have a back end that's written in Rust, you have some business

205
00:13:03,916 --> 00:13:07,586
logic that is written in rust, and you want to port it into your web

206
00:13:07,628 --> 00:13:11,370
application as well as your mobile applications like Android and iOS.

207
00:13:11,710 --> 00:13:17,434
The same binary can be shared between

208
00:13:17,472 --> 00:13:20,678
the web application using WebAssembly, for example,

209
00:13:20,784 --> 00:13:24,174
or the native model, and it can be compiled and

210
00:13:24,212 --> 00:13:27,646
reused inside Java or Swift, for example, so you can

211
00:13:27,668 --> 00:13:30,874
share the same code using pure

212
00:13:30,922 --> 00:13:34,606
rust. It's not true for WASM because once you compile it

213
00:13:34,628 --> 00:13:38,334
to a WaSM, it can only be executed by webassembly

214
00:13:38,382 --> 00:13:42,446
Vm. WebAssembly vms are available in all the browsers and node js,

215
00:13:42,478 --> 00:13:46,066
as I've said, but they are not available in mobile. For example, if you need

216
00:13:46,088 --> 00:13:49,826
to share your logic with your mobile application, and your mobile

217
00:13:49,858 --> 00:13:53,350
application is native, meaning it's written Java or Swift,

218
00:13:54,170 --> 00:13:57,414
then you can share the webassembly. Because as far as I

219
00:13:57,452 --> 00:14:01,494
know, maybe there are implementations for the Webassembly

220
00:14:01,542 --> 00:14:04,746
VM in Java or Swift, but as

221
00:14:04,768 --> 00:14:08,726
far as I know, it's not that easy. So if you're

222
00:14:08,758 --> 00:14:12,734
talking about reusability, the native models can

223
00:14:12,772 --> 00:14:16,474
be reused in other languages that support foreign function interfaces.

224
00:14:16,602 --> 00:14:21,114
Let's talk about ergonomics. Ergonomics is roughly

225
00:14:21,162 --> 00:14:24,938
the amount of code you need to write in order to produce a working example.

226
00:14:25,124 --> 00:14:28,626
And if you paid attention that youve saw that the amount of code we

227
00:14:28,648 --> 00:14:31,934
need with the neon wrapper is relatively

228
00:14:31,982 --> 00:14:35,310
big. You need to import all the neon types,

229
00:14:35,390 --> 00:14:38,534
you need to write the glue layer, you need to write the export function.

230
00:14:38,732 --> 00:14:43,042
And the glue layer can become very messy because you have error handling,

231
00:14:43,186 --> 00:14:46,706
because remember, the Javascript isn't typed,

232
00:14:46,818 --> 00:14:50,534
there are no types. So you need to be able to do

233
00:14:50,572 --> 00:14:53,734
casts between maybe it's a string, maybe it's can odd string,

234
00:14:53,782 --> 00:14:57,146
maybe it's a number, maybe it's not a number. So you need to handle all

235
00:14:57,168 --> 00:15:01,086
the edge cases. Webassembly on the other hand is

236
00:15:01,268 --> 00:15:04,986
typed. So webassembly have types,

237
00:15:05,098 --> 00:15:08,766
they have basic types, but nevertheless the

238
00:15:08,788 --> 00:15:12,346
waslin binding and package is able to seamlessly convert

239
00:15:12,378 --> 00:15:14,930
your rust types into webassembly types,

240
00:15:16,230 --> 00:15:19,698
which with neon requires a glue layer, as I've said.

241
00:15:19,784 --> 00:15:23,134
So in my opinion, the ergonomics with webassembly,

242
00:15:23,182 --> 00:15:26,094
especially if youve doing like small optimizations,

243
00:15:26,142 --> 00:15:29,218
you want to rewrite maybe two to three functions.

244
00:15:29,394 --> 00:15:33,666
Then the ergonomics with the webassembly compilation

245
00:15:33,778 --> 00:15:37,186
are a lot nicer in my opinion, especially with the bus and binding

246
00:15:37,218 --> 00:15:40,522
and function, because all you need to do is just macro the function

247
00:15:40,576 --> 00:15:43,130
and you got an executable webassembly,

248
00:15:43,710 --> 00:15:46,982
it's a perfectly valid rasp code. Add the macro

249
00:15:47,046 --> 00:15:50,462
and you get a webassembly output. Let's talk about

250
00:15:50,516 --> 00:15:53,854
standard library for those of you who don't know,

251
00:15:53,972 --> 00:15:57,054
standard library or Stdlib is talking about

252
00:15:57,092 --> 00:16:00,602
the access to the file system, networking and anything OS

253
00:16:00,666 --> 00:16:04,594
related. And it's a funny one, because when

254
00:16:04,632 --> 00:16:08,946
I worked on this presentation and

255
00:16:08,968 --> 00:16:12,126
the blog post that inspired this presentation, I learned

256
00:16:12,158 --> 00:16:16,354
that you actually can't access files from webassembly because

257
00:16:16,392 --> 00:16:20,134
Webassembly does not have access. Two, the standard library and

258
00:16:20,172 --> 00:16:23,510
if you look at the WaSm Biengan package, you can see that

259
00:16:23,660 --> 00:16:27,126
anything that is related into the OS and

260
00:16:27,148 --> 00:16:30,566
file system and the standard library, it's actually not implemented.

261
00:16:30,598 --> 00:16:33,382
Inside the code there is a proposal.

262
00:16:33,446 --> 00:16:38,550
It's called wazi, which stands for Webassembly

263
00:16:38,630 --> 00:16:42,318
system interface I things which

264
00:16:42,404 --> 00:16:44,400
does give you access to,

265
00:16:45,250 --> 00:16:49,034
which is a proposal to give you access to the native operation

266
00:16:49,082 --> 00:16:51,390
system, things like file system and network.

267
00:16:52,290 --> 00:16:56,066
But for now it's only a proposal. And if youve need to have

268
00:16:56,088 --> 00:16:59,822
access to the standard library, your only solution

269
00:16:59,886 --> 00:17:03,854
today is to use native modules. Unless you want to experiment

270
00:17:03,902 --> 00:17:07,970
with the webassembly system interface, which is still in development.

271
00:17:09,350 --> 00:17:12,598
I also found out that there is

272
00:17:12,604 --> 00:17:16,374
an option that you can mount like a virtual file system, so your

273
00:17:16,412 --> 00:17:19,946
files will be actually compiled into the webassembly itself

274
00:17:20,128 --> 00:17:23,674
and then you have a virtual file system like

275
00:17:23,712 --> 00:17:27,306
in RAM file system that you can read the files from, but it's not the

276
00:17:27,328 --> 00:17:30,794
same as reading dynamic files, you can't use it

277
00:17:30,832 --> 00:17:34,400
for if you want to read a dynamic file from the disk for example.

278
00:17:35,170 --> 00:17:38,974
So if that's your use case youve absolutely have to

279
00:17:39,092 --> 00:17:43,178
go to the native model solution. If we are talking about portability,

280
00:17:43,354 --> 00:17:46,690
it's the famous phrase that it works in my machine.

281
00:17:47,670 --> 00:17:51,806
You need to remember that native models are host machine dependent.

282
00:17:51,998 --> 00:17:56,382
This means that when I compile my rust code on MacBook

283
00:17:56,446 --> 00:18:00,286
M one it will be compiled into the ARM

284
00:18:00,318 --> 00:18:03,846
architecture. I can just take this binary and give it to my

285
00:18:03,868 --> 00:18:07,802
friend who runs a Windows machine because his windows machine is running a different

286
00:18:07,856 --> 00:18:10,810
architecture, the X 86 64.

287
00:18:10,880 --> 00:18:15,190
And this is probably most likely it's

288
00:18:15,270 --> 00:18:18,998
not true for WaSM because WaSM is executing by a vm.

289
00:18:19,094 --> 00:18:22,746
So once I have the WASM executable I

290
00:18:22,768 --> 00:18:26,074
can give it to the other person and as long as he have the vm

291
00:18:26,122 --> 00:18:30,154
he can executing the code. And for native models it's

292
00:18:30,202 --> 00:18:34,446
always important to recompile to the target architecture.

293
00:18:34,638 --> 00:18:38,462
So always remember that if you are using native models

294
00:18:38,606 --> 00:18:42,398
and you are running let's say on an Alpine Linux docker

295
00:18:42,494 --> 00:18:45,762
in your production environment, you should compile

296
00:18:45,826 --> 00:18:49,314
the native models on the same environment. So dockerized

297
00:18:49,362 --> 00:18:53,394
containers are good solutions. Don't just upload your binary

298
00:18:53,442 --> 00:18:56,722
files, always compile them in the required environment

299
00:18:56,786 --> 00:19:00,514
as you need. Let's talk about node JS and browser.

300
00:19:00,642 --> 00:19:04,022
And up until now I refer to NodeJs and JavaScript

301
00:19:04,086 --> 00:19:07,610
interchangeably. But they are two different things.

302
00:19:07,680 --> 00:19:11,226
JavaScript is a language, node JS is a framework, and the

303
00:19:11,248 --> 00:19:14,926
big takeaway that you can take from this is that native modules can't be

304
00:19:14,948 --> 00:19:18,234
used in the browser because JavaScript has no support for foreign

305
00:19:18,282 --> 00:19:22,474
function interface. The reason we can use native models

306
00:19:22,522 --> 00:19:26,542
inside Node Js is that NodeJs provides the so called can API,

307
00:19:26,606 --> 00:19:30,274
which is node API. It's an API to build

308
00:19:30,312 --> 00:19:34,114
native extensions with a stable API so

309
00:19:34,152 --> 00:19:37,650
you can write extensions in rust or in c

310
00:19:37,800 --> 00:19:41,186
or C and to extend your node JS

311
00:19:41,218 --> 00:19:44,914
ecosystem. So remember that native modules cannot

312
00:19:44,962 --> 00:19:48,406
be used in the browser. So your only solution for the browser

313
00:19:48,518 --> 00:19:51,770
is to actually use Wasm because

314
00:19:51,840 --> 00:19:55,686
all browsers have a VM for that except for Internet explorer

315
00:19:55,798 --> 00:19:59,898
as well as Node Js. But if

316
00:19:59,904 --> 00:20:03,662
youve don't target the browser and you target only node JS, so for example only

317
00:20:03,716 --> 00:20:07,482
backend code, then it's perfectly safe to write native

318
00:20:07,546 --> 00:20:10,030
models. Let's look at a recap.

319
00:20:11,330 --> 00:20:14,994
When I think. But whether to choose native models or

320
00:20:15,032 --> 00:20:19,182
webassembly, I like to have two mental models

321
00:20:19,326 --> 00:20:23,086
in my head. The first mental model says that native models

322
00:20:23,118 --> 00:20:26,246
are meant to extend your node JS code. So if

323
00:20:26,268 --> 00:20:30,470
you have a Nodejs code that you want to optimize,

324
00:20:31,130 --> 00:20:35,010
then you can use native modules to extend it beyond

325
00:20:35,090 --> 00:20:37,960
what Javascript and nodejs can provide you.

326
00:20:38,490 --> 00:20:42,342
While webassembly is meant to replace non performant Javascript

327
00:20:42,406 --> 00:20:46,646
code. So let's say you have some image processing in the browser,

328
00:20:46,838 --> 00:20:49,654
you want the user to be able to manipulate images.

329
00:20:49,782 --> 00:20:52,462
So webassembly will be a great place for this.

330
00:20:52,596 --> 00:20:56,666
Let's say youve developing a visualization application in the browser

331
00:20:56,698 --> 00:21:00,334
itself. It's very common now that many so

332
00:21:00,372 --> 00:21:03,600
called professional desktop tools are moving into the web,

333
00:21:03,910 --> 00:21:07,506
and so webassembly is a great place to squeeze all

334
00:21:07,528 --> 00:21:10,578
the performance that you need to squeeze from them.

335
00:21:10,664 --> 00:21:14,740
So those are the mental models I hold in my head.

336
00:21:15,510 --> 00:21:19,638
They work pretty well. And thank you very much.

337
00:21:19,804 --> 00:21:23,574
I hope you learned something. You can

338
00:21:23,612 --> 00:21:26,886
find me in LinkedIn I'm mostly active in

339
00:21:26,908 --> 00:21:30,630
LinkedIn. You can follow me on Twitter, you can find me in GitHub.

340
00:21:31,050 --> 00:21:34,246
You can scan this QR code which will lead you to my blog where

341
00:21:34,268 --> 00:21:37,862
you can find the articles that this talk is based

342
00:21:37,916 --> 00:21:42,590
on. There is more technical information inside

343
00:21:42,660 --> 00:21:46,106
the articles AWS, well as link to GitHub repos that you can execute

344
00:21:46,138 --> 00:21:49,694
the Fibonacci examples. And thank

345
00:21:49,732 --> 00:21:53,338
you very much and I hope you enjoyed my talk and enjoyed

346
00:21:53,354 --> 00:21:54,250
the rest of the conference.

