1
00:00:20,010 --> 00:00:23,658
I am a principal engineer at simply smart Technologies, private limited,

2
00:00:23,754 --> 00:00:27,222
and been working with that particular product since last three years.

3
00:00:27,276 --> 00:00:31,506
And predominantly the responsibilities includes

4
00:00:31,538 --> 00:00:35,202
like we manage all the software side development to development

5
00:00:35,266 --> 00:00:38,774
lifecycle to DevOps and all those sort of things. And that's

6
00:00:38,822 --> 00:00:42,380
pretty much the intro. So then let's start with our talk.

7
00:00:42,750 --> 00:00:46,374
So talking about the topic that I have chosen,

8
00:00:46,422 --> 00:00:49,930
like the connecting with dots. So why connecting with dots?

9
00:00:50,670 --> 00:00:53,790
Firstly, we work with IoT, so it has

10
00:00:53,860 --> 00:00:56,894
multiple nodes and we are connecting all those nodes to one another.

11
00:00:57,012 --> 00:01:00,446
So at the end we are connecting multiple dots to one another.

12
00:01:00,628 --> 00:01:04,714
But ironically, that has nothing to do with the talk name

13
00:01:04,772 --> 00:01:09,060
that I have worked, that I have figured it out. So it's due to

14
00:01:09,750 --> 00:01:12,946
because growing up I was fascinated by all

15
00:01:12,968 --> 00:01:16,326
the things that have been done and how Steve Jobs used to present all those

16
00:01:16,348 --> 00:01:21,506
things. And so in one of his speeches at Stanford

17
00:01:21,538 --> 00:01:25,062
University, he talked about how easy

18
00:01:25,116 --> 00:01:28,934
is to connect the dots or the incidents that

19
00:01:28,972 --> 00:01:32,586
happened with you in the past than to connect anything that in the future.

20
00:01:32,768 --> 00:01:36,490
So this is a talk about my experiences and how

21
00:01:36,560 --> 00:01:39,946
we have evolved through it and what sort of experiences and learnings we

22
00:01:39,968 --> 00:01:42,638
had while improving our own product.

23
00:01:42,804 --> 00:01:45,882
And that's why I'm connecting all those dots, looking backward.

24
00:01:45,946 --> 00:01:48,510
And that's why the name is connecting with dots.

25
00:01:49,410 --> 00:01:53,098
Now, what is a simplismart? So simply smart is an end

26
00:01:53,124 --> 00:01:56,242
to end water management tool. And in simple words,

27
00:01:56,296 --> 00:02:00,420
I would say you can predominantly look out from

28
00:02:00,870 --> 00:02:04,946
the motto that we have making simple things smart. So what we

29
00:02:04,968 --> 00:02:08,546
did, what we revolutionized, or I would say like the game changing factor

30
00:02:08,578 --> 00:02:11,942
that we have done, we have taken a simple

31
00:02:11,996 --> 00:02:15,814
thing, simple as water and we have made

32
00:02:15,852 --> 00:02:19,942
it smart. So how we did that, so what we did, we have given

33
00:02:19,996 --> 00:02:23,354
an end to end water management tool all the way

34
00:02:23,392 --> 00:02:27,322
from the hardware itself to all the way managing all the things remotely using

35
00:02:27,376 --> 00:02:30,886
a mobile app and admin tools for numerous

36
00:02:30,918 --> 00:02:32,970
residential as well as commercial projects,

37
00:02:35,310 --> 00:02:38,654
which in result save a huge amount of water at the end

38
00:02:38,692 --> 00:02:42,254
and which is our main goal while growing up, to save water.

39
00:02:42,452 --> 00:02:46,362
Yeah, so let's connect the dots then, starting with.

40
00:02:46,516 --> 00:02:49,986
Yeah, so this is just a gif to show what we are

41
00:02:50,008 --> 00:02:52,946
connecting here. Now, let's start with the first one.

42
00:02:52,968 --> 00:02:56,386
That is the time series data. So while working with all the people who have

43
00:02:56,488 --> 00:02:59,686
worked any way or any fashion with the IoT sort

44
00:02:59,708 --> 00:03:02,886
of things, we all know that we work with time series data. So what is

45
00:03:02,908 --> 00:03:06,406
the time series data? So whatever that is

46
00:03:06,428 --> 00:03:09,874
periodically given to us, or I would say like whatever it is dependent

47
00:03:09,922 --> 00:03:13,066
or the time is the main constraint in this case. So in

48
00:03:13,088 --> 00:03:17,450
our case, considering water meters, so all the readings from the meters

49
00:03:17,870 --> 00:03:20,586
that we have received at the cloud level and all those things is a time

50
00:03:20,608 --> 00:03:23,966
series data from which we can perform any sort of analysis and all those sort

51
00:03:23,988 --> 00:03:27,518
of things. Now moving ahead, what are the challenges that we have

52
00:03:27,524 --> 00:03:30,942
faced which led to this sort of talk and all those things?

53
00:03:31,076 --> 00:03:34,810
So while growing, the first challenges that we faced

54
00:03:34,970 --> 00:03:38,786
dealing with all the maintenance related stuff, and we always have that

55
00:03:38,808 --> 00:03:42,114
fact, like every day if your end

56
00:03:42,152 --> 00:03:45,454
user is releasing a thing like we have an issue with this sort of hardware,

57
00:03:45,502 --> 00:03:48,934
and then your hardware person is going like this, that doesn't sound good,

58
00:03:48,972 --> 00:03:52,726
right? And growing up at the start,

59
00:03:52,828 --> 00:03:55,986
it's kind of easy thing to manage, simple scale of the meters,

60
00:03:56,018 --> 00:03:59,814
but once you grow from that hardware account from 1000

61
00:03:59,852 --> 00:04:02,954
to 10,000 to 10,000 to 40,000 to 50,060, 70,

62
00:04:02,992 --> 00:04:06,282
80,000, it's quite hard to manually doing those things.

63
00:04:06,416 --> 00:04:09,818
So that was a bigger challenge that we have seen in the past like four

64
00:04:09,824 --> 00:04:13,066
or five years working with simply smart. Now the

65
00:04:13,088 --> 00:04:16,334
second part is abnormal utilization or usage. So this is

66
00:04:16,452 --> 00:04:19,354
why I did terminalize it as abnormal usage,

67
00:04:19,402 --> 00:04:22,846
because since we are working with water, so I'm considering that as a terminology to

68
00:04:22,868 --> 00:04:26,094
consider usage. Now you can see like if there is abnormal

69
00:04:26,142 --> 00:04:29,586
usage, then everybody will be as frightened and as surprised as this

70
00:04:29,608 --> 00:04:32,962
guy is. And we actually

71
00:04:33,016 --> 00:04:36,162
want to save water. So we need to resolve those abnormal usages

72
00:04:36,226 --> 00:04:39,762
and all those Sort of things so that water can be saved properly.

73
00:04:39,906 --> 00:04:43,800
So now what's the solution to these problems?

74
00:04:46,410 --> 00:04:50,278
And always in this today's era, every solution drilled

75
00:04:50,294 --> 00:04:53,914
down to the first thing that we came in our

76
00:04:53,952 --> 00:04:57,994
mind is that machine learning? Yeah. Yes, that's the solution we

77
00:04:58,032 --> 00:05:01,338
got. But we are like our most

78
00:05:01,424 --> 00:05:04,826
complete system is designed in Ruby. Like all the end

79
00:05:04,848 --> 00:05:08,846
user handling and all those sort of things are designed in Ruby. So is

80
00:05:08,868 --> 00:05:12,800
it machine learning with Ruby? But is it really possible to

81
00:05:13,170 --> 00:05:16,754
perform machine learning sort of application using Ruby? Because we all know that

82
00:05:16,792 --> 00:05:20,830
there are so many popular languages, I would say programming languages

83
00:05:20,990 --> 00:05:24,386
moving ahead, like Python R, even Javascript has

84
00:05:24,408 --> 00:05:27,526
few things. And when I tried searching about it,

85
00:05:27,548 --> 00:05:29,830
like can we do machine learning in Ruby?

86
00:05:31,370 --> 00:05:35,266
At the start it was like in top ten, I didn't find any ruby

87
00:05:35,298 --> 00:05:39,458
related sort of, nobody talked about it. Like we can achieve this thing using Ruby.

88
00:05:39,554 --> 00:05:42,982
So then I can search a lot. And from one of the conferences

89
00:05:43,046 --> 00:05:46,694
I got a contact of this guy, Andrew Kane.

90
00:05:46,742 --> 00:05:50,266
Yes, somebody did work in Ruby to perform certain sort

91
00:05:50,288 --> 00:05:53,486
of machine learning in Ruby natively in Ruby itself. So that

92
00:05:53,588 --> 00:05:56,666
somebody who is good with Ruby and some sort of mathematics

93
00:05:56,698 --> 00:06:00,862
related background, we can solve these sort of problems using simple

94
00:06:00,916 --> 00:06:04,606
solutions, using ruby itself. So you can definitely look

95
00:06:04,628 --> 00:06:08,354
at this guy, that is Andrew Kane. He has done a lot of work in

96
00:06:08,392 --> 00:06:12,222
these sort of things and as well as some sort of postgres sort of optimization

97
00:06:12,286 --> 00:06:15,506
as well as some graphical analysis. And all those

98
00:06:15,528 --> 00:06:19,030
things you do look at. So you can see here like there is a

99
00:06:19,100 --> 00:06:22,690
blazer, Ruby, gem gem or a package

100
00:06:22,850 --> 00:06:27,218
which works on business intelligence made simple. So he has solved

101
00:06:27,394 --> 00:06:31,158
smaller problems using simple solutions. And it's inheritedly

102
00:06:31,254 --> 00:06:34,358
what we are doing with the water meters, making simple things smart

103
00:06:34,374 --> 00:06:38,346
as possible. So let's look

104
00:06:38,368 --> 00:06:41,726
at some few packages that we going ahead before going

105
00:06:41,748 --> 00:06:44,800
to the actual solution and how we solve those problems.

106
00:06:45,570 --> 00:06:49,578
So moving ahead. The first one is Nemo array.

107
00:06:49,674 --> 00:06:53,214
So we all in some sort of way worked

108
00:06:53,252 --> 00:06:57,262
with numpy because we all know machine learning drill downs to mathematics

109
00:06:57,326 --> 00:07:00,370
at the end. Yeah, we all can agree on that fact.

110
00:07:00,520 --> 00:07:04,114
So I thought like how we can do

111
00:07:04,152 --> 00:07:07,778
similar stuff, like similar to numpy, some sort of matrix multiplications as

112
00:07:07,784 --> 00:07:10,966
well as some sort of scientific calculations and all those things in natively in

113
00:07:10,988 --> 00:07:14,614
Ruby. Whereas while looking at Andrew Kane's profile and

114
00:07:14,652 --> 00:07:18,626
other solutions as well, this was one of the package that I have found

115
00:07:18,748 --> 00:07:22,454
that is called pneumo array, which can easily

116
00:07:22,502 --> 00:07:25,990
perform all those sort of scientific level or mathematical level calculations

117
00:07:26,070 --> 00:07:29,814
easily similar to numpy and other similar sort of libraries

118
00:07:29,862 --> 00:07:33,726
in Python and R as well. Now you might be wondering like

119
00:07:33,908 --> 00:07:37,518
the screenshot that I have added here is some sort of

120
00:07:37,604 --> 00:07:40,442
looking like a Jupyter notebook,

121
00:07:40,586 --> 00:07:44,034
which is first kind of predominantly used

122
00:07:44,072 --> 00:07:47,650
for Python and how I'm running the ruby code

123
00:07:47,720 --> 00:07:51,118
in a Jupyter notebook.

124
00:07:51,214 --> 00:07:55,330
So for that also there is a gem called irubi which

125
00:07:55,400 --> 00:07:59,314
helps us in easily configuring these things to use a ruby kernel

126
00:07:59,362 --> 00:08:02,680
instead of a Python kernel. Do look that out as well.

127
00:08:03,130 --> 00:08:06,310
Yeah. Now comes the part how to handle the huge data,

128
00:08:06,460 --> 00:08:09,942
because we all know that machine learning and all those things

129
00:08:09,996 --> 00:08:13,706
work, do need like a huge amount of data to process and

130
00:08:13,808 --> 00:08:18,506
to work around with. And in Python that

131
00:08:18,528 --> 00:08:22,010
sort of work is handled using data frames,

132
00:08:22,170 --> 00:08:25,550
using pandas while moving ahead.

133
00:08:25,620 --> 00:08:29,354
So I wanted a strong solution, or I would say like performance related

134
00:08:29,402 --> 00:08:33,406
optimized solution to move ahead and to

135
00:08:33,428 --> 00:08:37,098
get the data to process the data efficiently. So I said like

136
00:08:37,204 --> 00:08:40,590
is there any library to go ahead with data frames?

137
00:08:40,750 --> 00:08:44,466
Now when I searched about it,

138
00:08:44,488 --> 00:08:47,814
I found many search outer solutions. But out of that, Rover is one of the,

139
00:08:47,852 --> 00:08:51,798
I would say like most optimized one and predominantly written in Ruby itself.

140
00:08:51,964 --> 00:08:55,734
So I'm always emphasizing on written Ruby because

141
00:08:55,772 --> 00:08:59,542
there has been a solution earlier that they were made

142
00:08:59,596 --> 00:09:02,426
wrappers around it, the initial libraries and all those things,

143
00:09:02,528 --> 00:09:05,894
and they have made some sort of copies of those Python libraries

144
00:09:05,942 --> 00:09:09,286
in Ruby itself. But whenever I try to override

145
00:09:09,318 --> 00:09:12,766
any sort of applicability and

146
00:09:12,788 --> 00:09:16,906
the solution to my custom solutions, I always have like it's

147
00:09:16,938 --> 00:09:21,002
written in Python. So inherently, whatever I'm inheriting,

148
00:09:21,066 --> 00:09:24,314
or I would say like rewriting

149
00:09:24,362 --> 00:09:28,018
it around, it's in Ruby. So how that will get an optimized solution? Because I

150
00:09:28,024 --> 00:09:31,762
can't override all the things, because every language has its own power and

151
00:09:31,816 --> 00:09:35,682
own sort of way of doing things. So by having

152
00:09:35,736 --> 00:09:38,130
a plane like something which is written,

153
00:09:38,870 --> 00:09:43,026
I would say like natively in Ruby, that helps me a lot to override

154
00:09:43,058 --> 00:09:46,230
the things, to optimize the things in a different level fashion. Now,

155
00:09:46,300 --> 00:09:49,722
firstly we had a mathematical level calculation, secondly, how to handle the data.

156
00:09:49,776 --> 00:09:52,860
Now comes the part how to plot it out.

157
00:09:53,790 --> 00:09:57,034
Yeah. So before plotting it out, we all know that we

158
00:09:57,072 --> 00:10:00,358
wanted, while growing with scripting sort of languages,

159
00:10:00,454 --> 00:10:03,966
we all know that we want some sort of solutions which are already there and

160
00:10:03,988 --> 00:10:06,590
optimized way in Python.

161
00:10:06,930 --> 00:10:10,842
It's kind of had a scikitlearn sort of option where easily

162
00:10:10,906 --> 00:10:14,014
you can within like six, seven to eight lines of code,

163
00:10:14,052 --> 00:10:17,218
you can train a small level of

164
00:10:17,304 --> 00:10:20,846
applications and do those things. In here there is a ruml.

165
00:10:20,958 --> 00:10:24,446
So you can see from the code that what we are doing, we are loading

166
00:10:24,478 --> 00:10:28,710
a sample data set similar to that

167
00:10:28,780 --> 00:10:32,418
we used to do in Python as well. Then we have transformed it using components

168
00:10:32,434 --> 00:10:36,502
and randomly detecting it. And then transform is nothing

169
00:10:36,556 --> 00:10:39,530
but like we are loading a model into it.

170
00:10:39,680 --> 00:10:43,574
Now we have fit that particular, all those samples

171
00:10:43,702 --> 00:10:47,274
to a transformer, then we

172
00:10:47,312 --> 00:10:50,590
fit it and then we have trained it with SVC linear model,

173
00:10:50,660 --> 00:10:53,966
so support vector kind of classification level model.

174
00:10:54,148 --> 00:10:57,758
And we have again fitted the transform data to that particular

175
00:10:57,844 --> 00:11:02,094
model. And then we opened it. Now comes the part

176
00:11:02,292 --> 00:11:05,406
why do we need like file open and we are dumping it somewhere and all

177
00:11:05,428 --> 00:11:08,862
those things? Because what I believe that we always can't

178
00:11:08,926 --> 00:11:12,834
just train all the things at runtime and then gives the solution. So we need

179
00:11:12,872 --> 00:11:16,546
to kind of pickle it out or dump somewhere that

180
00:11:16,568 --> 00:11:19,638
model which is trained on huge amount of data. So we are dumping it in

181
00:11:19,644 --> 00:11:23,046
the first block, I would say code block. Then we are

182
00:11:23,068 --> 00:11:26,246
again loading that particular, like we

183
00:11:26,268 --> 00:11:30,434
are loading the test related data. Then we are loading the classifier

184
00:11:30,482 --> 00:11:34,602
from the files, loading it out. Transformers as well as classifiers. Then we are

185
00:11:34,736 --> 00:11:38,346
trying to predict it. After predicting, you can

186
00:11:38,368 --> 00:11:41,594
see like we are getting some sort of 98% sort of accuracy here.

187
00:11:41,792 --> 00:11:45,134
So it can differ from different sort of application, different sort of solutions, or different

188
00:11:45,172 --> 00:11:48,878
sort of problem statements. But we are getting it done

189
00:11:49,044 --> 00:11:52,446
with not more than like, I would say ten to twelve lines of a

190
00:11:52,468 --> 00:11:55,474
code. Yeah.

191
00:11:55,672 --> 00:11:59,326
Ironically now this has been added like considering some indian

192
00:11:59,358 --> 00:12:04,466
sort of audience. So there is a package named Daru in

193
00:12:04,488 --> 00:12:07,906
Ruby, which works with data analysis. With Ruby. And whereas

194
00:12:07,938 --> 00:12:10,550
in hindi slang or in indian slang,

195
00:12:10,970 --> 00:12:14,594
it kind of represents a liquor. So it's kind of an ironical

196
00:12:14,642 --> 00:12:18,370
situation or a laughable situation that some sort of data analysis sort

197
00:12:18,380 --> 00:12:22,134
of package is named like a liquor.

198
00:12:22,262 --> 00:12:25,910
Yeah. Now there are so many other applications,

199
00:12:25,990 --> 00:12:29,478
there are some other references as well, like some sort of textual.

200
00:12:29,574 --> 00:12:32,474
If you want to perform some sort of textual analysis, you can go with fast

201
00:12:32,512 --> 00:12:35,486
text. If I want to do plotting sort of things, these two are there,

202
00:12:35,508 --> 00:12:39,134
nya plot and Vega. There are so many others as well. Do look it out

203
00:12:39,252 --> 00:12:42,590
and do explore it more and do contribute to it.

204
00:12:42,740 --> 00:12:46,318
Now moving ahead with our own problems that we have really faced,

205
00:12:46,334 --> 00:12:49,934
like challenges and all those things. Now the solution is anomaly detection.

206
00:12:50,062 --> 00:12:53,666
So we all know that whatever, like if that particular reading is

207
00:12:53,688 --> 00:12:57,006
behaving resulting into some sort of anomalies,

208
00:12:57,118 --> 00:13:00,438
there may be some sort of problem with it. IoT can be related to a

209
00:13:00,444 --> 00:13:04,214
maintenance related problem. IoT can be related to abnormal utilizations and all those things.

210
00:13:04,332 --> 00:13:07,590
But the solution is anomaly detecting and to do that.

211
00:13:07,660 --> 00:13:10,970
So let's just understand what sort of anomalies detection and how

212
00:13:11,040 --> 00:13:14,326
those are impacting the water related solutions.

213
00:13:14,358 --> 00:13:17,786
Or I would say like Iot related solutions. Moving ahead. The first one

214
00:13:17,808 --> 00:13:21,654
is point outliers. So I just added a graphical scenario

215
00:13:21,702 --> 00:13:25,438
so that everybody can understand. So in this case you can see like

216
00:13:25,524 --> 00:13:29,086
we are having some sort of point level outliers here.

217
00:13:29,188 --> 00:13:33,630
And you can see. So now in terms of Iot solution

218
00:13:34,050 --> 00:13:37,442
where this sort of anomalies can happen. So considering a water level

219
00:13:37,496 --> 00:13:40,974
solution, there can be some power failures.

220
00:13:41,022 --> 00:13:44,066
And due to that there can be some junk reading gets sent and we can

221
00:13:44,088 --> 00:13:47,526
see like that sort of problems we can detect. And if that

222
00:13:47,548 --> 00:13:51,094
sort of problems are continuously happening regularly within

223
00:13:51,132 --> 00:13:54,806
a day, there are two, three these sort of outliers. Then we need to

224
00:13:54,828 --> 00:13:58,658
check the support level system which is supporting like electrical

225
00:13:58,674 --> 00:14:02,566
system and other systems which are supporting the hardware that we are actually installed.

226
00:14:02,598 --> 00:14:06,726
At the site. Now comes the part, subsequent anomalies.

227
00:14:06,918 --> 00:14:10,858
So now these are the two types of subsequent anomalies. Like if you

228
00:14:10,864 --> 00:14:14,106
are working with single time series property or single time

229
00:14:14,128 --> 00:14:17,374
series sort of data that we are going at, then you can get

230
00:14:17,412 --> 00:14:20,846
univarried time series sort of data. And you can see here we are

231
00:14:20,868 --> 00:14:24,046
having some sort of outliers. There is one outlier, there is an o,

232
00:14:24,068 --> 00:14:27,586
two outlier, and it's kind of subsequent, it's not just

233
00:14:27,608 --> 00:14:31,362
a single outlier, single point outlier. And now the case

234
00:14:31,416 --> 00:14:34,114
happens, like if you get this sort of anomalies here,

235
00:14:34,312 --> 00:14:37,966
what does it depict? Because at the end it's all about what analytics

236
00:14:37,998 --> 00:14:41,302
we are getting out of it. So from

237
00:14:41,356 --> 00:14:44,866
these we can understand, like there is some issue with the meter because it's

238
00:14:44,898 --> 00:14:48,006
continuously, it's fluctuating up and down, up and down, up and down. If there's a

239
00:14:48,028 --> 00:14:51,174
subsequent anomalies here, in this case we can

240
00:14:51,212 --> 00:14:54,650
say like there might be some sort of issue with the hardware itself,

241
00:14:54,720 --> 00:14:58,266
not the supporting system that we are providing to it. And from that we can

242
00:14:58,288 --> 00:15:01,834
inform a hardware personnel proactively to go and check.

243
00:15:02,032 --> 00:15:05,786
So that kind of solve these first two can solve a proactive

244
00:15:05,818 --> 00:15:09,626
maintenance sort of case. Now comes the part, the abnormal utilization

245
00:15:09,658 --> 00:15:12,958
sort of part, how we can solve that. So to solve

246
00:15:12,974 --> 00:15:15,780
that abnormal utilization part,

247
00:15:16,630 --> 00:15:20,340
let's just first detect these sort of outliers. Then we can discuss about that thing.

248
00:15:20,870 --> 00:15:24,050
So in here we are using profit gem.

249
00:15:25,990 --> 00:15:29,174
There is a library named profit with Google, and they have

250
00:15:29,212 --> 00:15:32,726
made a similar sort of solution in Ruby. Easily detect some

251
00:15:32,748 --> 00:15:36,038
sort of basic outliers to it, so that we don't need to

252
00:15:36,204 --> 00:15:39,670
do all those things, because at the end it's all about solving problem

253
00:15:39,740 --> 00:15:43,562
efficiently in a lesser amount of time. So to do that, this is actually

254
00:15:43,616 --> 00:15:46,970
helping us. And in this, you can see what we are doing here.

255
00:15:47,120 --> 00:15:50,714
We are just iterating over

256
00:15:50,832 --> 00:15:54,158
the data that we are getting to get it a series level data from the

257
00:15:54,164 --> 00:15:57,966
CSV that we are providing to this particular solution. And then

258
00:15:57,988 --> 00:16:01,566
we are asking profit to detect the anomalies with this series. And now we can

259
00:16:01,588 --> 00:16:05,298
see it detecting the anomalies with the x and y coordinates to it

260
00:16:05,384 --> 00:16:08,850
from the values as well as other time series related time

261
00:16:08,920 --> 00:16:12,482
data. And using this sort of simple

262
00:16:12,536 --> 00:16:16,590
solution, we can detect the point outliers as well as the multivariate, single variate,

263
00:16:16,750 --> 00:16:20,690
multivariate outliers as well. And we can easily solve

264
00:16:21,030 --> 00:16:24,566
the proctimal maintenance related problems in a huge IoT systems as

265
00:16:24,588 --> 00:16:27,800
well. Now comes the part let's plot the data.

266
00:16:28,330 --> 00:16:32,074
Why did the plot that? Because it's just showing like some sort of scientific level

267
00:16:32,112 --> 00:16:35,226
data. I'm just plotting. And you can see like there is some issue in this

268
00:16:35,248 --> 00:16:38,010
particular time frame that we are getting an outlier.

269
00:16:38,510 --> 00:16:41,706
Now comes the part how to detect abnormal

270
00:16:41,738 --> 00:16:45,406
utilization. So we can do it by

271
00:16:45,588 --> 00:16:49,774
detection, by forecasting. It's a very popular method that

272
00:16:49,972 --> 00:16:53,598
in a machine learning what we do, we always forecast things. We always predict the

273
00:16:53,604 --> 00:16:56,738
things like how things should be, how things can be and all those sort of

274
00:16:56,744 --> 00:17:00,626
things. And doing that, what we have observed that

275
00:17:00,728 --> 00:17:04,050
in our solution, like water level solution,

276
00:17:04,870 --> 00:17:07,998
we can't just go ahead and see is there any spiked

277
00:17:08,014 --> 00:17:10,822
and all those sort of things, since it's a continuously increasing thing.

278
00:17:10,956 --> 00:17:14,646
So what we can do in this sort of solution, we can predict what

279
00:17:14,668 --> 00:17:18,214
could be the next possible value. Like from the trends, from the past

280
00:17:18,252 --> 00:17:22,218
learnings, like how the meter is consuming, how that particular resident or

281
00:17:22,304 --> 00:17:25,398
some sort of commercial project is consuming. Like let's say they're

282
00:17:25,414 --> 00:17:29,194
continuously consuming some sort of odd between, like in the morning, ten to twelve,

283
00:17:29,232 --> 00:17:32,646
they're continuously consuming some sort of 1000 liter, whereas in afternoon

284
00:17:32,678 --> 00:17:35,678
there is some dry period where they are just consuming 200 to 300 liters and

285
00:17:35,684 --> 00:17:39,114
afterwards in the evening, again, that's a rise. So this is a pattern

286
00:17:39,162 --> 00:17:42,506
that we are learning. We are asking our machine

287
00:17:42,538 --> 00:17:45,694
learning model to learn and then to detecting some sort

288
00:17:45,732 --> 00:17:49,118
of outliers from that. Like if suddenly at the afternoon it's

289
00:17:49,134 --> 00:17:52,446
showing some sort of 1200 or 1300 liters, then it's

290
00:17:52,478 --> 00:17:57,400
an abnormal case and which will say, like there might be some leakages or

291
00:17:58,410 --> 00:18:02,422
somebody, like there is a continuous consumption due to some tap open and somebody

292
00:18:02,476 --> 00:18:06,946
forgot to close the tap. And to save the water, we need to proactively

293
00:18:07,058 --> 00:18:10,594
alert the resident or a commercial, whoever is responsible

294
00:18:10,642 --> 00:18:14,406
to the thing and to solve that thing, we have detection by forecasting.

295
00:18:14,438 --> 00:18:18,220
So you can see here from the graph as well, like the black dots are

296
00:18:18,670 --> 00:18:22,486
the patterns which are acceptable patterns, acceptable forecasted values,

297
00:18:22,518 --> 00:18:26,074
like the forecasted values. The green one is kind of forecasting

298
00:18:26,122 --> 00:18:29,818
pattern to that thing. And whereas the red ones are like actual values

299
00:18:29,914 --> 00:18:33,326
which are out of the forecasted values. So that we can say, like in this

300
00:18:33,428 --> 00:18:36,546
particular problem, particular time frames, there is some sort

301
00:18:36,568 --> 00:18:39,954
of problems in our system or somebody needs to go and check that

302
00:18:39,992 --> 00:18:42,340
the utilization is happening properly or not.

303
00:18:43,270 --> 00:18:46,354
Now how to do that? So as I illustrated, we need to use

304
00:18:46,392 --> 00:18:49,718
those applications as well. So in this case, you can see I'm having a

305
00:18:49,724 --> 00:18:53,618
time frame and a simple one level reading. So we are going with single variate.

306
00:18:53,714 --> 00:18:57,522
Firstly, we have loaded the data from CSV

307
00:18:57,586 --> 00:19:01,034
using Rover to get it in a data frame sort of application.

308
00:19:01,232 --> 00:19:05,510
Then what we did, we have loaded the profit

309
00:19:05,670 --> 00:19:09,002
model from profit. Then we have fit the complete data,

310
00:19:09,056 --> 00:19:12,526
like fit it's in terms like training it with the data that

311
00:19:12,548 --> 00:19:16,074
we have loaded. Then what we are doing, we are performing,

312
00:19:16,122 --> 00:19:19,360
we are asking it to forecast it.

313
00:19:19,890 --> 00:19:23,866
And then we are asking. So firstly,

314
00:19:23,898 --> 00:19:27,266
we are asking him to get some future data frames because we want to

315
00:19:27,288 --> 00:19:30,898
have some sort of fixed parodicity in this one.

316
00:19:30,984 --> 00:19:34,114
Then we are asking our model to predict it for those

317
00:19:34,152 --> 00:19:37,574
future dots. Now let's see what

318
00:19:37,612 --> 00:19:41,480
it forecasts. So you can see here that

319
00:19:42,250 --> 00:19:45,286
the line that we are seeing is a forecasting line,

320
00:19:45,388 --> 00:19:48,998
whereas the black dots are actual consumption. From that we can see

321
00:19:49,164 --> 00:19:52,780
the dots that are quite slightly away from

322
00:19:53,150 --> 00:19:56,538
the forecasted line. We can see like there is some sort of abnormal consumption in

323
00:19:56,544 --> 00:19:59,814
that line. So in this particular data, it's continuously increasing

324
00:19:59,862 --> 00:20:03,866
data. There might be some cases whenever you are having some sort of hyperbolic

325
00:20:03,898 --> 00:20:06,560
data as well and you can detecting it using that as well.

326
00:20:07,250 --> 00:20:10,894
Now let's summarize what we have discussed in this particular talk,

327
00:20:10,932 --> 00:20:14,606
a short talk I would say. Firstly, we have discussed what

328
00:20:14,628 --> 00:20:18,066
is the time series data and how it impacts most of the Iot solutions that

329
00:20:18,088 --> 00:20:21,506
we work with. Now comes the thing, the challenges that

330
00:20:21,528 --> 00:20:25,054
we have faced and most of the people who are working with IoT related

331
00:20:25,102 --> 00:20:29,166
solution do have faced these sort of problems in one or the other way.

332
00:20:29,288 --> 00:20:33,106
Now comes the part how we can solve this using machine learning with Ruby,

333
00:20:33,138 --> 00:20:36,802
not with just normal machine learning problem and solving it using the traditional python related

334
00:20:36,866 --> 00:20:40,246
solution. And now the last one, how we used anomaly

335
00:20:40,278 --> 00:20:42,650
detection technique to solve our challenges.

336
00:20:45,230 --> 00:20:48,534
Thank you. You have been a great audience, like you are listening

337
00:20:48,582 --> 00:20:51,980
and you have washed it out now.

338
00:20:52,350 --> 00:20:55,890
Thank you. So you can do visit our website like simply motor deck

339
00:20:55,910 --> 00:20:59,182
to understand more like what we do and how we do. And you can connect

340
00:20:59,236 --> 00:21:03,498
to me on X at Vishwa

341
00:21:03,514 --> 00:21:06,974
Desurukar and let's move things over. And I do

342
00:21:07,012 --> 00:21:10,306
urge people to do look at these solutions. If you are a ruby developer and

343
00:21:10,328 --> 00:21:14,226
a budding ruby developer as well, you can do look out these packages and do

344
00:21:14,248 --> 00:21:17,160
contribute to it. That will help a lot to our community.

345
00:21:22,010 --> 00:21:25,906
Now. Thank you. Con 42 Internet

346
00:21:25,938 --> 00:21:29,270
of things to speak and to share my knowledge and whatever

347
00:21:29,340 --> 00:21:32,786
I have. I would say like my experiences over the period.

348
00:21:32,978 --> 00:21:36,694
And yeah, for all the guys,

349
00:21:36,812 --> 00:21:40,398
do enjoy the solutions and do connect with me if you have

350
00:21:40,404 --> 00:21:43,966
any if you are interested in knowing how all the other things we do

351
00:21:43,988 --> 00:21:46,926
from the end to end solutions to all the other things using different sort of

352
00:21:46,948 --> 00:21:48,220
architectures. Thank you.

